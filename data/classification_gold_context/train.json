[
 {
  "id": "021c423c731ecbe3e26b3ce234b390_0",
  "x": "Automatic detection of fake from legitimate news in different formats such as headlines, tweets and full news articles has been approached in recent Natural Language Processing literature (Vlachos and Riedel, 2014; Vosoughi, 2015; Jin et al., 2016;<cite> Rashkin et al., 2017</cite>; Wang, 2017; Pomerleau and Rao, 2017; Thorne et al., 2018) .",
  "y": "background"
 },
 {
  "id": "021c423c731ecbe3e26b3ce234b390_1",
  "x": "Most previous systems built to identify fake news articles rely on training data labeled with respect to the general reputation of the sources, i.e., domains/user accounts (Fogg et al., 2001; Lazer et al., 2017;<cite> Rashkin et al., 2017)</cite> . Even though some of these studies try to identify fake news based on linguistic cues, the question is whether they learn publishers' general writing style (e.g., common writing features of a few clickbaity websites) or deceptive style (similarities among news articles that contain misinformation).",
  "y": "motivation"
 },
 {
  "id": "021c423c731ecbe3e26b3ce234b390_2",
  "x": "A few recent studies have examined full articles (i.e., actual 'fake news') to extract discriminative linguistic features of misinformation<cite> Rashkin et al., 2017</cite>; Horne and Adali, 2017) .",
  "y": "background"
 },
 {
  "id": "021e5dbe22bf0f4ebda4d37040d0a6_0",
  "x": "In the cross-lingual study of<cite> McDonald et al. (2011)</cite> , where delexicalized parsing models from a number of source languages were evaluated on a set of target languages, it was observed that the best target language was frequently not the closest typologically to the source. In one stunning example, Danish was the worst source language when parsing Swedish, solely due to greatly divergent annotation schemes.",
  "y": "motivation background"
 },
 {
  "id": "021e5dbe22bf0f4ebda4d37040d0a6_1",
  "x": "We aim to do the same for syntactic dependencies and present cross-lingual parsing experiments to highlight some of the benefits of cross-lingually consistent annotation. First, results largely conform to our expectations of which target languages should be useful for which source languages, unlike in the study of<cite> McDonald et al. (2011)</cite> .",
  "y": "differences background"
 },
 {
  "id": "021e5dbe22bf0f4ebda4d37040d0a6_2",
  "x": "The selected sentences were pre-processed using cross-lingual taggers (Das and Petrov, 2011) and parsers <cite>(McDonald et al., 2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "021e5dbe22bf0f4ebda4d37040d0a6_3",
  "x": "One of the motivating factors in creating such a data set was improved cross-lingual transfer evaluation. To test this, we use a cross-lingual transfer parser similar to that of<cite> McDonald et al. (2011)</cite> . In particular, it is a perceptron-trained shift-reduce parser with a beam of size 8.",
  "y": "extends background"
 },
 {
  "id": "021e5dbe22bf0f4ebda4d37040d0a6_4",
  "x": "We can make several interesting observations. Most notably, for the Germanic and Romance target languages, the best source language is from the same language group. This is in stark contrast to the results of<cite> McDonald et al. (2011)</cite> , who observe that this is rarely the case with the heterogenous CoNLL treebanks.",
  "y": "background differences"
 },
 {
  "id": "021e5dbe22bf0f4ebda4d37040d0a6_5",
  "x": "With respect to evaluation, it is interesting to compare the absolute numbers to those reported in<cite> McDonald et al. (2011)</cite>",
  "y": "background"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_0",
  "x": "Recent NLP work on semantic idiomaticity has focused on the task of \"compositionality prediction\", in the form of a regression task whereby a given MWE is mapped onto a continuous-valued compositionality score, either for the MWE as a whole or for each of its component words (Reddy et al., 2011; Schulte im Walde et al., 2013;<cite> Salehi et al., 2014b)</cite> .",
  "y": "background"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_1",
  "x": "There has however been recent interest in approaches to MWEs that are more broadly applicable to a wider range of languages and MWE types (Brooke et al., 2014;<cite> Salehi et al., 2014b</cite>; Schneider et al., 2014) .",
  "y": "background"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_2",
  "x": "Our first method for building vectors is that of<cite> Salehi et al. (2014b)</cite> : the top 50 most-frequent words in the training corpus are considered to be stopwords and discarded, and words with frequency rank 51-1051 are considered to be the content-bearing words, which form the dimensions for our vectors, in the manner of Sch\u00fctze (1997) .",
  "y": "uses"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_3",
  "x": "The state-of-the-art method for this dataset <cite>(Salehi et al., 2014b</cite> ) is a supervised support vector regression model, trained over the distributional method from Section 3.1 as applied to both English and 51 target languages (under word and MWE translation).",
  "y": "background"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_4",
  "x": "The state-of-the-art method for this dataset <cite>(Salehi et al., 2014b</cite> ) is a linear combination of: (1) the distributional method from Section 3.1; (2) the same method applied to 10 target languages (under word and MWE translation, selecting the languages using supervised learning); and (3) the string similarity method of Salehi and Cook (2013) .",
  "y": "background"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_5",
  "x": "Note that for EVPC, we don't use the vector for the particle, in keeping with<cite> Salehi et al. (2014b)</cite> ; as such, there are no results for comp 2 .",
  "y": "similarities"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_6",
  "x": "For comp 1 , \u03b1 is set to 1.0 for EVPC, and 0.7 for both ENC and GNC, also based on the findings of<cite> Salehi et al. (2014b)</cite> .",
  "y": "uses"
 },
 {
  "id": "022049c0e75a490978b2c49da41deb_7",
  "x": "In future work we intend to explore the contribution of information from word embeddings of a target expression and its component words under translation into many languages, along the lines of<cite> Salehi et al. (2014b)</cite> .",
  "y": "similarities future_work"
 },
 {
  "id": "023a954d97b5d761b01f09bb242d19_0",
  "x": "Abstract Meaning Representation (AMR) forms a rooted acyclic directed graph that represents the content of a sentence. All nodes and edges of the AMR graph are labeled according to the sense of the words in a sentence. AMR parsing is the task of converting a given sentence to a corresponding graph. AMRs have been applied to several applications such as event extraction [13, 7] , text summarization [6, 11] and text generation [15, 14] . However, AMR annotation which requires a lot of human effort limits the outcome of data-driven approaches, one of which being neural network based methods<cite> [10,</cite> 3] . Therefore, a highly accurate parser is necessary in order to intensify other applications which are based on AMR.",
  "y": "motivation background"
 },
 {
  "id": "023a954d97b5d761b01f09bb242d19_1",
  "x": "NeuralAMR <cite>[10]</cite> has succeeded at both AMR parsing and sentence generation as the result of a bootstrapping training strategy on a 20-million-sentence unsupervised dataset.",
  "y": "background"
 },
 {
  "id": "023a954d97b5d761b01f09bb242d19_2",
  "x": "Although recent studies have utilized Long Short-Term Memory (LSTM) in AMR parsing<cite> [10,</cite> 1] , there are several disadvantages of employing LSTM compared to CNN. First, LSTM models long dependency, which might be noise to generate a linearized graph, whereas CNN provides a shorter dependency which is advantageous to generate graph traversal. Secondly, LSTM requires a chronologically computing process that restrains the ability of parallelization; on the contrary, CNN enables simultaneous parsing.",
  "y": "motivation background"
 },
 {
  "id": "023a954d97b5d761b01f09bb242d19_3",
  "x": "Unlike the prior work <cite>[10]</cite> , in our model, the graphs pass through a much simpler pre-processing series which consists of variable removal, graph linearization, and infrequent word replacement. For stripping the AMR text, we modified the depth-first-search traversal from the work of Kontas et al <cite>[10]</cite> in the way of marking the end of a path. The left parentheses are ignored and the right parentheses are replaced by doubling the concept of the terminal node. The process of recovering the stripped text from the graph is called de-linearization. The graph which contains multiple nodes of a single concept might not be perfectly reversed because those nodes have been collapsed into one.",
  "y": "extends"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_0",
  "x": "In contrast, <cite>Zilio et al. (2011)</cite> make a study involving training a model but use it only on English and use extra lexical resources to complement the machine learning method, so their study does not focus just on classifier evaluation.",
  "y": "background"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_1",
  "x": "In contrast, <cite>Zilio et al. (2011)</cite> make a study involving training a model but use it only on English and use extra lexical resources to complement the machine learning method, so their study does not focus just on classifier evaluation. This paper presents the first evaluation of mwetoolkit on French together with two resources very commonly used by the French NLP community: the tagger TreeTagger (Schmid, 1994) and the dictionary Dela.",
  "y": "motivation"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_2",
  "x": "Ramisch et al. (2010b) provide experiments on Portuguese, English and Greek. <cite>Zilio et al. (2011)</cite> provide experiments with this tool as well.",
  "y": "background"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_3",
  "x": "That is the reason why we will run three experiments close to the one of <cite>Zilio et al. (2011)</cite> but were the only changing parameter is the pattern that we train our classifiers on.",
  "y": "uses motivation"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_4",
  "x": "In contrast to <cite>Zilio et al. (2011)</cite> we run our experiment on French.",
  "y": "differences"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_5",
  "x": "For preprocessing we used the same processes as described in <cite>Zilio et al. (2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "033ce75c882764e08fb3871656a8d1_6",
  "x": "We tested several algorithms offered by Weka as well as the training options suggested by <cite>Zilio et al. (2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "03b7c2e050957dcff336183823e6f1_0",
  "x": "We use a recently proposed dependency parser <cite>(Titov and Henderson, 2007b )</cite> 1 which has demonstrated state-of-theart performance on a selection of languages from the CoNLL-X shared task (Buchholz and Marsi, 2006) .",
  "y": "uses"
 },
 {
  "id": "03b7c2e050957dcff336183823e6f1_1",
  "x": "When conditioning on words, we treated each word feature individually, as this proved to be useful in <cite>(Titov and Henderson, 2007b)</cite> .",
  "y": "motivation"
 },
 {
  "id": "03b7c2e050957dcff336183823e6f1_2",
  "x": "In our experiments we use the same definition of structural locality as was proposed for the ISBN dependency parser in <cite>(Titov and Henderson, 2007b)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "03b7c2e050957dcff336183823e6f1_3",
  "x": "Unlike <cite>(Titov and Henderson, 2007b )</cite>, in the shared task we used only the simplest feed-forward approximation, which replicates the computation of a neural network of the type proposed in (Henderson, 2003) .",
  "y": "differences"
 },
 {
  "id": "03b7c2e050957dcff336183823e6f1_4",
  "x": "To search for the most probable parse, we use the heuristic search algorithm described in <cite>(Titov and Henderson, 2007b)</cite> , which is a form of beam search.",
  "y": "uses"
 },
 {
  "id": "03b7c2e050957dcff336183823e6f1_5",
  "x": "As was demonstrated in <cite>(Titov and Henderson, 2007b)</cite> , even a minimal set of local explicit features achieves results which are non-significantly different from a carefully chosen set of explicit features, given the language independent definition of locality described in section 2.",
  "y": "similarities"
 },
 {
  "id": "0410820bea04fb68908f4885089081_0",
  "x": "tagger (e.g. the <cite>Brill tagger</cite> <cite>[2]</cite> ) for the English documents.",
  "y": "uses"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_0",
  "x": "<cite>(Gliozzo et al., 2005)</cite> succeeded eliminating this requirement by using the category name alone as the initial keyword, yet obtaining superior performance within the keywordbased approach.",
  "y": "background"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_1",
  "x": "<cite>(Gliozzo et al., 2005)</cite> succeeded eliminating this requirement by using the category name alone as the initial keyword, yet obtaining superior performance within the keywordbased approach. The goal of our research is to further improve the scheme of text categorization from category name, which was hardly explored in prior work.",
  "y": "motivation"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_2",
  "x": "When analyzing the behavior of the LSA representation of <cite>(Gliozzo et al., 2005)</cite> we noticed that <cite>it captures</cite> two types of similarities between the category name and document terms. <cite>One type</cite> regards words which refer specifically to the category name's meaning, such as pitcher for the category Baseball.",
  "y": "background"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_3",
  "x": "When analyzing the behavior of the LSA representation of <cite>(Gliozzo et al., 2005)</cite> we noticed that <cite>it captures</cite> two types of similarities between the category name and document terms. <cite>One type</cite> regards words which refer specifically to the category name's meaning, such as pitcher for the category Baseball. However, typical context words for the category which do not necessarily imply its specific meaning, like stadium, also come up as similar to baseball in LSA space. This limits <cite>the method's precision</cite>, due to false-positive classifications of contextually-related documents that do not discuss the specific category topic (such as other sports documents wrongly classified to Baseball). <cite>This behavior</cite> is quite typical for query expansion methods, which expand a query with contextually correlated terms. We propose a novel scheme that models separately these two types of similarity.",
  "y": "motivation"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_4",
  "x": "As described in Section 1, the keyword list in <cite>(Gliozzo et al., 2005)</cite> consisted of the category name alone. <cite>This was accompanied</cite> by representing the category names and documents (step 2) in LSA space, obtained through cooccurrence-based dimensionality reduction. In <cite>this space</cite>, words that tend to cooccur together, or occur in similar contexts, are represented by similar vectors.",
  "y": "background"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_5",
  "x": "We thus extend the scheme in Figure 1 by creating two vectors per category (in steps 1 and 2): a reference vector c ref in term space, consisting of referring terms for the category name; and a context vector c con , representing the category name in LSA space, as in <cite>(Gliozzo et al., 2005)</cite> .",
  "y": "uses"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_6",
  "x": "We therefore measure the contextual similarity between a category c and a document d utilizing LSA space, replicating the method in <cite>(Gliozzo et al., 2005)</cite> : c con and d LSA are taken as the LSA vectors of the category name and the document, respectively, yielding Sim con (c, d) = cos( c con , d LSA )).",
  "y": "uses"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_7",
  "x": "We tested our method on the two corpora used in <cite>(Gliozzo et al., 2005)</cite> : 20-NewsGroups, classified by a single-class scheme (single category per document), and Reuters-10 3 , of a multi-class scheme. As in <cite>their work</cite>, non-standard category names were adjusted, such as Foreign exchange for Money-fx.",
  "y": "uses"
 },
 {
  "id": "04b525b91b48e31258287a015d0401_8",
  "x": "As we hypothesized, the Reference model achieves much better precision than the Context model from <cite>(Gliozzo et al., 2005)</cite> resources, yielding a lower F1.",
  "y": "differences"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_0",
  "x": "<cite>Transformer</cite> is a powerful architecture that achieves superior performance on various sequence learning tasks, including neural machine translation, language understanding, and sequence prediction.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_1",
  "x": "At the core of the <cite>Transformer</cite> is the attention mechanism, which concurrently processes all inputs in the streams.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_2",
  "x": "This new formulation gives us a better way to understand individual components of the <cite>Transformer's</cite> attention, such as the better way to integrate the positional embedding.",
  "y": "motivation"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_3",
  "x": "Another important advantage of our kernel-based formulation is that it paves the way to a larger space of composing <cite>Transformer</cite>'s attention.",
  "y": "motivation"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_4",
  "x": "As an example, we propose a new variant of <cite>Transformer's</cite> attention which models the input as a product of symmetric kernels.",
  "y": "extends"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_5",
  "x": "<cite>Transformer</cite> <cite>(Vaswani et al., 2017 )</cite> is a relative new architecture which outperforms traditional deep learning models such as Recurrent Neural Networks (RNNs) (Sutskever et al., 2014) and Temporal Convolutional Networks (TCNs) (Bai et al., 2018) for sequence modeling tasks across neural machine translations <cite>(Vaswani et al., 2017)</cite> , language understanding (Devlin et al., 2018) , sequence prediction (Dai et al., 2019) , image generation (Child et al., 2019) , video activity classification (Wang et al., 2018) , music generation (Huang et al., 2018a) , and multimodal sentiment analysis (Tsai et al., 2019a) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_6",
  "x": "Instead of performing recurrence (e.g., RNN) or convolution (e.g., TCN) over the sequences, <cite>Transformer</cite> is a feed-forward model that concurrently processes the entire sequence.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_7",
  "x": "At the core of the <cite>Transformer</cite> is its attention mechanism, which is proposed to integrate the dependencies between the inputs.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_8",
  "x": "There are up to three types of attention within the full <cite>Transformer</cite> model as exemplified with neural machine translation application <cite>(Vaswani et al., 2017)</cite> : 1) Encoder self-attention considers the source sentence as input, generating a sequence of encoded representations, where each encoded token has a global dependency with other tokens in the input sequence.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_9",
  "x": "In all cases, the <cite>Transformer's</cite> attentions follow the same general mechanism.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_10",
  "x": "We note that this operation is orderagnostic to the permutation in the input se-quence (order is encoded with extra positional embedding <cite>(Vaswani et al., 2017</cite>; Shaw et al., 2018; Dai et al., 2019) ).",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_11",
  "x": "The above observation inspires us to connect <cite>Transformer's</cite> attention to kernel learning (Scholkopf and Smola, 2001) : they both concurrently and order-agnostically process all inputs by calculating the similarity between the inputs.",
  "y": "motivation"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_12",
  "x": "Therefore, in the paper, we present a new formulation for <cite>Transformer's</cite> attention via the lens of kernel.",
  "y": "motivation"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_13",
  "x": "Furthermore, our proposed formulation highlights naturally the main components of <cite>Transformer's</cite> attention, enabling a better understanding of this mechanism: recent variants of <cite>Transformers</cite> (Shaw et al., 2018; Huang et al., 2018b; Dai et al., 2019; Child et al., 2019; Wang et al., 2018; Tsai et al., 2019a) can be expressed through these individual components.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_15",
  "x": "Next, we show that this new formulation allows us to explore new family of attention while at the same time offering a framework to categorize previous attention variants <cite>(Vaswani et al., 2017</cite>; Shaw et al., 2018; Huang et al., 2018b; Dai et al., 2019; Child et al., 2019; Wang et al., 2018; Tsai et al., 2019a) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_17",
  "x": "Unlike recurrent computation (Sutskever et al., 2014 ) (i.e., RNNs) and temporal convolutional computation (Bai et al., 2018 ) (i.e., TCNs), <cite>Transformer's</cite> attention is an order-agnostic operation given the order in the inputs <cite>(Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_18",
  "x": "As a result, <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> introduced positional embedding to indicate the positional relation for the inputs.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_19",
  "x": "Note that f i can be the word representation (in neural machine translation <cite>(Vaswani et al., 2017)</cite> ), a pixel in a frame (in video activity recognition (Wang et al., 2018) ), or a music unit (in music generation (Huang et al., 2018b) ).",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_20",
  "x": "t i can be a mixture of sine and cosine functions <cite>(Vaswani et al., 2017)</cite> or parameters that can be learned during back-propagation (Dai et al., 2019; Ott et al., 2019) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_21",
  "x": "Followed the definition by <cite>Vaswani et al. (2017)</cite> , we use queries(q)/keys(k)/values(v) to represent the inputs for the attention.",
  "y": "uses"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_22",
  "x": "Given the introduced notation, the attention mechanism in original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> can be presented as:",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_23",
  "x": "Recent work (Shaw et al., 2018; Dai et al., 2019; Huang et al., 2018b; Child et al., 2019; Parmar et al., 2018; Tsai et al., 2019a) proposed modifications to the <cite>Transformer</cite> for the purpose of better modeling inputs positional relation (Shaw et al., 2018; Huang et al., 2018b; Dai et al., 2019) , appending additional keys in S x k (Dai et al., 2019) , modifying the mask applied to Eq. (1) (Child et al., 2019) , or applying to distinct feature types Parmar et al., 2018; Tsai et al., 2019a) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_24",
  "x": "The filtering function M (\u22c5, \u22c5) plays as the role of the mask in decoder self-attention <cite>(Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_26",
  "x": "Note that the kernel form k(x q , x k ) in the original <cite>Transformer</cite> <cite>(Vaswani et al., 2017 )</cite> is a asymmetric exponential kernel with additional mapping W q and W k (Wilson et al., 2016; Li et al., 2017) 2 .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_27",
  "x": "In addition to modeling sequences like word sentences <cite>(Vaswani et al., 2017)</cite> or music signals (Huang et al., 2018b) , the <cite>Transformer</cite> can also be applied to images (Parmar et al., 2018) , sets , and multimodal sequences (Tsai et al., 2019a) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_28",
  "x": "Due to distinct data types, these applications admit various kernel feature space: <cite>(Vaswani et al., 2017</cite>; Dai et al., 2019) :",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_33",
  "x": "Positional Embedding k(\u22c5, \u22c5) The kernel construction on X = (F \u00d7 T ) has distinct design in variants of <cite>Transformers</cite> <cite>(Vaswani et al., 2017</cite>; Dai et al., 2019; Huang et al., 2018b; Shaw et al., 2018; Child et al., 2019) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_34",
  "x": "(i) Absolute Positional Embedding <cite>(Vaswani et al., 2017</cite>; Dai et al., 2019; Ott et al., 2019) : For the original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> , each t i is represented by a vector with each dimension being sine or cosine functions.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_35",
  "x": "(ii) Relative Positional Embedding in <cite>Transformer</cite>-XL (Dai et al., 2019) : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions:",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_36",
  "x": "with k fq t q , t k being an asymmetric kernel with coefficients inferred by f q : log k fq t q , t k = \u2211 (iii) Relative Positional Embedding of Shaw et al. (2018) and Music <cite>Transformer</cite> (Huang et al., 2018b) : t \u22c5 represents the indicator of the position in the sequence, and the kernel is modified to be indexed by a look-up table:",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_37",
  "x": "The current <cite>Transformers</cite> consider two different value function construction: <cite>(Vaswani et al., 2017)</cite> and Sparse <cite>Transformer</cite> (Child et al., 2019) :",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_39",
  "x": "In the following, we itemize the corresponding designs for the variants in <cite>Transformers</cite>: (i) Encoder Self-Attention in original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> : For each query x q in the encoded sequence, M (x q , S x k ) = S x k contains the keys being all the tokens in the encoded sequence.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_40",
  "x": "(ii) Encoder-Decoder Attention in original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> : For each query x q in decoded sequence, M (x q , S x k ) = S x k contains the keys being all the tokens in the encoded sequence.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_41",
  "x": "(iii) Decoder Self-Attention in original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> : For each query x q in the decoded sequence, M (x q , S x k ) returns a subset of S x k (M (x q , S x k ) \u2282 S x k ).",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_42",
  "x": "Since the decoded sequence is the output for previous timestep, the query at position i can only observe the keys being the tokens that are decoded with position < i. For convenience, let us define S 1 as the set returned by original <cite>Transformer</cite> <cite>(Vaswani et al., 2017 )</cite> from M (x q , S x k ), which we will use it later.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_43",
  "x": "(iv) Decoder Self-Attention in <cite>Transformer</cite>-XL (Dai et al., 2019) : For each query x q in the decoded sequence, M (x q , S x k ) returns a set containing S 1 and additional memories (M (x q , S x k ) = S 1 + S mem , M (x q , S x k ) \u2283 S 1 ).",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_44",
  "x": "(v) Decoder Self-Attention in Sparse <cite>Transformer</cite> (Child et al., 2019) : For each query x q in the decoded sentence, M (x q , S x k ) returns a subset of S 1 (M (x q , S x k ) \u2282 S 1 ).",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_45",
  "x": "For performance-wise comparisons, <cite>Transformer</cite>-XL (Dai et al., 2019) showed that, the additional memories in M (x q , S x k ) are able to capture longer-term dependency than the original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> and hence results in better performance.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_46",
  "x": "Sparse <cite>Transformer</cite> (Child et al., 2019) showed that although having much fewer elements in M (x q , S x k ), if the elements are carefully chosen, the attention can still reach the same performance as <cite>Transformer</cite>-XL (Dai et al., 2019) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_48",
  "x": "Note that t i here is chosen as the mixture of sine and cosine functions as in the prior work <cite>(Vaswani et al., 2017</cite>; Ott et al., 2019) .",
  "y": "uses"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_50",
  "x": "We conduct experiments on neural machine translation (NMT) and sequence prediction (SP) tasks since these two tasks are commonly chosen for studying <cite>Transformers</cite> <cite>(Vaswani et al., 2017</cite>; Dai et al., 2019) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_52",
  "x": "Similar to prior work <cite>(Vaswani et al., 2017</cite>; Dai et al., 2019) , we report BLEU score for NMT and perplexity for SP.",
  "y": "similarities"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_53",
  "x": "Other than manipulating the kernel choice of the non-positional features, we fix the configuration by <cite>Vaswani et al. (2017)</cite> for NMT and the configuration by Dai et al. (2019) for SP.",
  "y": "uses differences"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_54",
  "x": "Note that, for fairness, other than manipulating the kernel choice of the non-positional features, we fix the configuration by <cite>Vaswani et al</cite>. <cite>(Vaswani et al., 2017)</cite> for NMT and the configuration by Dai et al. (Dai et al., 2019) for SP.",
  "y": "uses differences"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_56",
  "x": "The need of the positional embedding (PE) in the attention mechanism is based on the argument that the attention mechanism is an order-agnostic (or, permutation equivariant) operation <cite>(Vaswani et al., 2017</cite>; Shaw et al., 2018; Huang et al., 2018b; Dai et al., 2019; Child et al., 2019) .",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_57",
  "x": "For clarification, we are not attacking the claim made by the prior work <cite>(Vaswani et al.,</cite> 2017; Shaw et al., 2018;  Huang et al., 2018b; Dai et al., 2019; Child et al., 2019 ), but we aim at providing a new look at the order-invariance problem when considering the attention mechanism with masks (masks refer to the set filtering function in our kernel formulation).",
  "y": "motivation"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_58",
  "x": "Denote \u03a0 as the set of all permutations over [n] = {1, \u22ef, n}. A function f unc \u2236 X n \u2192 Y n is permutation equivariant iff for any permutation \u03c0 \u2208 \u03a0, f unc(\u03c0x) = \u03c0f unc(x). showed that the standard attention (encoder self-attention <cite>(Vaswani et al., 2017</cite>; Dai et al., 2019) ) is permutation equivariant.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_60",
  "x": "Nonetheless, the performance is slightly better than considering PE from the original <cite>Transformer</cite> <cite>(Vaswani et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_61",
  "x": "Other than relating <cite>Transformer's</cite> attention mechanism with kernel methods, the prior work (Wang et al., 2018; Shaw et al., 2018; Tsai et al., 2019b ) related the attention mechanism with graph-structured learning.",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_62",
  "x": "In addition to the fundamental difference between graph-structured learning and kernel learning, the prior work (Wang et al., 2018; Shaw et al., 2018; Tsai et al., 2019b) focused on presenting <cite>Transformer</cite> for its particular application (e.g., video classification (Wang et al., 2018) and neural machine translation (Shaw et al., 2018) ).",
  "y": "background"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_63",
  "x": "Alternatively, our work focuses on presenting a new formulation of <cite>Transformer's</cite> attention mechanism that gains us the possibility for understanding the attention mechanism better.",
  "y": "motivation"
 },
 {
  "id": "04f6b9d4296dee4bbf965f9911bf98_64",
  "x": "In this paper, we presented a kernel formulation for the attention mechanism in <cite>Transformer</cite>, which allows us to define a larger space for designing attention.",
  "y": "differences"
 },
 {
  "id": "0526911ab71c85bfa4a20b630f34ae_0",
  "x": "Morphologically rich languages like Arabic <cite>(Beesley, K. 1996</cite> ) present significant challenges to many natural language processing applications as the one described above because a word often conveys complex meanings decomposable into several morphemes (i.e. prefix, stem, suffix) .",
  "y": "background"
 },
 {
  "id": "0526911ab71c85bfa4a20b630f34ae_1",
  "x": "Morphologically rich languages like Arabic <cite>(Beesley, K. 1996</cite> ) present significant challenges to many natural language processing applications as the one described above because a word often conveys complex meanings decomposable into several morphemes (i.e. prefix, stem, suffix) . By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation (Brown et al. 1993 ) and information retrieval (Franz, M. and McCarley, S. 2002) .",
  "y": "extends"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_0",
  "x": "In order for the event mentions to be useful (i.e., for knowledge extraction tasks), it is important to determine their factual certainty so the actual event mentions can be retrieved (i.e., the event factuality prediction problem (EFP)). In this work, we focus on the recent regression formulation of EFP that aims to predict a real score in the range of [-3,+3 ] to quantify the occurrence possibility of a given event mention (Stanovsky et al., 2017;<cite> Rudinger et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_1",
  "x": "EFP is a challenging problem as different context words might jointly participate to reveal the factuality of the event mentions (i.e., the cue words), possibly located at different parts of the sentences and scattered far away from the anchor words of the events. There are two major mechanisms that can help the models to identify the cue words and link them to the anchor words, i.e., the syntactic trees (i.e., the dependency trees) and the semantic information<cite> (Rudinger et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_2",
  "x": "For the syntactic trees, they can connect the anchor words to the functional words (i.e., negation, modal auxiliaries) that are far away, but convey important information to affect the factuality of the event mentions. For instance, the dependency tree of the sentence \"I will, after seeing the treatment of others, go back when I need medical care.\" will be helpful to directly link the anchor word \"go\" to the modal auxiliary \"will\" to successfully predict the non-factuality of the event mention. Regarding the semantic information, the meaning of the some important context words in the sentences can contribute significantly to the factuality of an event mention. For example, in the sentence \"Knight lied when he said I went to the ranch.\", the meaning represented by the cue word \"lied\" is crucial to classify the event mention associated with the anchor word \"went\" as non-factual. The meaning of such cue words and their interactions with the anchor words can be captured via their distributed representations (i.e., with word embeddings and long-short term memory networks (LSTM))<cite> (Rudinger et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_3",
  "x": "The current state-of-the-art approach for EFP has involved deep learning models <cite>(Rudinger et al., 2018</cite> ) that examine both syntactic and semantic information in the modeling process. However, in these models, the syntactic and semantic information are only employed separately in the different deep learning architectures to generate syntactic and semantic representations. Such representations are only concatenated in the final stage to perform the factuality prediction. A major problem with this approach occurs in the event mentions when the syntactic and semantic information cannot identify the important structures for EFP individually (i.e., by itself). In such cases, both the syntactic and semantic representations from the separate deep learning models would be noisy and/or insufficient, causing the poor quality of their simple combination for EFP.",
  "y": "motivation background"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_4",
  "x": "Recently, deep learning has been applied to solve EFP. (Qian et al., 2018) employ Generative Adversarial Networks (GANs) for EFP while<cite> (Rudinger et al., 2018)</cite> utilize LSTMs for both sequential and dependency representations of the input sentences.",
  "y": "background"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_5",
  "x": "In the next step, we further abstract (e 1 , e 2 , . . . , e n ) for EFP by feeding them into two layers of bidirectional LSTMs (as in<cite> (Rudinger et al., 2018)</cite> ).",
  "y": "uses"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_6",
  "x": "Given the hidden representation (h 1 , h 2 , . . . , h n ), it is possible to use the hidden vector corresponding to the anchor word h k as the features to perform factuality prediction (as done in<cite> (Rudinger et al., 2018)</cite> ). However, despite the rich context information over the whole sentence, the features in h k are not directly designed to focus on the import context words for factuality prediction. In order to explicitly encode the information of the cue words into the representations for the anchor word, we propose to learn an importance matrix A = (a ij ) i,j=1..n in which the value in the cell a ij quantifies the contribution of the context word x i for the hidden representation at x j if the representation vector at x j is used to form features for EFP.",
  "y": "differences"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_7",
  "x": "Finally, similar to<cite> (Rudinger et al., 2018)</cite> , the feature vector V is fed into a regression model with two layers of feed-forward networks to produce the factuality score.",
  "y": "uses"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_8",
  "x": "Following<cite> (Rudinger et al., 2018)</cite> , we train the proposed model by optimizing the Huber loss with \u03b4 = 1 and the Adam optimizer with learning rate = 1.0.",
  "y": "uses"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_9",
  "x": "For the fourth dataset (i.e., UDS-IH2), we follow the instructions in<cite> (Rudinger et al., 2018)</cite> to scale the scores to the range of [-3, +3] .",
  "y": "uses"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_10",
  "x": "Following the previous work (Stanovsky et al., 2017;<cite> Rudinger et al., 2018)</cite> , we evaluate the proposed EFP model using four benchmark datasets: FactBack (Saur\u00ed and Pustejovsky, 2009 ), UW (Lee et al., 2015) , Meantime (Minard et al., 2016) and UDS-IH2<cite> (Rudinger et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_11",
  "x": "We compare the proposed model with the best reported systems in the literature with linguistic features (Lee et al., 2015; Stanovsky et al., 2017) and deep learning<cite> (Rudinger et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "05b53f9e0a347c4f47d0fd066538c7_12",
  "x": "Importantly, to achieve a fair comparison, we obtain the actual implementation of the current state-of-the-art EFP models from<cite> (Rudinger et al., 2018)</cite> , introduce the BERT embeddings as the inputs for those models and compare them with the proposed models (i.e., the rows with \"+BERT\").",
  "y": "extends"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_0",
  "x": "The introduction of pre-trained language models, such as BERT <cite>[2]</cite> and Open-GPT [3] , among many others, has brought tremendous progress to the NLP research and industrial communities.",
  "y": "background"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_1",
  "x": "Some early attempts include pre-trained models includes, CoVe [12] , CVT [13, 14] , ELMo [15] and ULMFiT [16] . However, the most successful ones are BERT <cite>[2]</cite> and Open-GPT [3] .",
  "y": "background"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_2",
  "x": "In the presence of the success of pre-trained language models, especially BERT <cite>[2]</cite> , it is natural to ask how to best utilize the pre-trained language models to achieve new state-of-the-art results.",
  "y": "motivation"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_3",
  "x": "Stickland and Murray [22] invented projected attention layer for multi-task learning using BERT, which results in an improvement in various state-of-the-art results compared to the original work of Devlin et al. <cite>[2]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_4",
  "x": "In this line of work, Liu et al. [21] investigated the linguistic knowledge and transferability of contextual representations by comparing BERT <cite>[2]</cite> with ELMo [15] , and concluded that while the higher levels of LSTM's are more task-specific, this trend does not exhibit in transformer based models.",
  "y": "background"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_5",
  "x": "In the paradigm proposed in the original work by Devlin et al. <cite>[2]</cite> , the author directly trained BERT along with with a light-weighted task-specific head.",
  "y": "background"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_6",
  "x": "Since BERT-Adam <cite>[2]</cite> has excellent performance, in our experiments, we use it as an optimizer with \u03b2 1 = 0.9, \u03b2 2 = 0.999,L 2 -weight decay of 0.01.We apply a dropout trick on all layers and set the dropout probability as 0.1.",
  "y": "similarities uses"
 },
 {
  "id": "05d1ecc230c7907d9a14d3351070c3_7",
  "x": "In the sequence labeling task,we explore sub-task named entity recognition using CoNLL03 dataset [6] , which is a public available used in many studies to test the accuracy of their proposed methods [30, 31, 32, 33,<cite> 2]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "05eecafea7684dc8de13c29a76b767_0",
  "x": "The strong geographical bias, most obviously at the language level (e.g. Finland vs. Japan), and more subtly at the dialect level (e.g. in English used in north-west England vs. north-east USA vs. Texas, USA), clearly reflected in language use in social media services such as Twitter, has been used extensively either for geolocation of users<cite> (Eisenstein et al., 2010</cite>; Roller et al., 2012; Rout et al., 2013; Wing and Baldridge, 2014) or dialectology Eisenstein, 2015) .",
  "y": "background"
 },
 {
  "id": "05eecafea7684dc8de13c29a76b767_1",
  "x": "Three main text-based approaches are: (1) the use of gazetteers Quercini et al., 2010) ; (2) unsupervised text clustering based on topic models or similar<cite> (Eisenstein et al., 2010</cite>; Hong et al., 2012; Ahmed et al., 2013) ; and (3) supervised classification (Ding et al., 2000; Backstrom et al., 2008; Cheng et al., 2010; Hecht et al., 2011; Kinsella et al., 2011; Wing and Baldridge, 2011; Han et al., 2012; Rout et al., 2013) , which unlike gazetteers can be applied to informal text and compared to topic models, scales better.",
  "y": "background"
 },
 {
  "id": "05eecafea7684dc8de13c29a76b767_2",
  "x": "There have also been attempts to automatically identify such words from geotagged documents<cite> (Eisenstein et al., 2010</cite>; Ahmed et al., 2013; Eisenstein, 2015) .",
  "y": "background"
 },
 {
  "id": "05eecafea7684dc8de13c29a76b767_3",
  "x": "We use three existing Twitter user geolocation datasets: (1) GEOTEXT<cite> (Eisenstein et al., 2010)</cite> , (2) TWITTER-US (Roller et al., 2012) , and (3) TWITTER-WORLD (Han et al., 2012) .",
  "y": "uses"
 },
 {
  "id": "05eecafea7684dc8de13c29a76b767_4",
  "x": "Following Cheng (2010) and<cite> Eisenstein (2010)</cite> , we evaluated the geolocation model using mean and median error in km (\"Mean\" and \"Median\" resp.) and accuracy within 161km of the actual location (\"Acc@161\").",
  "y": "uses"
 },
 {
  "id": "05fe3e9c1598f5b36b6efa79216309_0",
  "x": "presented an efficient method to generate the next word in a sequence when it is added an attention mechanism, improving the performance for long textual sequences <cite>[1]</cite> .",
  "y": "background"
 },
 {
  "id": "05fe3e9c1598f5b36b6efa79216309_1",
  "x": "The model is trained using two real-world datasets: BeerAdvocate [5] and Amazon book reviews <cite>[1]</cite> .",
  "y": "uses"
 },
 {
  "id": "05fe3e9c1598f5b36b6efa79216309_2",
  "x": "\u2022 Attention mechanism The attention mechanism, adaptively learns soft alignments c t between character dependencies H t and attention inputs a. Eq. 1 formally defines the new character dependencies using attention layer H attention t <cite>[1]</cite> .",
  "y": "uses"
 },
 {
  "id": "05fe3e9c1598f5b36b6efa79216309_3",
  "x": "The characters are given by maximizing the softmax conditional probability p, based on the new character dependencies H attention t <cite>[1]</cite> , as presented in Eq. 2 p = softmax(H attention t W + b), char = arg max p (2)",
  "y": "uses"
 },
 {
  "id": "05fe3e9c1598f5b36b6efa79216309_4",
  "x": "The model differs from recent works <cite>[1,</cite> 6] , due to the use of attention layer combined with character-level LSTM.",
  "y": "differences"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_0",
  "x": "AMRs can be seen as graphs connecting concepts by relations. Each concept is represented by a named instance. Co-reference is established by re-using these instances. For example, the AMRs corresponding to examples (1) and (2) above are given in Figure 1 . Note that, due to the bracketing, the variable b encapsulates the whole entity person :name \"Bob\" and not just person, i.e. b stands for a person with the name Bob. That there is a lot to gain in this area can be seen by applying the AMR evaluation suite of Damonte et al. (2017) , which calculates nine different metrics to evaluate AMR parsing, reentrancy being one of them. Out of the four systems that made these scores available (all scores reported in<cite> van Noord and Bos (2017)</cite> ), the reentrancy metric obtained the lowest F-score for three of them.",
  "y": "background"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_1",
  "x": "Various methods have been proposed to automatically parse AMRs, ranging from syntax-based approaches (e.g. Flanigan et al. (2014) ; Wang et al. (2015) ; Pust et al. (2015) ; Damonte et al. (2017) ) to the more recent neural approaches (Peng et al. (2017) ; Buys and Blunsom (2017) ; Konstas et al. (2017) ; Foland and Martin (2017);<cite> van Noord and Bos (2017)</cite> ). Especially the neural approaches are interesting, since they all use some sort of linearization method and therefore need a predefined way to handle reentrancy.",
  "y": "motivation background"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_2",
  "x": "Foland and Martin (2017) and<cite> van Noord and Bos (2017)</cite> use the same input transformation as Konstas et al. (2017) , but do try to restore co-referring nodes by merging all equal concepts into a single concept in a post-processing step. All these methods have in common that they are not very sophisticated, but more importantly, that it is not clear what the exact impact of these methods is on the final performance of the model, making it unclear what the best implementation is for future neural AMR parsers.",
  "y": "motivation background"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_3",
  "x": "In this paper we present three methods to handle reentrancy for AMR parsing. The first two methods are based on the previous work described above, while the third is a new, more principled method. These methods are applied on the model that reported the best results in the literature, the character-level neural semantic parsing method of<cite> van Noord and Bos (2017)</cite> . In a nutshell, this method uses a character-based sequence-to-sequence model to translate sentences to AMRs. To enable this process, pre-processing and post-processing steps are needed.",
  "y": "uses background"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_4",
  "x": "Method 1B: Reentrancy Restoring This method is created to restore reentrancy nodes in the output of the baseline model. It operates on a very ad hoc principle: if two nodes have the same concept, the second one was actually a reference to the first one. We therefore replace each node that has already occurred in the AMR by the variable of the antecedent node. This approach was applied by<cite> van Noord and Bos (2017)</cite> and Foland and Martin (2017) .",
  "y": "uses"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_5",
  "x": "The parameter settings are the same as in<cite> van Noord and Bos (2017)</cite> and are shown in Table 2 .",
  "y": "uses"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_6",
  "x": "We test the impact of the different methods on two of our earlier models, described in<cite> van Noord and Bos (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "06276db79ed5aa04bb24a31c10d3a9_7",
  "x": "The second approach also employs the postprocessing methods Wikification and pruning, as explained in<cite> van Noord and Bos (2017)</cite>.",
  "y": "uses background"
 },
 {
  "id": "06db17253d76150772c0926e11131d_0",
  "x": "Several large real image VQA datasets have recently emerged [8] [9]<cite> [10]</cite> [11] [12] [13] [14] .",
  "y": "background"
 },
 {
  "id": "06db17253d76150772c0926e11131d_1",
  "x": "However, it has been shown that they tend to exploit statistical regularities between answer occurrences and certain patterns in the question [24, <cite>10,</cite> 25, 23, 13] . While they are designed to merge information from both modalities, in practice they often answer without considering the image modality.",
  "y": "motivation"
 },
 {
  "id": "06db17253d76150772c0926e11131d_2",
  "x": "However, when evaluated on a test set that displays different statistical regularities, they usually suffer from a significant drop in accuracy<cite> [10,</cite> 25] .",
  "y": "motivation"
 },
 {
  "id": "06db17253d76150772c0926e11131d_3",
  "x": "We run extensive experiments on VQA-CP v2<cite> [10]</cite> and demonstrate the ability of RUBi to surpass current state-of-the-art results from a significant margin.",
  "y": "uses"
 },
 {
  "id": "06db17253d76150772c0926e11131d_4",
  "x": "VQA-CP v2 and VQA-CP v1<cite> [10]</cite> were recently introduced as diagnostic datasets containing different answer distributions for each questiontype between train and test splits.",
  "y": "background"
 },
 {
  "id": "06db17253d76150772c0926e11131d_5",
  "x": "VQA-CP v2 and VQA-CP v1<cite> [10]</cite> were recently introduced as diagnostic datasets containing different answer distributions for each questiontype between train and test splits. Consequentially, models biased towards the question modality fail on these benchmarks. We use the more challenging VQA-CP v2 dataset extensively in order to show the ability of our approach to reduce the learning of biases coming from the question modality.",
  "y": "uses"
 },
 {
  "id": "06db17253d76150772c0926e11131d_6",
  "x": "However, even with this additional balancing, statistical biases from the question remain and can be leveraged<cite> [10]</cite> .",
  "y": "motivation"
 },
 {
  "id": "06db17253d76150772c0926e11131d_7",
  "x": "VQA models are inclined to learn unimodal biases from the datasets<cite> [10]</cite> .",
  "y": "background"
 },
 {
  "id": "06db17253d76150772c0926e11131d_8",
  "x": "However, even with this additional balancing, statistical biases from the question remain and can be leveraged<cite> [10]</cite> . That is why we propose an approach to reduce unimodal biases during training.",
  "y": "motivation"
 },
 {
  "id": "06db17253d76150772c0926e11131d_9",
  "x": "Experimental setup We train and evaluate our models on VQA-CP v2<cite> [10]</cite> .",
  "y": "uses"
 },
 {
  "id": "06db17253d76150772c0926e11131d_10",
  "x": "This accuracy corresponds to a gain of +5.94 percentage points over the current state-of-the-art UpDn + Q-Adv + DoE. It also corresponds to a gain of +15.88 over GVQA<cite> [10]</cite> , which is a specific architecture designed for VQA-CP.",
  "y": "differences"
 },
 {
  "id": "06db17253d76150772c0926e11131d_11",
  "x": "We report a drop of 1.94 percentage points with respect to our baseline, while<cite> [10]</cite> report a drop of 3.78 between GVQA and their SAN baseline.",
  "y": "differences"
 },
 {
  "id": "06de9a8e72b832beea9c2f17e0862a_0",
  "x": "Later on, pressure from language researchers forced us to replace it with terms such as \"online memory minimization\"<cite> [5]</cite> because our initial formulation was obscure to them.",
  "y": "uses background"
 },
 {
  "id": "06de9a8e72b832beea9c2f17e0862a_1",
  "x": "Our position is grounded on the high predictive power of that principle per se<cite> [5]</cite> .",
  "y": "uses"
 },
 {
  "id": "06de9a8e72b832beea9c2f17e0862a_2",
  "x": "For sociological reasons, these arguments started appearing in print many years later [20, <cite>5,</cite> 21] .",
  "y": "background"
 },
 {
  "id": "06de9a8e72b832beea9c2f17e0862a_4",
  "x": "Later on, pressure from language researchers forced us to replace it with terms such as \"online memory minimization\"<cite> [5]</cite> because our initial formulation was obscure to them.",
  "y": "uses background"
 },
 {
  "id": "06de9a8e72b832beea9c2f17e0862a_5",
  "x": "Our position is grounded on the high predictive power of that principle per se<cite> [5]</cite> .",
  "y": "uses"
 },
 {
  "id": "06de9a8e72b832beea9c2f17e0862a_6",
  "x": "For sociological reasons, these arguments started appearing in print many years later [20, <cite>5,</cite> 21] .",
  "y": "background"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_0",
  "x": "For example, the coding manual for the Switchboard DAMSL dialogue act annotation scheme (Jurafsky, Shriberg, and Biasca 1997, page 2) states that kappa is used to \"assess labelling accuracy,\" and Di<cite> Eugenio and Glass (2004)</cite> relate reliability to \"the objectivity of decisions,\" whereas Carletta (1996) regards reliability as the degree to which we understand the judgments that annotators are asked to make.",
  "y": "background"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_1",
  "x": "Di<cite> Eugenio and Glass (2004)</cite> identify three general classes of agreement statistics and suggest that all three should be used in conjunction in order to accurately evaluate coding schemes.",
  "y": "background"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_2",
  "x": "The justification given for using percentage agreement is that it does not suffer from what Di<cite> Eugenio and Glass (2004)</cite> referred to as the \"prevalence problem.",
  "y": "differences"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_3",
  "x": "For example, Table 1 shows an example taken from Di<cite> Eugenio and Glass (2004)</cite> showing the classification of the utterance Okay as an acceptance or acknowledgment.",
  "y": "background"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_4",
  "x": "Di<cite> Eugenio and Glass (2004)</cite> perceive this as an \"unpleasant behavior\" of chancecorrected tests, one that prevents us from concluding that the example given in Table 1 shows satisfactory levels of agreement.",
  "y": "differences"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_5",
  "x": "The second class of agreement measure recommended in Di<cite> Eugenio and Glass (2004)</cite> is that of chance-corrected tests that do not assume an equal distribution of categories between coders.",
  "y": "background"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_6",
  "x": "Di<cite> Eugenio and Glass (2004)</cite> conclude with the proposal that these three forms of agreement measure collectively provide better means with which to judge agreement than any individual test.",
  "y": "background"
 },
 {
  "id": "0706cab049274ffc82c5e2ef6f7b99_7",
  "x": "The prevalent use of this criterion despite repeated advice that it is unlikely to be suitable for all studies (Carletta 1996; <cite>Di Eugenio and Glass 2004</cite>; Krippendorff 2004a ) is probably due to a desire for a simple system that can be easily applied to a scheme.",
  "y": "background"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_0",
  "x": "They also proposed an algorithm that uses successive splits and merges of semantic roles clusters in order to improve their quality in<cite> (Lang and Lapata, 2011a)</cite> .",
  "y": "background"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_1",
  "x": "Following common practice<cite> (Lang and Lapata, 2011a</cite>; Titov and Klementiev, 2012) , we assume oracle argument identification and focus on argument labeling.",
  "y": "similarities uses"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_2",
  "x": "As done in<cite> (Lang and Lapata, 2011a)</cite> and (Titov and Klementiev, 2012) , we use purity and collocation measures to assess the quality of our role induction process.",
  "y": "similarities uses"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_3",
  "x": "In the same way as<cite> (Lang and Lapata, 2011a)</cite> , we use the micro-average obtained by weighting the scores for individual verbs proportionally to the number of argument instances for that verb.",
  "y": "similarities uses"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_4",
  "x": "The baseline model is the \"syntactic function\" used for instance in<cite> (Lang and Lapata, 2011a)</cite> , which simply clusters predicate arguments according to the dependency relation to their head.",
  "y": "similarities"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_5",
  "x": "We made our best to follow the setup used in previous work<cite> (Lang and Lapata, 2011a</cite>; Titov and Kle-mentiev, 2012) , in order to compare with the current state of the art.",
  "y": "similarities uses"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_6",
  "x": "We can first note that, despite our efforts to reproduce the same baseline, there is still a difference between our baseline (Synt.Func.) and the baseline reported in<cite> (Lang and Lapata, 2011a)</cite>",
  "y": "differences"
 },
 {
  "id": "0763666190b6b4be1bcf494d7c6fe2_7",
  "x": "The other results respectively correspond to the Split Merge approach presented in<cite> (Lang and Lapata, 2011a</cite> ) (Split Merge), the Graph Partitioning algorithm (Graph Part.) presented in (Lang and Lapata, 2011b) , and two Bayesian approaches presented in (Titov and Klementiev, 2012) , which achieve the best current unsupervised SRL results.",
  "y": "similarities"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_0",
  "x": "One popular approach is to use a log-linear parsing model and maximise the conditional likelihood function (Johnson et al., 1999; Riezler et al., 2002;<cite> Clark and Curran, 2004b</cite>; Malouf and van Noord, 2004; Miyao and Tsujii, 2005) .",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_1",
  "x": "In<cite> Clark and Curran (2004b)</cite> we use cluster computing resources to solve this problem.",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_2",
  "x": "Dynamic programming (DP) in the form of the inside-outside algorithm can be used to calculate the expectations, if the features are sufficiently local (Miyao and Tsujii, 2002) ; however, the memory requirements can be prohibitive, especially for automatically extracted, wide-coverage grammars. In<cite> Clark and Curran (2004b)</cite> we use cluster computing resources to solve this problem.",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_3",
  "x": "We use a lexicalized phrase-structure parser, the CCG parser of<cite> Clark and Curran (2004b)</cite> , together with a DP-based decoder.",
  "y": "uses"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_4",
  "x": "Previous discriminative models for CCG <cite>(Clark and Curran, 2004b)</cite> required cluster computing resources to train. In this paper we reduce the memory requirements from 20 GB of RAM to only a few hundred MB, but without greatly increasing the training time or reducing parsing accuracy.",
  "y": "motivation"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_5",
  "x": "2 The CCG Parser<cite> Clark and Curran (2004b)</cite> describes the CCG parser.",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_6",
  "x": "In<cite> Clark and Curran (2004b)</cite> we use a cluster of 45 machines, together with a parallel implementation of the BFGS training algorithm, to solve this problem. The need for cluster computing resources presents a barrier to the development of further CCG parsing models.",
  "y": "motivation"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_7",
  "x": "In<cite> Clark and Curran (2004b)</cite> we use a cluster of 45 machines, together with a parallel implementation of the BFGS training algorithm, to solve this problem.",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_8",
  "x": "In this paper, Y is the set of possible CCG derivations and GEN(x) enumerates the set of derivations for sentence x. We use the same feature representation \u03a6(x, y) as in<cite> Clark and Curran (2004b)</cite> , to allow comparison with the log-linear model.",
  "y": "uses"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_9",
  "x": "A feature forest is essentially a packed chart with only the feature information retained (see Miyao and Tsujii (2002) and<cite> Clark and Curran (2004b)</cite> for the details).",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_10",
  "x": "For the log-linear parsing model in<cite> Clark and Curran (2004b)</cite> , the inside-outside algorithm is used to calculate feature expectations, which are then used by the BFGS algorithm to optimise the likelihood function.",
  "y": "background"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_11",
  "x": "We applied the same normal-form restrictions used in<cite> Clark and Curran (2004b)</cite> : categories can only combine if they have been seen to combine in Sections 2-21 of CCGbank, and only if they do not violate the Eisner (1996a) normal-form constraints.",
  "y": "uses"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_12",
  "x": "In<cite> Clark and Curran (2004b)</cite> we use a cluster of 45 machines, together with a parallel implementation of BFGS, to solve this problem, but need up to 20 GB of RAM. The feature forest representation, and our implementation of it, is so compact that the perceptron training requires only 20 MB of RAM.",
  "y": "differences"
 },
 {
  "id": "07b062d569749924fa6ee1b2223411_13",
  "x": "Following<cite> Clark and Curran (2004b)</cite> , accuracy is measured using F-score over the goldstandard predicate-argument dependencies in CCGbank.",
  "y": "uses"
 },
 {
  "id": "0924035155d4bbac7768c65fbe8f9a_1",
  "x": "Since the shared task graphs used relations between nodes which were often not easily mappable to native OpenCCG relations, we trained a maxent classifier to tag the most likely relation, as well as an auxiliary maxent classifier to POS tag the graph nodes, much like hypertagging <cite>(Espinosa et al., 2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_0",
  "x": "Our NCE-trained language models achieve significantly lower perplexity on the One Billion Word Benchmark language modeling challenge, and contain one sixth of the parameters in the best single model in<cite> Chelba et al. (2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_1",
  "x": "1 Henceforth we will use terms like \"RNN\" and \"LSTM\" with the understanding that we are referring to language models that use these formalisms have outperformed their count-based counterparts <cite>(Chelba et al., 2013</cite>; Zaremba et al., 2014; Mikolov, 2012) .",
  "y": "differences"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_2",
  "x": "Using our new objective, we train large multi-layer LSTMs on the One Billion Word benchmark<cite> (Chelba et al., 2013)</cite> , with its full 780k word vocabulary.",
  "y": "uses"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_3",
  "x": "We achieve significantly lower perplexities with a single model, while using only a sixth of the parameters of a very strong baseline model<cite> (Chelba et al., 2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_4",
  "x": "The contributions in this paper are the following: 2 www.github.com/isi-nlp/Zoph_RNN \u2022 Significantly improved perplexities (43.2) on the One Billion Word benchmark over<cite> Chelba et al. (2013)</cite> \u2022 Extrinsic machine translation improvement over a strong baseline.",
  "y": "extends differences"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_5",
  "x": "We conducted two series of experiments to validate the efficiency of our approach and the quality of the models we learned using it: An intrinsic study of language model perplexity using the standard One Billion Word benchmark<cite> (Chelba et al., 2013)</cite> and an extrinsic end-to-end statistical machine translation task that uses an LSTM as one of several feature functions in re-ranking.",
  "y": "uses"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_6",
  "x": "For our language modeling experiment we use the One Billion Word benchmark proposed by<cite> Chelba et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_7",
  "x": "Our perplexity results are shown in Table 1 , where we get significantly lower perplexities than the best single model from<cite> Chelba et al. (2013)</cite> , while having almost 6 times fewer parameters.",
  "y": "differences"
 },
 {
  "id": "09f627b9a70966dc7b63316c56a2a0_8",
  "x": "Parameters Perplexity<cite> Chelba et al. (2013)</cite> 20m 51.3 NCE (ours) 3.4m 43.2 Recently, (J\u00f3zefowicz et al., 2016) achieved stateof-the-art language modeling perplexities (30.0) on the billion word dataset with a single model, using importance sampling to approximate the normalization constant, Z(u).",
  "y": "differences"
 },
 {
  "id": "0a538968f0cd121a1ef63b58a0c9f7_1",
  "x": "We follow the same data split of 1115 training and 19 test conversations as in the baseline approach (Stolcke et al., 2000;<cite> Kalchbrenner and Blunsom, 2013)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_0",
  "x": "This paper proposes a new scalable and accurate neural dialogue state tracking model, based on the recently proposed Global-Local Self-Attention encoder (GLAD) model by <cite>Zhong et al. (2018)</cite> which uses global modules to share parameters between estimators for different types (called slots) of dialogue states, and uses local modules to learn slot-specific features.",
  "y": "uses"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_1",
  "x": "Recently, <cite>Zhong et al. (2018)</cite> proposed a model based on training a binary classifier for each slot-value, Global-Locally Self Attentive encoder (GLAD, by employing recurrent and self attention for each utterance and previous system actions, and measuring similaity of these computed representation to each slot-value, which achieve state of the art results on WoZ and DSTC2 (Williams et al., 2013) datasets.",
  "y": "background"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_2",
  "x": "Recently, <cite>Zhong et al. (2018)</cite> proposed a model based on training a binary classifier for each slot-value, Global-Locally Self Attentive encoder (GLAD, by employing recurrent and self attention for each utterance and previous system actions, and measuring similaity of these computed representation to each slot-value, which achieve state of the art results on WoZ and DSTC2 (Williams et al., 2013) datasets. Although the proposed neural based models achieves state of the art results on several benchmark, they are still inefficient for deployment in production system, due to their latency which stems from using recurrent networks.",
  "y": "motivation"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_3",
  "x": "Recently, <cite>Zhong et al. (2018)</cite> proposed a model based on training a binary classifier for each slot-value, Global-Locally Self Attentive encoder (GLAD, by employing recurrent and self attention for each utterance and previous system actions, and measuring similaity of these computed representation to each slot-value, which achieve state of the art results on WoZ and DSTC2 (Williams et al., 2013) datasets. Although the proposed neural based models achieves state of the art results on several benchmark, they are still inefficient for deployment in production system, due to their latency which stems from using recurrent networks. In this paper, we propose a new encoder, by improving GLAD architecture<cite> (Zhong et al., 2018)</cite> .",
  "y": "uses motivation"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_4",
  "x": "In this paper, we propose a new encoder, by improving GLAD architecture<cite> (Zhong et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_5",
  "x": "First, section 2.1 explains the recently proposed GLAD encoder<cite> (Zhong et al., 2018)</cite> architecture, followed by our proposed encoder in section 2.2.",
  "y": "uses background"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_6",
  "x": "Here, we employ the similar approach of learning slot-specific temporal and context representation of user utterance and system actions, as proposed in GLAD<cite> (Zhong et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_7",
  "x": "Scoring Model: We follow the proposed architecture in GLAD<cite> (Zhong et al., 2018)</cite> for computing score of each slot-value pair, in the user utterance and previous system actions.",
  "y": "uses"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_8",
  "x": "The joint goal is the accumulation of turn goals as described in <cite>Zhong et al. (2018)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "0a55859a36d0887ba4febc98762715_9",
  "x": "The evaluation metric is based on joint goal and turn-level request and joint goal tracking accuracy. The joint goal is the accumulation of turn goals as described in <cite>Zhong et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_0",
  "x": "Several metrics have been proposed recently for evaluating VQA systems (see section 2), but accuracy is still the most commonly used evaluation criterion [4, 11, 23, 42, 44, <cite>1</cite>, 5, 14, 45, 2] .",
  "y": "background"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_1",
  "x": "In recent years, a number of VQA datasets have been proposed: VQA 1.0 [4] , VQA-abstract [<cite>1</cite>] , VQA 2.0 [47, 14] , FM-IQA [13] , DAQUAR [24] , COCO-QA [30] , Visual Madlibs [46] , Visual Genome [20] , VizWiz [16] , Visual7W [48] , TDIUC [18] , CLEVR [17] , SHAPES [3] , Visual Reasoning [34] , Embodied QA [7] . What all these resources have in common is the task for which they were designed: Given an image (either real or abstract) and a question in natural language, models are asked to correctly answer the question.",
  "y": "background"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_2",
  "x": "Being simple to compute and interpret, this metric (hence, VQA3+) is the standard evaluation criterion for open-ended VQA [4, <cite>1</cite>, 16, 47, 14] .",
  "y": "background"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_3",
  "x": "Moreover, it only works with rigid semantic concepts, making it not suitable for phrasal or sentence answers that can be found in [4, <cite>1</cite>, 16, 47, 14] .",
  "y": "background"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_4",
  "x": "This is crucial since, as shown in Figure 3 , in current datasets the proportion of samples with a perfect inter-annotator agreement (i.e., 1 unique answer) is relatively low: 35% in VQA 1.0 [4] , 33% in VQA 2.0 [14] , 43% in VQA-abstract [<cite>1</cite>] , and only 3% in VizWiz [16] .",
  "y": "background"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_5",
  "x": "We tested the validity of our metric by experimenting with four VQA datasets: VQA 1.0 [4] , VQA 2.0 [14] , VQA-abstract [<cite>1</cite>] , and VizWiz [16] .",
  "y": "uses"
 },
 {
  "id": "0a93feafef3ba2d4bb5360ff215171_6",
  "x": "To enable a fair comparison across the datasets, for each dataset we followed the same pipeline: The standard VQA model used in [<cite>1</cite>] was trained on the training split and tested on the validation split.",
  "y": "uses"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_0",
  "x": "By adding very simple CLM-based features to the system, our scores approach those of a state-of-the-art NER system<cite> (Lample et al., 2016)</cite> across multiple languages, demonstrating both the unique importance and the broad utility of this approach.",
  "y": "similarities"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_1",
  "x": "4 We compare the CLM's Entity Identification against two state-of-the-art NER systems: CogCompNER (Khashabi et al., 2018) and LSTM-CRF<cite> (Lample et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_2",
  "x": "4 We compare the CLM's Entity Identification against two state-of-the-art NER systems: CogCompNER (Khashabi et al., 2018) and LSTM-CRF<cite> (Lample et al., 2016)</cite> . As Table 2 shows, the result of Ngram CLM, which yields the highest performance, is remarkably close to the result of state-of-theart NER systems (especially for English) given the simplicity of the model.",
  "y": "similarities"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_3",
  "x": "CogCompNER is run with standard features, including Brown clusters;<cite> (Lample et al., 2016)</cite> is run with default parameters and pre-trained embeddings.",
  "y": "uses"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_4",
  "x": "We compare with the state-of-theart character-level neural NER system of<cite> (Lample et al., 2016)</cite> , which inherently encodes comparable information to CLMs, as a way to investigate how much of that system's performance can be attributed directly to name-internal structure.",
  "y": "uses"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_5",
  "x": "The results in Table 3 show that for six of the eight languages we studied, the baseline NER can be significantly improved by adding simple CLM features; for English and Arabic, it performs better even than the neural NER model of<cite> (Lample et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_6",
  "x": "While the end-to-end model developed by<cite> (Lample et al., 2016)</cite> clearly includes information comparable to that in the CLM, it requires a fully annotated NER corpus, takes significant time and computational resources to train, and is non-trivial to integrate into a new NER system.",
  "y": "motivation"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_7",
  "x": "While the end-to-end model developed by<cite> (Lample et al., 2016)</cite> clearly includes information comparable to that in the CLM, it requires a fully annotated NER corpus, takes significant time and computational resources to train, and is non-trivial to integrate into a new NER system. The CLM approach captures a very large fraction of the entity/non-entity distinction capacity of full NER systems, and can be rapidly trained using only entity and non-entity token lists -i.e., it is corpus-agnostic.",
  "y": "motivation differences"
 },
 {
  "id": "0ae49d1618e18eb794666543d924ed_8",
  "x": "<cite>Lample et al. (2016)</cite> use character embeddings in an LSTM-CRF model.",
  "y": "background"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_0",
  "x": "We present a replication study of BERT pretraining<cite> (Devlin et al., 2019)</cite> that carefully measures the impact of many key hyperparameters and training data size.",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_1",
  "x": "Self-training methods such as ELMo (Peters et al., 2018) , GPT (Radford et al., 2018) , BERT<cite> (Devlin et al., 2019)</cite> , XLM (Lample and Conneau, 2019) , and XLNet have brought significant performance gains, but it can be challenging to determine which aspects of the methods contribute the most.",
  "y": "motivation background"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_2",
  "x": "We present a replication study of BERT pretraining<cite> (Devlin et al., 2019)</cite> , which includes a careful evaluation of the effects of hyperparmeter tuning and training set size.",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_3",
  "x": "We present a replication study of BERT pretraining<cite> (Devlin et al., 2019)</cite> , which includes a careful evaluation of the effects of hyperparmeter tuning and training set size. We find that BERT was significantly undertrained and propose an improved recipe for training BERT models, which we call RoBERTa, that can match or exceed the performance of all of the post-BERT methods.",
  "y": "extends"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_4",
  "x": "In this section, we give a brief overview of the BERT<cite> (Devlin et al., 2019)</cite> pretraining approach and some of the training choices that we will examine experimentally in the following section.",
  "y": "uses background"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_5",
  "x": "Unlike<cite> Devlin et al. (2019)</cite> , we do not randomly inject short sequences, and we do not train with a reduced sequence length for the first 90% of updates.",
  "y": "differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_6",
  "x": "Our finetuning procedure follows the original BERT paper<cite> (Devlin et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_7",
  "x": "For SQuAD V1.1 we adopt the same span prediction method as BERT<cite> (Devlin et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_8",
  "x": "Results Table 1 compares the published BERT BASE results from<cite> Devlin et al. (2019)</cite> to our reimplementation with either static or dynamic masking.",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_9",
  "x": "Results Table 1 compares the published BERT BASE results from<cite> Devlin et al. (2019)</cite> to our reimplementation with either static or dynamic masking. We find that our reimplementation with static masking performs similar to the original BERT model, and dynamic masking is comparable or slightly better than static masking.",
  "y": "uses similarities"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_10",
  "x": "\u2022 SEGMENT-PAIR+NSP: This follows the original input format used in BERT<cite> (Devlin et al., 2019)</cite> , with the NSP loss.",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_11",
  "x": "We first compare the original SEGMENT-PAIR input format from<cite> Devlin et al. (2019)</cite> to the SENTENCE-PAIR format; both formats retain the NSP loss, but the latter uses single sentences.",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_12",
  "x": "We find that this setting outperforms the originally published BERT BASE results and that removing the NSP loss matches or slightly improves downstream task performance, in contrast to<cite> Devlin et al. (2019)</cite> .",
  "y": "differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_13",
  "x": "The original BERT implementation<cite> (Devlin et al., 2019)</cite> uses a character-level BPE vocabulary of size 30K, which is learned after preprocessing the input with heuristic tokenization rules.",
  "y": "background"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_14",
  "x": "The original BERT implementation<cite> (Devlin et al., 2019)</cite> uses a character-level BPE vocabulary of size 30K, which is learned after preprocessing the input with heuristic tokenization rules. Following Radford et al. (2019) , we instead consider training BERT with a larger byte-level BPE vocabulary containing 50K subword units, without any additional preprocessing or tokenization of the input.",
  "y": "background differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_15",
  "x": "For example, the recently proposed XLNet architecture ) is pretrained using nearly 10 times more data than the original BERT<cite> (Devlin et al., 2019)</cite> .",
  "y": "differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_16",
  "x": "We pretrain for 100K steps over a comparable BOOK-CORPUS plus WIKIPEDIA dataset as was used in<cite> Devlin et al. (2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_17",
  "x": "This formulation significantly simplifies the task, but is not directly comparable to BERT<cite> (Devlin et al., 2019)</cite> .",
  "y": "differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_18",
  "x": "In particular, while both BERT<cite> (Devlin et al., 2019)</cite> and XLNet augment their training data with additional QA datasets, we only finetune RoBERTa using the provided SQuAD training data.",
  "y": "differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_19",
  "x": "For SQuAD v1.1 we follow the same finetuning procedure as<cite> Devlin et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_20",
  "x": "Most of the top systems build upon either BERT<cite> (Devlin et al., 2019)</cite> or XLNet , both of which rely on additional external training data.",
  "y": "background"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_21",
  "x": "Most of the top systems build upon either BERT<cite> (Devlin et al., 2019)</cite> or XLNet , both of which rely on additional external training data. In contrast, our submission does not use any additional data.",
  "y": "differences"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_22",
  "x": "Pretraining methods have been designed with different training objectives, including language modeling (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018) , machine translation (McCann et al., 2017) , and masked language modeling <cite>(Devlin et al., 2019</cite>; Lample and Conneau, 2019) .",
  "y": "background"
 },
 {
  "id": "0af8cacc0f85bb557e1943e32450e2_23",
  "x": "Performance is also typically improved by training bigger models on more data <cite>(Devlin et al., 2019</cite>; Yang et al., 2019; Radford et al., 2019) .",
  "y": "background"
 },
 {
  "id": "0b2e3651610aba4bd7150eee50797f_0",
  "x": "These approaches were either complicated (Ma et al., 2007; Chang et al., 2008; Ma and Way, 2009; Paul et al., 2010) , or of high computational complexity (Chung and Gildea 2009;<cite> Duan et al., 2010)</cite> .",
  "y": "background"
 },
 {
  "id": "0b2e3651610aba4bd7150eee50797f_1",
  "x": "However, this kind of errors cannot be fixed by methods which learn new words by packing already segmented words, such as word packing (Ma et al., 2007) and Pseudo-word <cite>(Duan et al., 2010)</cite> .",
  "y": "background"
 },
 {
  "id": "0b2e3651610aba4bd7150eee50797f_2",
  "x": "In this setting, we gradually set the phrase length and the distortion limits of the phrase-based decoder (context size) to 7, 9, 11 and 13, in order to remove the disadvantage of shorter context size of using character as WSR for fair comparison with WordSys as suggested by<cite> Duan et al. (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "0b334057bc358f5537497ed15344c1_1",
  "x": "This is probably the reason for growing interest in creation of annotated corpora [4] , development of methods for augmenting the existing annotation [5] , speeding up the annotation process [5] , and reducing its cost; evaluating the comparability of results obtained applying the same methods to different collections<cite> [6]</cite> , And increasing compatibility of different annotations [7] .",
  "y": "background"
 },
 {
  "id": "0b334057bc358f5537497ed15344c1_2",
  "x": "Increasingly sophisticated relation extraction methods <cite>[6,</cite> 8] are being applied to a broader set of iii relations [9] .",
  "y": "background"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_0",
  "x": "The goal of the <cite>Penn Discourse Treebank (PDTB)</cite> project is to develop a large-scale corpus, annotated with coherence relations marked by discourse connectives. Currently, the primary application of the <cite>PDTB</cite> annotation has been to news articles.",
  "y": "background"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_1",
  "x": "In this study, we tested whether the <cite>PDTB</cite> guidelines can be adapted to a different genre.",
  "y": "motivation"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_2",
  "x": "In this study, we tested whether the <cite>PDTB</cite> guidelines can be adapted to a different genre. We annotated discourse connectives and <cite>their</cite> arguments in one 4,937-token full-text biomedical article.",
  "y": "uses"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_3",
  "x": "Thus our experiments suggest that the <cite>PDTB</cite> annotation can be adapted to new domains by minimally adjusting the guidelines and by adding some further domain-specific linguistic cues.",
  "y": "extends"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_4",
  "x": "The <cite>Penn Discourse Treebank (PDTB)</cite> (http://www.seas.upenn.edu/~pdtb) (<cite>Prasad et al. 2008a</cite>) annotates the argument structure, semantics, and attribution of discourse connectives and their arguments.",
  "y": "background"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_5",
  "x": "This work examines whether the <cite>PDTB</cite> annotation guidelines can be adapted to a different genre, the biomedical literature.",
  "y": "motivation"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_6",
  "x": "Following the <cite>PDTB</cite> annotation manual (Prasad et al. 2008b ), we conducted a pilot annotation of discourse connectivity in biomedical text.",
  "y": "uses"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_7",
  "x": "When the annotation work was completed, we measured the inter-annotator agreement, following the <cite>PDTB</cite> exact match criterion (Miltsakaki et al. 2004 ).",
  "y": "uses"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_8",
  "x": "We discussed the annotation results and made suggestions to adapt the <cite>PDTB</cite> guidelines to biomedical text.",
  "y": "extends"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_9",
  "x": "The <cite>PDTB</cite> also reported a higher level of agreement in annotating Arg2 than in annotating Arg1 (Miltsakaki et al. 2004) .",
  "y": "background"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_10",
  "x": "The overall agreement for the 68 discourse relations is 45.6% for exact match, 45.6% for Arg1, and 79.4% for Arg2. The <cite>PDTB</cite> also reported a higher level of agreement in annotating Arg2 than in annotating Arg1 (Miltsakaki et al. 2004) . We manually analyzed the cases with disagreement.",
  "y": "differences"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_11",
  "x": "After the completion of the pilot annotation and the discussion, we decided to add the following conventions to the <cite>PDTB</cite> annotation guidelines to address the characteristics of biomedical text: i. Citation references are to be annotated as a part of an argument because the inclusion will benefit many text-mining tasks including identifying the semantic relations among citations.",
  "y": "extends"
 },
 {
  "id": "0c233d68fb2ccdf033fc6a08c8f4bf_12",
  "x": "We will annotate a wider variety of nominalizations as arguments than allowed by the <cite>PDTB</cite> guidelines.",
  "y": "extends"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_0",
  "x": "In this paper we aim to improve the state-of-the-art for the task of learning a TAG supertagger from an annotated treebank <cite>(Kasai et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_1",
  "x": "Our experimental results show that our novel multi-task learning framework leads to a new state-of-the-art accuracy score of 91.39% for TAG supertagging on the Penn Treebank dataset (Marcus et al., 1993; Chen et al., 2006) which is a significant improvement over the previous multi-task result for supertagging that combines supertagging with graph-based parsing <cite>(Kasai et al., 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_2",
  "x": "Neural linear-time transition based parsers are still not accurate enough to compete with the state-of-the-art supertagging models or parsers that use supertagging as the initial step (Chung et al., 2016;<cite> Kasai et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_3",
  "x": "For our baseline supertagging model we use the state-of-the-art model that currently has the highest accuracy on the Penn treebank dataset <cite>(Kasai et al., 2018)</cite> . For the supertagging model the main contribution of<cite> Kasai et al. (2018)</cite> was two-fold: the first was to add a character CNN for modeling word embeddings using subword features, and the second was to add highway connections to add more layers to a standard bidirectional LSTM.",
  "y": "uses"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_4",
  "x": "Another extension to the standard sequence prediction model in<cite> Kasai et al. (2018)</cite> was to combine supertagging with graph-based parsing.",
  "y": "extends"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_5",
  "x": "<cite>(Kasai et al., 2018)</cite> we use two components in the word embedding: \u2022 a 30-dimensional character level embedding vector computed using a char-CNN which captures the morphological information (Santos and Zadrozny, 2014; Chiu and Nichols, 2016; Ma and Hovy, 2016;<cite> Kasai et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_6",
  "x": "Unlike <cite>(Kasai et al., 2018)</cite> we do not use predicted part of speech (POS) tags as part of the input sequence.",
  "y": "differences"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_7",
  "x": "For the hyperparameters, we use the settings in<cite> Kasai et al. (2018)</cite> in order to ensure a fair comparison.",
  "y": "uses"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_8",
  "x": "Unlike <cite>(Kasai et al., 2018)</cite> we do not use highway connections in our model.",
  "y": "differences"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_9",
  "x": "In our case, because we re-use the same training set for multi-task learning, we have made sure our experimental settings exactly match the previous best state-of-the-art method for supertagging <cite>(Kasai et al., 2018)</cite> and we use the same pre-trained word embeddings to ensure a fair comparison.",
  "y": "uses"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_10",
  "x": "We use the dataset that has been widely used by previous work in supertagging and TAG parsing (Bangalore et al., 2009; Chung et al., 2016; Friedman et al., 2017;<cite> Kasai et al., , 2018</cite> .",
  "y": "uses"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_12",
  "x": "All of those words are<cite> Kasai et al. (2018)</cite> refers to highway connections, and POS refers to the use of predicted part-of-speech tags as inputs. We do not use HW or POS in our models as they do not provide any benefit.",
  "y": "differences"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_13",
  "x": "Neural network based supertagging models in TAG <cite>(Kasai et al., 2018)</cite> and CCG (Xu Lewis et al., 2016; Xu, 2016; Vaswani et al., 2016) have shown substantial improvement in performance, but the supertagging models are all quite similar as they all use a bi-directional RNN feeding into a prediction layer.",
  "y": "background"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_14",
  "x": "<cite>(Kasai et al., 2018)</cite> combines supertagging with parsing which does provide state-of-the-art accuracy but at the expense of computational complexity.",
  "y": "background"
 },
 {
  "id": "0c3f9588b6f587d04c286384ca24e0_15",
  "x": "extends the BiLSTM model with predicted part-of-speech tags and suffix embeddings as inputs, then<cite> Kasai et al. (2018)</cite> further extends the BiLSTM model with highway connection as well as character CNN as input, and jointly train the supertagging model with parsing model and this work had the state-of-the-art accuracy before our paper on the Penn treebank dataset.",
  "y": "background"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_0",
  "x": "Finally, it would be interesting to determine whether using ASs extracted from a corpus of native texts enables a better prediction than that obtained by using the simple frequency of the unigrams and bigrams<cite> (Yannakoudakis et al., 2011)</cite> .",
  "y": "future_work"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_1",
  "x": "Dataset: The analyses were conducted on the First Certificate in English (FCE) ESOL examination scripts described in <cite>Yannakoudakis et al. (2011</cite> Yannakoudakis et al. ( , 2012 .",
  "y": "similarities uses"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_2",
  "x": "As in<cite> Yannakoudakis et al. (2011)</cite> , the 1141 texts from the year 2000 were used for training, while the 97 texts from the year 2001 were used for testing.",
  "y": "similarities"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_3",
  "x": "Lexical Features: As a benchmark for comparison, the lexical features that were showed to be good predictors of the quality of the texts in this dataset<cite> (Yannakoudakis et al., 2011)</cite> were chosen.",
  "y": "similarities uses"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_4",
  "x": "These features were extracted as described in<cite> Yannakoudakis et al. (2011)</cite> ; the only difference is that they used the RASP tagger and not the CLAWS tagger.",
  "y": "extends differences"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_5",
  "x": "Supervised Learning Approach and Evaluation: As in<cite> Yannakoudakis et al. (2011)</cite> , the automated scoring task was treated as a rankpreference learning problem by means of the SVM-Rank package (Joachims, 2006) , which is a much faster version of the SVM-Light package used by<cite> Yannakoudakis et al. (2011)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_6",
  "x": "Since the quality ratings are distributed on a zero to 40 scale, I chose Pearson's correlation coefficient, also used by<cite> Yannakoudakis et al. (2011)</cite> , as the measure of performance.",
  "y": "similarities uses"
 },
 {
  "id": "0cc576e90c5ee2af043e09234792f5_7",
  "x": "To get an idea of how well the collocational and lexical features perform, the correlations in Table 2 can be compared to the average correlation between the Examiners' scores reported by<cite> Yannakoudakis et al. (2011)</cite> , which give an upper bound of 0.80 while the All models with more than three bins obtain a correlation of at least 0.75.",
  "y": "similarities"
 },
 {
  "id": "0d06c8509ebbdc61985bebcdb26e6c_0",
  "x": "In a similar work, Mnih et al. <cite>[13]</cite> proposed to use Noise Contrastive Estimation (NCE) [14] to speed-up the training.",
  "y": "background"
 },
 {
  "id": "0d06c8509ebbdc61985bebcdb26e6c_1",
  "x": "Hence, an adaptive IS may use a large number of samples to solve this problem whereas NCE is more stable and requires a fixed small number of noise samples (e.g., 100) to achieve a good performance<cite> [13,</cite> 16] .",
  "y": "background"
 },
 {
  "id": "0d06c8509ebbdc61985bebcdb26e6c_2",
  "x": "Furthermore, we can show that this solution optimally approximates the sampling from a unigram distribution, which has been shown to be a good noise distribution choice<cite> [13,</cite> 16] .",
  "y": "background"
 },
 {
  "id": "0d06c8509ebbdc61985bebcdb26e6c_3",
  "x": "Hence, we solely focus our experiments on NCE as a major approach to achieve this goal [17,<cite> 13,</cite> 16] in comparison to the reference full softmax function.",
  "y": "uses"
 },
 {
  "id": "0d06c8509ebbdc61985bebcdb26e6c_4",
  "x": "Following the setup proposed in<cite> [13,</cite> 16] , S-NCE uses K = 100 noise samples, whereas B-NCE uses only the target words in the batch (K=0).",
  "y": "uses"
 },
 {
  "id": "0d1fb27d847ca44af36862cf78744e_0",
  "x": "In addition, there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington, 1990;<cite> Kahane et al., 1998</cite>; Duchier and Debusmann, 2001; Holan et al., 2001; Hellwig, 2003) .",
  "y": "background"
 },
 {
  "id": "0d1fb27d847ca44af36862cf78744e_1",
  "x": "First, the training data for the parser is projectivized by applying a minimal number of lifting operations<cite> (Kahane et al., 1998)</cite> and encoding information about these lifts in arc labels.",
  "y": "background"
 },
 {
  "id": "0d1fb27d847ca44af36862cf78744e_3",
  "x": "As observed by <cite>Kahane et al. (1998)</cite> , any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc w j \u2192 w k by a projective arc w i \u2192 w k such that w i \u2192 * w j holds in the original graph.",
  "y": "background"
 },
 {
  "id": "0d1fb27d847ca44af36862cf78744e_4",
  "x": "Using the terminology of <cite>Kahane et al. (1998)</cite> , we say that jedna is the syntactic head of Z, while je is its linear head in the projectivized representation.",
  "y": "uses"
 },
 {
  "id": "0d1fb27d847ca44af36862cf78744e_5",
  "x": "Unlike <cite>Kahane et al. (1998)</cite> , we do not regard a projectivized representation as the final target of the parsing process.",
  "y": "differences"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_0",
  "x": "Recent state-of-the-art models (Wang et al., 2018;<cite> Fried et al., 2018b</cite>; Ma et al., 2019) have demonstrated large gains in accuracy on the VLN task.",
  "y": "background"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_1",
  "x": "In this paper, we find that agents without any visual input can achieve competitive performance, matching or even outperforming their vision-based counterparts under two state-of-theart model models<cite> (Fried et al., 2018b</cite>; Ma et al., 2019) .",
  "y": "motivation"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_2",
  "x": "In this paper, we show that the same trends hold for two recent state-of-the-art architectures (Ma et al., 2019;<cite> Fried et al., 2018b)</cite> for the VLN task; we also analyze to what extent object-based representations and mixture-ofexperts methods can address these issues.",
  "y": "similarities"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_3",
  "x": "In this work, we analyze two recent VLN models, which typify the visual grounding approaches of VLN work: the panoramic \"follower\" model from the Speaker-Follower (SF) system of<cite> Fried et al. (2018b)</cite> and the Self-Monitoring (SM) model of Ma et al. (2019) .",
  "y": "similarities uses"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_4",
  "x": "We compare performance on the validation sets of the R2R dataset: the val-seen split, consisting of the same environments as in training, and the val- Table 1 : Success rate (SR) of the vision-based full agent (\"RN\", using ResNet) and the non-visual agent (\"no vis.\", setting all visual features to zero) on the R2R dataset under different model architectures (SpeakerFollower (SF)<cite> (Fried et al., 2018b)</cite> and Self-Monitoring (SM) (Ma et al., 2019) ) and training schemes.",
  "y": "extends differences"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_5",
  "x": "We then use the same visual attention mechanism as in<cite> Fried et al. (2018b)</cite> and Ma et al. (2019) to obtain an attended object representation x obj,att over these {x obj,j } vectors.",
  "y": "similarities uses"
 },
 {
  "id": "0d798fcdee6ee5722d6dc5638210c2_7",
  "x": "The Speaker-Follower (SF) model<cite> (Fried et al., 2018b</cite> ) and the Self-Monitoring (SM) model (Ma et al., 2019) which we analyze both use sequenceto-sequence model (Cho et al., 2014) with attention (Bahdanau et al., 2015) as their base instruction-following agent.",
  "y": "similarities"
 },
 {
  "id": "0e4ca87c0e2b899bfd1f36dc5974b9_0",
  "x": "For other languages, one could retrain a language-specific model using the BERT architecture Martin et al., 2019; de Vries et al., 2019] or employ existing pre-trained multilingual BERT-based models [Devlin et al., 2019;<cite> Conneau et al., 2019</cite>;<cite> Conneau and Lample, 2019]</cite> .",
  "y": "background"
 },
 {
  "id": "0e4ca87c0e2b899bfd1f36dc5974b9_1",
  "x": "In terms of Vietnamese language modeling, to the best of our knowledge, there are two main concerns: (i) The Vietnamese Wikipedia corpus is the only data used to train all monolingual language models , and it also is the only Vietnamese dataset included in the pre-training data used by all multilingual language models except XLM-R<cite> [Conneau et al., 2019]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "0e4ca87c0e2b899bfd1f36dc5974b9_2",
  "x": "For NLI, we use the Vietnamese validation and test sets from the XNLI corpus v1.0 <cite>[Conneau et al., 2018]</cite> where the Vietnamese training data is machinetranslated from English.",
  "y": "uses"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_0",
  "x": "The model improves over previous work on reference resolution applied to the same data (Iida et al., 2010;<cite> Iida et al., 2011)</cite> .",
  "y": "differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_1",
  "x": "It has been shown that incorporating gaze improves RR in a situated setting because speakers need to look at and distinguish from distractors the objects they are describing: this has been shown in a static scene on a computer screen (Prasov and Chai, 2008) , in human-human interactive puzzle tasks (Iida et al., 2010;<cite> Iida et al., 2011)</cite> , in web browsing (Hakkani-t\u00fcr et al., 2014) , and in a moving car where speakers look at objects in their vicinity (Misu et al., 2014) .",
  "y": "background"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_2",
  "x": "The corpora presented in <cite>Iida et al. (2011)</cite> and Spanger et al. (2012) are a collection of human/human interaction data where the participants collaboratively solved Tangram puzzles.",
  "y": "background"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_3",
  "x": "Further details of the corpus can be found in<cite> (Iida et al., 2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_4",
  "x": "<cite>Iida et al. (2011)</cite> applied a support vector machine-based ranking algorithm (Joachims, 2002) to the task of resolving REs in this corpus.",
  "y": "background"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_5",
  "x": "In order to compare our results directly with those of <cite>Iida et al. (2011)</cite> , we provide our model with the same training and evaluation data, in a 10-fold cross-validation of the 1192 REs from 27 dialogues (the T2009-11 corpus in ).",
  "y": "uses"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_6",
  "x": "3 We derive these properties from a representation of the scene; similar to how <cite>Iida et al. (2011)</cite> computed features to present to their classifier: namely Ling (linguistic features), TaskSp (task specific features), and Gaze (from SV only).",
  "y": "similarities"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_7",
  "x": "These properties differ somewhat from the features for the Ling model presented in <cite>Iida et al. (2011)</cite> .",
  "y": "differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_8",
  "x": "TaskSp <cite>Iida et al. (2011)</cite> used 14 task-specific features, three of which they found to be the most informative in their model.",
  "y": "background"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_9",
  "x": "TaskSp <cite>Iida et al. (2011)</cite> used 14 task-specific features, three of which they found to be the most informative in their model. Here, we will only use the two most informative features as properties (the third one, whether or not an object was being manipulated at the beginning of the RE, did not improve results in a held-out test): the object that was most recently moved received the most recent move property and objects that have the mouse cursor over them received the mouse pointed property (see Figure 2 ; object 4 would receive both of these properties, but only for the duration that the mouse was actually over it).",
  "y": "differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_10",
  "x": "Gaze Similar to <cite>Iida et al. (2011)</cite> , we consider gaze during a window of 1500ms before the onset of the RE.",
  "y": "similarities"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_11",
  "x": "Our Gaze properties are made up of these 4 properties, as opposed to the 14 features in <cite>Iida et al. (2011)</cite> .",
  "y": "differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_12",
  "x": "Going beyond <cite>Iida et al. (2011)</cite> , our model computes a resolution hypothesis incrementally; for the performance of this aspect of the system we followed previously used metrics for evaluation : first correct: how deep into the RE does the model predict the referent for the first time? first final: how deep into the RE does the model predict the correct referent and keep that decision until the end? edit overhead: how often did the model unnecessarily change its prediction (the only necessary prediction happens when it first makes a correct prediction)?",
  "y": "extends"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_13",
  "x": "We compare non-incremental results to three evaluations performed in <cite>Iida et al. (2011)</cite> , namely when Ling is used alone, Ling+TaskSP used together, and Ling+TaskSp+Gaze.",
  "y": "uses"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_14",
  "x": "The SIUM model performs better than the combined approach of <cite>Iida et al. (2011)</cite> , and performs better than their separated model-when not including gaze (there is a significant difference between SIUM and the separated models for Ling+TaskSp, though (2011) SIUM only got one more correct than the separated model).",
  "y": "differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_15",
  "x": "Second, and more importantly, separated models means less feature confusion: in <cite>Iida et al. (2011)</cite> (Section 5.2) , the authors give a comparison of the most informative features for each model; task and gaze features were prominent for the pronoun model, whereas gaze and language features were prominent for the non-pronoun model.",
  "y": "background"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_17",
  "x": "In contrast, previous work in RR<cite> (Iida et al., 2011</cite>; Chai et al., 2014 ) used a hand-coded concept-labeled semantic representation and checked if aspects of the RE match that of a particular object.",
  "y": "background differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_18",
  "x": "However, in the current work we observed that REs with pronouns were more difficult for the model to resolve than the model presented in <cite>Iida et al. (2011)</cite> .",
  "y": "differences"
 },
 {
  "id": "0e5c3df8309dbaf93d10c94fb292fc_19",
  "x": "We surmise that SIUM had a difficult time grounding certain properties, as the Japanese pronoun sore can be used anaphorically or demonstratively in this kind of context (i.e., sometimes sore refers to previously-manipulated objects, or objects that are newly identified with a mouse pointer over them); the model presented in <cite>Iida et al. (2011)</cite> made more use of contextual information when pronouns were used, particularly in the combined model which incorporated gaze information, as shown above.",
  "y": "differences"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_0",
  "x": "For the task of fact extraction from billions of Web pages the method of Open Information Extraction (OIE) <cite>(Fader et al., 2011)</cite> trains domainindependent extractors.",
  "y": "background"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_1",
  "x": "Existing approaches for OIE, such as REVERB <cite>(Fader et al., 2011)</cite> , WOE (Wu and Weld, 2010) or WANDER-LUST (Akbik and Bross, 2009 ) focus on the extraction of binary facts, e.g. facts that consist of only two arguments, as well as a fact phrase which denotes the nature of the relationship between the arguments.",
  "y": "background"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_2",
  "x": "Worse, the analyses performed in <cite>(Fader et al., 2011)</cite> and (Akbik and Bross, 2009) show that incorrect handling of N-ary facts leads to extraction errors, such as incomplete, uninformative or erroneous facts.",
  "y": "background"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_3",
  "x": "Worse, the analyses performed in <cite>(Fader et al., 2011)</cite> and (Akbik and Bross, 2009) show that incorrect handling of N-ary facts leads to extraction errors, such as incomplete, uninformative or erroneous facts. Our first example illustrates the case of a significant information loss: a) In the 2002 film Bubba Ho-tep, Elvis lives in a nursing home.",
  "y": "motivation"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_4",
  "x": "We examine intra sentence fact correctness (true/false) and fact completeness for KRAKEN and REVERB on the corpus of <cite>(Fader et al., 2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_5",
  "x": "The OIE system REVERB <cite>(Fader et al., 2011)</cite> by contrast uses a fast shallow syntax parser for labeling sentences and applies syntactic and a lexical constraints for identifying binary facts.",
  "y": "background"
 },
 {
  "id": "0f0e13e275c4bc4021b1b0d26f3e0c_6",
  "x": "Data set: We use the data set from <cite>(Fader et al., 2011)</cite> which consists of 500 sentences sampled from the Web using Yahoo's random link service.",
  "y": "uses"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_0",
  "x": "<cite>Faruqui and Dyer (2014)</cite> use canonical correlation analysis to project the embeddings in both languages to a shared vector space.",
  "y": "background"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_1",
  "x": "We start with a basic optimization objective (Mikolov et al., 2013b) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods <cite>(Faruqui and Dyer, 2014</cite>; Xing et al., 2015) .",
  "y": "extends uses"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_2",
  "x": "We start with a basic optimization objective (Mikolov et al., 2013b) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods <cite>(Faruqui and Dyer, 2014</cite>; Xing et al., 2015) . Our framework provides a more general view of bilingual word embedding mappings, showing the underlying connection between the existing methods, revealing some flaws in their theoretical justification and providing an alternative theoretical interpretation for them.",
  "y": "extends differences"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_3",
  "x": "We start with a basic optimization objective (Mikolov et al., 2013b) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods <cite>(Faruqui and Dyer, 2014</cite>; Xing et al., 2015) . Our framework provides a more general view of bilingual word embedding mappings, showing the underlying connection between the existing methods, revealing some flaws in their theoretical justification and providing an alternative theoretical interpretation for them. Our experiments on an existing English-Italian word translation induction and an English word analogy task give strong empirical evidence in favor of our theoretical reasoning, while showing that one of our models clearly outperforms previous alternatives.",
  "y": "differences"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_4",
  "x": "where C m denotes the centering matrix This equivalence reveals that the method proposed by <cite>Faruqui and Dyer (2014)</cite> is closely related to our framework.",
  "y": "similarities"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_5",
  "x": "where C m denotes the centering matrix This equivalence reveals that the method proposed by <cite>Faruqui and Dyer (2014)</cite> is closely related to our framework. More concretely, <cite>Faruqui and Dyer (2014)</cite> use Canonical Correlation Analysis (CCA) to project the word embeddings in both languages to a shared vector space. Therefore, the only fundamental difference between both methods is that, while our model enforces monolingual invariance, <cite>Faruqui and Dyer (2014)</cite> do change the monolingual embeddings to meet this restriction.",
  "y": "similarities differences"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_6",
  "x": "As for the method by <cite>Faruqui and Dyer (2014)</cite> , we used their original implementation in Python and MAT-LAB 6 , which we extended to cover cases where the dictionary contains more than one entry for the same word.",
  "y": "extends uses"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_8",
  "x": "In any case, it is our proposed method with the orthogonality constraint and a global preprocessing with length normalization followed by dimensionwise mean centering that achieves the best accuracy in the word translation induction task. Moreover, it does not suffer from any considerable degradation in monolingual quality, with an anecdotal drop of only 0.07% in contrast with 2.86% for Mikolov et al. (2013b) and 7.02% for <cite>Faruqui and Dyer (2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_9",
  "x": "It should be noted that the implementation by <cite>Faruqui and Dyer (2014)</cite> also length-normalizes the word embeddings in a preprocessing step.",
  "y": "similarities"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_10",
  "x": "Following the discussion in Section 2.3, this means that our best performing configuration is conceptually very close to the method by <cite>Faruqui and Dyer (2014)</cite> , as they both coincide on maximizing the average dimension-wise covariance and length-normalize the embeddings in both languages first, the only difference being that our model enforces monolingual invariance after the normalization while theirs does change the monolingual embeddings to make different dimensions have the same variance and be uncorrelated among themselves.",
  "y": "similarities"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_11",
  "x": "However, our model performs considerably better than any configuration from <cite>Faruqui and Dyer (2014)</cite> in both the monolingual and the bilingual task, supporting our hypothesis that these two constraints that are implicit in their method are not only conceptually confusing, 2292 but also have a negative impact.",
  "y": "differences"
 },
 {
  "id": "0f5c87e5434785a612c6578244543d_12",
  "x": "Our experiments show the effectiveness of the proposed model and give strong empirical evidence in favor of our reinterpretation of Xing et al. (2015) and <cite>Faruqui and Dyer (2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "0fed8b9e785426880fa8e5641116a4_0",
  "x": "AMBER is a machine translation evaluation metric first described in <cite>(Chen and Kuhn, 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "0fed8b9e785426880fa8e5641116a4_1",
  "x": "Our original AMBER paper <cite>(Chen and Kuhn, 2011)</cite> describes the ten penalties used at that time; two of these penalties, the normalized Spearman's correlation penalty and the normalized Kendall's correlation penalty, model word reordering.",
  "y": "background"
 },
 {
  "id": "0fed8b9e785426880fa8e5641116a4_2",
  "x": "The AMBER score can be computed with different types of text preprocessing, i.e. different combinations of several text preprocessing techniques: lowercasing, tokenization, stemming, word splitting, etc. 8 types were tried in <cite>(Chen and Kuhn, 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "0fed8b9e785426880fa8e5641116a4_3",
  "x": "In <cite>(Chen and Kuhn, 2011)</cite> , we manually set the 17 free parameters of AMBER (see section 3.2 of that paper). In the experiments reported below, we tuned the 18 free parameters -the original 17 plus the ordering metric v described in the previous section -automatically, using the downhill simplex method of (Nelder and Mead, 1965) as described in (Press et al., 2002) .",
  "y": "differences"
 },
 {
  "id": "0fed8b9e785426880fa8e5641116a4_4",
  "x": "We have made two changes to AMBER, a metric described in <cite>(Chen and Kuhn, 2011)</cite> .",
  "y": "extends"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_0",
  "x": "While there is a substantial amount of work on statistical (Rozovskaya and Roth, 2016; Junczys-Dowmunt and Grundkiewicz, 2014; Yannakoudakis et al., 2017) and neural (Ji et al., 2017; Xie et al., 2016; Yuan and Briscoe, 2016; Chollampatt et al., 2016; Chollampatt and Ng, 2017; Chollampatt and Ng, 2018) machine translation methods for GEC, we follow the approach of <cite>Bryant and Briscoe (2018)</cite> and explore how such models would fare in this task when treated as simple language models.",
  "y": "uses"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_1",
  "x": "More specifically, <cite>Bryant and Briscoe (2018)</cite> train a 5-gram language model on the One Billion Word Benchmark (Chelba et al., 2013) dataset and find that it produces competitive baseline results without any supervised training. In our work, we extend <cite>this work</cite> by substituting the n-gram model for several publicly available implementations of state-of-the-art Transformer language models trained on large linguistic corpora and assess their performance on GEC without any supervised training.",
  "y": "extends motivation"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_2",
  "x": "However, <cite>Bryant and Briscoe (2018)</cite> recently revived the idea, achieving competitive performance with the state-ofthe-art, demonstrating the effectiveness of the approaches to the task without using any annotated data for training.",
  "y": "background"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_3",
  "x": "In this work, we follow the setup from <cite>Bryant and Briscoe (2018)</cite> substituting the 5-gram language model for different language models based on the Transformer architecture.",
  "y": "extends"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_4",
  "x": "Since our systems do not generate novel sequences, we follow <cite>Bryant and Briscoe (2018)</cite> and use simple heuristics to generate a confusion set of sentences that our language models score.",
  "y": "uses"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_5",
  "x": "Finally, for spelling mistakes, we, again, follow <cite>Bryant and Briscoe (2018)</cite> and use CyHunSpell 3 to generate alternatives for non-words.",
  "y": "uses"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_6",
  "x": "Concretely, let P (s c ) be the probability of the candidate sentence and P (s o ) the probability of the Table 2 : Results of our Transformer-Language Model approach against similar approaches <cite>(Bryant and Briscoe, 2018)</cite> and state-of-the-art on Grammatical Error Correction.",
  "y": "uses"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_8",
  "x": "Note that in our method, we do not make use of the training sets commonly used with these datasets. However, we use the development sets used by <cite>Bryant and Briscoe (2018)</cite> to tune the hyperparameter \u03c4 .",
  "y": "uses differences"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_9",
  "x": "Similar to <cite>Bryant and Briscoe (2018)</cite> , we report results on three metrics.",
  "y": "similarities"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_10",
  "x": "Table 2 presents the results of our method comparing them against recent state-of-the-art supervised models and the simple n-gram language model used by <cite>Bryant and Briscoe (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "1056d36c5ed22c7a34f6fe82b4962f_11",
  "x": "Our key motivation was to corroborate and extend the results of <cite>Bryant and Briscoe (2018)</cite> to current state-of-the-art language models which have been trained in several languages and show that these models are tough baselines to beat for novel GEC systems.",
  "y": "extends motivation"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_0",
  "x": "Aspect and/or opinion terms extraction research has been conducted by Wang et al. [2] and Xu et al. <cite>[3]</cite> that outperformed the best systems in the aspect-based sentiment analysis task on the International Workshop on Semantic Evaluation (SemEval) for aspect and opinion terms extraction.",
  "y": "background"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_1",
  "x": "Xu et al. <cite>[3]</cite> proposed a Convolutional Neural Network (CNN) model employing two types of pre-trained word embeddings, general-purpose embeddings and domainspecific embeddings, for aspect term extraction.",
  "y": "background"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_2",
  "x": "Wang et al. [2] and Xu et al. <cite>[3]</cite> approaches have not been applied for Indonesian reviews.",
  "y": "background"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_3",
  "x": "This paper aims to perform aspect and opinion terms extraction in Indonesian hotel reviews by adapting CMLA architecture [2] and double embeddings mechanism <cite>[3]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_4",
  "x": "Xu et al. <cite>[3]</cite> use double embeddings that leverage both general embeddings and domain embeddings as a feature for a CNN model and let the CNN model decide which embeddings have more useful information.",
  "y": "background"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_5",
  "x": "The experiment conducted in <cite>[3]</cite> demonstrated that double embedding mechanism achieved better performance for aspect terms extraction compared to the use of general embeddings or domain embeddings alone.",
  "y": "background"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_6",
  "x": "As stated previously, the goal of this work is to extract aspect and opinion terms in Indonesian hotel reviews by adapting CMLA architecture [2] and double embeddings mechanism <cite>[3]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_7",
  "x": "We use various types of word embeddings adapted from <cite>[3]</cite> .",
  "y": "uses"
 },
 {
  "id": "10de18ba49c0da530b15ff2d14f343_8",
  "x": "For the general embeddings and domain embeddings, we use the same dimension and number of iterations as in <cite>[3]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_0",
  "x": "In this work, we experiment with the <cite>Self-reported Mental Health Diagnoses</cite> (<cite>SMHD</cite>) dataset (<cite>Cohan et al., 2018</cite>) , consisting of thousands of Reddit users diagnosed with one or more mental illnesses.",
  "y": "uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_1",
  "x": "The <cite>SMHD</cite> dataset (<cite>Cohan et al., 2018</cite>) is a largescale dataset of Reddit posts from users with one or multiple mental health conditions.",
  "y": "background"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_2",
  "x": "For each disorder, <cite>Cohan et al. (2018)</cite> analyze the differences in language use between diagnosed users and their respective control groups.",
  "y": "background"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_3",
  "x": "For each disorder, <cite>Cohan et al. (2018)</cite> analyze the differences in language use between diagnosed users and their respective control groups. <cite>They</cite> also provide benchmark results for the binary classification task of predicting whether the user belongs to the diagnosed or the control group.",
  "y": "background"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_4",
  "x": "For each disorder, <cite>Cohan et al. (2018)</cite> analyze the differences in language use between diagnosed users and their respective control groups. <cite>They</cite> also provide benchmark results for the binary classification task of predicting whether the user belongs to the diagnosed or the control group. We reproduce <cite>their</cite> baseline models for each disorder and compare to our deep learning-based model, explained in Section 2.3.",
  "y": "uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_5",
  "x": "<cite>Cohan et al. (2018)</cite> select nine or more control users for each diagnosed user and run their experiments with these mappings.",
  "y": "background"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_6",
  "x": "<cite>Cohan et al. (2018)</cite> select nine or more control users for each diagnosed user and run their experiments with these mappings. With this exact mapping not being available, for each of the nine conditions, we had to select the control group ourselves.",
  "y": "extends differences"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_7",
  "x": "For each diagnosed user, we draw exactly nine control users from the pool of 335,952 control users present in <cite>SMHD</cite> and proceed to train and test our binary classifiers on the newly created sub-datasets.",
  "y": "extends uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_8",
  "x": "In order to create a statistically-fair comparison, we run the selection process multiple times, as well as reimplement the benchmark models used in <cite>Cohan et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_9",
  "x": "We implement the baselines as in <cite>Cohan et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_10",
  "x": "In contrast to <cite>Cohan et al. (2018)</cite> , supervised FastText yields worse results than tuned linear models.",
  "y": "differences"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_11",
  "x": "We examine attention weights on a word level and compare the most attended words to prior research on depression. Depression is selected as the most prevalent disorder in the <cite>SMHD</cite> dataset with a number of studies in the field (Rude et al., 2004; Chung and Pennebaker, 2007; De Choudhury et al., 2013b; Park et al., 2012) .",
  "y": "uses"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_12",
  "x": "The importance of personal pronouns in distinguishing depressed authors from the control group is supported by multiple studies (Rude et al., 2004; Chung and Pennebaker, 2007; De Choudhury et al., 2013b; <cite>Cohan et al., 2018</cite>) .",
  "y": "background"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_13",
  "x": "In the categories Affective processes, Social processes, and Biological processes, <cite>Cohan et al. (2018)</cite> report significant differences between depressed and control group, similar to some other disorders.",
  "y": "background"
 },
 {
  "id": "10f17930192132077f0d4526e7d755_14",
  "x": "While most studies use Twitter data (Coppersmith et al., 2015a (Coppersmith et al., , 2014 Benton et al., 2017; Coppersmith et al., 2015b) , a recent stream turns to Reddit as a richer source of high-volume data (De Choudhury and De, 2014; Shen and Rudzicz, 2017; Gjurkovi\u0107 and\u0160najder, 2018; <cite>Cohan et al., 2018</cite>; Sekuli\u0107 et al., 2018; Zirikly et al., 2019) .",
  "y": "background"
 },
 {
  "id": "119d473a0a5a4c42de193e51564f1f_0",
  "x": "The example is taken from the Simple English Wikipedia corpus <cite>(Coster and Kauchak, 2011)</cite> connectives do not belong to any linguistic class and except for a few discourse connectives such as oh and well, most carry meaning.",
  "y": "background"
 },
 {
  "id": "119d473a0a5a4c42de193e51564f1f_1",
  "x": "The first data set was created from the Simple English Wikipedia corpus <cite>(Coster and Kauchak, 2011)</cite> ; the other was created from the Newsela corpus (Xu et al., 2015) .",
  "y": "extends"
 },
 {
  "id": "119d473a0a5a4c42de193e51564f1f_2",
  "x": "The Simple English Wikipedia (SEW) corpus <cite>(Coster and Kauchak, 2011)</cite> contains two sections: 1) article-aligned and 2) sentence-aligned. Here, we used the sentence-aligned section, which contains 167,686 pairs of aligned sentences.",
  "y": "extends uses"
 },
 {
  "id": "119d473a0a5a4c42de193e51564f1f_3",
  "x": "We used this article-aligned corpus to align it at the sentence-level using an approach similar to <cite>(Coster and Kauchak, 2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_0",
  "x": "While most of the work in this direction has been devoted to learning the acoustic model directly from sequences of phonemes or characters without intermediate alignment step or phone-state/senome induction, the other end of the pipeline model -namely, learning directly from the waveform rather than from speech features such as mel-filterbanks or MFCC -has recently received attention [1, 2, 3, 4, 5, 6, 7,<cite> 8]</cite> , but the performances on the master task of speech recognition still seem to be lagging behind those of models trained on speech features [9, 10] .",
  "y": "background"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_1",
  "x": "More recently, Zeghidour et al. <cite>[8]</cite> proposed an alternative learnable architecture based on a convolutional architecture that computes a scattering transform and can be initialized as an approximation of mel-filterbanks, and obtained promising results on endto-end phone recognition on TIMIT.",
  "y": "background"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_2",
  "x": "3. For scattering-based trainable filterbanks, keeping the lowpass filter fixed during training allows to efficiently learn the filters from a random initialization, whereas the results of <cite>[8]</cite> with random initialization of both the filters and the lowpass filter showed poor performances compared to a suitable initialization;",
  "y": "differences"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_3",
  "x": "The first architecture we consider is inspired by [3, 4] , the second one is taken from <cite>[8]</cite> .",
  "y": "uses"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_4",
  "x": "In their work, they use a max-pooling operator for low-pass filtering. In contrast, Zeghidour et al. <cite>[8]</cite> use 40 complex-valued filters with a square modulus operator as non-linearity.",
  "y": "background"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_5",
  "x": "For both architectures, we also propose to keep this low-pass filter fixed while learning the convolution filter weights, a setting that was not explored by Zeghidour et al. <cite>[8]</cite> , who learnt the lowpass filter weights when randomly initializing the convolutions.",
  "y": "differences"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_6",
  "x": "2 <cite>[8]</cite> use 1 to prevent log(0) and [3, 4] use 0.01. We kept the values initially used by the authors of the respective papers and did not try alternatives.",
  "y": "uses"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_8",
  "x": "As described in Section 2.2, we evaluate the integration of instance normalization after the log-compression in the trainable filterbanks, which was not used in previous work [3, 4, 7,<cite> 8]</cite> but is used in our baseline.",
  "y": "differences"
 },
 {
  "id": "123d8e8ddef15fed120908c5c20656_9",
  "x": "More importantly, using either an Han-fixed or Han-learnt filter when learning scatteringbased filterbanks from a random initialization removes the gap in performance with the Gabor wavelet initialization that was observed in <cite>[8]</cite> where the lowpass filter was also initialized randomly.",
  "y": "differences"
 },
 {
  "id": "12ab280d48ef6bfae0ff27a400e2ab_0",
  "x": "This session focused on experimental or planned approaches to human language technology evaluation and included an overview and five papers: two papers on experimental evaluation approaches [l, 2], and three about the ongoing work in new annotation and evaluation approaches for human language technology [3, <cite>4,</cite> 5] .",
  "y": "background"
 },
 {
  "id": "12ab280d48ef6bfae0ff27a400e2ab_1",
  "x": "The last three papers ([3, <cite>4,</cite> 5]) take various approaches to the issue of predicate-argument 1The Penn Treebank parse annotations provide an interesting case where annotation supported evaluation.",
  "y": "background"
 },
 {
  "id": "12ab280d48ef6bfae0ff27a400e2ab_2",
  "x": "This session focused on experimental or planned approaches to human language technology evaluation and included an overview and five papers: two papers on experimental evaluation approaches [l, 2] , and three about the ongoing work in new annotation and evaluation approaches for human language technology [3, <cite>4,</cite> 5] .",
  "y": "background"
 },
 {
  "id": "12ab280d48ef6bfae0ff27a400e2ab_3",
  "x": "The last three papers ( [3, <cite>4,</cite> 5] ) take various approaches to the issue of predicate-argument 1The Penn Treebank parse annotations provide an interesting case where annotation supported evaluation.",
  "y": "background"
 },
 {
  "id": "12ab280d48ef6bfae0ff27a400e2ab_4",
  "x": "The last three papers [3, <cite>4,</cite> 5] all reflect a concern to develop better evaluation methods for semantics, with a shared focus on predicate-argument evaluation.",
  "y": "background"
 },
 {
  "id": "12ab280d48ef6bfae0ff27a400e2ab_5",
  "x": "Both Marcus and Grishman argued that the Treebank annotation should directly support the MUC-style predicate-argument evaluation outlined in<cite> [4]</cite> , although the Treebank annotations may be a sub-set of what is used for MUC predicate-argument evaluation.",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_0",
  "x": "Verb-noun combinations (VNCs), consisting of a verb with a noun in its direct object position, are a common type of semantically-idiomatic MWE in English and cross-lingually (<cite>Fazly et al., 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_1",
  "x": "In this paper we further incorporate knowledge of the lexico-syntactic fixedness of VNCs -automatically acquired from corpora using the method of <cite>Fazly et al. (2009)</cite> -into our various embedding-based approaches.",
  "y": "uses"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_2",
  "x": "Much research on MWE identification has focused on specific kinds of MWEs (e.g., Patrick and Fletcher, 2005; Uchiyama et al., 2005) , including English VNCs (e.g., <cite>Fazly et al., 2009</cite>; Salton et al., 2016) , although some recent work has considered the identification of a broad range of kinds of MWEs (e.g., Schneider et al., 2014; Brooke et al., 2014; Savary et al., 2017) .",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_3",
  "x": "Work on MWE identification has leveraged rich linguistic knowledge of the constructions under consideration (e.g., <cite>Fazly et al., 2009</cite>; Fothergill and Baldwin, 2012) , treated literal and idiomatic as two senses of an expression and applied approaches similar to word-sense disambiguation (e.g., Birke and Sarkar, 2006; Hashimoto and Kawahara, 2008) , incorporated topic models (e.g., Li et al., 2010) , and made use of distributed representations of words (Gharbieh et al., 2016) .",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_4",
  "x": "<cite>Fazly et al. (2009)</cite> formed a set of eleven lexicosyntactic patterns for VNC instances capturing the voice of the verb (active or passive), determiner (e.g., a, the), and number of the noun (singular or plural).",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_5",
  "x": "<cite>Fazly et al. (2009)</cite> formed a set of eleven lexicosyntactic patterns for VNC instances capturing the voice of the verb (active or passive), determiner (e.g., a, the), and number of the noun (singular or plural). <cite>They</cite> then determine the canonical form, C(v, n), for a given VNC as follows: 2",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_6",
  "x": "<cite>Fazly et al. (2009)</cite> showed that idiomatic usages of a VNC tend to occur in that expression's canonical form, while literal usages do not.",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_7",
  "x": "We use the VNC-Tokens dataset (Cook et al., 2008) -the same dataset used by <cite>Fazly et al. (2009)</cite> and Salton et al. (2016) -to train and evaluate our models.",
  "y": "similarities uses"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_8",
  "x": "<cite>Fazly et al. (2009)</cite> and Salton et al. (2016) structured their experiments differently.",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_9",
  "x": "<cite>Fazly et al.</cite> report results over DEV and TEST separately.",
  "y": "background"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_10",
  "x": "We therefore use accuracy to evaluate our models following <cite>Fazly et al. (2009)</cite> because the classes are roughly balanced.",
  "y": "motivation uses"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_11",
  "x": "In Table 2 we report results on DEV and TEST for each model, as well as the unsupervised CForm model of <cite>Fazly et al. (2009)</cite> , which simply labels a VNC as idiomatic if it occurs in its canonical form, and as literal otherwise.",
  "y": "differences"
 },
 {
  "id": "12c5d72fad925c8ec025cda87a0fd9_12",
  "x": "In line with the findings of <cite>Fazly et al. (2009)</cite> , CForm achieves higher precision and recall on idiomatic usages than literal ones.",
  "y": "similarities"
 },
 {
  "id": "13249ad2fd022b9b4f1d22d2ca77cd_0",
  "x": "The weights of this linear combination are usually trained to maximise some automatic translation metric (e.g. BLEU) [1] using Minimum Error Rate Training (MERT) [2,<cite> 3]</cite> or a variant of the Margin Infused Relaxed Algorithm (MIRA) [4, 5] .",
  "y": "background"
 },
 {
  "id": "13249ad2fd022b9b4f1d22d2ca77cd_1",
  "x": "The most common approach is an iterative algorithm MERT <cite>[3]</cite> which employs N-best lists (the best N translations decoded with a weight set from a previous iteration) as candidate translations C. In this way, the loss function is constructed as E(\u0112,\u00ca) = S s=1 E(\u0113 s ,\u00ea s ), where\u0113 is the reference sentence,\u00ea is selected from N-best lists by\u00ea s = arg max e\u2208C K k=1 w k H k (e, f s ) and S represents the volume of sentences.",
  "y": "background"
 },
 {
  "id": "134baefab4d27e9dafd0c050c43775_0",
  "x": "The only exceptions we are aware of are the Groningen Meaning Bank and the Parallel Meaning Bank <cite>(Abzianidze et al., 2017)</cite> , two annotation efforts which use a graphical user interface for annotating sentences with CCG derivations and other annotation layers, and which have produced CCG treebanks for English, German, Italian, and Dutch.",
  "y": "background"
 },
 {
  "id": "13d1d79a4922d3b5d215d6f8f722ba_0",
  "x": "De Cao et al. <cite>[2]</cite> proposed a method to detect the set of suitable WordNet senses able to evoke the same frame by exploiting the hypernym hierarchies that capture the largest number of LUs in the frame.",
  "y": "background"
 },
 {
  "id": "13d1d79a4922d3b5d215d6f8f722ba_1",
  "x": "The only comparable evaluation available is reported in [5] , and shows that our results are promising. De Cao at al. <cite>[2]</cite> reported a better performance, particularly for recall, but evaluation of their mapping algorithm relied on a gold standard of 4 selected frames having at least 10 LUs and a given number of corpus instantiations.",
  "y": "differences"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_0",
  "x": "Several neural architectures have been employed including variants of Long Short-Term Memory (LSTM)<cite> (Alikaniotis et al., 2016</cite>; Taghipour and Ng, 2016) and Convolutional Neural Networks (CNN) (Dong and Zhang, 2016) .",
  "y": "background"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_1",
  "x": "For instance, <cite>Alikaniotis et al. (2016)</cite> developed score-specific word embeddings (SSWE) to address the AA task on the ASAP dataset.",
  "y": "motivation"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_2",
  "x": "We implement a CNN as the AA model and compare its performance when initialized with our embeddings, tuned based on natural writing errors, to the one obtained when bootstrapped with the SSWE, proposed by <cite>Alikaniotis et al. (2016)</cite> , that relies on random noisy contexts and script scores.",
  "y": "similarities uses"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_3",
  "x": "<cite>Alikaniotis et al. (2016)</cite> assessed the same dataset by building a bidirectional double-layer LSTM which outperformed Distributed Memory Model of Paragraph Vectors (PV-DM) (Le and Mikolov, 2014) and Support Vector Machines (SVM) baselines.",
  "y": "background"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_4",
  "x": "<cite>Alikaniotis et al. (2016)</cite> applied a similar idea; in their SSWE model, they trained word embeddings to distinguish between correct and noisy contexts in addition to focusing more on each word's contribution to the overall text score.",
  "y": "background motivation"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_5",
  "x": "In this section, we describe three different neural networks to pre-train word representations: the model implemented by <cite>Alikaniotis et al. (2016)</cite> and the two error-oriented models we propose in this work.",
  "y": "uses"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_6",
  "x": "We compare our pre-training models to the SSWE developed by <cite>Alikaniotis et al. (2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "13d3d973a4be832f66b049b364fea5_7",
  "x": "Table 2 demonstrates that learning from the er-9 Using the same parameters as <cite>Alikaniotis et al. (2016)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_0",
  "x": "The vast majority of prior methods assume a domain independent context, and rely on Wikipedia and Simple English Wikipedia, a subset of Wikipedia using simplified grammar and terminology, to learn simplifications <cite>(Biran et al., 2011</cite>; Paetzold and Specia, 2015) , with translationbased approaches using an aligned version (Coster and Kauchak, 2011; Horn et al., 2014; Yatskar et al., 2010) .",
  "y": "background"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_1",
  "x": "Further, some approaches work by detecting all pairs of words in a corpus and filtering to isolate synonym or hypernym-relationship pairs using WordNet<cite> (Biran et al., 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_2",
  "x": "One approach identifies all pairwise permutations of 'content' terms and then applies semantic (i.e., WordNet) and simplicity filters to eliminate pairs that are not simplifications<cite> (Biran et al., 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_3",
  "x": "Embeddings identify words that share context in an unsupervised, scalable way and are more efficient than constructing co-occurrence matrices<cite> (Biran et al., 2011)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_4",
  "x": "To retain only rules of the form complex word \u2192 simple word we calculate the corpus complexity, C<cite> (Biran et al., 2011)</cite> of each word w as the ratio between the frequency (f ) in the scientific versus general corpus: C w = f w,scientif ic /f w,general .",
  "y": "similarities"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_5",
  "x": "We require that the final complexity score of the first word in the rule be greater than the second. While this simplicity filter has been shown to work well in general corpora<cite> (Biran et al., 2011)</cite> , it is sensitive to very small differences in the frequencies with which both words appear in the corpora.",
  "y": "differences"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_6",
  "x": "In prior context-aware simplification systems, the decision of whether to apply a simplification rule in an input sentence is complex, involving several similarity operations on word co-occurrence matrices<cite> (Biran et al., 2011)</cite> or using embeddings to incorporate co-occurrence context for pairs generated using other means (Paetzold and Specia, 2015) .",
  "y": "background"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_7",
  "x": "The second is the cosine similarity of a minimum shared frequency co-occurrence matrix for the words in the pair and the co-occurrence matrix for the input sentence<cite> (Biran et al., 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_8",
  "x": "Our SimpleScience approach outperforms the original approach by<cite> Biran et al. (2011)</cite> applied to the Wikipedia and SEW corpus as well as to the scientific corpus (Table 1) .",
  "y": "similarities uses"
 },
 {
  "id": "1527ce2786adfe0decf8c926a3d846_9",
  "x": "Adding techniques to filter antonym rules, such as using co-reference chains<cite> (Adel and Sch\u00fctze, 2014)</cite> , is important in future work.",
  "y": "future_work"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_0",
  "x": "Bollmann and S\u00f8gaard (2016) and <cite>Bollmann et al. (2017)</cite> recently showed that we can obtain more robust historical text normalization models by exploiting synergies across historical text normalization datasets and with related tasks.",
  "y": "background"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_1",
  "x": "Specifically, <cite>Bollmann et al. (2017)</cite> showed that multitask learning with German grapheme-to-phoneme translation as an auxiliary task improves a stateof-the-art sequence-to-sequence model for historical text normalization of medieval German manuscripts.",
  "y": "background"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_2",
  "x": "We consider 10 datasets from 8 different languages: German, using the <cite>Anselm dataset</cite> (taken from <cite>Bollmann et al., 2017</cite>) and texts from the RIDGES corpus (Odebrecht et al., 2016) <cite>Bollmann et al. (2017)</cite> to obtain a single dataset.",
  "y": "uses"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_3",
  "x": "Specifically, we evaluate a state-ofthe-art approach to historical text normalization <cite>(Bollmann et al., 2017)</cite> with and without various auxiliary tasks, across 10 historical text normalization datasets.",
  "y": "motivation uses"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_4",
  "x": "Model We use the same encoder-decoder architecture with attention as described in <cite>Bollmann et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_5",
  "x": "The hyperparameters were set on a randomly selected subset of 50,000 tokens from each of the following datasets: English, German (<cite>Anselm</cite>), Hungarian, Icelandic, and Slovene (Gaj).",
  "y": "uses"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_6",
  "x": "<cite>Bollmann et al. (2017)</cite> also describe a multi-task learning (MTL) scenario where the encoder-decoder model is trained on two datasets in parallel.",
  "y": "background"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_7",
  "x": "<cite>Bollmann et al. (2017)</cite> also describe a multi-task learning (MTL) scenario where the encoder-decoder model is trained on two datasets in parallel. We perform similar experiments on pairwise combinations of our datasets.",
  "y": "similarities"
 },
 {
  "id": "1540b0b172971ac75771b414765f1d_8",
  "x": "There is a wide range of design questions and sharing strategies that we ignore here, focusing instead on under what circumstances the approach advocated in <cite>(Bollmann et al., 2017)</cite> works.",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_0",
  "x": "LR-decoding algorithms exist for phrasebased (Koehn, 2004; Galley and Manning, 2010) and syntax-based (Huang and Mi, 2010; Feng et al., 2012 ) models and also for hierarchical phrasebased models (Watanabe et al., 2006; <cite>Siahbani et al., 2013</cite>) , which is our focus in this paper.",
  "y": "uses background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_1",
  "x": "Throughout this paper we abuse the notation for simplicity and use the term GNF grammars for such SCFGs. This constraint drastically reduces the size of grammar for LR-Hiero in comparison to Hiero grammar (<cite>Siahbani et al., 2013</cite>) .",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_2",
  "x": "This constraint drastically reduces the size of grammar for LR-Hiero in comparison to Hiero grammar (<cite>Siahbani et al., 2013</cite>) .",
  "y": "background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_3",
  "x": "<cite>Siahbani et al. (2013)</cite> propose an augmented version of LR decoding to address some limitations in the original LR-Hiero algorithm in terms of translation quality and time efficiency.",
  "y": "background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_4",
  "x": "We introduce two improvements to LR decoding of GNF grammars: (1) We add queue diversity to the <cite>cube pruning algorithm for LR-Hiero</cite>, and (2) We extend the LR-Hiero decoder to capture all the hierarchical phrasal alignments that are reachable in CKY-Hiero (restricted to using GNF grammars).",
  "y": "extends uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_5",
  "x": "Although, LR-Hiero performs much faster than Hiero in decoding and obtains BLEU scores comparable to phrase-based translation system on some language pairs, there is still a notable gap between CKY-Hiero and LR-Hiero (<cite>Siahbani et al., 2013</cite>) .",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_6",
  "x": "LR-Hiero with CP was introduced in (<cite>Siahbani et al., 2013</cite>) .",
  "y": "extends background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_7",
  "x": "d=1 in standard cube pruning for LR-Hiero (<cite>Siahbani et al., 2013</cite>) .",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_8",
  "x": "Pop limit for Hiero and <cite>LRHiero+CP</cite> is 500 and beam size LR-Hiero is 500.",
  "y": "uses background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_9",
  "x": "We extend the LR-Hiero decoder to handle such cases by making the GNF grammar more expressive. Pop limit for Hiero and <cite>LRHiero+CP</cite> is 500 and beam size LR-Hiero is 500. Other extraction and decoder settings such as maximum phrase length, etc. were identical across settings.",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_10",
  "x": "Pop limit for Hiero and <cite>LRHiero+CP</cite> is 500 and beam size LR-Hiero is 500. Other extraction and decoder settings such as maximum phrase length, etc. were identical across settings.",
  "y": "uses background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_11",
  "x": "To make the results comparable we use the same feature set for all baselines, Hiero as well (including new features proposed by (<cite>Siahbani et al., 2013</cite>) ).",
  "y": "similarities uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_12",
  "x": "We use 3 baselines: (i) our implementation of (Watanabe et al., 2006) : LR-Hiero with beam search (LR-Hiero) and (ii) LR-Hiero with cube pruning (<cite>Siahbani et al., 2013</cite>) : (<cite>LR-Hiero+CP</cite>); and (iii) Kriya, an open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012) .",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_13",
  "x": "Row 3 is from (<cite>Siahbani et al., 2013</cite>) 5 . As we discussed in Section 2, <cite>LR-Hiero+CP</cite> suffers from severe search errors on Zh-En (1.5 BLEU) but using queue diversity (QD=15) we fill this gap.",
  "y": "motivation uses differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_14",
  "x": "Table 2a shows the translation quality of different systems in terms of BLEU score. Row 3 is from (<cite>Siahbani et al., 2013</cite>) 5 . As we discussed in Section 2, <cite>LR-Hiero+CP</cite> suffers from severe search errors on Zh-En (1.5 BLEU) but using queue diversity (QD=15) we fill this gap. We achieve better results than <cite>our previous work</cite> (<cite>Siahbani et al., 2013</cite>) type (c) rules.",
  "y": "differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_15",
  "x": "We can see that for all language pairs (ab) constantly improves performance of LRHiero, significantly better than <cite>LR-Hiero+CP</cite> and LR-Hiero (p-value<0.05) on Cs-En and Zh-En, evaluated by MultEval (Clark et al., 2011) .",
  "y": "differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_16",
  "x": "Table 2a shows the translation quality of different systems in terms of BLEU score. Row 3 is from (<cite>Siahbani et al., 2013</cite>) 5 . As we discussed in Section 2, <cite>LR-Hiero+CP</cite> suffers from severe search errors on Zh-En (1.5 BLEU) but using queue diversity (QD=15) we fill this gap. Row 4 is the same translation system as row 3 (<cite>LR-Hiero+CP</cite>).",
  "y": "differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_17",
  "x": "But modifying rule type (c) does not show any improvement due to spurious ambiguity created by 5 We report results on Cs-En and De-En in (<cite>Siahbani et al., 2013</cite>) .",
  "y": "similarities uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_18",
  "x": "Table 2a shows the translation quality of different systems in terms of BLEU score. We can see that for all language pairs (ab) constantly improves performance of LRHiero, significantly better than <cite>LR-Hiero+CP</cite> and LR-Hiero (p-value<0.05) on Cs-En and Zh-En, evaluated by MultEval (Clark et al., 2011) . But modifying rule type (c) does not show any improvement due to spurious ambiguity created by 5 We report results on Cs-En and De-En in (<cite>Siahbani et al., 2013</cite>) .",
  "y": "similarities differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_19",
  "x": "We achieve better results than <cite>our previous work</cite> (<cite>Siahbani et al., 2013</cite>) type (c) rules.",
  "y": "differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_20",
  "x": "In (<cite>Siahbani et al., 2013</cite>) we discuss that LR-Hiero with beam search (Watanabe et al., 2006) does not perform at the same level of state-of-the-art Hiero (more LM calls and less translation quality).",
  "y": "background"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_21",
  "x": "In (<cite>Siahbani et al., 2013</cite>) we discuss that LR-Hiero with beam search (Watanabe et al., 2006) does not perform at the same level of state-of-the-art Hiero (more LM calls and less translation quality). As we can see in this figure, adding new modified rules slightly increases the number of language model queries on Cs-En and De-En so that <cite>LR-Hiero+CP</cite> still works 2 to 3 times faster than Hiero.",
  "y": "uses"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_22",
  "x": "<cite>LRHiero+CP</cite> with our modifications works substantially faster than LR-Hiero while obtain significantly better translation quality on Zh-En.",
  "y": "differences"
 },
 {
  "id": "1542325bbf9bed87c22d34d12ee40e_23",
  "x": "On Zh-En, <cite>LR-Hiero+CP</cite> applies queue diversity (QD=15) which reduces search errors and improves translation quality but increases the number of hypothesis generation as well.",
  "y": "differences"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_0",
  "x": "Here, we also try to mimic the word2vec <cite>(Mikolov et al., 2013)</cite> embeddings (i.e. that are the expected outputs of the model) to learn the rare word representations with a complex morphology.",
  "y": "uses"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_1",
  "x": "Classical word representation models such as word2vec <cite>(Mikolov et al., 2013)</cite> have been successful in learning word representations for frequent words.",
  "y": "background"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_2",
  "x": "Bojanowski et al. (2017) introduce an extension to word2vec <cite>(Mikolov et al., 2013)</cite> by representing each word in terms of the vector representations of its n-grams, which was earlier applied by Sch\u00fctze (1993) that learns the representations of fourgrams by applying singular value decomposition (SVD).",
  "y": "background"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_3",
  "x": "For training, we use the pre-trained word2vec <cite>(Mikolov et al., 2013)</cite> vectors in order to minimize the cost between the learned and pre-trained vectors with the following objective function:",
  "y": "uses"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_4",
  "x": "For the pre-trained word vectors, we used the word vectors of dimension 300 that were obtained by training word2vec <cite>(Mikolov et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_6",
  "x": "However, our model performs better than both fasttext (Bojanowski et al., 2017) and word2vec <cite>(Mikolov et al., 2013)</cite> on Turkish despite the highly agglutinative morphological structure of the language.",
  "y": "differences"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_7",
  "x": "For English, we used the syntactic relations section provided in the Google analogy dataset <cite>(Mikolov et al., 2013)</cite> that involves 10675 questions.",
  "y": "uses"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_8",
  "x": "The results show that our model outperforms both word2vec <cite>(Mikolov et al., 2013)</cite> and fasttext (Bojanowski et al., 2017) on both Turkish and English languages.",
  "y": "differences"
 },
 {
  "id": "155920441b8e81dff4e2b8e110383d_11",
  "x": "Our morpheme-based model morph2vec learns better word representations for morphologically complex words compared to the word-based model word2vec <cite>(Mikolov et al., 2013)</cite> , character-based model char2vec (Cao and Rei, 2016) , and the character n-gram level model fasttext (Bojanowski et al., 2017) .",
  "y": "differences"
 },
 {
  "id": "15bacab4a8c520cfcdd7e7bd1e9ec5_1",
  "x": "We will introduce an in-depth case study of Generative Adversarial Networks for NLP, with a focus on dialogue generation <cite>(Li et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "15bacab4a8c520cfcdd7e7bd1e9ec5_2",
  "x": "Finally, we provide an in-depth case study of deploying two-agent GAN models for conversational AI <cite>(Li et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "15c8ca572430c214d9c571fbe0db95_0",
  "x": "In this paper, we present a phrase-based unigram system similar to the one in (<cite>Tillmann and Xia, 2003</cite>) , which is extended by an unigram orientation model.",
  "y": "similarities"
 },
 {
  "id": "15c8ca572430c214d9c571fbe0db95_1",
  "x": "Our baseline model is the unigram monotone model described in (<cite>Tillmann and Xia, 2003</cite>) .",
  "y": "uses"
 },
 {
  "id": "15c8ca572430c214d9c571fbe0db95_2",
  "x": "We use a DP-based beam search procedure similar to the one presented in (<cite>Tillmann and Xia, 2003</cite>) .",
  "y": "similarities"
 },
 {
  "id": "15c8ca572430c214d9c571fbe0db95_3",
  "x": "This is the model presented in (<cite>Tillmann and Xia, 2003</cite>) .",
  "y": "uses"
 },
 {
  "id": "15df1d107fb349f78c313b0c3342b8_0",
  "x": "The system that we propose builds on top of one of the latest neural MT architectures called the Transformer <cite>(Vaswani et al., 2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "15df1d107fb349f78c313b0c3342b8_1",
  "x": "This section provides a brief high-level explanation of the neural MT approach that we are using as a baseline system, which is one of the strongest systems presented recently <cite>(Vaswani et al., 2017)</cite> , as well as a glance of its differences with other popular neural machine translation architectures.",
  "y": "motivation background"
 },
 {
  "id": "15df1d107fb349f78c313b0c3342b8_2",
  "x": "In this paper we make use of the third paradigm for neural machine translation, proposed in <cite>(Vaswani et al., 2017)</cite> , namely the Transformer architecture, which is based on a feed-forward encoder-decoder scheme with attention mechanisms.",
  "y": "uses"
 },
 {
  "id": "15df1d107fb349f78c313b0c3342b8_3",
  "x": "Equations and details about the transformer system can be found in the original paper <cite>(Vaswani et al., 2017)</cite> and are out of the scope of this paper.",
  "y": "background"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_0",
  "x": "Current Simultaneous Neural Machine Translation (SNMT) systems (Satija and Pineau, 2016; Cho and Esipova, 2016; <cite>Gu et al., 2017)</cite> use an AGENT to control an incremental encoder-decoder (or sequence to sequence) NMT model.",
  "y": "background"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_1",
  "x": "Current Simultaneous Neural Machine Translation (SNMT) systems (Satija and Pineau, 2016; Cho and Esipova, 2016; <cite>Gu et al., 2017)</cite> use an AGENT to control an incremental encoder-decoder (or sequence to sequence) NMT model. In this paper, we propose adding a new action to the AGENT: a PREDICT action that predicts what words might appear in the input stream.",
  "y": "extends"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_2",
  "x": "An agent-based framework whose actions decide whether to translate or wait for more input is a natural way to extend neural MT to simultaneous neural MT and has been explored in (Satija and Pineau, 2016; <cite>Gu et al., 2017)</cite> which contains two main components: The ENVIRONMENT which receives the input words X = {x 1 , . . . , x N } from the source language and incrementally generates translated words W = {w 1 , . . . , w M } in the target language; And the AGENT which decides an action for each time step, a t .",
  "y": "background"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_3",
  "x": "The agent in the greedy decoding framework<cite> (Gu et al., 2017)</cite> was trained using reinforcement learning with the policy gradient algorithm (Williams, 1992) , which observes the current state of the ENVIRONMENT at time step t as o t where o t = [c t ; s t ; w m ].",
  "y": "uses"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_4",
  "x": "The delay reward is smoothed using a Target Delay which is a scalar constant denoted by d \u21e4<cite> (Gu et al., 2017)</cite> :",
  "y": "uses"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_5",
  "x": "Reinforcement Learning is used to train the AGENT using a policy gradient algorithm<cite> (Gu et al., 2017</cite>; Williams, 1992) which searches for the maximum in",
  "y": "uses"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_6",
  "x": "All sentences have been tokenized and the words are segmented using byte pair encoding (BPE) (Sennrich et al., 2016 Model Configuration For a fair comparison, we follow the settings that worked the best for the greedy decoding model in<cite> (Gu et al., 2017)</cite> and set the target delay d \u21e4 for the AGENT to 0.7.",
  "y": "uses"
 },
 {
  "id": "167511f278a8596aed0124c3a4242b_7",
  "x": "We modified the SNMT trainable agent in<cite> (Gu et al., 2017)</cite> and added a new non-trivial PREDICT action to the agent.",
  "y": "extends"
 },
 {
  "id": "16780bd3c2b350f6d61f2f55f9f88c_0",
  "x": "For our study, we use a small corpus of Enron email threads which has been previously annotated with dialog acts <cite>(Hu et al., 2009</cite> ).",
  "y": "uses"
 },
 {
  "id": "16780bd3c2b350f6d61f2f55f9f88c_1",
  "x": "An utterance has one of 5 dialog acts: RequestAction, RequestInformation, Inform, Commit and Conventional (see <cite>(Hu et al., 2009</cite> ) for details).",
  "y": "background"
 },
 {
  "id": "16780bd3c2b350f6d61f2f55f9f88c_2",
  "x": "We use the manual gold dialog act annotations present in our corpus, which use a very small dialog act tag set. An utterance has one of 5 dialog acts: RequestAction, RequestInformation, Inform, Commit and Conventional (see <cite>(Hu et al., 2009</cite> ) for details).",
  "y": "uses background"
 },
 {
  "id": "16780bd3c2b350f6d61f2f55f9f88c_3",
  "x": "We instead use the DA tagger of<cite> Hu et al. (2009)</cite> , which we re-trained using the training sets for each of our cross validation folds, applying it to the test set of that fold.",
  "y": "uses"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_0",
  "x": "Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French (Xia and McCord, 2004) , German-English (Collins et al., 2005) , Chinese-English <cite>(Wang et al., 2007</cite>; Zhang et al., 2008) , and English-Japanese (Lee et al., 2010) .",
  "y": "background"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_1",
  "x": "The pre-ordering rules can be made manually (Collins et al., 2005;<cite> Wang et al., 2007</cite>; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011) .",
  "y": "background"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_2",
  "x": "Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007) , and English-SOV languages (Xu et al., 2009; Katz-Brown et al., 2011) . The pre-ordering rules can be made manually (Collins et al., 2005;<cite> Wang et al., 2007</cite>; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011) .",
  "y": "background"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_3",
  "x": "Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English (Habash, 2007) , and English-SOV languages (Xu et al., 2009; Katz-Brown et al., 2011) . The pre-ordering rules can be made manually (Collins et al., 2005;<cite> Wang et al., 2007</cite>; Han et al., 2012) or extracted automatically from a parallel corpus (Xia and McCord, 2004; Habash, 2007; Zhang et al., 2007; Wu et al., 2011) . The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system.",
  "y": "motivation"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_4",
  "x": "Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by 1.61. Moreover, this rule set substantially decreased the total times of rule application about 60%, compared with a constituent-based approach<cite> (Wang et al., 2007)</cite> .",
  "y": "differences"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_5",
  "x": "The most similar work to this paper is that of<cite> Wang et al. (2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_6",
  "x": "We argue that even though the rules by<cite> Wang et al. (2007)</cite> exist, it is almost impossible to automatically convert their rules into rules that are applicable to dependency parsers.",
  "y": "motivation"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_7",
  "x": "The most similar work to this paper is that of<cite> Wang et al. (2007)</cite> . They created a set of preordering rules for constituent parsers for ChineseEnglish PBSMT. In contrast, we propose a set of pre-ordering rules for dependency parsers.",
  "y": "similarities differences"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_8",
  "x": "We used the MOSES PBSMT system in our experiments. The training data, which included those data used in<cite> Wang et al. (2007)</cite> , contained 1 million pairs of sentences extracted from the Linguistic Data Consortium's parallel news corpora. Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs.",
  "y": "differences"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_9",
  "x": "We used the MOSES PBSMT system in our experiments. The training data, which included those data used in<cite> Wang et al. (2007)</cite> , contained 1 million pairs of sentences extracted from the Linguistic Data Consortium's parallel news corpora.",
  "y": "similarities"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_10",
  "x": "We implemented the constituent-based preordering rule set in<cite> Wang et al. (2007)</cite> for comparison, which is called WR07 below.",
  "y": "uses"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_11",
  "x": "Similar to<cite> Wang et al. (2007)</cite> , we carried out human evaluations to assess the accuracy of our dependency-based pre-ordering rules by employing the system \"OUR DEP 2\" in Table 1 .",
  "y": "uses similarities"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_12",
  "x": "The overall accuracy of this rule set is 60.0%, which is almost at the same level as the WR07 rule set (62.1%), according to the similar evaluation (200 sentences and one annotator) conducted in<cite> Wang et al. (2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "17252628fa9c03c2fe0b44763fc7a2_13",
  "x": "Notice that some of the incorrect pre-orderings may be caused by erroneous parsing as also suggested by<cite> Wang et al. (2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_0",
  "x": "Transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008;<cite> Huang and Sagae, 2010</cite> ) utilize a deterministic shift-reduce process for making structural predictions.",
  "y": "background"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_1",
  "x": "In the aspect of decoding, beam-search (Johansson and Nugues, 2007; Zhang and Clark, 2008; Huang et al., 2009 ) and partial dynamic-programming<cite> (Huang and Sagae, 2010)</cite> have been applied to improve upon greedy one-best search, and positive results were reported.",
  "y": "background"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_2",
  "x": "Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003;<cite> Huang and Sagae, 2010)</cite> process.",
  "y": "background"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_3",
  "x": "Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard (Yamada and Matsumoto, 2003;<cite> Huang and Sagae, 2010)</cite> process. We adopt the arc-eager system 1 , for which the actions are: \u2022 Shift, which removes the front of the queue and pushes it onto the top of the stack; \u2022 Reduce, which pops the top item off the stack; \u2022 LeftArc, which pops the top item off the stack, and adds it as a modifier to the front of the queue; \u2022 RightArc, which removes the front of the queue, pushes it onto the stack and adds it as a modifier to the top of the stack.",
  "y": "uses"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_4",
  "x": "These features are mostly taken from Zhang and Clark (2008) and<cite> Huang and Sagae (2010)</cite> , and our parser reproduces the same accuracies as reported by both papers.",
  "y": "similarities uses"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_5",
  "x": "2 Following<cite> Huang and Sagae (2010)</cite>, we assign POS-tags to the training data using ten-way jackknifing.",
  "y": "uses"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_6",
  "x": "Table 4 shows the final test results of our parser for English. We include in the table results from the pure transition-based parser of Zhang and Clark (2008) (row 'Z&C08 transition'), the dynamic-programming arc-standard parser of<cite> Huang and Sagae (2010)</cite> (row 'H&S10'), and graphbased models including MSTParser (McDonald and Pereira, 2006) , the baseline feature parser of Koo et al. (2008) (row 'K08 baeline') , and the two models of Koo and Collins (2010 ing the highest attachment score reported for a transition-based parser, comparable to those of the best graph-based parsers.",
  "y": "uses"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_7",
  "x": "Table 5 shows the results of our final parser, the pure transition-based parser of Zhang and Clark (2008) , and the parser of<cite> Huang and Sagae (2010)</cite> on Chinese.",
  "y": "uses"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_8",
  "x": "Table 5 shows the results of our final parser, the pure transition-based parser of Zhang and Clark (2008) , and the parser of<cite> Huang and Sagae (2010)</cite> on Chinese. Our scores for this test set are the best reported so far and significantly better than the previous systems.",
  "y": "differences"
 },
 {
  "id": "17d44521cfdd351d29b4e5f80d41cd_9",
  "x": "The effect of the new features appears to outweigh the effect of combining transition-based and graph-based models, reported by Zhang and Clark (2008) , as well as the effect of using dynamic programming, as in-<cite> Huang and Sagae (2010)</cite> .",
  "y": "differences"
 },
 {
  "id": "17eb0ea80e5a2f18096ef41521af4e_0",
  "x": "Our work tries to learn the main concepts making up the template structure in domain summaries, similar to <cite>(Chambers and Jurafsky, 2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "17eb0ea80e5a2f18096ef41521af4e_1",
  "x": "Our work demonstrates the possibility of learning conceptual information in several domains and languages, while previous work <cite>(Chambers and Jurafsky, 2011)</cite> has addressed sets of related domains (e.g., MUC-4 templates) in English.",
  "y": "differences"
 },
 {
  "id": "188f10a5b78a5e691e10d180dfde6f_0",
  "x": "Various NLP tasks have benefited from domain adaptation techniques, including part-ofspeech tagging (Blitzer et al., 2006; Huang and Yates, 2010a) , chunking (Daum\u00e9 III, 2007;<cite> Huang and Yates, 2009)</cite> , named entity recognition (Guo et al., 2009; Turian et al., 2010) , dependency parsing (Dredze et al., 2007; Sagae and Tsujii, 2007) and semantic role labeling (Dahlmeier and Ng, 2010; Huang and Yates, 2010b) .",
  "y": "background"
 },
 {
  "id": "188f10a5b78a5e691e10d180dfde6f_1",
  "x": "A number of techniques have been developed in the literature to tackle the problem of cross-domain feature divergence and feature sparsity, including clustering based word representation learning methods<cite> (Huang and Yates, 2009</cite>; Candito et al., 2011) , word embedding based representation learning methods (Turian et al., 2010; Hovy et al., 2015) and some other representation learning methods (Blitzer et al., 2006) .",
  "y": "background"
 },
 {
  "id": "188f10a5b78a5e691e10d180dfde6f_2",
  "x": "The proposed approach is closely related to the clustering based method<cite> (Huang and Yates, 2009</cite> ) as we both use latent state representations as generalizable features.",
  "y": "similarities uses"
 },
 {
  "id": "188f10a5b78a5e691e10d180dfde6f_3",
  "x": "For example,<cite> Huang and Yates (2009)</cite> used the discrete hidden state of a word under HMMs as augmenting features for cross-domain POS tagging and NP chunking.",
  "y": "background"
 },
 {
  "id": "188f10a5b78a5e691e10d180dfde6f_4",
  "x": "Previous works have demonstrated the usefulness of discrete hidden states induced from a HMM on addressing feature sparsity in domain adaptation<cite> (Huang and Yates, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "188f10a5b78a5e691e10d180dfde6f_5",
  "x": "We used the same experimental datasets as in<cite> (Huang and Yates, 2009</cite> ) for cross-domain POS tagging from Wall Street Journal (WSJ) domain (Marcus et al., 1993) to MED-LINE domain (PennBioIE, 2005) and for crossdomain NP chunking from CoNLL shared task dataset (Tjong et al., 2000) to Open American National Corpus (OANC) (Reppen et al., 2005) .",
  "y": "uses similarities"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_0",
  "x": "One can also assign interpretations; for example, <cite>[27]</cite> argue their LAS self-attention heads are differentiated phoneme detectors.",
  "y": "background"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_1",
  "x": "Hybrid self-attention/LSTM encoders were studied in the context of listenattend-spell (LAS) <cite>[27]</cite> , and the Transformer was directly adapted to speech in [19, 28, 29] ; both are encoder-decoder systems.",
  "y": "background"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_2",
  "x": "Unlike past works, we do not require convolutional frontends [19] or interleaved recurrences <cite>[27]</cite> to train self-attention for ASR.",
  "y": "differences"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_3",
  "x": "Wide contexts also enable incorporation of noise/speaker contexts, as <cite>[27]</cite> suggest regarding the broad-context attention heads in the first layer of their self-attentional LAS model.",
  "y": "background"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_4",
  "x": "Our proposed framework ( Figure 1a ) is built around self-attention layers, as used in the Transformer encoder [22] , previous explorations of self-attention in ASR [19,<cite> 27]</cite> , and defined in Section 2.3.",
  "y": "similarities uses"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_5",
  "x": "A convolutional frontend is a typical downsampling strategy [8, 19] ; however, we leave integrating other layer types into SAN-CTC as future work. Instead, we consider three fixed approaches, from least-to most-preserving of the input data: subsampling, which only takes every k-th frame; pooling, which aggregates every k consecutive frames via a statistic (average, maximum); reshaping, where one concatenates k consecutive frames into one <cite>[27]</cite> .",
  "y": "extends differences"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_6",
  "x": "The latter was found necessary for self-attentional LAS <cite>[27]</cite> , as additive encodings did not give convergence.",
  "y": "differences"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_7",
  "x": "We see that unlike self-attentional LAS <cite>[27]</cite> , SAN-CTC works respectably even with no position en- coding; in fact, the contribution of position is relatively minor (compare with [21] , where location in an encoder-decoder system improved CER by 3% absolute).",
  "y": "differences"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_8",
  "x": "Inspired by <cite>[27]</cite> , we plot the standard deviation of attention weights for each head as training progresses; see Figure 2 for details.",
  "y": "similarities uses"
 },
 {
  "id": "18a44fac8d2f450aee62fc15c00c6f_9",
  "x": "In the first layers, we similarly observe a differentiation of variances, along with wide-context heads; in later layers, unlike <cite>[27]</cite> we still see mild differentiation of variances.",
  "y": "differences"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_0",
  "x": "State-of-the-art deep neural networks leverage task-specific architectures to develop hierarchical representations of their input, with each layer building a refined abstraction of the layer that came before it<cite> (Conneau et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_1",
  "x": "State-of-the-art deep neural networks leverage task-specific architectures to develop hierarchical representations of their input, with each layer building a refined abstraction of the layer that came before it<cite> (Conneau et al., 2016)</cite> . In a departure from this philosophy, we propose a divide-and-conquer approach, where a team of readers each focus on different aspects of the text, and then combine their representations to make a joint decision.",
  "y": "differences"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_2",
  "x": "Compared to deep Convolutional Networks (CNN) for text (Zhang et al., 2015; <cite>Conneau et al., 2016)</cite> , the MVN strategy emphasizes network width over depth.",
  "y": "differences"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_3",
  "x": "That is, we replace Equation 5 with v i = s<cite> (Conneau et al., 2016)</cite>",
  "y": "uses"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_4",
  "x": "The AG corpus (Zhang et al., 2015; <cite>Conneau et al., 2016)</cite> contains categorized news articles from more than 2,000 news outlets on the web.",
  "y": "background"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_5",
  "x": "The AG corpus (Zhang et al., 2015; <cite>Conneau et al., 2016)</cite> contains categorized news articles from more than 2,000 news outlets on the web. A random sample of the training set was used for hyper-parameter tuning.",
  "y": "uses"
 },
 {
  "id": "193d388c3f4c346cb62711f3f04c0f_6",
  "x": "These results show that the bag-of-words MVN outperforms the state-of-theart accuracy obtained by the non-neural n-gram TFIDF approach (Zhang et al., 2015) , as well as several very deep CNNs<cite> (Conneau et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_0",
  "x": "For example, <cite>Mikolov et al. (2013)</cite> utilize Skipgram NegativeSampling (SGNS) to train word embeddings using word-context pairs formed from windows moving across a text corpus.",
  "y": "background"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_1",
  "x": "We are interested in modifying the Skipgram Negative-Sampling (SGNS) objective in<cite> (Mikolov et al., 2013)</cite> to utilize document-wide feature vectors while simultaneously learning continuous document weights loading onto topic vectors.",
  "y": "extends"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_2",
  "x": "Each word is represented with a fixedlength dense distributed-representation vector, but unlike <cite>Mikolov et al. (2013)</cite> the same word vectors are used in both the pivot and target representations.",
  "y": "differences"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_3",
  "x": "As in <cite>Mikolov et al. (2013)</cite> , pairs of pivot and target words (j, i) are extracted when they cooccur in a moving window scanning across the corpus.",
  "y": "uses"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_4",
  "x": "Unless stated otherwise, the negative sampling power beta is set to 3/4 and the number of negative samples is fixed to n = 15 as in <cite>Mikolov et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_5",
  "x": "<cite>Mikolov et al. (2013)</cite> provide the intuition that word vectors can be summed together to form a semantically meaningful combination of both words.",
  "y": "background"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_6",
  "x": "Word vectors are initialized to the pretrained values found in <cite>Mikolov et al. (2013)</cite> but otherwise updates are allowed to these vectors at training time.",
  "y": "uses"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_7",
  "x": "The first, which we Figure 5 demonstrates that token similarities are learned in a similar fashion as in SGNS<cite> (Mikolov et al., 2013</cite> ) but specialized to the Hacker News corpus.",
  "y": "similarities"
 },
 {
  "id": "197b557d7b5c7c2d195be84990719b_8",
  "x": "This work demonstrates a simple model, lda2vec, that extends SGNS<cite> (Mikolov et al., 2013)</cite> to build unsupervised document representations that yield coherent topics.",
  "y": "extends"
 },
 {
  "id": "19b647ab74d28b59b7df2be729b2d7_0",
  "x": "The style of an utterance can be altered based on requirements; introducing elements of sarcasm, or aspects of factual and emotional argumentation styles<cite> [15,</cite> 14] .",
  "y": "background"
 },
 {
  "id": "19b647ab74d28b59b7df2be729b2d7_1",
  "x": "By using machine learning models designed to classify different classes of interest, such as sentiment, sarcasm, and topic, data can be bootstrapped to greatly increase the amount of data available for indexing and utterance selection <cite>[15]</cite> .",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_0",
  "x": "Of the two state-of-the-art approaches on dialog act recognition, one uses a deep stack of Recurrent Neural Networks (RNNs) (Schmidhuber, 1990) to capture long distance relations between tokens (Khanpour et al., 2016) , while the other uses multiple parallel temporal Convolutional Neural Networks (CNNs) (Fukushima, 1980) to capture relevant functional patterns with different length <cite>(Liu et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_1",
  "x": "Thus, only speaker information that is directly related to the dialog, such as turn-taking <cite>(Liu et al., 2017)</cite> , is typically considered.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_2",
  "x": "Concerning information from the surrounding segments, its influence, especially that of preceding segments, has been thoroughly explored in at least two studies (Ribeiro et al., 2015; <cite>Liu et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_3",
  "x": "On the convolutional side, <cite>Liu et al. (2017)</cite> generated the segment representation by combining the outputs of three parallel CNNs with different context window sizes, in order to capture different functional patterns.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_4",
  "x": "<cite>Liu et al. (2017)</cite> used 200-dimensional Word2Vec embeddings trained on Facebook data.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_5",
  "x": "Still, Khanpour et al. (2016) reported 73.9% accuracy on the validation set and 80.1% on the test set, while <cite>Liu et al. (2017)</cite> reported 74.5% and 76.9% accuracy on the two sets used to evaluate <cite>their experiments</cite>.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_6",
  "x": "Additionally, <cite>Liu et al. (2017)</cite> explored the use of context information concerning speaker changes and from the surrounding segments.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_7",
  "x": "Additionally, <cite>Liu et al. (2017)</cite> explored the use of context information concerning speaker changes and from the surrounding segments. The first was provided as a flag and concatenated to the segment representation. Concerning the latter, <cite>they explored</cite> the use of discourse models, as well as of approaches that concatenated the context information directly to the segment representation.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_8",
  "x": "Additionally, <cite>Liu et al. (2017)</cite> explored the use of context information concerning speaker changes and from the surrounding segments. The first was provided as a flag and concatenated to the segment representation. Concerning the latter, <cite>they explored</cite> the use of discourse models, as well as of approaches that concatenated the context information directly to the segment representation. <cite>The discourse models</cite> transform the model into a hierarchical one by generating a sequence of dialog act classifications from the sequence of segment representations.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_9",
  "x": "Additionally, <cite>Liu et al. (2017)</cite> explored the use of context information concerning speaker changes and from the surrounding segments. The first was provided as a flag and concatenated to the segment representation. Concerning the latter, <cite>they explored</cite> the use of discourse models, as well as of approaches that concatenated the context information directly to the segment representation. <cite>The discourse models</cite> transform the model into a hierarchical one by generating a sequence of dialog act classifications from the sequence of segment representations. Thus, when predicting the classification of a segment, the surrounding ones are also taken into account. However, when the <cite>discourse model</cite> is based on a CNN or a bidirectional LSTM unit, it considers information from future segments, which is not available for a dialog system.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_10",
  "x": "Additionally, <cite>Liu et al. (2017)</cite> explored the use of context information concerning speaker changes and from the surrounding segments. The first was provided as a flag and concatenated to the segment representation. Concerning the latter, <cite>they explored</cite> the use of discourse models, as well as of approaches that concatenated the context information directly to the segment representation. <cite>The discourse models</cite> transform the model into a hierarchical one by generating a sequence of dialog act classifications from the sequence of segment representations. Thus, when predicting the classification of a segment, the surrounding ones are also taken into account. However, when the <cite>discourse model</cite> is based on a CNN or a bidirectional LSTM unit, it considers information from future segments, which is not available for a dialog system. Still, even when relying on future information, the approaches based on <cite>discourse models</cite> performed worse than those that concatenated the context information directly to the segment representation.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_11",
  "x": "In this sense, similarly to our previous study using SVMs (Ribeiro et al., 2015) , <cite>Liu et al. (2017)</cite> concluded that providing that information in the form of the classification of the surrounding segments leads to better results than using <cite>their words</cite>, even when those classifications are obtained automatically.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_12",
  "x": "Using the setup with gold standard labels from three preceding segments, <cite>Liu et al. (2017)</cite> achieved 79.6% and 81.8% on the two sets used to evaluate the approach.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_13",
  "x": "The resulting word embeddings are 200-dimensional as in the study by <cite>Liu et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_14",
  "x": "This is a dense layer which maps the segment representations into a 100-dimensional space, as in the study by <cite>Liu et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_15",
  "x": "As stated in Section 3, of the two state-of-the-art approaches on dialog act recognition, one uses a RNN-based approach (Khanpour et al., 2016) for segment representation, while the other uses one based on CNNs <cite>(Liu et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_16",
  "x": "As described in Section 3, the convolutional approach by <cite>Liu et al. (2017)</cite> uses a set of parallel temporal CNNs with different window size, each followed by a max pooling operation.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_17",
  "x": "To achieve the results presented in <cite>their paper</cite>, <cite>Liu et al. (2017)</cite> used three CNNs with 100 filters and 1, 2, and 3 as context window sizes.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_18",
  "x": "As stated in Section 3, Khanpour et al. (2016) explored embedding spaces with dimensionality 75, 150, and 300 together with different embedding approaches. In every case, the embedding space with dimensionality 150 led to the best results. <cite>Liu et al. (2017)</cite> used a different dimensionality value, 200, in <cite>their study</cite>.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_19",
  "x": "Khanpour et al. (2016) used pre-trained embeddings using both approaches in their study and achieved their best results using Word2Vec embeddings trained on Wikipedia data. <cite>Liu et al. (2017)</cite> also used Word2Vec embeddings, but trained on Facebook data.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_20",
  "x": "In <cite>their study</cite>, <cite>Liu et al. (2017)</cite> used pre-trained embeddings but let them adapt to the task during the training phase. However, they did not perform a comparison with the case where the embeddings are not adaptable. Thus, in our study we experimented with both fixed and adaptable embeddings.",
  "y": "motivation"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_22",
  "x": "Starting with the dimensionality of the embedding space, in Table 3 we can see that using an embedding space with 200 dimensions, such as in the study by <cite>Liu et al. (2017)</cite> , leads to better results than any of the dimensionality values used by Khanpour et al. (2016) .",
  "y": "similarities"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_23",
  "x": "for dialog act recognition is the dialog history, with influence decaying with distance (Ribeiro et al., 2015; Lee & Dernoncourt, 2016; <cite>Liu et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_24",
  "x": "However, information concerning the speakers and, more specifically, turn-taking has also been proved important <cite>(Liu et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_25",
  "x": "<cite>Liu et al. (2017)</cite> further showed that using a single label per segment is better than using the probability of each class.",
  "y": "background"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_26",
  "x": "In our previous study, we have used up to five preceding segments and showed that the gain becomes smaller as the number of preceding segments increases, which supports the claim that the closest segments are the most relevant. <cite>Liu et al. (2017)</cite> stopped at three preceding segments, but noticed a similar pattern.",
  "y": "similarities"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_27",
  "x": "Although both our previous study and that by <cite>Liu et al. (2017)</cite> used the classifications of preceding segments as context information, none of them took into account that those segments have a sequential nature and simply flattened the sequence before appending it to the segment representation.",
  "y": "motivation"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_28",
  "x": "Thus, turn-taking information is relevant for dialog act recognition. In fact, this has been confirmed in the study by <cite>Liu et al. (2017)</cite> . Thus, we also use turn-taking information in this study.",
  "y": "motivation"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_29",
  "x": "Starting with the reproduction of the flat label sequence approach, in Table 9 we can see that the results follow the same pattern as in our previous study and that by <cite>Liu et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_30",
  "x": "We used adaptations of the approaches with top performance in previous studies, namely the RNN-based approach by Khanpour et al. (2016) and the CNN-based approach by <cite>Liu et al. (2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_31",
  "x": "Starting with the typically used word-level, we have shown that using an embedding space with 200 dimensions as used by <cite>Liu et al. (2017)</cite> in <cite>their study</cite> leads to better results than any of the dimensionality values used by Khanpour et al. (2016) .",
  "y": "uses"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_32",
  "x": "In the case of <cite>the study</cite> by <cite>Liu et al. (2017)</cite> , direct result comparison with those reported is not possible since they were obtained on different sets.",
  "y": "differences"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_33",
  "x": "In the case of <cite>the study</cite> by <cite>Liu et al. (2017)</cite> , direct result comparison with those reported is not possible since they were obtained on different sets. However, the result differences between overlapping steps in our experiments are consistent with those described in <cite>their paper</cite>.",
  "y": "similarities differences"
 },
 {
  "id": "1ab7893c2a930bc5af3c34a5912dd2_34",
  "x": "In the case of <cite>the study</cite> by <cite>Liu et al. (2017)</cite> , direct result comparison with those reported is not possible since they were obtained on different sets. However, the result differences between overlapping steps in our experiments are consistent with those described in <cite>their paper</cite>. Thus, we can safely state that <cite>their approach</cite> can be improved by using five parallel CNNs, dependency-based word embeddings, and the summary representation of context information.",
  "y": "similarities differences"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_0",
  "x": "We have recently introduced a new transdimensional random field (TRF 1 ) LM <cite>[4]</cite> , where the whole sentence is modeled as a random field. As the random field approach avoids local normalization which is required in the conditional approach, it is computationally more efficient in computing sentence probabilities and has the potential advantage of being able to flexibly integrating a richer set of features.",
  "y": "background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_1",
  "x": "Improvements: First, in <cite>[4]</cite> , the diagonal elements of the Hessian matrices are online estimated during the SA iterations to rescale the gradients, which is shown to benefit the convergence of the training algorithm.",
  "y": "background motivation"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_2",
  "x": "As defined in <cite>[4]</cite> , a trans-dimensional random field model represents the joint probability of the pair (l, x l ) as where n l /n is the empirical probability of length l. f ( T is the feature vector, which is usually defined to be position-independent and length-independent, e.g. is the normalization constant of length l. By making explicit the role of length in model definition, it is clear that the model in (1) is a mixture of random fields on sentences of different lengths (namely on subspaces of different dimensions), and hence will be called a trans-dimensional random field (TRF).",
  "y": "background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_3",
  "x": "In the joint SA training algorithm <cite>[4]</cite> , we define another form of mixture distribution as follows: where \u03b6 = {\u03b61, . . . , \u03b6m} with \u03b61 = 0 and \u03b6 l is the hypothesized value of the log ratio of Z l (\u03bb) with respect to Z1(\u03bb), namely log . Z1(\u03bb) is chosen as the reference value and can be calculated exactly.",
  "y": "extends"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_4",
  "x": "In order to make use of Hessian information in parameter optimization, we use the online estimated Hessian diagonal elements to rescale the gradients in <cite>[4]</cite> .",
  "y": "uses background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_5",
  "x": "Step I: MCMC sampling: Generate a sample set B (t) with p(l, x l ; \u03bb (t\u22121) , \u03b6 (t\u22121) ) as the stationary distribution, using the trans-dimensional mixture sampling method (See Section 3.3 in <cite>[4]</cite> ).",
  "y": "uses background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_6",
  "x": "Fig.1 show an example of convergence curves of the SA training algorithm in <cite>[4]</cite> and the new improved SA.",
  "y": "background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_7",
  "x": "The improved SA algorithm (in Section 2.2) is used to train the TRF LMs, in conjunction with the trans-dimensional mixture sampling proposed in Section 3.3 of <cite>[4]</cite> .",
  "y": "uses background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_8",
  "x": "The learning rates of \u03bb and \u03b6 are set as suggested in <cite>[4]</cite> : where tc, t0 are constants and 0.5 < \u03b2 \u03bb , \u03b2 \u03b6 < 1.",
  "y": "uses background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_9",
  "x": "The class information is also used to accelerate the sampling, and more than one CPU cores are used to parallelize the algorithm, as described in <cite>[4]</cite> .",
  "y": "uses background"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_10",
  "x": "In this section, speech recognition and 1000-best list rescoring experiments are conducted as configured in <cite>[4]</cite> . The maximum length of TRFs is m = 82, which is equal to the maximum length of the training sentences. The other configurations are: K = 300, \u03b2 \u03bb = 0.8, \u03b2 \u03b6 = 0.6, tc = 3000, t0 = 2000, tmax = 20, 000. L2 regularization with constant 4 \u00d7 10 \u22125 is used to avoid over-fitting. 6 CPU cores are used to parallelize the algorithm. The word error rates (WERs) and perplexities (PPLs) on WSJ'92 test set are shown in Tab.4.",
  "y": "uses"
 },
 {
  "id": "1baddfeea7d11fc02cc26ff698a601_13",
  "x": "Equally importantly, evaluations in this paper and also in <cite>[4]</cite> have shown that TRF LMs are able to perform as good as NN LMs (either RNN or FNN) on a variety of tasks.",
  "y": "background"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_0",
  "x": "Contributions In this work, we alleviate the requirements: (1) We present the first model that is able to induce bilingual word embeddings from non-parallel data without any other readily available translation resources such as pre-given bilingual lexicons; (2) We demonstrate the utility of BWEs induced by this simple yet effective model in the BLI task from comparable Wikipedia data on benchmarking datasets for three language pairs<cite> (Vuli\u0107 and Moens, 2013b</cite> ).",
  "y": "similarities"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_1",
  "x": "Training Data We use comparable Wikipedia data introduced in (Vuli\u0107 and Moens, 2013a;<cite> Vuli\u0107 and Moens, 2013b</cite> ) available in three language pairs to induce bilingual word embeddings: (i) a collection of 13, 696 Spanish-English Wikipedia article pairs (ES-EN), (ii) a collection of 18, 898 ItalianEnglish Wikipedia article pairs (IT-EN), and (iii) a collection of 7, 612 Dutch-English Wikipedia article pairs (NL-EN).",
  "y": "similarities"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_2",
  "x": "Following prior work (Haghighi et al., 2008; Prochasson and Fung, 2011;<cite> Vuli\u0107 and Moens, 2013b)</cite> , we retain only nouns that occur at least 5 times in the corpus.",
  "y": "extends differences"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_3",
  "x": "The seed lexicon is bootstrapped using the method from (Peirsman and Pad\u00f3, 2011;<cite> Vuli\u0107 and Moens, 2013b)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_4",
  "x": "All parameters of the baseline BLI models (i.e., topic models and their settings, the number of dimensions K, feature pruning values, window size) are set to their optimal values according to suggestions in prior work (Steyvers and Griffiths, 2007; Vuli\u0107 and Moens, 2013a;<cite> Vuli\u0107 and Moens, 2013b</cite>; Kiela and Clark, 2014) .",
  "y": "similarities uses"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_5",
  "x": "Due to space constraints, for (much) more details about the baselines we point to the relevant literature (Peirsman and Pad\u00f3, 2011; Tamura et al., 2012; Vuli\u0107 and Moens, 2013a;<cite> Vuli\u0107 and Moens, 2013b)</cite> .",
  "y": "background"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_6",
  "x": "Test Data For each language pair, we evaluate on standard 1,000 ground truth one-to-one translation pairs built for the three language pairs (ES/IT/NL-EN) (Vuli\u0107 and Moens, 2013a;<cite> Vuli\u0107 and Moens, 2013b)</cite> .",
  "y": "similarities"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_7",
  "x": "lation in the other language (EN) according to the ground truth over the total number of ground truth translation pairs (=1000) (Gaussier et al., 2004; Tamura et al., 2012;<cite> Vuli\u0107 and Moens, 2013b)</cite> .",
  "y": "background"
 },
 {
  "id": "1c0d971cf771f351b51661950f4b14_8",
  "x": "Finally, we may use the knowledge of BWEs obtained by BWESG from document-aligned data to learn bilingual correspondences (e.g., word translation pairs or lists of semantically similar words across languages) which may in turn be used for representation learning from large unaligned multilingual datasets as proposed in (Haghighi et al., 2008; Mikolov et al., 2013b;<cite> Vuli\u0107 and Moens, 2013b)</cite> .",
  "y": "motivation"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_0",
  "x": "<cite>Vaswani et al. (2017)</cite> propose a new architecture that avoids recurrence and convolution completely.",
  "y": "background"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_1",
  "x": "In <cite>Vaswani et al. (2017)</cite> , the authors introduce the Transformer network, a novel architecture that avoids the recurrence equation and maps the input sequences into hidden states solely using attention.",
  "y": "background"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_2",
  "x": "In <cite>Vaswani et al. (2017)</cite> , the authors introduce the Transformer network, a novel architecture that avoids the recurrence equation and maps the input sequences into hidden states solely using attention. We propose a variant of the Transformer network which we call Weighted Transformer that uses self-attention branches in lieu of the multi-head attention.",
  "y": "extends"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_3",
  "x": "The Transformer network<cite> (Vaswani et al., 2017)</cite> avoids the recurrence completely and uses only self-attention.",
  "y": "background"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_4",
  "x": "The Transformer network<cite> (Vaswani et al., 2017)</cite> avoids the recurrence completely and uses only self-attention. We propose a modified Transformer network wherein the multi-head attention layer is replaced by a branched self-attention layer.",
  "y": "extends"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_5",
  "x": "<cite>Vaswani et al. (2017)</cite> proportionally reduce d k = d v = d model so that the computational load of the multi-head attention is the same as simple self-attention.",
  "y": "background"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_6",
  "x": "For the sake of brevity, we refer the reader to <cite>Vaswani et al. (2017)</cite> for additional details regarding the architecture.",
  "y": "background"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_7",
  "x": "<cite>Vaswani et al. (2017)</cite> state three reasons for the preference: (a) computational complexity of each layer, (b) concurrency, and (c) path length between long-range dependencies.",
  "y": "background"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_8",
  "x": "In Equations (3) and (4), we described the attention layer proposed in <cite>Vaswani et al. (2017)</cite> comprising the multi-head attention sub-layer and a FFN sub-layer.",
  "y": "uses"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_9",
  "x": "As in <cite>Vaswani et al. (2017)</cite> , we used the Adam optimizer (Kingma & Ba, 2014) with (\u03b2 1 , \u03b2 2 ) = (0.9, 0.98) and = 10 \u22129 .",
  "y": "similarities"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_10",
  "x": "Further, we do not use any averaging strategies employed in <cite>Vaswani et al. (2017)</cite> and simply return the final model for testing purposes.",
  "y": "differences"
 },
 {
  "id": "1c1b524d2bfe00c62a5a2e1a05ffc7_13",
  "x": "Our proposed model outperforms the state-of-the-art models including the Transformer<cite> (Vaswani et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_0",
  "x": "In recent years, a number of successful approaches have been proposed for both extractive (Nallapati et al., 2017; Narayan et al., 2018) and abstractive (See et al., 2017;<cite> Chen and Bansal, 2018)</cite> summarization paradigms.",
  "y": "background"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_1",
  "x": "State-ofthe-art approaches are typically trained to generate summaries either in a fully end-to-end fashion (See et al., 2017) , processing the entire article at once; or hierarchically, first extracting content and then paraphrasing it sentence-by-sentence <cite>(Chen and Bansal, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_2",
  "x": "Our approach is similar to <cite>(Chen and Bansal, 2018)</cite> , except that they use parallel data to train their extractors and abstractors.",
  "y": "similarities differences"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_3",
  "x": "We follow the preprocessing pipeline of <cite>(Chen and Bansal, 2018)</cite> , splitting the dataset into 287k/11k/11k pairs for training/validation/testing.",
  "y": "uses"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_4",
  "x": "We pick this model size to be comparable to recent work (See et al., 2017;<cite> Chen and Bansal, 2018)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_5",
  "x": "EXT-ABS is the hierarchical model from <cite>(Chen and Bansal, 2018)</cite> , consisting of a supervised LSTM extractor and separate abstractor, both of which are individually trained on the CNN/DM dataset by aligning summary to article sentences. Our work best resembles EXT-ABS except that we do not rely on any parallel data.",
  "y": "uses similarities differences"
 },
 {
  "id": "1c86f563ababf5ec3c67cbf259252b_6",
  "x": "EXT-ABS is the hierarchical model from <cite>(Chen and Bansal, 2018)</cite> , consisting of a supervised LSTM extractor and separate abstractor, both of which are individually trained on the CNN/DM dataset by aligning summary to article sentences.",
  "y": "background"
 },
 {
  "id": "1dd3adcb79c8bc4b5187b85d836ceb_0",
  "x": "This approach has been shown to be accurate, relatively efficient, and robust using both generative and discriminative models (Roark, 2001; Roark, 2004; <cite>Collins and Roark, 2004</cite>) .",
  "y": "uses"
 },
 {
  "id": "1dd3adcb79c8bc4b5187b85d836ceb_1",
  "x": "Beam-search parsing using an unnormalized discriminative model, as in <cite>Collins and Roark (2004)</cite> , requires a slightly different search strategy than the original generative model described in Roark (2001; 2004) .",
  "y": "uses"
 },
 {
  "id": "1dd3adcb79c8bc4b5187b85d836ceb_2",
  "x": "A generative parsing model can be used on its own, and it was shown in <cite>Collins and Roark (2004)</cite> that a discriminative parsing model can be used on its own.",
  "y": "background"
 },
 {
  "id": "1dd3adcb79c8bc4b5187b85d836ceb_3",
  "x": "Beam-search parsing using an unnormalized discriminative model, as in <cite>Collins and Roark (2004)</cite> , requires a slightly different search strategy than the original generative model described in Roark (2001; 2004) .",
  "y": "uses"
 },
 {
  "id": "1dd3adcb79c8bc4b5187b85d836ceb_4",
  "x": "A generative parsing model can be used on its own, and it was shown in <cite>Collins and Roark (2004)</cite> that a discriminative parsing model can be used on its own.",
  "y": "background"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_0",
  "x": "Recent successes in statistical syntactic parsing based on supervised learning techniques trained on a large corpus of syntactic trees (Collins, 1999; Charniak, 2000;<cite> Henderson, 2003)</cite> have brought forth the hope that the same approaches could be applied to the more ambitious goal of recovering the propositional content and the frame semantics of a sentence.",
  "y": "background"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_1",
  "x": "We present work to test the hypothesis that a current statistical parser <cite>(Henderson, 2003)</cite> can output richer information robustly, that is without any significant degradation of the parser's accuracy on the original parsing task, by explicitly modelling semantic role labels as the interface between syntax and semantics.",
  "y": "extends uses"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_2",
  "x": "To achieve the complex task of assigning semantic role labels while parsing, we use a family of statistical parsers, the Simple Synchrony Network (SSN) parsers <cite>(Henderson, 2003)</cite> , which do not make any explicit independence assumptions, and are therefore likely to adapt without much modification to the current problem.",
  "y": "motivation uses"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_3",
  "x": "<cite>(Henderson, 2003)</cite> exploits this bias by directly inputting information which is considered relevant at a given step to the history representation of the constituent on the top of the stack before that step.",
  "y": "background"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_4",
  "x": "However, the recency preference exhibited by recursively defined neural networks biases learning towards information which flows through fewer history representations. <cite>(Henderson, 2003)</cite> exploits this bias by directly inputting information which is considered relevant at a given step to the history representation of the constituent on the top of the stack before that step.",
  "y": "motivation"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_5",
  "x": "According to the original SSN model in <cite>(Henderson, 2003)</cite> , only the information carried over by the leftmost child and the most recent child of a constituent directly flows to that constituent.",
  "y": "background"
 },
 {
  "id": "1deb67be8226867fe6b9514cdecdec_7",
  "x": "The third line of Table 1 gives the performance on the simpler PTB parsing task of the original SSN parser <cite>(Henderson, 2003)</cite> , that was trained on the PTB data sets contrary to our SSN model trained on the PropBank data sets. These results clearly indicate that our model can perform the PTB parsing task at levels of per-3 Such pairs consists of a tag and a word token.",
  "y": "similarities"
 },
 {
  "id": "1ebbddc6c6740aea71ade2ed915de4_0",
  "x": "To avoid complexities of asynchronous parallel training with shared parameter server (Dean et al., 2012) , the architecture in Fig.2 and Fig. 3 instead can be trained using the alternating training approach proposed in <cite>(Luong et al., 2016)</cite> , where each task is optimized for a fixed number of parameter updates (or mini-batches) before switching to the next task (which is a different language pair).",
  "y": "background"
 },
 {
  "id": "1ebbddc6c6740aea71ade2ed915de4_1",
  "x": "Neural translation attention mechanism (Bahdanau, Cho & Bengio, 2014) has been shown to be highly beneficial for bi-lingual neural translation of long sentences, but it is not compatible with the multi-task multilingual translation models (Dong et al., 2015;<cite> Luong et al, 2016)</cite> described in the previous Section and character-level translation models (Barzdins & Gosko, 2016) described in this Section.",
  "y": "background"
 },
 {
  "id": "1f48420f55771e243c73babf54632f_0",
  "x": "This tutorial introduces the advances in deep Bayesian learning with abundant applications for natural language understanding ranging from speech recognition (Saon and Chien, 2012; Chan et al., 2016) to document summarization (Chang and Chien, 2009 ), text classification (Blei et al., 2003; Zhang et al., 2015) , text segmentation (Chien and Chueh, 2012) , information extraction (Narasimhan et al., 2016) , image caption generation (Vinyals et al., 2015; Xu et al., 2015) , sentence generation (<cite>Li et al., 2016b</cite>) , dialogue control (Zhao and Eskenazi, 2016; Li et al., 2016a) , sentiment classification, recommendation system, question answering (Sukhbaatar et al., 2015) and machine translation , to name a few.",
  "y": "uses"
 },
 {
  "id": "201aa2a740b5d45f273ee298595f5a_0",
  "x": "Recently, multiple studies have focussed on providing a fine-grained analysis of the nature of concrete vs. abstract words from a corpus-based perspective (Bhaskar et al., 2017; Frassinelli et al., 2017; <cite>Naumann et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "201aa2a740b5d45f273ee298595f5a_1",
  "x": "Specifically,<cite> Naumann et al. (2018)</cite> performed their analyses across parts-of-speech by comparing the behaviour of nouns, verbs and adjectives in large-scale corpora.",
  "y": "background"
 },
 {
  "id": "201aa2a740b5d45f273ee298595f5a_3",
  "x": "Moreover, as discussed in previous studies by<cite> Naumann et al. (2018)</cite> and Pollock (2018) , mid-range concreteness scores indicate words that are difficult to categorise unambiguously regarding their concreteness.",
  "y": "background"
 },
 {
  "id": "201aa2a740b5d45f273ee298595f5a_4",
  "x": "This result is perfectly in line with the more general analysis by<cite> Naumann et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "201aa2a740b5d45f273ee298595f5a_5",
  "x": "The general pattern already described in<cite> Naumann et al. (2018)</cite> is confirmed by our quantitative analysis: overall, concrete verbs predominantly subcategorise concrete nouns as subjects and direct objects, while abstract verbs predominantly subcategorise abstract nouns as subjects and direct objects.",
  "y": "similarities"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_0",
  "x": "Previous attempts to annotate QA-SRL initially involved trained annotators (He et al., 2015) but later resorted to crowdsourcing (<cite>Fitzgerald et al., 2018</cite>) to achieve scalability.",
  "y": "background"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_1",
  "x": "Previous attempts to annotate QA-SRL initially involved trained annotators (He et al., 2015) but later resorted to crowdsourcing (<cite>Fitzgerald et al., 2018</cite>) to achieve scalability. Naturally, employing crowd workers raises challenges when annotating semantic structures like SRL. As <cite>Fitzgerald et al. (2018)</cite> acknowledged, the main shortage of the large-scale 2018 dataset is the lack of recall, estimated by experts to be in the lower 70s. In light of this and other annotation inconsistencies, we propose an improved QA-SRL crowdsourcing protocol for high-quality annotation, allowing for substantially more reliable performance evaluation of QA-SRL parsers.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_2",
  "x": "As <cite>Fitzgerald et al. (2018)</cite> acknowledged, the main shortage of the large-scale 2018 dataset is the lack of recall, estimated by experts to be in the lower 70s. In light of this and other annotation inconsistencies, we propose an improved QA-SRL crowdsourcing protocol for high-quality annotation, allowing for substantially more reliable performance evaluation of QA-SRL parsers.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_3",
  "x": "Previous attempts to annotate QA-SRL initially involved trained annotators (He et al., 2015) but later resorted to crowdsourcing (<cite>Fitzgerald et al., 2018</cite>) to achieve scalability. Naturally, employing crowd workers raises challenges when annotating semantic structures like SRL.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_4",
  "x": "Previous attempts to annotate QA-SRL initially involved trained annotators (He et al., 2015) but later resorted to crowdsourcing (<cite>Fitzgerald et al., 2018</cite>) to achieve scalability. Naturally, employing crowd workers raises challenges when annotating semantic structures like SRL. In light of this and other annotation inconsistencies, we propose an improved QA-SRL crowdsourcing protocol for high-quality annotation, allowing for substantially more reliable performance evaluation of QA-SRL parsers.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_5",
  "x": "To foster future research, we release an assessed high-quality gold dataset along with our reproducible protocol and evaluation scheme, and report the performance of the existing <cite>parser</cite> (<cite>Fitzgerald et al., 2018</cite>) as a baseline.",
  "y": "uses"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_6",
  "x": "In subsequent work, <cite>Fitzgerald et al. (2018)</cite> constructed a large-scale corpus and used it to train a <cite>parser</cite>.",
  "y": "background"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_7",
  "x": "In subsequent work, <cite>Fitzgerald et al. (2018)</cite> constructed a large-scale corpus and used it to train a <cite>parser</cite>. 1 <cite>They</cite> crowdsourced 133K verbs with 2.0 QA pairs per verb on average.",
  "y": "background"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_8",
  "x": "Corpora The original 2015 QA-SRL dataset (He et al., 2015) was annotated by non-expert workers after completing a brief training procedure. In subsequent work, <cite>Fitzgerald et al. (2018)</cite> constructed a large-scale corpus and used it to train a <cite>parser</cite>. As both 2015 and <cite>2018 datasets</cite> use a single question generator, both struggle with maintaining coverage.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_9",
  "x": "Corpora The original 2015 QA-SRL dataset (He et al., 2015) was annotated by non-expert workers after completing a brief training procedure. In subsequent work, <cite>Fitzgerald et al. (2018)</cite> constructed a large-scale corpus and used it to train a <cite>parser</cite>. As both 2015 and <cite>2018 datasets</cite> use a single question generator, both struggle with maintaining coverage. Also noteworthy, is that while traditional SRL annotations contain a single authoritative and nonredundant annotation, the <cite>2018 dataset</cite> provides the raw annotations of all annotators. We found that these characteristics of the dataset impede its utility for future development of parsers.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_10",
  "x": "In subsequent work, <cite>Fitzgerald et al. (2018)</cite> constructed a large-scale corpus and used it to train a <cite>parser</cite>. Also noteworthy, is that while traditional SRL annotations contain a single authoritative and nonredundant annotation, the <cite>2018 dataset</cite> provides the raw annotations of all annotators.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_11",
  "x": "Annotation We adopt the annotation machinery of (<cite>Fitzgerald et al., 2018</cite>) implemented using Amazon's Mechanical Turk, 2 and annotate each predicate by 2 trained workers independently, while a third consolidates their annotations into a final set of roles and arguments.",
  "y": "uses"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_12",
  "x": "QA generating annotators are paid the same as in <cite>Fitzgerald et al. (2018)</cite> , while the consolidator is rewarded 5\u00a2 per verb and 3\u00a2 per question.",
  "y": "uses"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_13",
  "x": "Since detecting question paraphrases is still an open challenge, we propose both unlabeled and labeled evaluation metrics. Unlabeled Argument Detection (UA) Inspired by the method presented in (<cite>Fitzgerald et al., 2018</cite>) , arguments are matched using a span matching criterion of intersection over union \u2265 0.5 .",
  "y": "extends"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_14",
  "x": "Unlabeled Argument Detection (UA) Inspired by the method presented in (<cite>Fitzgerald et al., 2018</cite>) , arguments are matched using a span matching criterion of intersection over union \u2265 0.5 .",
  "y": "extends background"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_15",
  "x": "All aligned arguments from the previous step are inspected for label equivalence, similar to the joint evaluation reported in (<cite>Fitzgerald et al., 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_16",
  "x": "As we will see, our evaluation heuristics, adapted from those in <cite>Fitzgerald et al. (2018)</cite> , significantly underestimate agreement between annotations, hence reflecting performance lower bounds.",
  "y": "uses"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_17",
  "x": "We extend our metric for evaluating manual or automatic redundant annotations, like the Dense dataset or <cite>the parser</cite> in (<cite>Fitzgerald et al., 2018</cite>) , which predicts argument spans independently of each other.",
  "y": "uses similarities"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_18",
  "x": "To illustrate the effectiveness of our new goldstandard, we use its Wikinews development set to evaluate the currently available <cite>parser</cite> from (<cite>Fitzgerald et al., 2018</cite>) . While <cite>the parser</cite> correctly predicts 82% of non-implied roles, it skips half of the implied ones.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_19",
  "x": "To illustrate the effectiveness of our new goldstandard, we use its Wikinews development set to evaluate the currently available <cite>parser</cite> from (<cite>Fitzgerald et al., 2018</cite>) . For each predicate, <cite>the parser</cite> classifies every span for being an argument, independently of the other spans.",
  "y": "uses background"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_20",
  "x": "To illustrate the effectiveness of our new goldstandard, we use its Wikinews development set to evaluate the currently available <cite>parser</cite> from (<cite>Fitzgerald et al., 2018</cite>) . As expected, <cite>the parser</cite>'s recall against our gold is substantially lower than the 84.2 recall reported in (<cite>Fitzgerald et al., 2018</cite>) against Dense, due to the limited recall of Dense relative to our gold set.",
  "y": "uses background differences"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_21",
  "x": "To illustrate the effectiveness of our new goldstandard, we use its Wikinews development set to evaluate the currently available <cite>parser</cite> from (<cite>Fitzgerald et al., 2018</cite>) . Based on this inspection, <cite>the parser</cite> completely misses 23% of the 154 roles present in the gold-data, out of which, 17% are implied.",
  "y": "motivation"
 },
 {
  "id": "211b889125682f2596f708be1e83b9_22",
  "x": "As mentioned in the paper body, the <cite>Fitzgerald et al. parser</cite> generates redundant role questions and answers.",
  "y": "differences background motivation"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_0",
  "x": "In <cite>[17]</cite> a dynamical model of language change was proposed, based on a spin glass model for syntactic parameters and language interactions.",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_1",
  "x": "In the case of syntactic parameters behaving as independent variables, in the low temperature regime (see <cite>[17]</cite> for a discussion of the interpretation of the temperature parameter in this model) the dynamics converges rapidly towards an equilibrium state where all the spin variables corresponding to a given syntactic feature for the various languages align to the value most prevalent in the initial configuration.",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_2",
  "x": "Using syntactic data from [6] , [7] , which record explicit entailment relation between different parameter, it was shown in <cite>[17]</cite> , for small graph examples, that in the presence of relations the dynamics settles on equilibrium states that are not necessarily given by completely aligned spins.",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_3",
  "x": "When we interpret the dynamics of the model considered in <cite>[17]</cite> in terms of codes and the space of code parameters, the initial datum of the set of languages L at the vertices of the graph, with its given list of syntactic binary variables, determines a code C L .",
  "y": "uses"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_4",
  "x": "In the presence of entailment relations between different syntactic variables, it was shown in <cite>[17]</cite> that the Hamiltonian should be modified by a term that introduces the relations as a Lagrange multiplier.",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_5",
  "x": "Given an initial condition x 0 \u2208 {0, 1} n L and the datum (J e ) e\u2208E(G L ) of the strengths of the interaction energies along the edges, the same method used in <cite>[17]</cite> , based on the standard Metropolis-Hastings algorithm, can be used to study the dynamics in this setting, with a similar behavior.",
  "y": "uses background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_6",
  "x": "Consider the very small example, with just two entailed syntactic variables and four languages, discussed in <cite>[17]</cite> , where the chosen languages are L = { 1 , 2 , 3 , 4 } = {English, Welsh, Russian, Bulgarian} and the two syntactic parameters are {x 1 , x 2 } = {StrongDeixis, StrongAnaphoricity}. Since we have an entailment relation, the possible values of the variables x i are now ternary, x i ( ) \u2208 {0, \u22121, +1}, that is, we consider here codes C \u2282 F n 3 .",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_7",
  "x": "One can see already in a very simple example, and using the dynamical system in the form described in <cite>[17]</cite> , that the dynamics in the space of code parameters now does not need to move towards the \u03b4 = 0 line.",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_8",
  "x": "We consider in this case the same dynamical system used in <cite>[17]</cite> to model the case with entailment, which is a modification of the Ising model to a coupling of an Ising and a Potts model with q = 3 at the vertices of the graph.",
  "y": "uses"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_9",
  "x": "In the cases with high temperature and either high or low entailment energy, it is shown in <cite>[17]</cite> that one can have equilibrium states like for the high entailment energy case, or for the low entailment energy case.",
  "y": "background"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_10",
  "x": "The example mentioned above is too simple and artificial to be significant, but we can analyze a more general situation, where we consider the full syntactic data of [6] , [7] , with all the entailment relations taken into account, and the same interaction energies along the edges as in <cite>[17]</cite> , taken from the data of [16] , which can be regarded as roughly proportional to a measure of the amount of bilingualism.",
  "y": "uses"
 },
 {
  "id": "22253d7b7cd43697b99909e09e7ebb_11",
  "x": "Dynamics in the space of code parameters: average distance. a lot more complicated than the simple examples discussed in <cite>[17]</cite> .",
  "y": "differences"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_0",
  "x": "Recently, <cite>Vaswani et al. (2017)</cite> proposed the Transformer architecture for machine translation.",
  "y": "motivation background"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_1",
  "x": "The concept of self-attention (Cheng et al., 2016; Parikh et al., 2016) , central to our proposed approach, has shown great promises in natural language processing; It produced state-of-the-art results for machine translation<cite> (Vaswani et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_2",
  "x": "3 SANet: Self-Attention Network Inspired by the Transformer architecture<cite> (Vaswani et al., 2017)</cite> which performed machine translation without recurrent or convolutional layers, we propose the Self-Attention Network (SANet) architecture targeting instead text classification.",
  "y": "differences"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_3",
  "x": "One key difference between our approach and <cite>Vaswani et al. (2017)</cite> 's is that we only perform input-input attention with self-attention, as we do not have sequences as output but a text classification.",
  "y": "differences"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_4",
  "x": "<cite>Vaswani et al. (2017)</cite> defined attention as a function with as input a triplet containing queries Q, keys K with associated values V .",
  "y": "background"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_5",
  "x": "In the case of self-attention, Q, K and V are linear projections of X. Thus, we define the dot-product<cite> (Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_6",
  "x": "We use the positional encoding vectors that were defined by <cite>Vaswani et al. (2017)</cite> as follows.",
  "y": "similarities"
 },
 {
  "id": "22dc2a38e29a1f5ac55c9ac220782b_7",
  "x": "Contrary to <cite>Vaswani et al. (2017)</cite> , we only use a single attention head, with attention performed on the complete sequence with constant d-dimensional inputs.",
  "y": "differences"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_0",
  "x": "Very recently,<cite> Lee et al. (2017)</cite> proposed the first state-of-the-art end-to-end neural coreference resolution system.",
  "y": "background"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_1",
  "x": "We adopt the same span representation approach as in<cite> Lee et al. (2017)</cite> using bidirectional LSTMs and a headfinding attention.",
  "y": "similarities uses"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_2",
  "x": "Compared with the traditional FFNN approach in<cite> Lee et al. (2017)</cite> , biaffine attention directly models both the compatibility of s i and s j by\u015d j U bi\u015di and the prior likelihood of s i having an antecedent by v bi\u015d i .",
  "y": "uses similarities"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_3",
  "x": "Therefore,<cite> Lee et al. (2017)</cite> train the model end-to-end by maximizing the following marginal log-likelihood where GOLD(i) are gold antecedents for s i :",
  "y": "background"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_4",
  "x": "Implementation Details For fair comparisons, we follow the same hyperparameters as in<cite> Lee et al. (2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_5",
  "x": "F1 Our model (single) 67.8 without mention detection loss 67.5 without biaffine attention 67.4<cite> Lee et al. (2017)</cite> 67.3 Table 2 : Ablation study on the development set.",
  "y": "background"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_6",
  "x": "Based on the results on the development set, \u03bb detection = 0.1 works best from {0.05, 0.1, 0.5, 1.0}. Model is trained with ADAM optimizer (Kingma and Ba, 2015) and converges in around 200K updates, which is faster than that of<cite> Lee et al. (2017)</cite> . In particular, compared with<cite> Lee et al. (2017)</cite> , our improvement mainly results from the precision scores.",
  "y": "differences"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_7",
  "x": "While Moosavi and Strube (2017) observe that there is a large overlap between the gold mentions of the training and dev (test) sets, we find that our model can correctly detect 1048 mentions which are not detected by<cite> Lee et al. (2017)</cite> , consisting of 386 mentions existing in training data and 662 mentions not existing in training data.",
  "y": "differences"
 },
 {
  "id": "23119eff3cfd71370e8ad408fc75e1_8",
  "x": "(2) Mention-ranking models explicitly rank all previous candidate mentions for the current mention and select a single highest scoring antecedent for each anaphoric mention (Denis and Baldridge, 2007b; Wiseman et al., 2015; Clark and Manning, 2016a; <cite>Lee et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_0",
  "x": "Meanwhile, several previous works (Carreras, 2007; <cite>Koo and Collins, 2010)</cite> have shown that grandchild interactions provide important information for dependency parsing.",
  "y": "background"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_1",
  "x": "Meanwhile, several previous works (Carreras, 2007; <cite>Koo and Collins, 2010)</cite> have shown that grandchild interactions provide important information for dependency parsing. However, the computational cost of the parsing algorithm increases with the need for more expressive factorizations.",
  "y": "motivation"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_2",
  "x": "However, the computational cost of the parsing algorithm increases with the need for more expressive factorizations. Consequently, the existing most powerful parser<cite> (Koo and Collins, 2010</cite> ) is limited to third-order parts, which requires O(n 4 ) time and O(n 3 ) space.",
  "y": "motivation"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_3",
  "x": "Following<cite> Koo and Collins (2010)</cite> , we refer to these augmented structures as g-spans.",
  "y": "uses"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_4",
  "x": "Following previous works (McDonald and Pereira, 2006; <cite>Koo and Collins, 2010)</cite> , the fourthorder parser captures not only features associated with corresponding fourth-order grand-trisibling parts, but also the features of relevant lower-order parts that are enclosed in its factorization.",
  "y": "uses"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_5",
  "x": "The second set of features is defined as backed-off features<cite> (Koo and Collins, 2010)</cite> for grand-tri-sibling part (g, s, r, m, t)-the 4-gram (g, r, m, t), which never exist in any lower-order part.",
  "y": "uses"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_6",
  "x": "Following<cite> Koo and Collins (2010)</cite> , two versions of POS tags are used for any features involve POS: one using is normal POS tags and another is a coarsened version of the POS tags.",
  "y": "uses"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_7",
  "x": "We compare our method to first-order and secondorder sibling dependency parsers (McDonald and Pereira, 2006) , and two third-order graphbased parsers<cite> (Koo and Collins, 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_8",
  "x": "Our results are also better than the results of the two third-order graph-based dependency parsing models in<cite> Koo and Collins (2010)</cite> .",
  "y": "differences"
 },
 {
  "id": "24506b0aa7a859eb8744e390f9fb60_9",
  "x": "Here we compare our method to an implement of the third-order grand-sibling parser -whose parsing performance on CTB is not reported in<cite> Koo and Collins (2010)</cite> , and the dynamic programming transition-based parser of Huang and Sagae (2010) .",
  "y": "differences"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_0",
  "x": "Several sites have made significant progress to lower the WER to within the 5%-10% range on the Switchboard-CallHome subsets of the Hub5 2000 evaluation <cite>[2</cite>, 3, 4, 5] .",
  "y": "background"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_1",
  "x": "Several sites have made significant progress to lower the WER to within the 5%-10% range on the Switchboard-CallHome subsets of the Hub5 2000 evaluation <cite>[2</cite>, 3, 4, 5] . Given the progress on conversational telephone speech, we focus on the other closely related broadcast news recognition task that received similar attention within the DARPA EARS program.",
  "y": "motivation"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_2",
  "x": "In terms of the amount of training data available from the DARPA EARS program for training systems on CTS and BN, there are a few significant differences as well. The CTS acoustic training corpus consists of approximately 2000 hours of speech with human transcriptions <cite>[2]</cite> . In other words, models being developed for BN typically use lightly supervised transcripts for training [6] .",
  "y": "background"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_3",
  "x": "In <cite>[2,</cite> 3] we describe state-of-the-art speech recognition systems on the CTS task using multiple LSTM and ResNet acoustic models trained on various acoustic features along with word and character LSTMs and convolutional WaveNet-style language models. In this paper we develop a similar but simpler variant for BN.",
  "y": "similarities motivation"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_4",
  "x": "In addition to automatic speech recognition results, similar to <cite>[2]</cite> , we also present human performance on the same BN test sets.",
  "y": "similarities"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_5",
  "x": "Similar to <cite>[2]</cite> , human performance measurements on two broadcast news tasks -RT04 and DEV04F -are carried out by Appen.",
  "y": "similarities"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_6",
  "x": "The transcriptions were also filtered to remove non-speech markers, partial words, punctuation marks etc as described in <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_8",
  "x": "In <cite>[2]</cite> , two kinds of acoustic models, a convolutional and a non-convolutional acoustic model with comparable performance, are used since they produce good complementary outputs which can be further combined for improved performance. The convolutional network used in that work is a residual network (ResNet) and an LSTM is used as the non-convolutional network. Similar to that work, in this paper also we train ResNet and LSTM based acoustic models.",
  "y": "similarities"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_9",
  "x": "To complement the LSTM acoustic model, we train a deep Residual Network based on the best performing architecture proposed in <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_10",
  "x": "In comparison with the results obtained on the CTS evaluation with similar acoustic models <cite>[2]</cite> , the LSTM and ResNet operate at similar WERs.",
  "y": "similarities"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_11",
  "x": "We observe significant WER gains after using the LSTM LMs similar to those reported in <cite>[2]</cite> .",
  "y": "similarities"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_12",
  "x": "4. Compared to the telephone conversation confusions recorded in <cite>[2]</cite> -one symbol that is clearly missing is the back-channel response -this is probably from the very nature of the BN domain.",
  "y": "differences"
 },
 {
  "id": "247bbc4eb671895222065ed425f968_13",
  "x": "5. Similar to telephone conversation confusions reported in <cite>[2]</cite> , humans performance is much higher because the number of deletions is significantly lower -compare 2.3% vs 0.8%/0.6% for deletion errors in Table 5 .",
  "y": "similarities"
 },
 {
  "id": "24b38363d53468175e0274ac0b4fd3_0",
  "x": "Excitingly, the state of the art has recently shifted toward novel semi-supervised techniques such as the incorporation of word embeddings to represent the context of words and concepts<cite> (Tang et al., 2014b)</cite> .",
  "y": "background"
 },
 {
  "id": "24b38363d53468175e0274ac0b4fd3_1",
  "x": "In previous work (Tang et al., 2014a; <cite>Tang et al., 2014b)</cite> sentiment-specific word embeddings have been used as features for identification of tweet-level sentiment but not phrase-level sentiment.",
  "y": "background"
 },
 {
  "id": "24b38363d53468175e0274ac0b4fd3_2",
  "x": "In previous work (Tang et al., 2014a; <cite>Tang et al., 2014b)</cite> sentiment-specific word embeddings have been used as features for identification of tweet-level sentiment but not phrase-level sentiment. In this work we present two different strategies for learning phrase level sentiment specific word embeddings.",
  "y": "motivation background"
 },
 {
  "id": "24b38363d53468175e0274ac0b4fd3_3",
  "x": "For each strategy, class and dimension, we used the functions suggested by<cite> (Tang et al., 2014b</cite> ) (average, maximum and minimum), resulting in 2,400 features.",
  "y": "uses"
 },
 {
  "id": "24b38363d53468175e0274ac0b4fd3_4",
  "x": "We also employed the word embeddings encoding sentiment information generated through the unified models in<cite> (Tang et al., 2014b)</cite> .",
  "y": "uses"
 },
 {
  "id": "24b38363d53468175e0274ac0b4fd3_5",
  "x": "Contrary to the approach by<cite> (Tang et al., 2014b)</cite> , we didn't integrate the sentiment information in the word embeddings training process, but rather the sentiment-specific nature of the embeddings was reflected in the choice of different training datasets, yielding different word embedding features for positive and negative tweets.",
  "y": "differences"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_0",
  "x": "Our work is most closely related to the models presented in [12, 13, 14,<cite> 15]</cite> .",
  "y": "similarities"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_1",
  "x": "Our work is most closely related to the models presented in [12, 13, 14,<cite> 15]</cite> . In the current study we improve upon these previous approaches to visual grounding of speech and present state-of-the-art image-caption retrieval results.",
  "y": "extends similarities"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_2",
  "x": "The work by [12, 13, 14,<cite> 15]</cite> and the results presented here are a step towards more cognitively plausible models of language learning as it is more natural to learn language without prior assumptions about the lexical level.",
  "y": "background"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_3",
  "x": "The approach is based on our own text-based model described in [8] and on the speech-based models described in [13,<cite> 15]</cite> and we refer to those studies for more details.",
  "y": "uses background"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_4",
  "x": "We use importance sampling to select the mismatched pairs; rather than using all the other samples in the mini-batch as mismatched pairs (as done in [8,<cite> 15]</cite> ), we calculate the loss using only the hardest examples (i.e. mismatched pairs with high cosine similarity).",
  "y": "differences"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_5",
  "x": "The main differences with the approaches described in [13,<cite> 15]</cite> are the use of multi-layered GRUs, importance sampling, the cyclic learning rate, snapshot ensembling and the use of vectorial rather than scalar attention.",
  "y": "differences"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_6",
  "x": "While our model is not explicitly trained to recognise words or segment the speech signal, previous work has shown that such information can be extracted by visual grounding models<cite> [15,</cite> 28] .",
  "y": "background"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_7",
  "x": "<cite>[15]</cite> use a binary decision task: given a word and a sentence embedding, decide if the word occurs in the sentence.",
  "y": "background"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_8",
  "x": "We compare our models to [12] and <cite>[15]</cite> , and include our own character-based model for comparison.",
  "y": "uses"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_9",
  "x": "[12] is a convolutional approach, whereas <cite>[15]</cite> is an approach using recurrent highway networks with scalar attention.",
  "y": "background"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_10",
  "x": "We compare our models to [12] and <cite>[15]</cite> , and include our own character-based model for comparison. [12] is a convolutional approach, whereas <cite>[15]</cite> is an approach using recurrent highway networks with scalar attention.",
  "y": "uses"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_11",
  "x": "The largest improvement comes from using the learned MBN features but our approach also improves results for MFCCs, which are the same features as were used in <cite>[15]</cite> .",
  "y": "uses"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_12",
  "x": "We are currently collecting the Semantic Textual Similarity (STS) database in spoken format and the next step will be to investigate whether the model presented here also learns to capture sentence level semantic information and understand language in a deeper sense than recognising word presence. The work presented in <cite>[15]</cite> has made the first efforts in this regard and we aim to extend this to a larger database with sentences from multiple domains.",
  "y": "extends"
 },
 {
  "id": "24ee9b2bd8c97cbe923bc747b09806_13",
  "x": "The work presented in <cite>[15]</cite> has made the first efforts in this regard and we aim to extend this to a larger database with sentences from multiple domains.",
  "y": "background"
 },
 {
  "id": "2504d707a8123774791d98b755551a_0",
  "x": "This also enables us to do inference efficiently since our inference time is merely the inference time of two sequential CRF's; in contrast<cite> Finkel et al. (2005)</cite> reported an increase in running time by a factor of 30 over the sequential CRF, with their Gibbs sampling approximate inference.",
  "y": "differences"
 },
 {
  "id": "2504d707a8123774791d98b755551a_2",
  "x": "However, as can be seen from table 2, we find that the consistency constraint does not hold nearly so strictly in this case. A very common case of this in the CoNLL dataset is that of documents containing references to both The China Daily, a newspaper, and China, the country<cite> (Finkel et al., 2005)</cite> .",
  "y": "similarities"
 },
 {
  "id": "2504d707a8123774791d98b755551a_3",
  "x": "At the same time, the simplicity of our two-stage approach keeps inference time down to just the inference time of two sequential CRFs, when compared to approaches such as those of<cite> Finkel et al. (2005)</cite> who report that their inference time with Gibbs sampling goes up by a factor of about 30, compared to the Viterbi algorithm for the sequential CRF.",
  "y": "differences"
 },
 {
  "id": "2504d707a8123774791d98b755551a_4",
  "x": "\u2022 Most existing work to capture labelconsistency, has attempted to create all n 2 pairwise dependencies between the different occurrences of an entity,<cite> (Finkel et al., 2005</cite>; Sutton and McCallum, 2004) , where n is the number of occurrences of the given entity.",
  "y": "background"
 },
 {
  "id": "2504d707a8123774791d98b755551a_5",
  "x": "Below, we give some intuition about areas for improvement in existing work and explain how our approach incorporates the improvements. \u2022 Most existing work to capture labelconsistency, has attempted to create all n 2 pairwise dependencies between the different occurrences of an entity,<cite> (Finkel et al., 2005</cite>; Sutton and McCallum, 2004) , where n is the number of occurrences of the given entity. This complicates the dependency graph making inference harder.",
  "y": "motivation"
 },
 {
  "id": "2504d707a8123774791d98b755551a_6",
  "x": "\u2022 Most work has looked to model non-local dependencies only within a document<cite> (Finkel et al., 2005</cite>; Chieu and Ng, 2002; Sutton and McCallum, 2004; Bunescu and Mooney, 2004) .",
  "y": "background"
 },
 {
  "id": "2504d707a8123774791d98b755551a_7",
  "x": "The simplicity of our approach makes it easy to incorporate dependencies across the whole corpus, which would be relatively much harder to incorporate in approaches like (Bunescu and Mooney, 2004) and<cite> (Finkel et al., 2005)</cite> .",
  "y": "differences"
 },
 {
  "id": "2504d707a8123774791d98b755551a_8",
  "x": "Additionally, our approach makes it possible to do inference in just about twice the inference time with a single sequential CRF; in contrast, approaches like Gibbs Sampling that model the dependencies directly can increase inference time by a factor of 30<cite> (Finkel et al., 2005</cite> ).",
  "y": "differences"
 },
 {
  "id": "2504d707a8123774791d98b755551a_9",
  "x": "We also compare our performance against (Bunescu and Mooney, 2004) and<cite> (Finkel et al., 2005)</cite> and find that we manage higher relative improvement than existing work despite starting from a very competitive baseline CRF.",
  "y": "differences"
 },
 {
  "id": "2504d707a8123774791d98b755551a_10",
  "x": "Recent work looking to directly model non-local dependencies and do approximate inference are that of Bunescu and Mooney (2004) , who use a Relational Markov Network (RMN) (Taskar et al., 2002) to explicitly model long-distance dependencies, Sutton and McCallum (2004) , who introduce skip-chain CRFs, which add additional non-local edges to the underlying CRF sequence model (which Bunescu and Mooney (2004) lack) and<cite> Finkel et al. (2005)</cite> who hand-set penalties for inconsistency in labels based on the training data and then use Gibbs Sampling for doing approximate inference where the goal is to obtain the label sequence that maximizes the product of the CRF objective function and their penalty.",
  "y": "background"
 },
 {
  "id": "2504d707a8123774791d98b755551a_11",
  "x": "The approach of<cite> Finkel et al. (2005)</cite> makes it possible a to model a broader class of longdistance dependencies than Sutton and McCallum (2004) , because they do not need to make any initial assumptions about which nodes should be connected and they too model dependencies between whole token sequences representing entities and between entity token sequences and their token supersequences that are entities.",
  "y": "background"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_0",
  "x": "The algorithm, which is an extension of<cite> Sassano's (2004)</cite> , allows us to chunk morphemes into base phrases and decide dependency relations of the phrases in a strict left-toright manner.",
  "y": "uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_1",
  "x": "A bunsetsu is a base phrasal unit and consists of one or more content words followed by zero or more function words. In addition, most of algorithms of Japanese dependency parsing, e.g., (Sekine et al., 2000;<cite> Sassano, 2004)</cite> , assume the three constraints below. (1) Each bunsetsu has only one head except the rightmost one. (2) Dependency links between bunsetsus go from left to right. (3) Dependency links do not cross one another.",
  "y": "background"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_2",
  "x": "Most of the modern dependency parsers for Japanese require bunsetsu chunking (base phrase chunking) before dependency parsing (Sekine et al., 2000; Kudo and Matsumoto, 2002;<cite> Sassano, 2004)</cite> .",
  "y": "background"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_3",
  "x": "The algorithm that we propose is based on<cite> (Sassano, 2004)</cite> , which is considered to be a simple form of shift-reduce parsing.",
  "y": "uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_4",
  "x": "The flow of the algorithm, which has the same structure as<cite> Sassano's (2004)</cite> , is controlled with a stack that holds IDs for modifier morphemes.",
  "y": "uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_5",
  "x": "See<cite> (Sassano, 2004)</cite> for further details.",
  "y": "background"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_6",
  "x": "We have designed rather simple features based on the common feature set (Uchimoto et al., 1999; Kudo and Matsumoto, 2002;<cite> Sassano, 2004)</cite> for bunsetsu-based parsers.",
  "y": "uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_7",
  "x": "The system with the previous method employs the algorithm<cite> (Sassano, 2004</cite> ) with the voted perceptron.",
  "y": "extends uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_8",
  "x": "We implemented a parser that employs the algorithm of<cite> (Sassano, 2004)</cite> with the commonly used features and runs with VP instead of SVM, which <cite>Sassano (2004)</cite> originally used.",
  "y": "uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_9",
  "x": "To enable us to compare them we gave bunsetsu chunked sentences by our parser to the parser of<cite> (Sassano, 2004)</cite> in the Kyoto University Corpus. And then we received results from the parser of<cite> (Sassano, 2004)</cite> , which are bunsetsu-based dependency structures, and converted them to morpheme-based structures that follow the scheme we propose in this paper.",
  "y": "extends uses"
 },
 {
  "id": "250a88831a4911f76acca3c9d318de_10",
  "x": "We implemented a parser that employs the algorithm of<cite> (Sassano, 2004)</cite> with the commonly used features and runs with VP instead of SVM, which <cite>Sassano (2004)</cite> originally used. His parser, which cannot do bunsetsu chunking, accepts only a chunked sentence and then produces a bunsetsu-based dependency structure. Thus we cannot directly compare results with ours.",
  "y": "motivation differences"
 },
 {
  "id": "253d635829c733309bb49fc1fcc1cd_0",
  "x": "Automatic detection of fake from legitimate news in different formats such as headlines, tweets and full news articles has been approached in recent Natural Language Processing literature (Vlachos and Riedel, 2014; Vosoughi, 2015; Jin et al., 2016; Rashkin et al., 2017;<cite> Wang, 2017</cite>; Pomerleau and Rao, 2017; Thorne et al., 2018) .",
  "y": "background"
 },
 {
  "id": "253d635829c733309bb49fc1fcc1cd_1",
  "x": "The Liar dataset<cite> (Wang, 2017)</cite> is the first large dataset collected through reliable annotation, but it contains only short statements.",
  "y": "background"
 },
 {
  "id": "253d635829c733309bb49fc1fcc1cd_2",
  "x": "These methods have been used for fake news detection in previous work (Rashkin et al., 2017;<cite> Wang, 2017</cite> fore, we use this model to demonstrate how a classifier trained on data labeled according to publisher's reputation would identify misinformative news articles.",
  "y": "uses background"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_0",
  "x": "Generative models defining joint distributions over parse trees and sentences are good theoretical models for interpreting natural language data, and appealing tools for tasks such as parsing, grammar induction and language modeling (Collins, 1999; Henderson, 2003; Titov and Henderson, 2007; Petrov and Klein, 2007;<cite> Dyer et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_1",
  "x": "Generative models defining joint distributions over parse trees and sentences are good theoretical models for interpreting natural language data, and appealing tools for tasks such as parsing, grammar induction and language modeling (Collins, 1999; Henderson, 2003; Titov and Henderson, 2007; Petrov and Klein, 2007;<cite> Dyer et al., 2016)</cite> . However, they often impose strong independence assumptions which restrict the use of arbitrary features for effective disambiguation. Moreover, generative parsers are typically trained by maximizing the joint probability of the parse tree and the sentence-an objective that only indirectly relates to the goal of parsing. In this work, we propose a parsing and language modeling framework that marries a generative model with a discriminative recognition algorithm in order to have the best of both worlds.",
  "y": "motivation"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_2",
  "x": "We showcase the framework using Recurrent Neural Network Grammars (RNNGs;<cite> Dyer et al. 2016</cite> ), a recently proposed probabilistic model of phrase-structure trees based on neural transition systems.",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_3",
  "x": "In this section we briefly describe Recurrent Neural Network Grammars (RNNGs;<cite> Dyer et al. 2016</cite> ), a top-down transition-based algorithm for parsing and generation.",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_4",
  "x": "Specifically, we use the following features: 1) the stack embedding d t which encodes the stack of the decoder and is obtained with a stack-LSTM (Dyer et al., 2015 <cite>(Dyer et al., , 2016</cite> ; 2) the output buffer embedding o t ; we use a standard LSTM to compose the output buffer and o t is represented as the most recent state of the LSTM; and 3) the parent non-terminal embedding n t which is accessible in the generative model because the RNNG employs a depth-first generation order.",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_5",
  "x": "6 See \u00a7 4 and Appendix A for comparison between this objective and the importance sampler of<cite> Dyer et al. (2016</cite>",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_6",
  "x": "7 Another way of computing p(x) (without lower bounding) would be to use the variational approximation q(a|x) as the proposal distribution as in the importance sampler of<cite> Dyer et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_9",
  "x": "Further connections can be drawn with the importance-sampling based inference of<cite> Dyer et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_10",
  "x": "To find the MAP parse tree argmax a p(a, x) (where p(a, x) is used rank the output of q(a|x)) and to compute the language modeling perplexity (where a \u223c q(a|x)), we collect 100 samples from q(a|x), same as<cite> Dyer et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_12",
  "x": "methods for parsing, ranking approximated MAP trees from q(a|x) with respect to p(a, x) yields a small improvement, as in<cite> Dyer et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_13",
  "x": "It is worth noting that our parsing performance lags behind<cite> Dyer et al. (2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_14",
  "x": "While<cite> Dyer et al. (2016)</cite> use an LSTM as the syntactic composition function of each subtree, we adopt a rather simple composition function based on embedding averaging, which gains computational efficiency but loses accuracy.",
  "y": "differences"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_15",
  "x": "On language modeling, our framework achieves lower perplexity compared to<cite> Dyer et al. (2016)</cite> and baseline models.",
  "y": "differences"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_16",
  "x": "However, we acknowledge a subtle difference between<cite> Dyer et al. (2016)</cite> and our approach compared to baseline language models: while the latter incrementally estimate the next word probability, our approach<cite> (and Dyer et al. 2016</cite> ) directly assigns probability to the entire sentence.",
  "y": "similarities differences"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_17",
  "x": "Overall, the advantage of our framework compared to<cite> Dyer et al. (2016)</cite> is that it opens an avenue to unsupervised training.",
  "y": "differences"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_18",
  "x": "In the future, we would like to perform grammar induction based on Equation (8), with gradient descent and posterior regularization techniques (Ganchev et al., 2010 A Comparison to Importance Sampling<cite> (Dyer et al., 2016)</cite> In this appendix we highlight the connections between importance sampling and variational inference, thereby comparing our method with<cite> Dyer et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_19",
  "x": "As shown in Rubinstein and Kroese (2008) , the optimal choice of the proposal distribution is in fact the true posterior p(a|x), in which case the importance weight p(a,x) p(a|x) = p(x) is constant with respect to a. In<cite> Dyer et al. (2016)</cite> , the proposal distribution depends on x, i.e., q(a) q(a|x), and is computed with a separately-trained, discriminative model.",
  "y": "background"
 },
 {
  "id": "25e03048cd34685cec34754bdade4e_20",
  "x": "As shown in Rubinstein and Kroese (2008) , the optimal choice of the proposal distribution is in fact the true posterior p(a|x), in which case the importance weight p(a,x) p(a|x) = p(x) is constant with respect to a. In<cite> Dyer et al. (2016)</cite> , the proposal distribution depends on x, i.e., q(a) q(a|x), and is computed with a separately-trained, discriminative model. This proposal choice is close to optimal, since in a fully supervised setting a is also observed and the discriminative model can be trained to approximate the true posterior well. We hypothesize that the performance of their importance sampler is dependent on this specific proposal distribution.",
  "y": "motivation"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_0",
  "x": "End-to-end neural machine translation (NMT) is a newly proposed paradigm for machine translation [Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014;<cite> Bahdanau et al., 2015]</cite> .",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_1",
  "x": "While early NMT models encode a source sentence as a fixed-length vector, <cite>Bahdanau et al. [2015]</cite> advocate the use of attention in NMT.",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_2",
  "x": "Such an attentional mechanism has proven to be an effective technique in text generation tasks such as machine translation<cite> [Bahdanau et al., 2015</cite>; Luong et al., 2015] and image caption generation [Xu et al., 2015] . The encoder-decoder framework [Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Sutskever et al., 2014;<cite> Bahdanau et al., 2015]</cite> usually uses a recurrent neural network (RNN) to encode the source sentence into a sequence of hidden states h = h 1 , . . . , h m , . . . , h M : where h m is the hidden state of the m-th source word and f is a non-linear function.",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_3",
  "x": "For example, <cite>Bahdanau et al. [2015]</cite> use a bidirectional RNN and concatenate the forward and backward states as the hidden state of a source word to capture both forward and backward contexts.",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_4",
  "x": "<cite>Bahdanau et al. [2015]</cite> define the conditional probability in Eq. (1) as where g is a non-linear function and s n is the hidden state corresponding to the n-th target word computed by",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_5",
  "x": "We follow <cite>Bahdanau et al. [2015]</cite> to restrict that sentences are no longer than 50 words.",
  "y": "uses"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_6",
  "x": "GroundHog is an attention-based neural machine translation system<cite> [Bahdanau et al., 2015]</cite> .",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_7",
  "x": "We compared our approach with two state-of-the-art SMT and NMT systems: [Koehn and Hoang, 2007] . GroundHog is an attention-based neural machine translation system<cite> [Bahdanau et al., 2015]</cite> . 1. Moses [Koehn and Hoang, 2007] : a phrase-based SMT system; 2. GroundHog<cite> [Bahdanau et al., 2015]</cite> : an attention-based NMT system.",
  "y": "uses"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_8",
  "x": "GroundHog is an attention-based neural machine translation system<cite> [Bahdanau et al., 2015]</cite> . Our approach simply extends GroundHog by replacing independent training with agreement-based joint training.",
  "y": "extends background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_9",
  "x": "<cite>Bahdanau et al. [2015]</cite> first introduce the attentional mechanism into neural machine translation to enable the decoder to focus on relevant parts of the source sentence during decoding.",
  "y": "background"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_10",
  "x": "After analyzing the alignment matrices generated by GroundHog<cite> [Bahdanau et al., 2015]</cite> , we find that modeling the structural divergence of natural languages is so challenging that unidirectional models can only capture part of alignment regularities. This finding inspires us to improve attention-based NMT by combining two unidirectional models.",
  "y": "motivation"
 },
 {
  "id": "260489da0fb3f7a201a6a1cce8f03b_11",
  "x": "After analyzing the alignment matrices generated by GroundHog<cite> [Bahdanau et al., 2015]</cite> , we find that modeling the structural divergence of natural languages is so challenging that unidirectional models can only capture part of alignment regularities.",
  "y": "motivation"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_0",
  "x": "The progress in both fields has inspired researchers to build holistic architectures for challenging grounding [14, 15] , natural language generation from image/video [16, 17, 18] , image-to-sentence alignment [19, 20, 21, 22] , and recently presented question-answering problems [23, 24, 25, 26, <cite>27]</cite> .",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_1",
  "x": "Third, if our aim is to mimic human response, we have to deal with inherent ambiguities due to human judgement that stem from issues like binding, reference frames, social conventions. For instance <cite>[27]</cite> reports that for a question answering task on real-world images even human answers are inconsistent.",
  "y": "motivation"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_2",
  "x": "We exemplify some of our findings on the <cite>DAQUAR dataset</cite> <cite>[27]</cite> with the aim of demonstrating different challenges that are present in <cite>the dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_3",
  "x": "The quality of an answer depends on how ambiguous and latent notions of reference frames and intentions are understood <cite>[27</cite>, 44] .",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_5",
  "x": "<cite>DAQUAR</cite> <cite>[27]</cite> is a challenging, large dataset for a question answering task based on real-world images.",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_6",
  "x": "<cite>DAQUAR's</cite> language scope is beyond the nouns or tuples that are typical to recognition datasets [51, 52, 53] .",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_7",
  "x": "In this section we discuss in isolation different challenges reflected in <cite>DAQUAR</cite>.",
  "y": "motivation"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_8",
  "x": "The machine world in <cite>DAQUAR</cite> is represented as a set of images and questions about their content.",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_9",
  "x": "<cite>DAQUAR</cite> contains 1088 different nouns in the question, 803 in the answers, and 1586 altogether (we use the Stanford POS Tagger [59] to extract the nouns from the questions).",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_10",
  "x": "<cite>DAQUAR</cite> also contains other parts of speech where only colors and spatial prepositions are grounded in <cite>[27]</cite> .",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_11",
  "x": "Moreover, ambiguities naturally emerge due to fine grained categories that exist in <cite>DAQUAR</cite>.",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_12",
  "x": "<cite>DAQUAR</cite> includes various challenges related to natural language understanding.",
  "y": "motivation"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_13",
  "x": "Common sense knowledge <cite>DAQUAR</cite> includes questions that can be reliably answered using common sense knowledge.",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_14",
  "x": "To sum up, we believe that common sense knowledge is an interesting venue to explore with <cite>DAQUAR</cite>.",
  "y": "motivation"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_15",
  "x": "Some authors [23, 24, <cite>27]</cite> treat the grounding (understood here as the logical representation of the meaning of the question) as a latent variable in the question answering task.",
  "y": "background"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_16",
  "x": "We exemplify the aforementioned requirements by illustrating the WUPS scorean automatic metric that quantifies performance of the holistic architectures proposed by <cite>[27]</cite> .",
  "y": "uses"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_17",
  "x": "The authors of <cite>[27]</cite> have proposed using WUP similarity [62] as the membership measure \u00b5 in the WUPS score. Such choice of \u00b5 suffers from the aforementioned coverage problem and the whole metric takes only one human interpretation of the question into account. Future directions for defining metrics Recent work provides several directions towards improving scores.",
  "y": "future_work"
 },
 {
  "id": "2606ecb66287c0199f3aa6d95f6774_18",
  "x": "We identify particular challenges that holistic tasks should exhibit and exemplify how they are manifested in <cite>a recent question answering challenge</cite> <cite>[27]</cite> . To judge competing architectures and measure the progress on the task, we suggest several directions to further improve existing metrics, and discuss different experimental scenarios.",
  "y": "future_work"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_0",
  "x": "<cite>Olabiyi et al. [7]</cite> tackle this problem by training a modified HRED generator alongside an adversarial discriminator in order to provide a stronger guarantee to the generator's output.",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_1",
  "x": "However, the HRED system suffers from lack of diversity and does not support any guarantees on the generator output since the output conditional probability is not calibrated. <cite>Olabiyi et al. [7]</cite> tackle this problem by training a modified HRED generator alongside an adversarial discriminator in order to provide a stronger guarantee to the generator's output.",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_2",
  "x": "However, the HRED system suffers from lack of diversity and does not support any guarantees on the generator output since the output conditional probability is not calibrated. <cite>Olabiyi et al. [7]</cite> tackle this problem by training a modified HRED generator alongside an adversarial discriminator in order to provide a stronger guarantee to the generator's output. While the hredGAN system improves upon response quality, it does not capture speaker and other attributes modalities within a dataset and fails to generate persona-specific responses in datasets with multiple modalities.",
  "y": "motivation background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_3",
  "x": "<cite>Olabiyi et al. [7]</cite> tackle this problem by training a modified HRED generator alongside an adversarial discriminator in order to provide a stronger guarantee to the generator's output. While the hredGAN system improves upon response quality, it does not capture speaker and other attributes modalities within a dataset and fails to generate persona-specific responses in datasets with multiple modalities. At the same time, there has been some recent work on introducing persona into dialogue models.",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_4",
  "x": "To overcome these limitations, we propose phredGAN , a multi-modal hredGAN dialogue system which additionally conditions the adversarial framework proposed by <cite>Olabiyi et al. [7]</cite> on speaker and/or utterance attributes in order to maintain response quality of hredGAN and still capture speaker and other modalities within a conversation.",
  "y": "extends uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_5",
  "x": "We train and sample the proposed phredGAN similar to the procedure for hredGAN <cite>[7]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_6",
  "x": "We train and sample the proposed phredGAN similar to the procedure for hredGAN <cite>[7]</cite> . We demonstrate system superiority over hredGAN and the state-of-the-art persona conversational model in terms",
  "y": "extends differences"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_7",
  "x": [
   "We demonstrate system superiority over hredGAN and the state-of-the-art persona conversational model in terms"
  ],
  "y": "differences"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_8",
  "x": [
   "The hredGAN proposed by Olabiyi et. al <cite>[7]</cite> contains three major components."
  ],
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_9",
  "x": "In the case of hredGAN <cite>[7]</cite> , it is a bidirectional RNN that discriminates at the word level to capture both the syntactic and semantic difference between the ground truth and the generator output.",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_10",
  "x": "Problem Formulation: The hredGAN <cite>[7]</cite> formulates multi-turn dialogue response generation as: given a dialogue history of sequence of utterances, where T i is the number of generated tokens. The framework uses a conditional GAN structure to learn a mapping from an observed dialogue history to a sequence of output tokens.",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_11",
  "x": "The generator, G, is trained to produce sequences that cannot be distinguished from the ground truth by an adversarially trained discriminator, D, akin to a two-player min-max optimization problem. The generator is also trained to minimize the cross-entropy loss L MLE (G) between the ground truth X i+1 , and the generator output Y i . The following objective summarizes both goals: where \u03bb G and \u03bb M are hyperparameters and L cGAN (G, D) and L MLE (G) are defined in Eqs. (5) and (7) of <cite>[7]</cite> respectively.",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_12",
  "x": [
   "The proposed architecture of phredGAN is very similar to that of hredGAN summarized above."
  ],
  "y": "similarities"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_13",
  "x": [
   "The proposed architecture of phredGAN is very similar to that of hredGAN summarized above. The only difference is that the dialogue history is now X i = (X 1 , C 1 ), (X 2 , C 2 ), \u00b7 \u00b7 \u00b7 , (X i , C i ) where C i is additional input that represents the speaker and/or utterance attributes."
  ],
  "y": "extends differences"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_14",
  "x": "Discriminator: In addition to the D RN N in the discriminator of hredGAN , if the attribute C i+1 is a sequence of tokens, then the same tattRN N is used to summarize the attribute token embeddings; otherwise the single attribute embedding is concatenated with the other inputs of D RN N in Fig. 1 of <cite>[7]</cite> .",
  "y": "background"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_15",
  "x": "The modified system is as follows: Discriminator: In addition to the D RN N in the discriminator of hredGAN , if the attribute C i+1 is a sequence of tokens, then the same tattRN N is used to summarize the attribute token embeddings; otherwise the single attribute embedding is concatenated with the other inputs of D RN N in Fig. 1 of <cite>[7]</cite> .",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_16",
  "x": "Noise Injection: Although <cite>[7]</cite> demonstrated that injecting noise at the word level seems to perform better than at the utterance level for hredGAN , we found that this is datasetdependent for phredGAN .",
  "y": "differences"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_17",
  "x": "The modified system is as follows: Noise Injection: Although <cite>[7]</cite> demonstrated that injecting noise at the word level seems to perform better than at the utterance level for hredGAN , we found that this is datasetdependent for phredGAN .",
  "y": "extends"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_18",
  "x": "We train both the generator and the discriminator (with a shared encoder) of phredGAN using the same training procedure in Algorithm 1 with \u03bb G = \u03bb M = 1 <cite>[7]</cite> .",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_19",
  "x": "The number of attributes, V c is dataset-dependent Compute the generator output similar to Eq. (11) in <cite>[7]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_20",
  "x": "The parameter update is conditioned on the discriminator accuracy performance as in <cite>[7]</cite> with acc D th = 0.99 and acc G th = 0.75.",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_21",
  "x": "For the modified noise sample, we perform a linear search for \u03b1 with sample size L = 1 based on the average discriminator loss, \u2212logD(G(.)) <cite>[7]</cite> using trained models run in autoregressive mode to reflect performance in actual deployment.",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_22",
  "x": "In this section, we explore phredGAN 's results on two conversational datasets and compare its performance to the persona system in Li et al. [8] and hredGAN <cite>[7]</cite> in terms of quantitative and qualitative measures.",
  "y": "similarities differences"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_23",
  "x": "We follow the same training, development, and test split as the UDC dataset in <cite>[7]</cite> , with 90%, 5%, and 5% proportions, respectively.",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_24",
  "x": "We use similar evaluation metrics as in <cite>[7]</cite> including perplexity, BLEU [15] , ROUGE [16] , and distinct n-gram [17] scores.",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_25",
  "x": "We also compare our system to hredGAN from <cite>[7]</cite> in terms of perplexity, ROGUE, and distinct n-grams scores.",
  "y": "similarities differences"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_26",
  "x": "In <cite>[7]</cite> , the authors recommend the version with word-level noise injection, hredGAN w , so we use this version in our comparison.",
  "y": "uses"
 },
 {
  "id": "264bdb348c13f167768fd859b047e8_27",
  "x": "Also for fair comparison, we use the same UDC dataset as reported in <cite>[7]</cite> .",
  "y": "uses"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_0",
  "x": "Though Baroni et al. (2014) suggested that predictive models which use neural networks to generate the distributed word representations (also known as embeddings in this context) outperform counting models which work on co-occurrence matrices, recent work shows evidence to the contrary (Levy et al., 2014;<cite> Salle et al., 2016)</cite> .",
  "y": "motivation"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_1",
  "x": "In this paper, we focus on improving a state-ofthe-art counting model, LexVec <cite>(Salle et al., 2016)</cite> , which performs factorization of the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling (WSNS).",
  "y": "uses"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_2",
  "x": "Though Baroni et al. (2014) suggested that predictive models which use neural networks to generate the distributed word representations (also known as embeddings in this context) outperform counting models which work on co-occurrence matrices, recent work shows evidence to the contrary (Levy et al., 2014;<cite> Salle et al., 2016)</cite> . In this paper, we focus on improving a state-ofthe-art counting model, LexVec <cite>(Salle et al., 2016)</cite> , which performs factorization of the positive pointwise mutual information (PPMI) matrix using window sampling and negative sampling (WSNS).",
  "y": "motivation"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_3",
  "x": "P n is the distribution used for drawing negative samples, chosen to be with \u03b1 = 3/4 (Mikolov et al., 2013b;<cite> Salle et al., 2016)</cite> , and #(w) the unigram frequency of w. Two methods were defined for the minimization of eqs. (2) and (3): Mini-batch and Stochastic <cite>(Salle et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_4",
  "x": "with \u03b1 = 3/4 (Mikolov et al., 2013b;<cite> Salle et al., 2016)</cite> , and #(w) the unigram frequency of w. Two methods were defined for the minimization of eqs. (2) and (3): Mini-batch and Stochastic <cite>(Salle et al., 2016)</cite> . Since the latter is more computationally efficient and yields equivalent results, we adopt it in this paper.",
  "y": "uses"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_5",
  "x": "As suggested by Levy et al. (2015) and<cite> Salle et al. (2016)</cite> , positional contexts (introduced in Levy et al. (2014) ) are a potential solution to poor performance on syntactic analogy tasks.",
  "y": "background motivation"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_6",
  "x": "We report results from<cite> Salle et al. (2016)</cite> and use the same training corpus and parameters to train LexVec with positional contexts and external memory.",
  "y": "uses"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_7",
  "x": "As recommended in Levy et al. (2015) and used in<cite> Salle et al. (2016)</cite> , the PPMI matrix used in all LexVec models and in PPMI-SVD is transformed using context distribution smoothing exponentiating context frequencies to the power 0.75.",
  "y": "uses"
 },
 {
  "id": "26b00c6e5b499eea30e9cef0bbaf9f_8",
  "x": "Therefore, we perform the exact same evaluation as<cite> Salle et al. (2016)</cite> , namely the WS-353 Similarity (WSim) and Relatedness (WRel) (Finkelstein et al., 2001) , MEN (Bruni et al., 2012) , MTurk (Radinsky et al., 2011) , RW (Luong et al., 2013) , SimLex-999 (Hill et al., 2015) , MC (Miller and Charles, 1991) , RG (Rubenstein and Goodenough, 1965) , and SCWS (Huang et al., 2012) word similarity tasks 1 , and the Google semantic (GSem) and syntactic (GSyn) analogy (Mikolov et al., 2013a) and MSR syntactic analogy dataset (Mikolov et al., 2013c) tasks.",
  "y": "uses"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_0",
  "x": "Several work have shown that discourse relations can improve the results of summarization in the case of factual texts or news articles (e.g.<cite> (Otterbacher et al., 2002)</cite> ).",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_1",
  "x": "In particular,<cite> (Otterbacher et al., 2002)</cite> experimentally showed that discourse relations can improve the coherence of multi-document summaries.",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_2",
  "x": "The comparison, contingency, and illustration relations are also considered by most of the work in the field of discourse analysis such as the PDTB: Penn Discourse TreeBank research group <cite>(Prasad et al., 2008)</cite> and the RST Discourse Treebank research group (Carlson and Marcu, 2001 ).",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_3",
  "x": "From our corpus analysis, we have identified the six most prevalent discourse relations in this blog dataset, namely comparison, contingency, illustration, attribution, topic-opinion, and attributive. The comparison, contingency, and illustration relations are also considered by most of the work in the field of discourse analysis such as the PDTB: Penn Discourse TreeBank research group <cite>(Prasad et al., 2008)</cite> and the RST Discourse Treebank research group (Carlson and Marcu, 2001 ).",
  "y": "similarities"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_4",
  "x": "The comparison, contingency, and illustration relations are also considered by most of the work in the field of discourse analysis such as the PDTB: Penn Discourse TreeBank research group <cite>(Prasad et al., 2008)</cite> and the RST Discourse Treebank research group (Carlson and Marcu, 2001 ). We considered three additional classes of relations: attributive, attribution, and topic-opinion.",
  "y": "extends differences"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_5",
  "x": "For example: \"Allied Capital is a closed-end management investment company that will operate as a business development concern.\" As shown in Figure 1 , illustration relations can be sub-divided into sub-categories: joint, list, disjoint, and elaboration relations according to the RST Discourse Treebank (Carlson and Marcu, 2001 ) and the Penn Discourse TreeBank <cite>(Prasad et al., 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_6",
  "x": "As shown in Figure 1 , the contingency relation subsumes several more specific relations: explanation, evidence, reason, cause, result, consequence, background, condition, hypothetical, enablement, and purpose relations according to the Penn Discourse TreeBank <cite>(Prasad et al., 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_7",
  "x": "The comparison relation subsumes the contrast relation according to the Penn Discourse TreeBank <cite>(Prasad et al., 2008)</cite> and the analogy and preference relations according to the RST Discourse Treebank (Carlson and Marcu, 2001) .",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_8",
  "x": "However, we have complemented this parser with three other approaches: (Jindal and Liu, 2006 )'s approach is used to identify intra-sentence comparison relations; we have designed a tagger based on (Fei et al., 2008) 's approach to identify topic-opinion relations; and we have proposed a new approach to tag attributive relations<cite> (Mithun, 2012)</cite> .",
  "y": "extends uses"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_9",
  "x": "A description and evaluation of these approaches can be found in<cite> (Mithun, 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_10",
  "x": "However, we have complemented this parser with three other approaches: (Jindal and Liu, 2006 )'s approach is used to identify intra-sentence comparison relations; we have designed a tagger based on (Fei et al., 2008) 's approach to identify topic-opinion relations; and we have proposed a new approach to tag attributive relations<cite> (Mithun, 2012)</cite> . A description and evaluation of these approaches can be found in<cite> (Mithun, 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_11",
  "x": "To measure the usefulness of discourse relations for the summarization of informal texts, we have tested the effect of each relation with four different summarizers: BlogSum<cite> (Mithun, 2012)</cite> , MEAD<cite> (Radev et al., 2004)</cite> , the best scoring system at TAC 2008 5 and the best scoring system at DUC 2007 6 .",
  "y": "uses"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_12",
  "x": "To measure the usefulness of discourse relations for the summarization of informal texts, we have tested the effect of each relation with four different summarizers: BlogSum<cite> (Mithun, 2012)</cite> , MEAD<cite> (Radev et al., 2004)</cite> , the best scoring system at TAC 2008 5 and the best scoring system at DUC 2007 6 . Finally the most appropriate schema is selected based on a given question type; and candidate sentences fill particular slots in the selected schema based on which discourse relations they contain in order to create the final summary (details of BlogSum can be found in<cite> (Mithun, 2012)</cite> ).",
  "y": "uses background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_13",
  "x": "Finally the most appropriate schema is selected based on a given question type; and candidate sentences fill particular slots in the selected schema based on which discourse relations they contain in order to create the final summary (details of BlogSum can be found in<cite> (Mithun, 2012)</cite> ).",
  "y": "background"
 },
 {
  "id": "26fbf9f4ae740513d8889160ad9f63_14",
  "x": "To ensure that the results were not specific to our summarizer, we performed the same experiments with two other systems: the MEAD summarizer<cite> (Radev et al., 2004)</cite> , a publicly available and a widely used summarizer, and with the output of the TAC best-scoring system.",
  "y": "uses"
 },
 {
  "id": "27dbdd4827554df0f53013966242dc_0",
  "x": "Our work is based on the SummaRuNNer model <cite>[5]</cite> . It consists of a two-layer bi-directional Gated Recurrent Unit (GRU) Recurrent Neural Network (RNN) which treats the summarization problem as a binary sequence classification problem, where each sentence is classified sequentially as sentence to be included or not in the summary. However, we introduced two modifications to the original SummaRuNNer architecture, leading to better results while reducing complexity: arXiv:1911.06121v1 [cs.CL] 13 Nov 2019 Fig. 1 .",
  "y": "extends"
 },
 {
  "id": "27dbdd4827554df0f53013966242dc_2",
  "x": "In contrast to <cite>[5]</cite> , we trained our model only on CNN articles from the CNN/Daily Mail corpus [2] .",
  "y": "differences"
 },
 {
  "id": "27dbdd4827554df0f53013966242dc_3",
  "x": "In a similar approach to <cite>[5]</cite> , we calculated the ROUGE-1 F1 score between each sentence and its article's abstractive summary.",
  "y": "similarities"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_0",
  "x": "A review of the methods in the article <cite>[35]</cite> about the recognition of timexes for English and Spanish has shown a certain shift within the most popular solutions.",
  "y": "uses"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_1",
  "x": "The best systems listed in <cite>[35]</cite> , called TIPSem [16] and ClearTK [1] , use CRFs for recognition, so initially, we decided to apply the CRF-based approach for this task.",
  "y": "uses"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_2",
  "x": "Experiments were carried out by the method proposed in <cite>[35]</cite> .",
  "y": "uses"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_3",
  "x": "Then we evaluated these results using more detailed measures for timexes, presented in <cite>[35]</cite> .",
  "y": "uses"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_5",
  "x": "If there was an overlap, a relaxed type F1-score (Type.F1) was calculated <cite>[35]</cite> .",
  "y": "uses"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_6",
  "x": "Then we evaluated these results using more detailed measures for timexes, presented in <cite>[35]</cite> . F1) evaluation has also been carried out to determine whether there is an overlap between the system entity and gold entity, e.g. [Sunday] and [Sunday morning] <cite>[35]</cite> .",
  "y": "uses"
 },
 {
  "id": "27ee0fbed3a88854ebe945dfffefd8_7",
  "x": "Table 9 : Evaluation results for all TIMEX3 classes (total) for 9 word embeddings models (3 best models from each embeddings group: EE, EP, EC from Table 8 ) using the following measures from <cite>[35]</cite> : strict precision, strict recall, strict F1-score, relaxed precision, relaxed recall, relaxed F1-score, type F1-score.",
  "y": "uses"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_0",
  "x": "The task of definition modeling, introduced by <cite>Noraset et al. (2017)</cite> , consists in generating the dictionary definition of a specific word: for instance, given the word \"monotreme\" as input, the system would need to produce a definition such as \"any of an order (Monotremata) of egg-laying mammals comprising the platypuses and echidnas\".",
  "y": "background"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_1",
  "x": "A major intended application of definition modeling is the explication and evaluation of distributed lexical representations, also known as word embeddings<cite> (Noraset et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_2",
  "x": "In their seminal work on definition modeling, <cite>Noraset et al. (2017)</cite> likened systems generating definitions to language models, which can naturally be used to generate arbitrary text.",
  "y": "background"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_3",
  "x": "This reformulation can appear contrary to the original proposal by <cite>Noraset et al. (2017)</cite> , which conceived definition modeling as a \"word-tosequence task\".",
  "y": "background"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_4",
  "x": "Though different kinds of linguistic contexts have been suggested throughout the literature, we remark here that sentential context may sometimes suffice to guess the meaning of a word that we don't know (Lazaridou et al., 2017) . Quoting from the example above, the context \"enough around-let's get back to work!\" sufficiently characterizes the meaning of the omitted verb to allow for an approximate definition for it even if the blank is not filled (Taylor, 1953; Devlin et al., 2018) . This reformulation can appear contrary to the original proposal by <cite>Noraset et al. (2017)</cite> , which conceived definition modeling as a \"word-tosequence task\".",
  "y": "differences"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_5",
  "x": "Despite some key differences, all of the previously proposed architectures we are aware of<cite> (Noraset et al., 2017</cite>; Gadetsky et al., 2018; followed a pattern similar to sequence-to-sequence models.",
  "y": "similarities"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_6",
  "x": "In the case of <cite>Noraset et al. (2017)</cite> , the encoding was the concatenation of the embedding of the definiendum, a vector representation of its sequence of characters derived from a characterlevel CNN, and its \"hypernym embedding\".",
  "y": "background"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_7",
  "x": "Should we mark the definiendum before encoding, then only the definiendum embedding is passed into the encoder: the resulting system provides out-of-context definitions, like in <cite>Noraset et al. (2017)</cite> where the definition is not linked to the context of a word but to its definiendum only.",
  "y": "similarities"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_8",
  "x": "4 The dropout rate and warmup steps number were set using a hyperparameter search on the dataset from <cite>Noraset et al. (2017)</cite> , during which encoder and decoder vocabulary were merged for computational simplicity and models stopped after 12,000 steps.",
  "y": "uses"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_9",
  "x": "The dataset of <cite>Noraset et al. (2017)</cite> (henceforth D Nor ) maps definienda to their respective definientia, as well as additional information not used here.",
  "y": "differences"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_10",
  "x": "We train our models on three distinct datasets, which are all borrowed or adapted from previous works on definition modeling. The dataset of <cite>Noraset et al. (2017)</cite> (henceforth D Nor ) maps definienda to their respective definientia, as well as additional information not used here.",
  "y": "uses"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_11",
  "x": "Perplexity measures for <cite>Noraset et al. (2017)</cite> and Gadetsky et al. (2018) are taken from the authors' respective publications.",
  "y": "background"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_12",
  "x": "Perplexity measures for <cite>Noraset et al. (2017)</cite> and Gadetsky et al. (2018) are taken from the authors' respective publications. All our models perform better than previous proposals, by a margin of 4 to 10 points, for a relative improvement of 11-23%.",
  "y": "differences"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_13",
  "x": "A manual analysis of definitions produced by our system reveals issues similar to those discussed by <cite>Noraset et al. (2017)</cite> , namely selfreference, 7 POS-mismatches, over-and underspecificity, antonymy, and incoherence.",
  "y": "similarities"
 },
 {
  "id": "28038a4fa4182ccdc6134f2138c0da_14",
  "x": "As for POS-mismatches, we do note that the work of <cite>Noraset et al. (2017)</cite> had a much lower rate of 4.29%: we suggest that this may be due to the fact that they employ a learned character-level convolutional network, which arguably would be able to capture orthography and rudiments of morphology.",
  "y": "differences"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_0",
  "x": "This paper proposes an expansion of set of primitive constraints available within the Primitive Optimality Theory framework <cite>(Eisner, 1997a)</cite> .",
  "y": "uses"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_1",
  "x": "This paper proposes an expansion of set of primitive constraints available within the Primitive Optimality Theory framework <cite>(Eisner, 1997a)</cite> . This expansion consists of the addition of a new family of constraints--existential implicational constraints, which allow the specification of faithfulness constraints that can be satisfied at a distance--and the definition of two ways to combine simple constraints into com: plex constraints, that is, constraint disjunction (Crowhurst and Hewitt, 1995) and local constraint conjunction (Smolensky, 1995) .",
  "y": "extends"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_2",
  "x": "Primitive Optimality Theory (OTP) <cite>(Eisner, 1997a)</cite> , and extensions to it (e.g., Albro (1998) ), can be useful as a formal system in which phonological analyses can be implemented and evaluated.",
  "y": "background"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_3",
  "x": "Primitive Optimality Theory (OTP) <cite>(Eisner, 1997a)</cite> , and extensions to it (e.g., Albro (1998) ), can be useful as a formal system in which phonological analyses can be implemented and evaluated. However, for certain types of constraints, translation into the primitives of OTP (Eisner (1997b) ) can only be accomplished by adding to the grammar a number of ad hoc phonological tiers.",
  "y": "motivation"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_4",
  "x": "This paper looks at three types of constraints employed throughout the Optimality Theoretic literature that cannot be translated in to the 1The computation time for an Optimality Theoretic derivation within the implementation of Albro (1998) increases exponentially with the number of tiers. The same is true for the implementation described in<cite> Eisner (1997a)</cite> , although a proposal is given there for a method that might improve the situation.",
  "y": "uses motivation"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_5",
  "x": "primitives of OTP without reference to ad hoc tiers, and proposes a formalization of these constraints that is compatible with the finite state model described in<cite> Eisner (1997a)</cite> and Albro (1998) .",
  "y": "background"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_6",
  "x": "2 Existential Implication 2.1 Motivation OWP as described in<cite> Eisner (1997a)</cite> provides some support for correspondence constraints (input-output only).",
  "y": "background"
 },
 {
  "id": "291a6ac3f0c2d27ca69ee8f5f266f5_7",
  "x": "Using the FST notation of<cite> Eisner (1997a)</cite> , the implementation for this constraint would be the following FST:",
  "y": "uses"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_0",
  "x": "<cite>Leuski et al. (2006)</cite> developed algorithms for training such characters using linked questions and responses in the form of unstructured natural language text.",
  "y": "background"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_1",
  "x": "These algorithms have been incorporated into a tool which has been used to create characters for a variety of applications (e.g.<cite> Leuski et al., 2006</cite>; Artstein et al., 2009; Swartout et al., 2010) .",
  "y": "background"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_2",
  "x": "We reimplemented parts of the response ranking algorithms of <cite>Leuski et al. (2006)</cite> , including both the language modeling (LM) and cross-language modeling (CLM) approaches.",
  "y": "extends differences"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_3",
  "x": "We did not implement the parameter learning of <cite>Leuski et al. (2006)</cite> ; instead we use a constant smoothing parameter \u03bb \u03c0 = \u03bb \u03c6 = 0.1.",
  "y": "differences"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_4",
  "x": "We also do not use the response threshold parameter, which <cite>Leuski et al. (2006)</cite> use to determine whether the top-ranked response is good enough.",
  "y": "differences"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_5",
  "x": "This measure does not take into account non-understanding, that is the classifier's determination that the best response is not good enough<cite> (Leuski et al., 2006)</cite> , since this capability was not implemented; however, since all of our test questions are known to have at least one appropriate response, any non-understanding of a question would necessarily count against accuracy anyway.",
  "y": "differences background"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_6",
  "x": "The LM approach almost invariably produced better results than the CLM approach; this is the opposite of the findings of <cite>Leuski et al. (2006)</cite> , where CLM fared consistently better.",
  "y": "differences"
 },
 {
  "id": "29294f2ed3cc2772ca57fd4294274c_7",
  "x": "In our experiments the LM approach consistently outperforms the CLM approach, contra <cite>Leuski et al. (2006)</cite> .",
  "y": "differences"
 },
 {
  "id": "2a01f96893f9c0630a01ecce320184_0",
  "x": "Several research works have been proposed to detect propaganda on document-level (Rashkin et al., 2017; Barr\u00f3n-Cede\u00f1o et al., 2019b) , sentencelevel and fragment-level <cite>(Da San Martino et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "2a01f96893f9c0630a01ecce320184_1",
  "x": "Although Da San<cite> Martino et al. (2019)</cite> indicates that multi-task learning of both the SLC and the FLC could be beneficial for the SLC, in this paper, we only focus on the SLC task so as to better investigate whether context information could improve the performance of our system.",
  "y": "differences"
 },
 {
  "id": "2a01f96893f9c0630a01ecce320184_2",
  "x": "A fine-grained propaganda corpus was proposed in Da San<cite> Martino et al. (2019)</cite> which includes both sentencelevel and fragment-level information.",
  "y": "background"
 },
 {
  "id": "2a01f96893f9c0630a01ecce320184_3",
  "x": "More details of the dataset could be found in Da San<cite> Martino et al. (2019)</cite> .",
  "y": "background"
 },
 {
  "id": "2a01f96893f9c0630a01ecce320184_4",
  "x": "As described in Da San<cite> Martino et al. (2019)</cite> , the source of the dataset that we use is news articles, and since the title is usually the summarization of a news article, we use the title as supplementary information.",
  "y": "uses background"
 },
 {
  "id": "2a01f96893f9c0630a01ecce320184_5",
  "x": "In the future, we plan to apply multi-task learning to this context-dependent BERT, similar to the method mentioned in Da San<cite> Martino et al. (2019)</cite> or introducing other kinds of tasks, such as sentiment analysis or domain classification.",
  "y": "similarities future_work"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_0",
  "x": "In our previous work <cite>[7]</cite> , we applied a dual RNN in order to obtain a richer representation by blending the content and acoustic knowledge.",
  "y": "background"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_1",
  "x": "In our previous work <cite>[7]</cite> , we applied a dual RNN in order to obtain a richer representation by blending the content and acoustic knowledge. In this paper, we improve upon our earlier work by incorporating an attention mechanism in the emotion recognition framework.",
  "y": "extends"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_2",
  "x": "Recently,<cite> [7,</cite> 18] combined acoustic information and conversation transcripts using a neural network-based model to improve emotion classification accuracy.",
  "y": "background"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_3",
  "x": "Recently,<cite> [7,</cite> 18] combined acoustic information and conversation transcripts using a neural network-based model to improve emotion classification accuracy. However, none of these studies utilized attention method over audio and text modality in tandem for contextual understanding of the emotion in audio recording.",
  "y": "background motivation"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_4",
  "x": "Motivated by the architecture used in<cite> [7,</cite> 17, 19] , we train a recurrent encoder to predict the categorical class of a given audio signal.",
  "y": "motivation"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_5",
  "x": "To follow previous research <cite>[7]</cite> , we also add another prosodic feature vector, p, with each ot to generate a more informative vector representation of the signal, o A t .",
  "y": "uses"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_6",
  "x": "Previous research used multi-modal information independently using neural network model by concatenating features from each modality<cite> [7,</cite> 21] .",
  "y": "background"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_7",
  "x": "Previous research used multi-modal information independently using neural network model by concatenating features from each modality<cite> [7,</cite> 21] . As opposed to this approach, we propose a neural network architecture that exploits information in each modality by extracting relevant segments of the speech data using information from the lexical content (and vice-versa).",
  "y": "differences"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_8",
  "x": "For consistent comparison with previous works<cite> [7,</cite> 18] , all utterances labeled \"excitement\" are merged with those labeled \"happiness\".",
  "y": "uses"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_9",
  "x": "As this research is extended work from previous research <cite>[7]</cite> , we use the same feature extraction method as done in our previous work.",
  "y": "extends"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_10",
  "x": "We use the same dataset and features as other researchers<cite> [7,</cite> 18] .",
  "y": "uses"
 },
 {
  "id": "2a84615479af66bbf875517a3a753b_11",
  "x": "In audio-BRE (Fig. 2(a) ), most of the emotion labels are frequently misclassified as neutral class, supporting the claims of<cite> [7,</cite> 25] .",
  "y": "similarities"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_0",
  "x": "In order to compare the performance of our system with others, we also used the dataset of<cite> Tu and Roth (2012)</cite> , which contains 1,348 sentences taken from different parts of the British National Corpus.",
  "y": "uses"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_1",
  "x": "One example is<cite> Tu and Roth (2012)</cite> , where the authors examined a verbparticle combination only if the verbal components were formed with one of the previously given six verbs (i.e. make, take, have, give, do, get).",
  "y": "background"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_2",
  "x": "As Table 3 shows, the six verbs used by<cite> Tu and Roth (2012)</cite> are responsible for only 50 VPCs on the Wiki50 corpus, so it covers only 11.16% of all gold standard VPCs.",
  "y": "background"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_3",
  "x": "Furthermore, 127 different verbal component occurred in Wiki50, but the verbs have and do -which are used by<cite> Tu and Roth (2012)</cite> -do not appear in the corpus as verbal component of VPCs.",
  "y": "background"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_4",
  "x": "Moreover, Support Vector Machines (SVM) (Cortes and Vapnik, 1995) results are also reported to compare the performance of our methods with that of<cite> Tu and Roth (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_5",
  "x": "As<cite> Tu and Roth (2012)</cite> presented only the accuracy scores on the Tu & Roth dataset, we also employed an accuracy score as an evaluation metric on this dataset, where positive and negative examples were also marked.",
  "y": "similarities"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_6",
  "x": "We also compared our results with the rule-based results available for Wiki50 and also with the 5-fold cross validation results of<cite> Tu and Roth (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_7",
  "x": "In order to compare the performance of our system with others, we evaluated it on the Tu&Roth dataset <cite>(Tu and Roth, 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_8",
  "x": "over, it also lists the results of<cite> Tu and Roth (2012)</cite> and the VPCTagger evaluated in the 5-fold cross validation manner, as<cite> Tu and Roth (2012)</cite> applied this evaluation schema.",
  "y": "uses"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_9",
  "x": "Moreover, the results obtained with our machine learning approach on the Tu&Roth dataset outperformed those reported in<cite> Tu and Roth (2012)</cite> .",
  "y": "differences"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_10",
  "x": "A striking difference between the Tu & Roth database and Wiki50 is that while<cite> Tu and Roth (2012)</cite> included the verbs do and have in their data, they do not occur at all among the VPCs collected from Wiki50.",
  "y": "background"
 },
 {
  "id": "2b10893f03b4f5eaac0fe06b4d6115_11",
  "x": "Our method yielded better results than those got using the dependency parsers on the Wiki50 corpus and the method reported in <cite>(Tu and Roth, 2012)</cite> on the Tu&Roth dataset.",
  "y": "differences"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_0",
  "x": "In this paper, we consider the referential games of <cite>Lazaridou et al. (2017)</cite> , and investigate the representations the agents develop during their evolving interaction.",
  "y": "motivation"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_1",
  "x": "Unlike earlier work (e.g., Briscoe, 2002; Cangelosi and Parisi, 2002; Steels, 2012) , many recent simulations consider realistic visual input, for example, by playing referential games with real-life pictures (e.g., Jorge et al., 2016; <cite>Lazaridou et al., 2017</cite>; Havrylov and Titov, 2017; Lee et al., 2018; Evtimova et al., 2018) . This setup allows us to address the exciting issue of whether the needs of goal-directed communication will lead agents to associate visually-grounded conceptual representations to discrete symbols, developing naturallanguage-like word meanings.",
  "y": "motivation background"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_2",
  "x": "We study here agent representations following the model and setup of <cite>Lazaridou et al. (2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_3",
  "x": "In their first game, <cite>Lazaridou</cite>'s Sender and Receiver are exposed to the same pair of images, one of them being randomly marked as the \"target\".",
  "y": "background"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_4",
  "x": "Since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts (such as beaver or bayonet), <cite>Lazaridou and colleagues</cite> next modify the game, by presenting to the Sender and the Receiver different images for each of the two concepts (e.g., the Sender must now signal that the target is a beaver, while seeing a different beaver from the one shown to the Receiver).",
  "y": "background"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_5",
  "x": "<cite>Lazaridou and colleagues</cite> present preliminary evidence suggesting that, indeed, agents are now developing conceptual symbol meanings.",
  "y": "background"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_6",
  "x": "We replicate <cite>Lazaridou</cite>'s games, and we find that, in both, the agents develop successfully aligned representations that, however, are not capturing conceptual properties at all.",
  "y": "uses motivation"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_7",
  "x": "Architecture We re-implement <cite>Lazaridou</cite>'s Sender and Receiver architectures (using their better-behaved \"informed\" Sender).",
  "y": "uses"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_8",
  "x": "See <cite>Lazaridou et al. (2017</cite>) for details.",
  "y": "background"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_9",
  "x": "Data Following <cite>Lazaridou et al. (2017)</cite> , for each of the 463 concepts <cite>they</cite> used, we randomly sample 100 images from ImageNet (Deng et al., 2009 ).",
  "y": "uses similarities"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_10",
  "x": "Following <cite>Lazaridou</cite>, the images are passed through a pre-trained VGG ConvNet (Simonyan and Zisserman, 2015) .",
  "y": "similarities uses"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_11",
  "x": "Games We re-implement both <cite>Lazaridou</cite>'s same-image game, where Sender and Receiver are shown the same two images (always of different concepts), and their different-image game, where the Receiver sees different images than the Sender's.",
  "y": "uses"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_12",
  "x": "As we faithfully reproduced the setup of <cite>Lazaridou et al. (2017)</cite> , we refer the reader there for hyper-parameters and training details.",
  "y": "similarities background"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_13",
  "x": "<cite>Lazaridou et al. (2017)</cite> designed <cite>their</cite> second game to encourage more general, concept-like referents. Unfortunately, we replicate the anomalies above in the different-image setup, although to a less marked extent.",
  "y": "background similarities"
 },
 {
  "id": "2b148e376c39eae7f674610118e588_14",
  "x": "However, the important contribution of <cite>Lazaridou et al. (2017)</cite> is to play a signaling game with real-life images instead of artificial symbols. This raises new empirical questions that are not answered by the general mathematical results, such as: When the agents do succeed at communicating, what are the input features they rely upon?",
  "y": "motivation"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_0",
  "x": "In this work, we use the datasets released by <cite>(Davidson et al. 2017 )</cite> and HEOT dataset provided by (Mathur et al. 2018) .",
  "y": "uses"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_1",
  "x": "The embeddings were trained on both the datasets provided by <cite>(Davidson et al. 2017 )</cite> and HEOT.",
  "y": "uses"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_2",
  "x": "As indicated by the Figure 1 , the model was initially trained on the dataset provided by <cite>(Davidson et al. 2017)</cite> , and then re-trained on the HEOT dataset so as to benefit from the transfer of learned features in the last stage.",
  "y": "uses"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_3",
  "x": "For comparison purposes, in Table 4 we have also evaluated our results on the dataset by <cite>(Davidson et al. 2017 )</cite>.",
  "y": "uses"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_4",
  "x": "Both the HEOT and <cite>(Davidson et al. 2017 )</cite> datasets contain tweets which are annotated in three categories: offensive, abusive and none (or benign).",
  "y": "background"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_5",
  "x": "Both the HEOT and <cite>(Davidson et al. 2017 )</cite> datasets contain tweets which are annotated in three categories: offensive, abusive and none (or benign). We use a LSTM based classifier model for training our model to classify these tweets into these three categories.",
  "y": "uses"
 },
 {
  "id": "2b6dd9388c43df4416c738b2d1ed5f_6",
  "x": "Results Table 3 shows the performance of our model (after getting trained on <cite>(Davidson et al. 2017)</cite> ) with two types of embeddings in comparison to the models by (Mathur et al. 2018) and <cite>(Davidson et al. 2017 )</cite> on the HEOT dataset averaged over three runs.",
  "y": "uses similarities differences"
 },
 {
  "id": "2b7267b7b192aeca15c0d10a5f0a4b_0",
  "x": "An important work that has relevance here is <cite>[8]</cite> where authors present an even larger movie review dataset of 50,000 movie reviews from IMBD.",
  "y": "background"
 },
 {
  "id": "2b7267b7b192aeca15c0d10a5f0a4b_1",
  "x": "In <cite>[8]</cite> for example, authors who created movie review dataset try on it their probabilistic model that is able to capture semantic similarities between words.",
  "y": "background"
 },
 {
  "id": "2b7267b7b192aeca15c0d10a5f0a4b_2",
  "x": "Our scores on this task are somehow lower than those reported from various studies that explore advanced deep learning constructs on same dataset. In <cite>[8]</cite> for example, authors who created movie review dataset try on it their probabilistic model that is able to capture semantic similarities between words.",
  "y": "differences"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_0",
  "x": "Traditional relation-extraction systems rely on manual annotations or domain-specific rules provided by experts, both of which are scarce resources that are not portable across domains. To remedy these problems, recent years have seen interest in the distant supervision approach for relation extraction (Wu and Weld, 2007; <cite>Mintz et al., 2009)</cite> .",
  "y": "motivation"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_1",
  "x": "While the largest corpus (Wikipedia and New York Times) employed by recent work on distant supervision<cite> (Mintz et al., 2009</cite>; Hoffmann et al., 2011) contain about 2M documents, we run experiments on a 100M-document (50X more) corpus drawn from ClueWeb.",
  "y": "background"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_2",
  "x": "Since<cite> Mintz et al. (2009)</cite> coined the name \"distant supervision,\" there has been growing interest in this technique.",
  "y": "background"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_3",
  "x": "At each step of the distant supervision process, we closely follow the recent literature<cite> (Mintz et al., 2009</cite>; .",
  "y": "similarities"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_4",
  "x": "Following recent work<cite> (Mintz et al., 2009</cite>; Hoffmann et al., 2011) , we use Freebase 5 as the knowledge base for seed facts.",
  "y": "similarities uses"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_5",
  "x": "As in previous work, we impose the constraint that both mentions (m 1 , m 2 ) \u2208 R + i are contained in the same sentence<cite> (Mintz et al., 2009</cite>; Hoffmann et al., 2011) .",
  "y": "similarities uses"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_6",
  "x": "To generate negative examples for each relation, we follow the assumption in<cite> Mintz et al. (2009)</cite> that relations are disjoint and sample from other relations, i.e., R",
  "y": "similarities uses"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_7",
  "x": "Following recent work on distant supervision<cite> (Mintz et al., 2009</cite>; Hoffmann et al., 2011) , we use both lexical and syntactic features.",
  "y": "similarities uses"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_8",
  "x": "Interestingly, the Freebase held-out metric<cite> (Mintz et al., 2009</cite>; Hoffmann et al., 2011 ) turns out to be heavily biased toward distantly labeled data (e.g., increasing human feedback hurts precision; see Section 4.6).",
  "y": "differences"
 },
 {
  "id": "2bb41cea97a0375f67eab3a77c3a97_9",
  "x": "In addition to the TAC-KBP benchmark, we also follow prior work<cite> (Mintz et al., 2009</cite>; Hoffmann et al., 2011) and measure the quality using held-out data from Freebase.",
  "y": "differences"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_0",
  "x": "The most frequently applied technique in the CoNLL-2003 shared task is the Maximum Entropy Model. Three systems used Maximum Entropy Models in isolation (Bender et al., 2003; Chieu and Ng, 2003; Curran and Clark, 2003) . Two more systems used them in combination with other techniques<cite> (Florian et al., 2003</cite>; Klein et al., 2003) .",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_1",
  "x": "Hidden Markov Models were employed by four of the systems that took part in the shared task<cite> (Florian et al., 2003</cite>; Klein et al., 2003; Mayfield et al., 2003; Whitelaw and Patrick, 2003) .",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_2",
  "x": "Zhang and Johnson (2003) used robust risk minimization, which is a Winnow technique. <cite>Florian et al. (2003)</cite> employed the same technique in a combination of learners.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_3",
  "x": "Transformation-based learning<cite> (Florian et al., 2003)</cite> , Support Vector Machines (Mayfield et al., 2003) and Conditional Random Fields (McCallum and Li, 2003) were applied by one system each.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_4",
  "x": "<cite>Florian et al. (2003)</cite> tested different methods for combining the results of four systems and found that robust risk minimization worked best.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_5",
  "x": "One participating team has used externally trained named entity recognition systems for English as a part in a combined system<cite> (Florian et al., 2003)</cite> . with extra information compared to while using only the available training data.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_6",
  "x": "The inclusion of extra named entity recognition systems seems to have worked well<cite> (Florian et al., 2003)</cite> .",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_7",
  "x": "For English, the combined classifier of <cite>Florian et al. (2003)</cite> achieved the highest overall F \u03b2=1 rate.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_8",
  "x": "<cite>Florian et al. (2003)</cite> have also obtained the highest F \u03b2=1 rate for the German data.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_9",
  "x": "A majority vote of five systems (Chieu and Ng, 2003;<cite> Florian et al., 2003</cite>; Klein et al., 2003; McCallum and Li, 2003; Whitelaw and Patrick, 2003) performed best on the English development data.",
  "y": "background"
 },
 {
  "id": "2c3a2999390b82f4e29b00d59f90f2_10",
  "x": "The best performance for both languages has been obtained by a combined learning system that used Maximum Entropy Models, transformation-based learning, Hidden Markov Models as well as robust risk minimization<cite> (Florian et al., 2003)</cite> .",
  "y": "background"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_0",
  "x": "Only few approaches have attempted comprehension on multiparty dialogue <cite>Ma, Jurczyk, and Choi [2018]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_1",
  "x": "Inspired by various options of analytic models and the potential of the dialogue processing market, we extend the corpus presented by <cite>Ma, Jurczyk, and Choi [2018]</cite> for comprehensive predictions of personal entities in multiparty dialogue and develop deep learning models to make robust inference on their contexts.",
  "y": "uses"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_2",
  "x": "Distinguished from the previous work that only focused on a single variable per passage <cite>Ma, Jurczyk, and Choi [2018]</cite> , we propose two new passage completion tasks on multiparty dialogue which increase the task complexity by replacing more character mentions with variables with a better motivated data split.",
  "y": "extends"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_3",
  "x": "Unlike the above tasks where documents and queries are written in a similar writing style, the multiparty dialogue reading comprehension task introduced by <cite>Ma, Jurczyk, and Choi [2018]</cite> has a very different writing style between dialogues and queries.",
  "y": "background"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_4",
  "x": "Plot summaries of all episodes for the first eight seasons were collected by Jurczyk and Choi [2017] to evaluate a document retrieval task. The rest of the plot summaries were collected by <cite>Ma, Jurczyk, and Choi [2018]</cite> .",
  "y": "background"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_5",
  "x": "Table 1 shows the statistical data of the corpus from <cite>Ma, Jurczyk, and Choi [2018]</cite> . Based on the above corpus we created a new data split different from <cite>Ma, Jurczyk, and Choi [2018]</cite> 's data split.",
  "y": "uses"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_6",
  "x": "In the previous work of <cite>Ma, Jurczyk, and Choi [2018]</cite> , they used a random data split where 1,187 of 1,349 queries in the development set and 1,207 of 1,353 queries in the test set are generated from the same plot summaries as some queries in the training set with only masking the different character entities which makes the model can see the right answer in the training set.",
  "y": "motivation"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_7",
  "x": "We propose three tasks, one is from <cite>Ma, Jurczyk, and Choi [2018]</cite> , and another two tasks are new tasks designed by us.",
  "y": "uses"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_8",
  "x": "We propose three tasks, one is from <cite>Ma, Jurczyk, and Choi [2018]</cite> , and another two tasks are new tasks designed by us. The single variable task from <cite>Ma, Jurczyk, and Choi [2018]</cite> consists a dialogue passage p, a query q which is from plot summary of the dialogue passage and an answer a. In this 1 https://github.com/emorynlp/character-mining task, a query q replaces only one character entity with an unknown variable x and the machine is asked to infer the replaced character entity (answer a) from all the possible entities appear in the dialogue passage p. This task is evaluated by computing the accuracy of predictions (see Section ).",
  "y": "uses"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_9",
  "x": "The single variable task from <cite>Ma, Jurczyk, and Choi [2018]</cite> consists a dialogue passage p, a query q which is from plot summary of the dialogue passage and an answer a. In this 1 https://github.com/emorynlp/character-mining task, a query q replaces only one character entity with an unknown variable x and the machine is asked to infer the replaced character entity (answer a) from all the possible entities appear in the dialogue passage p. This task is evaluated by computing the accuracy of predictions (see Section ).",
  "y": "background"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_10",
  "x": "Based on <cite>Ma, Jurczyk, and Choi [2018]</cite> , we first use CNN to extract the gram-level features of utterances and then use @ent04 asks @ent00 how someone could get a hold of @ent00 's credit card number and @ent00 is surprised at how much was spent .",
  "y": "uses"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_11",
  "x": "This method is the SOTA method last year in <cite>Ma, Jurczyk, and Choi [2018]</cite> 's data split which is also selected as one of our experimental methods.",
  "y": "uses"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_12",
  "x": "Adding a CNN can achieve even lower accuracy because passing sequences to the CNN only keeps important information after the pooling operation, but for dialogue data, most of the time the replaced entity needs to be decided by <cite>Ma, Jurczyk, and Choi [2018]</cite> are not helpful for these tasks on our data split because dialogues contain so many informal expressions and the size of the corpus is small.",
  "y": "motivation"
 },
 {
  "id": "2cedb1a0f0c0fbb9bd95d5b54e4967_13",
  "x": "Results Table 4 shows the results of our experiment. BiL-STM is good at capturing the sequence information of sentences; however, since it only finds some kind of answer distributions on the sequence information, it cannot capture the information of the relation between query and utterance. Adding a CNN can achieve even lower accuracy because passing sequences to the CNN only keeps important information after the pooling operation, but for dialogue data, most of the time the replaced entity needs to be decided by <cite>Ma, Jurczyk, and Choi [2018]</cite> are not helpful for these tasks on our data split because dialogues contain so many informal expressions and the size of the corpus is small.",
  "y": "uses differences"
 },
 {
  "id": "2d2da2e9215691bffad74bfb97dbf3_0",
  "x": "This was the case in SemEval-2013, whose task 2 <cite>(Wilson et al., 2013)</cite> required sentiment analysis of Twitter and SMS text messages.",
  "y": "background"
 },
 {
  "id": "2d2da2e9215691bffad74bfb97dbf3_1",
  "x": "And perhaps this is the cause for lower score in the unconstrained mode, something that happened also with many systems in the past edition <cite>(Wilson et al., 2013)</cite> .",
  "y": "similarities"
 },
 {
  "id": "2d2ec7230a651d1d6786d0f8a71f7e_0",
  "x": "These two lines of research converge in prior work to show, e.g., the increasing association of the lexical item 'gay' with the meaning dimension of homosexuality<cite> (Kim et al., 2014</cite>; Kulkarni et al., 2015) .",
  "y": "background"
 },
 {
  "id": "2d2ec7230a651d1d6786d0f8a71f7e_1",
  "x": "It is thus a continuation of prior work, in which we investigated historical English texts only (Hellrich and Hahn, 2016a) , and also influenced by the design decisions of <cite>Kim et al. (2014)</cite> and Kulkarni et al. (2015) which were the first to use word embeddings in diachronic studies.",
  "y": "uses"
 },
 {
  "id": "2d2ec7230a651d1d6786d0f8a71f7e_2",
  "x": "Word embeddings can be used rather directly for tracking semantic changes, namely by measuring the similarity of word representations generated for one word at different points in time-words which underwent semantic shifts will be dissimilar with themselves. These models must either be trained in a continuous manner where the model for each time span is initialized with its predecessor<cite> (Kim et al., 2014</cite>; Hellrich and Hahn, 2016b) , or a mapping between models for different points in time must be calculated (Kulkarni et al., 2015; Hamilton et al., 2016) . The first approach cannot be performed in parallel and is thus rather time-consuming, if texts are not subsampled.",
  "y": "motivation background"
 },
 {
  "id": "2d2ec7230a651d1d6786d0f8a71f7e_3",
  "x": "These models must either be trained in a continuous manner where the model for each time span is initialized with its predecessor<cite> (Kim et al., 2014</cite>; Hellrich and Hahn, 2016b) , or a mapping between models for different points in time must be calculated (Kulkarni et al., 2015; Hamilton et al., 2016) .",
  "y": "background"
 },
 {
  "id": "2d2ec7230a651d1d6786d0f8a71f7e_4",
  "x": "The averaged cosine values between word embeddings before and after an epoch are used as a convergence measure c<cite> (Kim et al., 2014</cite>; Kulkarni et al., 2015) .",
  "y": "uses"
 },
 {
  "id": "2d2ec7230a651d1d6786d0f8a71f7e_5",
  "x": "The convergence criterion proposed by Kulkarni et al. (2015) , i.e., c = 0.9999, was never reached (this observation might be explained by Kulkarni et al.'s decision not to reset the learning rate for each training epoch, as was done by us and <cite>Kim et al. (2014)</cite> ).",
  "y": "similarities"
 },
 {
  "id": "2d7e98487698b0b6ae85f052402f7c_0",
  "x": "Prosodic Cues for DA Recognition: It has also been noted that prosodic knowledge plays a major role in DA identification for certain DA types<cite> Stolcke et al., 2000)</cite> . The main reason is that the acoustic signal of the same utterance can be very different in a different DA class. This indicates that if one wants to classify DA classes only from the text, the context must be an important aspect to consider: simply classifying single utterances might not be enough, but considering the preceding utterances as a context is important.",
  "y": "background"
 },
 {
  "id": "2d7e98487698b0b6ae85f052402f7c_1",
  "x": "Lexical, Prosodic, and Syntactic Cues: Many studies have been carried out to find out the lexical, prosodic and syntactic cues <cite>(Stolcke et al., 2000</cite>; Surendran and Levow, 2006; O'Shea et al., 2012; Yang et al., 2014) .",
  "y": "background"
 },
 {
  "id": "2d7e98487698b0b6ae85f052402f7c_2",
  "x": "For the SwDA corpus, the state-of-the-art baseline result was 71% for more than a decade using a standard Hidden Markov Model (HMM) with language features such as words and n-grams<cite> (Stolcke et al., 2000)</cite> . The inter-annotator agreement accuracy for the same corpus is 84%, and in this particular case, we are still far from achieving human accuracy. However, words like 'yeah' appear in many classes such as backchannel, yes-answer, agree/accept etc.",
  "y": "motivation background"
 },
 {
  "id": "2d7e98487698b0b6ae85f052402f7c_3",
  "x": "We follow the same data split of 1115 training and 19 test conversations as in the baseline approach <cite>(Stolcke et al., 2000</cite>; Kalchbrenner and Blunsom, 2013) .",
  "y": "uses"
 },
 {
  "id": "2db25254f275303c41f1e7ab15a5e0_0",
  "x": "However, Sporleder and Lascarides (2008) show that models trained on explicitly marked examples generalize poorly to implicit relation identification. They argued that explicit and implicit examples may be linguistically dissimilar, as writers tend to avoid discourse connectives if the discourse relation could be inferred from context (Grice, 1975) . Similar observations are made by <cite>Rutherford and Xue (2015)</cite> , who attempt to add automatically-labeled instances to improve supervised classification of implicit discourse relations. In this paper, we approach this problem from the perspective of domain adaptation.",
  "y": "motivation background"
 },
 {
  "id": "2db25254f275303c41f1e7ab15a5e0_1",
  "x": "<cite>Rutherford and Xue (2015)</cite> explore several selection heuristics for adding automatically-labeled examples from Gigaword to their system for implicit relation detection, obtaining a 2% improvement in Macro-F 1 . Our work differs from these previous efforts in that we focus exclusively on training from automaticallylabeled explicit instances, rather than supplementing a training set of manually-labeled implicit examples.",
  "y": "differences background"
 },
 {
  "id": "2db25254f275303c41f1e7ab15a5e0_2",
  "x": "It may also be desirable to ensure that the source and target training instances are similar in terms of their observed features; this is the idea behind the instance weighting approach to domain adaptation (Jiang and Zhai, 2007) . Motivated by this idea, we require that sampled instances from the source domain have a cosine similarity of at least \u03c4 with at least one target domain instance<cite> (Rutherford and Xue, 2015)</cite> .",
  "y": "background similarities"
 },
 {
  "id": "2db25254f275303c41f1e7ab15a5e0_3",
  "x": "In a pilot study we found that larger amounts of additional training data yielded no further improvements, which is consistent with the recent results of <cite>Rutherford and Xue (2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "2db25254f275303c41f1e7ab15a5e0_4",
  "x": "We have presented two methods -feature representation learning and resampling -from domain adaptation to close the gap of using explicit examples for unsupervised implicit discourse relation identification. Future work will explore the combination of this approach with more sophisticated techniques for instance selection<cite> (Rutherford and Xue, 2015)</cite> and feature selection (Park and Cardie, 2012; Biran and McKeown, 2013) , while also tackling the more difficult problems of multi-class relation classification and fine-grained level-2 discourse relations.",
  "y": "future_work"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_0",
  "x": "Although traditional AES methods typically rely on handcrafted features (Larkey, 1998; Foltz et al., 1999; Attali and Burstein, 2006; Dikli, 2006; Wang and Brown, 2008; Chen and He, 2013; Somasundaran et al., 2014; Yannakoudakis et al., 2014; Phandi et al., 2015) , recent results indicate that state-of-the-art deep learning methods reach better performance (Alikaniotis et al., 2016; Dong and Zhang, 2016; Taghipour and Ng, 2016; Song et al., 2017; <cite>Tay et al., 2018</cite>) , perhaps because <cite>these methods</cite> are able to capture subtle and complex information that is relevant to the task (Dong and Zhang, 2016) .",
  "y": "background"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_1",
  "x": "The empirical results indicate that our approach yields a better performance than state-of-the-art approaches (Phandi et al., 2015; Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "differences"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_2",
  "x": "Since the official test data of the ASAP competition is not released to the public, we, as well as others before us (Phandi et al., 2015; Dong and Zhang, 2016;  1 https://www.kaggle.com/c/asap-aes/data <cite>Tay et al., 2018</cite>) , use only the training data in our experiments.",
  "y": "similarities"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_3",
  "x": "We compare our approach with stateof-the-art methods based on handcrafted features (Phandi et al., 2015) , as well as deep features (Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_4",
  "x": "We used functions from the VLFeat li- Table 2 : In-domain automatic essay scoring results of our approach versus several state-of-the-art methods (Phandi et al., 2015; Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "differences"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_5",
  "x": "We first note that the histogram intersection string kernel alone reaches better overall performance (0.780) than all previous works (Phandi et al., 2015; Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "differences"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_6",
  "x": "Although the BOSWE model can be regarded as a shallow approach, its overall results are comparable to those of deep learning approaches (Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "similarities"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_7",
  "x": "The average QWK score of HISK and BOSWE (0.785) is more than 2% better the average scores of the best-performing state-of-the-art approaches <cite>Tay et al., 2018</cite>) .",
  "y": "differences"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_8",
  "x": "We compared our approach on the Automated Student Assessment Prize data set, in both in-domain and crossdomain settings, with several state-of-the-art approaches (Phandi et al., 2015; Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "2eaa48dbc5e42a5934e905ec2288ac_9",
  "x": "Using a shallow approach, we report better results compared to recent deep learning approaches (Dong and Zhang, 2016; <cite>Tay et al., 2018</cite>) .",
  "y": "differences"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_0",
  "x": "Hence, an adaptive IS may use a large number of samples to solve this problem whereas NCE is more stable and requires a fixed small number of noise samples (e.g., 100) to achieve a good performance [13, <cite>16]</cite> .",
  "y": "background"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_1",
  "x": "To alleviate this problem, noise samples can be shared across the batch<cite> [16]</cite> .",
  "y": "background"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_2",
  "x": "Furthermore, we can show that this solution optimally approximates the sampling from a unigram distribution, which has been shown to be a good noise distribution choice [13, <cite>16]</cite> .",
  "y": "background"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_3",
  "x": "This can be done by simply drawing an additional K samples form the noise distribution pn, and share them across the batch as it was done in<cite> [16]</cite> .",
  "y": "background"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_4",
  "x": "Each of the models is trained using the proposed B-NCE approach and the shared noise NCE (S-NCE)<cite> [16]</cite> .",
  "y": "uses"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_6",
  "x": "Following the setup proposed in [13, <cite>16]</cite> , S-NCE uses K = 100 noise samples, whereas B-NCE uses only the target words in the batch (K=0).",
  "y": "uses"
 },
 {
  "id": "2ef456a3f6b043350121c4c5cfd404_7",
  "x": "Moreover, the performance of the small ReLu-LSTM is comparable to the LSTM models proposed in<cite> [16]</cite> and [18] which use large hidden layers.",
  "y": "background"
 },
 {
  "id": "2f7b64db6939786a5026fc033c85bd_0",
  "x": "Until recently, GRE algorithms have focussed on the generation of distinguishing descriptions that are either as short as possible (e.g. (Dale, 1992; Gardent, 2002) ) or almost as short as possible (e.g. <cite>(Dale and Reiter, 1995)</cite> ).",
  "y": "background"
 },
 {
  "id": "2f7b64db6939786a5026fc033c85bd_1",
  "x": "allow the Full Brevity algorithm (Dale, 1992) to be viewed as minimising cost(S), and the incremental algorithm <cite>(Dale and Reiter, 1995)</cite> as hill-climbing (strictly, hill-descending), guided by the property-ordering which that algorithm requires.",
  "y": "background"
 },
 {
  "id": "2f7b64db6939786a5026fc033c85bd_2",
  "x": "Standard GRE algorithms assume that the speaker knows what the hearer knows <cite>(Dale and Reiter, 1995)</cite> .",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_0",
  "x": "Related work on exploring syntactic structured information in pronoun resolution can be typically classified into three categories: parse tree-based search algorithms ( Hobbs 1978) , feature-based (Lappin and Leass 1994; Bergsma and Lin 2006) and tree kernel-based methods<cite> (Yang et al 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_1",
  "x": "As for tree kernel-based methods, <cite>Yang et al (2006)</cite> captured syntactic structured information for pronoun resolution by using the convolution tree kernel (Collins and Duffy 2001) to measure the common sub-trees enumerated from the parse trees and achieved quite success on the ACE 2003 corpus.",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_2",
  "x": "Compared with Collins and Duffy's kernel and its application in pronoun resolution<cite> (Yang et al 2006)</cite> , the context-sensitive convolution tree kernel enumerates not only context-free sub-trees but also context-sensitive sub-trees by taking their ancestor node paths into consideration.",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_3",
  "x": "To deal with the cases that an anaphor and an antecedent candidate do not occur in the same sentence, we construct a pseudo parse tree for an entire text by attaching the parse trees of all its sentences to an upper \"S \" node, similar to <cite>Yang et al (2006)</cite> .",
  "y": "similarities"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_4",
  "x": "Figure 2 shows the three tree span schemes explored in <cite>Yang et al (2006)</cite> : MinExpansion (only including the shortest path connecting the anaphor and the antecedent candidate), Simple-Expansion (containing not only all the nodes in Min-Expansion but also the first level children of these nodes) and Full-Expansion (covering the sub-tree between the anaphor and the candidate), such as the sub-trees inside the dash circles of Figures 2(a) , 2(b) and 2(c) respectively.",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_5",
  "x": "It is found<cite> (Yang et al 2006)</cite> that the simpleexpansion tree span scheme performed best on the ACE 2003 corpus in pronoun resolution.",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_6",
  "x": "This convolution tree kernel has been successfully applied by <cite>Yang et al (2006)</cite> in pronoun resolution.",
  "y": "background"
 },
 {
  "id": "2fbf5397a8219923d1d9bc0464cb59_7",
  "x": "Table 1 systematically evaluates the impact of different m in our context-sensitive convolution tree kernel and compares our dynamic-expansion tree span scheme with the existing three tree span schemes, min-, simple-and full-expansions as described in <cite>Yang et al (2006)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "2fdfa1b36fcf0d77826c96101ac428_0",
  "x": "To address the model design issue, we discuss several recent solutions (He et al., 2016b; Li et al., 2016; <cite>Xiong et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "2fdfa1b36fcf0d77826c96101ac428_1",
  "x": "To address the model design issue, we discuss several recent solutions (He et al., 2016b; Li et al., 2016; <cite>Xiong et al., 2017)</cite> . We then focus on a new case study of hierarchical deep reinforcement learning for video captioning (Wang et al., 2018b) , discussing the techniques of leveraging hierarchies in DRL for NLP generation problems.",
  "y": "differences"
 },
 {
  "id": "2fdfa1b36fcf0d77826c96101ac428_2",
  "x": "We outline the applications of deep reinforcement learning in NLP, including dialog (Li et al., 2016) , semi-supervised text classification (Wu et al., 2018) , coreference (Clark and Manning, 2016; Yin et al., 2018) , knowledge graph reasoning<cite> (Xiong et al., 2017</cite> ), text games (Narasimhan et al., 2015; He et al., 2016a) , social media (He et al., 2016b; Zhou and Wang, 2018) , information extraction (Narasimhan et al., 2016; Qin et al., 2018) , language and vision (Pasunuru and Bansal, 2017; Misra et al., 2017; Wang et al., 2018a,b,c; Xiong et al., 2018) , etc.",
  "y": "background"
 },
 {
  "id": "2fdfa1b36fcf0d77826c96101ac428_3",
  "x": "To address the model design issue, we discuss several recent solutions (He et al., 2016b; Li et al., 2016; <cite>Xiong et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "2fdfa1b36fcf0d77826c96101ac428_4",
  "x": "To address the model design issue, we discuss several recent solutions (He et al., 2016b; Li et al., 2016; <cite>Xiong et al., 2017)</cite> . We then focus on a new case study of hierarchical deep reinforcement learning for video captioning (Wang et al., 2018b) , discussing the techniques of leveraging hierarchies in DRL for NLP generation problems.",
  "y": "differences"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_0",
  "x": "To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (Hu and Liu, 2004a; Popescu and Etzioni, 2005; Liu et al., 2005; Wang and Wang, 2008; Qiu et al., 2011;<cite> Liu et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_1",
  "x": "To resolve these problems,<cite> Liu et al. (2012)</cite> formulated identifying opinion relations between words as an monolingual alignment process.",
  "y": "background"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_2",
  "x": "Although <cite>(Liu et al., 2012)</cite> had proved the effectiveness of WAM, they mainly performed experiments on the dataset with medium size.",
  "y": "motivation"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_3",
  "x": "<cite>(Liu et al., 2012)</cite> formulated identifying opinion relations between words as an alignment process.",
  "y": "background"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_4",
  "x": "We notice these two methods ( <cite>(Liu et al., 2012)</cite> and (Liu et al., 2013) ) only performed experiments on the corpora with a medium size.",
  "y": "motivation"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_5",
  "x": "To extract opinion targets from reviews, we adopt the framework proposed by <cite>(Liu et al., 2012)</cite> , which is a graph-based extraction framework and has two main components as follows.",
  "y": "uses"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_6",
  "x": "In this paper, we assume opinion targets to be nouns or noun phrases, and opinion words may be adjectives or verbs, which are usually adopted by (Hu and Liu, 2004a; Qiu et al., 2011; Wang and Wang, 2008;<cite> Liu et al., 2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_7",
  "x": "Similar to <cite>(Liu et al., 2012)</cite> , every sentence in reviews is replicated to generate a parallel sentence pair, and the word alignment algorithm is applied to the monolingual scenario to align a noun/noun phase with its modifiers.",
  "y": "uses"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_8",
  "x": "Then, similar to <cite>(Liu et al., 2012)</cite> , the association between an opinion target candidate and its modifier is estimated as follows.",
  "y": "uses"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_9",
  "x": "In the second component, we adopt a graph-based algorithm used in <cite>(Liu et al., 2012)</cite> to compute the confidence of each opinion target candidate, and the candidates with higher confidence than the threshold will be extracted as the opinion targets.",
  "y": "uses"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_10",
  "x": "Similar to <cite>(Liu et al., 2012)</cite> , we set each item in , where tf (v) is the term frequency of v in the corpus, and df (v) is computed by using the Google n-gram corpus 2 .",
  "y": "uses"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_11",
  "x": "In this section, to answer the questions mentioned in the first section, we collect a large collection named as LARGE, which includes reviews from three different domains and different languages. This collection was also used in <cite>(Liu et al., 2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_12",
  "x": "To further prove the effectiveness of our combination, we compare PSWAM with some state-of-the-art methods, including Hu (Hu and Liu, 2004a) , which extracted frequent opinion target words based on association mining rules, DP (Qiu et al., 2011) , which extracted opinion targets through syntactic patterns, and LIU <cite>(Liu et al., 2012)</cite> , which fulfilled this task by using unsupervised WAM.",
  "y": "uses"
 },
 {
  "id": "304773c64de1f0906f0246f2aa0d29_13",
  "x": "To further prove the effectiveness of our combination, we compare PSWAM with some state-of-the-art methods, including Hu (Hu and Liu, 2004a) , which extracted frequent opinion target words based on association mining rules, DP (Qiu et al., 2011) , which extracted opinion targets through syntactic patterns, and LIU <cite>(Liu et al., 2012)</cite> , which fulfilled this task by using unsupervised WAM. The parameter settings in these baselines are the same as the settings in the original papers.",
  "y": "uses"
 },
 {
  "id": "30718e751f18432c2478442530267e_0",
  "x": "According to<cite> Jia and Liang (2017)</cite> , the single BiDAF system (Seo et al., 2016) only achieves an F1 score of 4.8 on the ADDANY adversarial dataset.",
  "y": "background"
 },
 {
  "id": "30718e751f18432c2478442530267e_1",
  "x": "According to<cite> Jia and Liang (2017)</cite> , the single BiDAF system (Seo et al., 2016) only achieves an F1 score of 4.8 on the ADDANY adversarial dataset. In this paper, we present a method to tackle this problem via answer sentence selection.",
  "y": "motivation"
 },
 {
  "id": "30718e751f18432c2478442530267e_2",
  "x": "However,<cite> Jia and Liang (2017)</cite> show that these systems are very vulnerable to paragraphs with adversarial sentences.",
  "y": "background"
 },
 {
  "id": "30718e751f18432c2478442530267e_3",
  "x": "Besides the single BiDAF, the single Match LSTM, the ensemble Match LSTM, and the ensemble BiDAF achieve an F1 of 7.6, 11.7, and 2.7 respectively in question answering on ADDANY adversarial dataset<cite> (Jia and Liang, 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "30718e751f18432c2478442530267e_4",
  "x": "Besides the single BiDAF, the single Match LSTM, the ensemble Match LSTM, and the ensemble BiDAF achieve an F1 of 7.6, 11.7, and 2.7 respectively in question answering on ADDANY adversarial dataset<cite> (Jia and Liang, 2017)</cite> . Therefore, question answering with adversarial sentences in paragraphs is a prominent issue and is the focus of this study.",
  "y": "background motivation"
 },
 {
  "id": "30718e751f18432c2478442530267e_5",
  "x": "Our test set is<cite> Jia and Liang (2017)</cite>'s ADDANY adversarial dataset.",
  "y": "uses"
 },
 {
  "id": "30718e751f18432c2478442530267e_6",
  "x": "The performance of question answering is evaluated by the Macro-averaged F1 score (Rajpurkar <cite>Jia and Liang, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "30718e751f18432c2478442530267e_7",
  "x": "However, following the idea of adversarial examples in image recognition (Goodfellow et al., 2014; Kurakin et al., 2016; Papernot et al., 2016) ,<cite> Jia and Liang (2017)</cite> point out the unreliability of existing question answering models in the presence of adversarial sentences.",
  "y": "background"
 },
 {
  "id": "30718e751f18432c2478442530267e_8",
  "x": "However, following the idea of adversarial examples in image recognition (Goodfellow et al., 2014; Kurakin et al., 2016; Papernot et al., 2016) ,<cite> Jia and Liang (2017)</cite> point out the unreliability of existing question answering models in the presence of adversarial sentences. In this study, we propose a method to tackle this problem through answer sentence selection.",
  "y": "background motivation"
 },
 {
  "id": "30718e751f18432c2478442530267e_9",
  "x": "However,<cite> Jia and Liang (2017)</cite> also present the deterioration of QA systems on another dataset, ADDSENT adversarial dataset.",
  "y": "similarities"
 },
 {
  "id": "311b238406da4891c09cb9c3c0334d_0",
  "x": "This makes the task more difficult, compared to the sentiment analysis, but it can often bring complementary information <cite>[3]</cite> .",
  "y": "background"
 },
 {
  "id": "311b238406da4891c09cb9c3c0334d_1",
  "x": "We preprocessed the Czech commentaries by the same rules as in the original system <cite>[3]</cite> (for example: all urls were replaced by keyword URL, links to images are replaced by IMGURL, only letters are preserved, the rest of the characters is removed, \u2026).",
  "y": "uses"
 },
 {
  "id": "311b238406da4891c09cb9c3c0334d_2",
  "x": "The original system <cite>[3]</cite> used more features, which could not be easily applied on Czech commentaries.",
  "y": "differences"
 },
 {
  "id": "311b238406da4891c09cb9c3c0334d_3",
  "x": "We did not identify strong candidates to build a domain specific dictionary as in <cite>[3]</cite> .",
  "y": "differences"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_0",
  "x": "The techniques examined are Structural Correspondence Learning (SCL)<cite> (Blitzer et al., 2006)</cite> and Self-training (Abney, 2007; McClosky et al., 2006) .",
  "y": "background"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_1",
  "x": "We examine Structural Correspondence Learning (SCL)<cite> (Blitzer et al., 2006)</cite> for this task, and compare it to several variants of Self-training (Abney, 2007; McClosky et al., 2006) .",
  "y": "similarities"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_2",
  "x": "So far, Structural Correspondence Learning has been applied successfully to PoS tagging and Sentiment Analysis<cite> (Blitzer et al., 2006</cite>; ).",
  "y": "background"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_3",
  "x": "Structural Correspondence Learning<cite> (Blitzer et al., 2006)</cite> exploits unlabeled data from both source and target domain to find correspondences among features from different domains.",
  "y": "background"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_4",
  "x": "Pivots are features occurring frequently and behaving similarly in both domains<cite> (Blitzer et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_5",
  "x": "Intuitively, if we are able to find good correspondences through 'linking' pivots, then the augmented source data should transfer better to a target domain<cite> (Blitzer et al., 2006)</cite> .",
  "y": "similarities"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_6",
  "x": "So far, pivot features on the word level were used<cite> (Blitzer et al., 2006</cite>; .",
  "y": "background"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_7",
  "x": "In our empirical setup, we follow<cite> Blitzer et al. (2006)</cite> and balance the size of source and target data.",
  "y": "similarities uses"
 },
 {
  "id": "3188ee1583a9c711cf147fc596768d_8",
  "x": "The paper compares Structural Correspondence Learning<cite> (Blitzer et al., 2006)</cite> with (various instances of) self-training (Abney, 2007; McClosky et al., 2006) for the adaptation of a parse selection model to Wikipedia domains.",
  "y": "similarities"
 },
 {
  "id": "31b06dfc081149e1e436f0bb5e0904_0",
  "x": "As a global trend, we observe that models that incorporate rich global features are typically more accurate, even if pruning is necessary or decoding needs to be approximate Koo and Collins, 2010; Bohnet and Nivre, 2012; Martins et al., 2009<cite> Martins et al., , 2013</cite> .",
  "y": "motivation background"
 },
 {
  "id": "31b06dfc081149e1e436f0bb5e0904_1",
  "x": "The parser was built as an extension of a recent dependency parser, TurboParser (Martins et al., 2010<cite> (Martins et al., , 2013</cite> , with the goal of performing semantic parsing using any of the three formalisms considered in the shared task (DM, PAS, and PSD).",
  "y": "uses"
 },
 {
  "id": "31b06dfc081149e1e436f0bb5e0904_2",
  "x": "Most of these features were taken from TurboParser <cite>(Martins et al., 2013)</cite> , and others were inspired by the semantic parser of Johansson and Nugues (2008) .",
  "y": "uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_0",
  "x": "We present a reproduction and extension to the work of <cite>Schulder et al. (2017)</cite> , <cite>which</cite> introduced a lexicon of verbal polarity shifters, as well as methods to increase the size of this lexicon through bootstrapping.",
  "y": "extends uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_1",
  "x": "The <cite>original approach</cite> was developed on English. We apply <cite>it</cite> to German, validating the generality of <cite>the approach</cite> and creating a new resource, a German lexicon of 677 verbal polarity shifters.",
  "y": "extends"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_2",
  "x": "However, while there has been significant research on negation in sentiment analysis (Wiegand et al., 2010) , current classifiers fail to handle polarity shifters adequately (<cite>Schulder et al., 2017</cite>) .",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_3",
  "x": "Unlike negation words (no, not, never, etc.) , of which there are only a few dozen in a language, polarity shifters are far more numerous. Among verbs alone there are many hundreds (<cite>Schulder et al., 2017</cite>) .",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_4",
  "x": "Once available, they can be used to improve the aforementioned tasks, as has already been shown for the case of English polarity classification (<cite>Schulder et al., 2017</cite>) .",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_5",
  "x": "To reduce the cost of creating such polarity shifter lexicons, <cite>Schulder et al. (2017)</cite> introduced methods to automatically generate a labeled list of words using either a limited amount of labeled training data or no labeled data at all.",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_6",
  "x": "<cite>Their approach</cite> includes both features that rely on semantic resources and datadriven ones.",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_7",
  "x": "<cite>They</cite> limited <cite>their work</cite> to English verbs, but expressed the expectation that <cite>their methods</cite> should also work for other languages.",
  "y": "differences motivation future_work"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_8",
  "x": "To verify that expectation, we apply <cite>their approach</cite> to German, for which all resources required to reproduce <cite>their experiments</cite> are available.",
  "y": "extends"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_9",
  "x": "Focusing on verbs also allows us a closer comparison with <cite>Schulder et al. (2017)</cite> and to investigate cross-lingual similarities between verbal shifters.",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_10",
  "x": "(i) we introduce a German lexicon of verbal polarity shifters; (ii) we reproduce and adapt the approach of <cite>Schulder et al. (2017)</cite> to German to extend our lexicon; (iii) we introduce additional methods that take advantage of the existence of the English verbal polarity shifter lexicon and improve upon the current state of the art.",
  "y": "extends uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_11",
  "x": "So far the only larger resources for polarity shifters are the English-language verbal shifter lexicons recently introduced by <cite>Schulder et al. (2017)</cite> and Schulder et al. (2018) .",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_12",
  "x": "<cite>Schulder et al. (2017)</cite> automatically bootstrap a lexicon which covers 980 verbal shifters at the lemma level, while Schulder et al. (2018) manually annotate word senses of verbs, creating a lexicon of 2131 shifter senses across 1220 verbs.",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_13",
  "x": "As we reproduce and extend the work of <cite>Schulder et al. (2017)</cite> , all further use of and comparison to an English shifter lexicon refers to their bootstrapped lexicon as well.",
  "y": "extends uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_14",
  "x": "<cite>Schulder et al. (2017)</cite> also make use of NPIs in addition to a number of other features.",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_15",
  "x": "<cite>Schulder et al. (2017)</cite> show that the explicit knowledge provided by a shifter lexicon can improve polarity classification in such cases.",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_16",
  "x": "We create a gold standard for German verbal shifters, following the approach <cite>Schulder et al. (2017)</cite> used for <cite>their</cite> English gold standard.",
  "y": "uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_17",
  "x": "We start by outlining the features proposed by <cite>Schulder et al. (2017)</cite> and how we adapt them for use with German ( \u00a74.1).",
  "y": "extends"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_18",
  "x": "In this section we briefly describe how we adapt the features of <cite>Schulder et al. (2017)</cite> to German language data.",
  "y": "extends"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_19",
  "x": "The word embeddings are created using Word2Vec (Mikolov et al., 2013) on the German web corpus DeWaC (Baroni et al., 2009) , using the same hyperparameters as <cite>Schulder et al. (2017)</cite> and German translations of their negation seeds.",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_20",
  "x": "<cite>Schulder et al. (2017)</cite> hypothesize that this phenomenon correlates with shifting, which can be seen as producing a new (negative) end state.",
  "y": "background"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_21",
  "x": "<cite>Schulder et al. (2017)</cite> hypothesize that this phenomenon correlates with shifting, which can be seen as producing a new (negative) end state. Therefore, <cite>they</cite> collect particle verbs containing relevant English particles, such as away, down and out. For our German data we chose the following particles associated with negative end states: ab, aus, entgegen, fort, herunter, hinunter, weg and wider.",
  "y": "motivation"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_22",
  "x": "<cite>Schulder et al. (2017)</cite> showed that the English NPI any co-occurs with shifters, so its presence in a verb phrase can indicate the presence of a verbal shifter. We expect the same for the German NPI jeglich, as seen in (8).",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_23",
  "x": "<cite>Schulder et al. (2017)</cite> used glosses, hypernyms and supersenses taken from the English WordNet (Miller et al., 1990) as features in <cite>their work</cite>. We use GermaNet (Hamp and Feldweg, 1997) , a German wordnet resource that provides all these features.",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_24",
  "x": "<cite>Schulder et al. (2017)</cite> use the frame memberships of verbs as a feature, hypothesizing that verbal shifters will be found in the same frames. We reproduce this feature using frames from the German FrameNet project Salsa (Burchardt et al., 2006) .",
  "y": "similarities uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_25",
  "x": "The motivation behind the work of <cite>Schulder et al. (2017)</cite> was to introduce a large lexicon of verbal polarity shifters. Now that such a lexicon exists for English, it is an obvious resource to use when creating verbal shifter lexicons for other languages. We hypothesize that a verb with the same meaning as an English verbal shifter will also function as a shifter in its own language.",
  "y": "motivation"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_26",
  "x": "We choose to use the bootstrapped lexicon of <cite>Schulder et al. (2017)</cite> , rather than the manually created one of Schulder et al. (2018) , to show that bootstrapping is sufficient for all stages of the learning process.",
  "y": "uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_27",
  "x": "<cite>Schulder et al. (2017)</cite> also observe in <cite>their</cite> error analysis that some verbs act as shifters in only some of their word senses. As different word senses often do not translate into the same foreign word, indiscriminate translation may introduce non-shifting senses of English shifter words as false positives. Evaluating the dictionary mapping as a feature will allow us to judge its usefulness for high-precision lexicon induction in future works.",
  "y": "future_work"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_28",
  "x": "We start our evaluation by reproducing the classifier evaluation of <cite>Schulder et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_29",
  "x": "Analogous to <cite>Schulder et al. (2017)</cite> we evaluate a supervised SVM classifier as well as a graph-based label propagation (LP) classifier that requires no labeled training data.",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_30",
  "x": "7 As in <cite>Schulder et al. (2017)</cite> , accuracy proves to be a problematic measure, as it has a strong majority label bias.",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_31",
  "x": "All features in data and resource were also used in <cite>Schulder et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_33",
  "x": "The most feature-rich SVM configuration, SVM data+resource+dict+embed , provides a significant improvement over SVM data+resource , the best classifier of <cite>Schulder et al. (2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_34",
  "x": "SVM data+resource represents the previously best classifier (<cite>Schulder et al., 2017</cite>) .",
  "y": "differences"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_35",
  "x": "Figure 2 shows the performance of the differently sized dictionaries as stand-alone classifiers, while Figure 3 shows how much they can improve the best classifier of <cite>Schulder et al. (2017)</cite> , i.e. SVM data+resource .",
  "y": "differences"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_36",
  "x": "In their intrinsic evaluation <cite>Schulder et al. (2017)</cite> showed that explicit knowledge of a large number of polarity shifters can improve sentiment analysis. To increase the size of our lexicon, we bootstrap additional shifters following <cite>their approach.</cite>",
  "y": "extends uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_37",
  "x": "Like <cite>Schulder et al. (2017)</cite> , we see very high performance for the first quartile, matching <cite>their</cite> observation that manual confirmation is not strictly necessary for high confidence labels.",
  "y": "similarities"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_38",
  "x": "In reproducing the work of <cite>Schulder et al. (2017)</cite> , we limited ourselves to verbs.",
  "y": "uses"
 },
 {
  "id": "31e8c524f05495fdd87bfac6fbecc8_39",
  "x": "While we have shown that the <cite>same approach</cite> for classifying verbal shifters works for German and English, future work will expand the number of languages, especially to verify that these methods can also be applied to non-Indo-European languages, such as Chinese, Japanese or Arabic.",
  "y": "similarities future_work"
 },
 {
  "id": "32ca78f6e01b7732a4bf573b91fbfe_0",
  "x": "An important advance in this area is the development of the word2vec technique [4] , which has proved to be an effective approach in Twitter sentiment classification<cite> [5]</cite> .",
  "y": "background"
 },
 {
  "id": "32ca78f6e01b7732a4bf573b91fbfe_1",
  "x": "Word embeddings proved to be effective representations in the tasks of sentiment analysis<cite> [5,</cite> 8, 9 ] and text classification [10] .",
  "y": "background"
 },
 {
  "id": "32ca78f6e01b7732a4bf573b91fbfe_2",
  "x": "Word embeddings proved to be effective representations in the tasks of sentiment analysis<cite> [5,</cite> 8, 9 ] and text classification [10] . In this work, I are aiming at evaluating word embeddings for sentiment analysis of citations.",
  "y": "uses background"
 },
 {
  "id": "32ca78f6e01b7732a4bf573b91fbfe_3",
  "x": "To improve sentiment citation classification results, I trained polarity specific word embeddings (PS-Embeddings), which were inspired by the Sentiment-Specific Word Embedding<cite> [5]</cite> .",
  "y": "uses"
 },
 {
  "id": "32ca78f6e01b7732a4bf573b91fbfe_6",
  "x": "However, unlike the outcomes in the paper of<cite> [5]</cite> , where they concluded that sentiment specific word embeddings performed best, integrating polarity information did not improve the result in this experiment.",
  "y": "differences"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_1",
  "x": "Multiple works in the recent past (Bruni et al., 2014; Lazaridou et al., 2015; Lopopolo and van Miltenburg, 2015;<cite> Kiela and Clark, 2015</cite>; Kottur et al., 2016) have explored using perceptual modalities like vision and sound to learn language embeddings.",
  "y": "background"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_2",
  "x": "While Lopopolo and van Miltenburg (2015) show preliminary results on using sound to learn distributional representations,<cite> Kiela and Clark (2015)</cite> build on ideas from Bruni et al. (2014) to learn word embeddings that respect both linguistic and auditory relationships by optimizing a joint objective.",
  "y": "background"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_3",
  "x": "We use the freesound database (Font et al., 2013) , also used in prior work<cite> (Kiela and Clark, 2015</cite>; Lopopolo and van Miltenburg, 2015) to learn the proposed sound-word2vec embeddings.",
  "y": "uses"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_4",
  "x": "AMEN and ASLex<cite> (Kiela and Clark, 2015)</cite> are subsets of the standard MEN (Bruni et al., 2014) and SimLex (Hill et al., 2015) word similarity datasets consisting of word-pairs that \"can be associated with a distinctive associated sound\".",
  "y": "background"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_5",
  "x": "AMEN and ASLex<cite> (Kiela and Clark, 2015)</cite> are subsets of the standard MEN (Bruni et al., 2014) and SimLex (Hill et al., 2015) word similarity datasets consisting of word-pairs that \"can be associated with a distinctive associated sound\". We evaluate on this dataset for completeness to benchmark our approach against previous work.",
  "y": "uses"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_6",
  "x": "Our use of language embeddings as an initialization to fine-tune (specialize) from, as opposed to formulating a joint objective with language and audio context<cite> (Kiela and Clark, 2015)</cite> is driven by the fact that we are interested in embeddings for words grounded in sounds, and not better generic word similarity.",
  "y": "differences"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_8",
  "x": "We use the openly available implementation for Lopopolo and van Miltenburg (2015) and re-implement<cite> Kiela and Clark (2015)</cite> and train them on our dataset for a fair comparison of the methods.",
  "y": "uses"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_10",
  "x": "We see that specializing the embeddings for sound using our two-stage training outperforms prior work <cite>(Kiela and Clark (2015)</cite> and Lopopolo and van Miltenburg (2015) ), which did not do specialization.",
  "y": "differences"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_11",
  "x": "Our approach performs better than<cite> Kiela and Clark (2015)</cite> .",
  "y": "differences"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_12",
  "x": "We find that Sound-word2vec performs the best with a mean rank of 34.6 compared to other baselines tag-word2vec (38.9), soundword2vec(r) (114.3) and word2vec (189.45). As observed previously, the second best performing approach is tag-word2vec. Lopopolo and van Miltenburg (2015) and<cite> Kiela and Clark (2015)</cite> perform worse than tag-word2vec with a mean rank of 48.4 and 42.1 respectively.",
  "y": "differences"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_13",
  "x": "AMEN and ASLex<cite> (Kiela and Clark, 2015)</cite> are subsets of the MEN and SimLex-999 datasets for word relatedness grounded in sound.",
  "y": "background"
 },
 {
  "id": "32e860cdf03df7f6cb58b7f9e85ac0_14",
  "x": "From Table 2, we can see that our embeddings outperform<cite> (Kiela and Clark, 2015)</cite> on both AMEN and ASLex.",
  "y": "differences"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_0",
  "x": "The issue is an open research area in computer vision and machine learning [1, 2, 3, <cite>4,</cite> 5, 6] .",
  "y": "background"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_1",
  "x": "In recent years, recurrent neural networks (RNNs) implemented by long short-term memory (LSTM) especially show good performances in sequence data processing and they are widely used as decoders to generate a natural language description from an image in many methods [3, <cite>4,</cite> 5, 6, 7] . High-performance approaches on convolutional neural networks (CNNs) have been proposed [8, 9] , which are employed to represent the input image with a feature vector for the caption generation [3, <cite>4,</cite> 5] .",
  "y": "background"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_2",
  "x": "High-level semantic concepts of the image are effective to describe a unique situation and a relation between objects in an image<cite> [4,</cite> 10] . Extracting specific arXiv:1807.09434v1 [cs.CV] 25 Jul 2018 semantic concepts encoded in an image, and applying them into RNN network has improved the performance significantly<cite> [4]</cite> .",
  "y": "background"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_3",
  "x": "Combinations of CNNs and RNNs have been widely used for the image captioning networks [1, 2, 3, <cite>4,</cite> 12, 13] .",
  "y": "background"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_4",
  "x": "Gan et al.<cite> [4]</cite> proposed Semantic Concept Network (SCN) integrating semantic concept to a LSTM network.",
  "y": "background"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_5",
  "x": "Gan et al.<cite> [4]</cite> proposed Semantic Concept Network (SCN) integrating semantic concept to a LSTM network. SCN factorized each weight matrix of the attribute integrated the LSTM model to reduce the number of parameters. We employed SCN-LSTM as a language generator to verify the effectiveness of our method.",
  "y": "uses"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_6",
  "x": "We used SCN-LSTM<cite> [4]</cite> as a decoder which is a tag integrated network.",
  "y": "uses"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_7",
  "x": "Similar to<cite> [4,</cite> 13, 18] , the objective function is composed of the conditional log-likelihood on the image feature and the attribute as",
  "y": "similarities"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_8",
  "x": "Most of the previous methods constituted semantic information, that was a ground truth attribute, as a binary form<cite> [4,</cite> 12, 13, 19] .",
  "y": "uses"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_9",
  "x": "In the perspective of vocabulary size, Gan<cite> [4]</cite> and Fang [12] selected 1000 words and Wu [13] selected 256 words, respectively.",
  "y": "background"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_10",
  "x": "In the perspective of vocabulary size, Gan<cite> [4]</cite> and Fang [12] selected 1000 words and Wu [13] selected 256 words, respectively. They all selected vocabulary among nouns, verbs, and adjectives. We determine the words to be included in the vocabulary based on the IDF scores. We do not distinguish between verbs, nouns, adjectives, and other parts of speech.",
  "y": "differences"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_11",
  "x": "We note that our network does not contain softmax as a final layer, different from other attribute predictors described in previous papers<cite> [4,</cite> 13] .",
  "y": "differences"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_12",
  "x": "SCN-LSTM training procedure generally follows<cite> [4]</cite> except for the dimension of the input attribute vector.",
  "y": "similarities"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_13",
  "x": "We use the public implementation [30] of this method opened by Gan who is the author of the published paper<cite> [4]</cite> .",
  "y": "uses"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_14",
  "x": "We average inferred probability for 5 identical SCN-LSTM model as<cite> [4]</cite> did.",
  "y": "uses"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_15",
  "x": "The output attribute of previous methods<cite> [4,</cite> 12, 13, 19] represent probabilities, on the other hand, that of the proposed method are the distinctiveness score itself.",
  "y": "differences"
 },
 {
  "id": "33096f1e855d23046cb4cbfe95eef0_16",
  "x": "In the experiment, we compared our method with SCN<cite> [4,</cite> 30] that uses extracted tags according to their semantic concept detection method.",
  "y": "uses"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_0",
  "x": "The trees may be learned directly from parallel corpora<cite> (Wu, 1997</cite>), or provided by a parser trained on hand-annotated treebanks (Yamada and Knight, 2001) .",
  "y": "background"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_1",
  "x": "The trees may be learned directly from parallel corpora<cite> (Wu, 1997</cite>), or provided by a parser trained on hand-annotated treebanks (Yamada and Knight, 2001) . In this paper, we compare these approaches on Chinese-English and French-English datasets, and find that automatically derived trees result in better agreement with human-annotated word-level alignments for unseen test data.",
  "y": "uses"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_2",
  "x": "<cite>Wu (1997)</cite> modeled the reordering process with binary branching trees, where each production could be either in the same or in reverse order going from source to target language.",
  "y": "background"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_3",
  "x": "This gives the translation model more information about the structure of the source language, and further constrains the reorderings to match not just a possible bracketing as in <cite>Wu (1997)</cite> , but the specific bracketing of the parse tree provided.",
  "y": "background"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_4",
  "x": "In this paper, we make a direct comparison of a syntactically unsupervised alignment model, based on <cite>Wu (1997)</cite> , with a syntactically supervised model, based on Yamada and Knight (2001) .",
  "y": "uses"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_5",
  "x": "The Inversion Transduction Grammar of <cite>Wu (1997)</cite> can be thought as a a generative process which simultaneously produces strings in both languages through a series of synchronous context-free grammar productions.",
  "y": "background"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_6",
  "x": "In our experiments we use a grammar with a start symbol S, a single preterminal C, and two nonterminals A and B used to ensure that only one parse can generate any given word-level alignment (ignoring insertions and deletions)<cite> (Wu, 1997</cite>; Zens and Ney, 2003) .",
  "y": "uses"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_7",
  "x": "\"Inversion Transduction Grammar\" (ITG) is the model of <cite>Wu (1997)</cite> , \"Tree-to-String\" is the model of Yamada and Knight (2001) , and \"Tree-to-String, Clone\" allows the node cloning operation described above.",
  "y": "background"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_8",
  "x": "We ran Model 1 for three iterations, then the HMM model for three iterations, and finally Model 4 for two iterations, training each model until AER began to increase on our held-out cross validation data. \"Inversion Transduction Grammar\" (ITG) is the model of <cite>Wu (1997)</cite> , \"Tree-to-String\" is the model of Yamada and Knight (2001) , and \"Tree-to-String, Clone\" allows the node cloning operation described above.",
  "y": "uses background"
 },
 {
  "id": "332e252e09d28763deb1ded2171c90_9",
  "x": "Zens and Ney (2003) compute the viterbi alignments for German-English and French-English sentences pairs using IBM Model 5, and then measure how many of the resulting alignments fall within the hard constraints of both <cite>Wu (1997)</cite> and Berger et al. (1996) .",
  "y": "background"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_0",
  "x": "In recent years, methods based on string kernels have demonstrated remarkable performance in various text classification tasks ranging from authorship identification (Popescu and Grozea, 2012) and sentiment analysis (Gim\u00e9nez-P\u00e9rez et al., 2017; to native language identification (Popescu and Ionescu, 2013; Ionescu et al., 2014 Ionescu et al., , 2016 , dialect identification (Ionescu and Popescu, 2016b;<cite> Ionescu and Butnaru, 2017</cite>; and automatic essay scoring (Cozma et al., 2018) .",
  "y": "background"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_1",
  "x": "As long as a labeled training set is available, string kernels can reach state-of-the-art results in various languages including English (Ionescu et al., 2014; Gim\u00e9nez-P\u00e9rez et al., 2017; Cozma et al., 2018) , Arabic (Ionescu, 2015; Ionescu et al., 2016;<cite> Ionescu and Butnaru, 2017</cite>; , Chinese and Norwegian (Ionescu et al., 2016) .",
  "y": "background"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_2",
  "x": "Nevertheless, we present empirical results indicating that our approach can obtain significantly better accuracy rates in cross-domain polarity classification and Arabic dialect identification compared to state-of-the-art methods based on string kernels (Gim\u00e9nez-P\u00e9rez et al., 2017;<cite> Ionescu and Butnaru, 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_3",
  "x": "We choose as baseline the approach of Ionescu and<cite> Butnaru (2017)</cite> , which is based on string kernels and multiple kernel learning.",
  "y": "uses"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_4",
  "x": "Ionescu and<cite> Butnaru (2017)</cite> combined four kernels into a sum, and used Kernel Ridge Regression for training.",
  "y": "background"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_5",
  "x": "In our experiments, we employ the exact same kernels as Ionescu and<cite> Butnaru (2017)</cite> to ensure an unbiased comparison with their ap- <cite>Butnaru, 2017)</cite> and the first runner up .",
  "y": "similarities uses"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_6",
  "x": "The marker * indicates that the performance is significantly better than (Ionescu and <cite>Butnaru, 2017)</cite> according to a paired McNemar's test performed at a significance level of 0.01.",
  "y": "differences"
 },
 {
  "id": "3351b13fc0c9d4d2de16d897c78aee_7",
  "x": "The domain-adapted sum of kernels obtains improvements above 0.8% over the stateof-the-art sum of kernels (Ionescu and <cite>Butnaru, 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "3356313ee5cdf186816cd6fecfce84_0",
  "x": "In recent years, end-to-end architectures gained traction that directly classify keyword posterior probabilites based on the previously extracted features, e.g., [1,<cite> 2,</cite> 3, 4, 5] .",
  "y": "background"
 },
 {
  "id": "3356313ee5cdf186816cd6fecfce84_2",
  "x": "DSCconvs have first been introduced in the domain of Image Processing [8, 13] and have been applied to other domains since: Zhang et al. applied DSCconv to KWS <cite>[2]</cite> .",
  "y": "background"
 },
 {
  "id": "3356313ee5cdf186816cd6fecfce84_4",
  "x": "DSConv have been successfully applied to the domain of computer vision [8, 13] , neural translation [7] and KWS <cite>[2]</cite> .",
  "y": "background"
 },
 {
  "id": "3356313ee5cdf186816cd6fecfce84_5",
  "x": "Compared to the DSConv network in <cite>[2]</cite> , our network is more efficient in terms of accuracy for a given parameter count.",
  "y": "differences"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_0",
  "x": "We often draw pragmatic inferences about a speaker's intentions from what they choose to say, but also from what they choose not to say in context. This suggests that pragmatic reasoning might allow modern neural network models to more efficiently learn on grounded language data from cooperative reference games. As a motivating case, consider an instance of the color reference task from<cite> Monroe et al. (2017)</cite> shown in the first row of Table 1 . In this task, a speaker communicates a target color to a listener in a context containing two distractor colors; the listener picks out the target based on what the speaker says. In the first instance from Table 1 , the speaker utters \"dark blue\" to describe the target. Whereas \"dark\" and \"blue\" also apply to the target, they lose their informativity in the presence of the distractors, and so the speaker pragmatically opts for \"dark blue\". A listener who is learning the language from such examples might draw several inferences from the speaker's utterance. First, under the assumption that the speaker is informative, a \"literal\" learner might infer that \"dark blue\" applies to the target shade more than the distractors. Second, a \"pragmatic\" learner might consider the cheaper alternatives-\"dark\" and \"blue\"-that have occurred in the presence of the same target in prior contexts, and infer that these alternative utterances must also apply to the distractors given the speaker's failure to use them. The pragmatic learner might thus gain more semantic knowledge from the same training instances than the literal learner: pragmatic reasoning can reduce the data complexity of learning.",
  "y": "background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_1",
  "x": "We compare pragmatic and non-pragmatic models at training and at test, while varying conditions on the training data to test hypotheses regarding the utility of pragmatic inference for learning. In particular, we show that incorporating pragmatic reasoning at training time yields improved, state-of-the-art accuracy for listener models on the color reference task from<cite> Monroe et al. (2017)</cite> , and the effect demonstrated by this improvement is especially large under small training data sizes. We further introduce a new color-grid reference task and data set consisting of higher dimensional objects and more complex speaker language; we find that the effect of pragmatic listener training is even larger in this setting.",
  "y": "differences background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_2",
  "x": "Prior work has shown that neural network models trained to capture the meanings of utterances can be improved using pragmatic reasoning at test time via the RSA framework (Andreas and Klein, 2016;<cite> Monroe et al., 2017</cite>; Goodman and Frank, 2016; Frank and Goodman, 2012) .",
  "y": "background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_3",
  "x": "For instance,<cite> Monroe et al. (2017)</cite> train context-agnostic (i.e. non-pragmatic) neural network models to learn the meanings of color utterances using a corpus of examples of the form shown in the first line of Table 1 . At evaluation, they add an RSA layer on top of the trained model to draw pragmatic, context-sensitive inferences about intended color referents.",
  "y": "background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_4",
  "x": "We compare neural nets trained pragmatically and non-pragmatically on a new color-grid reference game corpus as well as the color reference corpus from<cite> Monroe et al. (2017)</cite> .",
  "y": "background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_5",
  "x": "The color reference game from<cite> Monroe et al. (2017)</cite> consists of rounds played between a speaker and a listener. Each round has a context of two distractors and a target color (Figure 1a ). Only the speaker knows the target, and must communicate it to the listener-who must pick out the target based on the speaker's English utterance. Similarly, each round of our new color-grid reference game contains target and distractor color-grid objects, and the speaker must communicate the target grid to the listener (Figure 1b) . We train neural network models to play the listener role in these games.",
  "y": "background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_6",
  "x": "The language model is pre-trained over speaker utterances paired with targets, but the support of the distribution encoded by this LSTM is too large for the s 1 normalization term within the RSA listener to be computed efficiently. Similar to<cite> Monroe et al. (2017)</cite>, we resolve this issue by taking a small set of samples from the pre-trained LSTM applied to each object in a context, to approximate p(U | O), each time l 1 is computed during training and evaluation.",
  "y": "similarities background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_7",
  "x": "Sample<cite> Monroe et al. (2017)</cite> ).",
  "y": "uses"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_8",
  "x": "For the color reference task, we use the data collected by<cite> Monroe et al. (2017)</cite> from human play on the color reference task through Amazon Mechanical Turk using the framework of Hawkins (2015). Each game consists of 50 rounds played by a human speaker and listener. In each round, the speaker describes a target color surrounded by a context of two other distractor colors, and a listener clicks on the targets based on the speaker's description (see Figure 1a) . The resulting data consists of 46, 994 rounds across 948 games, where the colors of some rounds are sampled to be more likely to require pragmatic reasoning than others. In particular, 15, 516 trials are close with both distractors within a small distance to the target color in RGB space, 15, 782 are far with both distractors far from the target, and 15, 693 are split with one distractor near the target and one far from the target.",
  "y": "uses background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_9",
  "x": "For model development, we use the train/dev/test split from<cite> Monroe et al. (2017)</cite> with 15, 665 training, 15, 670 dev, and 15, 659 test rounds. Within our models, we represent color objects using a 3-dimensional CIELAB color spacenormalized so that the values of each dimension are in [\u22121, 1]. Our use of the CIELAB color space departs from prior work on the color data which used a 54-dimensional Fourier space <cite>(Monroe et al., 2017</cite> (Monroe et al., , 2016 Zhang and Lu, 2002) .",
  "y": "extends background"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_10",
  "x": "Following<cite> Monroe et al. (2017)</cite> , we preprocess the tokens by lowercasing, splitting off punctuation, and replacing tokens that appear only once with [unk] . In the color data, we also follow the prior work and split off -er, -est, and -ish, suffixes.",
  "y": "extends"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_11",
  "x": "We follow<cite> Monroe et al. (2017)</cite> for language model hyper-parameters, with embedding and LSTM layers of size 100. Also following this prior work, we use a learning rate of 0.004, batch size 128, and apply 0.5 dropout to each layer. We train for 7, 000 iterations, evaluating the model's accuracy on the dev set every 100 iterations.",
  "y": "uses"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_12",
  "x": "We generally use speaker rationality \u03b1 = 8.0 based on dev set tuning, and we follow<cite> Monroe et al. (2017)</cite> for other hyper-parameters-with embedding size of 100 and LSTM size of 100 in our meaning functions. Also following this prior work, we allow the LSTM to be bidirectional with learning rate of 0.005, batch size 128, and gradient clipping at 5.0. We train listeners for 10, 000 iterations on the color data and 15, 000 iterations on grid data, evaluating dev set accuracy every 500 iterations. We pick the model with the best accuracy from those evaluated at 500 iteration intervals.",
  "y": "uses"
 },
 {
  "id": "3395c9ed8ad9f2d048bf8ebf950d16_13",
  "x": "These results provide evidence that literal meanings estimated through pragmatic training are better calibrated for pragmatic usage than meanings estimated through non-pragmatic l 0 training. Furthermore, relative to state-of-the-art in<cite> Monroe et al. (2017)</cite> , Table 2 shows that our pragmatically trained model yields improved accuracy over their best \"blended\" pragmatic L e model which computed predictions based on the product of two separate non-pragmatically trained models.",
  "y": "differences background"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_0",
  "x": "Recent work using word embeddings-low-dimensional vector representations of words trained on large datasets to capture key semantic informationhas demonstrated that language encodes several gender, racial, and other common contemporary biases that correlate with both implicit biases (Caliskan et al., 2017) and macro-scale historical trends <cite>(Garg et al., 2018)</cite> . For example, the historical biases presented in <cite>(Garg et al., 2018)</cite> are computed using decade-specific word embeddings produced by training different Word2Vec (Mikolov et al., 2013 ) models on a large corpus of historical text from that decade.",
  "y": "background"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_1",
  "x": "To validate our model, we compare our results to those produced via the decade-by-decade models trained in <cite>(Garg et al., 2018)</cite> using the Corpus of Historical American English (Davies, 2010) . In particular, we compute linguistic bias scores for two analyses presented in <cite>(Garg et al., 2018)</cite> : the extent to which female versus male words are semantically similar to occupation-related words, and the extent to which Asian vs. White last names are semantically similar to the same, from 1910 through 1990.",
  "y": "similarities uses"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_2",
  "x": "The correlation between our scores and changes in workforce participation rates are similar to the correlation between the scores from <cite>(Garg et al., 2018)</cite> and the same (r = 0.8, p = 0.01 and r = 0.81, p < 0.01, respectively, for gender occupation bias; r = 0.84, p < 0.01 and r = 0.79, p = 0.01, respectively, for Asian/White occupation bias).",
  "y": "similarities"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_3",
  "x": "Qualitative inspection of Figure 2 suggests that our model also produces smoother decade-by-decade scores, suggesting that it not only identifies attribute- <cite>(Garg et al., 2018)</cite> and our model (blue dotted and green dashed lines, respectively) compared to actual workforce participation rates (solid lines) for gender (top) and Asian/White (bottom) linguistic biases.",
  "y": "differences"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_4",
  "x": "Finally, we define bias towards refugees similar to how the authors of <cite>(Garg et al., 2018)</cite> define bias against Asians during the 20th century, measuring to what extent radio shows associate \"outsider\" adjectives like \"aggressive\", \"frightening\", \"illegal\", etc. To compute refugee bias scores with respect to the attribute set A, we use the relative norm distance metric from <cite>(Garg et al., 2018)</cite> :",
  "y": "similarities uses"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_5",
  "x": "From qualitative inspection, the day-byday scores produced by the non-dynamic model appear much less smooth, and hence, fail to show the relative shift in discourse that likely occurred in response to a major refugee-related news event. One possible reason for this is that the median number of words for each day in the talk radio corpus is 4 million-over 5x fewer than a median of 22 million words per decade used to train each decade-specific model in <cite>(Garg et al., 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "34b73a56bd9b80dc415ca2c5608596_6",
  "x": "We validated our model by replicating gender and ethnic stereotypes produced in <cite>(Garg et al., 2018)</cite> by training multiple word embedding models and applied it to a novel corpus of talk radio data to analyze how perceptions of refugees as \"outsiders\" vary by geography and over time.",
  "y": "similarities uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_0",
  "x": "Similar to our previous work in product reviews<cite> (Xu et al., 2016)</cite> , we call the mouse target entity and those 4 products complementary entities of the target entity.",
  "y": "similarities background"
 },
 {
  "id": "35233406ffd78d87743478454432d5_1",
  "x": "Given the structure of a QA pair, our method naturally has a twostage framework: Complementary Entity Recognition (CER)<cite> (Xu et al., 2016)</cite> and yes/no answer classification.",
  "y": "uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_2",
  "x": "For the first stage, we employ a similar approach as in<cite> (Xu et al., 2016)</cite> ; for the second stage, it is reduced to a yes/no answer classification problem (McAuley and Yang, 2016) .",
  "y": "uses similarities"
 },
 {
  "id": "35233406ffd78d87743478454432d5_3",
  "x": "The problem of Complementary Entity Recognition (CER) is first proposed by Xu et. al.<cite> (Xu et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "35233406ffd78d87743478454432d5_4",
  "x": "The problem of Complementary Entity Recognition (CER) is first proposed by Xu et. al.<cite> (Xu et al., 2016)</cite> . However, our previous work focuses on product reviews and consider CER as a special kind of aspect extraction problem (Liu, 2015) . Determining the polarities of compatibility is reduced to a traditional sentiment classification problem. This paper focuses on yes/no QAs in PCQA and the polarities of compatibility is a yes/no answer classification problem.",
  "y": "motivation"
 },
 {
  "id": "35233406ffd78d87743478454432d5_5",
  "x": "We discussed the benefit of CER over social network problem in <cite>(Xu et al., 2016</cite> ) so we omit here but keep a performance comparison in Section 5.",
  "y": "background"
 },
 {
  "id": "35233406ffd78d87743478454432d5_6",
  "x": "We also bring out the test dataset used in<cite> (Xu et al., 2016)</cite> for a comparison (Section 5).",
  "y": "uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_7",
  "x": "Then we briefly introduce the method for CER in<cite> (Xu et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_8",
  "x": "Since complementary entities are mentioned in yes/no questions and their polarities of compatibility information are in answers, the proposed method naturally has a two-stage framework: Complementary Entity Recognition: we extract complementary entities from questions using dependency paths almost the same as in<cite> (Xu et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_9",
  "x": "We briefly introduce the method used in<cite> (Xu et al., 2016)</cite> and how the dependency paths can be used in questions of PCQA (details of dependency paths can be found in the original paper).",
  "y": "uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_10",
  "x": "We briefly introduce the method used in<cite> (Xu et al., 2016)</cite> and how the dependency paths can be used in questions of PCQA (details of dependency paths can be found in the original paper). The basic idea is to use dependency paths to identify the context of complementary relations around complementary entities.",
  "y": "extends"
 },
 {
  "id": "35233406ffd78d87743478454432d5_11",
  "x": "To obtain knowledge about domainspecific verbs, we use 6000 reviews for each product similar as in<cite> (Xu et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "35233406ffd78d87743478454432d5_12",
  "x": "CER6K: This method is the method proposed in<cite> (Xu et al., 2016)</cite> . Specifically, it uses 6000 reviews to expand domain-specific verbs. Next, we perform a separate evaluation on yes/no answer classification.",
  "y": "uses"
 },
 {
  "id": "35522a080b41f716723d2a619f59c4_0",
  "x": "To reduce this kind of error introduced by the translator, Wan in <cite>(Wan, 2009</cite> ) applied a co-training scheme.",
  "y": "background"
 },
 {
  "id": "35522a080b41f716723d2a619f59c4_1",
  "x": "The difficulty we are facing is, due to noise in the translations, the conditional probabilities p(y|x s ) and the one in the translated texts p(y|x s ) may be quite different. Consider the following two straightforward strategies of using automatic machine translations: one can translate the original English labeled data (y, x s ) into (y, x t ) in Chinese and train a classifier, or one can train a classifier on (y, x s ) and translate x t in Chinese into x s in English so as to use the classifier. But as the conditional distribution can be quite different for the original language and the pseudo language produced by the machine translators, these two strategies give poor performance as reported in<cite> (Wan, 2009)</cite> .",
  "y": "similarities"
 },
 {
  "id": "35522a080b41f716723d2a619f59c4_2",
  "x": "For comparsion, we use the same data set in<cite> (Wan, 2009)</cite> :",
  "y": "uses"
 },
 {
  "id": "35522a080b41f716723d2a619f59c4_3",
  "x": "Also following the setting in<cite> (Wan, 2009)</cite> , we only use the Chinese unlabeled data and English training sets for our SCL training procedures.",
  "y": "uses"
 },
 {
  "id": "35522a080b41f716723d2a619f59c4_4",
  "x": "The features we used are bigrams and unigrams in the two languages as in<cite> (Wan, 2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "35522a080b41f716723d2a619f59c4_5",
  "x": "We compare our procedure with the co-training scheme reported in<cite> (Wan, 2009)</cite> :",
  "y": "uses"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_0",
  "x": "The creation of question answering (QA) benchmarks for these knowledge bases (KB) has a significant impact on the domain, as shown by the number of QA systems recently proposed in the literature (Berant and Liang, 2014; Berant et al., 2013; Bordes et al., 2014a; <cite>Bordes et al., 2014b</cite>; Fader et al., 2013; Fader et al., 2014; Yao and Van Durme, 2014; Yih et al., 2014; Dong et al., 2015) .",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_1",
  "x": "IR-based approaches try to identify the best possible match between the knowledge base and the question (Bordes et al., 2014a; <cite>Bordes et al., 2014b</cite>; Yao and Van Durme, 2014; Dong et al., 2015) .",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_2",
  "x": "We follow the approach of <cite>Bordes et .al (2014b)</cite> which learns the embeddings of words and KB elements.",
  "y": "uses"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_3",
  "x": "<cite>They</cite> model the semantics of natural language sentences and KB triples as the sum of the embeddings of the associated words and KB elements respectively.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_4",
  "x": "Something even more interesting (<cite>Bordes et al., 2014b</cite>) is that the system can have a good performance even without using a paraphrase corpus.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_5",
  "x": "Like (<cite>Bordes et al., 2014b</cite>) , we use al-most no linguistic features such as POS tagging, parsing, etc.",
  "y": "uses"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_6",
  "x": "<cite>Bordes et al. (2014b)</cite> introduce a linguistically leaner IR-based approach which identifies the KB triple most similar to the input NL question.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_7",
  "x": "In <cite>their</cite> approach, KB triples and NL questions are represented as sums of embeddings of KB symbols and words respectively.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_8",
  "x": "Interestingly, <cite>Bordes' (2014b)</cite> system performs relatively well (MAP score 0.34) on the Wikianswers dataset even without using the paraphrase corpus.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_9",
  "x": "Interestingly, <cite>Bordes' (2014b)</cite> system performs relatively well (MAP score 0.34) on the Wikianswers dataset even without using the paraphrase corpus. Our work continues this direction by further separating relations with entities.",
  "y": "extends"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_10",
  "x": "The embeddings learned in (<cite>Bordes et al., 2014b</cite> ) also encode context information.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_11",
  "x": "The model is introduced in (<cite>Bordes et al., 2014b</cite>) and we use the same scoring function.",
  "y": "uses"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_12",
  "x": "Originally in (<cite>Bordes et al., 2014b</cite>) , given a question to be answered, training is performed by imposing a margin-constraint between the correct answer and negative ones.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_13",
  "x": "In (<cite>Bordes et al., 2014b</cite>) , the embedding of the semantics is then calculated as e + r for this very simple case.",
  "y": "background"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_14",
  "x": "What do cassava come from ? (cassava.e be-source-of.r security.e) (cassava.e be-grow-in.r africa.e) Table 1 : Some examples for which our system differs from ( (<cite>Bordes et al., 2014b</cite>) ).",
  "y": "differences"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_15",
  "x": "We compare the model (<cite>Bordes et al., 2014b</cite>) with the model where we enforce E and R (and also \"E\" and \"R\") to be orthogonal.",
  "y": "uses"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_16",
  "x": "This is the \"reranking\" setting used in (<cite>Bordes et al., 2014b</cite>) .",
  "y": "uses"
 },
 {
  "id": "357667e192057a48dff60edad86bf0_17",
  "x": "The Embedding scores are taken from (<cite>Bordes et al., 2014b</cite>) Table 3 shows that our technique improves the performance also on the larger, non-synthetic, dataset provided by Fader (2013) over the <cite>Bordes (2014b)</cite>'s method.",
  "y": "uses"
 },
 {
  "id": "36436e1d8a3f1d65fcc369649341f2_0",
  "x": "Apart from the empirical work in Tilburg and Antwerp, a number of recent studies on statistical natural language processing (e.g. Dagan & Lee, 1997; <cite>Collins & Brooks, 1995)</cite> also suggest that, contrary to common wisdom, forgetting specific training items, even when they represent extremely low-frequency events, is harmful to generalization accuracy.",
  "y": "background"
 },
 {
  "id": "36436e1d8a3f1d65fcc369649341f2_1",
  "x": "Apart from the empirical work in Tilburg and Antwerp, a number of recent studies on statistical natural language processing (e.g. Dagan & Lee, 1997; <cite>Collins & Brooks, 1995)</cite> also suggest that, contrary to common wisdom, forgetting specific training items, even when they represent extremely low-frequency events, is harmful to generalization accuracy. After reviewing this empirical work briefly, I will report on new results (work in progress in collaboration with van den Bosch and Zavrel), systematically comparing greedy and lazy learning techniques on a number of benehrnark natural language processing tasks: tagging, grapheme-to-phoneme conversion, and pp-attachment. The results show that forgetting individual training items, however \"improbable' they may be, is indeed harmful.",
  "y": "similarities"
 },
 {
  "id": "36436e1d8a3f1d65fcc369649341f2_2",
  "x": "Apart from the empirical work in Tilburg and Antwerp, a number of recent studies on statistical natural language processing (e.g. Dagan & Lee, 1997; <cite>Collins & Brooks, 1995)</cite> also suggest that, contrary to common wisdom, forgetting specific training items, even when they represent extremely low-frequency events, is harmful to generalization accuracy.",
  "y": "background"
 },
 {
  "id": "36436e1d8a3f1d65fcc369649341f2_3",
  "x": "Apart from the empirical work in Tilburg and Antwerp, a number of recent studies on statistical natural language processing (e.g. Dagan & Lee, 1997; <cite>Collins & Brooks, 1995)</cite> also suggest that, contrary to common wisdom, forgetting specific training items, even when they represent extremely low-frequency events, is harmful to generalization accuracy. After reviewing this empirical work briefly, I will report on new results (work in progress in collaboration with van den Bosch and Zavrel), systematically comparing greedy and lazy learning techniques on a number of benehrnark natural language processing tasks: tagging, grapheme-to-phoneme conversion, and pp-attachment.",
  "y": "extends"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_0",
  "x": "The overall structure and dynamics of networks representing texts have been modeled to describe their mechanism of growth and attachment [21, 22] , while nuances in the topology of real networks were exploited in practical problems, including natural language processing [23, 24,<cite> 25]</cite> .",
  "y": "background"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_1",
  "x": "It is crucial for practical applications such as text classification<cite> [25]</cite> , copyright resolution [28] , identification of terrorist messages [29] and of plagiarism [26] .",
  "y": "background"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_2",
  "x": "The adequacy of co-occurrence networks for the task was confirmed for the first time with the correlation between network topology and authors' styles<cite> [25]</cite> .",
  "y": "background"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_3",
  "x": "The adequacy of co-occurrence networks for the task was confirmed for the first time with the correlation between network topology and authors' styles<cite> [25]</cite> . Despite this relative success, some issues concerning the applicability of network methods remain unsolved.",
  "y": "background motivation"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_4",
  "x": "The co-occurrence networks were constructed with each distinct word becoming a node and two words being linked if they were adjacent in the pre-processed text<cite> [25]</cite> .",
  "y": "uses"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_5",
  "x": "Moreover, this measurement has been proven useful for analyzing text styles<cite> [25]</cite> .",
  "y": "uses background"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_6",
  "x": "The first moments \u00b5 1 represent the static metrics previously studied (see e.g. <cite>[25,</cite> 51] ) and define a subset of 12 attributes.",
  "y": "uses"
 },
 {
  "id": "370da04cbb2a6ab807428f7e058110_7",
  "x": "A similar study for the same task<cite> [25]</cite> analyzed 40 texts from 8 authors in English reaching a success score of 65%.",
  "y": "similarities"
 },
 {
  "id": "3881903212a2d0fea039c8967ab553_0",
  "x": "The motivation for this paper stems from prior work done by the first author in collaboration with other researchers (Prabhakaran et al., 2013a; <cite>Prabhakaran et al., 2013b)</cite> .",
  "y": "motivation"
 },
 {
  "id": "3881903212a2d0fea039c8967ab553_1",
  "x": "Prabhakaran et al. (2013a) introduced the notion of power in the domain of presidential debates, and<cite> Prabhakaran et al. (2013b)</cite> followed it up with an automatic power ranker system based on interactions within the debates.",
  "y": "background"
 },
 {
  "id": "3881903212a2d0fea039c8967ab553_2",
  "x": "As an additional contribution of this paper, we demonstrate the utility of our topic shift features extracted using both types of SITS-based analyses in improving the performance of the automatic power ranker system presented in<cite> (Prabhakaran et al., 2013b)</cite> .",
  "y": "differences"
 },
 {
  "id": "3881903212a2d0fea039c8967ab553_3",
  "x": "As we do in<cite> (Prabhakaran et al., 2013b)</cite> , we here report Kendall's Tau and Normalized Discounted Cumulative Gain values (NDCG and NDCG@3) on 5-fold cross validation (at the debate level).",
  "y": "uses"
 },
 {
  "id": "3881903212a2d0fea039c8967ab553_4",
  "x": "We use the best performing feature set of<cite> (Prabhakaran et al., 2013b)</cite> posted the overall best system obtaining a Tau of 0.60, NDCG of 0.970, and NDCG@3 of 0.937.",
  "y": "uses"
 },
 {
  "id": "38ad38f25a2823c64cd16bc9f2af93_0",
  "x": "This transcription bottleneck problem can be handled by translating into a widely spoken language to ensure subsequent interpretability of the collected recordings, and such parallel corpora have been recently created by aligning the collected audio with translations in a well-resourced language (Adda et al., 2016;<cite> Godard et al., 2017</cite>; Boito et al., 2018) .",
  "y": "background"
 },
 {
  "id": "38ad38f25a2823c64cd16bc9f2af93_1",
  "x": "The Multilingual Mboshi Parallel Corpus: In this work we extend the bilingual Mboshi-French parallel corpus <cite>(Godard et al., 2017)</cite> , fruit of the documentation process of Mboshi (Bantu C25), an endangered language spoken in Congo-Brazzaville.",
  "y": "extends"
 },
 {
  "id": "38ad38f25a2823c64cd16bc9f2af93_2",
  "x": "Nous traduisons un corpus parall\u00e8le bilingue Mboshi-Fran\u00e7ais <cite>(Godard et al., 2017)</cite> dans quatre autres langues, et \u00e9valuons l'impact de la langue de traduction sur une t\u00e2che de segmentation en mots non supervis\u00e9e.",
  "y": "extends"
 },
 {
  "id": "38ad38f25a2823c64cd16bc9f2af93_3",
  "x": "We translate the bilingual Mboshi-French parallel corpus <cite>(Godard et al., 2017)</cite> into four other languages, and we perform bilingual-rooted unsupervised word discovery.",
  "y": "extends"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_0",
  "x": "Another approach has been proposed by <cite>Zhang et al. (2017)</cite> who present a simple, yet efficient and accurate parsing model that generates unlabelled trees by identifying the most probable head for each token in the input.",
  "y": "background"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_1",
  "x": "Dependency Parsing as Head Selection Our labelling model is an extension of the parsing model of <cite>Zhang et al. (2017)</cite> . We use our own implementation of the head-selection parser and focus on the grammatical function labelling part.",
  "y": "extends"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_2",
  "x": "Dependency Parsing as Head Selection Our labelling model is an extension of the parsing model of <cite>Zhang et al. (2017)</cite> .",
  "y": "extends uses"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_3",
  "x": "Despite its simplicity and the lack of global optimisation, <cite>Zhang et al. (2017)</cite> report competitive results for English, Czech, and German.",
  "y": "background"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_4",
  "x": "Although the labelling approach in <cite>Zhang et al. (2017)</cite> is simple and efficient, looking at head and dependent only when assigning the labels comes with some disadvantages.",
  "y": "motivation background"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_5",
  "x": "Although the labelling approach in <cite>Zhang et al. (2017)</cite> is simple and efficient, looking at head and dependent only when assigning the labels comes with some disadvantages. To address this issue, we propose an extended labelling model that incorporates a decision history.",
  "y": "motivation"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_6",
  "x": "Our interest is focussed on German, but to put our work in context, we follow <cite>Zhang et al. (2017)</cite> and report results also for English, which has a configurational word order, and for Czech, which has a free word order, rich morphology, and less ambiguity in the case paradigm than German.",
  "y": "uses"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_7",
  "x": "The German and Czech data come from the CoNLL-X shared task (Buchholz and Marsi, 2006) and our data split follows <cite>Zhang et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_8",
  "x": "Unless stated otherwise, all parameters are set according to <cite>Zhang et al. (2017)</cite> , and tag embedding size was set to 40 for all languages.",
  "y": "uses"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_9",
  "x": "In the next step, we train four different labelling models: the labeller of <cite>Zhang et al. (2017)</cite> that uses a rectifier neural network with two hidden layers (baseline), two bidirectional LSTM models (BILSTM(L) and BILSTM(B)), and one tree LSTM model (TREELSTM) ( \u00a73).",
  "y": "uses"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_10",
  "x": "The scores for English are slightly lower since, in contrast to <cite>Zhang et al. (2017)</cite> , we do not use pre-trained embeddings.",
  "y": "differences"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_11",
  "x": "While we tried to reimplement the model of <cite>Zhang et al. (2017)</cite> following the details in the paper, our reimplemented model yields higher scores for German, compared to the results in the paper.",
  "y": "differences"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_12",
  "x": "3 When applied to unlabelled gold trees, the distance between our models and the baseline becomes larger and the best of our history-based models (BILSTM(B), 97.38%) outperforms the original labeller of <cite>Zhang et al. (2017)</cite> (96.15%) by more than 1%.",
  "y": "differences"
 },
 {
  "id": "392cbe849c1b8a69aae9923ade41aa_13",
  "x": "All our models outperform the original labeller of <cite>Zhang et al. (2017)</cite> and give results in the same range as the best system from the SPMRL-2014 shared task (without the reranker), but with a much simpler model.",
  "y": "differences"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_0",
  "x": "End-to-end neural machine translation (NMT) (Sutskever et al., 2014; <cite>Bahdanau et al., 2015)</cite> has gained increasing popularity in the machine translation community.",
  "y": "background"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_1",
  "x": "Capable of capturing longdistance dependencies with gating (Hochreiter and Schmidhuber, 1997; Cho et al., 2014) and attention<cite> (Bahdanau et al., 2015)</cite> mechanisms, NMT has proven to outperform conventional statistical machine translation systematically across a variety of language pairs (Junczys-Dowmunt et al., 2016) .",
  "y": "background"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_2",
  "x": "On top of Theano (Bergstra et al., 2010) , THUMT implements the standard attention-based encoder-decoder framework for NMT<cite> (Bahdanau et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_4",
  "x": "On top of Theano (Bergstra et al., 2010) , THUMT implements the standard attention-based encoder-decoder framework for NMT<cite> (Bahdanau et al., 2015)</cite> . It sup- * Corresponding author: Yang Liu. ports three training criteria: maximum likelihood estimation<cite> (Bahdanau et al., 2015)</cite> , minimum risk training , and semisupervised training .",
  "y": "uses"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_5",
  "x": "We compare THUMT with the state-of-the-art opensource toolkit GroundHog<cite> (Bahdanau et al., 2015)</cite> and achieve significant improvements on ChineseEnglish translation tasks by introducing new training criteria and optimizers.",
  "y": "differences"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_6",
  "x": "2 The Toolkit 2.1 Model THUMT implements the standard attention-based NMT model<cite> (Bahdanau et al., 2015)</cite> on top of Theano (Bergstra et al., 2010) .",
  "y": "uses"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_7",
  "x": "Please refer to<cite> (Bahdanau et al., 2015)</cite> for more details.",
  "y": "background"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_8",
  "x": "1. Maximum likelihood estimation (MLE)<cite> (Bahdanau et al., 2015)</cite> : the default training criterion in THUMT, which aims to find a set of model parameters that maximizes the likelihood of training data.",
  "y": "uses"
 },
 {
  "id": "397e593f8f282d4951402d83036c12_9",
  "x": "Our baseline system is GroundHog<cite> (Bahdanau et al., 2015)</cite> , a state-of-the-art open-source NMT toolkit.",
  "y": "uses"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_0",
  "x": "Although training using augmented text data is rare, generating new questions about images has been studied. The COCO-QA dataset<cite> (Ren et al., 2015)</cite> for VQA was created by parsing COCO captions with a syntactic parser, and then used this to create QA pairs for four kinds of questions using hand-crafted rules.",
  "y": "background"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_1",
  "x": "We conduct experiments on two of the most popular VQA datasets: 'The VQA Dataset' (Antol et al., 2015) and COCO-QA<cite> (Ren et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_2",
  "x": "COCO-QA<cite> (Ren et al., 2015)</cite> also uses images from COCO, with the questions generated by an NLP algorithm that uses COCO's captions.",
  "y": "background"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_3",
  "x": "The COCO-QA dataset<cite> (Ren et al., 2015)</cite> for VQA was created by parsing COCO captions with a syntactic parser, and then used this to create QA pairs for four kinds of questions using hand-crafted rules.",
  "y": "background"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_4",
  "x": "The COCO-QA dataset<cite> (Ren et al., 2015)</cite> for VQA was created by parsing COCO captions with a syntactic parser, and then used this to create QA pairs for four kinds of questions using hand-crafted rules. However, due to inability of the algorithm to cope with complex sentence structures, a significant portion of COCO-QA questions have grammatical errors or are oddly phrased.",
  "y": "motivation"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_5",
  "x": "These baseline methods predict the answer using a vector of image features concatenated to a vector of question features<cite> (Ren et al., 2015</cite>; Zhou et al., 2015; Kafle and Kanan, 2016) .",
  "y": "background"
 },
 {
  "id": "3a7625a0f38424fe922ad095e07e68_6",
  "x": "CNN features from ResNet-152 and the skip-thought vectors<cite> (Kiros et al., 2015)</cite> are used as image and question features respectively.",
  "y": "background"
 },
 {
  "id": "3a7f65a63e875db3e6d722a695aa5a_0",
  "x": "The current system is backed by the EasyCCG parser <cite>(Lewis and Steedman, 2014)</cite> , slightly modified to allow for incorporating constraints, and other CCG parsers could be plugged in with similar modifications.",
  "y": "extends"
 },
 {
  "id": "3a7f65a63e875db3e6d722a695aa5a_1",
  "x": "Span Constraints Although constraining lexical categories is often enough to determine the entire CCG derivation (cf. Bangalore and Joshi, 1999;<cite> Lewis and Steedman, 2014)</cite> , this is not always the case.",
  "y": "background"
 },
 {
  "id": "3b0a82129333203eca96a7473095f3_0",
  "x": "In a recent paper advocating a corpus-based and probabilistic approach to grammar development, <cite>Black, Lafferty, and Roukos (1992)</cite> argue that \"the current state of the art is far from being able to produce a robust parser of general English\" and advocate \"steady and quantifiable,\" empirically corpus-driven grammar development and testing.",
  "y": "motivation background"
 },
 {
  "id": "3b0a82129333203eca96a7473095f3_1",
  "x": "<cite>Black et al.</cite> are addressing a community in which armchair introspection has been and still is the dominant methodology in many quarters, but in some parts of Europe, corpus linguistics never died.",
  "y": "background"
 },
 {
  "id": "3b0a82129333203eca96a7473095f3_2",
  "x": "In a recent paper advocating a corpus-based and probabilistic approach to grammar development, <cite>Black, Lafferty, and Roukos (1992)</cite> argue that \"the current state of the art is far from being able to produce a robust parser of general English\" and advocate \"steady and quantifiable,\" empirically corpus-driven grammar development and testing. <cite>Black et al.</cite> are addressing a community in which armchair introspection has been and still is the dominant methodology in many quarters, but in some parts of Europe, corpus linguistics never died.",
  "y": "background"
 },
 {
  "id": "3b0a82129333203eca96a7473095f3_3",
  "x": "Oostdijk's work provides an excellent example of the strengths and weaknesses of the approach advocated by <cite>Black et al.</cite> In addition, she discusses issues such as sampling and tokenization of corpus material, as well as the exploitation of the analyzed corpus in studies of language variation.",
  "y": "background"
 },
 {
  "id": "3b0a82129333203eca96a7473095f3_4",
  "x": "However, other approaches are possible, such as the use of probabilities to guide parse selection, if not grammar induction (e.g., <cite>Black et al. 1992</cite> ).",
  "y": "background"
 },
 {
  "id": "3b0a82129333203eca96a7473095f3_5",
  "x": "While I am sympathetic to Oostdijk's position and think that the grammar she goes on to present is impressive enough to bias us towards the opposite conclusion, it is a mistake to accept the assumption that the two approaches are incompatible, as much recent work (including that of <cite>Black et al. 1992</cite>) has demonstrated the usefulness of combining statistical techniques with rule-based systems.",
  "y": "background"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_0",
  "x": "In terms of reproducibility via code release, recent TDSA papers have generally been very good with regards to publishing code alongside their papers (Mitchell et al., 2013; Zhang et al., 2016; Liu and Zhang, 2017;<cite> Wang et al., 2017)</cite> but other papers have not released code (Wang et al., 2016; Tay et al., 2017) .",
  "y": "background"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_1",
  "x": "Of course, we would not expect researchers to produce industrial strength code, or provide continuing free ongoing support for multiple years after publication, but the situation is clearly problematic for the development of the new field in general. In this paper, we therefore reproduce three papers chosen as they employ widely differing methods: Neural Pooling (NP) , NP with dependency parsing<cite> (Wang et al., 2017)</cite> , and RNN (Tang et al., 2016a) , as well as having been applied largely to different datasets.",
  "y": "motivation"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_2",
  "x": "Since its inception, papers have applied different methods such as feature based (Kiritchenko et al., 2014) , Recursive Neural Networks (RecNN) (Dong et al., 2014) , Recurrent Neural Networks (RNN) (Tang et al., 2016a) , attention applied to RNN (Wang et al., 2016; Chen et al., 2017; Tay et al., 2017) , Neural Pooling (NP)<cite> Wang et al., 2017)</cite> , RNN combined with NP (Zhang et al., 2016) , and attention based neural networks (Tang et al., 2016b) .",
  "y": "background"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_3",
  "x": "<cite>Wang et al. (2017)</cite> extended the work of by using the dependency linked words from the target.",
  "y": "background"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_6",
  "x": "One major difficulty with the description of the method in the paper and re-implementation is handling the same target multiple appearances issue as originally raised by <cite>Wang et al. (2017)</cite> .",
  "y": "background"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_7",
  "x": "We therefore took the approach of <cite>Wang et al. (2017)</cite> and found all of the features for each appearance and performed median pooling over features.",
  "y": "uses"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_9",
  "x": "<cite>Wang et al. (2017)</cite> extended the NP work of and instead of using the full tweet/sentence/text contexts they used the full dependency graph of the target word.",
  "y": "background"
 },
 {
  "id": "3bc48bea420e4977027832240450ec_10",
  "x": "The experiments are performed on the Dong et al. (2014) and <cite>Wang et al. (2017)</cite> Twitter datasets where we train and test on the previously specified train and test splits.",
  "y": "uses"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_1",
  "x": "We evaluate three end-to-end NLG systems: RNNLG<cite> (Wen et al., 2015)</cite> , TGen (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015) and LOLS (Lampouras and Vlachos, 2016) , using a large number of 21 automated metrics.",
  "y": "uses"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_2",
  "x": "Recent advances in corpus-based NLG (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015; <cite>Wen et al., 2015</cite>; Mei et al., 2016; Wen et al., 2016; Du\u0161ek and Jur\u010d\u00ed\u010dek, 2016; Lampouras and Vlachos, 2016) require costly training data, consisting of meaning representations (MRs) paired with corresponding NL texts.",
  "y": "motivation"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_3",
  "x": "Recent advances in corpus-based NLG (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015; <cite>Wen et al., 2015</cite>; Mei et al., 2016; Wen et al., 2016; Du\u0161ek and Jur\u010d\u00ed\u010dek, 2016; Lampouras and Vlachos, 2016) require costly training data, consisting of meaning representations (MRs) paired with corresponding NL texts. In our work, we propose a novel framework for crowdsourcing high quality NLG training data, using automatic quality control measures and evaluating two types of MRs, pictorial and textual, used to elicit data (Novikova and Rieser, 2016) .",
  "y": "differences motivation"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_4",
  "x": "Using this framework, we collected a dataset of 50k instances in the restaurant domain, which is 10 times bigger than datasets currently used for NLG training, e.g. SFRest and SFHot<cite> (Wen et al., 2015)</cite> or Bagel (Mairesse et al., 2010) .",
  "y": "differences"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_6",
  "x": "We evaluate three end-to-end NLG systems: RNNLG<cite> (Wen et al., 2015)</cite> , TGen (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015) and LOLS (Lampouras and Vlachos, 2016) , using a large number of 21 automated metrics.",
  "y": "uses"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_7",
  "x": "Recent advances in corpus-based NLG (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015; <cite>Wen et al., 2015</cite>; Mei et al., 2016; Wen et al., 2016; Du\u0161ek and Jur\u010d\u00ed\u010dek, 2016; Lampouras and Vlachos, 2016) require costly training data, consisting of meaning representations (MRs) paired with corresponding NL texts.",
  "y": "motivation"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_8",
  "x": "Recent advances in corpus-based NLG (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015; <cite>Wen et al., 2015</cite>; Mei et al., 2016; Wen et al., 2016; Du\u0161ek and Jur\u010d\u00ed\u010dek, 2016; Lampouras and Vlachos, 2016) require costly training data, consisting of meaning representations (MRs) paired with corresponding NL texts. In our work, we propose a novel framework for crowdsourcing high quality NLG training data, using automatic quality control measures and evaluating two types of MRs, pictorial and textual, used to elicit data (Novikova and Rieser, 2016) .",
  "y": "differences motivation"
 },
 {
  "id": "3c4c0875593ed0f196f5295fbaeb37_9",
  "x": "Using this framework, we collected a dataset of 50k instances in the restaurant domain, which is 10 times bigger than datasets currently used for NLG training, e.g. SFRest and SFHot<cite> (Wen et al., 2015)</cite> or Bagel (Mairesse et al., 2010) .",
  "y": "differences"
 },
 {
  "id": "3c74f66c209335ea33dda38c203199_0",
  "x": "To this end we use the long-distance agreement benchmark recently introduced by <cite>Gulordava et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "3c74f66c209335ea33dda38c203199_1",
  "x": "Assessing the syntactic abilities of monolingual neural LMs trained without explicit supervision has been the focus of several recent studies: Linzen et al. (2016) analyzed the performance of LSTM LMs at an English subject-verb agreement task, while <cite>Gulordava et al. (2018)</cite> extended the analysis to various long-range agreement patterns in different languages.",
  "y": "background"
 },
 {
  "id": "3c74f66c209335ea33dda38c203199_2",
  "x": "Following the setup of <cite>Gulordava et al. (2018)</cite> , we train 2-layer LSTM models with embedding and hidden layers of 650 dimensions for 40 epochs.",
  "y": "uses"
 },
 {
  "id": "3c74f66c209335ea33dda38c203199_3",
  "x": "The trained models are evaluated on the Italian section of the syntactic benchmark provided by <cite>Gulordava et al. (2018)</cite> , which includes various non-trivial number agreement constructions.",
  "y": "uses"
 },
 {
  "id": "3d1f3980190048625ec93517ebffdc_0",
  "x": "We use four families of features: Word n-gram features We use tf.idf -weighted word [1, 3]-grams<cite> (Rashkin et al. 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "3d1f3980190048625ec93517ebffdc_1",
  "x": "We evaluated proppy on data from<cite> Rashkin et al. (2017)</cite> in a binary setup of distinguishing propaganda vs nonpropaganda.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_0",
  "x": "Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the <cite>WinoBias probing corpus</cite>.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_1",
  "x": "Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on <cite>WinoBias</cite> can be eliminated.",
  "y": "differences"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_2",
  "x": "Specifically, we evaluate a state-of-the-art coreference resolution system ) that makes use of ELMo's contextual embeddings on <cite>WinoBias</cite> (<cite>Zhao et al., 2018a</cite>) , a coreference diagnostic <cite>dataset that</cite> evaluates whether systems behave differently on decisions involving male and female entities of stereotyped or anti-stereotyped occupations.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_3",
  "x": "We explore two different strategies: (1) a training-time data augmentation technique (<cite>Zhao et al., 2018a</cite>) , where we augment the corpus for training the coreference system with its genderswapped variant (female entities are swapped to male entities and vice versa) and, afterwards, retrain the coreference system; and (2)",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_4",
  "x": "For example, <cite>Zhao et al. (2018a)</cite> and Rudinger et al. (2018) show that coreference resolution systems relying on word embeddings encode such occupational stereotypes.",
  "y": "background"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_5",
  "x": "For example, <cite>Zhao et al. (2018a)</cite> and Rudinger et al. (2018) show that coreference resolution systems relying on word embeddings encode such occupational stereotypes. In contrast, we analyze bias in contextualized word representations and its effect on a downstream task.",
  "y": "differences"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_6",
  "x": "We use the set of occupation words defined in the <cite>WinoBias corpus</cite> and their assignments as prototypically male or female (<cite>Zhao et al., 2018a</cite>) .",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_7",
  "x": "The analysis shows that the <cite>Billion Word corpus</cite> contains a significant skew with respect to gender: (1) male pronouns occur three times more than female pronouns and (2) male pronouns co-occur more frequently with occupation words, irrespective of whether they are prototypically male or female.",
  "y": "motivation"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_8",
  "x": "To visualize the gender subspace, we pick a few sentence pairs from <cite>WinoBias</cite> (<cite>Zhao et al., 2018a</cite>) .",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_9",
  "x": "Then we split all such instances into training and test, with 539 and 62 instances, respectively and augment these sentences by swapping all the gendered words with words of the opposite gender such that the numbers of male 1 We use the list collected in (<cite>Zhao et al., 2018a</cite>) and female entities are balanced.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_10",
  "x": "We evaluate bias with respect to the <cite>WinoBias</cite> dataset (<cite>Zhao et al., 2018a</cite>) , a benchmark of paired male and female coreference resolution examples following the Winograd format (Hirst, 1981; Rahman and Ng, 2012; Peng et al., 2015) .",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_11",
  "x": "<cite>It</cite> contains two different subsets, pro-stereotype, where pronouns are associated with occupations predominately associated with the gender of the pronoun, or anti-stereotype, when the opposite relation is true.",
  "y": "background"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_12",
  "x": "Table 2 : F1 on OntoNotes and <cite>WinoBias</cite> development sets.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_13",
  "x": "<cite>WinoBias dataset</cite> is split Semantics Only and w/ Syntactic Cues subsets.",
  "y": "background"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_14",
  "x": "ELMo improves the performance on the OntoNotes dataset by 5% but shows stronger bias on the <cite>WinoBias dataset.</cite>",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_15",
  "x": "Previous work (<cite>Zhao et al., 2018a</cite>) evaluated the systems based on GloVe embeddings but here we evaluate a state-of-the-art system that trained on the OntoNotes corpus with ELMo embeddings .",
  "y": "motivation background"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_16",
  "x": "<cite>Zhao et al. (2018a)</cite> propose a method to reduce gender bias in coreference resolution by augmenting the training corpus for this task.",
  "y": "background"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_17",
  "x": "In addition, <cite>they</cite> find it useful to also mitigate bias in supporting resources and therefore replace standard GloVe embeddings with bias mitigated word embeddings from Bolukbasi et al. (2016) .",
  "y": "background"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_18",
  "x": "We evaluate the performance of both aspects of <cite>this approach</cite>.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_19",
  "x": "Table 2 summarizes our results on <cite>WinoBias</cite>.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_20",
  "x": "ELMo Bias Transfers to Coreference Row 3 in Table 2 summarizes performance of the ELMo based coreference system on <cite>WinoBias</cite>.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_21",
  "x": "It exhibits large differences between pro-and anti-stereotyped sets (|Diff|) on both semantic and syntactic examples in <cite>WinoBias</cite>.",
  "y": "uses"
 },
 {
  "id": "3d6df70136820f74ce76f60a59cc42_22",
  "x": "Neutralization is less effective than augmentation and cannot fully remove gender bias on the Semantics Only portion of <cite>WinoBias</cite>, indicating it is effective only for simpler cases.",
  "y": "motivation"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_0",
  "x": "Finally, the work that most resembles ours is that of<cite> Fagarasan et al. (2015)</cite> , who use Partial Least Squares Regression (PLSR) to learn a mapping from a word embedding model onto specific conceptual properties.",
  "y": "uses"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_1",
  "x": "Finally, the work that most resembles ours is that of<cite> Fagarasan et al. (2015)</cite> , who use Partial Least Squares Regression (PLSR) to learn a mapping from a word embedding model onto specific conceptual properties. Concurrent work recently undertaken by Li and Summers-Stay (2019) replaces the PLSR model with a feedforward neural network. In our work, we instead map property knowledge directly into vector space models of word meaning, rather than learning a supervised predictive function from concept embedding dimensions to feature terms.",
  "y": "extends differences"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_2",
  "x": "We make primary comparison with the work of<cite> Fagarasan et al. (2015)</cite> , although their approach differs from ours in that they map from an embedding space onto the feature space, while we learn a mapping from the feature domain onto the embedding space.",
  "y": "uses differences"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_3",
  "x": "In implementing PLSR, we set the intermediate dimension size to 50, following<cite> Fagarasan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_4",
  "x": "We first evaluate how well the baseline PLSR model performs on the feature vector reconstruction task used by<cite> Fagarasan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_5",
  "x": "We report results over both 50 (as in<cite> Fagarasan et al. (2015)</cite> ) and 120 dimensions for a range of values of N (Table 1) .",
  "y": "similarities"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_6",
  "x": "As property norms do not represent an exhaustive listing of property knowledge, this is not surprising, and predicted properties not in the norms are not necessarily errors (Devereux et al., 2009; <cite>Fagarasan et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "3d84cf97f48dad66b4d8de0baf79b1_7",
  "x": "As discussed by<cite> Fagarasan et al. (2015)</cite> and others, it is clear that property norm datasets provide only a semi-complete picture of human conceptual knowledge, and more extensive surveys may provide additional useful property knowledge information.",
  "y": "motivation"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_0",
  "x": "In this paper we contribute in this direction presenting the first Greek annotated dataset for offensive language identification: the Offensive Greek Tweet Dataset (OGTD). OGTD uses a working definition of offensive language inspired by the OLID dataset for English (<cite>Zampieri et al., 2019a</cite>) used in the recent OffensEval (SemEval-2019 Task 6) (Zampieri et al., 2019b) .",
  "y": "uses"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_1",
  "x": "OGTD considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in (<cite>Zampieri et al., 2019a</cite>) .",
  "y": "uses"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_2",
  "x": "(<cite>Zampieri et al., 2019a</cite>) model distinguishes targeted from general profanity, and considers the target of offensive posts as indicators of potential hate speech posts (insults targeted at groups) and cyberbulling posts (insults targeted at individuals).",
  "y": "background"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_3",
  "x": "OGTD considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in (<cite>Zampieri et al., 2019a</cite>) . (<cite>Zampieri et al., 2019a</cite>) model distinguishes targeted from general profanity, and considers the target of offensive posts as indicators of potential hate speech posts (insults targeted at groups) and cyberbulling posts (insults targeted at individuals).",
  "y": "uses"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_4",
  "x": "The bulk of work on detecting abusive posts online addressed particular types of such language like textual attacks and hate speech (Malmasi and Zampieri, 2017) , ag-gression (Kumar et al., 2018) , and others. OGTD considers a more general definition of offensiveness inspired by the first layer of the hierarchical annotation model described in (<cite>Zampieri et al., 2019a</cite>) .",
  "y": "similarities"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_5",
  "x": "The most recent project expanded on existing ideas for defining offensive language and presented the OLID (Offensive Language Identification Dataset), a corpus of Twitter posts hierarchically annotated on three levels, whether they contain offensive language or not, whether the offense is targeted and finally, the target of the offense (<cite>Zampieri et al., 2019a</cite>) .",
  "y": "background"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_6",
  "x": "Following the methodology described in (<cite>Zampieri et al., 2019a</cite>) and others, including a recent comparable Danish dataset (Sigurbergsson and Derczynski, 2020) , we collected tweets using keywords such as sensitive or obscene language.",
  "y": "uses"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_7",
  "x": "The final query for data collection was for tweets containing \"\u03b5\u03af\u03c3\u03b1\u03b9\" (eisai, \"you are\") as a keyword, inspired by (<cite>Zampieri et al., 2019a</cite>) .",
  "y": "uses"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_8",
  "x": "URLs, Emojis and Emoticons were removed, while usernames and user mentions were filtered as @USER following the same methodology described in OLID (<cite>Zampieri et al., 2019a</cite>) .",
  "y": "uses"
 },
 {
  "id": "3e2fb3d4c1e224c084117c22a5db78_9",
  "x": "We used the same guidelines used in the annotation of the English OLID dataset (<cite>Zampieri et al., 2019a</cite>) .",
  "y": "uses"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_0",
  "x": "Character CNN was first introduced by Zhang <cite>[2]</cite> for the text classification task.",
  "y": "background"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_1",
  "x": "Pure Character level classification was first explored using CNN architecture <cite>[2]</cite> .",
  "y": "background"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_2",
  "x": "Character-level CNN can sufficiently replace words for classifications <cite>[2]</cite> .",
  "y": "background"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_3",
  "x": "Character-level CNN can sufficiently replace words for classifications <cite>[2]</cite> . This means CNN does not require the syntactic or semantic structure of a language, which makes such approaches effectively independent of language as the number of characters is limited. To this end, CNN was used in this paper to perform the task of author attribution.",
  "y": "uses background"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_4",
  "x": "With larger datasets, this model will be able to perform significantly better <cite>[2]</cite> .",
  "y": "background"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_5",
  "x": "With larger datasets, this model will be able to perform significantly better <cite>[2]</cite> . This can be illustrated from Figure 1 that with a larger number of samples, the Char-CNN model raises steeply and performs competitively with the other models.",
  "y": "similarities"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_6",
  "x": "As stated in the paper <cite>[2]</cite> , ConvNets with character embedding can completely replace words and work even without any semantic meanings.",
  "y": "background"
 },
 {
  "id": "3e344c590b4d5270a29054ac15efa5_7",
  "x": "Considering the small size of our datasets, we hope to have improved performance with larger datasets, as is the case for character level ConvNets <cite>[2]</cite> .",
  "y": "similarities"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_0",
  "x": "Recently, <cite>Chen and Manning (2014)</cite> have showed that fast and accurate parsing can be achieved using neural network based parsers.",
  "y": "background"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_1",
  "x": "We first adapt <cite>Chen and Manning (2014)</cite> 's shift-reduce dependency parser for CCG parsing.",
  "y": "extends"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_2",
  "x": "<cite>Chen and Manning (2014)</cite> developed a neural network architecture for dependency parsing.",
  "y": "background"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_3",
  "x": "<cite>Chen and Manning (2014)</cite> 's parser used a feed forward neural network.",
  "y": "background"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_4",
  "x": "The architecture of our neural network based shift-reduce CCG parser is similar to that of <cite>Chen and Manning (2014)</cite> .",
  "y": "similarities"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_5",
  "x": "Following <cite>Chen and Manning (2014)</cite>, we use a cube activation function and softmax for output layer.",
  "y": "uses"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_6",
  "x": "We use the training settings of <cite>Chen and Manning (2014)</cite> for our parser.",
  "y": "uses"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_7",
  "x": "<cite>Chen and Manning (2014)</cite>'s parser is a greedy parser and it is not straight forward to add a beam during training into their parser.",
  "y": "background"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_8",
  "x": "Unlike 's neural network architecture, which consists of two hidden layers with 2048 hidden units each, we use the <cite>Chen and Manning (2014)</cite> style architecture described in the previous sections.",
  "y": "uses"
 },
 {
  "id": "3e5c070a6966361b54f069248438ec_9",
  "x": "Our neural network parser differs from <cite>Chen and Manning (2014)</cite> in a number of respects.",
  "y": "differences"
 },
 {
  "id": "3ea1f4acd7e2812e68eca54600fc5c_0",
  "x": "Dependency parsing is a topic that has engendered increasing interest in recent years. One promising approach is based on exact search and structural learning<cite> (McDonald et al., 2005</cite>; McDonald and Pereira, 2006) .",
  "y": "background"
 },
 {
  "id": "3ea1f4acd7e2812e68eca54600fc5c_2",
  "x": "In our approach, we adopt Eisner (1996) 's bottomup chart-parsing algorithm in <cite>McDonald et al. (2005)</cite> 's formulation, which finds the best projective dependency tree for an input string",
  "y": "extends"
 },
 {
  "id": "3ea1f4acd7e2812e68eca54600fc5c_3",
  "x": "We essentially employ the same set of features as <cite>McDonald et al. (2005)</cite> :",
  "y": "uses"
 },
 {
  "id": "3ea1f4acd7e2812e68eca54600fc5c_4",
  "x": "Having a closed-form solution, OPAL is easier to implement and more efficient than the MIRA algorithm used by <cite>McDonald et al. (2005)</cite> , although it achieves a performance comparable to MIRA's on many problems (Crammer et al., 2006) .",
  "y": "differences"
 },
 {
  "id": "3ea1f4acd7e2812e68eca54600fc5c_5",
  "x": "So far, the presented system, which follows closely the approach of <cite>McDonald et al. (2005)</cite> , only predicts unlabelled dependency trees. To derive a labeling, we departed from their approach: We split each feature along the deprel label dimension, so that each deprel U is associated with its own feature vector (cf. eq. (4), where V is the tensor product and In parsing, we only consider the best deprel label.",
  "y": "motivation differences"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_0",
  "x": "With advances in deep learning, neural models have given state-of-the-art results on many sequence labeling tasks (Ling et al., 2015; <cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) .",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_1",
  "x": "Many existing state-of-the-art neural sequence labeling models utilize word-level Long Short-Term Memory (LSTM) structures to represent global sequence information and a CRF layer to capture dependencies between neighboring labels <cite>Lample et al., 2016</cite>; Ma and Hovy, 2016; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_2",
  "x": "Liu et al. (2018) report lower average F-scores on NER when reproducing the structure of <cite>Lample et al. (2016)</cite> , and on POS tagging when reproducing Ma and Hovy (2016) . Most literature compares results with others by citing the scores directly <cite>Lample et al., 2016</cite>) without re-implementing them under the same setting, resulting in less persuasiveness on the advantage of their models.",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_3",
  "x": "For example, most work observes that stochastic gradient descent (SGD) gives best performance on NER task (Chiu and Nichols, 2016; <cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) , while Reimers and Gurevych (2017b) report that SGD is the worst optimizer on the same datasets.",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_4",
  "x": "Ling et al. (2015) give results only on POS dataset, while some papers (Chiu and Nichols, 2016; <cite>Lample et al., 2016</cite>; Strubell et al., 2017) report results on the NER dataset only.",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_5",
  "x": "Most work uses the development set to select hyperparameters (<cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) , while others add development set into training set (Chiu and Nichols, 2016; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_6",
  "x": "A typical data preprocessing step is to normize digit characters (Chiu and Nichols, 2016; <cite>Lample et al., 2016</cite>; Yang et al., 2016; Strubell et al., 2017) .",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_7",
  "x": "Besides, <cite>Lample et al. (2016)</cite> and Ma and Hovy (2016) use end-to-end structure without handcrafted features.",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_8",
  "x": "built a BiLSTM-CRF structure, which has been extended by adding character-level LSTM (<cite>Lample et al., 2016</cite>; Liu et al., 2018) , GRU (Yang et al., 2016) , and CNN (Chiu and Nichols, 2016; Ma and Hovy, 2016) features.",
  "y": "extends"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_9",
  "x": "3) Our findings are more consistent with most previous work on configurations such as usefulness of character information (<cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) , optimizer (Chiu and Nichols, 2016; <cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) and tag scheme (Ratinov and Roth, 2009; Dai et al., 2015) .",
  "y": "similarities"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_10",
  "x": "Our neural sequence labeling framework contains three layers, i.e., a character sequence representation layer, a word sequence representation layer and an inference layer, as shown in Figure 1 . Character information has been proven to be critical for sequence labeling tasks (Chiu and Nichols, 2016; <cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) , with LSTM and CNN being used to model character sequence information (\"Char Rep.\").",
  "y": "background motivation"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_11",
  "x": "Character features such as prefix, suffix and capitalization can be represented with embeddings through a feature-based lookup table (Collobert et al., 2011; Strubell et al., 2017) , or neural networks without human-defined features (<cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) .",
  "y": "background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_12",
  "x": "We examined both structures and found that they give comparable accuracies on sequence labeling tasks. We choose <cite>Lample et al. (2016)</cite> 's structure as its character LSTMs can be calculated in parallel, making the system more efficient.",
  "y": "uses"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_13",
  "x": "Similar to character sequences in words, we can model word sequence information through LSTM or CNN structures. LSTM has been widely used in sequence labeling (<cite>Lample et al., 2016</cite>; Ma and Hovy, 2016; Chiu and Nichols, 2016; Liu et al., 2018) .",
  "y": "similarities background"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_14",
  "x": "The results of <cite>Lample et al. (2016)</cite> can be reproduced by our CLSTM+WLSTM+CRF.",
  "y": "similarities"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_15",
  "x": "The results of <cite>Lample et al. (2016)</cite> , Ma and Hovy (2016) and Yang et al. (2017b) can be reproduced by our CLSTM+WLSTM+CRF and CCNN+WLSTM+CRF models.",
  "y": "similarities"
 },
 {
  "id": "3fd7a249a8fa7a71a4c6aa2e79fecf_16",
  "x": "Our observation is consistent with most literature (Chiu and Nichols, 2016; <cite>Lample et al., 2016</cite>; Ma and Hovy, 2016) .",
  "y": "similarities"
 },
 {
  "id": "3ff58556ab973a9dde640a2b74c37b_0",
  "x": "The two existing systems that use function labels sucessfully, either inherit Collins' modelling of the notion of complement (Gabbard, Kulick and Marcus, 2006) or model function labels directly <cite>(Musillo and Merlo, 2005)</cite> .",
  "y": "background"
 },
 {
  "id": "3ff58556ab973a9dde640a2b74c37b_1",
  "x": "The two existing systems that use function labels sucessfully, either inherit Collins' modelling of the notion of complement (Gabbard, Kulick and Marcus, 2006) or model function labels directly <cite>(Musillo and Merlo, 2005)</cite> . Furthermore, our results indicate that the proposed models are robust.",
  "y": "uses background"
 },
 {
  "id": "3ff58556ab973a9dde640a2b74c37b_2",
  "x": "For more information on this technique to capture structural domains, see <cite>(Musillo and Merlo, 2005)</cite> where the technique was applied to function parsing.",
  "y": "uses background"
 },
 {
  "id": "3ff58556ab973a9dde640a2b74c37b_3",
  "x": "Extending a technique presented in (Klein and Manning, 2003 ) and adopted in<cite> (Merlo and Musillo, 2005)</cite> for function labels with stateof-the-art results, we split some part-of-speech tags into tags marked with AM-X semantic role labels.",
  "y": "extends"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_0",
  "x": "<cite>Yarowsky (1992)</cite> introduces a thesaurus-based approach to statistical sense disambiguation which works on monolingual corpora without the need for sense-tagged training data.",
  "y": "background"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_1",
  "x": "Like the thesaurusbased approach of <cite>Yarowsky (1992)</cite> , our approach relies on the dilution of this noise by their distribution through all the 1792 defining concepts.",
  "y": "similarities"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_2",
  "x": "Our system is tested on the twelve words discussed in <cite>Yarowsky (1992)</cite> and previous publications on sense disambiguation.",
  "y": "uses"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_3",
  "x": "Numerically, the result is not as good as the 92% as reported in <cite>Yarowsky (1992)</cite> .",
  "y": "differences"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_4",
  "x": "9 The average sentence length in the Brown corpus is 19.41\u00b0 words which is 5 times smaller than the 100 word window used in Gale et al. (1992) and <cite>Yarowsky (1992)</cite> .",
  "y": "differences"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_5",
  "x": "(thesaurus) marks the column with the results of <cite>Yarowsky (1992)</cite> tested on the Grolier's Encyclopedia.",
  "y": "uses"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_6",
  "x": "3. The senses marked with * are used in <cite>Yarowsky (1992)</cite> but no corresponding sense is found in LDOCE.",
  "y": "uses"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_7",
  "x": "4. The sense marked with ** is defined in LDOCE but not used in <cite>Yarowsky (1992)</cite> .",
  "y": "differences"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_8",
  "x": "For some of the words, more than one sense listed in LDOCE corresponds to a sense as used in <cite>Yarowsky (1992)</cite> .",
  "y": "similarities"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_9",
  "x": "On the other hand, the thesaurus-based method of <cite>Yarowsky (1992)</cite> may suffer from loss of information (since it is semi-class-based) as well as data sparseness (since H Classes used in Resnik (1992) are based on the WordNet taxonomy while classes of Brown et al. (1992) and Pereira et al. (1993) are derived from statistical data collected from corpora.",
  "y": "differences"
 },
 {
  "id": "412c2daf6d060f520850d187c6eb36_10",
  "x": "such as that described in <cite>Yarowsky (1992)</cite> are very unlikely to be capable of acquiring this finer knowledge because the problem of data sparseness becomes even more serious with the introduction of syntactic constraints.",
  "y": "differences"
 },
 {
  "id": "418016e4df12f80205cadc41119244_0",
  "x": "Actually we find Inspired by <cite>[2]</cite> , we formulate BioCS as a sequence tagging problem.",
  "y": "uses"
 },
 {
  "id": "418e03aa7ba304c4774111e9f300ad_0",
  "x": "All our models are based on encoder-decoder model introduced by <cite>Faruqui et al. (2016)</cite> for the morphological inflection task.",
  "y": "uses"
 },
 {
  "id": "418e03aa7ba304c4774111e9f300ad_1",
  "x": "Most of the morphological inflection models are variants of sequence to sequence models applied by <cite>Faruqui et al. (2016)</cite> to morphological reinflection.",
  "y": "background"
 },
 {
  "id": "418e03aa7ba304c4774111e9f300ad_2",
  "x": "The work presented in this paper is based on the work of the simple encoder-decoder system of <cite>Faruqui et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_0",
  "x": "Left-to-right (LR) decoding<cite> (Watanabe et al., 2006</cite> ) is promising decoding algorithm for hierarchical phrase-based translation (Hiero) that visits input spans in arbitrary order producing the output translation in left to right order.",
  "y": "background"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_1",
  "x": "LR-decoding algorithms exist for phrasebased (Koehn, 2004; Galley and Manning, 2010) and syntax-based (Huang and Mi, 2010; Feng et al., 2012 ) models and also for hierarchical phrasebased models<cite> (Watanabe et al., 2006</cite>; Siahbani et al., 2013) , which is our focus in this paper.",
  "y": "background"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_2",
  "x": "<cite>Watanabe et al. (2006)</cite> first proposed left-toright (LR) decoding for Hiero (LR-Hiero henceforth) which uses beam search and runs in O(n 2 b) in practice where n is the length of source sentence and b is the size of beam (Huang and Mi, 2010) .",
  "y": "background"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_3",
  "x": "LR-Hiero uses a constrained lexicalized SCFG which we call a GNF grammar: X \u2192 \u03b3,b \u03b2 where \u03b3 is a string of non-terminal and terminal symbols,b is a string of terminal symbols and \u03b2 is a possibly empty sequence of non-terminals. This ensures that as each rule is used in a derivation, Add h to hypList 29: return hypList the target string is generated from left to right. The rules are obtained from a word and phrase aligned bitext using the rule extraction algorithm in<cite> (Watanabe et al., 2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_4",
  "x": "Left side shows the rules used in the derivation (G indicates glue rules as defined in<cite> (Watanabe et al., 2006)</cite> ).",
  "y": "uses"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_5",
  "x": "We use 3 baselines: (i) our implementation of<cite> (Watanabe et al., 2006)</cite> : LR-Hiero with beam search (LR-Hiero) and (ii) LR-Hiero with cube pruning (Siahbani et al., 2013) : (LR-Hiero+CP); and (iii) Kriya, an open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012) .",
  "y": "uses"
 },
 {
  "id": "41d56f3f962fa3b0e0563544a6de40_6",
  "x": "In (Siahbani et al., 2013) we discuss that LR-Hiero with beam search<cite> (Watanabe et al., 2006)</cite> does not perform at the same level of state-of-the-art Hiero (more LM calls and less translation quality).",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_0",
  "x": "<cite>They</cite> proposed using a differential evolution search algorithm to find the input parameters which maximize the topic model stability measured as the similarity of topics between multiple runs.",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_1",
  "x": "Latent Dirichlet Allocation (LDA) is a topic modeling technique for textual data [5] that is widely applied in software engineering <cite>[1</cite>-4, 6, 10, 11, 14-16, 19, 24, 25] for different tasks such as requirements engineering [15] , software architecture [10] , source code analysis [9] , defect reports [16] , testing [14] and to bibliometric analysis of software engineering literature [11, 22] .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_2",
  "x": "Many sources give methodological guidance on how to apply LDA topic modeling in software engineering <cite>[1</cite>, 3, 19] .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_3",
  "x": "Other target metrics are based on empirical observations such as coherence, which measures topic model quality using word co-occurrences in publicly available texts [23] , or stability which investigates similarity of topics between different runs <cite>[1]</cite> .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_4",
  "x": "Recently, <cite>Agrawal et al. [1]</cite> published a paper titled \"What is wrong with topic modeling? And how to fix it using search-based software engineering\", where <cite>they</cite> claimed that the instability of topics is one major shortcoming of this technique.",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_5",
  "x": "Past work in software engineering has used different techniques to find optimal input parameters such as genetic algorithms [19] or differential evolution <cite>[1]</cite> .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_6",
  "x": "As pointed out in Section 1, what is optimal can be measured with many metrics such as perplexity [13] , stability <cite>[1]</cite> , or coherence [23] .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_7",
  "x": "Instability (the lack of stability) is caused by the non-deterministic nature of Monte-Carlo simulation that is part of the LDA algorithm <cite>[1]</cite> .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_8",
  "x": "Past work has shown different stability measures and how to optimize the input parameters to provide a stable topic model <cite>[1</cite>, 8, 12] .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_9",
  "x": "Extended Jaccard measures have been used in LDA stability task optimization <cite>[1,</cite> 12] .",
  "y": "background"
 },
 {
  "id": "425148e63eb84bba50326e362cc5b8_10",
  "x": "Past work in software engineering <cite>[1]</cite> and machine learning [12] point out that LDA instability may lead to incorrect conclusions and proposes input parameter optimization to alleviate the problem.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_0",
  "x": "<cite>Transformer</cite> with self-attention has achieved great success in the area of nature language processing.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_1",
  "x": "Recently, there have been a few studies on <cite>transformer</cite> for end-to-end speech recognition, while its application for hybrid acoustic model is still very limited.",
  "y": "motivation"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_2",
  "x": "In this paper, we revisit the <cite>transformer</cite>-based hybrid acoustic model, and propose a model structure with interleaved self-attention and 1D convolution, which is proven to have faster convergence and higher recognition accuracy.",
  "y": "extends"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_3",
  "x": "We also study several aspects of the <cite>transformer model</cite>, including the impact of the positional encoding feature, dropout regularization, as well as training with and without time restriction.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_4",
  "x": "<cite>Transformer</cite> <cite>[8]</cite> , which relies solely on self-attention to capture the temporal correlations in sequential signals, is a new type of neural network structure for sequence modeling, which has achieved excellent results in machine translation <cite>[8]</cite> , language modeling [9] , as well as end-to-end speech recognition [10, 11] .",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_5",
  "x": "While there have been many studies on end-to-end speech recognition using <cite>transformers</cite> [10, 11, 12, 13, 14] , their applications for hybrid acoustic models are less well understood.",
  "y": "motivation"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_6",
  "x": "In this paper, we study the more standard <cite>transformer</cite> for speech recognition within the hybrid framework, and provide further insight to this model through experiments on the Librispeech public dataset.",
  "y": "extends"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_7",
  "x": "There have been a few studies on <cite>transformers</cite> for end-to-end speech recognition, particularly for sequence-to-sequence with attention model [10, 11, 12] , as well as transducer [13] and CTC models [14] .",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_8",
  "x": "In [10] , the authors compared RNNs with <cite>transformers</cite> for various speech recognition and synthesis tasks, and obtained competitive or even better results with <cite>transformers</cite>.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_9",
  "x": "However, the key challenge for <cite>transformer-based sequence-to-sequence model</cite> is to perform online streaming speech recognition, as there is no clear boundary for chunk-wise self-attention.",
  "y": "motivation"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_10",
  "x": "<cite>Transformer</cite> based transducer [13] and CTC model [14] do not have the issue for online speech recognition, however, the results presented in the two studies are not competitive compared the hybrid baseline system from Kaldi [15] .",
  "y": "motivation"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_11",
  "x": "In [16, 17, 18] , self-attention is only applied in a chunk of acoustic input restricted by a time window, which makes the <cite>transformer model</cite> easier to train as it does not need to consider very long term correlations.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_12",
  "x": "While whole sequence-level self-attention has been applied in sequence-to-sequence models [10] , hybrid model is different in the sense that it is required to maintain strict frame-level alignments before performing predictions, which may be challenging for a <cite>transformer</cite> with multiple layers of self-attention as it may reorder the sequence.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_13",
  "x": "Furthermore, lower sampling rates are usually used for <cite>transformer</cite>-based acoustic models, which makes it easier for sequence-level self-attention as the input sequences are much shorter.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_14",
  "x": "We propose an interleaved self-attention and convolution structure for <cite>transformer model</cite>, with the motivation that convolution can learn local feature correlations and maintain the ordering information of the sequence while self-attention can capture longterm correlations.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_16",
  "x": "**<cite>TRANSFORMER</cite>** In this section, we review each component in the standard <cite>transformer model</cite>, and discuss a model structure that is mainly investigated for speech recognition in this work.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_17",
  "x": "In this section, we review each component in the standard <cite>transformer model</cite>, and discuss a model structure that is mainly investigated for speech recognition in this work.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_18",
  "x": "The attention mechanism in <cite>transformer</cite> is technically the same as in the original RNN-based attention model [19] .",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_19",
  "x": "In <cite>[8]</cite> , the authors used the dot-production attention [20] rather than the conventional additive attention [19] in favor of the low computational complexity, which is rewritten here as:",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_20",
  "x": "where Q, K, V are referred to the query, key and value according to <cite>[8]</cite> .",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_21",
  "x": "In <cite>transformer</cite>, both Q and K are from the source sequence, while in the conventional RNN-based attention model [19] , Q is from the decoder hidden state, and K is from the encoder hidden state.",
  "y": "differences"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_22",
  "x": "Another key idea from the <cite>transformer paper</cite> <cite>[8]</cite> is the <cite>multihead attention mechanism</cite>, which performs multiple attention operations in parallel using different model parameters.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_23",
  "x": "For hybrid models, our preliminary experiments show that <cite>transformers</cite> with multiple self-attention layers alone is hard to train without time restriction, and it can easily diverge after a few epochs.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_24",
  "x": "In this paper, we propose a <cite>transformer</cite> model with interleaved 1D convolution and self-attention, with the motivation that the convolution layer can maintain the sequential information of the input sequence, while at the same time, it can learn the local correlations.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_25",
  "x": "Same as the standard <cite>transformer</cite> <cite>[8]</cite> , we also insert the feedforward layer after the multi-head attention.",
  "y": "similarities"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_26",
  "x": "Table 1 shows the number of parameters in each component of the <cite>transformer</cite> model studied in this paper.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_27",
  "x": "To constrain our research scope, we fixed the depth of the <cite>transformer models</cite> to be 6 layers, and the dimension of the model d k in Eq (1) to be 512.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_28",
  "x": "We did not train deeper <cite>transformer models</cite> due to the memory constraint.",
  "y": "differences"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_29",
  "x": "As the memory cost of self-attention is in the order of O(T 2 ), where T is the length of the acoustic sequence, lower frame rate would significantly cut down the memory cost, and enable the training of much deeper <cite>transformer models</cite> that will studied in our future work.",
  "y": "future_work"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_30",
  "x": "Our <cite>transformer</cite> acoustic models were trained using the PyKaldi2 toolbox [22] , which is built on top of Kaldi and PyTorch through the PyKaldi [23] wrapper.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_31",
  "x": "We used the Adam optimizer [24] cross entropy (CE) training, and the same learning rate scheduler as in <cite>[8]</cite> .",
  "y": "similarities"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_32",
  "x": "We first evaluated the positional encoding discussed in section 3.2 and dropout training for the <cite>transformer model</cite>.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_33",
  "x": "Unlike the observations in the area of machine translation, positional encoding did not make a big difference in terms of recognition accuracies for our <cite>transformer models</cite>.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_34",
  "x": "We performed a sanity check by removing the positional encoding when evaluating a <cite>transformer model</cite> trained with positional encoding, and obtained results which are only around 0.1% worse absolute.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_35",
  "x": "As for dropout training, it was pointed out in <cite>[8]</cite> that <cite>transformer model</cite> for sequence to-sequence ASR may suffer from overfitting easily, and regularization such as dropout is important to address such kind of issue.",
  "y": "background"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_36",
  "x": "We then evaluated the impact of the 1D convolution layers in our <cite>transformer</cite> model by removing all the convolution layers.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_37",
  "x": "This corresponds to a vanilla <cite>transformer</cite> as in <cite>[8]</cite> .",
  "y": "similarities"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_38",
  "x": "We also have to insert another layer normalization to the output of the <cite>transformer</cite> before the output linear layer to stabilize the training.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_39",
  "x": "However, this is very challenging for sequenceto-sequence model based on <cite>transformer</cite> as the boundary for each output token is unclear.",
  "y": "motivation"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_40",
  "x": "For faster convergence, we used the <cite>transformer models</cite> with one more layer normalization as in section 4.2, although the offline results on the dev-other and test-other evaluation sets are slightly worse.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_41",
  "x": "The table shows that when we limited the future context information for the <cite>transformer model</cite>, we obtained slightly worse results.",
  "y": "differences"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_42",
  "x": "In Table 5 , we show the sequence training results of the <cite>transformer</cite> model trained with the maximum mutual information (MMI) criterion.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_43",
  "x": "While <cite>transformer</cite> has been very successful in the area of nature language processing, its application to speech recognition is mostly within the end-to-end architecture.",
  "y": "motivation"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_44",
  "x": "We are more interested in <cite>transformers</cite> for hybrid acoustic models as there is no theoretical issues for online streaming speech recognition.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_45",
  "x": "In this paper, we have presented a <cite>transformer</cite> model with interleaved self-attention and convolution for hybrid acoustic modeling, although this structure may be also applicable to end-to-end models.",
  "y": "uses"
 },
 {
  "id": "42854f204c8d2a62822e12f731ad08_46",
  "x": "For our future works, we shall study training much deeper <cite>transformer</cite> with low frame rate to get rid of the GPU memory constraint, as well as evaluate the model in the setting with a very large amount of training data.",
  "y": "future_work"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_0",
  "x": "The principle of dependency length minimization makes conditional predictions, which do not imply that placing heads at the center is optimal in general (Ferreri-Cancho, 2015) . In the context of just one head and at least one dependent, the principle predicts that the central placement of the head is optimal when there are at least two dependents but that placement is irrelevant if there is only one dependent. In the context of an initial verb followed by two arguments (e.g., subject and object), the principle predicts that the heads of the verbal arguments are placed first with respect to their dependents, e.g., articles or adjectives follow the head noun, whereas, for a final verb, the prediction is that the heads of the arguments are placed last with respect to their dependents, e.g. articles or adjectives precede the head noun<cite> (Ferrer-i-Cancho, 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_1",
  "x": "The principle of dependency length minimization predicts consistent branching, to some extent, for verb-first or verb-last placements. 1 If there is one head, the principle predicts a rather symmetric head placement but various heads can lead to an anti-symmetric placement <cite>(Ferrer-i-Cancho, 2015</cite> , 2008 .",
  "y": "background"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_2",
  "x": "An alternative solution is considering the placement of the verb as a parameter. From that single parameter we have shown that it is possible to infer head-final placement within verb arguments in SOV, head-first placement within verb arguments in SVO, head-first placement within verb arguments of VSO/VOS<cite> (Ferrer-i-Cancho, 2015)</cite> and also head first for the placement of inflected auxiliaries in SOV and head-final for their placement in VSO (Ferrer-i-Cancho, 2008 ). However, the predictive power of the position of the verb does not imply that this is a fundamental parameter in a universal grammar sense: verb position might be determined by evolutionary time (e.g., verb-last being more likely in early stages of evolution) or sentence length (e.g., SVO being more likely in languages where speakers produce more elaborate sentences or simply longer sentences) as explained by Ferrer-i-Cancho (2014) .",
  "y": "motivation background"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_3",
  "x": "Fourth, an explanation for the relative placement of verbal auxiliaries given the placement of the main verb <cite>(Ferrer-i-Cancho, 2015</cite> , 2008 would be lost. A theory covering all the phenomena reached originally by the principle of online memory minimization would be heavier.",
  "y": "background"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_4",
  "x": "2 The monotonic dependency between cognitive cost and distance<cite> Ferrer-i-Cancho (2015)</cite> assumes that the cognitive cost of a dependency is a strictly monotonic function of its length.",
  "y": "background"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_5",
  "x": "Third, notice that<cite> Ferrer-i-Cancho (2015)</cite> assumes that the cost of a dependency of length d is g(d). In that setup, the identity of the dependents is irrelevant.",
  "y": "background"
 },
 {
  "id": "42ca932eaa96c174cdfb815bee82cb_6",
  "x": "3 The unit of measurement of dependency length A limitation of<cite> Ferrer-i-Cancho (2015)</cite> is that dependency length is measured in words. However, it could be measured in other linguistic units: syllables, morphemes, phonemes, etc. A higher level of precision might illuminate inconsistencies between the dominant order according to the criteria in Dryer (2013) and other orders that appear recurrently in particular circumstances.",
  "y": "motivation background"
 },
 {
  "id": "43422cf92d8cbb280c0b4c590632f1_0",
  "x": "A strategy to combat uncertainty about neuronal activity is to materialize information by relative values instead of absolute ones. For instance, this is the way that sparse associative memories based on neural cliques [11] are recovered through the Winner-Takes-All (WTA) mechanism which has shown high biological plausibility [12] . Furthermore, the WTA principle is applied in several studies [13, 14,<cite> 15]</cite> for increase activation sparseness in neural networks.",
  "y": "background"
 },
 {
  "id": "43422cf92d8cbb280c0b4c590632f1_1",
  "x": "Recent work has started to address as well the problematic of memory footprint when learning word embeddings [20,<cite> 15]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "43422cf92d8cbb280c0b4c590632f1_2",
  "x": "In order to mitigate such an issue, <cite>[15]</cite> proposed a method that learns multi-codebook. Therefore, each word is now represented by a hash code of discrete numbers, that have to be defined in a way that similar words will have similar representations as well as a factor of difference, to capture nuances.",
  "y": "background future_work"
 },
 {
  "id": "43422cf92d8cbb280c0b4c590632f1_3",
  "x": "Presenting a different use for the previous work done by the field of codebooks compression based source coding, known as product quantization (PQ) [21] and additive quantization [22] , they show that by minimizing the squared distance between both distributions (baseline and composed embeddings), and using a direct learning approach for the codes in an end-to-end neural network, with a Gumbel-softmax layer [23] to encourage the discreteness <cite>[15]</cite> , it is possible to construct the word embeddings radically reducing the number of parameters without hurting performance. These word codebooks are learned using a local WTA rule in the hidden layer of an autoencoder neural network.",
  "y": "background"
 },
 {
  "id": "43422cf92d8cbb280c0b4c590632f1_4",
  "x": "For the sake of simplicity, we adopted the same architecture as <cite>[15]</cite> , as shown in Fig. 2 .",
  "y": "uses"
 },
 {
  "id": "43422cf92d8cbb280c0b4c590632f1_5",
  "x": "Our framework is an extension of <cite>[15]</cite> work to deal with latent representations of contextual pretrained LM.",
  "y": "extends"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_0",
  "x": "Since manual classification is costly (Kipper et al., 2008) automatic approaches have been proposed recently which could be used to learn novel classifications in a cost-effective manner (Joanis et al., 2008; Li and Brew, 2008; \u00d3 S\u00e9aghdha and Copestake, 2008; Vlachos et al., 2009;<cite> Sun and Korhonen, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_1",
  "x": "We take a recent verb clustering approach developed for English <cite>(Sun and Korhonen, 2009</cite> ) and apply it to French -a major language for which no such experiment has been conducted yet.",
  "y": "uses"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_2",
  "x": "Systems similar to ASSCI have been used in recent verb classification works e.g. (Schulte im Walde, 2006; Li and Brew, 2008;<cite> Sun and Korhonen, 2009</cite> ).",
  "y": "similarities"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_3",
  "x": "We adopt a fully unsupervised approach to SP acquisition using the method of<cite> Sun and Korhonen (2009)</cite> , with the difference that we determine the optimal number of SP clusters automatically following Zelnik-Manor and Perona (2004) .",
  "y": "extends differences"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_4",
  "x": "Spectral clustering (SPEC) has proved promising in previous verb clustering experiments (Brew and Schulte im Walde, 2002;<cite> Sun and Korhonen, 2009</cite> ) and other similar NLP tasks involving high dimensional feature space (Chen et al., 2006) .",
  "y": "background"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_5",
  "x": "Following<cite> Sun and Korhonen (2009)</cite> we used the MNCut spectral clustering (Meila and Shi, 2001 ) which has a wide applicability and a clear probabilistic interpretation (von Luxburg, 2007; Verma and Meila, 2005) .",
  "y": "similarities uses"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_6",
  "x": "We employ the same measures for evaluation as previously employed e.g. by\u00d3 S\u00e9aghdha and Copestake (2008) and<cite> Sun and Korhonen (2009)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_7",
  "x": "The 4th column of the table shows, for comparison, the results of<cite> Sun and Korhonen (2009)</cite> obtained for English when they used the same features as us, clustered them using SPEC, and evaluated them against the English version of our gold standard, also using F-measure 2 .",
  "y": "similarities"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_8",
  "x": "Those results suggest that when 2000 or more occurrences per verb are used, most features perform like they performed for English in the experiment of<cite> Sun and Korhonen (2009)</cite> which is not typical to many other classes.",
  "y": "similarities"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_9",
  "x": "When considering the general level of performance, our best performance for French (65.4 F) is lower than the best performance for English in the experiment of<cite> Sun and Korhonen (2009)</cite> .",
  "y": "differences"
 },
 {
  "id": "43a52325987ea035136a6a718389d9_10",
  "x": "However, parser and feature extraction performance can also play a big role in overall accuracy, and should therefore be investigated further <cite>(Sun and Korhonen, 2009</cite> ).",
  "y": "future_work"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_0",
  "x": "Recent research in the area of unit segmentation (Eger et al., 2017;<cite> Ajjour et al., 2017)</cite> has lead to promising results with F1-scores of up to 0.90 for in-domain segmentation (Eger et al., 2017) .",
  "y": "background"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_1",
  "x": "Further, <cite>Ajjour et al. (2017)</cite> proposed a setup with three bidirectional LSTMs (Bi-LSTMs) (Schuster and Paliwal, 1997) in total as their best solution.",
  "y": "background"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_2",
  "x": "This framework has been applied previously for the same task (Stab, 2017; Eger et al., 2017;<cite> Ajjour et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_3",
  "x": "The architectures proposed in this section build on <cite>Ajjour et al. (2017)</cite> , omitting the second Bi-LSTM, which was used to process features other than word embeddings (see section 3.1).",
  "y": "extends differences"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_4",
  "x": "Baseline re-implementation The baseline model from <cite>Ajjour et al. (2017)</cite> uses a total of three Bi-LSTMs (two of them fully connected) to assign labels to tokens (see Figure 1a) .",
  "y": "similarities uses"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_5",
  "x": "According to <cite>Ajjour et al. (2017)</cite> , the latter Bi-LSTM is used to correct the errors of the first one.",
  "y": "similarities"
 },
 {
  "id": "44916cd85311c78666839a3376ccc6_6",
  "x": "For our re-implementation of the baseline, we are able to approximately reproduce the results reported by <cite>Ajjour et al. (2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_0",
  "x": "Research in automatic summarization has made headway over the years with single document summarization as the front-runner due to the availability of large datasets (Sandhaus, 2008; Hermann et al., 2015;<cite> Narayan et al., 2018b)</cite> which has enabled the development of novel methods, many of them employing recent advances in neural networks (See et al., 2017; Narayan et al., 2018c; , inter alia).",
  "y": "background"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_1",
  "x": "Those that conduct manual assessment of the content, typically use a single reference summary, either directly (Celikyilmaz et al., 2018; Tan et al., 2017) or through questions <cite>(Narayan et al., 2018b</cite>,c) and thus are also likely to exhibit reference bias.",
  "y": "background"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_2",
  "x": "Those that conduct manual assessment of the content, typically use a single reference summary, either directly (Celikyilmaz et al., 2018; Tan et al., 2017) or through questions <cite>(Narayan et al., 2018b</cite>,c) and thus are also likely to exhibit reference bias. In this paper we propose a novel approach for manual evaluation, HIGHlight-based Referenceless Evaluation of document Summarization (HIGHRES), in which a summary is assessed against the source document via manually highlighted salient content in the latter (see Figure 1 for an example).",
  "y": "differences"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_3",
  "x": "To validate our proposed approach we use the recently introduced eXtreme SUMmarization dataset (XSUM,<cite> Narayan et al., 2018b)</cite> to evaluate two state-of-the-art abstractive summarization methods, Pointer Generator Networks (See et al., 2017) and Topic-aware Convolutional Networks<cite> (Narayan et al., 2018b)</cite> , using crowd-sourcing for both highlight annotation and quality judgments.",
  "y": "uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_4",
  "x": "Evaluation Metrics Despite differences in the exact definitions, the majority (e.g., Hsu et al., 2018; Celikyilmaz et al., 2018;<cite> Narayan et al., 2018b</cite>; Chen and Bansal, 2018; Peyrard and Gurevych, 2018) agree on both or either one of two broad quality definitions: coverage determines how much of the salient content of the source document is captured in the summary, and informativeness, how much of the content captured in the summary is salient with regards to the original document.",
  "y": "background"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_5",
  "x": "Clarke and Lapata (2010) proposed a question-answering based approach to improve the agreement among human evaluations for the quality of summary content, which was recently employed by<cite> Narayan et al. (2018b)</cite> and Narayan et al. (2018c) (QA in Table 1 ).",
  "y": "background"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_6",
  "x": "Most recent work uses a single human judgment to capture all linguistic qualities of the summary (Hsu et al., 2018; Kry\u015bci\u0144ski et al., 2018;<cite> Narayan et al., 2018b</cite>; Song et al., 2018; Guo et al., 2018) ; we group them under \"Fluency\" in Table 1 with an exception of \"Clarity\" which was evaluated in the DUC evaluation campaigns (Dang, 2005) .",
  "y": "uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_7",
  "x": "Absolute assessment was also employed in combination with the question answering approach for content evaluation <cite>(Narayan et al., 2018b</cite>; Mendes et al., 2019) .",
  "y": "uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_8",
  "x": "However, summarization datasets are limited to a single reference summary per document (Sandhaus, 2008; Hermann et al., 2015; Grusky et al., 2018;<cite> Narayan et al., 2018b)</cite> thus evaluations using them is prone to reference bias (Louis and Nenkova, 2013) , also a known issue in machine translation evaluation (Fomicheva and Specia, 2016) .",
  "y": "motivation"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_9",
  "x": "We use the extreme summarization dataset (XSUM,<cite> Narayan et al., 2018b)</cite> 2 which comprises BBC articles paired with their singlesentence summaries, provided by the journalists writing the articles.",
  "y": "uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_10",
  "x": "Following<cite> Narayan et al. (2018b)</cite> , we didn't use the whole test set portion, but sampled 50 articles from it for our highlight-based evaluation.",
  "y": "uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_11",
  "x": "We assessed summaries from two state-ofthe-art abstractive summarization systems using our highlight-based evaluation: (i) the PointerGenerator model (PTGEN) introduced by See et al. (2017) is an RNN-based abstractive systems which allows to copy words from the source text, and (ii) the Topic-aware Convolutional Sequence to Sequence model (TCONVS2S) introduced by<cite> Narayan et al. (2018b)</cite> is an abstractive model which is conditioned on the article's topics and based entirely on Convolutional Neural Networks.",
  "y": "uses"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_12",
  "x": "The superiority of TCONVS2S is expected; TCONVS2S is better than PTGEN for recognizing pertinent content and generating informative summaries due to its ability to represent high-level document knowledge in terms of topics and long-range dependencies<cite> (Narayan et al., 2018b)</cite> .",
  "y": "similarities"
 },
 {
  "id": "45238fe9b493ccdf5921c8f5284097_13",
  "x": "When comparing the reference summaries against the original documents, both ROUGE and HROUGE confirm that the reference summaries are rather abstractive as reported by<cite> Narayan et al. (2018b)</cite> , and they in fact score below the system summaries.",
  "y": "similarities"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_0",
  "x": "To model homophily, recent research in abusive language detection on Twitter<cite> (Mishra et al., 2018a)</cite> incorporates embeddings for authors (i.e., users who have composed tweets) that encode the structure of their surrounding communities.",
  "y": "background"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_1",
  "x": "Qian et al. (2018) Following previous work<cite> (Mishra et al., 2018a)</cite> , we experiment with a subset of the Twitter dataset compiled by Waseem and Hovy (2016",
  "y": "uses"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_2",
  "x": "We create two different graphs: the first one is identical to the community graph of <cite>Mishra et al. (2018a)</cite> (referred to as the community graph).",
  "y": "uses similarities"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_3",
  "x": "We first describe the approach of <cite>Mishra et al. (2018a)</cite> that learns author embeddings using node2vec (Grover and Leskovec, 2016) ; this serves as our baseline.",
  "y": "uses background"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_4",
  "x": "Following <cite>Mishra et al. (2018a)</cite> , we initialize these parameters to their default value of 1 and set the embedding size and number of iterations to 200 and 25 respectively.",
  "y": "uses"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_5",
  "x": "This is the state of the art method<cite> (Mishra et al., 2018a)</cite> for the dataset we are using.",
  "y": "background"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_6",
  "x": "However, on the racism class, its recall is hindered by the same factor that <cite>Mishra et al. (2018a)</cite> highlighted for their node2vec-only method, i.e., that racist tweets come from 5 unique authors only who have also contributed sexist or clean tweets.",
  "y": "similarities"
 },
 {
  "id": "45551e674210bb9bbb56c8778d2f8c_7",
  "x": "In this paper, we built on the work of <cite>Mishra et al. (2018a)</cite> that introduces community-based profiling of authors for abusive language detection.",
  "y": "extends"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_0",
  "x": "We propose a variant of a well-known machine translation (MT) evaluation metric, HyTER <cite>(Dreyer and Marcu, 2012)</cite> , which exploits reference translations enriched with meaning equivalent expressions.",
  "y": "extends"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_1",
  "x": "We propose a variant of a well-known machine translation (MT) evaluation metric, HyTER <cite>(Dreyer and Marcu, 2012)</cite> , which exploits reference translations enriched with meaning equivalent expressions. We test, for the first time, <cite>HyTER</cite> with automatically built paraphrase lattices.",
  "y": "uses"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_2",
  "x": "We propose a variant of a well-known machine translation (MT) evaluation metric, HyTER <cite>(Dreyer and Marcu, 2012)</cite> , which exploits reference translations enriched with meaning equivalent expressions. The original <cite>HyTER metric</cite> relied on hand-crafted paraphrase networks which restricted its applicability to new data.",
  "y": "extends motivation"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_3",
  "x": "We propose a variant of a well-known machine translation (MT) evaluation metric, HyTER <cite>(Dreyer and Marcu, 2012)</cite> , which exploits reference translations enriched with meaning equivalent expressions. We show that although <cite>the metric</cite> obtains good results on small and carefully curated data with both manually and automatically selected substitutes, it achieves medium performance on much larger and noisier datasets, demonstrating the limits of <cite>the metric</cite> for tuning and evaluation of current MT systems.",
  "y": "extends motivation"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_4",
  "x": "The HyTER metric <cite>(Dreyer and Marcu, 2012 )</cite> relies on massive reference networks encoding an exponential number of correct translations for parts of a given sentence, proposed by human annotators.",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_5",
  "x": "The HyTER metric <cite>(Dreyer and Marcu, 2012 )</cite> relies on massive reference networks encoding an exponential number of correct translations for parts of a given sentence, proposed by human annotators. The manually built networks attempt to encode the set of all correct translations for a sentence, and <cite>HyTER</cite> rewards high quality hypotheses by measuring their minimum edit distance to the set of possible translations.",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_6",
  "x": "The HyTER metric <cite>(Dreyer and Marcu, 2012 )</cite> relies on massive reference networks encoding an exponential number of correct translations for parts of a given sentence, proposed by human annotators. <cite>HyTER</cite> spurred a lot of enthusiasm but the need for human annotations heavily reduced its applicability to new data.",
  "y": "motivation"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_7",
  "x": "<cite>HyTER</cite> spurred a lot of enthusiasm but the need for human annotations heavily reduced its applicability to new data. We propose to use an embedding-based lexical substitution model (Melamud et al., 2015) for building this type of reference networks and test, for the first time, the metric with automatically generated lattices (hereafter HyTERA). We show that HyTERA strongly correlates with <cite>HyTER</cite> with hand-crafted lattices, and approximates the hTER score (Snover et al., 2006) as measured using post-edits made by human annotators.",
  "y": "similarities uses"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_8",
  "x": "<cite>HyTER</cite> spurred a lot of enthusiasm but the need for human annotations heavily reduced its applicability to new data. We propose to use an embedding-based lexical substitution model (Melamud et al., 2015) for building this type of reference networks and test, for the first time, the metric with automatically generated lattices (hereafter HyTERA). Furthermore, we generate lattices for standard datasets from a recent WMT Metrics Shared Task and perform the first evaluation of <cite>HyTER</cite> on large and noisier datasets.",
  "y": "uses"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_9",
  "x": "The HyTER metric <cite>(Dreyer and Marcu, 2012)</cite> computes the similarity between a translation hypothesis and a reference lattice that compactly encodes millions of meaning-equivalent translations.",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_10",
  "x": "The HyTER metric <cite>(Dreyer and Marcu, 2012)</cite> computes the similarity between a translation hypothesis and a reference lattice that compactly encodes millions of meaning-equivalent translations. Formally <cite>HyTER</cite> is defined as: where Y is a set of references that can be encoded as a finite state automaton such as the one represented in Figure 1 , x is a translation hypothesis and LS is the standard Levenshtein distance, defined as the minimum number of substitutions, deletions and insertions required to transform x into y. We use, in all our experiments, our own im-plementation of <cite>HyTER</cite> 1 that relies on the Open-FST framework (Allauzen et al., 2007) .",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_11",
  "x": "Formally <cite>HyTER</cite> is defined as: where Y is a set of references that can be encoded as a finite state automaton such as the one represented in Figure 1 , x is a translation hypothesis and LS is the standard Levenshtein distance, defined as the minimum number of substitutions, deletions and insertions required to transform x into y. We use, in all our experiments, our own im-plementation of <cite>HyTER</cite> 1 that relies on the Open-FST framework (Allauzen et al., 2007) .",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_12",
  "x": "Contrary to the original <cite>HyTER</cite> implementation, we do not consider permutations when transforming x into y as previous results (cf. Table 3 in <cite>(Dreyer and Marcu, 2012)</cite> ) have shown that permutations have only very little impact while significantly increasing the computational complexity of <cite>HyTER</cite> computation.",
  "y": "extends differences"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_13",
  "x": "<cite>The HyTER metric</cite> has already been successfully used in MT evaluation but only with handcrafted lattices.",
  "y": "differences background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_14",
  "x": "We first use the setting of <cite>Dreyer and Marcu (2012)</cite> , in Section \u00a7 5.1, to compare the score estimated by <cite>HyTER</cite> and HyTERA to hTER scores.",
  "y": "uses differences"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_15",
  "x": "To evaluate the performance of HyTER, <cite>Dreyer and Marcu (2012)</cite> examine whether it can approximate the hTER score (Snover et al., 2006) that measures the number of edits required to change a system output into its post-edition.",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_16",
  "x": "<cite>Dreyer and Marcu (2012)</cite> show that it can be closely approximated by <cite>HyTER</cite> scores.",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_17",
  "x": "We propose to use an embedding-based lexical substitution model (Melamud et al., 2015) for building this type of reference networks and test, for the first time, the metric with automatically generated lattices (hereafter HyTERA). 9 In all cases, there is a high correlation between <cite>HyTER</cite>, HyTERA and hTER, significantly higher than the correlation between BLEU and hTER.",
  "y": "similarities"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_18",
  "x": "This observation shows that replacing the handcrafted lattices with automatically built ones has only a moderate impact on the H<cite>yTER</cite> metric quality: automatic lattices result in a small drop of the correlation when evaluating hypotheses translated from Chinese, and slightly improve it for the Arabic to English condition.",
  "y": "extends similarities"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_19",
  "x": "We propose to use an embedding-based lexical substitution model (Melamud et al., 2015) for building this type of reference networks and test, for the first time, the metric with automatically generated lattices (hereafter HyTERA). Overall HyTERA scores are highly correlated with <cite>HyTER</cite> scores (\u03c1 = 0.766 for Arabic and \u03c1 = 0.756 for Chinese).",
  "y": "similarities"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_20",
  "x": "Overall HyTERA scores are highly correlated with <cite>HyTER</cite> scores (\u03c1 = 0.766 for Arabic and \u03c1 = 0.756 for Chinese).",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_21",
  "x": "9 In all cases, there is a high correlation between <cite>HyTER</cite>, HyTERA and hTER, significantly higher than the correlation between BLEU and hTER.",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_22",
  "x": "Note that the tested systems were selected by NIST to cover a variety of system architectures (statistical, rule-based, hybrid) and performances <cite>(Dreyer and Marcu, 2012)</cite> , which makes distinction between them an easy task for all metrics.",
  "y": "uses"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_23",
  "x": "All metrics rank the systems in the same order, except from <cite>HyTER</cite> with allParsFiltered that only inverts two systems.",
  "y": "similarities"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_24",
  "x": "The benefits of using a metric like <cite>HyTER</cite>, which focuses on the word level, are much clearer in the sentence-based evaluation (Table 2) .",
  "y": "motivation"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_25",
  "x": "HyTERA obtains medium performance on the WMT16 dataset, which is much larger and noisier than the dataset used for evaluation in <cite>(Dreyer and Marcu, 2012)</cite> : it is made, for each language, of 560 translations sampled from outputs of all systems taking part in the WMT15 campaign.",
  "y": "differences"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_26",
  "x": "It is important to note that the hTER scores used in the initial <cite>HyTER</cite> evaluation were produced by experienced LDC annotators, while the WMT16 Direct Assessment (DA) adequacy judgments were collected from non-experts through crowd-sourcing (Bojar et al., 2016) .",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_27",
  "x": "While in the <cite>(Dreyer and Marcu, 2012)</cite> evaluation, the systems came from the 2010 Open MT NIST evaluation and were selected to cover a variety of architectures and performances, the systems that participated in WMT15 are, for the large part, neural MT systems (Bojar et al., 2015) .",
  "y": "background"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_28",
  "x": "While in the <cite>(Dreyer and Marcu, 2012)</cite> evaluation, the systems came from the 2010 Open MT NIST evaluation and were selected to cover a variety of architectures and performances, the systems that participated in WMT15 are, for the large part, neural MT systems (Bojar et al., 2015) . As reported by Bentivogli et al. (2016) , Neural MT systems make at least 17% fewer lexical choice errors than phrase-based systems, which limits the potential of HyTERA, primarily focused on capturing correct lexical choice.",
  "y": "differences"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_29",
  "x": "We have proposed a method for automatic paraphrase lattice creation which makes the H<cite>yTER metric</cite> applicable to new datasets.",
  "y": "extends"
 },
 {
  "id": "45ba2841e91a2fd62f0534aeaf7491_30",
  "x": "We provide the first evaluation of <cite>HyTER</cite> on data from a recent WMT Metrics Shared task.",
  "y": "uses"
 },
 {
  "id": "45c4e9bc90d28cd1a5a61393625062_0",
  "x": "More recently, and departing from such traditional approaches, we have proposed in<cite> (Li and Gaussier, 2010)</cite> an approach based on improving the comparability of the corpus under consideration, prior to extracting bilingual lexicons.",
  "y": "background"
 },
 {
  "id": "45c4e9bc90d28cd1a5a61393625062_1",
  "x": "In order to measure the degree of comparability of bilingual corpora, we make use of the measure M developed in<cite> (Li and Gaussier, 2010)</cite> : Given a comparable corpus P consisting of an English part P e and a French part P f , the degree of comparability of P is defined as the expectation of finding the translation of any given source/target word in the target/source corpus vocabulary.",
  "y": "uses"
 },
 {
  "id": "45c4e9bc90d28cd1a5a61393625062_2",
  "x": "In our experiments, we use the method described in this paper, as well as the one in<cite> (Li and Gaussier, 2010)</cite> which is the only alternative method to enhance corpus comparability.",
  "y": "uses"
 },
 {
  "id": "45c4e9bc90d28cd1a5a61393625062_3",
  "x": "As mentioned before, we also used the method described in<cite> (Li and Gaussier, 2010)</cite> on the same data, producing resulting corpora P 1 (with P 1 T ) and P 2 (with P 2 T ) from P 0 .",
  "y": "uses"
 },
 {
  "id": "45c4e9bc90d28cd1a5a61393625062_4",
  "x": "In a first series of experiments, bilingual lexicons were extracted from the corpora obtained by our approach (P 1 and P 2 ), the corpora obtained by the approach described in <cite>(Li and Gaussier, 2010</cite> ) (P 1 and P 2 ) and the original corpus P 0 , with the fixed N value set to 20.",
  "y": "uses"
 },
 {
  "id": "45c4e9bc90d28cd1a5a61393625062_5",
  "x": "We have followed here the general approach in<cite> (Li and Gaussier, 2010)</cite> which consists in enhancing the quality of a comparable corpus prior to extracting information from it.",
  "y": "uses"
 },
 {
  "id": "45d4d6f0ac4a4f3bf7b2ac70fbcf7f_0",
  "x": "The sample in Figure 1 from MSDialog-Intent corpus <cite>[14]</cite> discusses a technical issue with Microsoft Bingo among two users (U 1 & U 2) and two agents (A1 & A2).",
  "y": "background"
 },
 {
  "id": "45d4d6f0ac4a4f3bf7b2ac70fbcf7f_1",
  "x": "Qu et al. <cite>[14]</cite> apply a CNN-based text classifier proposed by Kim [8] using a fixed window to represent the context.",
  "y": "background"
 },
 {
  "id": "45d4d6f0ac4a4f3bf7b2ac70fbcf7f_2",
  "x": "Although capable of classifying utterances with CDAs, Qu et al. <cite>[14]</cite> 's model only concerns a strictly-local context range and thus cannot include distant information. In this paper, we present a novel neural model that is adapted from Convolutional Recurrent Neural Network (CRNN) to both incorporate the interaction between distant utterances and generalize the DA recognition task to accommodate CDA.",
  "y": "motivation"
 },
 {
  "id": "45d4d6f0ac4a4f3bf7b2ac70fbcf7f_3",
  "x": "We use the MSDialog-Intent dataset <cite>[14]</cite> to conduct experiments.",
  "y": "uses"
 },
 {
  "id": "45d4d6f0ac4a4f3bf7b2ac70fbcf7f_4",
  "x": "Besides, unlike Qu et al. <cite>[14]</cite> , we keep all the DA annotations in the dataset to preserve the meaningful DA structures within and across utterances.",
  "y": "differences"
 },
 {
  "id": "45d4d6f0ac4a4f3bf7b2ac70fbcf7f_7",
  "x": "Following previous work <cite>[14]</cite> on multi-label classification, we adopt label-based accuracy (i.e., Hamming score) and micro-F 1 score as our main evaluation metrics.",
  "y": "uses"
 },
 {
  "id": "460b820360d51d99b4a7ae3f0755bc_0",
  "x": "Firstly WSD tasks before 2013 generally relied on only a lexicon, such as WordNet (Fellbaum, 1998) or an alternative equivalent, whereas SemEval 2013 Task 12 WSD and this task <cite>(Moro and Navigli, 2015)</cite> included Entity Linking (EL) using the encyclopaedia Wikipedia via BabelNet (Navigli and Ponzetto, 2012) .",
  "y": "background"
 },
 {
  "id": "460b820360d51d99b4a7ae3f0755bc_1",
  "x": "Yet it is worth noting the results of the task paper <cite>(Moro and Navigli, 2015)</cite> report that SUDOKU Run2 and Run3 achieved very low F-Scores for named entity disambiguation (<28.6) in Spanish and Italian.",
  "y": "background"
 },
 {
  "id": "460b820360d51d99b4a7ae3f0755bc_2",
  "x": "The author's baseline-independent submissions were unaffected by this, which on reviewing results in <cite>(Moro and Navigli, 2015)</cite> appears to have helped SUDOKU do best for these languages.",
  "y": "background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_0",
  "x": "In practice, current statistical parsers do not encode LDD directly, as illustrated in Figure 2 , and leave it to post-processing procedures to recover the LDD relation (Johnson, 2002;<cite> Nivre et al., 2010)</cite> . These approaches exploit the very strong constraints that govern long-distance relations syntactically, and ignore the full or partial recovery of the semantic roles entirely.",
  "y": "motivation background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_1",
  "x": "This figure illustrates the Stanford dependency representation that was used in Rimmel et al. (2009), and<cite> Nivre et al. (2010)</cite> , indicating below the sentence the long distance dependency that needs to be recovered, but that is not in the representation.",
  "y": "background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_2",
  "x": "Compared to the other statistical dependency parsers, questions (OQ) are not well represented in our training data, since they do not include the additional QB data<cite> (Nivre et al., 2010)</cite> used to improve the performance of MSTParser and MaltParser.",
  "y": "background differences"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_3",
  "x": "Like the dependency parser in<cite> Nivre et al. (2010)</cite> , the parser was not trained on the same data or tree representations as those used in the test data.",
  "y": "similarities"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_4",
  "x": "Unlike<cite> Nivre et al. (2010)</cite> , we did not use an external part-of-speech tagger to annotate the data of the development set. To minimize preprocessing of the data, we choose to have part-ofspeech tagging as an internal part of the parsing model, which therefore, takes raw input.",
  "y": "differences"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_6",
  "x": "Like in previous papers (Rimell et al., 2009;<cite> Nivre et al., 2010)</cite> , we evaluate the parser on its ability to recover LDDs. Two evaluations were done. The first one was semi-automatic, performed with a modified version of the evaluation script developed in Rimell et al. (2009) . An independent manual evaluation was also performed.",
  "y": "similarities"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_7",
  "x": "Both previous evaluation exercises (Rimell et al., 2009;<cite> Nivre et al., 2010)</cite> suggest some avenues to relax the matching conditions, and define equivalence classes of representations.",
  "y": "background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_8",
  "x": "To relax the requirement of exact match on the definition of arc, a set of equivalence classes between single arcs and paths connecting two nodes indirectly is precisely defined in the post-processing scheme of<cite> Nivre et al. (2010)</cite> , which applies to the Stanford labelling scheme.",
  "y": "background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_9",
  "x": "In<cite> Nivre et al. (2010)</cite> , the encoding of long-distance dependencies in a dependency parser is categorised as simple, complex, and indirect. In the simple case, the LDD coincides with an arc in a tree. In the complex case, the LDD is represented by a path of arcs. In the indirect case, the dependency is not directly encoded in a path in the tree, but it must be inferred from a larger portion of the tree using heuristics. The two last cases require post-processing of the tree.",
  "y": "background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_10",
  "x": "Following<cite> Nivre et al. (2010)</cite> , we define a longdistance dependency as simple or complex. In the simple case, the LDD coincides with an arc in a tree. A complex dependency is defined as a path of at most two simple dependencies.",
  "y": "similarities"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_11",
  "x": "Automatic and manual results (percent recall) are shown in Table 1 , where we compare our results to the relevant ones of those reported in previous evaluations (Rimell et al., 2009; <cite>Nivre et al., 2010</cite>; Nguyen et al., 2012) .",
  "y": "background"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_12",
  "x": "9 Like the other parsers discussed in Rimell et al. (2009) and<cite> Nivre et al. (2010)</cite> , the overall performance on these long-distance constructions is much lower than the overall scores for this parser. However, the parser recovers long-distance dependencies at least as well as standard statistical dependency parsers that use a post-processing step, and better than standard statistical parsers.",
  "y": "similarities differences"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_13",
  "x": "We classify the errors made by our parser on the development set based on<cite> Nivre et al. (2010)</cite> one which occurs when the parser fails to assign the correct functional relation (e.g., subject, object), while a Sem error is one in which the parser fails to assign the correct semantic relation (e.g., A1, A2).",
  "y": "uses"
 },
 {
  "id": "46a23364b7bc51493d83f874a824ad_14",
  "x": "Questions (OQ) are not well represented in our training data, since they do not include the additional QB data<cite> (Nivre et al., 2010)</cite> used to improve the performance of MSTParser and MaltParser (see Table 4 for comparison of number of errors for each parser).",
  "y": "differences"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_0",
  "x": "The syntactic features provide an additional 0.3% reduction in test-set error rate beyond the model of (Roark et al., 2004a;<cite> Roark et al., 2004b</cite> ) (significant at p < 0.001), which makes use of a discriminatively trained n-gram model, giving a total reduction of 1.2% over the baseline Switchboard system.",
  "y": "differences"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_1",
  "x": "We build on the work in Roark et al. (2004a;<cite> 2004b)</cite> , which was summarized and extended in Roark et al. (2005) .",
  "y": "extends"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_2",
  "x": "Previous work (Roark et al., 2004a;<cite> Roark et al., 2004b)</cite> has shown that discriminative methods within an ngram approach can lead to significant reductions in WER, in spite of the features being of the same type as the original language model.",
  "y": "similarities"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_3",
  "x": "We follow the framework of Collins (2002; 2004) , recently applied to language modeling in Roark et al. (2004a;<cite> 2004b)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_4",
  "x": "As one example, the language modeling features might take into account n-grams, for example through definitions such as \u03a6 2 (a, w) = Count of the the in w Previous work (Roark et al., 2004a;<cite> Roark et al., 2004b</cite> ) considered features of this type.",
  "y": "background"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_5",
  "x": "We briefly review the two training algorithms described in<cite> Roark et al. (2004b)</cite> , the perceptron algorithm and global conditional log-linear models (GCLMs).",
  "y": "similarities uses"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_6",
  "x": "A second parameter estimation method, which was used in <cite>(Roark et al., 2004b)</cite> , is to optimize the log-likelihood under a log-linear model.",
  "y": "extends differences"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_7",
  "x": "A number of results-e.g., in Sha and Pereira (2003) and<cite> Roark et al. (2004b)</cite> -suggest that the GCLM approach leads to slightly higher accuracy than the perceptron training method.",
  "y": "background"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_8",
  "x": "The experimental set-up we use is very similar to that of Roark et al. (2004a;<cite> 2004b)</cite> , and the extensions to that work in Roark et al. (2005) .",
  "y": "similarities uses"
 },
 {
  "id": "46b9079fb1dd6b4626f20819ccfa07_9",
  "x": "In addition, we plan to explore the alternative parameter estimation methods described in (Roark et al., 2004a;<cite> Roark et al., 2004b)</cite> , which were shown in this previous work to give further improvements over the perceptron.",
  "y": "future_work"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_0",
  "x": "Given our interest in the analysis of multi-party dialogues, we used the STAC corpus of multiparty chats, an initial version of which is described in (Afantenos et al., 2015;<cite> Perret et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_1",
  "x": "To compare our approach to earlier efforts, we also used the corpus from<cite> (Perret et al., 2016)</cite> . This corpus was also useful to check for over fitting of our Generative model developed on the multi-modal data. The corpus from<cite> (Perret et al., 2016)</cite> is an early version of a \"linguistic only\" version of the STAC corpus. It contains no nonlinguistic DUs, unlike the STAC multimodal corpus. 3 It also contains quite a few errors; for example, about 60 stories in the<cite> (Perret et al., 2016)</cite> dataset have no discourse structure in them at all and consist of only one DU.",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_2",
  "x": "3 It also contains quite a few errors; for example, about 60 stories in the<cite> (Perret et al., 2016)</cite> dataset have no discourse structure in them at all and consist of only one DU. We eliminated these from the Perret 2016 data set that we used in our comparative experiments below, as these sto-3 There is also on the STAC website an updated linguistic only version of the STAC corpus.",
  "y": "differences"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_3",
  "x": "The dataset from<cite> (Perret et al., 2016)</cite> is similar to our linguistic only STAC corpus but is still substantially different and degraded in quality.",
  "y": "similarities"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_4",
  "x": "report significant error rates in annotation on the earlier versions of the STAC corpus and that the current linguistic only corpus of STAC offers an improvement over the<cite> (Perret et al., 2016)</cite> corpus.",
  "y": "differences"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_5",
  "x": "3. Following (Muller et al., 2012;<cite> Perret et al., 2016)</cite> we \"flatten\" CDUs by connecting all relations incoming or outgoing from a CDU to the \"head\" of the CDU, or its first DU.",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_6",
  "x": "We also performed these operations on our version of the linguistic only corpus used by<cite> (Perret et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_7",
  "x": "LFs also exploit information about the DUs' linguistic or non-linguistic status, the dialogue acts they express, their lexical content, grammatical category and speaker, and the distance between them-features also used in supervised learning methods <cite>(Perret et al., 2016</cite>; Afantenos et al., 2015; Muller et al., 2012) .",
  "y": "background"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_8",
  "x": "As in previous work (Muller et al., 2012; Afantenos et al., 2015;<cite> Perret et al., 2016)</cite> , we use the Maximum Spanning Tree (MST) algorithm, and a variation thereof, to ensure that the dialogue structures predicted conform to some more general structural principle.",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_9",
  "x": "Since SDRT structures can contain nodes with multiple incoming relations, i.e. are not always tree-like, we altered the MST algorithm in the manner of (Muller et al., 2012; Afantenos et al., 2015;<cite> Perret et al., 2016)</cite> , forcing the MST to include all high-probability incoming relations which do not create cycles.",
  "y": "extends"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_10",
  "x": "We also implemented BERT+LogReg*, a learning algorithm that uses BERT's encodings together with a Logistic Regression classifier trained on STAC's gold data with handcrafted features from (Afantenos et al., 2015) and used in<cite> (Perret et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_11",
  "x": "Finally, we wanted to see how GEN and our other models fared on our version of the (Perret<cite> (Perret et al., 2016)</cite> data set, GEN has higher scores than LogReg*'s local model; but with a decoding mechanism similar to that reported in<cite> (Perret et al., 2016)</cite> , Lo-gReg*'s global model significantly improves over the GEN's.",
  "y": "uses"
 },
 {
  "id": "46faad9d86cda118df5eb9c1e7df65_12",
  "x": "Note, however, that even on the<cite> (Perret et al., 2016)</cite> data set, the MST decoding mechanism provided LogReg* only a boost of 12 F1 points, as seen in Table 4 , which is significantly lower than what is reported in<cite> (Perret et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_0",
  "x": "Unsupervised speech representation learning [2, 3, 4, 5, <cite>6,</cite> 7, 8, 9, 10] is effective in extracting high-level properties from speech.",
  "y": "background"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_1",
  "x": "Autoregressive Predictive Coding (APC)<cite> [6]</cite> uses autoregressive models to encode temporal information of past acoustic sequences; the model predicts future frames like an RNN-based language model [11] , optimized with reconstruction loss.",
  "y": "background"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_2",
  "x": "Unidirectional models are commonly used in the previous approaches [2, 3, 4, 5, <cite>6,</cite> 7] .",
  "y": "background"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_3",
  "x": "Moreover, as previous approaches restrict the power of the pre-trained models to representation extraction only [5, <cite>6,</cite> 7, 8] , the proposed method is robust and can be fine-tuned easily on downstream tasks.",
  "y": "differences"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_4",
  "x": "Following previous works [2, 3, 4, 5, <cite>6,</cite> 7, 8] , we evaluate different features and representations on downstream tasks, including: phoneme classification, speaker recognition, and sentiment classification on spoken content.",
  "y": "uses"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_5",
  "x": "The proposed approaches are mainly compared with APC<cite> [6]</cite> representations, as they also experiment on phone classification and speaker verification.",
  "y": "uses"
 },
 {
  "id": "472b7c9f53b3130d7e5bba772e5b88_6",
  "x": "As reported in<cite> [6]</cite> , the APC approach outperformed CPC representations [5, 7, 9] in both two tasks, which makes APC suitable as a strong baseline.",
  "y": "uses background"
 },
 {
  "id": "485464efe36b1ca1f6dc4e1cf8d474_0",
  "x": "This tutorial introduces the advances in deep Bayesian learning with abundant applications for natural language understanding ranging from speech recognition (Saon and Chien, 2012; Chan et al., 2016) to document summarization (Chang and Chien, 2009 ), text classification (Blei et al., 2003; Zhang et al., 2015) , text segmentation (Chien and Chueh, 2012) , information extraction (<cite>Narasimhan et al., 2016</cite>) , image caption generation (Vinyals et al., 2015; Xu et al., 2015) , sentence generation (Li et al., 2016b) , dialogue control (Zhao and Eskenazi, 2016; Li et al., 2016a) , sentiment classification, recommendation system, question answering (Sukhbaatar et al., 2015) and machine translation , to name a few.",
  "y": "uses background"
 },
 {
  "id": "48def208400142f043a07be5d83713_0",
  "x": "We improve our RTM models<cite> (Bi\u00e7ici and Way, 2014)</cite>: \u2022 by using improved ParFDA instance selection model allowing better language models (LM) in which similarity judgments are made to be built with improved optimization and selection of the LM data, \u2022 by selecting TreeF features over source and translation data jointly instead of taking their intersection, \u2022 with extended learning models including bayesian ridge regression (Tan et al., 2015) , which did not obtain better performance than support vector regression in training results (Section 2.2).",
  "y": "motivation background differences"
 },
 {
  "id": "48def208400142f043a07be5d83713_1",
  "x": "We present top results with Referential Translation Machines (Bi\u00e7ici, 2015;<cite> Bi\u00e7ici and Way, 2014)</cite> at quality estimation task (QET15) in WMT15 (Bojar et al., 2015) .",
  "y": "uses background"
 },
 {
  "id": "48def208400142f043a07be5d83713_2",
  "x": "We improve our RTM models<cite> (Bi\u00e7ici and Way, 2014</cite> ): \u2022 by using improved ParFDA instance selection model allowing better language models (LM) in which similarity judgments are made to be built with improved optimization and selection of the LM data, \u2022 by selecting TreeF features over source and translation data jointly instead of taking their intersection, \u2022 with extended learning models including bayesian ridge regression (Tan et al., 2015) , which did not obtain better performance than support vector regression in training results (Section 2.2).",
  "y": "motivation background differences"
 },
 {
  "id": "48def208400142f043a07be5d83713_3",
  "x": "We present top results with Referential Translation Machines (Bi\u00e7ici, 2015;<cite> Bi\u00e7ici and Way, 2014)</cite> at quality estimation task (QET15) in WMT15 (Bojar et al., 2015) .",
  "y": "uses background"
 },
 {
  "id": "48def208400142f043a07be5d83713_4",
  "x": "We present results using support vector regression (SVR) with RBF (radial basis functions) kernel (Smola and Sch\u00f6lkopf, 2004) for sentence and document translation prediction tasks and Global Linear Models (GLM) (Collins, 2002) with dynamic learning (GLMd) (Bi\u00e7ici, 2013;<cite> Bi\u00e7ici and Way, 2014)</cite> for word-level translation performance prediction.",
  "y": "uses background"
 },
 {
  "id": "48def208400142f043a07be5d83713_5",
  "x": "We develop individual RTM models for each subtask and use GLMd model (Bi\u00e7ici, 2013;<cite> Bi\u00e7ici and Way, 2014)</cite> , for predicting the quality at the word-level.",
  "y": "uses"
 },
 {
  "id": "48def208400142f043a07be5d83713_6",
  "x": "We compare the difficulty of tasks according to MRAER levels achieved. In Table 6 , we list the RTM test results for tasks and subtasks that predict HTER or METEOR from QET15, QET14<cite> (Bi\u00e7ici and Way, 2014)</cite> , and QET13 (Bi\u00e7ici, 2013) .",
  "y": "uses"
 },
 {
  "id": "4924d721b50abe1c8d883a7efd0205_0",
  "x": "UKB is a collection of programs which was first released for performing graph-based Word Sense Disambiguation using a preexisting knowledge base such as WordNet, and attained state-of-the-art results among knowledge-based systems when evaluated on standard benchmarks<cite> Agirre et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "4924d721b50abe1c8d883a7efd0205_1",
  "x": "When UKB was released, the papers specified the optimal parameters for WSD<cite> Agirre et al., 2014)</cite> , as well as other key issues like the underlying knowledge-base version, specific set of relations to be used, and method to pre-process the input text.",
  "y": "background"
 },
 {
  "id": "4924d721b50abe1c8d883a7efd0205_2",
  "x": "When using UKB for WSD, the main parameters and settings can be classified in five main categories. For each of those we mention the best options and the associated UKB parameter when relevant (in italics), as taken from <cite>Agirre et al., 2014</cite> ):",
  "y": "uses"
 },
 {
  "id": "4924d721b50abe1c8d883a7efd0205_3",
  "x": "The use of sense frequencies with UKB was introduced in<cite> (Agirre et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "4924d721b50abe1c8d883a7efd0205_4",
  "x": "In addition to UKB, the table also reports the 5 Note that the UKB results for S2, S3 and S07 (62.6, 63.0 and 48.6 respectively) are different from those in<cite> (Agirre et al., 2014)</cite> , which is to be expected, as the new datasets have been converted to WordNet 3.0 (we confirmed experimentally that this is the sole difference between the two experiments).",
  "y": "differences"
 },
 {
  "id": "4924d721b50abe1c8d883a7efd0205_5",
  "x": "In addition to the results of UKB using the setting in<cite> Agirre et al., 2014)</cite> as specified in Section 3, we checked whether some reasonable settings would obtain better results.",
  "y": "extends"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_0",
  "x": "Latest results are based on neural network experience, but are far more simple: various versions of Word2Vec, Skip-gram and CBOW models [8] , which currently show the State-of-the-Art results and have proven success with morphologically complex languages like Russian [1] ,<cite> [10]</cite> .",
  "y": "background"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_1",
  "x": "Traditional corpora for the word semantic similarity task are News, Wikipedia, electronic libraries and others (e.g. RUSSE workshop<cite> [10]</cite> ).",
  "y": "background"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_2",
  "x": "To mitigate this the \"RUSSE: The First Workshop on Russian Semantic Similarity\"<cite> [10]</cite> was conducted, producing RUSSE Human-Judgements evaluation dataset (we will refer to it as HJ-dataset).",
  "y": "background"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_3",
  "x": "The RUSSE contest was followed by paper from its organizers<cite> [10]</cite> and several participators [1] , [5] , thus filling the gap in word semantic similarity task for Russian language.",
  "y": "background"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_4",
  "x": "To compute correlation we use Spearman coefficient, since it was used as accuracy measure in RUSSE<cite> [10]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_5",
  "x": "For convenience we replicate results for these corpora, originally presented in<cite> [10]</cite> , alongside with our result in Table 5 .",
  "y": "similarities uses"
 },
 {
  "id": "497b717bc4ff6b9e2160ee823f6b42_6",
  "x": "We use HJ-dataset, which was created for RUSSE contest<cite> [10]</cite> to measure correlation between similarity of word vectors and human judgements on word pairs similarity.",
  "y": "uses"
 },
 {
  "id": "499580e888a1598681a8d877b07866_0",
  "x": "<cite>Kim and Lee (2016)</cite> apply neural machine translation (NMT) models, based on recurrent neural network, to sentence-level QE.",
  "y": "background"
 },
 {
  "id": "499580e888a1598681a8d877b07866_1",
  "x": "Recurrent neural network (RNN) based quality estimation model<cite> (Kim and Lee, 2016)</cite> consists of two parts: two bidirectional RNNs on the source and target sentences in the first part and another RNN for predicting the quality in the second part.",
  "y": "background"
 },
 {
  "id": "499580e888a1598681a8d877b07866_2",
  "x": "In this paper, we extend the recurrent neural network based quality estimation model to word and phrase level. Recurrent neural network (RNN) based quality estimation model<cite> (Kim and Lee, 2016)</cite> consists of two parts: two bidirectional RNNs on the source and target sentences in the first part and another RNN for predicting the quality in the second part.",
  "y": "extends uses"
 },
 {
  "id": "499580e888a1598681a8d877b07866_3",
  "x": "1 <cite>Kim and Lee (2016)</cite> modify the NMT model to 1) use source and target A Recurrent Neural Networks Approach for Estimating the Quality of Machine Translation Output",
  "y": "background"
 },
 {
  "id": "499580e888a1598681a8d877b07866_4",
  "x": "Figure 1: First part of recurrent neural network based quality estimation model for generating quality vectors<cite> (Kim and Lee, 2016)</cite> sentences as inputs, 2 2) apply bidirectional RNNs both on source and target sentences, which enable to fully utilize the bidirectional quality information, and 3) generate quality vectors for target words as outputs.",
  "y": "background"
 },
 {
  "id": "499580e888a1598681a8d877b07866_5",
  "x": "<cite>Kim and Lee (2016)</cite> apply RNN based model to sentence-level QE and we extend this model to word and phraselevel QE.",
  "y": "extends uses"
 },
 {
  "id": "499580e888a1598681a8d877b07866_6",
  "x": "In RNN based sentence-level QE model (Figure 2) , HTER (human-targeted translation edit rate) (Snover et al., 2006) in [0,1] for target sentence is predicted by using a logistic sigmoid func-A Recurrent Neural Networks Approach for Estimating the Quality of Machine Translation Output<cite> (Kim and Lee, 2016)</cite> tion such that",
  "y": "background"
 },
 {
  "id": "499580e888a1598681a8d877b07866_7",
  "x": "The hidden state h j is computed by where f is the activation function of RNN<cite> (Kim and Lee, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "4a19f17c00e904a595c1703ab9318d_0",
  "x": "Thanks to recent advances in deep learning over the last two decades, machine translation (MT) has shown steady improvements (Bahdanau et al., 2014; Gehring et al., 2017;<cite> Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "4a19f17c00e904a595c1703ab9318d_1",
  "x": "Furthermore, as the newly proposed architecture called the Transformer network<cite> (Vaswani et al., 2017)</cite> has shown to be effective in various sequence-to-sequence problems, various multi-source adaptations of the Transformer (Junczys-Dowmunt and Grundkiewicz, 2018; Shin and Lee, 2018; Tebbifakhr et al., 2018) have been applied to APE.",
  "y": "background"
 },
 {
  "id": "4a19f17c00e904a595c1703ab9318d_2",
  "x": "As described in<cite> Vaswani et al. (2017)</cite> , each stacked layer is composed of multi-head attention networks and position-wise fully connected feed-forward networks.",
  "y": "background"
 },
 {
  "id": "4a19f17c00e904a595c1703ab9318d_3",
  "x": "In addition to shared embedding described in<cite> Vaswani et al. (2017)</cite> , we also utilize weight sharing across the embedding and output layers in a manner similar to Junczys-Dowmunt and Grundkiewicz (2018).",
  "y": "uses"
 },
 {
  "id": "4a19f17c00e904a595c1703ab9318d_4",
  "x": "As described in<cite> Vaswani et al. (2017)</cite> , we utilize the same multihead attention with h-heads based on scaled dotproduct attention to get matrix C composed of context vectors as follows:",
  "y": "uses similarities"
 },
 {
  "id": "4a19f17c00e904a595c1703ab9318d_5",
  "x": "We trained our model for ~14K update steps with the Adam optimizer (Kingma and Ba, 2014), warm up learning rates<cite> (Vaswani et al., 2017</cite> ) with a size of 12,000, and batch size of approximately 17,000 tokens for each triplet.",
  "y": "uses"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_0",
  "x": "Recent work has revisited these classic critiques through studies of modern neural architectures [10,<cite> 15,</cite> 3, 20, 22, 2, 6] , with a focus on the sequence-to-sequence (seq2seq) models used successfully in machine translation and other NLP tasks [32, 4, 36] .",
  "y": "background"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_1",
  "x": "Recent work has revisited these classic critiques through studies of modern neural architectures [10,<cite> 15,</cite> 3, 20, 22, 2, 6] , with a focus on the sequence-to-sequence (seq2seq) models used successfully in machine translation and other NLP tasks [32, 4, 36] . These studies show that powerful seq2seq approaches still have substantial difficulties with compositional generalization, especially when combining a new concept (\"to Facebook\") with previous concepts (\"slowly\" or \"eagerly\")<cite> [15,</cite> 3, 20] . New benchmarks have been proposed to encourage progress [10,<cite> 15,</cite> 2] , including the SCAN dataset for compositional learning <cite>[15]</cite> .",
  "y": "background"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_2",
  "x": "After training, the aim is to execute, zero-shot, novel instructions such as \"walk around right after look twice.\" Previous studies show that seq2seq recurrent neural networks (RNN) generalize well when the training and test sets are similar, but fail catastrophically when generalization requires systematic compositionality<cite> [15,</cite> 3, 20] .",
  "y": "background"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_3",
  "x": "The meta seq2seq architecture builds upon the seq2seq architecture from <cite>[15]</cite> that performed best across a range of SCAN evaluations.",
  "y": "extends"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_4",
  "x": "A greedy decoder is used since it is effective on SCAN's deterministic outputs <cite>[15]</cite> .",
  "y": "uses"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_5",
  "x": "This experiment applies meta seq2seq learning to the SCAN task of adding a new primitive <cite>[15]</cite> .",
  "y": "uses"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_6",
  "x": "The goal is to learn a new primitive instruction and use it compositionally, operationalized in SCAN as the \"add jump\" split <cite>[15]</cite> . Models learn a new primitive \"jump\" and aim to use it compositionally in other instructions, resembling the \"to Facebook\" example introduced earlier in this paper. First, the original seq2seq problem from <cite>[15]</cite> is described.",
  "y": "uses"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_7",
  "x": "Following <cite>[15]</cite> , the critical \"jump\" demonstration is overrepresented in training to ensure it is learned.",
  "y": "uses"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_8",
  "x": "It fails even while achieving near perfect performance on the training set (>99% on average). This replicates the results from <cite>[15]</cite> which trained many seq2seq models, finding the best network performed at only 1.2% accuracy.",
  "y": "similarities"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_9",
  "x": "On the \"add jump\" test set <cite>[15]</cite> , standard seq2seq modeling completely fails to generalize compositionally, reaching an average performance of only 0.03% correct (SD = 0.02).",
  "y": "background"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_10",
  "x": "The standard seq2seq learner takes advantage of the augmented training to generalize better than in standard SCAN training (Experiment 4.3 and <cite>[15]</cite> ), achieving 12.26% accuracy (SD = 8.33) on the test instructions (with >99% accuracy during training).",
  "y": "differences"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_11",
  "x": "This experiment uses the SCAN \"length\" split <cite>[15]</cite> .",
  "y": "uses"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_12",
  "x": "After learning how to \"dax,\" people understand how to \"dax twice,\" \"dax slowly,\" or even \"dax like there is no tomorrow.\" These abilities are central to language and thought yet they are conspicuously lacking in modern neural networks<cite> [15,</cite> 3, 20, 22, 2] .",
  "y": "background"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_13",
  "x": "After learning how to \"dax,\" people understand how to \"dax twice,\" \"dax slowly,\" or even \"dax like there is no tomorrow.\" These abilities are central to language and thought yet they are conspicuously lacking in modern neural networks<cite> [15,</cite> 3, 20, 22, 2] . In this paper, I introduced a meta sequence-to-sequence (meta seq2seq) approach for learning to generalize compositionally, exploiting the algebraic structure of a domain to help understand novel utterances.",
  "y": "motivation"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_14",
  "x": "After learning how to \"dax,\" people understand how to \"dax twice,\" \"dax slowly,\" or even \"dax like there is no tomorrow.\" These abilities are central to language and thought yet they are conspicuously lacking in modern neural networks<cite> [15,</cite> 3, 20, 22, 2] . In this paper, I introduced a meta sequence-to-sequence (meta seq2seq) approach for learning to generalize compositionally, exploiting the algebraic structure of a domain to help understand novel utterances. In contrast to standard seq2seq, meta seq2seq learners can abstract away the surface patterns and operate closer to rule space.",
  "y": "differences"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_16",
  "x": "Hybrid models could also address the challenge of generalizing to longer output sequences, a problem that continues to vex neural networks<cite> [15,</cite> 3, 28] including meta seq2seq learning.",
  "y": "background"
 },
 {
  "id": "4a28a289ffc730fea4114f6c71bd06_17",
  "x": "In future work, I intend to explore adding more symbolic machinery to the architecture [27] with the goal of handling genuinely new symbols. Hybrid models could also address the challenge of generalizing to longer output sequences, a problem that continues to vex neural networks<cite> [15,</cite> 3, 28] including meta seq2seq learning.",
  "y": "future_work"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_0",
  "x": "On the ISNotes corpus<cite> (Markert et al., 2012)</cite> , our model with the contextually-encoded word representations (BERT) (Devlin et al., 2018) achieves new state-of-the-art performances on fine-grained IS classification, obtaining a 4.1% absolute overall accuracy improvement compared to Hou et al. (2013a) .",
  "y": "uses"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_1",
  "x": "For instance, according to <cite>Markert et al. (2012)</cite> , old mentions 1 refer to entities that have been referred to previously; mediated men-tions have not been mentioned before but are accessible to the hearer by reference to another old mention or to prior world knowledge; and new mentions refer to entities that are introduced to the discourse for the first time and are not known to the hearer before.",
  "y": "background"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_2",
  "x": "In this paper, we follow the IS scheme proposed by <cite>Markert et al. (2012)</cite> and focus on learning finegrained IS on written texts.",
  "y": "uses"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_3",
  "x": "On the ISNotes corpus<cite> (Markert et al., 2012)</cite> , our model with the contextually-encoded word representations (BERT) (Devlin et al., 2018) achieves new state-of-the-art performances on fine-grained IS classification, obtaining a 4.1% absolute overall accuracy improvement compared to Hou et al. (2013a) .",
  "y": "uses"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_5",
  "x": "<cite>Markert et al. (2012)</cite> et al. (2013a) regarding the overall IS classificiation accuracy but the result on bridging anaphora recognition is much worse than Hou et al. (2013a) .",
  "y": "background"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_6",
  "x": "The IS scheme proposed by <cite>Markert et al. (2012)</cite> adopts three major IS categories (old, new and mediated) from Nissim et al. (2004) and distinguishes six subcategories for mediated.",
  "y": "background"
 },
 {
  "id": "4a7fecf3b80c274739e9c83be9a36b_7",
  "x": "We perform experiments on the ISNotes corpus<cite> (Markert et al., 2012)</cite> , which contains 10,980 mentions annotated for information status in 50 news texts.",
  "y": "uses"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_0",
  "x": "There has also been a great deal of work on sentence-based image search or cross-modal retrieval where the objective is to learn a joint space for images and text (Hodosh et al., 2013; Frome et al., 2013;<cite> Kiros et al., 2015</cite>; Socher et al., 2014; Donahue et al., 2015) .",
  "y": "background"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_1",
  "x": "Most work on learning a joint space for images and their descriptions is based on Canonical Correlation Analysis (CCA) or neural variants of CCA over representations of image and its descriptions (Hodosh et al., 2013; Andrew et al., 2013; Yan and Mikolajczyk, 2015; Gong et al., 2014; . Besides CCA, a few others learn a visual-semantic or multimodal embedding space of image descriptions and representations by optimizing a ranking cost function<cite> (Kiros et al., 2015</cite>; Socher et al., 2014; Vendrov et al., 2016) or by aligning image regions (objects) and segments of the description Plummer et al., 2015) in a common space.",
  "y": "background"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_2",
  "x": "A similar loss function is useful for learning multimodal embeddings in a single language<cite> (Kiros et al., 2015)</cite> .",
  "y": "motivation"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_3",
  "x": "We used the L2 norm to mitigate over-fitting<cite> (Kiros et al., 2015)</cite> . Specifically, we use Visual Semantic Embeddings (VSE) of<cite> Kiros et al. (2015)</cite> and Order Embeddings (OE) of Vendrov et al. (2016) .",
  "y": "similarities"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_5",
  "x": "In Tables 1 and 2 we present the ranking results of the baseline models of<cite> Kiros et al. (2015)</cite> and Vendrov et al. (2016) and our proposed PIVOT and PARALLEL models.",
  "y": "background"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_6",
  "x": "In the semantic textual similarity task (STS), we use the textual embeddings from our model to compute the similarity between a pair of sen- (Wieting et al., 2017) \u2212 83.7 84.5 85.0 MLMME (Calixto et al., 2017) VGG19 \u2212 72.7 79.7 VSE<cite> (Kiros et al., 2015)</cite> VGG19 80.6 82.7 89.6 OE (Vendrov et al., 2016) VGG19 82.",
  "y": "similarities"
 },
 {
  "id": "4adcc28c6d1906d74874b8fca371dc_7",
  "x": "We compare with the best reported scores for the STS shared tasks, achieved by MLMME (Calixto et al., 2017) , paraphrastic sentence embeddings (Wieting et al., 2017) , visual semantic embeddings<cite> (Kiros et al., 2015)</cite> , and order embeddings (Vendrov et al., 2016) .",
  "y": "background similarities"
 },
 {
  "id": "4b08797852539f464793dd23cf8999_0",
  "x": "In fact, word embedding generalized the idea of discrete clustering representation to continuous vector representation in language models, with the goal of improving the continuous word analogy prediction and generalization ability (Bengio et al., 2003; Mikolov et al., 2013a; <cite>Mikolov et al., 2013b)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "4b08797852539f464793dd23cf8999_1",
  "x": "When the memory for training word embedding is also limited, we need to modify the training algorithms by introducing new data structures to reduce the bits used to encode the values. In practice, we found that in the stochastic gradient descent (SGD) iteration in word2vec algorithms (Mikolov et al., 2013a; <cite>Mikolov et al., 2013b)</cite> , the updating vector's values are often very small numbers (e.g., < 10 \u22125 ). In this case, if we directly apply the rounding method to certain precisions (e.g., 8 bits), the update of word vectors will always be zero. For example, the 8-bit precision is 2 \u22127 = 0.0078, so 10 \u22125 is not significant enough to update the vector with 8-bit values.",
  "y": "motivation background"
 },
 {
  "id": "4b08797852539f464793dd23cf8999_2",
  "x": "We train the word embedding algorithms, word2vec (Mikolov et al., 2013a; <cite>Mikolov et al., 2013b)</cite> , based on the Oct. 2013 Wikipedia dump.",
  "y": "uses"
 },
 {
  "id": "4b08797852539f464793dd23cf8999_3",
  "x": "We ran both CBOW and skipgram with negative sampling (Mikolov et al., 2013a; <cite>Mikolov et al., 2013b)</cite> on the Wikipedia dump data, and set the window size of context to be five.",
  "y": "uses"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_0",
  "x": "Our method leverages <cite>Cotterell et al. (2017)</cite> 's formulation of Mikolov et al. (2013) 's popular skip-gram model as exponential family principal component analysis (EPCA) and tensor factorization.",
  "y": "uses"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_1",
  "x": "In so doing, we also generalize <cite>Cotterell et al.</cite>'s method to arbitrary tensor dimensions.",
  "y": "extends"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_2",
  "x": "<cite>Cotterell et al. (2017)</cite> showed that SG is a form of exponential family PCA that factorizes the matrix of word/context cooccurrence counts (rather than shifted positive PMI values). With this interpretation, <cite>they</cite> generalize SG from matrix to tensor factorization, and provide a theoretical basis for modeling higher-order SG (or additional context, such as morphological features of words) within a word embeddings framework. Specifically, <cite>Cotterell et al.</cite> recast higher-order SG as maximizing the log-likelihood",
  "y": "background"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_3",
  "x": "We also follow <cite>Cotterell et al. (2017)</cite> and augment the above with the signed number of tokens separating w i and w j , e.g., recording that w i appeared two to the left of w j ; these counts form a 3-tensor.",
  "y": "uses"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_6",
  "x": "The 0 line represents a plain word2vec baseline and the dashed line represents the 3-tensor baseline of <cite>Cotterell et al. (2017)</cite> . Both of <cite>these baselines</cite> are windowed: <cite>they</cite> are restricted to a local context and cannot take advantage of frames or any lexical signal that can be derived from frames.",
  "y": "uses"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_7",
  "x": "Examining Fig. 2a , we see that both model types outperform both the word2vec and <cite>Cotterell et al. (2017)</cite> baselines in nearly all model configurations and ablations.",
  "y": "differences"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_8",
  "x": "Both <cite>Cotterell et al. (2017)</cite> and Levy and Goldberg (2014a) incorporate additional syntactic and morphological information in their word embeddings.",
  "y": "background"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_9",
  "x": "The recent popularity of word embeddings have inspired others to consider leveraging linguistic annotations and resources to learn embeddings. Both <cite>Cotterell et al. (2017)</cite> and Levy and Goldberg (2014a) incorporate additional syntactic and morphological information in their word embeddings.",
  "y": "motivation"
 },
 {
  "id": "4b0aab00a99547791bff0597aabc06_10",
  "x": "As demonstrated by our experiments, our extension of <cite>Cotterell et al. (2017)</cite> 's tensor factorization enriches word embeddings by including syntacticsemantic information not often captured, resulting in consistently higher SPR-based correlations.",
  "y": "extends"
 },
 {
  "id": "4b17b24ec0203263e581cbeeaa9fc7_0",
  "x": "There has been considerable recent interest in the use of statistical methods for grouping words in large on-line corpora into categories which capture some of our intuitions about the reference of the words we use and the relationships between them (e.g.<cite> Brown et al., 1992</cite>; Schiitze, 1993) .",
  "y": "background"
 },
 {
  "id": "4b17b24ec0203263e581cbeeaa9fc7_1",
  "x": "Using an approach similar to that of <cite>Brown et al. (1992)</cite> , each 'target word '1 wi in the corpus was represented as a vector in which each component j is the probability that any one word position in a 'context window' will be occupied by a 'context word' wj, given that the window is centred on word wi.",
  "y": "similarities"
 },
 {
  "id": "4b17b24ec0203263e581cbeeaa9fc7_2",
  "x": "The approach described here differs from that of <cite>Brown et al. (1992)</cite> in that context words both preceding and following the target word are considered (although information about the ordering of the context was not used), and in that Euclidean distance, rather than average mutual information, is used for clustering.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_0",
  "x": "Lately, there have been a number of attempts to develop a purely neural machine translation system (NMT) [12, 5, 2,<cite> 22]</cite> .",
  "y": "background"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_1",
  "x": "NMT systems also use minimal domain knowledge, which makes them applicable to any other problem that can be formulated as mapping a sequence to another sequence<cite> [22]</cite> .",
  "y": "background"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_2",
  "x": "Empirically, both Sutskever et al.<cite> [22]</cite> and Bahdanau et al. [2] have observed that sentences with many rare words tend to be translated much more poorly than sentences containing mainly frequent words.",
  "y": "motivation background"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_3",
  "x": "For example, Kalchbrenner et al. [12] used a combination of a convolutional neural network and a recurrent neural network, Sutskever et al.<cite> [22]</cite> used a large and deep Long Short-Term Memory (LSTM) model, Cho et al. [5] used an architecture similar to the LSTM, and Bahdanau et al. [2] used a more elaborate neural network architecture that uses an attentional mechanism over the input sequence, similarly to Graves [9] and Graves et al. [10] .",
  "y": "background"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_4",
  "x": "In this work, we use the exact model of Sutskever et al.<cite> [22]</cite> , which has a large deep LSTM to encodue the input sequence and a separate deep LSTM to produce a translation from the input sequence.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_5",
  "x": "We treat the NMT system [12, <cite>22,</cite> 5] as a black box and train it on a dataset annotated with alignment information specified by one of the models below.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_6",
  "x": "To be comparable with the results reported by previous work on neural machine translation systems<cite> [22,</cite> 5, 2] , we train our models on the same training data of 12M parallel sentences (348M French and 304M English words).",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_7",
  "x": "2 Due to the computationally intensive nature of the naive softmax in the target language, we limit the French vocabulary to the 40K most frequent French words (note that<cite> [22]</cite> used a vocabulary of 80k French words).",
  "y": "differences"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_8",
  "x": "Our training procedure and hyperparameter choices are similar to those used by Sutskever et al.<cite> [22]</cite> .",
  "y": "similarities"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_9",
  "x": "Like Sutskever et al.<cite> [22]</cite> , we reverse the words in the source sentences which has been shown to improve LSTM memory utilization and results in better translations of long sentences.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_10",
  "x": "We also follow the GPU parallelization scheme proposed in<cite> [22]</cite> , allowing us to reach a training speed of 9.0K words per second ([22] achieved 6.3K words per second with a larger vocabulary of 80K; our target vocabulary has 40K words).",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_11",
  "x": "However, all other systems that we compared against have been evaluated on the tokenized translations using the multi-bleu.pl script, which is consistent with previous work [5, 2, 19,<cite> 22]</cite> .",
  "y": "similarities"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_12",
  "x": "Thus, to make it possible to compare our system against the system of Durrani et al. [7] , we evaluated its tokenized predictions (which can be downloaded from statmt.org [7] ) on the test set (newstest2014) and arrived at the BLEU score of 37.0 points<cite> [22]</cite> .",
  "y": "similarities"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_13",
  "x": "Our best result (36.9 BLEU) outperforms all other NMT systems by a large margin, and in particular, it outperforms the current best NMT system<cite> [22]</cite> by 2.1 BLEU points (we even outperform Sutskever et al.<cite> [22]</cite> when they rerank the n-best list of a phrase-based baseline<cite> [22]</cite> ).",
  "y": "differences"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_14",
  "x": "To analyze the effect of rare words on translation quality, we follow Sutskever et al.<cite> [22]</cite> and sort the sentences in newstest2014 by the average frequency rank of their words.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_15",
  "x": "We evaluate our systems before and after translating the OOV words and compare with the standard MT systems -we use the state-of-the-art (SOTA) system from WMT'14 [7] , and neural MT systems -we use the ensemble system described in<cite> [22]</cite> (See Section 4).",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_16",
  "x": "The translation quality of our model before applying the unknown word translations is shown by the green star line, and the current best NMT system<cite> [22]</cite> is the purple diamond line.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_17",
  "x": "While<cite> [22]</cite> produces excellent translations of sentences with frequent words (the left part of the graph), they are worse than SOTA system (red triangle line) on sentences with many rare words (the right side of the graph).",
  "y": "differences"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_18",
  "x": "Overall, our rare word translation model interpolates between the SOTA system and the system of Sutskever et al.<cite> [22]</cite> , which allows us to outperform SOTA on sentences that consist predominantly of frequent words and approach its performance on sentences with many OOV words.",
  "y": "uses"
 },
 {
  "id": "4b34c36a93a049b8fd637fee768438_19",
  "x": "A key advantage of our technique is the fact that it is applicable to any NMT system and not only to the deep LSTM model of Sutskever et al.<cite> [22]</cite> .",
  "y": "differences"
 },
 {
  "id": "4bb290aba7ee7843280a8b0e88e5a0_1",
  "x": "A major distinction between the work of Berant et al. (2013) and<cite> Yao and Van Durme (2014)</cite> is the ability of the former to represent, and compose, aggregation operators (such as argmax, or count), as well as integrate disparate pieces of information.",
  "y": "background"
 },
 {
  "id": "4bb290aba7ee7843280a8b0e88e5a0_2",
  "x": "jacana-freebase 2 <cite>(Yao and Van Durme, 2014)</cite> treats QA from a KB as a binary classification problem.",
  "y": "background"
 },
 {
  "id": "4bb290aba7ee7843280a8b0e88e5a0_3",
  "x": "Both Berant et al. (2013) and<cite> Yao and Van Durme (2014)</cite> tested their systems on the WEBQUESTIONS dataset, which contains 3778 training questions and 2032 test questions collected from the Google Suggest API.",
  "y": "background"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_0",
  "x": "To do so, we build on previous work on sentiment detection algorithms for the more formal news genre, notably the work of<cite> Agarwal et al (2009)</cite> , but adapt it for the language of social media, in particular Twitter.",
  "y": "extends"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_1",
  "x": "In this rest of this paper, we discuss related work, including the state of the art sentiment system<cite> (Agarwal et al., 2009)</cite> our method is based on, the lexicons we used, our method, and experiments and results.",
  "y": "extends"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_2",
  "x": "We use the DAL and expand it with WordNet, as it was used in the original work<cite> (Agarwal et al., 2009)</cite> , and expand it further to use Wiktionary and an emoticon lexicon.",
  "y": "extends similarities uses"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_3",
  "x": "We compute the polarity of a chunk in the same manner as the original work<cite> (Agarwal et al., 2009)</cite> , using the sum of the AE Space Score's (| \u221a ee 2 + aa 2 |) of each word within the chunk.",
  "y": "similarities uses"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_4",
  "x": "The DAL and other dictionaries are used along with a negation state machine<cite> (Agarwal et al., 2009)</cite> to determine the polarity for each word in the sentence.",
  "y": "uses"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_5",
  "x": "We include all the features described in the original system<cite> (Agarwal et al., 2009</cite> ).",
  "y": "similarities uses"
 },
 {
  "id": "4be5a47b5fd900c3578330b352b24c_6",
  "x": "We include POS tags and the top 500 n-gram features<cite> (Agarwal et al., 2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_0",
  "x": "For automatic evaluation of a simplification output, it is common practice to use machine translation (MT) metrics (e.g. BLEU (Papineni et al., 2002) ), simplicity metrics (e.g. SARI <cite>(Xu et al., 2016)</cite> ), and readability metrics (e.g. FKGL (Kincaid et al., 1975) ).",
  "y": "background"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_1",
  "x": "Previous work <cite>(Xu et al., 2016)</cite> has shown that BLEU correlates fairly well with human judgements of grammaticality and meaning preservation.",
  "y": "background"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_2",
  "x": "Although<cite> Xu et al. (2016)</cite> indicate that only precision should be considered for the deletion operation, we follow the Java implementation that uses F1 score for all operations in corpus-level SARI.",
  "y": "differences"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_3",
  "x": "EASSE provides access to three publicly available datasets for automatic SS evaluation (Table 1): PWKP (Zhu et al., 2010) , TurkCorpus <cite>(Xu et al., 2016)</cite> , and HSplit (Sulem et al., 2018a) .",
  "y": "background"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_4",
  "x": "TurkCorpus<cite> Xu et al. (2016)</cite> asked crowdworkers to simplify 2,359 original sentences extracted from PWKP to collect eight simplification references for each one.",
  "y": "background"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_5",
  "x": "We also included SBSMT-SARI <cite>(Xu et al., 2016)</cite> , which relies on syntaxbased statistical MT; DRESS-LS (Zhang and Lapata, 2017 ), a neural model using the standard encoder-decoder architecture with attention combined with reinforcement learning; and DMASS-DCSS (Zhao et al., 2018) , the current state-of-theart in the TurkCorpus, which is based on the Transformer architecture (Vaswani et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "4c615cb5a496c1e225a8457a4f55d4_6",
  "x": "According to<cite> Xu et al. (2016)</cite> , the annotators in TurkCorpus were instructed to mainly produce paraphrases, i.e. mostly replacements with virtually no deletions.",
  "y": "background"
 },
 {
  "id": "4c71ac789203d50e3e428458c2f88c_0",
  "x": "Our proposed mixed hierarchi- Table Summarization with fixed schema tables as input cal attention model provides an improvement of around 18 BLEU (around 30%) over the current state-of-the-art result by<cite> Mei et al. (2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "4c71ac789203d50e3e428458c2f88c_1",
  "x": "Dynamic Record attention for Decoder: Our decoder is a GRU based decoder with dynamic attention mechanism similar to <cite>(Mei et al., 2016)</cite> with modifications to modulate attention weights at each time step using static record attentions.",
  "y": "extends"
 },
 {
  "id": "4c71ac789203d50e3e428458c2f88c_2",
  "x": "We compared the performance of our model against the state-of-the-art work of MBW <cite>(Mei et al., 2016)</cite> , as well as two other baseline models KL (Konstas and Lapata, 2013) and ALK (Angeli et al., 2010 '00010000000000' and '00001000000000' respectively.",
  "y": "uses"
 },
 {
  "id": "4c71ac789203d50e3e428458c2f88c_3",
  "x": "In addition to the standard BLEU (sBleu) (Papineni et al., 2002) , a customized BLEU (cBleu) <cite>(Mei et al., 2016)</cite> has also been reported.",
  "y": "uses"
 },
 {
  "id": "4c8e83eb213879e68285e9cd09be47_0",
  "x": "The soft attention model performs surprisingly poorly on seen words, so that its overall performance is worse than the na\u00efve baseline and several earlier models<cite> (Pettersson et al., 2014)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "4c8e83eb213879e68285e9cd09be47_1",
  "x": "Over the years, researchers have proposed normalization methods based on rules and/or edit distances (Baron and Rayson, 2008; Bollmann, 2012; Hauser and Schulz, 2007; Bollmann et al., 2011; Pettersson et al., 2013a; Mitankin et al., 2014;<cite> Pettersson et al., 2014)</cite> , statistical machine translation (Pettersson et al., 2013b; Scherrer and Erjavec, 2013) , and most recently neural network models (Bollmann and S\u00f8gaard, 2016; Bollmann et al., 2017; Korchagina, 2017) . However, most of these systems have been developed and tested on a single language (or even a single corpus), and many have not been compared to the na\u00efve but strong baseline that only changes words seen in the training data, normalizing each to its most frequent modern form observed during training. 1 These issues make it hard to tell which methods generalize across languages and corpora, and how they compare to each other.",
  "y": "motivation background"
 },
 {
  "id": "4c8e83eb213879e68285e9cd09be47_2",
  "x": "Since historical spelling normalization is typically a low-resource task, systems should also ideally be tested with varying amounts of training data to assess how much annotation might be required for a new corpus <cite>(Pettersson et al., 2014</cite>; Bollmann and S\u00f8gaard, 2016; Korchagina, 2017) .",
  "y": "background"
 },
 {
  "id": "4c8e83eb213879e68285e9cd09be47_4",
  "x": "We use the same datasets as<cite> Pettersson et al. (2014)</cite> , with data from five languages over a range of historical periods.",
  "y": "uses"
 },
 {
  "id": "4c8e83eb213879e68285e9cd09be47_5",
  "x": [
   "6 We use the same train/dev/test splits as Pettersson; dataset statistics are shown in Table  1 . Because we do no hyperparameter tuning, we do not use the development sets, and all results are reported on the test sets."
  ],
  "y": "extends"
 },
 {
  "id": "4d25b647a261a415d769532386265a_0",
  "x": "Recently, transformer networks have been shown to perform well for neural machine translation <cite>[11]</cite> and many other NLP tasks [12] . A Transformer layer distinguishes itself from a regular recurrent network by entirely relying on a key-value \"self\"-attention mechanism for learning relationships between distant concepts, rather than relying on recurrent connections and memory cells to preserve information, as in LSTMs, that can fade over time steps. Transformer layers can be seen as bagof-concept layers because they don't preserve location information in the weighted sum self-attention operation.",
  "y": "background"
 },
 {
  "id": "4d25b647a261a415d769532386265a_1",
  "x": "To model word order, sinusoidal positional embeddings are used <cite>[11]</cite> .",
  "y": "uses"
 },
 {
  "id": "4d25b647a261a415d769532386265a_2",
  "x": "Transformer layers <cite>[11]</cite> have the ability to learn long range relationships for many sequential classification tasks [12] . Multi- The dot product between keys and queries is scaled by the inverse square root of the key dimension. This self-attention operation is done h times in parallel, for the case of h attention heads, with different projection matrices from dinput to d k , d k , and dv. The final output is a concatenation of h vectors each with dimension dv which is in turn linearly projected to the desired output dimension of the self-attention layer. On top of the self-attention component, transformer layers have multiple operations applied on each time step; dropout, residual connection, layer norm, two fully connected layers with a ReLU layer in between, another residual and Layer norm operations.",
  "y": "background"
 },
 {
  "id": "4d25b647a261a415d769532386265a_3",
  "x": "Figure(1) -left show the details of one transformer layer as proposed by <cite>[11]</cite> .",
  "y": "uses background"
 },
 {
  "id": "4d25b647a261a415d769532386265a_4",
  "x": "In table (1) we show the WER of the proposed transformer encoder-decoder model with convolutional context using the canonical configuration in the first row. Replacing the 1-D convolutional context in the decoder with sinusoidal positional embedding, as proposed in the baseline machine translation transformers <cite>[11]</cite> and adopted in [13, 15] , shows inferior WER performance. By combining sinusoidal and convolutional position embedding (rows 1+2), we don't observe any gains. This supports our intuition that the relative convolutional positional information provides sufficient signal for the transformer layers to recreate more global word order.",
  "y": "uses background"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_0",
  "x": "To aggregate the information from multiple utterances, we adapt an existing <cite>integer linear programming (ILP)</cite> based fusion technique <cite>[1]</cite> .",
  "y": "uses"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_1",
  "x": "Each edge of the merged structure is represented as a variable in the <cite>ILP</cite> objective function, and the solution will decide whether the edge has to be preserved or discarded.",
  "y": "uses"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_2",
  "x": "Further, to solve the <cite>ILP</cite>, we introduce several constraints, such as desired length of the output, etc.",
  "y": "motivation"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_4",
  "x": "We model the problem as an <cite>integer linear programming (ILP)</cite> formulation, similar to the dependency graph fusion as proposed by <cite>Fillipova and Strube</cite> <cite>[1]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_5",
  "x": "In order to solve the above <cite>ILP</cite> problem, we impose a number of constraints.",
  "y": "uses"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_6",
  "x": "Some of the constraints have been directly adapted from the original <cite>ILP</cite> formulation <cite>[1]</cite> .",
  "y": "extends"
 },
 {
  "id": "4dbf6e2bfa30e96816b7f6d9c6e069_7",
  "x": "In order to solve the above <cite>ILP</cite> problem, we impose a number of constraints. Some of the constraints have been directly adapted from the original <cite>ILP</cite> formulation <cite>[1]</cite> .",
  "y": "extends"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_0",
  "x": "This paper studies the stability of K-NRM, a recent state-of-the-art neural ranking model<cite> [10]</cite> .",
  "y": "background"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_1",
  "x": "SIGIR '18, July [8] [9]<cite> [10]</cite> [11] [12] 2018 word embeddings tailored for search tasks and kernels that group matches into bins of different quality.",
  "y": "background"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_2",
  "x": "Interaction-based models use local interactions between the query and document words and neural networks that learn matching patterns [2, <cite>10]</cite> .",
  "y": "background"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_3",
  "x": "K-NRM<cite> [10]</cite> is an interaction-based model that uses kernel pooling to summarize word-word interactions.",
  "y": "background"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_4",
  "x": "Our experiments followed the original K-NRM work<cite> [10]</cite> and used its open-source implementation 1 .",
  "y": "similarities uses"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_5",
  "x": "Xiong, et al.<cite> [10]</cite> built the vocabulary from queries and titles, but we built it from the queries, titles and URLs for better term coverage.",
  "y": "extends differences"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_6",
  "x": "Testing Labels: Following Xiong et al.<cite> [10]</cite> , three testing conditions were used.",
  "y": "similarities uses"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_7",
  "x": "Model Configuration: We adopted the same default hyperparameter configuration and 11 Gaussian kernels as in prior work<cite> [10]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "4e7ee576b07a8a21a42472bf921291_8",
  "x": "Table 1 also shows results reported by Xiong et al<cite> [10]</cite> . Their model performance falls in the lower end of our trials, probably due to different vocabularies and stopping conditions.",
  "y": "differences"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_0",
  "x": "Our model can be seen as an extension of the recently proposed model for the same problem by<cite> Rush et al. (2015)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_1",
  "x": "Empirically we show that our model beats the state-of-the-art systems of<cite> Rush et al. (2015)</cite> on multiple data sets.",
  "y": "similarities"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_2",
  "x": "Very recently<cite> Rush et al. (2015)</cite> proposed a neural attention model for this problem using a new data set for training and showing state-of-the-art performance on the DUC tasks.",
  "y": "background"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_3",
  "x": "The data is pre-processed in the same way as<cite> Rush et al. (2015)</cite> and we use the same splits for training, validation, and testing.",
  "y": "similarities uses"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_4",
  "x": "For Gigaword we report results on the same randomly held-out test set of 2000 sentence-summary pairs as <cite>(Rush et al., 2015)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_5",
  "x": "As baseline we use the state-of-the-art attention-based system (ABS) of<cite> Rush et al. (2015)</cite> which relies on a feed-forward network decoder.",
  "y": "similarities uses"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_6",
  "x": "Table 1 shows that both our RAS-Elman and RAS-LSTM models achieve lower perplexity than ABS as well as other models reported in<cite> Rush et al. (2015)</cite> .",
  "y": "differences"
 },
 {
  "id": "4f5a25d7a961e7e61c2caef81418e0_7",
  "x": "We extend the state-of-the-art model for abstractive sentence summarization <cite>(Rush et al., 2015)</cite> to a recurrent neural network architecture.",
  "y": "extends differences"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_0",
  "x": "We extend the MorphoChains system <cite>(Narasimhan et al., 2015)</cite> to provide morphological analyses that can abstract over spelling differences in functionally similar morphs.",
  "y": "extends"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_1",
  "x": "We present a system that adapts the unsupervised MorphoChains segmentation system <cite>(Narasimhan et al., 2015)</cite> to provide morphological analyses that aim to abstract over spelling differences in functionally similar morphemes.",
  "y": "extends"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_2",
  "x": "We base our work on the MorphoChains segmentation system <cite>(Narasimhan et al., 2015)</cite> , 1 which defines a morphological chain as a sequence of child-parent pairs.",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_3",
  "x": "We predict child-parent pairs using a log-linear model, following<cite> Narasimhan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_4",
  "x": "Following<cite> Narasimhan et al. (2015)</cite>, we do so using Contrastive Estimation (CE) (Smith and Eisner, 2005) .",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_5",
  "x": "We use the same neighbourhood functions as<cite> Narasimhan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_6",
  "x": "Semantic similarity was an important feature in MorphoChains:<cite> Narasimhan et al. (2015)</cite> concluded that up to 25 percent of their model's precision was due to the semantic similarity feature.",
  "y": "background"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_7",
  "x": "Semantic similarity was an important feature in MorphoChains:<cite> Narasimhan et al. (2015)</cite> concluded that up to 25 percent of their model's precision was due to the semantic similarity feature. We use the same feature here (COS).",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_8",
  "x": "To identify possible affixes to use as features,<cite> Narasimhan et al. (2015)</cite> counted the number of words that end (or start) with each substring Table 3 : Examples illustrating which of the binary features in the model are active for various potential child-parent pairs.",
  "y": "background"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_9",
  "x": "Semantic similarity was an important feature in MorphoChains:<cite> Narasimhan et al. (2015)</cite> concluded that up to 25 percent of their model's precision was due to the semantic similarity feature. We use the same feature here (COS). To identify possible affixes to use as features,<cite> Narasimhan et al. (2015)</cite> counted the number of words that end (or start) with each substring Table 3 : Examples illustrating which of the binary features in the model are active for various potential child-parent pairs.",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_10",
  "x": "Stop Condition To identify words with no parents we use two types of binary features suggested by<cite> Narasimhan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_11",
  "x": "Hyperparameters In addition to threshold values described above, we use the same \u03bb = 1 (Equation 3) as<cite> Narasimhan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_12",
  "x": "Baselines We compare our model to three other systems: Morfessor 2.0 (Virpioja et al., 2013) , MORSEL (Lignos et al., 2009; Lignos, 2010) and MorphoChains <cite>(Narasimhan et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "518b281a4bc04b3504d3b385a5dc62_13",
  "x": "Using these features gives gains of +1.0%, 3.8% and 0.6% F-1 absolute on English, German and Turkish respectively over using the raw affix occurrence frequencies as used by<cite> Narasimhan et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_0",
  "x": "Using the described approach, we demonstrate a word-error-rate (WER) reduction of 65% over a do-nothing input baseline, and we improve over a state-of-the-art system<cite> (Eskander et al., 2013)</cite> which relies heavily on language-specific and manually-selected constraints. We present a detailed analysis of mistakes and demonstrate that the proposed model indeed learns to correct a wider variety of errors.",
  "y": "motivation background differences"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_1",
  "x": "The work of<cite> Eskander et al. (2013)</cite> is the most relevant to the present study: it presents a character-edit classification model (CEC) using the same dataset we use in this paper.",
  "y": "background similarities"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_2",
  "x": "2<cite> Eskander et al. (2013)</cite> analyzed the data to identify the seven most common types of errors. They developed seven classifiers and applied them to the data in succession. This makes the approach tailored to the specific data set in use and limited to a specific set of errors.",
  "y": "uses similarities"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_3",
  "x": "In this work, a single model is considered for all types of errors. The model considers every character in the input text for a possible spelling error, as opposed to looking only at certain input characters and contexts in which they appear. Moreover, in contrast to<cite> Eskander et al. (2013)</cite> , it looks beyond the boundary of the current word.",
  "y": "differences"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_4",
  "x": "To address errors occurring at the end 2<cite> Eskander et al. (2013)</cite> also considered a slower, more expensive, and more language-specific method using a morphological tagger that outperformed the CEC model; however, we do not compare to it in this paper.",
  "y": "background differences"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_5",
  "x": "Labels modeled by<cite> Eskander et al. (2013)</cite> are marked with E , and EP for cases modeled partially, for example, the Insert{A} would only be applied at certain positions such as the end of the word.",
  "y": "uses"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_6",
  "x": "The CODA orthography was proposed by Habash et al. (2012) in an attempt to standardize dialectal writing, and we use it as a reference of correct text for spelling correction following the previous work by<cite> Eskander et al. (2013)</cite> . We use the same corpus (labeled \"ARZ\") and experimental setup splits used by them.",
  "y": "uses"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_7",
  "x": "We further distinguish between the phenomena modeled by our system and by<cite> Eskander et al. (2013)</cite> . At least 10% of all generated action labels are not handled by<cite> Eskander et al. (2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_8",
  "x": "We include a set of basic features inspired by<cite> Eskander et al. (2013)</cite> in their CEC system and additional features for further improvement. Basic features We use a set of nine basic features: the given character, the preceding and following two characters, and the first two and last two characters in the word. These are the same features used by CEC, except that CEC does not include characters beyond the word boundary, while we consider space characters as well as characters from the previous and next words.",
  "y": "uses motivation background"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_9",
  "x": "A speech effect handling step was applied as a preprocessing step to all models. This step removes redundant repetitions of characters in sequence, e.g., ktyyyyyr 'veeeeery'. The same speech effect handling was applied by<cite> Eskander et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_10",
  "x": "Finally, the accuracy Acc metric, used by<cite> Eskander et al. (2013)</cite> , is a simple string matching metric which enforces a word alignment that pairs words in the reference to those of the output. It is calculated by dividing the number of correct output words by the number of words in the input. This metric assumes no split errors in the data (a word incorrectly split into two words), which is the case in the data we are working with.",
  "y": "background"
 },
 {
  "id": "518d8a8395e38d9971bd51344cf1b8_12",
  "x": "The Acc score reported by<cite> Eskander et al. (2013)</cite> for CEC+MLE is 91.3% .",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_0",
  "x": "Our results improve the best published result on the hotel review data (<cite>Ott et al., 2011</cite>) reaching 91.2% accuracy with 14% error reduction.",
  "y": "differences"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_1",
  "x": "Most are based on dictionarybased word counting using LIWC (Pennebaker et al., 2007 ) (e.g., Hancock et al. (2007) , Vrij et al. (2007) ), while some recent ones explored the use of machine learning techniques using simple lexico-syntactic patterns, such as n-grams and part-of-speech (POS) tags (Mihalcea and Strapparava (2009) , <cite>Ott et al. (2011)</cite> ).",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_2",
  "x": "Most are based on dictionarybased word counting using LIWC (Pennebaker et al., 2007 ) (e.g., Hancock et al. (2007) , Vrij et al. (2007) ), while some recent ones explored the use of machine learning techniques using simple lexico-syntactic patterns, such as n-grams and part-of-speech (POS) tags (Mihalcea and Strapparava (2009) , <cite>Ott et al. (2011)</cite> ). <cite>These</cite> previous studies unveil interesting correlations between certain lexical items or categories with deception that may not be readily apparent to human judges.",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_3",
  "x": "For instance, the work of <cite>Ott et al. (2011)</cite> in the hotel review domain results in very insightful observations that deceptive reviewers tend to use verbs and personal pronouns (e.g., \"I\", \"my\") more often, while truthful reviewers tend to use more of nouns, adjectives, prepositions.",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_4",
  "x": "Our results improve the best published result on the hotel review data of <cite>Ott et al. (2011)</cite> reaching 91.2% accuracy with 14% error reduction.",
  "y": "uses"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_5",
  "x": "To explore different types of deceptive writing, we consider the following four datasets spanning from the product review to the essay domain: I. TripAdvisor-Gold: Introduced in <cite>Ott et al. (2011)</cite> , this dataset contains 400 truthful reviews obtained from www.tripadviser.com and 400 deceptive reviews gathered using Amazon Mechanical Turk, evenly distributed across 20 Chicago hotels.",
  "y": "uses"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_6",
  "x": "Words Previous work has shown that bag-ofwords are effective in detecting domain-specific deception (<cite>Ott et al., 2011</cite>; Mihalcea and Strapparava, 2009 ).",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_7",
  "x": "Note that <cite>Ott et al. (2011)</cite> found that even though POS tags are effective in detecting fake product reviews, they are not as effective as words.",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_8",
  "x": "Note that <cite>Ott et al. (2011)</cite> found that even though POS tags are effective in detecting fake product reviews, they are not as effective as words. Therefore, we strengthen POS features with unigram features.",
  "y": "motivation"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_9",
  "x": "As reported in <cite>Ott et al. (2011)</cite> , bag-of-words features achieve surprisingly high performance, reaching upto 89.6% accuracy.",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_10",
  "x": "We first discuss the results for the TripAdvisorGold dataset shown in Table 2 . As reported in <cite>Ott et al. (2011)</cite> , bag-of-words features achieve surprisingly high performance, reaching upto 89.6% accuracy.",
  "y": "similarities"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_11",
  "x": "We first discuss the results for the TripAdvisorGold dataset shown in Table 2 . As reported in <cite>Ott et al. (2011)</cite> , bag-of-words features achieve surprisingly high performance, reaching upto 89.6% accuracy. Deep syntactic features, encoded asr * slightly improves this performance, achieving 90.4% accuracy.",
  "y": "differences"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_12",
  "x": "3 Numbers in italic are classification results reported in <cite>Ott et al. (2011)</cite> and Mihalcea and Strapparava (2009).",
  "y": "background"
 },
 {
  "id": "520437f612e678dcd4ec9c043cf701_13",
  "x": "Two previous work obtained more precise gold standard labels by hiring Amazon turkers to write deceptive articles (e.g., Mihalcea and Strapparava (2009), <cite>Ott et al. (2011)</cite> ), both of which have been examined in this study with respect to their syntactic characteristics.",
  "y": "uses background"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_0",
  "x": "Most of the presented works study the interrelationship between words in a text snip- pet<cite> (Hill et al., 2016</cite>; Kiros et al., 2015; Le and Mikolov, 2014) in an unsupervised fashion.",
  "y": "background"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_1",
  "x": "This makes our work distinguished from to the work of (Le and Mikolov, 2014; <cite>Hill et al., 2016</cite>; Kiros et al., 2015) where they study the interrelationship of words in the text snippet.",
  "y": "differences"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_2",
  "x": "(1) Some neural-based paragraph representations such as paragraph vectors (Le and Mikolov, 2014) , FastSent<cite> (Hill et al., 2016)</cite> use a shared space between the words and paragraphs.",
  "y": "background"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_3",
  "x": "Below we describe our motivation towards the proposal of our novel representation: (1) Some neural-based paragraph representations such as paragraph vectors (Le and Mikolov, 2014) , FastSent<cite> (Hill et al., 2016)</cite> use a shared space between the words and paragraphs.",
  "y": "background motivation"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_4",
  "x": "This is an advantage compared to existing methods for generating paragraph vectors, such as (Le and Mikolov, 2014;<cite> Hill et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_5",
  "x": "Recently other neural-based sentence and paragraph level representations appeared to provide a fixed length representation like Skip-Thought Vectors (Kiros et al., 2015) and FastSent<cite> (Hill et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_6",
  "x": "We follow the setup used in<cite> (Hill et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_7",
  "x": "The competing methods are the paragraph vectors (Le and Mikolov, 2014) , skip-thought vectors (Kiros et al., 2015) , Fastsent<cite> (Hill et al., 2016)</cite> , Sequential (Denoising) Autoencoders (SDAE)<cite> (Hill et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_8",
  "x": "We contrast our results against the methods reported in<cite> (Hill et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_9",
  "x": "We use same evaluation measures<cite> (Hill et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_10",
  "x": "Other models such as skipthought vectors (Kiros et al., 2015) and SDAE<cite> (Hill et al., 2016)</cite> requires building an encoder-decoder model which takes time 3 to learn.",
  "y": "background"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_11",
  "x": "For other models like paragraph vectors (Le and Mikolov, 2014) and Fastsent vectors<cite> (Hill et al., 2016)</cite> , they require a gradient descent inference step to compute the paragraph/sentence vectors.",
  "y": "background"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_12",
  "x": "Other models such as skipthought vectors (Kiros et al., 2015) and SDAE<cite> (Hill et al., 2016)</cite> requires building an encoder-decoder model which takes time 3 to learn. For other models like paragraph vectors (Le and Mikolov, 2014) and Fastsent vectors<cite> (Hill et al., 2016)</cite> , they require a gradient descent inference step to compute the paragraph/sentence vectors. Using the DoCoV, we just require a pre-trained word embedding model and we do not need any additional training like encoder-decoder models or inference steps via gradient descent.",
  "y": "background differences"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_13",
  "x": "We use linear<cite> (Hill et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_15",
  "x": "We use classification accuracy as the evaluation measure for this experiment as<cite> (Hill et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "52b5ed7a0753402ad4bceb83a2b495_16",
  "x": "We further observe that DoCoV is consistently better than the paragraph vectors (Le and Mikolov, 2014) , Fastsent and SDAE<cite> (Hill et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "53bc4206427e95d600f787e0531df1_0",
  "x": "To solve this problem, we consider the <cite>Pointwise Mutual Information (PMI)</cite> <cite>[9]</cite> .",
  "y": "uses"
 },
 {
  "id": "53bc4206427e95d600f787e0531df1_1",
  "x": "To solve this problem, we consider the <cite>Pointwise Mutual Information (PMI)</cite> <cite>[9]</cite> . Since the <cite>PMI</cite> score not only considers the co-occurrence frequency of the two words, but also normalizes by the single word frequency.",
  "y": "background"
 },
 {
  "id": "53bc4206427e95d600f787e0531df1_2",
  "x": "To solve this problem, we consider the <cite>Pointwise Mutual Information (PMI)</cite> <cite>[9]</cite> . Thus, we want to apply <cite>PMI</cite> score in the original BTM.",
  "y": "uses"
 },
 {
  "id": "53bc4206427e95d600f787e0531df1_3",
  "x": "To solve this problem, we consider the <cite>Pointwise Mutual Information (PMI)</cite> <cite>[9]</cite> . A suitable way to apply <cite>PMI</cite> scores is modifying the priors in the BTM.",
  "y": "uses"
 },
 {
  "id": "53bc4206427e95d600f787e0531df1_4",
  "x": "To solve this problem, we consider the <cite>Pointwise Mutual Information (PMI)</cite> <cite>[9]</cite> . Applying the <cite>PMI</cite> score to the \u03b2-priors is the only one choice because we can adjust the degree of the word co-occurrence by modifying the distributions in the \u03b2-priors.",
  "y": "uses"
 },
 {
  "id": "53cd860c539e20874ada4343ab788f_0",
  "x": "This mismatch of needs has motivated various proposals to reconstruct missing entries, in WALS and other databases, from known entries (Daum\u00e9 III and Campbell, 2007; Daum\u00e9 III, 2009;<cite> Coke et al., 2016</cite>; Littell et al., 2017) .",
  "y": "background"
 },
 {
  "id": "53cd860c539e20874ada4343ab788f_1",
  "x": "Baseline Feature Vectors: Several previous methods take advantage of typological implicature, the fact that some typological traits correlate strongly with others, to use known features of a language to help infer other unknown features of the language (Daum\u00e9 III and Campbell, 2007; Takamura et al., 2016;<cite> Coke et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "53cd860c539e20874ada4343ab788f_2",
  "x": "This has been demonstrated to some extent in previous work that has used specifically engineered alignment-based models (Lewis and Xia, 2008; \u00d6stling, 2015;<cite> Coke et al., 2016)</cite> , and we examine whether these results apply to neural network feature extractors and expand beyond word order and syntax to other types of typology as well.",
  "y": "extends"
 },
 {
  "id": "53cd860c539e20874ada4343ab788f_4",
  "x": "Interestingly, and in contrast to previous methods for inferring typology from raw text, which have been specifically designed for inducing word order or other syntactic features (Lewis and Xia, Table 2 : Top 5 improvements from \"NONE -Aux\" to \"MTBOTH -Aux\" in the syntax (\"S \"), phonology (\"P \"), and inventory (\"I \") classes. 2008; \u00d6stling, 2015;<cite> Coke et al., 2016)</cite> , our proposed method is also able to infer information about phonological or phonetic inventory features.",
  "y": "differences"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_0",
  "x": "Some recent work has addressed this by learning general-purpose sentence representations Wieting et al., 2015; Hill et al., 2016;<cite> Conneau et al., 2017</cite>; McCann et al., 2017; Jernite et al., 2017; Nie et al., 2017; Pagliardini et al., 2017) .",
  "y": "background"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_1",
  "x": "More recently, <cite>Conneau et al. (2017)</cite> show that a completely supervised approach to learning sentence representations from natural language inference data outperforms all previous approaches on transfer learning benchmarks.",
  "y": "background"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_2",
  "x": "This is the same classification strategy adopted by <cite>Conneau et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_3",
  "x": "We follow a similar evaluation protocol to those presented in ; Hill et al. (2016) ; <cite>Conneau et al. (2017)</cite> which is to use our learned representations as features for a low complexity classifier (typically linear) on a novel supervised task/domain unseen during training without updating the parameters of our sentence representation model.",
  "y": "similarities"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_4",
  "x": "The choice of transfer tasks and evaluation framework 3 are borrowed largely from <cite>Conneau et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_5",
  "x": "Unlike <cite>Conneau et al. (2017)</cite> , who use pretrained GloVe word embeddings, we learn our word embeddings from scratch.",
  "y": "differences"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_6",
  "x": "The first 6 rows are taken from , the next 4 are from Tomar et al. (2017) , the next 5 from Shen et al. (2017) and The last 4 rows are our experiments using Infersent<cite> (Conneau et al., 2017)</cite> and our models.",
  "y": "uses"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_7",
  "x": "For natural language inference, the same encoder is used to encode both the premise and hypothesis and a concatenation of their representations along with the absolute difference and hadamard product (as described in <cite>Conneau et al. (2017)</cite> ) are given to a single layer MLP with a dropout (Srivastava et al., 2014 ) rate of 0.3.",
  "y": "uses"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_9",
  "x": "In addition to performing 10-fold cross-validation to determine the L2 regularization penalty on the logistic regression models, we also tune the way in which our sentence representations are generated from the hidden states corresponding to words in a sentence. For example, use the last hidden state while <cite>Conneau et al. (2017)</cite> perform max-pooling across all of the hidden states. We consider both of these approaches and pick the one with better performance on the validation set.",
  "y": "uses differences"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_10",
  "x": "In tables 3 and 5 we do not concatenate the representations of multiple models. and <cite>Conneau et al. (2017)</cite> provide a detailed description of tasks that are typically used to evaluate sentence representations.",
  "y": "uses"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_11",
  "x": "In addition to the above tasks which were considered by <cite>Conneau et al. (2017)</cite> , we also evaluate on the recently published Quora duplicate question dataset 6 since it is an order of magnitude larger than the others (approximately 400,000 question pairs).",
  "y": "extends"
 },
 {
  "id": "547551e556d8aa919f731da99424c9_12",
  "x": "Other numbers were obtained from the evaluation suite provided by <cite>Conneau et al. (2017)</cite>",
  "y": "uses"
 },
 {
  "id": "5503b8571748ea900340aead22743b_0",
  "x": "These approaches can generally be classified in two categories: models that integrate base parsers at learning time, e.g., using stacking (Nivre and McDonald, 2008;<cite> Attardi and Dell'Orletta, 2009)</cite> , and approaches that combine independently-trained models only at parsing time (Sagae and Lavie, 2006; Hall et al., 2007; <cite>Attardi and Dell'Orletta, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "5503b8571748ea900340aead22743b_1",
  "x": "One such algorithm was proposed by<cite> Attardi and Dell'Orletta (2009)</cite> .",
  "y": "background"
 },
 {
  "id": "5503b8571748ea900340aead22743b_2",
  "x": "Recent work has shown that the combination of base parsers at learning time, e.g., through stacking, yields considerable benefits (Nivre and McDonald, 2008; <cite>Attardi and Dell'Orletta, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "55f67c918001335974608200a87cfc_0",
  "x": "Fusing structured knowledge from knowledge graphs into deep models using Graph Neural Networks (GNN) [23, 30, 29] is shown to improve their performance on tasks such as visual question answering [12] , object detection [9] , natural language inference [2] , neural machine translation [11] , and opendomain question answering <cite>[17]</cite> .",
  "y": "background"
 },
 {
  "id": "55f67c918001335974608200a87cfc_1",
  "x": "Text corpora have high coverage but extracting information from them is challenging whereas knowledge graphs are incomplete but are easier to extract answers from <cite>[17]</cite> . In this paper, we propose a relational GNN for open-domain question answering that learns contextual knowledge graph embeddings by jointly updating the embeddings from a knowledge graph and a set of linked documents.",
  "y": "motivation"
 },
 {
  "id": "55f67c918001335974608200a87cfc_2",
  "x": "A few recent works, on the other hand, use GNNs to compute the knowledge graph representation [24, 20, 27] . These high-level knowledge graph representations are particularly important for question answering task [22, 10, <cite>17]</cite> .",
  "y": "background"
 },
 {
  "id": "55f67c918001335974608200a87cfc_3",
  "x": "A few recent works, on the other hand, use GNNs to compute the knowledge graph representation [24, 20, 27] . These high-level knowledge graph representations are particularly important for question answering task [22, 10, <cite>17]</cite> . We use pre-trained representations to initialize the model and then update them using a relational and bi-directional GNN model.",
  "y": "extends motivation"
 },
 {
  "id": "55f67c918001335974608200a87cfc_4",
  "x": "This linking is used in GRAFT-Net as well which also performs question answering through fusing learned knowledge graph and linked document representations <cite>[17]</cite> .",
  "y": "background"
 },
 {
  "id": "55f67c918001335974608200a87cfc_5",
  "x": "Following <cite>[17]</cite> , we first extract a subgraph G q \u2282 G which contains v aq with high probability.",
  "y": "uses"
 },
 {
  "id": "55f67c918001335974608200a87cfc_6",
  "x": "To distinguish inward edges from outward edges, we negate h r . This is distinct from previous approaches which only process incoming nodes [<cite>17]</cite> .",
  "y": "differences"
 },
 {
  "id": "55f67c918001335974608200a87cfc_7",
  "x": "Following <cite>[17]</cite> , we apply the same pre-processing and report average F 1 and Hits@1, as well as micro-average, and macro-average F 1 scores.",
  "y": "uses"
 },
 {
  "id": "55f67c918001335974608200a87cfc_8",
  "x": "Table 1 shows the performance of our model compared to other models that also feature early fusion of the knowledge graph and text. These include Key-Value Memory Networks (KVMN) [3] and GRAFT-Net <cite>[17]</cite> . The results suggest that our model outperforms GRAFT-Net with an absolute increase in all metrics.",
  "y": "differences"
 },
 {
  "id": "563476cdb64cdf7d47bc5e8e1c32c3_0",
  "x": "Therefore, we apply a re-implementation of a state-of-the-art, discriminative L2P system <cite>(Jiampojamarn et al., 2008)</cite> to the problem, without further modification.",
  "y": "uses"
 },
 {
  "id": "563476cdb64cdf7d47bc5e8e1c32c3_1",
  "x": "For our submission, we re-implement the L2P approach described by<cite> Jiampojamarn et al. (2008)</cite> as faithfully as possible, and apply it unmodified to the transliteration shared task for the English-to-Hindi (Kumaran and Kellner, 2007) and English-to-Japanese Katakana 1 tests.",
  "y": "uses"
 },
 {
  "id": "563476cdb64cdf7d47bc5e8e1c32c3_2",
  "x": "There are two main categories of features: context and transition features, which follow the first two feature templates described by<cite> Jiampojamarn et al. (2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "563476cdb64cdf7d47bc5e8e1c32c3_3",
  "x": "Our system made two alternate design decisions (we do not claim improvements) over those made by <cite>(Jiampojamarn et al., 2008)</cite> , mostly based on the availability of software.",
  "y": "differences"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_0",
  "x": "Recent work seeks to derive valuable information from SynData while filtering noise, via domain adaptation (Braud and Denis, 2014; , classifying connectives (Rutherford and Xue, 2015) or multi-task learning (Lan et al., 2013;<cite> Liu et al., 2016)</cite> , and shows promising results.",
  "y": "background"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_1",
  "x": "Following <cite>Liu et al. (2016)</cite> , we alternately use two tasks to train the model, one task per epoch.",
  "y": "uses"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_2",
  "x": "<cite>Liu et al. (2016)</cite> use a multi-task model with three auxiliary tasks: 1) conn: connective classification on explicit instances, 2) exp: relation classification on the labeled explicit instances in the PDTB, and 3) rst: relation classification on the labeled RST corpus (William and Thompson, 1988), which defines different discourse relations with that in the PDTB.",
  "y": "background"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_3",
  "x": "Although <cite>Liu et al. (2016)</cite> achieve the stateof-the-art performance (Line 5), they use two additional labeled corpora.",
  "y": "background motivation"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_4",
  "x": "Although <cite>Liu et al. (2016)</cite> achieve the stateof-the-art performance (Line 5), they use two additional labeled corpora. We can find that M T N bi (Line 6) yields better results than those systems incorporating SynData (Line 1, 2 and 3), or even the labeled RST (Line 4).",
  "y": "differences"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_5",
  "x": "Lan et al. (2013) and <cite>Liu et al. (2016)</cite> combine explicit and implicit data using multi-task learning models and gain improvements.",
  "y": "background"
 },
 {
  "id": "56fa13128027f7c37d504d97cfcc45_6",
  "x": "Lan et al. (2013) and <cite>Liu et al. (2016)</cite> combine explicit and implicit data using multi-task learning models and gain improvements. Different from all the above work, we construct additional training data from a bilingual corpus.",
  "y": "differences"
 },
 {
  "id": "574ab9a51f3414e6587da7dfca2ff8_0",
  "x": "The last few years have seen an increased interest in narrative within the field of Natural Language Generation <cite>(Reiter et al., 2008</cite>; Elson and McKeown, 2010; Siddharthan et al., 2012; Lester, 2012) .",
  "y": "background"
 },
 {
  "id": "574ab9a51f3414e6587da7dfca2ff8_1",
  "x": "The last few years have seen an increased interest in narrative within the field of Natural Language Generation <cite>(Reiter et al., 2008</cite>; Elson and McKeown, 2010; Siddharthan et al., 2012; Lester, 2012) .",
  "y": "background"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_0",
  "x": "Similarly, the lexical predictability ratio (LPR) of<cite> Brooke et al. (2015)</cite> is an association measure applicable to any possible syntactic pattern, which is calculated by discounting syntactic predictability from the overall conditional probability for each word given the other words in the phrase.",
  "y": "background"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_1",
  "x": "Sakaguchi et al. (2016) demonstrate that improving fluency (closely linked to the use of linguistic formulas) is more important than improving strict grammaticality with respect to native speaker judgments of non-native productions;<cite> Brooke et al. (2015)</cite> explicitly argue for FS lexicons as a way to identify, track, and improve learner proficiency.",
  "y": "background"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_2",
  "x": "Our approach to FS identification involves optimization of the total explanatory power of a lattice, where each node corresponds to an n-gram type. The explanatory power of the whole lattice is defined simply as a product of the explainedness of the individual nodes. Each node can be considered either \"on\" (is an FS) or \"off\" (is not an FS). The basis of the calculation of explainedness is the syntax-sensitive LPR association measure of<cite> Brooke et al. (2015)</cite> , but it is calculated differently depending on the on/off status of the node as well as the status of the nodes in its vicinity.",
  "y": "uses differences"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_3",
  "x": "Since our primary association measure is an adaption of LPR, our approach in this section mostly follows<cite> Brooke et al. (2015)</cite> up until the last stage.",
  "y": "extends similarities"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_4",
  "x": "An initial requirement of any such method is an n-gram frequency threshold, which we set to 1 instance per 10 million words, following<cite> Brooke et al. (2015)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_5",
  "x": "In the segmentation approach of<cite> Brooke et al. (2015)</cite> , LPR for an entire span is calculated as a product of the individual LPRs, but here we will use the minimum LPR across the words in the sequence:",
  "y": "differences"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_6",
  "x": "We also use the concept of hard covering to address the issue of pronouns, based on the observation that specific pronouns often have high LPR values due to pragmatic biases <cite>(Brooke et al., 2015)</cite> ; for instance, private state verbs like feel tend to have first person singular subjects.",
  "y": "motivation"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_7",
  "x": "In English, we follow<cite> Brooke et al. (2015)</cite> in using a 890M token filtered portion of the ICWSM blog corpus (Burton et al., 2009 ) tagged with the Tree Tagger (Schmid, 1995) .",
  "y": "uses"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_8",
  "x": "For English, gaps are identified using the same POS regex used in<cite> Brooke et al. (2015)</cite> , which includes simple nouns and portions thereof, up to a maximum of 4 words.",
  "y": "similarities uses"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_9",
  "x": "Other than the inclusion of new languages, our test sets differ from<cite> Brooke et al. (2015)</cite> in two ways.",
  "y": "differences"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_11",
  "x": "The LPRseg method of<cite> Brooke et al. (2015)</cite> consistently outperforms simple ranking, and the lattice method proposed here does better still, with a margin that is fairly consistent across the languages.",
  "y": "differences"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_12",
  "x": "When only covering is used, the results are fairly similar to<cite> Brooke et al. (2015)</cite> , which is unsurprising given the extent to which decomposition and covering are related.",
  "y": "similarities"
 },
 {
  "id": "57ef27eefdf272bead22212863a8a8_14",
  "x": "Although the optimization of the lattice is several orders of magnitude more complex than the decomposition heuristics of<cite> Brooke et al. (2015)</cite> , the time needed to build and optimize the lattice is a fraction of the time required to collect the statistics for LPR calculation, and so the end-to-end runtimes of the two methods are comparable.",
  "y": "differences"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_0",
  "x": "<cite>Kushman and Barzilay (2013)</cite> proposed a model that learns to perform the task from a parallel corpus of regular expressions and the text descriptions.",
  "y": "background"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_1",
  "x": "Given the same parallel corpus used in <cite>Kushman and Barzilay (2013)</cite> , we use an LSTM-based sequence to sequence neural network to perform the mapping.",
  "y": "uses"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_2",
  "x": "Our work, however, is closest to <cite>Kushman and Barzilay (2013)</cite> .",
  "y": "similarities"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_3",
  "x": "We identify these via frequency analysis of smaller datasets from previous work<cite> (Kushman and Barzilay, 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_4",
  "x": "In addition, we also evaluate our model on the dataset used by <cite>Kushman and Barzilay (2013)</cite> (KB13), although it contains far fewer data points (824).",
  "y": "uses"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_5",
  "x": "We report DFA-Equal accuracy as our model's evaluation metric, using <cite>Kushman and Barzilay (2013)</cite> 's implementation to directly compare our results.",
  "y": "uses"
 },
 {
  "id": "58b423c4ea2a3530d0c469fc0f5528_6",
  "x": "Semantic-Unify: Our second baseline, SemanticUnify, is the previous state-of-the-art model from<cite> (Kushman and Barzilay, 2013)</cite> , explained above.",
  "y": "uses"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_0",
  "x": "1.) Geodesic grids are the most straightforward, but do not \"lead to a natural representation of the administrative, population-based or language boundaries in the region\"<cite> (Han et al., 2012)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_1",
  "x": "Previous work includes three different approaches to discretizing continuous values into location labels (see also Section 2): 1.) Geodesic grids are the most straightforward, but do not \"lead to a natural representation of the administrative, population-based or language boundaries in the region\"<cite> (Han et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_2",
  "x": "Previous work typically considered cities with a population of at least 100K <cite>(Han et al., 2012</cite> (Han et al., , 2014 .",
  "y": "background"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_3",
  "x": "Previous work typically considered cities with a population of at least 100K <cite>(Han et al., 2012</cite> (Han et al., , 2014 . This approach has the opposite problem of clustering: different linguistic areas might be contained within a single administrative region.",
  "y": "motivation"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_4",
  "x": "The ability of the labels to reflect real anthropological areas, however, affects primarily the models which rely on linguistic data. This is the case of the studies of<cite> Han et al. (2012)</cite> and Han et al. (2014) who based their predictions on the so-called Location-Indicative Words (LIW).",
  "y": "motivation"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_5",
  "x": "Data sets We apply our method to two widely used data sets for geolocation: TWITTER-US (Roller et al., 2012) , and TWITTER-WORLD<cite> (Han et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_6",
  "x": "The algorithm converges when the final number of points cannot be further reduced, since they all are farther apart from each other than the maximum distance d. After assigning each instance its new coordinates, we follow<cite> Han et al. (2012</cite> Han et al. ( , 2014 in using the GeoNames data set to associate clusters with cities, by substituting the instance coordinates with those of the closest town center.",
  "y": "uses"
 },
 {
  "id": "591e2873606d6171e48fd34a731fc7_7",
  "x": "Following<cite> Han et al. (2012)</cite> , we further filter the vocabulary via Information Gain Ratio (IGR), selecting the terms with the highest values until we reach a computationally feasible vocabulary size: here, 750K and 460K for TWITTER-US and TWITTER-WORLD.",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_0",
  "x": "Distant supervision is less expensive to obtain than directly supervised labels, but produces noisy training data whenever matching errors occur. Hence distant supervision is often coupled with learning methods that allow for this sort of noise, e.g., by introducing latent variables for each entity mention<cite> (Hoffmann et al., 2011</cite>; Riedel et al., 2010; Surdeanu et al., 2012) ; by carefully selecting the entity mentions from contexts likely to include specific KB facts (Wu and Weld, 2010) ; or by careful filtering of the KB strings used as seeds (Movshovitz-Attias and Cohen, 2012) .",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_1",
  "x": "Another recently-introduced approach to reducing the noise in distant supervision is to combine distant labeling with label propagation (LP) (Bing et al., 2015;<cite> Bing et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_2",
  "x": "Depending on the LP method used, agreement with seed labels can be imposed as a hard constraint (Zhu et al., 2003) or a soft constraint<cite> (Lin and Cohen, 2010</cite>; Talukdar and Cohen, 2014) .",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_3",
  "x": "An extension of this approach <cite>(Bing et al., 2016)</cite> learned to classify NP pairs as relations, using a more complex graph structure.",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_4",
  "x": "In <cite>(Bing et al., 2016)</cite> , relation extraction was performed on an \"entity centric\" corpus, where each document is primarily concerned with a particular \"title entity\", and the first argument of each relation is always the title entity: hence relation extraction can be viewed as classification, where an entity mention is labeled with its slot filling role, i.e., its relation to the title entity.",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_5",
  "x": "We use an existing multi-class label propagation method, namely, MultiRankWalk (MRW)<cite> (Lin and Cohen, 2010)</cite> , which is a graph-based SSL method related to personalized PageRank (PPR) (Haveliwala et al., 2003) (aka random walk with restart (Tong et al., 2006) ).",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_6",
  "x": "We use SVMs (Chang and<cite> Lin, 2001)</cite> and discard singleton features, as well as the most frequent 5% of features (as a stop-wording variant).",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_7",
  "x": "Our evaluation dataset contains 20 manually labeled pages, 10 pages each from the disease corpus WikiDisease and the drug corpus DailyMed. This data was originally generated in <cite>(Bing et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_8",
  "x": "We also compare against two latent variable learners. The first is MultiR<cite> (Hoffmann et al., 2011</cite>) which models each relation mention separately and aggregates their labels using a deterministic OR.",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_9",
  "x": "We also compare with DIEBOLDS <cite>(Bing et al., 2016)</cite> , which uses LP on a graph containing entity mention pairs.",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_10",
  "x": "The results for precision, recall and F1 measure are given in Table 1 . The results for DIEBOLDS are from <cite>(Bing et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_11",
  "x": "MultiR<cite> (Hoffmann et al., 2011) and</cite> MIML-RE (Surdeanu et al., 2012) extend this approach to support multi- ple relations expressed by different sentences in a bag.",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_12",
  "x": "To overcome the noise in distantly-labeled examples, (Riedel et al., 2010) introduced an \"at least one\" heuristic, where instead of taking all mentions for a pair as correct examples only at least one of them is assumed to express that relation. MultiR<cite> (Hoffmann et al., 2011) and</cite> MIML-RE (Surdeanu et al., 2012) extend this approach to support multi- ple relations expressed by different sentences in a bag.",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_13",
  "x": "Document structure was previously explored by <cite>(Bing et al., 2016)</cite> , which used the structure to enrich an LP graph by adding coupling edges between mentions in the same section of particular documents.",
  "y": "background"
 },
 {
  "id": "59b6eaca400342159b867d018d4042_14",
  "x": "In the classic bootstrap learning scheme (Riloff and Jones, 1999; Agichtein and Gravano, 2000;<cite> Bunescu and Mooney, 2007)</cite> , a small number of seed instances are used to extract new patterns from a large corpus, which are then used to extract more instances.",
  "y": "background"
 },
 {
  "id": "5a039a2af7e07cffff76d3470f32f1_0",
  "x": "Many techniques have been proposed to learn such embeddings (Pennington et al., 2014;<cite> Mikolov et al., 2013</cite>; Mnih and Kavukcuoglu, 2013) .",
  "y": "background"
 },
 {
  "id": "5a039a2af7e07cffff76d3470f32f1_1",
  "x": "There is a wealth of research on evaluating unsupervised word embeddings, which can be can be broadly divided into intrinsic and extrinsic evalu- <cite>(Mikolov et al., 2013</cite>; Gao et al., 2014; Schnabel et al., 2015) .",
  "y": "background"
 },
 {
  "id": "5a039a2af7e07cffff76d3470f32f1_2",
  "x": "Zahran et al. (Zahran et al., 2015) translated the English benchmark in<cite> (Mikolov et al., 2013)</cite> and used it to evaluate different embedding techniques when applied on a large Arabic corpus.",
  "y": "background"
 },
 {
  "id": "5a039a2af7e07cffff76d3470f32f1_3",
  "x": "Once tuples have been generated, they can be used as word analogy questions to evaluate different word embeddings as defined by Mikolov et al.<cite> (Mikolov et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "5a039a2af7e07cffff76d3470f32f1_4",
  "x": "This provides a more accurate representation of a relation as mentioned in<cite> (Mikolov et al., 2013)</cite> .",
  "y": "similarities"
 },
 {
  "id": "5a039a2af7e07cffff76d3470f32f1_5",
  "x": "Using this corpus, the authors generated three different word embeddings using three different techniques, namely the Continuous Bagof-Words (CBOW) model<cite> (Mikolov et al., 2013)</cite> , the Skip-gram model<cite> (Mikolov et al., 2013)</cite> and GloVe (Pennington et al., 2014) .",
  "y": "uses"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_0",
  "x": "Recent research has attempted to induce unsupervised bilingual lexicons by aligning monolingual word vector spaces (Zhang et al., 2017a;<cite> Conneau et al., 2018</cite>; Aldarmaki et al., 2018; Artetxe et al., 2018a; Alvarez-Melis and Jaakkola, 2018; Mukherjee et al., 2018) . Given a pair of languages, their word alignment is inherently a bi-directional problem (e.g. EnglishItalian vs Italian-English). However, most existing research considers mapping from one language to another without making use of symmetry.",
  "y": "motivation background"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_1",
  "x": "As shown in Figure 1a , when the model of<cite> Conneau et al. (2018)</cite> is applied to English and Italian, the primal model maps the word \"three\" to the Italian word \"tre\", but the dual model maps \"tre\" to \"two\" instead of \"three\". We propose to address this issue by exploiting duality, encouraging forward and backward mappings to form a closed loop (Figure 1b ).",
  "y": "motivation background"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_2",
  "x": "In particular, we extend the model of<cite> Conneau et al. (2018)</cite> by using a cycle consistency loss (Zhou et al., 2016) to regularize two models in opposite directions. Our model significantly outperforms competitive baselines, obtaining the best published results.",
  "y": "differences similarities motivation"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_3",
  "x": "A typical line of work uses adversarial training (Miceli Barone, 2016; Zhang et al., 2017a,b;<cite> Conneau et al., 2018)</cite> , matching the distributions of source and target word embeddings through generative adversarial networks (Goodfellow et al., 2014) .",
  "y": "background"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_4",
  "x": "In this paper, we choose<cite> Conneau et al. (2018)</cite> as our baseline as it is theoretically attractive and gives strong results on large-scale datasets.",
  "y": "similarities"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_5",
  "x": "We take<cite> Conneau et al. (2018)</cite> as our baseline, introducing a novel regularizer to enforce cycle consistency. Let X = {x 1 , ..., x n } and Y = {y 1 , ..., y m } be two sets of n and m word embeddings for a source and a target language, respectively. The primal UBLI task aims to learn a linear mapping F : X \u2192 Y such that for each x i , F(x i ) corresponds to its translation in Y . Similarly, a linear mapping G : Y \u2192 X is defined for the dual task. In addition, we introduce two language discriminators D x and D y , which are trained to discriminate between the mapped word embeddings and the original word embeddings.",
  "y": "extends uses"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_6",
  "x": [
   "Conneau et al. (2018) align two word embedding spaces through generative adversarial networks, in which two networks are trained simultaneously."
  ],
  "y": "background"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_7",
  "x": "We follow<cite> Conneau et al. (2018)</cite> , using an unsupervised criterion to perform model selection.",
  "y": "uses"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_8",
  "x": "In preliminary experiments, we find in adversarial training that the single-direction criterion S(F, X, Y ) by<cite> Conneau et al. (2018)</cite> does not always work well. To address this, we make a simple extension by calculating the weighted average of forward and backward scores: Where \u03bb is a hyperparameter to control the importance of the two objectives. 1 Here S first generates bilingual lexicons by learned mappings, and then computes the average cosine similarity of these translations.",
  "y": "extends motivation"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_9",
  "x": "Our datasets includes: (i) The Multilingual Unsupervised and Supervised Embeddings (MUSE) dataset released by<cite> Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_10",
  "x": "We follow the evaluation setups of<cite> Conneau et al. (2018)</cite> , utilizing cross-domain similarity local scaling (CSLS) for retrieving the translation of given source words.",
  "y": "uses"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_11",
  "x": "Following a standard evaluation practice (Vuli\u0107 and Moens, 2013; Mikolov et al., 2013;<cite> Conneau et al., 2018)</cite> , we report precision at 1 scores (P@1).",
  "y": "uses"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_13",
  "x": "In this section, we compare our model with state-of-the-art systems, including those with different degrees of supervision. The baselines include: (1) Procrustes<cite> (Conneau et al., 2018)</cite> , which learns a linear mapping through Procrustes Analysis (Sch\u00f6nemann, 1966) .",
  "y": "background"
 },
 {
  "id": "5a2cd80d7c57e06a51457e53169b49_14",
  "x": "(4) GeoMM semi , iterative GeoMM with weak supervision. (5) Adv-C-Procrustes<cite> (Conneau et al., 2018)</cite> , which refines the mapping learned by Adv-C with iterative Procrustes, which learns the new mapping matrix by constructing a bilingual lexicon iteratively.",
  "y": "background"
 },
 {
  "id": "5ad1e8b75cc6f5b627f770cced8e0f_0",
  "x": "Approaches Based on Machine Translation (MT) Evaluation Metrics: <cite>Madnani et al. (2012)</cite> conduct a study on the usefulness of automated MT evaluation metrics (e.g., BLEU, NIST and Meteor) for the task of paraphrase identification.",
  "y": "background"
 },
 {
  "id": "5ad1e8b75cc6f5b627f770cced8e0f_1",
  "x": "From the Gold corpus, also the source text (numbered in the repository with 1, see <cite>Madnani et al. (2012)</cite> ) serves as reference, and the paraphrastic reuse of it (numbered with 2), provides the system output.",
  "y": "uses background"
 },
 {
  "id": "5ad1e8b75cc6f5b627f770cced8e0f_2",
  "x": "Similar to <cite>Madnani et al. (2012)</cite> we use these MT scores separately in a classification task to predict paraphrasticality where the respective MT score is fed into a MaxEnt classifier as only feature.",
  "y": "similarities"
 },
 {
  "id": "5aeb64701a6b7d9878ea5e14a87b4e_1",
  "x": "Some are \"lexical sample\" datasets, that is, only occurrences of some selected lemmas are annotated (McCarthy and Navigli, 2009; Biemann, 2013) , and some are \"all-words\", providing substitutes for all content words in the given sentences (Sinha and Mihalcea, 2014;<cite> Kremer et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "5aeb64701a6b7d9878ea5e14a87b4e_2",
  "x": "In addi- Table 2 : Analysis of lexical substitution data: Relation of the substitute to the target, in percentages by part of speech (from Kremer et al. (2014)) tion, providing substitutes is a task that seems to be well doable by untrained annotators: Both Biemann (2013) and our recent annotation<cite> (Kremer et al., 2014)</cite> used crowdsourcing to collect the substitutes.",
  "y": "background"
 },
 {
  "id": "5aeb64701a6b7d9878ea5e14a87b4e_3",
  "x": "In a recent lexical substitution annotation effort<cite> (Kremer et al., 2014)</cite> , we collected lexical substitution annotation for all nouns, verbs, and adjectives in a mixed news and fiction corpus, using untrained annotators via crowdsourcing.",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_0",
  "x": "<cite>Conneau et al. (2018)</cite> improved this approach with <cite>post-mapping refinements</cite>, showing impressive results for several language pairs.",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_1",
  "x": "<cite>Conneau et al. (2018)</cite> improved this approach with <cite>post-mapping refinements</cite>, showing impressive results for several language pairs. <cite>Their</cite> learned mapping was then successfully used to train a fully unsupervised neural machine translation system (Lample et al., 2018a,b) .",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_2",
  "x": "In particular, Artetxe et al. (2018b) show that the adversarial methods of <cite>Conneau et al. (2018)</cite> and Zhang et al. (2017a,b) fail for many language pairs.",
  "y": "motivation background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_3",
  "x": "In particular, Artetxe et al. (2018b) show that the adversarial methods of <cite>Conneau et al. (2018)</cite> and Zhang et al. (2017a,b) fail for many language pairs. In this paper, we revisit adversarial training and propose a number of key improvements that yield more robust training and improved mappings.",
  "y": "extends uses motivation"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_4",
  "x": "In particular, Artetxe et al. (2018b) show that the adversarial methods of <cite>Conneau et al. (2018)</cite> and Zhang et al. (2017a,b) fail for many language pairs. In this paper, we revisit adversarial training and propose a number of key improvements that yield more robust training and improved mappings. Our main idea is to learn the cross-lingual mapping in a projected latent space and add more constraints to guide the unsupervised mapping in this space.",
  "y": "extends"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_5",
  "x": "Although successful, adversarial training has been criticized for not being stable and failing to converge, inspiring researchers to propose nonadversarial methods more recently (Xu et al., 2018a; Hoshen and Wolf, 2018; Alvarez-Melis and Jaakkola, 2018; Artetxe et al., 2018b) . In particular, Artetxe et al. (2018b) show that the adversarial methods of <cite>Conneau et al. (2018)</cite> and Zhang et al. (2017a,b) fail for many language pairs.",
  "y": "motivation background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_6",
  "x": "Our results show that our model is more robust and yields significant gains over <cite>Conneau et al. (2018)</cite> for all translation tasks in all evaluation measures.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_7",
  "x": "This was first proposed by Miceli Barone (2016) , who initially used an adversarial network similar to <cite>Conneau et al. (2018)</cite> , and found that the mapper (which is also the encoder) translates everything to a single embedding, known commonly as the mode collapse issue (Goodfellow, 2017) .",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_8",
  "x": "<cite>Conneau et al. (2018)</cite> show impressive results with adversarial training and refinement with the Procrustes solution.",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_9",
  "x": "<cite>Conneau et al. (2018)</cite> show impressive results with adversarial training and refinement with the Procrustes solution. However, while <cite>all these methods</cite> learn the mapping in the original embedding space, our approach learns it in the latent code space considering both the mapper and the target encoder as adversary.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_10",
  "x": "Our aim is to learn a mapping f (x) in an unsupervised way (i.e., no bilingual dictionary given) such that for every x i , f (x) corresponds to its translation in Y. Our overall approach follows the same sequence of steps as <cite>Conneau et al. (2018)</cite>: 1.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_11",
  "x": "We use adversarial training to find a mapping between q(z x |x) and q(z y |y). This is in contrast with <cite>most existing methods</cite> (e.g., <cite>Conneau et al. (2018)</cite> ; Artetxe et al. (2017) ) that directly map the distribution of the source word embeddings p(x) to the distribution of the target p(y).",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_12",
  "x": "This is in contrast with <cite>most existing methods</cite> (e.g., <cite>Conneau et al. (2018)</cite> ; Artetxe et al. (2017) ) that directly map the distribution of the source word embeddings p(x) to the distribution of the target p(y).",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_13",
  "x": "Our discriminators have the same architecture as <cite>Conneau et al. (2018)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_14",
  "x": "Our discriminators have the same architecture as <cite>Conneau et al. (2018)</cite> . <cite>It is</cite> a feed-forward network with two hidden layers of size 2048 and Leaky-ReLU activations.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_15",
  "x": "We also apply the orthogonalization update to the mappers following <cite>Conneau et al. (2018)</cite> with \u03b2 = 0.01.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_16",
  "x": "Our training setting is similar to <cite>Conneau et al. (2018)</cite> , and we apply the same pre-and postprocessing steps.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_17",
  "x": "For selecting the best model, we use the unsupervised validation criterion proposed by <cite>Conneau et al. (2018)</cite> , which correlates highly with the mapping quality.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_18",
  "x": "For selecting the best model, we use the unsupervised validation criterion proposed by <cite>Conneau et al. (2018)</cite> , which correlates highly with the mapping quality. <cite>In this criterion</cite>, 10, 000 most frequent source words along with their nearest neighbors in the target space are considered.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_19",
  "x": "<cite>Conneau et al. (2018)</cite> and Artetxe et al. (2018b) propose fine-tuning methods to refine the initial mappings.",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_20",
  "x": "Similar to <cite>Conneau et al. (2018)</cite> ), we finetune our initial mappings (G and F ) by iteratively solving the Procrustes problem and applying a dictionary induction step.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_21",
  "x": "<cite>Conneau et al. (2018)</cite> and Artetxe et al. (2018b) propose fine-tuning methods to refine the initial mappings. Similar to <cite>Conneau et al. (2018)</cite> ), we finetune our initial mappings (G and F ) by iteratively solving the Procrustes problem and applying a dictionary induction step.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_22",
  "x": "Similar to <cite>Conneau et al. (2018)</cite> ), we finetune our initial mappings (G and F ) by iteratively solving the Procrustes problem and applying a dictionary induction step. <cite>This method</cite> uses singular value decomposition or SVD of Z T y Z x to find the optimal mappings G (similarly SVD(Z T x Z y ) for F ) given the approximate alignment of words from the previous step.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_23",
  "x": "For finding the nearest neighbors, we use the Cross-domain Similarity Local Scaling (CSLS) which works better in mitigating the hubness problem (<cite>Conneau et al., 2018</cite>) .",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_24",
  "x": "We evaluate our model on two different datasets. The first one is from <cite>Conneau et al. (2018)</cite> , <cite>which</cite> consists of FastText monolingual embeddings of (d =) 300 dimensions (Bojanowski et al., 2017) trained on Wikipedia monolingual corpus and gold dictionaries for 110 language pairs.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_25",
  "x": "We compare our method with the unsupervised models of <cite>Conneau et al. (2018)</cite> , Artetxe et al. (2018b) , Alvarez-Melis and Jaakkola (2018) , Xu et al. (2018a) , and Hoshen and Wolf (2018) .",
  "y": "similarities differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_26",
  "x": "To evaluate how our unsupervised method compares with methods that rely on a bilingual seed dictionary, we follow <cite>Conneau et al. (2018)</cite> , and compute a supervised baseline that uses the Procrustes solution directly on the seed dictionary (5000 pairs) to learn the mapping function, and then uses CSLS to do the nearest neighbor search.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_27",
  "x": "We compare our method with the unsupervised models of <cite>Conneau et al. (2018)</cite> , Artetxe et al. (2018b) , Alvarez-Melis and Jaakkola (2018) , Xu et al. (2018a) , and Hoshen and Wolf (2018) . For some of the <cite>baselines</cite>, results are reported from their papers, while for the rest we report results by running the publicly available codes on our machine.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_28",
  "x": "We present our results on European languages on the datasets of <cite>Conneau et al. (2018)</cite> and Dinu et al. (2015) in Tables 1 and 3 , while the results on non-European languages are shown in Table 2 .",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_29",
  "x": "Through experiments, our goal is to assess: 1. Does the unsupervised mapping method based on our proposed adversarial autoencoder model improve over the best existing adversarial method of <cite>Conneau et al. (2018)</cite> in terms of mapping accuracy and convergence (Section 5.1)?",
  "y": "motivation"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_31",
  "x": "Since our approach follows the same steps as <cite>Conneau et al. (2018),</cite> we first compare our proposed model with <cite>their model</cite> on European (Table 1) , non-European and low-resource languages (Table  2 ) on <cite>their dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_32",
  "x": "Since our approach follows the same steps as <cite>Conneau et al. (2018),</cite> we first compare our proposed model with <cite>their model</cite> on European (Table 1) , non-European and low-resource languages (Table  2 ) on <cite>their dataset</cite>. In the tables, we present the numbers that <cite>they</cite> reported in <cite>their paper</cite> (<cite>Conneau et al. (2018)</cite> (paper)) as well as the results that we get by running <cite>their code</cite> on our machine (<cite>Conneau et al. (2018)</cite> (code)).",
  "y": "uses similarities differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_33",
  "x": "Since our approach follows the same steps as <cite>Conneau et al. (2018),</cite> we first compare our proposed model with <cite>their model</cite> on European (Table 1) , non-European and low-resource languages (Table  2 ) on <cite>their dataset</cite>.",
  "y": "uses differences similarities"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_34",
  "x": "For a fair comparison with respect to the quality of the learned mappings (or induced seed dictionary), here we only consider the results of our approach that use the refinement procedure of <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_35",
  "x": "In Table 1 , we see that our Adversarial autoencoder + <cite>Conneau et al. (2018)</cite> Refinement outperforms <cite>Conneau et al. (2018)</cite> in all the six translation tasks involving European language pairs, yielding gains in the range 0.3 -1.3%.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_36",
  "x": "In Table 1 , we see that our Adversarial autoencoder + <cite>Conneau et al. (2018)</cite> Refinement outperforms <cite>Conneau et al. (2018)</cite> in all the six translation tasks involving European language pairs, yielding gains in the range 0.3 -1.3%. Our method is also superior to <cite>theirs</cite> for the non-European and low-resource language pairs in Table 2 .",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_37",
  "x": "In Table 1 , we see that our Adversarial autoencoder + <cite>Conneau et al. (2018)</cite> Refinement outperforms <cite>Conneau et al. (2018)</cite> in all the six translation tasks involving European language pairs, yielding gains in the range 0.3 -1.3%. We found <cite>their model</cite> to be very fragile for En from/to Ms, and does not converge at all for Ms\u2192En.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_38",
  "x": "In Table 1 , we see that our Adversarial autoencoder + <cite>Conneau et al. (2018)</cite> Refinement outperforms <cite>Conneau et al. (2018)</cite> in all the six translation tasks involving European language pairs, yielding gains in the range 0.3 -1.3%. We ran <cite>their code</cite> 10 times for Ms\u2192En but failed every time.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_39",
  "x": "Our method is also superior to <cite>theirs</cite> for the non-European and low-resource language pairs in Table 2 . We ran <cite>their code</cite> 10 times for Ms\u2192En but failed every time. Compared to <cite>that</cite>, our method is more robust and converged most of the time we ran.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_40",
  "x": "If we compare our method with the method of <cite>Conneau et al. (2018)</cite> on the more challenging Dinu-Artexe dataset in Table 3 , we see here also our method performs better than <cite>their method</cite> in all the four translation tasks involving European language pairs.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_41",
  "x": "If we compare our method with the method of <cite>Conneau et al. (2018)</cite> on the more challenging Dinu-Artexe dataset in Table 3 , we see here also our method performs better than <cite>their method</cite> in all the four translation tasks involving European language pairs. In this dataset, our method shows more robustness compared to <cite>their method</cite>.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_42",
  "x": "If we compare our method with the method of <cite>Conneau et al. (2018)</cite> on the more challenging Dinu-Artexe dataset in Table 3 , we see here also our method performs better than <cite>their method</cite> in all the four translation tasks involving European language pairs. For example, <cite>their method</cite> had difficulties in converging for En from/to Es translations; for En\u2192Es, it converges only 2 times out of 10 attempts, while for Es\u2192En it did not converge a single time in 10 attempts.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_43",
  "x": "If we compare our method with the method of <cite>Conneau et al. (2018)</cite> on the more challenging Dinu-Artexe dataset in Table 3 , we see here also our method performs better than <cite>their method</cite> in all the four translation tasks involving European language pairs. For example, <cite>their method</cite> had difficulties in converging for En from/to Es translations; for En\u2192Es, it converges only 2 times out of 10 attempts, while for Es\u2192En it did not converge a single time in 10 attempts. Compared to <cite>that</cite>, our method was more robust, converging 4 times out of 10 attempts.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_44",
  "x": "In Section 5.3, we compare our model with <cite>Conneau et al. (2018)</cite> more rigorously by evaluating them with and without fine-tuning and measuring their performance on P@1, P@5, and P@10.",
  "y": "uses differences similarities"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_45",
  "x": "In this section, we compare our model with other state-of-the-art methods that do not follow the same procedure as us and <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_46",
  "x": "Let us first consider the results for European language pairs on the dataset of <cite>Conneau et al. (2018)</cite> in Table 1 . Our Adversarial autoencoder + <cite>Conneau et al. (2018)</cite> Refinement performs better than most of the other methods on <cite>this dataset</cite>, achieving the highest accuracy for 4 out of 6 translation tasks.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_48",
  "x": "In our first experiment, we use their method to induce the initial seed dictionary and then apply iterative Procrustes solution (same refinement procedure of <cite>Conneau et al. (2018)</cite> ) for refinement.",
  "y": "uses"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_49",
  "x": "This setup allows us to compare our model directly with the adversarial model of <cite>Conneau et al. (2018)</cite> , putting the effect of finetuning aside.",
  "y": "uses differences similarities"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_50",
  "x": "This setup allows us to compare our model directly with the adversarial model of <cite>Conneau et al. (2018)</cite> , putting the effect of finetuning aside. Table 5 presents the ablation results for En-Es, En-De, and En-It in both directions. The first row presents the results of <cite>Conneau et al. (2018)</cite> <cite>that</cite> uses adversarial training to map the word embeddings.",
  "y": "uses similarities differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_51",
  "x": "However, it is important Table 5 : Ablation study of our adversarial autoencoder model on the dataset of <cite>Conneau et al. (2018)</cite>. to note that in contrast to <cite>Conneau et al. (2018)</cite> , our mapping is performed at the code space.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_52",
  "x": "As we compare our full model with the model of <cite>Conneau et al. (2018)</cite> in the without fine-tuning setting, we notice large improvements in all measures across all datasets: 5.1 -7.3% in En\u2192Es, 3 -6% in Es\u2192En, 3.4 -4.3% in En\u2192De, 1 -3% in De\u2192En, 3.4 -4.3% in En\u2192It, and 0.3 -3.7% in It\u2192En.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_53",
  "x": "These improvements demonstrate that our model finds a better mapping compared to <cite>Conneau et al. (2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_54",
  "x": "If we compare the results of ---Cycle with <cite>Conneau-18,</cite> we see sizeable gains for En-Es in both directions.",
  "y": "differences"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_55",
  "x": "However, this is not surprising as it has been shown that iterative fine-tuning with Procrustes solution is a robust method that can recover many errors made in the initial mapping (<cite>Conneau et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "5b14e259a557aa3cbfcbd6265f04c8_56",
  "x": "Through extensive experimentations on six different language pairs comprising European, nonEuropean and low-resource languages from two different data sources, we demonstrate that our method outperforms the method of <cite>Conneau et al. (2018)</cite> for all translation tasks in all measures (P@{1,5,10}) across all settings (with and without fine-tuning).",
  "y": "differences"
 },
 {
  "id": "5b9a6590d2e7c49f9a9788abe6dc1b_0",
  "x": "Recent work on neural constituency parsing<cite> (Dyer et al., 2016</cite>; Choe and Charniak, 2016) has found multiple cases where generative scoring models for which inference is complex outperform base models for which inference is simpler.",
  "y": "background"
 },
 {
  "id": "5b9a6590d2e7c49f9a9788abe6dc1b_1",
  "x": "In this paper, we present experiments to isolate the degree to which each gain occurs for each of two state-of-the-art generative neural parsing models: the Recurrent Neural Network Grammar generative parser (RG) of <cite>Dyer et al. (2016)</cite> , and the LSTM language modeling generative parser (LM) of Choe and Charniak (2016) .",
  "y": "uses"
 },
 {
  "id": "5b9a6590d2e7c49f9a9788abe6dc1b_2",
  "x": "Our findings suggest the presence of model combination effects in both generative parsers: when parses found by searching directly in the generative parser are added to a list of candidates from a strong base parser (the RNNG discriminative parser, RD<cite> (Dyer et al., 2016)</cite> ), performance decreases when compared to using just candidates from the base parser, i.e., B \u222a A \u2192 A has lower evaluation performance than B \u2192 A (Section 3.1).",
  "y": "uses"
 },
 {
  "id": "5b9a6590d2e7c49f9a9788abe6dc1b_3",
  "x": "We refer to <cite>Dyer et al. (2016)</cite> for a complete description of these actions, and the constraints on them necessary to ensure valid parse trees.",
  "y": "uses"
 },
 {
  "id": "5b9a6590d2e7c49f9a9788abe6dc1b_4",
  "x": "Past work on discriminative neural constituency parsers has shown the effectiveness of beam search with a small beam (Vinyals et al., 2015) or even greedy search, as in the case of RD<cite> (Dyer et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "5b9a6590d2e7c49f9a9788abe6dc1b_5",
  "x": "We train RNNG discriminative (RD) and generative (RG) models, following <cite>Dyer et al. (2016)</cite> by using the same hyperparameter settings, and using pretrained word embeddings from Ling et al. (2015) for the discriminative model.",
  "y": "uses"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_0",
  "x": "Second, we discuss the work done by<cite> (Barzilay & Lee, 2003)</cite> who use clustering of paraphrases to induce rewriting rules. We will see, through classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments, that clustering may not be the best approach for automatic pattern identification.",
  "y": "motivation background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_1",
  "x": "Sentence Compression takes an important place for Natural Language Processing (NLP) tasks where specific constraints must be satisfied, such as length in summarization (Barzilay & Lee, 2002; Knight & Marcu, 2002; Shinyama et al., 2002;<cite> Barzilay & Lee, 2003</cite>; Le Nguyen & Ho, 2004; Unno et al., 2006) , style in text simplification (Marsi & Krahmer, 2005) or sentence simplification for subtitling (Daelemans et al., 2004) .",
  "y": "background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_2",
  "x": "Second, we will discuss the work done by<cite> (Barzilay & Lee, 2003)</cite> who use clustering of paraphrases to induce rewriting rules. We will see, through classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments, that clustering may not be the best approach for automatic pattern identification.",
  "y": "motivation background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_3",
  "x": "Two different approaches have been proposed for Sentence Compression: purely statistical methodologies<cite> (Barzilay & Lee, 2003</cite>; Le Nguyen & Ho, 2004) and hybrid linguistic/statistic methodologies (Knight & Marcu, 2002; Shinyama et al., 2002; Daelemans et al., 2004; Marsi & Krahmer, 2005; Unno et al., 2006) . As our work is based on the first paradigm, we will focus on the works proposed by<cite> (Barzilay & Lee, 2003)</cite> and (Le Nguyen & Ho, 2004) . (Barzilay & Lee, 2003 ) present a knowledge-lean algorithm that uses multiple-sequence alignment to learn generate sentence-level paraphrases essentially from unannotated corpus data alone. In contrast to (Barzilay & Lee, 2002) , they need neither parallel data nor explicit information about sentence semantics. Rather, they use two comparable corpora. Their approach has three main steps. First, working on each of the comparable corpora separately, they compute lattices compact graph-based representations to find commonalities within groups of structurally similar sentences. Next, they identify pairs of lattices from the two different corpora that are paraphrases of each other. Finally, given an input sentence to be paraphrased, they match it to a lattice and use a paraphrase from the matched lattices mate to generate an output sentence.",
  "y": "background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_4",
  "x": "In particular, (Le Nguyen & Ho, 2004) do not propose any methodology to automatically extract paraphrases. Instead, they collect a corpus by performing the decomposition program using news and their summaries. Comparatively,<cite> (Barzilay & Lee, 2003)</cite> propose to use the N-gram Overlap metric to capture similarities between sentences and automatically create paraphrase corpora. However, this choice is arbitrary and mainly leads to the extraction of quasi-exact or exact matching pairs.",
  "y": "motivation background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_5",
  "x": "For that purpose, we introduce a new metric, the Sumo-Metric. Unlike (Le Nguyen & Ho, 2004) , one interesting idea proposed by<cite> (Barzilay & Lee, 2003</cite> ) is to cluster similar pairs of paraphrases to apply multiplesequence alignment. However, once again, this choice is not justified and we will see by classical visualization methodologies (Kruskal & Wish, 1977) and exhaustive experiments by applying different clustering algorithms, that clustering may not be the best approach for automatic pattern identification. As a consequence, we will study global and local biology based sequence alignments compared to multi-sequence alignment that may lead to better results for the induction of rewriting rules.",
  "y": "motivation background differences"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_6",
  "x": "A few unsupervised metrics have been applied to automatic paraphrase identification and extraction<cite> (Barzilay & Lee, 2003</cite>; Dolan & Brockett, 2004) . However, these unsupervised methodologies show a major drawback by extracting quasi-exact 2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan & Brockett, 2004) and word N-gram overlap for<cite> (Barzilay & Lee, 2003)</cite> . Such pairs are clearly useless.",
  "y": "motivation background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_7",
  "x": "More recently, (Anonymous, 2007) proposed a new metric, the Sumo-Metric specially designed for asymmetrical entailed pairs identification, and proved better performance over previous established metrics, even in the specific case when tested with the Microsoft Paraphrase Research Corpus (Dolan & Brockett, 2004) . In particular, it shows systematically better F-Measure and Accuracy measures over all other metrics showing an improvement of (1) at least 2.86% in terms of F-Measure and 3.96% in terms of Accuracy and (2) at most 6.61% in terms of FMeasure and 6.74% in terms of Accuracy compared to the second best metric which is also systematically the word N-gram overlap similarity measure used by<cite> (Barzilay & Lee, 2003)</cite> .",
  "y": "background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_8",
  "x": "Literature shows that there are two main reasons to apply clustering for paraphrase extraction. On one hand, as<cite> (Barzilay & Lee, 2003)</cite> evidence, clusters of paraphrases can lead to better learning of text-totext rewriting rules compared to just pairs of paraphrases. On the other hand, clustering algorithms may lead to better performance than stand-alone similarity measures as they may take advantage of the different structures of sentences in the cluster to detect a new similar sentence.",
  "y": "background"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_9",
  "x": "However, as<cite> (Barzilay & Lee, 2003)</cite> do not propose any evaluation of which clustering algorithm should be used, we experiment a set of clustering algorithms and present the comparative results. Contrarily to what expected, we will see that clustering is not a worthy effort. Instead of extracting only sentence pairs from corpora 3 , one may consider the extraction of paraphrase sentence clusters.",
  "y": "differences motivation"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_11",
  "x": "First, clustering seems not to be a natural way to manage 4 The limitation to 500 data is due to computation costs since MDS requires the diagonalization of the square similarity or distance matrix. such data. Then, according to the clustering method used, several types of clusters can be expected: very small clusters which contain \"satellite\" data (pretty relevant) or large clusters with part of the main central class (pretty irrelevant). These results confirm the observed figures in the previous subsection and reinforce the sight that clustering is a worthless effort for automatic paraphrase corpora construction, contrarily to what<cite> (Barzilay & Lee, 2003)</cite> suggest.",
  "y": "differences"
 },
 {
  "id": "5c13e64d468b8a1c403072f213c992_12",
  "x": "Experiments, by using 4 algorithms and through visualization techniques, revealed that clustering is a worthless effort for paraphrase corpora construction, contrary to the literature claims<cite> (Barzilay & Lee, 2003)</cite> . Therefore simple paraphrase pair extraction is suggested and by using a recent and more reliable metric (Sumo-Metric) (Anonymous, 2007) designed for asymmetrical entailed pairs.",
  "y": "differences"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_0",
  "x": "We modify an existing system, HIER-SUM<cite> (Haghighi & Vanderwende, 2009</cite>) , to use our objective, which significantly outperforms the original HIERSUM in pairwise user evaluation.",
  "y": "extends"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_1",
  "x": "<cite>Haghighi and Vanderwende (2009)</cite> demonstrated that these models can improve the quality of generic multi-document summaries over simpler surface models.",
  "y": "background"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_2",
  "x": "We re-implement the HIERSUM system from <cite>Haghighi and Vanderwende (2009)</cite> , and show that using our objective dramatically improves the content of extracted summaries.",
  "y": "extends"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_4",
  "x": "However, the raw<cite> (Haghighi & Vanderwende, 2009).</cite> unigram distribution may contain words that appear frequently in one document, but do not reflect the content of the document set as a whole.",
  "y": "background"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_5",
  "x": "This idea was first presented by Daum\u00e9 and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by <cite>Haghighi and Vanderwende (2009)</cite> .",
  "y": "background"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_6",
  "x": "HIERSUM<cite> (Haghighi & Vanderwende, 2009</cite> ) adds more structure to TOPICSUM by further splitting the content distribution into multiple sub-topics.",
  "y": "background"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_7",
  "x": "This quantity is used for summary sentence selection in several systems including Lerman and McDonald (2009) and <cite>Haghighi and Vanderwende (2009)</cite> , and was used as a feature in the discrimitive sentence ranking of Daum\u00e9 and Marcu (2006) .",
  "y": "background"
 },
 {
  "id": "5c5abc2773143af41d49087e17310e_8",
  "x": "We asked users to select which summary was better for the following ques-5 <cite>Haghighi and Vanderwende (2009)</cite> Q1 Which was better in terms of overall content?",
  "y": "uses"
 },
 {
  "id": "5cb56f6bf8123a9949a7f7c4ebc85c_0",
  "x": "Our study focuses on evaluating transfer learning using BERT <cite>(Devlin et al., 2019)</cite> to classify tokens from hotel reviews in bahasa Indonesia.",
  "y": "uses"
 },
 {
  "id": "5cb56f6bf8123a9949a7f7c4ebc85c_1",
  "x": "Our main contribution in this study is evaluating BERT <cite>(Devlin et al., 2019)</cite> as a pretrained transformer model on this token classification task on hotel reviews in bahasa Indonesia.",
  "y": "uses"
 },
 {
  "id": "5cb56f6bf8123a9949a7f7c4ebc85c_2",
  "x": "We proposed to use transfer learning from pretrained BERT-Base, Multilingual Cased <cite>(Devlin et al., 2019)</cite> for this token classification problem.",
  "y": "uses"
 },
 {
  "id": "5cb56f6bf8123a9949a7f7c4ebc85c_3",
  "x": "In their paper,<cite> Devlin et al. (2019)</cite> show that they can achieve state-of-the-art performance not only on sentence-level, but also on token-level tasks, such as for named entity recognition (NER).",
  "y": "background"
 },
 {
  "id": "5cb56f6bf8123a9949a7f7c4ebc85c_4",
  "x": "In their paper,<cite> Devlin et al. (2019)</cite> show that they can achieve state-of-the-art performance not only on sentence-level, but also on token-level tasks, such as for named entity recognition (NER). This motivates us to explore BERT in our study.",
  "y": "motivation"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_0",
  "x": "We follow the step-by-step approach to neural data-to-text generation we proposed in <cite>Moryossef et al. (2019)</cite> , in which the generation process is divided into a text-planning stage followed by a plan-realization stage.",
  "y": "uses"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_1",
  "x": "We follow the step-by-step approach to neural data-to-text generation we proposed in <cite>Moryossef et al. (2019)</cite> , in which the generation process is divided into a text-planning stage followed by a plan-realization stage. We suggest four extensions to that framework: (1) we introduce a trainable neural planning component that can generate effective plans several orders of magnitude faster than <cite>the original planner</cite>; (2) we incorporate typing hints that improve <cite>the model</cite>'s ability to deal with unseen relations and entities; (3) we introduce a verification-by-reranking stage that substantially improves the faithfulness of the resulting texts; (4) we incorporate a simple but effective referring expression generation module.",
  "y": "extends"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_2",
  "x": "In recent work <cite>(Moryossef et al., 2019)</cite> <cite>we</cite> proposed to adopt ideas from \"traditional\" language generation approaches (i.e. Reiter and Dale (2000) ; Walker et al. (2007) ; Gatt and Krahmer (2017) ) that separate the generation into a planning stage that determines the order and structure of the expressed facts, and a realization stage that maps the plan to natural language text.",
  "y": "background"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_3",
  "x": "In recent work <cite>(Moryossef et al., 2019)</cite> <cite>we</cite> proposed to adopt ideas from \"traditional\" language generation approaches (i.e. Reiter and Dale (2000) ; Walker et al. (2007) ; Gatt and Krahmer (2017) ) that separate the generation into a planning stage that determines the order and structure of the expressed facts, and a realization stage that maps the plan to natural language text. <cite>We</cite> show that by breaking the task this way, one can achieve the same fluency of neural generation systems while being able to better control the form of the generated text and to improve its correctness by reducing missing facts and \"hallucinations\", common in neural systems.",
  "y": "background"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_4",
  "x": "In this work we adopt the step-by-step framework of <cite>Moryossef et al. (2019)</cite> and propose four independent extensions that improve aspects of our original system: we suggest a new plan generation mechanism, based on a trainable-yetverifiable neural decoder, that is orders of magnitude faster than the original one ( \u00a73); we use knowledge of the plan structure to add typing information to plan elements.",
  "y": "extends uses"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_6",
  "x": "The data-to-plan component in <cite>Moryossef et al. (2019)</cite> exhaustively generates all possible plans, scores them using a heuristic, and chooses the highest scoring one for realization.",
  "y": "background"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_7",
  "x": "Each truncated DFS traversal corresponds to a sentence plan, following the DFS-to-plan procedure of <cite>Moryossef et al. (2019)</cite> : the linearized plan is generated incrementally at each step of the traversal.",
  "y": "uses"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_8",
  "x": "Speed On a 7 edges graph, <cite>the planner</cite> of <cite>Moryossef et al. (2019)</cite> takes an average of 250 seconds to generate a plan, while our planner takes 0.0025 seconds, 5 orders of magnitude faster.",
  "y": "differences"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_9",
  "x": "In <cite>Moryossef et al. (2019)</cite> , the sentence plan trees were linearized into strings that were then fed to a neural machine translation decoder (Open-NMT) (Klein et al., 2017) with a copy mecha-nism.",
  "y": "background"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_10",
  "x": "While the clear mapping between plans and text helps to reduce these issues greatly, <cite>the system</cite> in <cite>Moryossef et al. (2019)</cite> still has 2% errors of these kinds.",
  "y": "background"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_12",
  "x": "<cite>Moryossef et al. (2019)</cite> suggests the possibility of handling this with a post-processing referring-expression generation step (REG).",
  "y": "background"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_15",
  "x": "We repeat the coverage experiment in <cite>(Moryossef et al., 2019)</cite> , counting the number of output texts that contain all the entities in the input graph, and, of these text, counting the ones in which the entities appear in the exact same order as the plan.",
  "y": "uses"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_16",
  "x": "We thus performed manual analysis, following the procedure in <cite>Moryossef et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_18",
  "x": "We adopt the planning-based neural generation framework of <cite>Moryossef et al. (2019)</cite> and extend it to be orders of magnitude faster and produce more correct and more fluent text.",
  "y": "extends uses"
 },
 {
  "id": "5d68c07f716cd3c9861921d7e515ea_19",
  "x": "We conclude that these extensions not only improve <cite>the system</cite> of <cite>Moryossef et al. (2019)</cite> but also highlight the flexibility and advantages of the step-by-step framework for text generation.",
  "y": "differences"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_0",
  "x": "To address this drawback, new VQA datasets<cite> [44,</cite> 8, 37] have been recently proposed with questions that explicitly require understanding and reasoning about text in the image, which is referred to as the TextVQA task.",
  "y": "background"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_1",
  "x": "Compared to previous work (e.g. <cite>[44]</cite> ) on the TextVQA task, our model, accompanied by rich features for image text, handles all modalities with a multimodal transformer over a joint embedding space instead of pairwise fusion mechanisms between modalities.",
  "y": "differences"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_2",
  "x": "Several approaches<cite> [44,</cite> 8, 37, 7] have been proposed for the TextVQA task, based on OCR results of the image. In particular, LoRRA <cite>[44]</cite> extends previous VQA models [43] with an OCR attention branch and adds OCR tokens as a dynamic vocabulary to the answer classifier, allowing copying a single OCR token from the image as the answer.",
  "y": "background"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_3",
  "x": "In particular, LoRRA <cite>[44]</cite> extends previous VQA models [43] with an OCR attention branch and adds OCR tokens as a dynamic vocabulary to the answer classifier, allowing copying a single OCR token from the image as the answer. Similarly in [37] , OCR tokens are grouped into blocks and added to the output space of a VQA model. While these approaches enable reading text in images to some extent, they typically rely on custom pairwise multimodal fusion mechanisms between two modalities (such as single-hop attention over image regions and text tokens, conditioned on the input question), which limit the types of possible interactions between modalities. Furthermore, they treat answer prediction as a single-step classification problem -either selecting an answer from the training set answers or copying a text token from the image -making it difficult to generate complex answers such as book titles or signboard names with multiple words, or answers with both common words and specific image text tokens, such as McDonald's burger where McDonald's is from text in the image and burger is from the model's own vocabulary. In addition, the word embedding based image text features in previous work have limited representation power and miss important cues such as the appearance (e.g. font and color) and the location of text tokens in images. For example, tokens that have different fonts and are spatially apart from each other usually do not belong to the same street sign. In this paper, we address the above limitations with our novel Multimodal Multi-Copy Mesh (M4C) model for the TextVQA task, based on the transformer [48] architecture accompanied by iterative answer decoding through dynamic pointers, as shown in Figure 1 .",
  "y": "motivation"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_4",
  "x": "4) Our model significantly outperforms previous work on three challenging datasets for the TextVQA task: TextVQA <cite>[44]</cite> (+25% relative), ST-VQA [8] (+65% relative), and OCR-VQA [37] (+32% relative).",
  "y": "differences"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_5",
  "x": "Recently, a few datasets and methods<cite> [44,</cite> 8, 37, 7] have been proposed for visual question answering based on text in images (referred to as the TextVQA task).",
  "y": "background"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_6",
  "x": "LoRRA <cite>[44]</cite> , a prominent prior work on this task, extends the Pythia [43] framework for VQA and allows it to copy a single OCR token from the image as the answer, by applying a single attention hop (conditioned on the question) over the OCR tokens and including the OCR token indices in the answer classifier's output space.",
  "y": "background"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_7",
  "x": "For the TextVQA task, recent works<cite> [44,</cite> 37] have proposed to copy OCR tokens by adding their indices to classifier outputs.",
  "y": "background"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_8",
  "x": "For the TextVQA task, recent works<cite> [44,</cite> 37] have proposed to copy OCR tokens by adding their indices to classifier outputs. However, apart from their limitation of copying only a single token (or block), one drawback of these approaches is that they require a pre-defined number of OCR tokens (since the classifier has a fixed output dimension) and their output is dependent on the ordering of the tokens. In this work, we overcome this drawback using a permutation-invariant pointer network together with our multimodal transformer.",
  "y": "extends"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_9",
  "x": "Following prior work [3, 43,<cite> 44]</cite> , we extract appearance feature x fr m using the detector's output from the m-th object (where m = 1, \u00b7 \u00b7 \u00b7 , M ).",
  "y": "uses"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_10",
  "x": "We follow this intuition in our model and use a rich OCR representation consisting of four types of features, which is shown in our experiments to be significantly better than word embedding (such as FastText) alone in prior work <cite>[44]</cite> .",
  "y": "differences"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_11",
  "x": "We evaluate our model on three challenging datasets for the TextVQA task, including the TextVQA dataset <cite>[44]</cite> , the ST-VQA dataset [8] , and the OCR-VQA dataset [37] .",
  "y": "uses"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_12",
  "x": "The TextVQA dataset <cite>[44]</cite> contains 28,408 images from the Open Images dataset [27] , with human-written questions asking to reason about text in the image.",
  "y": "background"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_13",
  "x": "For visual objects, following Pythia [43] and LoRRA <cite>[44]</cite> , we detect objects with a Faster R-CNN detector [41] pretrained on the Visual Genome dataset [26] , and keeps 100 top-scoring objects per image.",
  "y": "uses"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_14",
  "x": "Unlike the prior work LoRRA <cite>[44]</cite> that uses a multilingual Rosetta version, in our model we use an English-only version of Rosetta that we find has higher recall.",
  "y": "differences"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_15",
  "x": "As a notable prior work on this dataset, we show a stepby-step comparison with the LoRRA model <cite>[44]</cite> .",
  "y": "uses"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_16",
  "x": "Figure 4 shows qualitative examples (more examples in appendix) of our M4C model on the TextVQA dataset in comparison to LoRRA <cite>[44]</cite> , where our model is capable of selecting multiple OCR tokens and combining them with its fixed vocabulary in predicted answers.",
  "y": "uses"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_17",
  "x": "Compared to the previous work LoRRA <cite>[44]</cite> which selects one answer from training set or copies only a single OCR token, our model can copy multiple OCR tokens and combine them with its fixed vocabulary through iterative decoding.",
  "y": "differences"
 },
 {
  "id": "5e0b1b085a7a10b1e1c17286f7048e_18",
  "x": "However, we note that even without fixed answer vocabulary, our restricted model (M4C w/o fixed vocabulary in Table 5 ) still outperforms the previous work LoRRA <cite>[44]</cite> , suggesting that it is particularly important to learn to copy multiple OCR tokens to form an answer (a key feature in our model but not in LoRRA).",
  "y": "differences"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_0",
  "x": "Besides CCA, a few others learn a visual-semantic or multimodal embedding space of image descriptions and representations by optimizing a ranking cost function (Kiros et al., 2015; Socher et al., 2014; <cite>Vendrov et al., 2016)</cite> or by aligning image regions (objects) and segments of the description Plummer et al., 2015) in a common space.",
  "y": "background"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_1",
  "x": "Following<cite> Vendrov et al. (2016)</cite> we set the dimensionality of the embedding space and the GRU hidden layer N to 1024 for both English and German.",
  "y": "similarities uses"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_2",
  "x": "For the former we use cosine similarity and for the latter we use the metric of<cite> Vendrov et al. (2016)</cite> which is useful for learning embeddings that maintain an order, e.g., dog and cat are more closer to pet than animal while being distinct.",
  "y": "uses similarities"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_3",
  "x": "Specifically, we use Visual Semantic Embeddings (VSE) of Kiros et al. (2015) and Order Embeddings (OE) of<cite> Vendrov et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_5",
  "x": "In Tables 1 and 2 we present the ranking results of the baseline models of Kiros et al. (2015) and<cite> Vendrov et al. (2016)</cite> and our proposed PIVOT and PARALLEL models.",
  "y": "background"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_6",
  "x": "In the semantic textual similarity task (STS), we use the textual embeddings from our model to compute the similarity between a pair of sen- (Wieting et al., 2017) \u2212 83.7 84.5 85.0 MLMME (Calixto et al., 2017) VGG19 \u2212 72.7 79.7 VSE (Kiros et al., 2015) VGG19 80.6 82.7 89.6 OE<cite> (Vendrov et al., 2016)</cite> VGG19 82.",
  "y": "similarities"
 },
 {
  "id": "5e85f66e9971497e5e21af6893418d_7",
  "x": "We compare with the best reported scores for the STS shared tasks, achieved by MLMME (Calixto et al., 2017) , paraphrastic sentence embeddings (Wieting et al., 2017) , visual semantic embeddings (Kiros et al., 2015) , and order embeddings<cite> (Vendrov et al., 2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "5f86a4791bee14e0b1053e9b9a6fff_0",
  "x": "So far, most researchers interested in co-occurrence of mutual translations have relied on bitexts where sentence boundaries (or other text unit boundaries) were easy to find (e.g. Gale & Church, 1991; Kumano & Hirakawa, 1994; Fung, 1995;<cite> Melamed, 1995)</cite> .",
  "y": "background"
 },
 {
  "id": "5f86a4791bee14e0b1053e9b9a6fff_1",
  "x": "However, when authors specify their algorithms in sufficient detail to answer this question, the most common answer (given, e.g., by Brown et al., 1993; Dagan et al., 1993; Kupiec, 1993;<cite> Melamed, 1995)</cite> turns out to be unsound.",
  "y": "background"
 },
 {
  "id": "5f86a4791bee14e0b1053e9b9a6fff_2",
  "x": "Other preconditions may be imposed if certain language-specific resources are available <cite>(Melamed, 1995)</cite> .",
  "y": "background"
 },
 {
  "id": "5f86a4791bee14e0b1053e9b9a6fff_3",
  "x": "It does not matter if there are dependencies among the different knowledge sources, as long as each is used as a simple filter on the co-occurrence relation <cite>(Melamed, 1995)</cite> .",
  "y": "background"
 },
 {
  "id": "5f97682d8a1b78f08fd3623ee81703_0",
  "x": "Subsequent research has focused on increasing recall -a noteworthy approach (OLLIE) uses bootstrapping for learning general language patterns <cite>(Mausam et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "5f97682d8a1b78f08fd3623ee81703_1",
  "x": "While the focus on verbs continues to be common in these Open IE systems, some works have directed attention on noun-mediated relations such as OL-LIE <cite>(Mausam et al., 2012)</cite> , RENOUN (Yahya et al., 2014) , and RELNOUN.",
  "y": "background"
 },
 {
  "id": "5f97682d8a1b78f08fd3623ee81703_2",
  "x": "Probably the earliest work on Nominal Open IE is OLLIE, which is a pattern learning approach based on a bootstrapped training data using high precision verb-based extractions <cite>(Mausam et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "5f97682d8a1b78f08fd3623ee81703_3",
  "x": "Following previous work <cite>(Mausam et al., 2012)</cite> , we report yield, since recall is proportional to yield and suffices for system comparisons.",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_0",
  "x": "In the generation step, a set of possible substitutions for the target word is commonly created by querying semantic databases such as Wordnet (Devlin and Tait, 1998) , learning substitution rules from sentence-aligned parallel corpora of complex-simple texts (Horn et al., 2014;<cite> Paetzold and Specia, 2017)</cite> , and learning word embeddings from a large corpora to obtain similar words of the complex word (Glava\u0161 and\u0160tajner, 2015; Kim et al., 2016; Specia, 2016a, 2017) .",
  "y": "background"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_1",
  "x": "For generating substitution candidates, we utilize the method proposed by<cite> Paetzold and Specia (2017)</cite> , which was recently shown to be the state-of-art method for generating substitution candidates.",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_2",
  "x": "The word embedding model is retrofitted over WordNet's synonym pairs (for details, please refer to<cite> Paetzold and Specia (2017)</cite> ).",
  "y": "uses background"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_3",
  "x": "As baseline features, we use the same n-gram probability features as in<cite> Paetzold and Specia (2017)</cite> , who also employ a neural network to rank substitution candidates.",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_4",
  "x": "As in<cite> Paetzold and Specia (2017)</cite> , the features were extracted using the SubIMDB corpus (Paetzold and Specia, 2015) .",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_5",
  "x": "Following previous works that used supervised machine learning for ranking in lexical simplification (Horn et al., 2014;<cite> Paetzold and Specia, 2017)</cite> , we train the DSSM using the LexMTurk dataset (Horn et al., 2014) , which contains 500 instances composed of a sentence, a target word and substitution candidates ranked by simplicity <cite>(Paetzold and Specia, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_6",
  "x": "To evaluate the proposed model, we conduct experiments on two common datasets for lexical simplification: BenchLS (Paetzold and Specia, 2016b) , which contains 929 instances, and NNSEval (Paetzold and Specia, 2016a) , which contains 239 instances. Each instance is composed of a sentence, a target word, and a set of gold candidates ranked by simplicity <cite>(Paetzold and Specia, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_7",
  "x": "We compared the proposed model (DSSM Ranking) to two state-of-the-art approaches to ranking in lexical simplification that exploit supervised machine learning-based methods. The first baseline is the Neural Substitution Ranking (NSR) approach described in <cite>(Paetzold and Specia, 2017)</cite> , which employs a multi-layer perceptron neural network.",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_9",
  "x": "All the three models employ the n-gram probability features extracted from the SubIMDB corpus (Paetzold and Specia, 2015) , as described in <cite>(Paetzold and Specia, 2017)</cite> , and are trained using the LexMTurk dataset.",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_10",
  "x": "We follow the Unsupervised Boundary Ranking Substitution Selection method described in<cite> Paetzold and Specia (2017)</cite> , which ranks candidates according to how well they fit the context of the target word, and discards 50% of the worst ranking candidates.",
  "y": "uses"
 },
 {
  "id": "5fe12a1a43957faded5722f698eb41_11",
  "x": "We follow the Unsupervised Boundary Ranking Substitution Selection method described in<cite> Paetzold and Specia (2017)</cite> , which ranks candidates according to how well they fit the context of the target word, and discards 50% of the worst ranking candidates. We obtain similar tendency in the results, with the DSSM Ranking outperforming both baselines.",
  "y": "similarities differences"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_0",
  "x": "Recently, <cite>Ott et al. (2011)</cite> have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews. However, the complementary problem of negative deceptive opinion spam, intended to slander competitive offerings, remains largely unstudied.",
  "y": "motivation"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_1",
  "x": "Following an approach similar to <cite>Ott et al. (2011)</cite> , in this work we create and study the first dataset of deceptive opinion spam with negative sentiment reviews.",
  "y": "similarities"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_2",
  "x": "Accordingly, there is a growing incentive for businesses to solicit and manufacture DECEPTIVE OPINION SPAMfictitious reviews that have been deliberately written to sound authentic and deceive the reader <cite>(Ott et al., 2011)</cite> .",
  "y": "motivation"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_3",
  "x": "While previous related work <cite>(Ott et al., 2011</cite>; Ott et al., 2012) has explored characteristics of positive deceptive opinion spam, the complementary problem of negative deceptive opinion spam remains largely unstudied.",
  "y": "motivation"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_4",
  "x": "Following the framework of <cite>Ott et al. (2011)</cite> , we use Amazon's Mechanical Turk service to produce the first publicly available 1 dataset of negative deceptive opinion spam, containing 400 gold standard deceptive negative reviews of 20 popular Chicago hotels.",
  "y": "similarities uses"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_5",
  "x": "In conjunction with <cite>Ott et al. (2011)</cite> 's positive deceptive opinion spam dataset, we then explore the interaction between sentiment and deception with respect to three types of language features: (1) changes in first-person singular use, often attributed to psychological distancing (Newman et al., 2003) , (2) decreased spatial awareness and more narrative form, consistent with theories of reality monitoring (Johnson and Raye, 1981) and imaginative writing (Biber et al., 1999; Rayson et al., 2001) , and (3) increased negative emotion terms, often attributed to leakage cues (Ekman and Friesen, 1969) , but perhaps better explained in our case as an exaggeration of the underlying review sentiment.",
  "y": "uses"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_6",
  "x": "One of the biggest challenges facing studies of deception is obtaining labeled data. Recently, <cite>Ott et al. (2011)</cite> have proposed an approach for generating positive deceptive opinion spam using Amazon's popular Mechanical Turk crowdsourcing service.",
  "y": "motivation"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_7",
  "x": "In this section we discuss our efforts to extend <cite>Ott et al. (2011)</cite> 's dataset to additionally include negative deceptive opinion spam.",
  "y": "extends"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_8",
  "x": "Deceptive negative reviews are gathered from Mechanical Turk using the same procedure as <cite>Ott et al. (2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_9",
  "x": "5 The average accepted review length was 178 words, higher than for the positive reviews gathered by <cite>Ott et al. (2011)</cite> , who report an average review length of 116 words.",
  "y": "differences"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_10",
  "x": "Following <cite>Ott et al. (2011)</cite> , we sample a subset of the available truthful reviews so that we retain an equal number of truthful and deceptive reviews (20 each) for each hotel.",
  "y": "similarities"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_11",
  "x": "However, because the truthful reviews are on average longer than our deceptive reviews, we sample the truthful reviews according to a log-normal distribution fit to the lengths of our deceptive reviews, similarly to <cite>Ott et al. (2011)</cite> Table 1 : Deception detection performance, incl.",
  "y": "similarities"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_12",
  "x": "Indeed, <cite>Ott et al. (2011)</cite> found that two out of three human judges were unable to perform statistically significantly better than chance (at the p < 0.05 level) at detecting positive deceptive opinion spam.",
  "y": "background"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_13",
  "x": "Following <cite>Ott et al. (2011)</cite> , we asked three volunteer undergraduate university students to read and make assessments on a subset of the negative review dataset described in Section 2.",
  "y": "similarities uses"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_14",
  "x": "Standard n-gram-based text categorization techniques have been shown to be effective at detecting deception in text (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; <cite>Ott et al., 2011</cite>; Feng et al., 2012) .",
  "y": "background"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_15",
  "x": "Following <cite>Ott et al. (2011)</cite> , we evaluate the performance of linear Support Vector Machine (SVM) classifiers trained with unigram and bigram term-frequency features on our novel negative deceptive opinion spam dataset.",
  "y": "uses"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_16",
  "x": "We employ the same 5-fold stratified cross-validation (CV) procedure as <cite>Ott et al. (2011)</cite> , whereby for each cross-validation iteration we train our model on all reviews for 16 hotels, and test our model on all reviews for the remaining 4 hotels.",
  "y": "uses"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_18",
  "x": "Likewise, our fake negative reviews had more verbs relative to nouns than truthful, suggesting a more narrative style that is indicative of imaginative writing (Biber et al., 1999; Rayson et al., 2001 ), a pattern also observed by <cite>Ott et al. (2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_19",
  "x": "In the positive reviews reported by <cite>Ott et al. (2011)</cite> , the rate of first person singular in fake reviews (M=4.36%, SD=2.96%) was twice the rate observed in truthful reviews (M=2.18%, SD=2.04%).",
  "y": "background"
 },
 {
  "id": "5fe872d8e15ac38f845bc244f7bf5f_20",
  "x": "We have additionally explored, albeit briefly, the relationship between sentiment and deception by utilizing <cite>Ott et al. (2011)</cite> 's positive deceptive opinion spam dataset in conjunction with our own.",
  "y": "uses"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_0",
  "x": "Distributed word representations, also known as word embeddings, are low-dimensional vector representations for words that capture semantic aspects (Bengio et al., 2003; Pennington et al., 2014; <cite>Mikolov et al., 2013a)</cite> .",
  "y": "background"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_1",
  "x": "More recently, Xu et al. (2014) combined the training objective of SKIP-GRAM<cite> (Mikolov et al., 2013a)</cite> with the training objective of (Bordes et al., 2013) to incorporate lexical 1 There exists work on relation extraction and knowledgebase completion that combines structured relation triplets and logical rules with unstructured text using various forms of latent variable models (Riedel et al., 2013; Chang et al., 2014; Toutanova et al., 2015; Rockt\u00e4schel et al., 2015) .",
  "y": "background"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_2",
  "x": "2 Subspace-regularized word embedding Although our proposed framework for relational modeling is general enough to use with any existing word embedding method, we work with Word2Vec model<cite> (Mikolov et al., 2013a)</cite> in this paper for illustrating our ideas and later for empirical evaluations.",
  "y": "uses"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_3",
  "x": "Two variants were proposed in<cite> (Mikolov et al., 2013a</cite> ) -SKIP-GRAM, which maximizes the log likelihood of the local context words given the target word, and CBOW, which maximizes the log likelihood of the target word given its local context.",
  "y": "background"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_4",
  "x": "Two variants were proposed in<cite> (Mikolov et al., 2013a</cite> ) -SKIP-GRAM, which maximizes the log likelihood of the local context words given the target word, and CBOW, which maximizes the log likelihood of the target word given its local context. We report empirical results with CBOW since it was computationally faster than SKIP-GRAM while giving similar results in our early explorations.",
  "y": "uses"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_5",
  "x": "Google word analogy data<cite> (Mikolov et al., 2013a)</cite> contains 19544 analogy relations (14 relation types -5 semantic, 9 syntactic) of the form a:b::c:d constructed from 550 unique relation triplets.",
  "y": "background"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_6",
  "x": "Google word analogy data<cite> (Mikolov et al., 2013a)</cite> contains 19544 analogy relations (14 relation types -5 semantic, 9 syntactic) of the form a:b::c:d constructed from 550 unique relation triplets. We use this data only for evaluation (test phase).",
  "y": "uses"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_7",
  "x": "We compare the proposed RELSUB model with two methods: (i) CBOW<cite> (Mikolov et al., 2013a)</cite> , and (ii) RELCONST which is based on constant translation model for relations which was originally proposed in (Bordes et al., 2013) for embedding knowledge-bases and was recently used by Table 2 : Google analogy data: Accuracy on word analogy task (Xu et al., 2014) for learning word embeddings.",
  "y": "uses"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_8",
  "x": "We use the Google word-analogy data<cite> (Mikolov et al., 2013a)</cite> for this evaluation.",
  "y": "uses"
 },
 {
  "id": "603f49fc6ecf90da67a9a55986f217_9",
  "x": "We compare the proposed RELSUB model with two methods: (i) CBOW<cite> (Mikolov et al., 2013a)</cite> , and (ii) RELCONST which is based on constant translation model for relations which was originally proposed in (Bordes et al., 2013) for embedding knowledge-bases and was recently used by Table 2 : Google analogy data: Accuracy on word analogy task (Xu et al., 2014) for learning word embeddings. We observe considerable gains with RELSUB over CBOW for semantic categories.",
  "y": "differences"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_0",
  "x": "In several cases, neural network approaches exceeded the previous state of the art on essay scoring<cite> (Taghipour and Ng, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_1",
  "x": "For example,<cite> Taghipour and Ng (2016)</cite> explore simple LSTM and CNN-based architectures with regression and evaluate on the ASAP-AES data.",
  "y": "background"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_2",
  "x": "On the other hand, recurrent neural networks may derive some of their predictive power in AES from more redundant signals in longer input sequences (as sketched by<cite> Taghipour and Ng (2016)</cite> ).",
  "y": "background"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_3",
  "x": "On the other hand, recurrent neural networks may derive some of their predictive power in AES from more redundant signals in longer input sequences (as sketched by<cite> Taghipour and Ng (2016)</cite> ). As a result, the shorter responses in SAS may hinder the ability of recurrent networks to achieve state-of-the-art results. To explore the effectiveness of neural network architectures on SAS, we use the basic architecture and parameters of<cite> Taghipour and Ng (2016)</cite> on three publicly available short answer datasets: ASAP-SAS (Shermis, 2015), Powergrading (Basu et al., 2013) , and SRA (Dzikovska et al., 2016 (Dzikovska et al., , 2013 .",
  "y": "motivation"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_4",
  "x": "To explore the effectiveness of neural network architectures on SAS, we use the basic architecture and parameters of<cite> Taghipour and Ng (2016)</cite> on three publicly available short answer datasets: ASAP-SAS (Shermis, 2015), Powergrading (Basu et al., 2013) , and SRA (Dzikovska et al., 2016 (Dzikovska et al., , 2013 .",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_5",
  "x": "We explore how well the optimal parameters for AES from<cite> Taghipour and Ng (2016)</cite> fare on these datasets, and whether different architectures and parameters perform better on the SAS task.",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_6",
  "x": "We took the best parameter set from<cite> Taghipour and Ng (2016)</cite> as our reference since it performed best on the AES data.",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_8",
  "x": "We work with the basic neural network architecture explored by<cite> Taghipour and Ng (2016)</cite> (Figure  4 ).",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_9",
  "x": "We use the same attention mechanism employed in<cite> Taghipour and Ng (2016)</cite> , which involves taking the dot product of each LSTM hidden state and a vector that is trained with the network.",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_10",
  "x": "The text is lightly preprocessed as input to the neural networks following<cite> Taghipour and Ng (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_11",
  "x": "Following<cite> Taghipour and Ng (2016)</cite> , for our parameter exploration experiments on the development set, we report the best performance across epochs.",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_12",
  "x": "Our focus in this section is comparing different architecture and parameter choices for the neural networks with the best parameters from<cite> Taghipour and Ng (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_13",
  "x": "We hypothesized that the mean-over-time layer is helpful when the input consists of longer responses (as was the case for the essay data in<cite> Taghipour and Ng (2016)</cite> ).",
  "y": "background"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_14",
  "x": "We hypothesized that the mean-over-time layer is helpful when the input consists of longer responses (as was the case for the essay data in<cite> Taghipour and Ng (2016)</cite> ). We computed the Pearson's correlation on the ASAP-SAS data between the difference on each prompt of the two conditions and the mean response length in the development set. However, the correlation was modest at 0.437.",
  "y": "differences"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_15",
  "x": "\"Baseline\" is the baseline non-neural system. \"T&N best\" is the best-performing parameter set in <cite>Taghipour & Ng (2016)</cite> : tuned embeddings (here, GLOVE 100 dimensions), 300-dimensional LSTM, unidirectional, mean-over-time layer.",
  "y": "background"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_16",
  "x": "\"Baseline\" is the baseline non-neural system. \"T&N best\" is the best-performing parameter set in<cite> Taghipour and Ng (2016)</cite> : tuned embeddings (here, GLOVE 100 dimensions), 300-dimensional LSTM, unidirectional, mean-over-time layer.",
  "y": "background"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_17",
  "x": "Mean-over-time produced competitive results on many prompts, but contrary to<cite> Taghipour and Ng (2016)</cite> , bidirectional LSTMS and attention produced some of the best results, which is consistent with results for neural models on other text classification tasks (e.g., Longpre et al. (2016) ).",
  "y": "differences"
 },
 {
  "id": "60b0b54af27a6b04a6708a60834952_18",
  "x": "Mean-over-time produced competitive results on many prompts, but contrary to<cite> Taghipour and Ng (2016)</cite> , bidirectional LSTMS and attention produced some of the best results, which is consistent with results for neural models on other text classification tasks (e.g., Longpre et al. (2016) ). Research is needed to explain these emerging differences in effective neural architectures for AES vs. SAS, including model-specific factors such as the interaction of an LSTM's integration of features over time and the redundancy of predictive signals in essays vs. short answers, along with data-specific factors such as the consistency of human scoring, the demands of different rubrics, and the homogeneity or diversity of prompts in each setting.",
  "y": "future_work"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_1",
  "x": "<cite>Clark and Curran (2004)</cite> evaluate a number of log-linear parsing models for CCG.",
  "y": "background"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_2",
  "x": "The feature set we use is from the best performing normal-form model in <cite>Clark and Curran (2004)</cite> .",
  "y": "uses"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_4",
  "x": "In <cite>Clark and Curran (2004)</cite> we describe a discriminative method for estimating the parameters of a log-linear parsing model.",
  "y": "background"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_5",
  "x": "In <cite>Clark and Curran (2004)</cite> we describe efficient methods for performing the calculations using packed charts. However, a very large amount of memory is still needed to store the packed charts for the complete training data even though the representation is very compact; in we report a memory usage of 30 GB. To handle this we have developed a parallel implementation of the estimation algorithm which runs on a Beowulf cluster.",
  "y": "motivation"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_6",
  "x": "In <cite>Clark and Curran (2004)</cite> we show that the parsing model resulting from training data generated in this way produces state-of-the-art CCG dependency recovery: 84.6 F-score over labelled dependencies.",
  "y": "background"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_7",
  "x": "In <cite>Clark and Curran (2004)</cite> we show that using this more restrictive setting has a small negative impact on the accuracy of the resulting parser (about 0.6 F-score over labelled dependencies). However, the memory requirement for training the model is now only 4 GB, a reduction of 87% compared with the original approach.",
  "y": "differences"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_8",
  "x": "The results in this section are all using the best performing normal-form model in <cite>Clark and Curran (2004)</cite> , which corresponds to row 3 in Table 3 .",
  "y": "uses"
 },
 {
  "id": "60cc075e5351a756de8f9919d5a84e_9",
  "x": "The parser is extremely fast, and in <cite>Clark and Curran (2004)</cite> we show that the F-score for labelled dependencies is almost 98%.",
  "y": "background"
 },
 {
  "id": "60d39eec9573e42d7fb306b0f696c7_0",
  "x": "With state-of-the-art empirical results, most regard BiLSTM-CNN as a robust core module for sequence-labeling NER [1,<cite> 2,</cite> 3, 4, 5] .",
  "y": "background"
 },
 {
  "id": "60d39eec9573e42d7fb306b0f696c7_1",
  "x": "With state-of-the-art empirical results, most regard BiLSTM-CNN as a robust core module for sequence-labeling NER [1,<cite> 2,</cite> 3, 4, 5] . However, each direction of BiLSTM only sees and encodes half of a sequence at each time step. This paper explores two types of cross-structures to help cope with the problem: Cross-BiLSTM-CNN and Att-BiLSTM-CNN.",
  "y": "motivation background"
 },
 {
  "id": "60d39eec9573e42d7fb306b0f696c7_2",
  "x": "For Baseline <cite>[2]</cite> , a CNN is used to compute character-level word features alongside word embedding and multi-layer BiLSTM is used to capture the future and the past for each time step:",
  "y": "uses"
 },
 {
  "id": "60d39eec9573e42d7fb306b0f696c7_3",
  "x": "Using OSBIE sequential labels <cite>[2]</cite> , when there are P entity types, the number of token classes d p = P \u00d7 4 + 1.",
  "y": "uses"
 },
 {
  "id": "60d39eec9573e42d7fb306b0f696c7_4",
  "x": "Besides Baseline-, Cross-, and Att-BiLSTM-CNN, results of bare-bone BiLSTM-CNN <cite>[2]</cite> , CRF-BiLSTM(-BiLSTM) [11, 12] , and CRF-IDCNN [11] from the literature are also listed.",
  "y": "uses"
 },
 {
  "id": "60f4e3a8c8cae1b1ba2620b11ae6b0_0",
  "x": "To that end, researchers have investigated the linguistic knowledge that these models learn by analyzing BERT (Goldberg, 2018; Lin et al., 2019) directly or training probing classifiers on the contextualized embeddings or attention heads of BERT (Tenney et al., 2019b,a;<cite> Hewitt and Manning, 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "60f4e3a8c8cae1b1ba2620b11ae6b0_1",
  "x": "<cite>Hewitt and Manning (2019)</cite> train a structural probing model that maps the hidden representations of each token to an inner-product space that corresponds to syntax tree distance.",
  "y": "background"
 },
 {
  "id": "60f4e3a8c8cae1b1ba2620b11ae6b0_2",
  "x": "(Using the gold root as the starting point in MST may artificially improve our results slightly, but this bias is applied evenly across all the models we compare.) The resulting tree is a valid directed dependency tree, though we follow <cite>Hewitt and Manning (2019)</cite> in evaluating it as undirected, for easier comparison with our MAX method.",
  "y": "uses"
 },
 {
  "id": "60f4e3a8c8cae1b1ba2620b11ae6b0_3",
  "x": "During evaluation when we compare the gold dependencies, to handle the subtokens within the merged tokens, we set all subtokens except for the first to depend on the first subtoken. This approach is largely similar to that in <cite>Hewitt and Manning (2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "60f4e3a8c8cae1b1ba2620b11ae6b0_4",
  "x": "Overall, the results of both analysis methods suggest that, although some attention heads of BERT capture specific dependency relation types, they do not reflect the full extent of the significant amount of syntactic knowledge BERT and RoBERTa are known to learn as shown in previous syntactic probing work (Tenney et al., 2019b;<cite> Hewitt and Manning, 2019)</cite> .",
  "y": "differences"
 },
 {
  "id": "60f54cf8f510affe214f63f8e23e19_0",
  "x": "We compare the performance of an off-the-shelf MWE identification system based on neural sequence tagging <cite>(Zampieri et al., 2018)</cite> using lemmas and surface forms as input features, encoded in the form of classical pre-initialised word2vec embeddings (Mikolov et al., 2013) or, alternatively, using new-generation FastText embeddings built from character n-grams (Bojanowski et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "60f54cf8f510affe214f63f8e23e19_1",
  "x": "The use of pre-trained vs. randomly initialised embeddings has been analysed in some PARSEME shared task papers (Ehren et al., 2018;<cite> Zampieri et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "60f54cf8f510affe214f63f8e23e19_2",
  "x": "The closest works to ours are the Veyn <cite>(Zampieri et al., 2018)</cite> and SHOMA (Taslimipoor and Rohanian, 2018) systems, submitted to the PARSEME shared task 1.1.",
  "y": "similarities"
 },
 {
  "id": "60f54cf8f510affe214f63f8e23e19_3",
  "x": "We use our inhouse MWE identification system Veyn <cite>(Zampieri et al., 2018)</cite> , based on sequence tagging using recurrent neural networks.",
  "y": "uses"
 },
 {
  "id": "616e8732490f0fa87d35998f769196_0",
  "x": "In addition, in the semantics domain, the use of a new TAG operation, flexible composition, is used to perform certain semantic operations that seemingly cannot be modeled with TL-MCTAG alone<cite> (Chiang and Scheffler, 2008)</cite> and in work in synchronous TAG semantics, constructions such as nested quantifiers require a set-local MCTAG (SL-MCTAG) analysis (Nesson and Shieber, 2006) .",
  "y": "background"
 },
 {
  "id": "616e8732490f0fa87d35998f769196_1",
  "x": "In Section 7 we recall the delayed TL-MCTAG formalism introduced by<cite> Chiang and Scheffler (2008)</cite> and define a CKY-style parser for it as well.",
  "y": "uses"
 },
 {
  "id": "616e8732490f0fa87d35998f769196_2",
  "x": "There are a few applications, including flexible composition and scrambling in free-word order languages that benefit from TAG-based grammars that drop the simultaneity requirement<cite> (Chiang and Scheffler, 2008</cite>; Rambow, 1994) .",
  "y": "background"
 },
 {
  "id": "616e8732490f0fa87d35998f769196_3",
  "x": "7 Delayed TL-MCTAG<cite> Chiang and Scheffler (2008)</cite> introduce the delayed TL-MCTAG formalism which makes use of a derivational distance restriction in a somewhat different way.",
  "y": "background"
 },
 {
  "id": "616e8732490f0fa87d35998f769196_4",
  "x": "Borrowing directly from<cite> Chiang and Scheffler (2008)</cite> , Figure 7 gives two examples.",
  "y": "uses"
 },
 {
  "id": "616e8732490f0fa87d35998f769196_5",
  "x": "Parsing for delayed TL-MCTAG is not discussed by<cite> Chiang and Scheffler (2008)</cite> but can be accomplished using a similar CKY-style strategy as in the two parsers above.",
  "y": "differences"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_0",
  "x": [
   "Zhang et al. (2014) proposed a triple-based document enrichment framework which uses triples of SPO as background knowledge. They first proposed a search enginebased method to evaluate the relatedness between every pair of triples, and then an iterative propagation algorithm was introduced to select the most relevant triples to a given source document (see Section 2), which achieved a good performance."
  ],
  "y": "background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_1",
  "x": "However, to evaluate the semantic relatedness between two triples,<cite> Zhang et al. (2014)</cite> primarily relied on the text of triples and used search engines, which makes their method difficult to re-implement and in turn limits its application in practice. Moreover, they did not carry out any task-based evaluation, which makes it uncertain whether their method will be helpful in real applications. Therefore, we instead use topic models, especially Latent Dirichlet Allocation (LDA), to encode distributional semantics of words and convert every triple into a real-valued vector, which is then used to evaluate the relatedness between a pair of triples. We then incorporate these triples into the given source document and represent them together as a graph of triples. Then a modified iterative propagation is carried out over the entire graph to select the most relevant triples of background knowledge to the given source document.",
  "y": "motivation background differences"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_2",
  "x": "The most closely related work in this area is our own <cite>(Zhang et al., 2014)</cite> , which used the triples of SPO as background knowledge. In that work, we first proposed a triple graph to represent the source document and then used a search enginebased iterative algorithm to rank all the triples.",
  "y": "background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_3",
  "x": "Triple graph<cite> Zhang et al. (2014)</cite> proposed the triple graph as a document representation, where the triples of SPO serve as nodes, and the edges between nodes indicate their semantic relatedness. There are two kinds of nodes in the triple graph: (1) source document nodes (sd-nodes), which are triples extracted from source documents, and (2) background knowledge nodes (bk-nodes), which are triples extracted from external sources. Both of them are extracted automatically with Reverb, a well-known Open Information Extraction system (Etzioni et al., 2011) . There are also two kinds of edges: (1) an edge between a pair of sd-nodes, and (2) an edge between one sd-node and another bk-node, both of which are unidirectional. In the original representation, there are no edges between two bk-nodes because they treat the bk-nodes as recipients of relevance weight only. In this paper, we modify this setup and connect every pair of bknodes with an edge, so the bk-nodes serve as intermediate nodes during the iterative propagation process and contribute to the final performance too as shown in our experiments (see Section 5.1).",
  "y": "differences background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_4",
  "x": "Relevance evaluation To compute the weight of a edge,<cite> Zhang et al. (2014)</cite> evaluate the semantic relatedness between two nodes with a search engine-based method. They first convert every node, which is a triple of SPO, into a query by combining the text of Subject and Object together. Then for every pair of nodes t i and t j , they construct three queries: p, q, and p \u2229 q, which correspond to the queries of t i , t j , and t j \u2229 t j , the combination of t i and t j . All these queries are put into a search engine to get H(p), H(q), and H(p \u2229 q), the numbers of returned pages for query p, p, and p \u2229 q. Then the WebJaccard Coefficient (Bollegala et al., 2007 ) is used to evaluate r(i, j), the relatedness between t i and t j , according to Formula 1. otherwise.",
  "y": "background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_5",
  "x": "Using r(i, j),<cite> Zhang et al. (2014)</cite> further define p(i, j), the probability of t i and t j propagating to each other, as shown in Formula 2. Here N is the set of all nodes, and \u03b4 (i, j) denotes whether an edge exists between two nodes or not.",
  "y": "background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_6",
  "x": "Zhang et al. (2014) evaluate this relevance by propagating relevance weight from sd-nodes to t b iteratively. After convergence, the relevance weight of t b will be treated as the final relevance to D. There are in total n \u00d7 n pairs of nodes, and their p(i, j) are stored in a matrix P.<cite> Zhang et al. (2014)</cite> use W = (w 1 , w 2 , . . . , w n ) to denote the relevance weights of nodes, where w i indicates the relevance of t i to D. At the beginning, each w i of bk-nodes is initialized to 0, and each that of sd-nodes is initialized to its importance to D. Then W is updated to W after every iteration according to Formula 3. They keep updating the weights of both sd-nodes and bk-nodes until convergence and do not distinguish them explicitly.",
  "y": "background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_7",
  "x": "In this part, we propose a modified iterative propagation based ranking model to select the mostrelevant triples of background knowledge. There are three primary modifications to the original model of<cite> Zhang et al. (2014)</cite> , all of which are shown more powerful in our experiments.",
  "y": "background"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_8",
  "x": "First of all, the original model <cite>(Zhang et al., 2014)</cite> does not reset the relevance weight of sdnodes after every iteration. This results in a continued decrease of the relevance weight of sd-nodes, which weakens the effect of sd-nodes during the iterative propagation and in turn affects the final performance. To tackle this problem, we decrease the relevance weight of bk-nodes and increase that of sd-nodes according to a fixed ratio after every iteration, so as to ensure that the total weight of sd-nodes is always higher than that of bk-nodes.",
  "y": "differences background motivation"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_9",
  "x": [
   "We also modify the definition of p(i, j), the probability of two nodes t i and t j propagating to each other. Zhang et al. (2014) compute this probability according to Formula 2, which highlights the number of neighbors, but weakens the relatedness between nodes, due to the normalization. We modify this setup by removing the normalization process and computing p(i, j) as the relatedness between t i and t j directly, which is evaluated according to Formula 1 ."
  ],
  "y": "differences motivation"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_10",
  "x": "Baseline systems As<cite> Zhang et al. (2014)</cite> argued, it is difficult to use the methods in traditional ranking tasks, such as information retrieval (Manning et al., 2008) and entity linking (Han et al., 2011; Sen, 2012) , as baselines in this task, because our model takes triples as basic input and thus lacks some crucial information such as link structure. For better comparison, we implement three methods as baselines, which have been proved effective in relevance evaluation: (1) Vector Space Model (VSM), (2) Word Embedding (WE), and (3) Latent Dirichlet Allocation (LDA). Note that our model captures the distributional semantics of triples with LDA, while WE serves as a baseline only, where the word embeddings are acquired over the same corpus mentioned previously with 2 http://www.sogou.com/labs/dl/c.html the publicly available tool word2vec 3 .",
  "y": "differences motivation"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_11",
  "x": "Experimental setup Previous research relies on manual annotation to evaluate the ranking performance <cite>(Zhang et al., 2014)</cite> , which costs a lot, and in which it is difficult to get high consistency. In this paper, we carry out an automatic evaluation.",
  "y": "background differences"
 },
 {
  "id": "6293d300ab46a6d6135ed256005403_12",
  "x": "This study encodes distributional semantics into the triple-based background knowledge ranking model <cite>(Zhang et al., 2014)</cite> for better document enrichment. We first use LDA to represent every triple as a real-valued vector, which is used to evaluate the relatedness between triples, and then propose a modified iterative propagation model to rank all the triples of background knowledge. For evaluation, we conduct two series of experiments: (1) evaluation as ranking problem, and (2) taskbased evaluation, especially for document classification. In the first set of experiments, our model outperforms multiple strong baselines based on VSM, LDA, and WE. In the second set of experiments, our full model with background knowledge outperforms the state-of-the-art systems significantly. Moreover, we also explore the impact of knowledge quality and show its importance.",
  "y": "background motivation"
 },
 {
  "id": "6330c615d4c62b30933dac3057c9d6_0",
  "x": "The discriminator decoder takes the hidden state at the last time step of a sequence concatenated with both the max-pooled and mean-pooled representation of the hidden states <cite>[20]</cite> and outputs a number in the range [0, 1].",
  "y": "uses"
 },
 {
  "id": "6330c615d4c62b30933dac3057c9d6_1",
  "x": "We use Adam optimizer [23] with \u03b21 = 0.7 and \u03b22 = 0.8 similar to <cite>[20]</cite> and use a batch size of 50.",
  "y": "similarities"
 },
 {
  "id": "6330c615d4c62b30933dac3057c9d6_2",
  "x": "We use the same pre-processing as in earlier work <cite>[20,</cite> 24] .",
  "y": "uses"
 },
 {
  "id": "6330c615d4c62b30933dac3057c9d6_3",
  "x": "We first pre-train our generator on the Gutenberg dataset [25] for 20 epochs and then fine-tune <cite>[20]</cite> them to our target datasets with a language modeling objective.",
  "y": "uses"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_0",
  "x": "Recently, with the renaissance of artificial neural networks in the form of deep learning algorithms, neural network (NN) based KWS has become very popular [5, 6,<cite> 7,</cite> 8] .",
  "y": "background"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_1",
  "x": "\u2022 We first train the popular KWS neural net models from the literature [5, 6,<cite> 7,</cite> 8] on Google speech commands dataset [9] and compare them in terms of accuracy, memory footprint and number of operations per inference.",
  "y": "similarities uses"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_2",
  "x": "Combining the strengths of CNNs and RNNs, convolutional recurrent neural network based KWS is investigated in <cite>[7]</cite> and demonstrate the robustness of the model to noise.",
  "y": "background"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_3",
  "x": "Although many neural network models for KWS are presented in literature, it is difficult to make a fair comparison between them as they are all trained and evaluated on different proprietary datasets (e.g. \"TalkType\" dataset in <cite>[7]</cite> , \"Alexa\" dataset in [8] , etc.) with different input speech features and audio duration.",
  "y": "background"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_4",
  "x": "Convolution recurrent neural network <cite>[7]</cite> is a hybrid of CNN and RNN, which takes advantages of both.",
  "y": "background"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_5",
  "x": "Table 2 summarizes the accuracy, memory requirement and operations per inference for the network architectures for KWS from literature [5, 6,<cite> 7,</cite> 8] trained on Google speech commands dataset [9] .",
  "y": "similarities uses"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_7",
  "x": "Figure 5 shows the number of operations per inference, memory requirement and test accuracy of neural network models from prior work [5, 6,<cite> 7,</cite> 8] trained on Google speech commands dataset overlayed with the memory and compute bounding boxes for the neural network classes from section 4.",
  "y": "background"
 },
 {
  "id": "649eff228a47b484d01872a980e58f_8",
  "x": "[5, 6,<cite> 7,</cite> 8] trained on the speech commands dataset [9] .",
  "y": "background"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_0",
  "x": "However,<cite> Collobert et al. (2011b)</cite> proposed an effective neural network model that requires little feature engineering and instead learns important features from word embeddings trained on large quantities of unlabelled text -an approach made possible by recent advancements in unsupervised learning of word embeddings on massive amounts of data (Collobert and Weston, 2008; Mikolov et al., 2013) and neural network training algorithms permitting deep architectures (Rumelhart et al., 1986) .",
  "y": "background"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_1",
  "x": "Unfortunately there are many limitations to the model proposed by<cite> Collobert et al. (2011b)</cite> .",
  "y": "background"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_2",
  "x": "Unfortunately there are many limitations to the model proposed by<cite> Collobert et al. (2011b)</cite> . First, it uses a simple feed-forward neural network, which restricts the use of context to a fixed sized window around each word -an approach that discards useful long-distance relations between words. Second, by depending solely on word embeddings, it is unable to exploit explicit character level features such as prefix and suffix, which could be useful especially with rare words where word embeddings are poorly trained. We seek to address these issues by proposing a more powerful neural network model.",
  "y": "motivation"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_3",
  "x": "Furthermore, as lexicons are crucial to NER performance, we propose a new lexicon encoding scheme and matching algorithm that can make use of partial matches, and we compare it to the simpler approach of<cite> Collobert et al. (2011b)</cite> .",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_4",
  "x": "Furthermore, as lexicons are crucial to NER performance, we propose a new lexicon encoding scheme and matching algorithm that can make use of partial matches, and we compare it to the simpler approach of<cite> Collobert et al. (2011b)</cite> . Extensive evaluation shows that our proposed method establishes a new state of the art on both the CoNLL-2003 NER shared task and the OntoNotes 5.0 datasets.",
  "y": "differences"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_5",
  "x": "Our neural network is inspired by the work of<cite> Collobert et al. (2011b)</cite> , where lookup tables transform discrete features such as words and characters into continuous vector representations, which are then concatenated and fed into a neural network.",
  "y": "motivation"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_6",
  "x": "Our best model uses the publicly available 50dimensional word embeddings released by<cite> Collobert et al. (2011b)</cite> 2 , which were trained on Wikipedia and the Reuters RCV-1 corpus.",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_7",
  "x": "6 Following<cite> Collobert et al. (2011b)</cite> , all words are lower-cased before passing through the lookup table  Text Hayao Tada , commander of the Japanese North China Area Army to convert to their corresponding embeddings.",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_8",
  "x": "As capitalization information is erased during lookup of the word embedding, we evaluate Collobert's method of using a separate lookup table to add a capitalization feature with the following options: allCaps, upperInitial, lowercase, mixedCaps, noinfo<cite> (Collobert et al., 2011b)</cite> .",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_9",
  "x": "As we will see in Section 4.5, we found that this more sophisticated method outperforms the method presented by<cite> Collobert et al. (2011b)</cite> , which treats partial and exact matches equally, allows prefix but not suffix matches, allows very short partial matches, and marks tokens with YES/ NO.",
  "y": "differences"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_10",
  "x": "In addition, since<cite> Collobert et al. (2011b)</cite> released their lexicon with their SENNA system, we also applied their lexicon to our model for comparison and investigated using both lexicons simultaneously as distinct features.",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_11",
  "x": "In addition, since<cite> Collobert et al. (2011b)</cite> released their lexicon with their SENNA system, we also applied their lexicon to our model for comparison and investigated using both lexicons simultaneously as distinct features. We found that the two lexicons complement each other and improve performance on the CoNLL-2003 dataset.",
  "y": "similarities"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_12",
  "x": "We train our network to maximize the sentencelevel log-likelihood from<cite> Collobert et al. (2011b)</cite> .",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_13",
  "x": "This objective function and its gradients can be efficiently computed by dynamic programming<cite> (Collobert et al., 2011b)</cite> .",
  "y": "background"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_14",
  "x": "We re-implemented the FFNN model of<cite> Collobert et al. (2011b)</cite> as a baseline for comparison.",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_15",
  "x": "On the other hand, we suspect that Google's embeddings perform poorly because of vocabulary mismatch -in particular, Google's embeddings were trained in a case-sensitive manner, and embeddings for many common punctuations and 27 Wilcoxon rank sum test, p < 0.001 28 To make a direct comparison to<cite> Collobert et al. (2011b)</cite> , we do not exclude the CoNLL-2003 NER task test data from the word vector training data.",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_16",
  "x": "Compared to the SENNA lexicon, our DBpedia lexicon is noisier but has broader coverage, which explains why when applying it using the same method as<cite> Collobert et al. (2011b)</cite> , it performs worse on CoNLL-2003 but better on OntoNotesa dataset containing many more obscure named entities.",
  "y": "uses"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_18",
  "x": "Much later, with the advent of neural word embeddings,<cite> Collobert et al. (2011b)</cite> presented SENNA, which employs a deep FFNN and word embeddings to achieve near state of the art results on POS tagging, chunking, NER, and SRL.",
  "y": "background"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_19",
  "x": "Much later, with the advent of neural word embeddings,<cite> Collobert et al. (2011b)</cite> presented SENNA, which employs a deep FFNN and word embeddings to achieve near state of the art results on POS tagging, chunking, NER, and SRL. We build on their approach, sharing the word embeddings, feature encoding method, and objective functions.",
  "y": "extends"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_20",
  "x": "Recently, Santos et al. (2015) presented their CharWNN network, which augments the neural network of<cite> Collobert et al. (2011b)</cite> with character level CNNs, and they reported improved performance on Spanish and Portuguese NER.",
  "y": "background"
 },
 {
  "id": "64b344bf8ec9b6a113bf6b3f638528_21",
  "x": "Recently, Santos et al. (2015) presented their CharWNN network, which augments the neural network of<cite> Collobert et al. (2011b)</cite> with character level CNNs, and they reported improved performance on Spanish and Portuguese NER. We have successfully incorporated character-level CNNs into our model.",
  "y": "similarities"
 },
 {
  "id": "652534f801dbff0c009c4a39fdef4d_0",
  "x": "This is the key problem addressed by research on ASR quality estimation C. de Souza et al., 2015;<cite> Jalalvand et al., 2015b)</cite> , and the task for which TranscRater, the tool described in this paper, has been designed.",
  "y": "background"
 },
 {
  "id": "652534f801dbff0c009c4a39fdef4d_1",
  "x": "A variant of the basic ASR QE task is to consider it as a QE-based ranking problem<cite> (Jalalvand et al., 2015b)</cite> , in which each utterance is captured by multiple microphones or transcribed by multiple ASR systems.",
  "y": "background"
 },
 {
  "id": "652534f801dbff0c009c4a39fdef4d_2",
  "x": "Based on the empirical results reported in C. de Souza et al., 2015;<cite> Jalalvand et al., 2015b)</cite> , which indicate that Extremely Randomized Trees (XRT (Geurts et al., 2006) ) is a very competitive algorithm in several WER prediction tasks, the current version of the tool exploits XRT.",
  "y": "background"
 },
 {
  "id": "652534f801dbff0c009c4a39fdef4d_3",
  "x": "The current version of the tool includes an interface to the Random Forest algorithm (RF (Breiman, 2001) ), the same used in<cite> (Jalalvand et al., 2015b)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "652534f801dbff0c009c4a39fdef4d_4",
  "x": "The features and algorithms contained in TranscRater have been successfully used in previous works C. de Souza et al., 2015;<cite> Jalalvand et al., 2015b</cite>; Jalalvand et al., 2015a) .",
  "y": "background"
 },
 {
  "id": "65f7546e2abfd74c0daa43c25ca63f_0",
  "x": "A linguistics constraint-driven generation approach such as equivalent constraint <cite>[6,</cite> 7] is not restrictive to languages with distinctive grammar structure.",
  "y": "background"
 },
 {
  "id": "65f7546e2abfd74c0daa43c25ca63f_1",
  "x": "This approach is the unification of all components in the work of<cite> [6]</cite> into a single computational model.",
  "y": "uses"
 },
 {
  "id": "65f7546e2abfd74c0daa43c25ca63f_2",
  "x": "The synthetic code-switching generation approach was introduced by adapting equivalence constraint on monolingual sentence pairs during the decoding step on an automatic speech recognition (ASR) model<cite> [6]</cite> .",
  "y": "background"
 },
 {
  "id": "65f7546e2abfd74c0daa43c25ca63f_3",
  "x": "As our baseline, we compare our proposed method with three other models: (1) We use Seq2Seq with attention; (2) We generate sequences that satisfy Equivalence Constraint<cite> [6]</cite> .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_0",
  "x": "Recent advances in the area of deep reinforcement learning (DRL) have inspired reinforcement learning (RL) based solutions for the KG completion problem [21, 3, 30, <cite>13</cite>, 19, 22, 14, 29] .",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_1",
  "x": "<cite>RL-based methods</cite> formulate the task of KG completion as a sequential decision-making process in which the goal is to train an RL agent to walk over the graph by taking a sequence of actions (i.e., choosing the next entity) that connects the source to the target entity.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_2",
  "x": "<cite>Existing RL-based methods</cite> for KG completion do not capture the entity's neighborhood information.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_3",
  "x": "<cite>Existing RL-based methods</cite> for KG completion do not capture the entity's neighborhood information. Previous studies on one-shot fact prediction have shown that the local neighborhood structure improves the fact prediction performance for long-tailed relations [31, 37] . We propose a graph neural network (GNN) [9] to encode the neighborhood information of the entities and leverage the state representation with the type and neighborhood information of the entities.",
  "y": "motivation"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_4",
  "x": "As a result, more recent methods proposed using RL to solve the multi-hop reasoning problem in knowledge graphs by framing it as a sequential decision-making process [3, 23, 30, 22, 12, <cite>13</cite>] .",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_5",
  "x": "<cite>Lin et al. [13]</cite> implement reward shaping to address the problem of the sparse reward signal and action dropout to reduce the effect of incorrect paths.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_6",
  "x": "Because these <cite>RL models</cite> treat the KG completion problem as a path reasoning problem instead of a link prediction problem, they are able to overcome both drawbacks of embedding methods that are outlined above.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_7",
  "x": "However, the <cite>RL models</cite> have drawbacks of their own, the most notable of which are computational cost and predictive accuracy.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_8",
  "x": "Many of <cite>these RL methods</cite> have tried to combine the representational power of embeddings and reasoning power of RL by training an agent to navigate an embedding space.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_9",
  "x": "For example, the authors of [<cite>13</cite>] build an agent-based model on top of pre-trained embeddings generated by ComplEx [27] or ConvE [4] .",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_10",
  "x": "For example, the authors of [<cite>13</cite>] build an agent-based model on top of pre-trained embeddings generated by ComplEx [27] or ConvE [4] . While we take a <cite>similar modular approach</cite>, our solution enriches the embedding space with additional information about entity types and local neighborhood information.",
  "y": "extends similarities"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_11",
  "x": "Similar to [3, <cite>13</cite>, 30] , we formulate this problem as a Markov Decision Process (MDP), in which the goal is to train a policy gradient agent (using REIN- FORCE [28] ) to learn an optimal reasoning path to answer a given query (e s , r, ?).",
  "y": "similarities"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_12",
  "x": "For example, [<cite>13</cite>] pre-computes PageRank scores for each node, and narrows the action space to a fixed number of highest-ranking neighbors.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_13",
  "x": "Inspired by [<cite>13</cite>] , we use pre-trained KG embeddings based on existing KG embedding methods to design a soft reward function for the terminal state s T based on [17] :",
  "y": "motivation"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_14",
  "x": "Where f (e s , r, e T ) is a similarity measure calculated based on pre-trained KG embedding approach [<cite>13</cite>] .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_15",
  "x": "Following [<cite>13</cite>] , we use an LST M to encode the history h t = {e t\u2212k , r t\u2212k+1 , ..., e t\u22121 , r t } of the past k steps taken by the agent in solving the query.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_16",
  "x": "To reduce the potential impact of argmax leading to the overuse of incorrect paths, we utilize random action dropout as described in [<cite>13</cite>] .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_17",
  "x": "We compare against several baseline methods: ConvE (embeddingbased) [4] , ComplEx (embedding-based) [27] , MINERVA (agent-based) [3] , and MultiHopKG (agent-based) using both ConvE and ComplEx for pre-trained embeddings [<cite>13</cite>] .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_18",
  "x": "Because none of these models generalize to unknown entities, followed by previous work [3, <cite>13</cite>] , we measure Hits@k and MRR only for queries for which both e s and e d have already been seen at least once by the model during training.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_19",
  "x": "For NELL-995, utilize the same hyperparameters described in [<cite>13</cite>] when training ConvE, ComplEx, Distmult, and <cite>Lin et al [13]</cite> baselines.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_20",
  "x": "For the two Amazon datasets, we perform a grid search for our method and all <cite>baselines</cite> and report the best performance for each.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_21",
  "x": "For NELL-995 data, We quote the results reported in [3, <cite>13</cite>] .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_22",
  "x": "Embedding-based methods show an overall higher performance compared to the <cite>RL-based methods</cite>.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_23",
  "x": "We can see that in all three datasets, our results outperform both RL baselines (<cite>Lin et al. [13]</cite> and MINERVA [3] ).",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_24",
  "x": "Our method results in a 4% improvement in MRR (and 5.43% in Hits@1) over the <cite>best RL baseline</cite> on Amazon Cellphones and a 3.9% improvement in MRR (and 5.5% in Hits@1) on Amazon Beauty.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_25",
  "x": "On the NELL-995 dataset, our method results in 2.8% improvement in MRR and 4% improvement in Hits@1 over the best performing <cite>baseline</cite>.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_26",
  "x": "We believe due to the sparsity of these two knowledge graphs, type information was more effective for action space pruning than entity page ranks, as done in [<cite>13</cite>] .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_27",
  "x": "For this analysis, we compare our ablation models (Ours (-N) and Ours (-T)) with the best performing RL baseline by <cite>Lin et al. [13]</cite> .",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_28",
  "x": "For this analysis, we compare our ablation models (Ours (-N) and Ours (-T)) with the best performing RL baseline by <cite>Lin et al. [13]</cite> . Our method is more successful in discovering novel paths and obtains a better hit ratio on the development set.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_29",
  "x": "We compare the ablation models along with the <cite>best RL baseline</cite> performance on seen and unseen queries.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_30",
  "x": "We compare the ablation models along with the <cite>best RL baseline</cite> performance on seen and unseen queries. Table 4 shows that our proposed method performs better on both seen and unseen queries.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_31",
  "x": "We evaluate our proposed model on different relation types and compare our results with the <cite>best performing RL baseline</cite>.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_32",
  "x": "We take a similar approach as [<cite>13</cite>] to extract to-many and to-one relations.",
  "y": "similarities"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_33",
  "x": "Our proposed model consistently shows a better performance than <cite>Lin et al.</cite>, except for the NELL-995 dataset where the improvement is marginal.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_34",
  "x": "Again, other <cite>RL baselines</cite> struggle with finding the next best step after entity New York.",
  "y": "background"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_35",
  "x": "Again, other <cite>RL baselines</cite> struggle with finding the next best step after entity New York. Our method uses the location information to find the answer Michael Bloomberg.",
  "y": "differences"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_37",
  "x": "Therefore, we focus on the diversity of the relations used in our method and the best performing baseline [<cite>13</cite>] for the discovered paths in the development set.",
  "y": "uses"
 },
 {
  "id": "666cc3c936358c5e9b2f7d0eb8d0e4_38",
  "x": "In the future, we plan to explore more efficient strategies for action-space pruning to improve the scalability of <cite>existing RL solutions</cite>.",
  "y": "future_work"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_0",
  "x": "Recent work <cite>(Barbieri et al., 2017)</cite> has shown that textual information can be used to predict emojis associated to text.",
  "y": "motivation background"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_1",
  "x": "Our task and experimental framework are similar to <cite>(Barbieri et al., 2017)</cite> , however, we use different data (Instagram instead of Twitter) and, in addition, we rely on images to improve the selection of the most likely emojis to associate to a post.",
  "y": "extends differences"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_2",
  "x": "Moreover, as done by<cite> Barbieri et al. (2017)</cite> , we considered only the posts which include one and only one of the 20 most frequent emojis (the most frequent emojis are shown in Table 3 ).",
  "y": "extends differences"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_3",
  "x": "In the experiments we also considered the subsets of the 10 (238,646 posts) and 5 most frequent emojis (184,044 posts) (similarly to the approach followed by<cite> Barbieri et al. (2017)</cite> ).",
  "y": "similarities uses"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_4",
  "x": "We extend the experimental scheme of<cite> Barbieri et al. (2017)</cite> , by considering also visual information when modeling posts.",
  "y": "extends differences"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_5",
  "x": "In the first experiment (Section 4.2) we compare the FastText model with the state of the art on emoji classification (B-LSTM) by<cite> Barbieri et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_6",
  "x": "Moreover, we evaluate a multimodal combination of both models respectively based on visual and<cite> Barbieri et al. (2017)</cite> , using the same Twitter dataset.",
  "y": "similarities uses"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_7",
  "x": "To compare the FastText model with the word and character based B-LSTMs presented by<cite> Barbieri et al. (2017)</cite> , we consider the same three emoji prediction tasks they proposed: top-5, top-10 and top-20 emojis most frequently used in their Tweet datasets.",
  "y": "uses similarities"
 },
 {
  "id": "6683d7b77f536b93416d985414afeb_8",
  "x": "Another relevant confusion scenario related to emoji prediction has been spotted by<cite> Barbieri et al. (2017)</cite> : relying on Twitter textual data they showed that the emoji was hard to predict as it was used similarly to .",
  "y": "similarities"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_0",
  "x": "Specifically, we train multinomial Bayes classifiers based on location indicative words (LIWs) in tweets<cite> (Han et al., 2012)</cite> , and user-declared location and time zone metadata.",
  "y": "uses"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_1",
  "x": "Given that most tweets are from urban areas, <cite>Han et al. (2012)</cite> consider a citybased class division, and explore different feature selection methods to extract \"location indicative words\", which they show to improve prediction accuracy.",
  "y": "background"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_2",
  "x": "As such, we build off the text-based naive Bayes-based geolocation system of <cite>Han et al. (2012)</cite> , which our experiments have shown to have a good balance of tractability and accuracy.",
  "y": "extends"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_3",
  "x": "In this study, we adopt the same city-based representation and multinomial naive Bayes learner as <cite>Han et al. (2012)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_4",
  "x": "<cite>Han et al. (2012)</cite> found that using feature selection to identify \"location indicative words\" led to improvements in geolocation performance. We use the same feature selection technique that they did.",
  "y": "uses motivation background similarities"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_5",
  "x": "In the original research of <cite>Han et al. (2012)</cite> , only the text of Twitter messages was used, and training was based exclusively on geotagged tweets, despite these accounting for only around 1% of the total public data on Twitter.",
  "y": "background"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_6",
  "x": "We base our evaluation on the publicly-available WORLD dataset of <cite>Han et al. (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_7",
  "x": "To benchmark our method, we reimplement two recently-published state-of-the-art methods: (1) the KL-divergence nearest prototype method of Roller et al. (2012) based on KD-tree partitioned grid cells, which we denote as KL; and (2) the multinomial naive Bayes city-level geolocation model of <cite>Han et al. (2012)</cite> , which we denote as MB.",
  "y": "uses"
 },
 {
  "id": "67b6d87aa2a943a854251fada6e183_8",
  "x": "Of the two original models, we can see that MB is comparable to KL, in line with the findings of <cite>Han et al. (2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "684a637d08e8dbabddc1f1982f5393_0",
  "x": "In this talk, we evaluate two recent approaches to information presentation in SDS: (1) the Refiner approach (Polifroni et al., 2003) which generates summaries by clustering the options to maximize coverage of the domain, and (2) the <cite>user-model based summarize and refine (UMSR)</cite> approach (<cite>Demberg and Moore, 2006</cite>) which clusters options to maximize utility with respect to a user model, and uses linguistic devices (e.g., discourse cues, adverbials) to highlight the trade-offs among the presented items.",
  "y": "uses"
 },
 {
  "id": "684a637d08e8dbabddc1f1982f5393_1",
  "x": "We report the results of two studies which show that the discourse cues in <cite>UMSR</cite> summaries help users compare different options and choose between options, even though they do not improve verbatim recall.",
  "y": "uses"
 },
 {
  "id": "684a637d08e8dbabddc1f1982f5393_2",
  "x": "Finally, we hypothesize that <cite>UMSR</cite> is more effective because <cite>it</cite> uses linguistic devices to highlight relations (e.g., trade-offs) between options and attributes.",
  "y": "differences"
 },
 {
  "id": "684a637d08e8dbabddc1f1982f5393_3",
  "x": "Using a Wizard-of-Oz methodology to evaluate the approaches in an interactive setting, we show that in addition to being preferred by users, the <cite>UMSR</cite> approach is superior to the Refiner approach in terms of both task success and dialogue efficiency, even when the user is performing a demanding secondary task.",
  "y": "differences"
 },
 {
  "id": "684a637d08e8dbabddc1f1982f5393_4",
  "x": "In this talk, we evaluate two recent approaches to information presentation in SDS: (1) the Refiner approach (Polifroni et al., 2003) which generates summaries by clustering the options to maximize coverage of the domain, and (2) the <cite>user-model based summarize and refine (UMSR)</cite> approach (<cite>Demberg and Moore, 2006</cite>) which clusters options to maximize utility with respect to a user model, and uses linguistic devices (e.g., discourse cues, adverbials) to highlight the trade-offs among the presented items. Using a Wizard-of-Oz methodology to evaluate the approaches in an interactive setting, we show that in addition to being preferred by users, the <cite>UMSR</cite> approach is superior to the Refiner approach in terms of both task success and dialogue efficiency, even when the user is performing a demanding secondary task.",
  "y": "uses"
 },
 {
  "id": "684a637d08e8dbabddc1f1982f5393_5",
  "x": "In this talk, we evaluate two recent approaches to information presentation in SDS: (1) the Refiner approach (Polifroni et al., 2003) which generates summaries by clustering the options to maximize coverage of the domain, and (2) the <cite>user-model based summarize and refine (UMSR)</cite> approach (<cite>Demberg and Moore, 2006</cite>) which clusters options to maximize utility with respect to a user model, and uses linguistic devices (e.g., discourse cues, adverbials) to highlight the trade-offs among the presented items. Finally, we hypothesize that <cite>UMSR</cite> is more effective because <cite>it</cite> uses linguistic devices to highlight relations (e.g., trade-offs) between options and attributes.",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_0",
  "x": "It performs two phases: first, machine understandable logical forms (programs) are generated from natural language questions following the work of<cite> [Pasupat and Liang, 2015]</cite> .",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_1",
  "x": "Our best single model achieves 34.8% accuracy on the WikiTableQuestions dataset, while the best ensemble of our models pushes the state-of-the-art score on this task to 38.7%, thus slightly surpassing both the engineered feature scoring baseline, as well as the Neural Programmer model of<cite> [Neelakantan et al., 2016]</cite> .",
  "y": "differences"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_2",
  "x": "One example are systems able to answer complex questions about a specific topic (e.g.<cite> [Wang et al., 2015]</cite> ).",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_3",
  "x": "Each natural language question is translated into a set of computer understandable candidate representations, called logical forms, based on the work of<cite> [Pasupat and Liang, 2015]</cite> .",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_4",
  "x": "We empirically confirm our approach on a series of experiments on WikiTableQuestions<cite> [Pasupat and Liang, 2015]</cite> , a real-world dataset containing 22,033 pairs of questions and their corresponding manually retrieved answers with about 2,108 randomly selected Wikipedia tables.",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_5",
  "x": "To tackle this problem, our method follows recent work of <cite>[Reddy et al., 2014</cite>; Kwiatkowski et al., 2013] that relies solely on weak-supervision through question-answertable triples.",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_6",
  "x": "In the context of QA for semi-structured tables and dealing with multi-compositional queries,<cite> [Pasupat and Liang, 2015]</cite> generate and rank candidate logical forms with a log-linear model trained on question-answer pairs.",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_7",
  "x": "In this work, we generate logical form candidates in the same way as<cite> [Pasupat and Liang, 2015]</cite> .",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_8",
  "x": "Paraphrases have been successfully used to facilitate semantic parsers<cite> [Wang et al., 2015</cite>; .",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_9",
  "x": "While [Berant and Liang, 2014] is suited for factoid questions with a modest amount of compositionality,<cite> [Wang et al., 2015]</cite> targets more complicated questions.",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_10",
  "x": "While [Berant and Liang, 2014] is suited for factoid questions with a modest amount of compositionality,<cite> [Wang et al., 2015]</cite> targets more complicated questions. Both of these paraphrase-driven QA systems differ from our work as their scoring relies on hand-crafted features.",
  "y": "differences background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_11",
  "x": "[<cite> Neelakantan et al., 2016]</cite> also focus on compositional questions, but instead of generating and ranking multiple logical forms, they propose a model that directly constructs a logical form from an embedding of the question.",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_12",
  "x": "Recently,<cite> [Yin et al., 2015]</cite> propose Neural Enquirer, a fully neural, end-to-end differentiable network that executes queries across multiple tables.",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_13",
  "x": "Representation learning using deep learning architectures has been widely explored in other domains, e.g. in the context of sentiment classification, [Kim, 2014;<cite> Socher et al., 2013]</cite> , or for image-hashtag prediction [Denton et al., 2015] .",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_14",
  "x": "Systems vary from operating on structured knowledge bases [Bordes et al., 2014b] ; [Bordes et al., 2014a ] to semi-structured tables<cite> [Pasupat and Liang, 2015]</cite> ,<cite> [Neelakantan et al., 2016]</cite> , [Jauhar et al., 2016] and completely unstructured text, which is related to information extraction [Clark et al., 2016] .",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_15",
  "x": "Systems vary from operating on structured knowledge bases [Bordes et al., 2014b] ; [Bordes et al., 2014a ] to semi-structured tables<cite> [Pasupat and Liang, 2015]</cite> ,<cite> [Neelakantan et al., 2016]</cite> , [Jauhar et al., 2016] and completely unstructured text, which is related to information extraction [Clark et al., 2016] . We focus on semi-structured tables that face the trade-off between degree of structure and ubiquity.",
  "y": "uses background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_16",
  "x": "For every question q : i) a set of candidate logical forms {z i } i\u2208Iq is generated using the method of<cite> [Pasupat and Liang, 2015]</cite> ; ii) each such candidate program z i is paraphrased in a textual representation t i that offers accuracy gain, interpretability and comprehensibility ; iii) all textual forms t i are scored against the input question q using a neural network model; iv) the logical form z * i corresponding to the highest ranked t * i is selected as the machine-understandable translation of question q; v) z * i is executed on the input table and its answer is returned to the user.",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_17",
  "x": "Our contributions are the novel models that perform the steps ii) and iii), while for i), iv) and v) we rely on the work of<cite> [Pasupat and Liang, 2015]</cite> (henceforth: PL2015).",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_18",
  "x": "Details about Lambda DCS language can be found in<cite> [Liang, 2013]</cite> return t t is the textual paraphrase of the Lambda DCS logical form 18: end procedure information from the KG facilitates the process of parsing a question into a set of candidate logical forms.",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_19",
  "x": "Each candidate logical form is represented in Lambda DCS form<cite> [Liang, 2013]</cite> and can be transformed into a SPARQL query, whose execution against the KG yields an answer.",
  "y": "uses"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_20",
  "x": "PL2015 report an oracle score of 76.7%, but a manual annotation by<cite> [Pasupat and Liang, 2015]</cite> reveals that PL2015 can answer only 53.5% of the questions correctly.",
  "y": "background"
 },
 {
  "id": "68b5e39365b153dd2bef32845617f2_21",
  "x": "Table 1 shows the performance of our models compared to Neural Programmer<cite> [Neelakantan et al., 2016]</cite> and PL2015<cite> [Pasupat and Liang, 2015]</cite> baselines.",
  "y": "uses"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_0",
  "x": "In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels<cite> (Barzilay and Lee, 2004)</cite> , while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005) .",
  "y": "background"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_1",
  "x": "A frequently used testbed for coherence models is the discourse ordering problem, which occurs often in text generation, complex question answering, and multi-document summarization: given discourse units, what is the most coherent ordering of them (Marcu, 1996; Lapata, 2003;<cite> Barzilay and Lee, 2004</cite>; Barzilay and Lapata, 2005) ? Because the problem is NP-complete (Althaus et al., 2005) , it is critical how coherence model evaluation is intertwined with search: if the search for the best ordering is greedy and has many errors, one is not able to properly evaluate whether a model is better than another.",
  "y": "motivation"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_2",
  "x": "One of the most frequently used metrics for the automatic evaluation of document coherence is Kendall's (Lapata, 2003;<cite> Barzilay and Lee, 2004)</cite> .",
  "y": "background"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_3",
  "x": "The task on which we conduct our evaluation is information ordering (Lapata, 2003;<cite> Barzilay and Lee, 2004</cite>; Barzilay and Lapata, 2005) .",
  "y": "uses"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_4",
  "x": "We evaluated the performance of several search algorithms across four stochastic models of document coherence: the IBM \u00a3 and IBM \u00a3 coherence models, the content model of<cite> Barzilay and Lee (2004)</cite> (CM) , and the entity-based model of Barzilay and Lapata (2005) (EB) (Section 2).",
  "y": "uses"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_6",
  "x": "We measure search performance using an Estimated Search Error (ESE) figure, which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID. Lapata (2003) 0.48 0.07 <cite>Barzilay & Lee (2004)</cite> 0.81 0.44 Barzilay & Lee (reproduced) 0.39 0.36 Barzilay & Lapata (2005) 0 the original sentence order (OSO).",
  "y": "uses"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_7",
  "x": "We are able to provide this comparison based on the TAU figures reported in<cite> (Barzilay and Lee, 2004)</cite> .",
  "y": "uses"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_8",
  "x": "We first note that, unfortunately, we failed to accurately reproduce the model of<cite> Barzilay and Lee (2004)</cite> .",
  "y": "differences"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_9",
  "x": "The large difference on the EARTHQUAKES corpus between the performance of<cite> Barzilay and Lee (2004)</cite> and our reproduction of their model is responsible for the overall lower performance (0.47) of our log-linear \u00a9 model and IDL-CH-HB \u00a3 V r V search algorithm, which is nevertheless higher than that of its component model CM (0.39).",
  "y": "differences"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_10",
  "x": "On the other hand, we achieve the highest accuracy figure (0.50) on the ACCIDENTS corpus, outperforming the previous-highest figure (0.44) of<cite> Barzilay and Lee (2004)</cite> .",
  "y": "differences"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_11",
  "x": "At the other end of the spectrum, the exhaustive search of<cite> Barzilay and Lee (2004)</cite> , while ensuring optimal solutions, is prohibitively expensive, and cannot be used to perform utility-based training.",
  "y": "background"
 },
 {
  "id": "69857bcd5ba67cb7ca0b4344a3a85f_12",
  "x": "Our generation algorithms are fundamentally different from previously-proposed algorithms for discourse generation. At the other end of the spectrum, the exhaustive search of<cite> Barzilay and Lee (2004)</cite> , while ensuring optimal solutions, is prohibitively expensive, and cannot be used to perform utility-based training.",
  "y": "differences"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_0",
  "x": "In this work we focus on vector spaces that directly weight a co-occurrence matrix and report results for SVD, GloVe and SGNS from the study of<cite> Levy et al. (2015)</cite> for comparison.",
  "y": "uses"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_1",
  "x": "The mismatch of recent experiments with nondense models in vector dimensionality between lexical and compositional tasks gives rise to a number of questions: Can the findings of<cite> Levy et al. (2015)</cite> be directly applied to models with a few thousand dimensions?",
  "y": "motivation"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_2",
  "x": "This can be generalised to an additional cutoff parameter k (neg) following<cite> Levy et al. (2015)</cite> , giving our third PMI variant (abbreviated as SPMI): 2",
  "y": "uses"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_3",
  "x": "Another issue with PMI is its bias towards rare events <cite>(Levy et al., 2015)</cite> ; one way of solving this issue is to weight the value by the co-occurrence frequency (Evert, 2005) :",
  "y": "motivation"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_4",
  "x": "We also compare them to the best scores reported by<cite> Levy et al. (2015)</cite> for their model (PMI and SVD), word2vec-SGNS (Mikolov et al., 2013) and GloVe (Pennington et al., 2014 )-see Figure 3a , where only the betterperforming SPMI and SCPMI are shown.",
  "y": "uses"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_5",
  "x": "With lognSCPMI and 1SCPMI, the heuristics follow<cite> Levy et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_6",
  "x": "On the right, our heuristic in comparison to the best and average results together with the models selected using the recommendations presented in<cite> Levy et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_7",
  "x": "As Figure 3b shows, our heuristics give performance close to the optimum for any dimensionality, with a large improvement over both an average parameter setting and the parameters suggested by<cite> Levy et al. (2015)</cite> in a high-dimensional setting.",
  "y": "differences"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_8",
  "x": "This paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in<cite> Levy et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "6a054953660e465151e4d8a2223a76_10",
  "x": "This paper presents a systematic study of cooccurrence quantification focusing on the selection of parameters presented in<cite> Levy et al. (2015)</cite> . We replicate their recommendation for high-dimensional vector spaces, and show that with appropriate parameter selection it is possible to achieve comparable performance with spaces of dimensionality of 1K to 50K, and propose a set of model selection heuristics that maximizes performance.",
  "y": "extends"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_0",
  "x": "The metric is built on the LFG F-structurebased approach presented in <cite>(Owczarzak et al., 2007)</cite> .",
  "y": "extends"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_1",
  "x": "With the addition of partial matching and n-best parses,<cite> Owczarzak et al. (2007)</cite> 's method considerably outperforms Liu and Gildea's (2005) w.r.t.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_2",
  "x": "The EDPM metric (Kahn et al., 2010) improves this line of research by using arc labels derived from a Probabilistic Context-Free Grammar (PCFG) parse to replace the LFG labels, showing that a PCFG parser is sufficient for preprocessing, compared to a dependency parser in (Liu and Gildea, 2005) and <cite>(Owczarzak et al., 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_3",
  "x": "In this paper we extend the work of <cite>(Owczarzak et al., 2007)</cite> in a different manner: we use an adapted version of the Malt parser (Nivre et al., 2006) to produce 1-best LFG dependencies and allow triple matches where the dependency labels are different.",
  "y": "extends"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_4",
  "x": "In this section, we briefly review the metric presented in <cite>(Owczarzak et al., 2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_5",
  "x": "The basic method of <cite>(Owczarzak et al., 2007)</cite> can be illustrated by the example in Table 1 .",
  "y": "uses"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_6",
  "x": "The metric in <cite>(Owczarzak et al., 2007)</cite> performs triple matching over the Hyp-and Ref-Triples and calculates the metric score using the F-score of matching precision and recall.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_7",
  "x": "The score of the hypothesis in <cite>(Owczarzak et al., 2007)</cite> is the Fscore based on the precision and recall of matching as in (1):<cite> Owczarzak et al., 2007)</cite> uses several techniques to facilitate triple matching.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_8",
  "x": "The metric described in <cite>(Owczarzak et al., 2007)</cite> uses the DCU LFG parser (Cahill et al., 2004) to produce LFG dependency triples.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_9",
  "x": "In <cite>(Owczarzak et al., 2007)</cite> , triple matching on f-structures produced by this paradigm correlates well with human judgement, but this paradigm is not adequate for the WMTMetricsMatr evaluation in two respects: 1) the inhouse LFG annotation algorithm is not publicly available and 2) the speed of this paradigm is not satisfactory.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_10",
  "x": "In <cite>(Owczarzak et al., 2007)</cite> , triple matching on f-structures produced by this paradigm correlates well with human judgement, but this paradigm is not adequate for the WMTMetricsMatr evaluation in two respects: 1) the inhouse LFG annotation algorithm is not publicly available and 2) the speed of this paradigm is not satisfactory. We instead use the Malt Parser 1 (Nivre et al., 2006 ) with a parsing model trained on LFG dependencies to produce the f-structure triples.",
  "y": "differences"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_11",
  "x": "Currently our parser produces only the 1-best outputs. Compared to the 50-best parses in <cite>(Owczarzak et al., 2007)</cite> , the 1-best parse limits the number of triple matches that can be found.",
  "y": "differences"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_12",
  "x": "In <cite>(Owczarzak et al., 2007)</cite> , lexical variations at the word-level are captured by WordNet.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_13",
  "x": "In <cite>(Owczarzak et al., 2007)</cite> , lexical variations at the word-level are captured by WordNet. We use a Porter stemmer and a unigram paraphrase database to allow more lexical variations.",
  "y": "extends"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_14",
  "x": "The metric described in <cite>(Owczarzak et al., 2007)</cite> does not explicitly consider word order and fluency.",
  "y": "background"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_15",
  "x": "The metric described in <cite>(Owczarzak et al., 2007)</cite> does not explicitly consider word order and fluency. METEOR, on the other hand, utilizes this information through a chunk penalty. We introduce a chunk penalty to our dependency-based metric following METEOR's string-based approach.",
  "y": "differences"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_16",
  "x": "The first two settings compare the effect of allowing/not allowing soft matches, but only uses WordNet as in <cite>(Owczarzak et al., 2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_17",
  "x": "Building upon the LFGbased metric described in <cite>(Owczarzak et al., 2007)</cite> , we use a publicly available parser instead of an in-house parser to produce dependency labels, so that the metric can run on a third party machine.",
  "y": "extends"
 },
 {
  "id": "6b11cfba6ee73c1f67941cf73506be_18",
  "x": "Building upon the LFGbased metric described in <cite>(Owczarzak et al., 2007)</cite> , we use a publicly available parser instead of an in-house parser to produce dependency labels, so that the metric can run on a third party machine. We improve the metric by allowing more lexical variations and weighting dependency triple matches depending on their importance according to correlation with human judgement.",
  "y": "differences"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_0",
  "x": "We focus on character n-grams based on research in the field of word embedding construction<cite> (Wieting et al. 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_1",
  "x": "For example, neural encoderdecoder models, which are becoming the de facto standard for various natural language generation tasks including machine translation (Sutskever, Vinyals, and Le 2014) , summarization (Rush, Chopra, and Weston 2015) , dialogue <cite>(Wen et al. 2015)</cite> , and caption generation<cite> (Vinyals et al. 2015)</cite> can be interpreted as conditional neural language models.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_2",
  "x": "In general, neural language models require word embeddings as an input<cite> (Zaremba, Sutskever, and Vinyals 2014)</cite>.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_3",
  "x": "However, as described by<cite> (Verwimp et al. 2017)</cite> , this approach cannot make use of the internal structure of words although the internal structure is often an effective clue for considering the meaning of a word.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_4",
  "x": "In general, neural language models require word embeddings as an input<cite> (Zaremba, Sutskever, and Vinyals 2014)</cite>. However, as described by<cite> (Verwimp et al. 2017)</cite> , this approach cannot make use of the internal structure of words although the internal structure is often an effective clue for considering the meaning of a word. For example, we can comprehend that the word 'causal' is related to 'cause' immediately because both words include the same character sequence 'caus'. Thus, if we incorporate a method that handles the internal structure such as character information, we can improve the quality of neural language models and probably make them robust to infrequent words.",
  "y": "motivation"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_5",
  "x": "To incorporate the internal structure,<cite> (Verwimp et al. 2017)</cite> concatenated character embeddings with an input word embedding.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_6",
  "x": "On the other hand, in the field of word embedding construction, some previous researchers found that character n-grams are more useful than single characters<cite> (Wieting et al. 2016</cite>; Bojanowski et al. 2017) .",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_7",
  "x": "In particular,<cite> (Wieting et al. 2016)</cite> demonstrated that constructing word embeddings from character n-gram embeddings outperformed the methods that construct word embeddings from character embeddings by using CNN or a Long Short-Term Memory (LSTM).",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_8",
  "x": "On the other hand, in the field of word embedding construction, some previous researchers found that character n-grams are more useful than single characters<cite> (Wieting et al. 2016</cite>; Bojanowski et al. 2017) . In particular,<cite> (Wieting et al. 2016)</cite> demonstrated that constructing word embeddings from character n-gram embeddings outperformed the methods that construct word embeddings from character embeddings by using CNN or a Long Short-Term Memory (LSTM). Based on their reports, in this paper, we propose a neural language model that utilizes character n-gram embeddings.",
  "y": "uses"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_9",
  "x": "We incorporate charn-MS-vec, which is an embedding constructed from character n-gram embeddings, into RNN language models since, as discussed earlier, previous studies revealed that we can construct better word embeddings by using character n-gram embeddings<cite> (Wieting et al. 2016</cite>; Bojanowski et al. 2017 ).",
  "y": "uses"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_10",
  "x": "Previous studies demonstrated that additive composition, which computes the (weighted) sum of embeddings, is a suitable method for embedding construction<cite> Wieting et al. 2016</cite> the number of character n-grams extracted from the word, and let S be the matrix whose i-th column corresponds to s i , that is, S = [s 1 , ..., s I ].",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_11",
  "x": "Since AWD-LSTM-MoS<cite> (Yang et al. 2018</cite> ) and AWD-LSTM-DOC<cite> (Takase, Suzuki, and Nagata 2018)</cite> achieved the stateof-the-art scores on PTB and WT2, we combined char3-MSvec with them.",
  "y": "uses"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_12",
  "x": "Finally, (Merity, Keskar, and Socher 2018b) introduced DropConnect<cite> (Wan et al. 2013</cite> ) and averaged SGD (Polyak and Juditsky 1992) into the LSTM language model and achieved state-of-the-art perplexities on PTB and WT2.",
  "y": "uses"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_13",
  "x": "Their proposed method achieved perplexity competitive with the basic LSTM language model<cite> (Zaremba, Sutskever, and Vinyals 2014)</cite> even though its parameter size is small.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_14",
  "x": "On the other hand, (Bojanowski et al. 2017 ) and<cite> (Wieting et al. 2016)</cite> focused on character n-gram.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_15",
  "x": "In addition,<cite> (Wieting et al. 2016)</cite> found that the sum of character n-gram embeddings also outperformed word embeddings constructed from character embeddings with CNN and LSTM.",
  "y": "background"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_16",
  "x": "In addition,<cite> (Wieting et al. 2016)</cite> found that the sum of character n-gram embeddings also outperformed word embeddings constructed from character embeddings with CNN and LSTM. As an encoder, previous studies argued that additive composition, which computes the (weighted) sum of embeddings, is a suitable method theoretically (Tian, Okazaki, and Inui 2016) and empirically (Muraoka et al. 2014; . In this paper, we used multidimensional self-attention to construct word embeddings because it can be interpreted as an element-wise weighted sum.",
  "y": "motivation"
 },
 {
  "id": "6b1432f4aac35e6acd8ca8770fe484_17",
  "x": "Based on the research in the field of word embedding construction<cite> (Wieting et al. 2016)</cite> , we focused on character n-gram embeddings to construct word embeddings.",
  "y": "uses"
 },
 {
  "id": "6bb7d5f16861470214626c1cc497bb_0",
  "x": "In this paper, we use it to evaluate two state-of-the-art (SoA) models of speaker commitment:<cite> Stanovsky et al. (2017)</cite> and .",
  "y": "uses"
 },
 {
  "id": "6bb7d5f16861470214626c1cc497bb_1",
  "x": "We evaluate the performance of two speaker commitment models on the CommitmentBank: a rulebased model<cite> (Stanovsky et al., 2017</cite> ) and a neuralbased one .",
  "y": "uses"
 },
 {
  "id": "6bb7d5f16861470214626c1cc497bb_2",
  "x": "Rule-based model<cite> Stanovsky et al. (2017)</cite> proposed a rule-based model based on a deterministic algorithm based on TruthTeller (Lotan et al., 2013) , which uses a top-down approach on a de- pendency tree and predicts speaker commitment score in [\u22123, 3] according to the implicative signatures (Karttunen, 2012) of the predicates, and whether the predicates are under the scope of negation and uncertainty modifiers.",
  "y": "background"
 },
 {
  "id": "6bb7d5f16861470214626c1cc497bb_3",
  "x": "We evaluate the performance of two speaker commitment models on the CommitmentBank: a rulebased model<cite> (Stanovsky et al., 2017</cite> ) and a neuralbased one . Rule-based model<cite> Stanovsky et al. (2017)</cite> proposed a rule-based model based on a deterministic algorithm based on TruthTeller (Lotan et al., 2013) , which uses a top-down approach on a de- pendency tree and predicts speaker commitment score in [\u22123, 3] according to the implicative signatures (Karttunen, 2012) of the predicates, and whether the predicates are under the scope of negation and uncertainty modifiers.",
  "y": "uses background"
 },
 {
  "id": "6bb7d5f16861470214626c1cc497bb_4",
  "x": "The score on UW with MAE was obtained by<cite> Stanovsky et al. (2017)</cite> , while the other scores were obtained by .",
  "y": "uses"
 },
 {
  "id": "6bb7d5f16861470214626c1cc497bb_5",
  "x": "Focusing on the restricted set, we perform detailed error analysis of the outputs of the rule-based and hybrid biLSTM models, which achieved the best Figure 3: Pearson r correlation and Mean Absolute Error (MAE) on All -2.0 baseline, Rule-based annotator<cite> (Stanovsky et al., 2017)</cite> , and three biLSTM models in .",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_0",
  "x": "Lee et al. (2017; <cite>Lee et al. (2018)</cite> first introduced a neural mention detector as a part of their end-to-end coreference system; however, the system does not output intermediate mentions, hence the mention detector cannot be used by other coreference systems directly.",
  "y": "background"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_1",
  "x": "In this paper, we compare three neural architectures for MD. The first system is a slightly modified version of the mention detection part of the <cite>Lee et al. (2018)</cite> system.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_2",
  "x": "Thirdly, by using better mentions from our mention detector, we can improve the end-to-end <cite>Lee et al. (2018)</cite> system and the Clark and Manning (2016a) pipeline system by up to 0.7% and 1.7% respectively.",
  "y": "extends"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_3",
  "x": "The system has been later extended by Zhang et al. (2018) and <cite>Lee et al. (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_4",
  "x": "In HIGH RECALL mode we output mentions based on a fixed mention/word ratio \u03bb; this is the same method used by <cite>Lee et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_5",
  "x": "Our first system is based on the mention detection part of the <cite>Lee et al. (2018)</cite> system.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_6",
  "x": "For the mention detection evaluation we use the <cite>Lee et al. (2018)</cite> system as baseline.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_7",
  "x": "For the coreference evaluation we use the state-of-the-art <cite>Lee et al. (2018)</cite> system as our baseline for the end-to-end system, and the Clark and Manning (2016a) system as our baseline for the pipeline system.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_8",
  "x": "During the evaluation, we slightly modified the <cite>Lee et al. (2018)</cite> system to allow the system to take the mentions predicted by our model instead of its internal mention detector.",
  "y": "extends"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_9",
  "x": "For our first model (LEE MD) we use the default settings of <cite>Lee et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_10",
  "x": "For mention detection on the CONLL data set, we first take the best model from <cite>Lee et al. (2018)</cite> and use its default mention/token ratio (\u03bb = 0.4) to output predicted mentions before coreference resolution.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_11",
  "x": "Evaluation on the CRAC data set 3 For the CRAC data set, we train the <cite>Lee et al. (2018)</cite> system end-to-end on the reduced corpus with singleton mentions removed and extract mentions from the system by set \u03bb = 0.4.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_12",
  "x": "We then train our models with the same \u03bb but on the full corpus, since our mention detectors naturally support both mention 3 As the <cite>Lee et al. (2018)</cite> system does not predict singleton mentions, the results on CRAC data set in Table 2 are evaluated without singleton mentions.",
  "y": "differences"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_13",
  "x": "We first evaluate our BIAFFINE MD in combination with the end-to-end <cite>Lee et al. (2018)</cite> system.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_14",
  "x": "We first evaluate our BIAFFINE MD in combination with the end-to-end <cite>Lee et al. (2018)</cite> system. We slightly modified the system to feed the system mentions predicted by our mention detector. As a result, the original mention selection function is switched off, we keep all the other settings (include the mention scoring function) unchanged.",
  "y": "differences"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_15",
  "x": "The <cite>Lee et al. (2018)</cite> system is an extended version of the Lee et al. (2017) system, hence they share most of the network architecture.",
  "y": "background"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_16",
  "x": "For our second experiment, we used the Lee et al. (2017) instead. The <cite>Lee et al. (2018)</cite> system is an extended version of the Lee et al. (2017) system, hence they share most of the network architecture.",
  "y": "uses"
 },
 {
  "id": "6c4264bedb6683e909c1e530f22262_17",
  "x": "We further evaluated the <cite>Lee et al. (2018)</cite> system on the CRAC data set. We first train the original <cite>Lee et al. (2018)</cite> on the reduced version (with singletons removed) of the CRAC data set to create a baseline.",
  "y": "uses"
 },
 {
  "id": "6c872be6b2fbe83890e28ddc1098a3_0",
  "x": "IRT was previously used to build a new test set for the NLI task<cite> (Lalor et al., 2016)</cite> and show that model performance is dependent on test set difficulty.",
  "y": "background"
 },
 {
  "id": "6c872be6b2fbe83890e28ddc1098a3_1",
  "x": "IRT was previously used to build a new test set for the NLI task<cite> (Lalor et al., 2016)</cite> and show that model performance is dependent on test set difficulty. In this work we use IRT to probe specific items to try to analyze model performance at a more finegrained level, and expand the analysis to include the task of SA.",
  "y": "extends"
 },
 {
  "id": "6c872be6b2fbe83890e28ddc1098a3_2",
  "x": "To model item difficulty we use the Three Parameter Logistic (3PL) model from IRT (Baker, 2001; Baker and Kim, 2004; <cite>Lalor et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "6c872be6b2fbe83890e28ddc1098a3_3",
  "x": "To estimate item difficulties for NLI, we used the pre-trained IRT models of<cite> Lalor et al. (2016)</cite> and extracted the difficulty item parameters.",
  "y": "uses"
 },
 {
  "id": "6c872be6b2fbe83890e28ddc1098a3_4",
  "x": "For SA, we collected a new data set of labels for 134 examples randomly selected from the Stanford Sentiment Treebank (SSTB) (Socher et al., 2013) , using a similar AMT setup as<cite> Lalor et al. (2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "6c872be6b2fbe83890e28ddc1098a3_5",
  "x": "Scores for the NLI annotations were calculated when the original dataset was collected and are reproduced here<cite> (Lalor et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_0",
  "x": "It is shown that many published models for the Stanford Question Answering Dataset (Rajpurkar et al., 2016) lack robustness, suffering an over 50% decrease in F1 score during adversarial evaluation based on the <cite>AddSent</cite> <cite>(Jia and Liang, 2017)</cite> algorithm.",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_1",
  "x": "It has also been shown that retraining models on data generated by <cite>AddSent</cite> has limited effect on their robustness.",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_2",
  "x": "Further, in order to improve robustness to <cite>AddSent</cite>'s semantic perturbations (e.g., antonyms), we jointly improve the model's semantic-relationship learning capabilities in addition to our AddSentDiversebased adversarial training data augmentation.",
  "y": "extends"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_3",
  "x": "However, as shown recently by <cite>Jia and Liang (2017)</cite> , these models are very fragile when presented with adversarially generated data.",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_4",
  "x": "<cite>They</cite> proposed <cite>AddSent</cite>, which creates a semantically-irrelevant sentence containing a fake answer that resembles the question syntactically, and appends it to the context.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_5",
  "x": "Many state-ofthe-art models exhibit a nearly 50% reduction in F1 score on <cite>AddSent</cite>, showing their over-reliance on syntactic similarity and limited semantic understanding.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_6",
  "x": "Thus during training, the model is rarely punished for answering questions based on syntactic similarity, and learns it as a reliable approach to Q&A. This correlation between syntactic similarity and correctness is of course not true in general: the adversaries generated by <cite>AddSent</cite> <cite>(Jia and Liang, 2017)</cite> are syntactically similar to the question but do not answer them.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_7",
  "x": "The models' failures on <cite>AddSent</cite> demonstrates their ignorance of this aspect of the task.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_8",
  "x": "<cite>Jia and Liang (2017)</cite> presented some initial attempts to fix this problem by retraining the BiDAF model (Seo et al., 2017) with adversaries generated with <cite>AddSent</cite>. But <cite>they</cite> showed that the method is not very effective, as slight modifications (e.g., different positioning of the distractor sentence in the paragraph and different fake answer set) to the adversary generation algorithm at test time have drastic impact on the retrained model's performance.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_9",
  "x": "In this paper, we show that their method of adversarial training failed because the specificity of the <cite>AddSent</cite> algorithm along with the lack of naturally-occurring counterexamples allow models to learn superficial clues regarding what is a 'distractor' and subsequently ignore it; thus significantly limiting their robustness.",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_10",
  "x": "We show that an AddSentDiverse-based adversariallytrained model beats an <cite>AddSent</cite>-trained model across 3 different adversarial test sets, showing an average improvement of 24.22% in F1 score, demonstrating a general increase in robustness.",
  "y": "differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_11",
  "x": "However, even with our diversified adversarial training data, the model is still not fully resilient to <cite>AddSent</cite>-style attacks, e.g., its antonymy-style semantic perturbations.",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_12",
  "x": "Overall, we demonstrate that with our adversarial training method and model improvement, we can increase the performance of a state-of-theart model by 36.46% on the <cite>AddSent</cite> evaluation set.",
  "y": "differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_13",
  "x": "Although we focused on the <cite>AddSent</cite> adversary <cite>(Jia and Liang, 2017)</cite> , our method of effective adversarial training by eliminating superficial statistical correlations (with joint model capability improvements) are generalizable to other similar insertion-based adversaries for Q&A tasks.",
  "y": "extends"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_14",
  "x": "In the field of Q&A, <cite>Jia and Liang (2017)</cite> introduced the <cite>AddSent</cite> algorithm, which generates adversaries that punish model failure in the other direction: overstability, or the inability to detect semantic-altering noise.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_15",
  "x": "When tested on these adversarial examples, <cite>Jia and Liang (2017)</cite> showed that even the most 'robust' amongst published models (the Mnemonic Reader (Hu et al., 2017) ) only achieved 46.6% F1 (compared to 79.6% F1 on the regular task).",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_16",
  "x": "In the field of Q&A, <cite>Jia and Liang (2017)</cite> attempted to retrain the BiDAF (Seo et al., 2017) model with data generated with <cite>AddSent</cite> algorithm.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_17",
  "x": "Despite performing well when evaluated on <cite>AddSent</cite>, the retrained model suffers a more than 30% decrease in F1 performance when tested on a slightly different adversarial dataset generated by AddSentMod (which differs from <cite>AddSent</cite> in two superficial ways: using a different set of fake answers and prepending instead of appending the distractor sentence to the context).",
  "y": "differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_18",
  "x": "We show that using <cite>AddSent</cite> to generate adversarial training data introduces new superficial trends for a model to exploit; and instead we propose the AddSentDiverse algorithm that generates highly varied data for adversarial training, resulting in more robust models.",
  "y": "extends"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_19",
  "x": "Our 'AddSentDiverse' algorithm is a modified version of <cite>AddSent</cite> <cite>(Jia and Liang, 2017)</cite> , aimed at producing good adversarial examples for robust training purposes.",
  "y": "extends"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_20",
  "x": "For each {context, question, answer} triple, <cite>AddSent</cite> does the following: (1) Several antonym and named-entity based semantic altering perturbations (swapping) are applied to the question; (2) A fake answer is generated that matches the 'type' of the original answer (e.g., Prague \u2192 Chicago, etc.); (3) The fake answer and the altered question are combined into a distractor statement based on a set of manually defined rules; (4) Errors in grammar are fixed by crowd-workers; (5) The finalized distractor is appended to the end of the context.",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_21",
  "x": "We thus introduce the AddSentDiverse algorithm, which adds two modifications to <cite>AddSent</cite> that allows for generating higher-variance adversarial examples.",
  "y": "extends"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_22",
  "x": "Lastly, to address the antonymstyle semantic perturbations used in <cite>AddSent,</cite> we show that we need to improve model capabilities by adding indicator features for semantic relationships (but only when) in tandem with the addition of diverse adversarial data (Sec. 3.3).",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_23",
  "x": "During training done by <cite>Jia and Liang (2017)</cite> , the distractor is always added as the last sentence, creating a very skewed distribution for Y .",
  "y": "background"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_24",
  "x": "To prevent the model from superficially deciding what is a distractor based on certain specific words, we dynamically generate the fake answers instead of using <cite>AddSent</cite>'s pre-defined set.",
  "y": "differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_25",
  "x": "For each answer a, we generate the fake answer dynamically by randomly selecting another answer a = a from S that has the same type as a, as opposed to <cite>AddSent</cite> <cite>(Jia and Liang, 2017)</cite> , which uses a pre-defined fake answer for each type (e.g., \"Chicago\" for any location).",
  "y": "differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_26",
  "x": "But even if we force the model to learn some deeper methods for identifying/discarding the distractors, it only has limited ability in recognizing semantic differences because its current inputs do not capture crucial aspects of lexical semantics such as antonymy (which were inserted by <cite>Jia and Liang (2017)</cite> when generating the <cite>AddSent</cite> adversaries; see Sec. 3).",
  "y": "differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_27",
  "x": "These shortcomings are reflected by our results in Sec. 4.6, where we see that we can't resolve all <cite>AddSent</cite>- style adversaries by diversifying the training data alone.",
  "y": "motivation"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_28",
  "x": "Models are evaluated on the original SQuAD dev set and 4 adversarial datasets: <cite>AddSent</cite>, the adversarial evaluation set by <cite>Jia and Liang (2017)</cite> , and 3 variations of <cite>AddSent</cite>: AddSentPrepend, where the distractor is prepended to the context, AddSentRandom, where the distractor is randomly inserted into the context, 4 and AddSentMod <cite>(Jia and Liang, 2017)</cite> , where a different set of fake answers is used and the distractor is prepended to the context.",
  "y": "uses"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_29",
  "x": "Experiments measure the soft F1 score and all of the adversarial evaluations are modeldependent, following the style of <cite>AddSent</cite>, where multiple adversaries are generated for each exam-ple in the evaluation set and the model's worst performance among the variants is recorded.",
  "y": "uses"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_30",
  "x": "In our main experiment, we compare the BSAE model's performance on different test sets when trained with three different training sets: the original SQuAD data (Original-SQuAD), SQuAD data augmented with <cite>AddSent</cite> generated adversaries (similar to adversarial training conducted by <cite>Jia and Liang (2017)</cite>), and SQuAD data augmented with our AddSentDiverse generated adversaries.",
  "y": "uses"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_31",
  "x": "First, as shown, the <cite>AddSent</cite>-trained model is not able to perform well on test sets where the distractors are not inserted at the end, e.g., the AddSentRandom adversarial test set.",
  "y": "uses"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_32",
  "x": "The retrained models are tested on <cite>AddSent</cite> and AddSentPrepend, whose only difference is where the distractor is located.",
  "y": "uses differences"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_33",
  "x": "Finally, we examined the errors of our final adversarially-trained BSAE+SA model on the <cite>AddSent</cite> dataset and found that out of the 21.09% remaining errors (Table 4) , 33.3% (46 cases) of these erroneous predictions occurred within the inserted distractor, and 63.7% (88 cases) occurred on questions that the model got wrong in the original SQuAD dev set (without the inserted distractors).",
  "y": "uses"
 },
 {
  "id": "6ca6283ae23bbd6d0827d8f5f2947a_34",
  "x": "This explains why in our experiment studying the effect of distractor placement strategies (see Table 2), InsMid's performance was not skewed towards either <cite>AddSent</cite> or AddSentPrepend, but was worse on both when compared to InsRandom.",
  "y": "uses"
 },
 {
  "id": "6ca7c7782c33f51e9bdb2e8613c24d_0",
  "x": "Natural language dialog has been used in many areas, such as for call-center/routing application (Carpenter & Chu-Carroll 1998) , email routing (Walker, Fromer & Narayanan 1998), information retrieval and database access <cite>(Androutsopoulos & Ritchie 1995)</cite> , and for telephony banking (Zadrozny et al. 1998) .",
  "y": "background"
 },
 {
  "id": "6ca7c7782c33f51e9bdb2e8613c24d_1",
  "x": "Natural language dialog has been used in many areas, such as for call-center/routing application (Carpenter & Chu-Carroll 1998) , email routing (Walker, Fromer & Narayanan 1998), information retrieval and database access <cite>(Androutsopoulos & Ritchie 1995)</cite> , and for telephony banking (Zadrozny et al. 1998) . In this demonstration, we present a natural language dialog interface to online shopping.",
  "y": "extends"
 },
 {
  "id": "6cb86d91918743b0e4ff27e9d2351b_0",
  "x": "Automatic methods for error detection in treebanks have been developed in the DECCA project 1 for several different annotation types, for example part-of-speech<cite> (Dickinson and Meurers, 2003a)</cite> , constituency syntax (Dickinson and Meurers, 2003b) , and dependency syntax (Boyd et al., 2008) .",
  "y": "background"
 },
 {
  "id": "6cb86d91918743b0e4ff27e9d2351b_1",
  "x": "The algorithm, described in <cite>Dickinson and Meurers (2003a)</cite> for POS tags, works by starting from individual tokens (the nuclei) by recording their assigned part-of-speech over an entire treebank.",
  "y": "background"
 },
 {
  "id": "6cb86d91918743b0e4ff27e9d2351b_2",
  "x": "In addition to the output of the algorithm by <cite>Dickinson and Meurers (2003a)</cite>, the tool also provides a second view, which displays tag distributions of word forms to the user (see Figure 2) .",
  "y": "extends"
 },
 {
  "id": "6cb86d91918743b0e4ff27e9d2351b_3",
  "x": "These results are in line with findings by <cite>Dickinson and Meurers (2003a)</cite> for the Penn Treebank.",
  "y": "similarities"
 },
 {
  "id": "6cb86d91918743b0e4ff27e9d2351b_4",
  "x": "It implements the error detection algorithms by <cite>Dickinson and Meurers (2003a)</cite> and Boyd et al. (2008) .",
  "y": "uses"
 },
 {
  "id": "6cbc59d4cb2d3246b3efa1ee612270_0",
  "x": "They also cleaned United Nations material and post-edited general-domain data that was previously filtered as indomain following the \"invitation model\" <cite>(Hoang and Sima'an, 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "6cbc59d4cb2d3246b3efa1ee612270_1",
  "x": "They also cleaned United Nations material and post-edited general-domain data that was previously filtered as indomain following the \"invitation model\" <cite>(Hoang and Sima'an, 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "6cc36fef99fb1f25370175452f30b0_0",
  "x": "There has been much recent work in attempting to convert native parser output into alternative representations for evaluation purposes, e.g. (Clark and Curran, 2007; <cite>Matsuzaki and Tsujii, 2008</cite> ).",
  "y": "background"
 },
 {
  "id": "6cc36fef99fb1f25370175452f30b0_1",
  "x": "There has been much recent work in attempting to convert native parser output into alternative representations for evaluation purposes, e.g. (Clark and Curran, 2007; <cite>Matsuzaki and Tsujii, 2008</cite> ). The conclusion is that such conversions are surprisingly difficult.",
  "y": "motivation background"
 },
 {
  "id": "6cc36fef99fb1f25370175452f30b0_2",
  "x": "There are three types of conversion schema: schemas which introduce nodes for lexical items; schemas which insert or elide PTB nodes for unary 3 Another possible approach has been taken by<cite> Matsuzaki and Tsujii (2008)</cite> , who convert HPSG analyses from a grammar automatically extracted from the PTB back into the PTB.",
  "y": "background"
 },
 {
  "id": "6cc36fef99fb1f25370175452f30b0_3",
  "x": "Even an upper bound of around 98%, which is achieved by<cite> Matsuzaki and Tsujii (2008)</cite> , is not sufficient, since this guarantees a loss of at least 2%.",
  "y": "background"
 },
 {
  "id": "6cc36fef99fb1f25370175452f30b0_4",
  "x": "The fact that the upper bound here is less than 95% shows that it is not possible to fairly evaluate the CCG parser on the complete test set. Even an upper bound of around 98%, which is achieved by<cite> Matsuzaki and Tsujii (2008)</cite> , is not sufficient, since this guarantees a loss of at least 2%.",
  "y": "differences"
 },
 {
  "id": "6cc36fef99fb1f25370175452f30b0_5",
  "x": "In addition, we have thrown further doubt on the possible use of the PTB for cross-framework parser evaluation, as recently suggested by<cite> Matsuzaki and Tsujii (2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "6cd4235e66a6e6e9768250c3db7fc6_0",
  "x": "The most recent work is the learningbased language-independent discriminative parsing approach for normalizing temporal expressions by <cite>Angeli and Uszkoreit (2013</cite> There are also (semi-)automatic approaches to port a temporal tagger from one language to another.",
  "y": "background"
 },
 {
  "id": "6cd4235e66a6e6e9768250c3db7fc6_1",
  "x": "However, no TempEval-2 participants addressed Chinese and only<cite> Angeli and Uszkoreit (2013)</cite> report evaluation results on this corpus.",
  "y": "background"
 },
 {
  "id": "6cd4235e66a6e6e9768250c3db7fc6_2",
  "x": "1 This issue was also reported by<cite> Angeli and Uszkoreit (2013)</cite> .",
  "y": "background"
 },
 {
  "id": "6cd4235e66a6e6e9768250c3db7fc6_4",
  "x": "Corpus: We use three versions of the TempEval-2 training and test sets: (i) the original versions, (ii) the improved versions described in Section 3.3, and (iii) the cleaned versions also used by<cite> Angeli and Uszkoreit (2013)</cite> in which temporal expressions without value information are removed.",
  "y": "uses similarities"
 },
 {
  "id": "6cd4235e66a6e6e9768250c3db7fc6_7",
  "x": "Table 4 shows the comparison between our approach and the one by<cite> Angeli and Uszkoreit (2013)</cite> . We outperform their approach not only with respect to the accuracy but also with respect to the numbers of correctly normalized expressions (574 vs. 484 5 and 121 vs. 86 5 on the training and test sets, respectively) -despite the fact that we perform the full task of temporal tagging and not only the normalization.",
  "y": "differences"
 },
 {
  "id": "6d8612cfb4bf05322fed1c02f4885a_0",
  "x": "Such findings encourage further research in the area of measuring readability, which not only facilitates adjusting the text to the reader (Danescu-Niculescu-Mizil et al., 2011) , but can also play an important role in identifying authorial style <cite>(Pitler and Nenkova, 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "6d8612cfb4bf05322fed1c02f4885a_1",
  "x": "As shorter words are considered more readable (Gunning, 1969;<cite> Pitler and Nenkova, 2008)</cite> , we also measure the ratio of words longer than five letters.",
  "y": "uses background"
 },
 {
  "id": "6d8612cfb4bf05322fed1c02f4885a_2",
  "x": "Syntax Researchers argue about longer sentences not necessarily being more complex in terms of syntax (Feng et al., 2009;<cite> Pitler and Nenkova, 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "6d8612cfb4bf05322fed1c02f4885a_3",
  "x": "We quantify the number of hedges (Hyland, 2005) and abstract words 1 used, and the ratio of standalone numbers stated per user as these are indicators of specificity (Pennebaker et al., 2003;<cite> Pitler and Nenkova, 2008)</cite> .",
  "y": "uses background"
 },
 {
  "id": "6edf517d79f7fd2a0653a3d5fb543d_0",
  "x": "While early methods required a training dictionary to find the initial alignment (Mikolov et al., 2013) , fully unsupervised methods have managed to obtain comparable results based on either adversarial training or selflearning<cite> (Artetxe et al., 2018b)</cite> .",
  "y": "background"
 },
 {
  "id": "6edf517d79f7fd2a0653a3d5fb543d_1",
  "x": "While early methods required a training dictionary to find the initial alignment (Mikolov et al., 2013) , fully unsupervised methods have managed to obtain comparable results based on either adversarial training or selflearning<cite> (Artetxe et al., 2018b)</cite> . A prominent application of these methods is Bilingual Lexicon Induction (BLI), that is, using the resulting cross-lingual embeddings to build a bilingual dictionary. In this paper, we go one step further and, rather than directly inducing the bilingual dictionary from the cross-lingual word embeddings, we use them to build an unsupervised machine translation system, and extract a bilingual dictionary from a synthetic parallel corpus generated with it.",
  "y": "extends background"
 },
 {
  "id": "6edf517d79f7fd2a0653a3d5fb543d_2",
  "x": "In our experiments, we use fastText embeddings (Bojanowski et al., 2017) mapped through VecMap<cite> (Artetxe et al., 2018b</cite> ), but the algorithm described next can also work with any other word embedding and cross-lingual mapping method.",
  "y": "uses"
 },
 {
  "id": "6edf517d79f7fd2a0653a3d5fb543d_3",
  "x": "Having done that, we map these word embeddings to a cross-lingual space using the unsupervised mode in VecMap<cite> (Artetxe et al., 2018b)</cite> , which builds an initial solution based on the intralingual similarity distribution of the embeddings and iteratively improves it through self-learning.",
  "y": "uses"
 },
 {
  "id": "6edf517d79f7fd2a0653a3d5fb543d_4",
  "x": "The amount of required supervision was later reduced through self-learning methods (Artetxe et al., 2017) , and then completely eliminated through adversarial training (Zhang et al., 2017a; or more robust iterative approaches combined with initialization heuristics<cite> (Artetxe et al., 2018b</cite>; Hoshen and Wolf, 2018) .",
  "y": "uses"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_0",
  "x": "In many practical problems, RNNs can be compressed orders of times with only slight quality drop or even with quality improvement<cite> [2,</cite> 15, 20] .",
  "y": "background"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_1",
  "x": "Methods for RNN compression can be divided into three groups: based on matrix factorization [6, 19] , quantization [7] or sparsification<cite> [2,</cite> 15, 20] .",
  "y": "background"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_2",
  "x": "Methods for RNN compression can be divided into three groups: based on matrix factorization [6, 19] , quantization [7] or sparsification<cite> [2,</cite> 15, 20] . We focus on RNNs sparsification.",
  "y": "uses"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_3",
  "x": "Bayesian sparsification techniques [14, 16, 8, 9,<cite> 2]</cite> treat weights of an RNN as random variables and approximate posterior distribution over them given sparsity-inducing prior distribution.",
  "y": "background"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_4",
  "x": "Following<cite> [2,</cite> 14] , we sparsify individual weights of the RNN.",
  "y": "uses"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_5",
  "x": "In <cite>[2]</cite> SparseVD is adapted to RNNs.",
  "y": "background"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_6",
  "x": "To sparsify individual weights, we apply SparseVD [14] to all weights of the RNN, taking into account recurrent specifics underlined in <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_7",
  "x": "In <cite>[2]</cite> SparseVD is adapted to RNNs. To sparsify individual weights, we apply SparseVD [14] to all weights of the RNN, taking into account recurrent specifics underlined in <cite>[2]</cite> .",
  "y": "similarities"
 },
 {
  "id": "6f4dc72277119f0df3d4a7155c61fc_8",
  "x": "Since in text classification tasks usually only a small number of input words are important, we use additional multiplicative weights to sparsify the input vocabulary in case of group sparsification (W+N, W+G+N) following <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_0",
  "x": "It has been more recently that graph-based methods for knowledge-based WSD have gained much attention in the NLP community ( (Sinha and Mihalcea, 2007) , (Navigli and Lapata, 2007) , (Agirre and Soroa, 2008) ,<cite> (Agirre and Soroa, 2009)</cite> ).",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_1",
  "x": "In <cite>(Agirre and Soroa, 2009</cite> ), a comparative analysis of different graph-based models over two well known WSD benchmarks is reported.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_2",
  "x": "In particular, a variant called Personalized PageRank (P P R) is proposed <cite>(Agirre and Soroa, 2009</cite> ) that tries to trade-off between the amount of the employed lexical information and the overall efficiency.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_3",
  "x": "In <cite>(Agirre and Soroa, 2009</cite> ), a possible, and more accurate alternative, is also presented called PPR word2word (P P Rw2w) where a different personalization vector is used for each word in a sentence.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_4",
  "x": "In <cite>(Agirre and Soroa, 2009</cite> ), a possible, and more accurate alternative, is also presented called PPR word2word (P P Rw2w) where a different personalization vector is used for each word in a sentence. Although clearly less efficient in terms of time complexity, this approach guarantees the best accuracy, so that it can be considered the state-ofthe art in unsupervised WSD. In this paper a different approach to personalization of the PageRank is presented, aiming at preserving the suitable efficiency of the sentence oriented PPR algorithm for WSD but achieving an accuracy at least as high as the P P Rw2w one.",
  "y": "motivation"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_5",
  "x": "The intuition is that distributional evidence is able to cover the gap between word oriented usages of the P P R as for the P P Rw2w defined in<cite> (Agirre and Soroa, 2009)</cite> , and its sentence oriented counterpart.",
  "y": "differences"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_6",
  "x": "Many algorithms (as well as the one proposed by<cite> (Agirre and Soroa, 2009)</cite> ) initialize the ranks of the vertex at a uniform value (usually 1/N for a graph with N vertices).",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_7",
  "x": "In order to address the above problems, in line with the notion of topic-sensitive PageRank, a personalized PageRank approach has been recently devised <cite>(Agirre and Soroa, 2009</cite> ) as discussed in the next section.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_8",
  "x": "In <cite>(Agirre and Soroa, 2009</cite> ), a novel use of PageRank for word sense disambiguation is presented.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_9",
  "x": "The alternative proposed in <cite>(Agirre and Soroa, 2009</cite> ) allows a more static use of the full LKB.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_10",
  "x": "A word oriented version of the algorithm is also proposed in <cite>(Agirre and Soroa, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_11",
  "x": "This approach to the personalized PageRank is termed word-by-word or P P Rw2w version in<cite> (Agirre and Soroa, 2009)</cite> .",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_12",
  "x": "The key idea in <cite>(Agirre and Soroa, 2009</cite> ) is to adapt the matrix initialization step in order to exploit the available contextual evidence.",
  "y": "background"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_13",
  "x": "In order to compare the quality of the proposed approach, the results of the personalized PageRank proposed in <cite>(Agirre and Soroa, 2009</cite> ) over the same dataset are reported in Table 1 (The * systems, denoted by UKB).",
  "y": "uses"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_15",
  "x": "The * systems was presented in <cite>(Agirre and Soroa, 2009</cite> ).",
  "y": "uses"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_16",
  "x": "In line with<cite> (Agirre and Soroa, 2009)</cite> , different types of WordNet graphs are employed in our experiments:",
  "y": "similarities"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_17",
  "x": "In <cite>(Agirre and Soroa, 2009</cite> ) the suggested parameters are \u03b1 = 0.85 as the damping factor and 30 as the upper limit to the PageRank iterations. We always adopted this setting to estimate the performances of the standard P P R and P P Rw2w algorithms referred through U KB.",
  "y": "uses"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_18",
  "x": "As a confirmation of the outcome in <cite>(Agirre and Soroa, 2009</cite> ), different lexical resources achieve different results.",
  "y": "similarities"
 },
 {
  "id": "70c786a0affcc9f206cc4252112cd2_19",
  "x": "An even more interesting outcome is that the improvement implied by the proposed LSA method on the sentence oriented model (i.e. the standard PPR method of<cite> (Agirre and Soroa, 2009)</cite> ) is higher, so that the difference between the performances of the P P Rw2w model are no longer strikingly better than the P P R one.",
  "y": "differences"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_0",
  "x": "In recent years, sentiment analysis has received considerable attentions in Natural Language Processing (NLP) community (Blitzer et al., 2007; Dasgupta and Ng, 2009; Pang et al., 2002) . Polarity classification, which determine whether the sentiment expressed in a document is positive or negative, is one of the most popular tasks of sentiment analysis<cite> (Dasgupta and Ng, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_1",
  "x": "Polarity classification, which determine whether the sentiment expressed in a document is positive or negative, is one of the most popular tasks of sentiment analysis<cite> (Dasgupta and Ng, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_2",
  "x": "Second, sentiment classification systems are typically domain-specific, which makes the expensive process of annotating a large amount of data for each domain and is a bottleneck in building high quality systems<cite> (Dasgupta and Ng, 2009</cite> ). This motivates the task of learning robust sentiment models from minimal supervision (Li, et al., 2009) .",
  "y": "motivation background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_3",
  "x": "Recently, semi-supervised learning, which uses large amount of unlabeled data together with labeled data to build better learners (Raina et al., 2007; Zhu, 2007) , has drawn more attention in sentiment analysis<cite> (Dasgupta and Ng, 2009</cite>; Li, et al., 2009) . As argued by several researchers (Bengio, 2007; Salakhutdinov and Hinton, 2007) , deep architecture, composed of multiple levels of non-linear operations (Hinton et al., 2006) , is expected to perform well in semi-supervised learning because of its capability of modeling hard artificial intelligent tasks.",
  "y": "background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_4",
  "x": "Recently, active learning had been applied in sentiment classification<cite> (Dasgupta and Ng, 2009)</cite> . Inspired by the study of semi-supervised learning, active learning and deep architecture, this paper proposes a novel semi-supervised polarity classification algorithm called Active Deep Networks (ADN) that is based on a representative deep learning algorithm Deep Belief Networks (DBN) (Hinton, et al., 2006) and active learning (Tong and Koller, 2002) .",
  "y": "motivation background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_5",
  "x": "Supervised sentiment classification systems are domain-specific and annotating a large scale corpus for each domain is very expensive<cite> (Dasgupta and Ng, 2009</cite> ). There are several solutions for this corpus annotation bottleneck. The first type of solution is using old domain labeled examples to new domain sentiment clas-sification. The second type of solution is semisupervised sentiment classification. The third type of solution is unsupervised sentiment classification.",
  "y": "motivation background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_6",
  "x": "However, unsupervised learning of sentiment is difficult, partially because of the prevalence of sentimentally ambiguous reviews<cite> (Dasgupta and Ng, 2009</cite> ). Using multi-domain sentiment corpus to sentiment classification is also hard to apply, because each domain has a very limited amount of training data, due to annotating a large corpus is difficult and time-consuming (Li and Zong, 2008) . So in this paper we focus on semi-supervised approach to sentiment classification.",
  "y": "motivation background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_7",
  "x": "There are many review documents in the dataset. We preprocess these reviews to be classified, which is similar with<cite> Dasgupta and Ng (2009)</cite> .",
  "y": "similarities"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_8",
  "x": "The main issue for an active learner is the choosing of next unlabeled instance to query. In this paper, we choose the reviews whose labels are most uncertain for the classifier. Following previous work on active learning for SVMs<cite> (Dasgupta and Ng, 2009</cite>; Tong and Koller, 2002) , we define the uncertainty of a review as its distance from the separating hyperplane. In other words, reviews that are near the separating hyperplane are chosen as the labeled training data.",
  "y": "similarities background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_9",
  "x": "The experimental setting is similar with<cite> Dasgupta & Ng (2009)</cite> . We perform active learning for five iterations and select twenty of the most uncertainty reviews to be queried each time. Then the ADN is re-trained on all of labeled and unlabeled reviews so far with semisupervised learning. At last, we can decide the label of reviews x according to the output h N (x) of the ADN architecture as below:",
  "y": "extends"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_10",
  "x": "Similar with<cite> Dasgupta and Ng (2009)</cite>, we divide the 2,000 reviews into ten equal-sized folds randomly and test all the algorithms with crossvalidation. In each folds, 100 reviews are random selected as training data and the remaining 100 data are used for test. Only the reviews in the training data set are used for the selection of labeled data by active learning. The ADN architecture has different number of hidden units for each hidden layer.",
  "y": "extends"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_11",
  "x": "We compare the classification performance of ADN with five representative classifiers, i.e., Semi-supervised spectral learning (Spectral) (Kamvar et al., 2003) , Transductive SVM (TSVM), Active learning (Active) (Tong and Koller, 2002) , Mine the Easy Classify the Hard (MECH)<cite> (Dasgupta and Ng, 2009)</cite> , and Deep Belief Networks (DBN) (Hinton, et al., 2006) .",
  "y": "background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_12",
  "x": "MECH is a new semi-supervised method for sentiment classification<cite> (Dasgupta and Ng, 2009)</cite> .",
  "y": "background"
 },
 {
  "id": "715cba53c376e50b76a0966ff16a6a_13",
  "x": "The results of previous four methods are reported by<cite> Dasgupta and Ng (2009)</cite> .",
  "y": "background"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_0",
  "x": "We also report a comparison of our approach with that of<cite> (Munteanu and Marcu, 2005)</cite> using exactly the same corpora and show performance gain by using much lesser data.",
  "y": "similarities differences"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_1",
  "x": "The ease of availability of these comparable corpora and the potential for parallel corpus as well as dictionary creation has sparked an interest in trying to make maximum use of these comparable resources, some of these works include dictionary learning and identifying word translations (Rapp, 1995) , named entity recognition (Sproat et al., 2006) , word sense disambiguation (Kaji, 2003) , improving SMT performance using extracted parallel sentences<cite> (Munteanu and Marcu, 2005)</cite> , (Rauf and Schwenk, 2009 ).",
  "y": "background"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_2",
  "x": "Recent work by <cite>Munteanu and Marcu (2005)</cite> uses a bilingual lexicon to translate some of the words of the source sentence.",
  "y": "background"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_3",
  "x": "Our use of full SMT sentences, gives us an added advantage of being able to detect one of the major errors of these approaches, also identified by<cite> (Munteanu and Marcu, 2005)</cite> , i.e, the cases where the initial sentences are identical but the retrieved sentence has a tail of extra words at sentence end.",
  "y": "similarities"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_4",
  "x": "We also perform a comparison of the data extracted by our approach and that by<cite> (Munteanu and Marcu, 2005)</cite> and report the results in Section 5.3.",
  "y": "uses"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_5",
  "x": "LDC provides extracted parallel texts extracted with the algorithm published by<cite> (Munteanu and Marcu, 2005)</cite> . This corpus contains 1.1M sentence pairs (about 35M words) which were automatically extracted and aligned from the monolingual Arabic and English Gigaword corpora, a confidence score being provided for each sentence pair. We also applied our approach on data provided by LDC, but on a different subset.",
  "y": "similarities"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_6",
  "x": "Contrary to the previous approaches as in<cite> (Munteanu and Marcu, 2005)</cite> which used small amounts of in-domain parallel corpus as an initial resource, our system exploits the target language side of the comparable corpus to attain the same goal, thus the comparable corpus itself helps to better extract possible parallel sentences.",
  "y": "differences"
 },
 {
  "id": "7176d3dd72e781dca42f8c146d062d_7",
  "x": "Our technique is similar to that of<cite> (Munteanu and Marcu, 2005)</cite> but we bypass the need of the bilingual dictionary by using proper SMT translations and instead of a maximum entropy classifier we use simple measures like the word error rate (WER) and the translation edit rate (TER) to decide whether sentences are parallel or not.",
  "y": "similarities differences"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_0",
  "x": "Previous work on classifying information status (Nissim, 2006;<cite> Rahman and Ng, 2011</cite>) is restricted to coarse-grained classification and focuses on conversational dialogue.",
  "y": "motivation"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_1",
  "x": "Previous work on learning IS (Nissim, 2006;<cite> Rahman and Ng, 2011</cite> ) is restricted in several ways.",
  "y": "motivation"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_2",
  "x": "We reimplement Nissim's (2006) and <cite>Rahman and Ng's (2011)</cite> approaches as baselines and show that our approach outperforms these by a large margin for both coarse-and finegrained IS classification.",
  "y": "uses differences"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_3",
  "x": "Nissim (2006) and<cite> Rahman and Ng (2011)</cite> both present algorithms for IS detection on Nissim et al.'s (2004) Switchboard corpus.",
  "y": "background"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_4",
  "x": "Nissim (2006) and<cite> Rahman and Ng (2011)</cite> both present algorithms for IS detection on Nissim et al.'s (2004) Switchboard corpus. Both papers treat IS classification as a local classification problem whereas we look at dependencies between the IS status of different mentions, leading to collective classification.",
  "y": "differences"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_5",
  "x": "We use the following local features, including the features in Nissim (2006) and<cite> Rahman and Ng (2011)</cite> to be able to gauge how their systems fare on our corpus and as a comparison point for our novel collective classification approach.",
  "y": "uses"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_6",
  "x": "Both Nissim (2006) and<cite> Rahman and Ng (2011)</cite> classify each mention individually in a standard supervised ML setting, not considering potential dependencies between the IS categories of different mentions.",
  "y": "background"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_7",
  "x": "Using such a relational feature catches two birds with one stone: firstly, it integrates the internal structure of a mention into the algorithm, which<cite> Rahman and Ng (2011)</cite> ignore; secondly, it captures dependencies between parent and child classification, which would not be possible if we integrated the internal structure via flat features or additional tree kernels.",
  "y": "differences"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_8",
  "x": "Following Nissim (2006) and<cite> Rahman and Ng (2011)</cite> , we perform all experiments on gold standard mentions and use the human WSJ syntactic annotation for feature extraction, when necessary.",
  "y": "uses"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_9",
  "x": "We reimplemented the algorithms in Nissim (2006) and<cite> Rahman and Ng (2011)</cite> as comparison baselines, using their feature and algorithm choices.",
  "y": "uses"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_10",
  "x": "One problem when using the SVM Tree kernel as relational classifier is that it allows only for binary classification so that we need to train several binary networks in a one-vs-all paradigm (see also<cite> (Rahman and Ng, 2011)</cite> ), which will not be able to use the multiclass dependencies of the relational features to optimum effect.",
  "y": "background"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_11",
  "x": "We show that our collective classification approach outperforms the state-of-the-art in coarse-grained IS classification by about 10% (Nissim, 2006) and 5%<cite> (Rahman and Ng, 2011)</cite> accuracy.",
  "y": "differences"
 },
 {
  "id": "71a72cfca17b0b15938ed590f9c868_12",
  "x": "Since the work reported in this paper relied -following Nissim (2006) and<cite> Rahman and Ng (2011)</cite> -on gold standard mentions and syntactic annotations, we plan to perform experiments with predicted mentions as well.",
  "y": "uses"
 },
 {
  "id": "71bcd87091c4f5e2b7bc564b7bd9dd_0",
  "x": "Here, we describe briefly the underlying framework, called RNN Encoder-Decoder, proposed by<cite> (Cho et al., 2014b)</cite> and (Sutskever et al., 2014) upon which we build a machine transliteration model that learns to transliterate end-to-end.",
  "y": "extends background"
 },
 {
  "id": "71bcd87091c4f5e2b7bc564b7bd9dd_1",
  "x": "We conducted a set of experiments to show the effectiveness of RNN Encoder-Decoder model<cite> (Cho et al., 2014b</cite>; Sutskever et al., 2014) in the task of machine transliteration using standard benchmark datasets provided by NEWS 2015-16 shared task .",
  "y": "uses"
 },
 {
  "id": "71bcd87091c4f5e2b7bc564b7bd9dd_2",
  "x": "We leveraged a character-based encoderdecoder model (Bojanowski et al., 2015; Chung et al., 2016) with soft attention mechanism<cite> (Cho et al., 2014b)</cite> .",
  "y": "uses"
 },
 {
  "id": "71bcd87091c4f5e2b7bc564b7bd9dd_3",
  "x": "The encoder has 128 hidden units for each direction (forward and backward), and the decoder has 128 hidden units with soft attention mechanism<cite> (Cho et al., 2014b)</cite> .",
  "y": "background"
 },
 {
  "id": "7202fd7fe7e776362b126f7cbf0bf3_0",
  "x": "End-to-end speech models often have millions of parameters [7, 8,<cite> 9,</cite> 10, 11] .",
  "y": "background"
 },
 {
  "id": "7202fd7fe7e776362b126f7cbf0bf3_1",
  "x": "End-to-end speech models often have millions of parameters [7, 8,<cite> 9,</cite> 10, 11] . However, data augmentation and dropout have not been extensively studied or applied to them. We investigate the effectiveness of data augmentation and dropout for regularizing end-to-end speech models.",
  "y": "background motivation"
 },
 {
  "id": "7202fd7fe7e776362b126f7cbf0bf3_2",
  "x": "Background noise is used for augmentation in [8,<cite> 9]</cite> to improve performance on noisy speech.",
  "y": "background"
 },
 {
  "id": "7202fd7fe7e776362b126f7cbf0bf3_3",
  "x": "Background noise is used for augmentation in [8,<cite> 9]</cite> to improve performance on noisy speech. Apart from adding noise, our data augmentation also modifies the tempo, pitch, volume and temporal alignment of the audio.",
  "y": "background similarities"
 },
 {
  "id": "7202fd7fe7e776362b126f7cbf0bf3_4",
  "x": "The end-to-end model structure used in this work is very similar to the model architecture of Deep Speech 2 (DS2) <cite>[9]</cite> .",
  "y": "similarities"
 },
 {
  "id": "7202fd7fe7e776362b126f7cbf0bf3_6",
  "x": "We would like to note that our model achieved comparable results with Amodei et al. <cite>[9]</cite> on LibriSpeech dataset, although our model is only trained only on the provided training set.",
  "y": "similarities"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_0",
  "x": "For our word-level submissions we have applied the approach proposed by<cite> Espl\u00e0-Gomis et al. (2015)</cite> , where we used black-box bilingual on-line resources.",
  "y": "extends differences"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_1",
  "x": "As described by<cite> Espl\u00e0-Gomis et al. (2015)</cite> , a collection of features is obtained from these correspondences and then used by a binary classifier to determine the final word-level MTQE labels.",
  "y": "extends differences"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_2",
  "x": "The method used to produce the word-level MTQE submissions is the same than that used by the UAlacant team in the last edition of the shared task of MTQE at WMT 2015 <cite>(Espl\u00e0-Gomis et al., 2015)</cite> , which uses binary classification based on a collection of information.",
  "y": "background"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_3",
  "x": "A complete description of the features used for word-level MTQE can be found in Section 2 of the paper by<cite> Espl\u00e0-Gomis et al. (2015)</cite> . Following the approach by<cite> Espl\u00e0-Gomis et al. (2015)</cite> , the perceptron was built with a single hidden layer containing the same number of nodes as the number of features; this was the best performing architecture in the preliminary experiments.",
  "y": "background"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_4",
  "x": "Following the approach by<cite> Espl\u00e0-Gomis et al. (2015)</cite> , the perceptron was built with a single hidden layer containing the same number of nodes as the number of features; this was the best performing architecture in the preliminary experiments.",
  "y": "extends differences"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_5",
  "x": "dcs.shef.ac.uk/wmt16_files_qe/task2p_ en-de_test.tar.gz 7 The rest of parameters of the classifiers were also kept as in the approach by<cite> Espl\u00e0-Gomis et al. (2015)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_6",
  "x": "Incidentally, and in spite of the changes in languages and machine translation systems, the results obtained for word-level MTQE are very similar to those obtained by<cite> Espl\u00e0-Gomis et al. (2015)</cite> for the translation from English into Spanish.",
  "y": "similarities"
 },
 {
  "id": "7293ab5db16d3fe1fee48d45154697_7",
  "x": "The results obtained confirm the conclusion by<cite> Espl\u00e0-Gomis et al. (2015)</cite> that combining the baseline features with those obtained from external sources of bilingual information provide a noticeable improvement, in this case, not only for word-level MTQE, but also for phrase-level MTQE.",
  "y": "extends differences"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_0",
  "x": "<cite>[10]</cite> released one of the initial data sets from Twitter with the goal of identifying what constitutes racism and sexism.",
  "y": "background"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_1",
  "x": "Stop saying dumb blondes with pretty faces as you need a pretty face to pull them off !!! #mkr In Islam women must be locked in their houses and Muslims claim this is treating them well Table 1 : Tweets from <cite>[10]</cite> data set demonstrating online abuse <cite>They</cite> find that racist and homophobic tweets are more likely to be classified as hate speech but sexist tweets are generally classified as offensive.",
  "y": "uses"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_2",
  "x": "2) Deep Learning models which learn feature representations on their own. <cite>[10]</cite> released the popular data set of 16k tweets annotated as belonging to sexism, racism or none class 1 , and provided a feature engineered model for detection of abuse in their corpus.",
  "y": "background"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_3",
  "x": "[2] in their work, experiment with multiple deep learning architectures for the task of hate speech detection on Twitter using the same data set by <cite>[10]</cite> .",
  "y": "background"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_4",
  "x": "On the data set released by <cite>[10]</cite> , [5] experiment with a two-step approach of detecting abusive language first and then classifying them into specific types i.e. racist, sexist or none.",
  "y": "background"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_5",
  "x": "Once u i is obtained we calculate the importance of the word as the similarity Data Set Tweets Count <cite>[10]</cite> 15,844 [9] 25,112 [4] 20,362 Table 2 : Data sets and their total tweets count of u i with u c and get a normalized importance weight \u03b1 i through a softmax function.",
  "y": "uses"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_6",
  "x": "At the time of the experiment, the <cite>[10]</cite> data set had a total of 15,844 tweets out of which 1,924 were labelled as belonging to racism, 3,058 as sexism and 10,862 as none.",
  "y": "uses"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_7",
  "x": "We call <cite>[10]</cite> data set as <cite>D1</cite> , [9] data set as D2 and [4] as D3 For tweet tokenization, we use Ekphrasis which is a text processing tool built specially from social platforms such as Twitter.",
  "y": "uses"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_8",
  "x": "The results are averaged over 10-fold cross-validations for <cite>D1</cite> and D3 and 5 fold cross-validations for D2 because [9] reported results using 5 fold CV.",
  "y": "uses"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_9",
  "x": "The first tweet is a tweet from <cite>[10]</cite> , the second tweet is a tweet from from [9] data set and the third from the [4]",
  "y": "uses"
 },
 {
  "id": "737a452057be3e254b35bd8df492be_10",
  "x": "The first tweet is a sexist tweet from <cite>[10]</cite> where as the second tweet is an example of racist tweet from the same datset .",
  "y": "uses"
 },
 {
  "id": "73d4518e44f14a725a28e86de96963_0",
  "x": "Information related to affect has been also exploited (Reyes et al., 2013;<cite> Barbieri et al., 2014</cite>; Hern\u00e1ndez Far\u00edas et al., 2015) .",
  "y": "background"
 },
 {
  "id": "73d4518e44f14a725a28e86de96963_1",
  "x": "In ) the robustness of emotIDM was assessed over different Twitter state-of-the-art corpora for irony detection (Reyes et al., 2013;<cite> Barbieri et al., 2014</cite>; Mohammad et al., 2015; Pt\u00e1\u010dek et al., 2014; Riloff et al., 2013) . The obtained results outperform those in the previous works confirming the significance of affective features for irony detection.",
  "y": "background"
 },
 {
  "id": "73d4518e44f14a725a28e86de96963_2",
  "x": "Furthermore,<cite> Barbieri et al. (2014)</cite> exploited a feature for alerting the existence of an URL in a tweet; such feature was ranked among the most discriminative ones according to an information gain analysis.",
  "y": "background"
 },
 {
  "id": "73d4518e44f14a725a28e86de96963_3",
  "x": "We exploited the corpora developed by (Reyes et al., 2013) , <cite>(Barbieri et al., 2014)</cite> , (Mohammad et al., 2015) , (Pt\u00e1\u010dek et al., 2014) , (Riloff et al., 2013) , (Ghosh et al., 2015) , (Karoui et al., 2017) , and (Sulis et al., 2016) .",
  "y": "uses"
 },
 {
  "id": "73d4518e44f14a725a28e86de96963_4",
  "x": "Distinguishing between different kinds of ironic devices is still a controversial issue. In computational linguistics, only few research works have attempted to address such a difficult task (Wang, 2013;<cite> Barbieri et al., 2014</cite>; Sulis et al., 2016; Van Hee et al., 2016) .",
  "y": "motivation background"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_0",
  "x": "Recently, with the rise of machine learning and especially deep learning techniques, researchers are starting to bring more data-driven approaches to this field<cite> (Sproat and Jaitly, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_1",
  "x": "Constructing such grammars is time consuming and error-prone and requires extensive linguistic knowledge and programming proficiency. Recently, with the rise of machine learning and especially deep learning techniques, researchers are starting to bring more data-driven approaches to this field<cite> (Sproat and Jaitly, 2016)</cite> . In this paper, we present our approach to nonstandard text normalization via machine translation techniques, where the source and target are written and spoken form text, respectively.",
  "y": "motivation"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_2",
  "x": "Recently, methods based on neural networks have been applied to TN and ITN<cite> (Sproat and Jaitly, 2016</cite>; Pusateri et al., 2017; Yolchuyeva et al., 2018) .",
  "y": "background"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_3",
  "x": "Recently, methods based on neural networks have been applied to TN and ITN<cite> (Sproat and Jaitly, 2016</cite>; Pusateri et al., 2017; Yolchuyeva et al., 2018) . To overcome one of the biggest problems -a lack of supervision, WFSTs have been used to transform large amounts of written-form text to its spoken form. Researchers hope a vast amount of such data can counteract the errors inherited in WFST-based models.",
  "y": "motivation"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_4",
  "x": "Recent data-driven approaches examine window-based sequence-to-sequence (seq2seq) models and convolutional neural networks (CNN) to normalize a central piece of text with the help of context<cite> (Sproat and Jaitly, 2016</cite>; Yolchuyeva et al., 2018) .",
  "y": "background"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_5",
  "x": "Following <cite>Sproat and Jaitly (2016)</cite>, we implement a seq2seq model trained on window-based data.",
  "y": "uses"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_6",
  "x": "A window center might contain 1 or more words (e.g., \"8 AM\") and the grouping is provided by the dataset where each input sentence is segmented into chunks corresponding to labels such as TIME, DATE, ORDINAL<cite> (Sproat and Jaitly, 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_7",
  "x": "The data for the window-based seq2seq model and full sentence seq2seq were generated from the publicly available release of parallel written/speech formatted text from <cite>Sproat and Jaitly (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_8",
  "x": "Our datasets were randomly sampled from a set of 4.9M sentences in the training data portion of the <cite>Sproat and Jaitly (2016)</cite> data release and split into training, validation, and test data.",
  "y": "uses"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_9",
  "x": "We follow <cite>Sproat and Jaitly (2016)</cite> in down-sampling window-based training data to constrain the proportion of \"<self>\" tokens to 10% of the data.",
  "y": "uses"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_10",
  "x": "Our first approach replicates the window-based seq2seq model of <cite>Sproat and Jaitly (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_11",
  "x": "As shown in Figure 2 , our replicated windowbased model achieves reasonable performance compared with <cite>Sproat and Jaitly (2016)</cite> , considering our training set is much smaller.",
  "y": "similarities differences"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_12",
  "x": "Data with TELEPHONE labels were not included in the initial analysis of <cite>Sproat and Jaitly (2016)</cite> , but were made available in the dataset release.",
  "y": "differences"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_13",
  "x": "* TELEPHONE is not reported in <cite>Sproat and Jaitly (2016)</cite> but included in the dataset; ** we removed ELECTRONIC category.",
  "y": "extends differences"
 },
 {
  "id": "73d7831596bfe6d6861f360042048f_14",
  "x": "Our labels are generated directly from the Google FST<cite> (Sproat and Jaitly, 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_0",
  "x": "For instance, both Lample et al. (2016) and <cite>Ma and Hovy (2016)</cite> propose end-to-end models for sequence labelling task and achieve state-of-the-art results.",
  "y": "background"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_1",
  "x": "Of particular interest to this paper is the work by <cite>Ma and Hovy (2016)</cite> introduce a strong end-to-end model combining a bi-directional Long Short-Term Memory (Bi-LSTM) network with Convolutional Neural Network (CNN) character encoding in a Conditional Random Field (CRF).",
  "y": "background"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_2",
  "x": "We build on a highly competitive sequence labelling model, namely Bi-LSTM-CNN-CRF, first introduced by <cite>Ma and Hovy (2016)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_3",
  "x": "Zadrozny, 2014; Chiu and Nichols, 2016;<cite> Ma and Hovy, 2016)</cite> have demonstrated that CNNs are highly capable of capturing character-level features.",
  "y": "background motivation"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_4",
  "x": "Here, our character-level CNN is similar to that used in <cite>Ma and Hovy (2016)</cite> but differs in that we use a ReLU activation (Nair and Hinton, 2010) .",
  "y": "extends differences"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_5",
  "x": "We use the IOBES tagging scheme, as previous study have shown that this scheme provides a modest improvement to the model performance (Ratinov and Roth, 2009; Chiu and Nichols, 2016; Lample et al., 2016;<cite> Ma and Hovy, 2016)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_6",
  "x": "Following the work of <cite>Ma and Hovy (2016)</cite> , we initialise word embeddings with GloVe (Pennington et al., 2014 ) (300-dimensional, trained on a 6B-token corpus).",
  "y": "similarities"
 },
 {
  "id": "73eaa7d5a54b2d60bd8128e0270683_7",
  "x": "In addition to reporting a number of prior results of competitive baseline models, as listed in Table 2 , we also re-implement the Bi-LSTM-CNN-CRF model by <cite>Ma and Hovy (2016)</cite> (referred to as Neural-CRF in Table 2 ) and report its average performance.",
  "y": "similarities uses"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_0",
  "x": "When applying VAEs for text modelling, recurrent neural networks (RNNs) 1 are commonly used as the architecture for both encoder and decoder (Bowman et al., 2016; <cite>Xu and Durrett, 2018</cite>; Dieng et al., 2019) . While such a VAE-RNN based architecture allows encoding and generating sentences (in the decoding phase) with variablelength effectively, it is also vulnerable to an issue known as latent variable collapse (or KL loss vanishing) , where the posterior collapses to the prior and the model will ignore the latent codes in generative tasks.",
  "y": "background"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_1",
  "x": "<cite>Xu and Durrett (2018)</cite> addressed the problem by replacing the standard normal distribution for the prior with the von Mises-Fisher (vMF) distribution.",
  "y": "background"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_2",
  "x": "Although the aforementioned works show effectiveness in addressing the latent variable collapse issue to some extent, they either require carefully engineering to balance the weight between the reconstruction loss and KL loss (Bowman et al., 2016; , or resort to designing more sophisticated model structures (Yang et al., 2017; <cite>Xu and Durrett, 2018</cite>; Dieng et al., 2019) . In this paper, we present a simple architecture called holistic regularisation VAE (HR-VAE), which can effectively avoid latent variable collapse.",
  "y": "motivation background"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_3",
  "x": "We evaluate our model against several strong baselines which apply VAE for text modelling (Bowman et al., 2016; Yang et al., 2017; <cite>Xu and Durrett, 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_4",
  "x": "Our model design is motivated by one noticeable defect shared by the VAE-RNN based models in previous works (Bowman et al., 2016; Yang et al., 2017; <cite>Xu and Durrett, 2018</cite>; Dieng et al., 2019) .",
  "y": "motivation"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_5",
  "x": "We evaluate our model on two public datasets, namely, Penn Treebank (PTB) (Marcus and Marcinkiewicz, 1993) and the end-to-end (E2E) text generation corpus (Novikova et al., 2017) , which have been used in a number of previous works for text generation (Bowman et al., 2016; <cite>Xu and Durrett, 2018</cite>; Wiseman et al., 2018; Su et al., 2018) .",
  "y": "uses"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_6",
  "x": "For the PTB dataset, we used the train-test split following (Bowman et al., 2016; <cite>Xu and Durrett, 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "740db031e3fc086dfdb2477caeac66_7",
  "x": "We compare our HR-VAE model with three strong baselines using VAE for text modelling: VAE-LSTM-base 3 : A variational autoencoder model which uses LSTM for both encoder and decoder. KL annealing is used to tackled the latent variable collapse issue (Bowman et al., 2016) ; VAE-CNN 4 : A variational autoencoder model with a LSTM encoder and a dilated CNN decoder (Yang et al., 2017) ; vMF-VAE 5 : A variational autoencoder model using LSTM for both encoder and decoder where the prior distribution is the von Mises-Fisher (vMF) distribution rather than a Gaussian distribution (<cite>Xu and Durrett, 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "74420437db295ca874d5c946891f69_0",
  "x": "<cite>Tsvetkov and Wintner (2014)</cite> proposed a Bayesian network model that combines linguistically motivated features and also models their interactions.",
  "y": "background"
 },
 {
  "id": "74420437db295ca874d5c946891f69_1",
  "x": "<cite>Tsvetkov and Wintner (2014)</cite> proposed a Bayesian network model that combines linguistically motivated features and also models their interactions. In this paper, we extend their model with new features and apply it to Croatian, a morphologically complex and a relatively free word order language, achieving a satisfactory performance of 0.823 F1-score.",
  "y": "extends"
 },
 {
  "id": "74420437db295ca874d5c946891f69_2",
  "x": "Recently, <cite>Tsvetkov and Wintner (2014)</cite> proposed an approach for the detection of MWE candidates that combines a number of statistical and linguistic features.",
  "y": "background"
 },
 {
  "id": "74420437db295ca874d5c946891f69_3",
  "x": "The starting point of our work is the model of <cite>Tsvetkov and Wintner (2014)</cite> , which we extend with a number of features, including language-specific ones that account for the relatively free word order.",
  "y": "extends"
 },
 {
  "id": "74420437db295ca874d5c946891f69_4",
  "x": "<cite>Tsvetkov and Wintner (2014)</cite> showed that a manually-designed BN substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity.",
  "y": "background"
 },
 {
  "id": "74420437db295ca874d5c946891f69_5",
  "x": "<cite>Tsvetkov and Wintner (2014)</cite> showed that a manually-designed BN substantially outperforms the one whose structure is learned automatically, hypothesizing that the cause for this might be the increased model complexity. We conduct a similar experiment using a structurelearning algorithm, but also model the interactions using a simpler, semi-naive Bayes classifier, for which the number of parameters is restricted.",
  "y": "similarities"
 },
 {
  "id": "74420437db295ca874d5c946891f69_6",
  "x": "Unlike <cite>Tsvetkov and Wintner (2014)</cite> , who only consider bigrams, we consider MWEs of up to five words in length.",
  "y": "differences"
 },
 {
  "id": "74420437db295ca874d5c946891f69_7",
  "x": "We adopt the BN model of <cite>Tsvetkov and Wintner (2014)</cite> , but extend it with language-specific as well as semantically motivated features.",
  "y": "extends"
 },
 {
  "id": "74420437db295ca874d5c946891f69_8",
  "x": "The model of <cite>Tsvetkov and Wintner (2014)</cite> uses nine statistically and linguistically motivated features, computed for each MWE candidate and designed to discriminate between MWEs and ordinary word sequences.",
  "y": "background"
 },
 {
  "id": "74420437db295ca874d5c946891f69_9",
  "x": "The model of <cite>Tsvetkov and Wintner (2014)</cite> uses nine statistically and linguistically motivated features, computed for each MWE candidate and designed to discriminate between MWEs and ordinary word sequences. We adopted eight of these features: 1 (1) capitalization (indicating which MWE constituents are capitalized), (2) hyphenation (which constituents are hyphenated), (3) fossil word (whether constituents also occur outside of the MWE), (4) frozen form (whether the MWE is morphologically frozen), (5) partial morphological inflection (whether MWE admits only limited inflection), (6) syntactic pattern (the MWE's part-of-speech pattern), (7) semantic context, and (8) association measure.",
  "y": "uses"
 },
 {
  "id": "74420437db295ca874d5c946891f69_10",
  "x": "We adopted the Bayesian network model of <cite>Tsvetkov and Wintner (2014)</cite> and extended it with new features and manually-designed feature interactions, inspired by an analysis of Croatian MWEs.",
  "y": "extends"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_0",
  "x": "There have been essentially two approaches to topic segmentation in the past. The first of these, lexical cohesion, may be used for either linear segmentation (Morris and Hirst, 1991; <cite>Hearst, 1997)</cite> or hierarchical segmentation (Yarri, 1997; Choi, 2000) .",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_1",
  "x": "In this study we apply the methods of Foltz et al. (1998) , Hearst (1994<cite> Hearst ( , 1997</cite> , and a new technique utilizing an orthonormal basis to topic segmentation of tutorial dialogue.",
  "y": "uses"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_2",
  "x": "Both Hearst (1994<cite> Hearst ( , 1997</cite> and Foltz et al. (1998) use vector space methods discussed below to represent and compare units of text.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_3",
  "x": "However, Hearst (1994<cite> Hearst ( , 1997</cite> and Foltz et al. (1998) differ on how text units are defined and on how to interpret the results of a comparison.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_4",
  "x": "The text unit's definition in Hearst (1994<cite> Hearst ( , 1997</cite> and Foltz et al. (1998) is generally task dependent, depending on what size gives the best results.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_5",
  "x": "Using LSA and this criterion, Foltz et al. (1998) detected chapter boundaries with an F-measure of .33 (see Manning and Sch\u00fctze (1999) for a definition of Fmeasure). Hearst (1994<cite> Hearst ( , 1997</cite> in contrast uses a relative comparison of cohesion, by recasting vector comparisons as depth scores.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_6",
  "x": "Hearst (1994<cite> Hearst ( , 1997</cite> in contrast uses a relative comparison of cohesion, by recasting vector comparisons as depth scores.",
  "y": "differences background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_7",
  "x": "Using a vector space method without singular value decomposition,<cite> Hearst (1997)</cite> reports an F-measure of .70 when detecting topic shifts between paragraphs.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_8",
  "x": "Thus previous work suggests that<cite> the Hearst (1997)</cite> method is superior to that of Foltz et al. (1998) , having roughly twice the accuracy indicated by F-measure.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_9",
  "x": "To replicate Foltz et al. (1998) , software was written in Java that created a moving window of varying sizes on the input text, and the software retrieved the LSA vector and calculated the cosine of each window. Hearst (1994<cite> Hearst ( , 1997</cite> was replicated using the JTextTile (Choi, 1999 ) Java software. A variant of Hearst (1994<cite> Hearst ( , 1997</cite> was created by using LSA instead of the standard vector space method.",
  "y": "uses"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_10",
  "x": "Using the development corpus's average topic length of 16 utterances as a reference point, F-measures were calculated for the combinations of window size and text unit size in Table 1 . On the test set, this combination of parameters yielded an F-measure of .14 as opposed to the Fmeasure for monologue reported by<cite> Hearst (1997)</cite> , .70.",
  "y": "differences"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_11",
  "x": "Recall that in monologue,<cite> Hearst (1997)</cite> reports a much larger F-measure than Foltz et al. (1998) , .70 vs. .33, albeit on different data sets.",
  "y": "background"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_12",
  "x": "Recall that in monologue,<cite> Hearst (1997)</cite> reports a much larger F-measure than Foltz et al. (1998) , .70 vs. .33, albeit on different data sets. In the present dialogue corpus, these roles are reversed, .14 vs. .52.",
  "y": "differences"
 },
 {
  "id": "74568758fe5fef3727d94e7597f305_13",
  "x": "It may be that Hearst (1994<cite> Hearst ( , 1997</cite> )'s segmentation criterion, i.e. depth scores, do not translate well to dialogue.",
  "y": "background"
 },
 {
  "id": "74e7b114ae968e196ea87f529f5eff_0",
  "x": "Cohyponymy (or coordination), on the other hand, is the relation held by words sharing a close hypernym, which are therefore attributionally similar <cite>(Weeds et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "74e7b114ae968e196ea87f529f5eff_1",
  "x": "The ability of discriminating hypernymy, co-hyponymy and random words has potentially infinite applications, including automatic thesauri creation, paraphrasing, textual entailment, sentiment analysis and so on <cite>(Weeds et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "74e7b114ae968e196ea87f529f5eff_2",
  "x": "For this reason, in the last decades, numerous methods, datasets and shared tasks have been proposed to improve computers' ability in such discrimination, generally achieving promising results <cite>(Weeds et al., 2014</cite>; Rimmel, 2014; Geffet and Dagan, 2005) .",
  "y": "background"
 },
 {
  "id": "74e7b114ae968e196ea87f529f5eff_3",
  "x": "Both supervised and unsupervised approaches have been investigated. The former have been shown to outperform the latter in <cite>Weeds et al. (2014)</cite> , even though Levy et al. (2015) have recently claimed that these methods may learn whether a term y is a prototypical hypernym, regardless of its actual relation with a term x.",
  "y": "background"
 },
 {
  "id": "74e7b114ae968e196ea87f529f5eff_4",
  "x": "In our evaluation, carried out using the 10-fold cross validation on 9,600 pairs, we achieved an accuracy of 88.3% when the three classes are present, and of 92.3% and 97.3% when only two classes are present. Such results are competitive with the state-of-the-art <cite>(Weeds et al., 2014)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "74e7b114ae968e196ea87f529f5eff_5",
  "x": "Our classifier is competitive with the state-of-the-art <cite>(Weeds et al., 2014)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "7516b533aafa8b41e7e554fa54e39c_0",
  "x": "Transformer models have come to dominate a wide variety of leader-boards in the NLU field; in the area of MRC, the current state-of-the-art model on the DREAM dataset (see<cite> [Sun et al., 2019]</cite> ) fine tunes Albert, a large pretrained Transformer-based model, and additionally combines it with an extra layer of multi-head attention between context and question-answer [Zhu et al., 2020] .",
  "y": "background"
 },
 {
  "id": "7516b533aafa8b41e7e554fa54e39c_1",
  "x": "In this note we will focus on the multi-choice MRC tasks, more specifically, the DREAM task <cite>[Sun et al., 2019</cite> ].",
  "y": "uses"
 },
 {
  "id": "7516b533aafa8b41e7e554fa54e39c_2",
  "x": "DREAM<cite> [Sun et al., 2019]</cite> is a much smaller reading comprehension dataset with more than 6,000 dialogues and over 10,000 questions.",
  "y": "background"
 },
 {
  "id": "7516b533aafa8b41e7e554fa54e39c_3",
  "x": "Early works on the DREAM task include feature-based GBDT<cite> [Sun et al., 2019]</cite> , and FTLM [Radford et al., 2018] which is based on the Transformer [Vaswani et al., 2017] architecture.",
  "y": "background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_0",
  "x": "Following <cite>Klementiev et al. (2012)</cite> we split our objective into two sub-objectives, a bilingual objective minimizing the transfer errors and a monolingual objective minimizing the monolingual errors for l 1 and l 2 .",
  "y": "uses"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_1",
  "x": "Crosslingual representations are induced to represent words, phrases, or documents for more than one language, where the representations are constrained to preserve representational similarity or can be transformed between languages<cite> (Klementiev et al., 2012</cite>; Hermann & Blunsom, 2014) . In particular, crosslingual representations can be helpful for tasks such as translation or to leverage training data in a source language when little or no training data is available for a target language.",
  "y": "background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_2",
  "x": "Examples of such transfer learning tasks are crosslingual sentiment analysis (Wan, 2009) and crosslingual document classification<cite> (Klementiev et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_3",
  "x": "<cite>Klementiev et al. (2012)</cite> used automatically aligned sentences and words to constrain word representations across languages based on the number of times a given word in one language was aligned to a word in another language. They also introduced a dataset for crosslingual document classification and evaluated their work on this task.",
  "y": "background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_4",
  "x": "However, these previous methods all suffer from one or more of three short-comings. <cite>Klementiev et al. (2012)</cite> ; ; Gouws et al. (2014) all learn their representations using a word-level monolingual objective. This effectively means that compositionality is not encouraged by the monolingual objective, which may be problematic when composing word representations for a phrase or document-level task.",
  "y": "motivation"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_5",
  "x": "Following the work of <cite>Klementiev et al. (2012)</cite> ; Hermann & Blunsom (2014) ; Gouws et al. (2014) we represent each word as a vector and use separate word representations for each language.",
  "y": "similarities"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_6",
  "x": "<cite>Klementiev et al. (2012)</cite> use a neural language model to leverage monolingual data. However, this does not explicitly encourage compositionality of the word representations.",
  "y": "background motivation"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_7",
  "x": "Gouws et al. (2014) introduced BilBOWA combining a bilingual objective with the Skip-Gram model proposed by which predicts the context of a word given the word itself. They achieve high accuracy on the German \u2192 English sub-task of the crosslingual document classification task introduced by <cite>Klementiev et al. (2012)</cite> .",
  "y": "background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_8",
  "x": "Like previous work, we evaluate our method on the crosslingual document classification task introduced by <cite>Klementiev et al. (2012)</cite> . The goal is to correctly classify news articles taken from the English and German sections of the RCV1 and RCV2 corpus (Lewis et al., 2004) into one of four (Collins, 2002) for 10 iterations on representations of documents in one language (English/German) and evaluate its performance on representations of documents in the corresponding other language (German/English).",
  "y": "uses background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_9",
  "x": "We use the original data and the original implementation of the averaged perceptron used by <cite>Klementiev et al. (2012)</cite> to evaluate the document representations created by our method. There are different versions of the training set of varying sizes, ranging from 100 to 10,000 documents, and the test sets for both languages contain 5,000 documents. Most related work only reports results using the 1,000 documents sized training set. Following previous work, we tune the hyperparameters of our model on held out documents in the same language that the model was trained on.",
  "y": "uses"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_10",
  "x": "Like <cite>Klementiev et al. (2012)</cite> we choose EuroParl v7 (Koehn, 2005) as our bilingual corpus and leverage the English and German parts of the RCV1 and RCV2 corpora as monolingual resources. To avoid a testing bias, we exclude all documents that are part of the crosslingual classification task.",
  "y": "similarities uses"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_11",
  "x": "The result table includes previous work as well as the Glossed, the machine translation and the majority class baselines from <cite>Klementiev et al. (2012)</cite> . Our method achieves results that are comparable or improve upon the previous state of the art for all dataset configurations.",
  "y": "background"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_12",
  "x": "To show that our method achieves high accuracy even with a reduced vocabulary, we discard representations for infrequent terms and report results using our best setup with the same vocabulary size as <cite>Klementiev et al. (2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "754ceac25ff3a711ec3737e7eb860b_13",
  "x": "Depending on the amount of training data available the accuracy achieved with our models is comparable or greatly improves upon previously reported results for the crosslingual document classification task introduced by <cite>Klementiev et al. (2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_0",
  "x": "It has been widely used in the context of dialog policy learning (Fatemi et al., 2016; Dhingra et al., 2017;<cite> Casanueva et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_1",
  "x": "However according to a recent comparison<cite> (Casanueva et al., 2017)</cite> in the context of dialog policy learning, it performed worse than other RL methods such as Gaussian Process in many testing conditions.",
  "y": "background"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_4",
  "x": "<cite>Casanueva et al. (2017)</cite> propose six different environmental models, varying in user friendliness, simulated input channel noise and the presence or absence of action masks, which, when enabled, simplify learning by masking some of the possible actions.",
  "y": "background"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_5",
  "x": "Evaluation results in <cite>Casanueva et al. (2017)</cite> with several dialog policy types, e.g. a handcrafted policy and the best reported policies serve as baselines in our experiments.",
  "y": "uses"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_6",
  "x": "Training and evaluation with the PyDial user simulator follows the PyDial benchmarking tasks<cite> (Casanueva et al., 2017)</cite> , where each task (see Table 1) is trained on 10000 dialogs split into ten training iterations of 1000 dialogs each.",
  "y": "uses"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_7",
  "x": "The first row of Table 3 and 4 show the results of the highest scoring policy from the PyDial benchmark<cite> (Casanueva et al., 2017)</cite> to serve as baselines.",
  "y": "uses"
 },
 {
  "id": "759c1c892361f62ad8f2c46e569e8a_8",
  "x": "Following the PyDial benchmarking process, we leave all hyperparameters constant across all environments and dialog domains<cite> (Casanueva et al., 2017)</cite> , thus also evaluating the generalization capabilities of the agents.",
  "y": "uses"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_0",
  "x": "We motivate the need to build NLP-QT as a resource in its own right, by comparing the Penn Treebank-style annotation scheme used for QuestionBank (Judge et al., 2006) with the modified NP annotation for the Penn Treebank introduced by <cite>Vadas and Curran (2007)</cite> .",
  "y": "motivation"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_1",
  "x": "Rather, we will follow a more hierarchical annotation style for NPs that has been proposed by <cite>Vadas and Curran (2007)</cite> and that provides an easier interface for semantic interpretation.",
  "y": "uses similarities"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_2",
  "x": "Section 3 will introduce the <cite>Vadas and Curran (2007)</cite> annotation style and will motivate why it is appropriate for the QA system envisaged here.",
  "y": "similarities"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_3",
  "x": "It is precisely this type of shortcoming that led <cite>Vadas and Curran (2007)</cite> to revise the Penn Treebank annotation style for NPs along the following lines:",
  "y": "background"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_4",
  "x": "From the point of view of semantic interpretation, the more contoured <cite>Vadas and Curran (2007)</cite> annotation style is to be preferred since it reflects the type of answer that is required, namely materials for second language acquisition, but not for example acquisition materials for second language, or the second (batch) of language acquisition materials.",
  "y": "background"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_5",
  "x": "It is precisely for this reason that we adopt the annotation style of <cite>Vadas and Curran (2007)</cite> for the NLP Resource Metadata Questions Treebank (henceforth abbreviated as NLP-QT).",
  "y": "similarities uses"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_6",
  "x": "This section summarizes the set of experiments that we have conducted with the <cite>Vadas and Curran (2007)</cite> annotation style for NPs and in particular with the NLP-QT data set.",
  "y": "similarities"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_7",
  "x": "Using Bikel (2004)'s parser, <cite>Vadas and Curran (2007)</cite> report that the parsing results slightly decrease when the parser is trained on the Penn Treebank with the modified annotation style for NPs.",
  "y": "background"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_8",
  "x": "The decrease in performance caused by adding the QuestionBank training data together with the modified NP annotation on section 23 is comparable to the one caused by adding the modified NP annotation alone (a decrease from 90.263 to 90.04, whereas for the original Penn Treebank data the F-score decreased from 90.43 to 89.96), but this slight decrease is more than offset by the increase in semantic information obtained from the <cite>Vadas and Curran (2007)</cite> annotation for complex base NPs.",
  "y": "differences"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_9",
  "x": "As in the experiments shown in the previous subsection, the performance with a model trained purely on Penn Treebank data (with NPs annotated in the <cite>Vadas and Curran (2007)</cite> style) serves as a baseline (the model is called np-wsj in the table).",
  "y": "similarities"
 },
 {
  "id": "7616f6f8c1c188b32cd3a8374b61dd_10",
  "x": "We have motivated the need to build NLP-QT as a resource in its own right by comparing the Penn Treebank-style annotation scheme used for QuestionBank with the modified NP annotation for the Penn Treebank introduced by <cite>Vadas and Curran (2007)</cite> .",
  "y": "motivation"
 },
 {
  "id": "7666d5a8e05e79f68ec60e47cddecd_0",
  "x": "Paraphrase templates containing concepts and typical strings were induced from comparable sentences in <cite>(Barzilay and Lee, 2003)</cite> using multisentence alignment to discover \"variable\" and fixed structures.",
  "y": "background"
 },
 {
  "id": "7666d5a8e05e79f68ec60e47cddecd_1",
  "x": "Our algorithm has a reasonable computational complexity, unlike alignment-based or clustering-based approaches <cite>(Barzilay and Lee, 2003)</cite> , which are computationally expensive.",
  "y": "differences"
 },
 {
  "id": "76fd2709a325366be6154d2a84b29b_0",
  "x": "Previous work addressing the problem can be roughly classified into three categories: (1) learning word embeddings from large collections of text using variants of neural networks (Mikolov et al. (2013a) ; Mikolov et al. (2013b) ; Mikolov et al. (2013c) ;<cite> Levy and Goldberg (2014)</cite> ) or global matrix factorization (Deerwester et al. (1990) ; Turney (2012) ); (2) extracting knowledge from existing semantic networks, such as WordNet (Yang and Powers (2005) ; Alvarez and Lim (2007) ; Hughes and Ramage (2007) ) and ConceptNet (Boteanu and Chernova (2015) ); (3) combining the above two models by various ways (Agirre et al. (2009) ; Zhila et al. (2013) ; Iacobacci et al. (2015) ; Summers-Stay et al. (2016) ).",
  "y": "background"
 },
 {
  "id": "76fd2709a325366be6154d2a84b29b_1",
  "x": "The original skip-gram embeddings can yield broad topical similarities, while the dependency-based word embeddings can capture more functional similarities <cite>(Levy et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "770368eff3410f3c2ab18b14b42243_0",
  "x": "The first are generative models, which are usually trained with cross-entropy to generate responses word-by-word conditioned on a dialogue context [Ritter et al., 2011 , Vinyals and Le, 2015 , Sordoni et al., 2015 , Shang et al., 2015<cite> , Li et al., 2016a</cite> , Serban et al., 2016b .",
  "y": "background"
 },
 {
  "id": "770368eff3410f3c2ab18b14b42243_1",
  "x": "One weakness of current generative models is their limited ability to incorporate rich dialogue context and to generate meaningful and diverse responses [Serban et al., 2016b<cite> , Li et al., 2016a</cite> .",
  "y": "motivation"
 },
 {
  "id": "770368eff3410f3c2ab18b14b42243_2",
  "x": "This task has been studied extensively in the recent literature [Ritter et al., 2011 , Sordoni et al., 2015<cite> , Li et al., 2016a</cite> .",
  "y": "background"
 },
 {
  "id": "770368eff3410f3c2ab18b14b42243_3",
  "x": "<cite>Li et al. [2016a]</cite> propose ranking candidate responses according to a mutual information criterion, in order to incorporate dialogue context efficiently and retrieve on-topic responses.",
  "y": "background"
 },
 {
  "id": "772cdd4263cf8979a54cc5196e5853_0",
  "x": "Both phrase-structure and dependency parsers have developed a lot in the last decade (Nivre et al., 2004; McDonald et al., 2005; Charniak and Johnson, 2005; <cite>Huang, 2008)</cite> . Different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used (and a growing gap between researcher communities). In this work, we exploit this divergence and show the added value of features extracted from automatic dependency parses of sentences for a discriminative phrase-structure parser.",
  "y": "motivation background"
 },
 {
  "id": "772cdd4263cf8979a54cc5196e5853_1",
  "x": "The most successful supervised phrase-structure parsers are feature-rich discriminative parsers which heavily depend on an underlying PCFG (Charniak and Johnson, 2005; <cite>Huang, 2008)</cite> . These approaches consists of two stages. At the first stage they apply a PCFG to extract possible parses. The full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence. The n-best list parsers keep just the 50-100 best parses according to the PCFG. Other methods remove nodes and hyperedges whose posterior probability is under a predefined threshold from the forest (chart). The task of the second stage is to select the best parse from the set of possible parses (i.e. rerank this set).",
  "y": "background"
 },
 {
  "id": "772cdd4263cf8979a54cc5196e5853_2",
  "x": "Our oracle extraction method is an extension of<cite> Huang (2008)</cite>'s dynamic programing procedure which takes into consideration POS tag and grammatical function matches as well and selects hyperedges with higher posterior probability for tie-breaking.",
  "y": "extends"
 },
 {
  "id": "772cdd4263cf8979a54cc5196e5853_3",
  "x": "For a detailed description of the training and supporting algorithms please refer to Charniak and Johnson (2005) and<cite> Huang (2008)</cite> .",
  "y": "background"
 },
 {
  "id": "772cdd4263cf8979a54cc5196e5853_4",
  "x": "Regarding the two discriminative approaches, our findings are similar to<cite> Huang (2008)</cite> , i.e. the packed forest-based and n-best list procedures achieved similar results by using only local features.",
  "y": "similarities"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_0",
  "x": "Recent work has shown that we can learn better visually grounded representations of sentences by training image-sentence ranking models on multiple languages (Gella et al., 2017; <cite>K\u00e1d\u00e1r et al., 2018)</cite> . This line of research has focused on training models on datasets where the same images are annotated with sentences in multiple languages. In this paper, we consider the problem of training an image-sentence ranking model using imagecaption collections in different languages with nonoverlapping images drawn from different sources.",
  "y": "motivation background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_1",
  "x": [
   "K\u00e1d\u00e1r et al. (2018) claim that a multilingual image-sentence ranking model trained on disjoint datasets performs on-par with a model trained on aligned data. However, the disjoint datasets in their paper are artificial because they were formed by randomly splitting the Multi30K dataset into two halves."
  ],
  "y": "motivation background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_2",
  "x": "We adopt the model architecture and training procedure of<cite> K\u00e1d\u00e1r et al. (2018)</cite> for the task of matching images with sentences. This task is defined as learning to rank the sentences associated with an image higher than other sentences in the data set, and vice-versa (Hodosh et al., 2013) . The model is comprised of a recurrent neural network language model and a convolutional neural network image encoder. The parameters of the language encoder are randomly initialized, while the image encoder is pre-trained, frozen during training and followed by a linear layer which is tuned for the task. The model is trained to make true pairs < a, b > similar to each other, and contrastive pairs <\u00e2, b > and < a,b > dissimilar from each other in a joint embedding space by minimizing the max-violation loss function (Faghri et al., 2017) :",
  "y": "uses background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_3",
  "x": "In our experiments, the < a, b > pairs are either image-caption pairs < i, c > or caption-caption pairs < c a , c b > (following Gella et al. (2017) ;<cite> K\u00e1d\u00e1r et al. (2018)</cite> ).",
  "y": "background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_4",
  "x": "For the caption-caption objective, we follow<cite> K\u00e1d\u00e1r et al. (2018)</cite> and generate a sentence pair data set by taking all pairs of sentences that belong to the same image and are written in different languages: 5 English and 5 German captions result in 25 English-German pairs. The sentences are encoded and we perform an update of the model parameters using the same loss. When training with both the image-caption and caption-caption (c2c) ranking tasks, we randomly select the task to perform with probability p=0.5.",
  "y": "uses"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_5",
  "x": "Our implementation, training protocol and parameter settings are based on the existing codebase of<cite> K\u00e1d\u00e1r et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_6",
  "x": "These results reproduce the findings of<cite> K\u00e1d\u00e1r et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_7",
  "x": "We find that a model trained in the aligned setting (De+En) is better than a model trained in the disjoint setting (De+COCO), as shown in Table  2 . This finding contradicts the conclusion of<cite> K\u00e1d\u00e1r et al. (2018)</cite> , who claimed that the aligned and disjoint conditions lead to comparable performance. This is most likely because the disjoint setting in<cite> K\u00e1d\u00e1r et al. (2018)</cite> is artificial, in the sense that they used different 50% subsets of M30K. In our experiments the disjoint image-caption sets are real, in the sense that we trained the models on the two different datasets.",
  "y": "background differences"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_8",
  "x": "Summary First we reproduced the findings of<cite> K\u00e1d\u00e1r et al. (2018)</cite> showing that bilingual joint training improves over monolingual and using c2c loss further improves performance.",
  "y": "differences background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_9",
  "x": "More recently, there has been a focus on solving this task using multilingual data (Gella et al., 2017; <cite>K\u00e1d\u00e1r et al., 2018)</cite> in the Multi30K dataset ; an extension of the popular Flickr30K dataset into German, French, and Czech. These works take a multi-view learning perspective in which images and their descriptions in multiple languages are different views of the same concepts. The assumption is that common representations of multiple languages and perceptual stimuli can potentially exploit complementary information between views to learn better representations.",
  "y": "background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_10",
  "x": "Their results were improved by the approach presented in<cite> K\u00e1d\u00e1r et al. (2018)</cite> , who has also shown that the multilingual models outperform bilingual models, and that image-caption retrieval performance in languages with less resources can be improved with data from higher-resource languages.",
  "y": "background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_11",
  "x": "We largely follow<cite> K\u00e1d\u00e1r et al. (2018)</cite> , however, our main interest lies in learning multimodal and bilingual representations in the scenario where the images do not come from the same data set i.e.: the data is presented is two sets of image-caption tuples rather than image-caption-caption triples. Taking a broader perspective, images have been used as pivots in multilingual multimodal language processing. On the word level this intuition is applied to visually grounded bilingual lexicon induction, which aims to learn cross-lingual word representations without aligned text using images as pivots (Bergsma and Van Durme, 2011; Kiela et al., 2015; Vuli\u0107 et al., 2016; Hartmann and S\u00f8gaard, 2017; Hewitt et al., 2018) . Images have been used as pivots to learn translation models only from image-caption data sets, without parallel text (Hitschler et al., 2016; Nakayama and Nishida, 2017; Lee et al., 2017; Chen et al., 2018) .",
  "y": "differences background"
 },
 {
  "id": "7895613ddd09696bbee4143c4359b0_12",
  "x": "Previous work has demonstrated improved imagesentence ranking performance when training models jointly on multiple languages (Gella et al., 2017; <cite>K\u00e1d\u00e1r et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "78a7ca27c5ca032116db12205af939_0",
  "x": "They introduce a novel Text-Image Embedding network (TieNet), which integrates self-attention LSTM using tex- tual report data and visual attention CNN using image data. TieNet is capable of extracting an informative embedding to represent the paired medical image and report, which significantly improves the disease classification performance compared to <cite>[16]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "78a7ca27c5ca032116db12205af939_1",
  "x": "Our contributions are in four-fold: (1) we describe an integrated image interpretation framework for disease annotation and medical report generation, (2) we transfer knowledge from large image data sets (ChestX-ray8 <cite>[16]</cite> and ImageNet) to enhance medical image interpretation using a small number of reports for training (IU X-ray [2] ), (3) we evaluate suitability of the NLP evaluation metrics for medical report generation, and (4) we demonstrate the functionality of localizing the key finding in an X-ray with a heatmap.",
  "y": "uses background"
 },
 {
  "id": "78a7ca27c5ca032116db12205af939_2",
  "x": "Similar to <cite>[16]</cite> , we apply a thresholding based bounding box (B-Box) generation method. The B-Box bounds pixels whose heatmap intensity is above 90% of the maximum intensity. The resulting region of interest is then cropped for next level modeling. Fig. 2b illustrates the process of report generation. If there is no active thoracic disease found in an X-ray, a report will be directly generated by an attentive LSTM based on the original X-ray as shown in the green dashed box. Otherwise (as shown in the red dashed box), the cropped subimage with localized disease from the classification module (Fig. 2a) is used to generate description of abnormalities whereas the original X-ray is used to generate description of normalities in the report.",
  "y": "uses"
 },
 {
  "id": "78a7ca27c5ca032116db12205af939_3",
  "x": "We filter out images and reports that are non-relevant to the eight common thoracic diseases included in both ChestX-ray8 <cite>[16]</cite> and IU X-ray datasets [2] , resulting in a dataset with 2225 pairs of X-ray image and report.",
  "y": "uses"
 },
 {
  "id": "7936967a70c44890f3a61f6625c59d_0",
  "x": "Researchers (He et al., 2018) recently studied natural language negotiations in buyer-seller bargaining setup, which is comparatively less restricted than previously studied game environments (Asher et al., 2016;<cite> Lewis et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "7936967a70c44890f3a61f6625c59d_1",
  "x": "Instead of focusing on the previously studied game environments (Asher et al., 2016;<cite> Lewis et al., 2017)</cite> , the dataset considers a more realistic setup: negotiating the price of products listed on Craigslist 1 .",
  "y": "differences"
 },
 {
  "id": "7936967a70c44890f3a61f6625c59d_2",
  "x": "This can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning <cite>(Lewis et al., 2017</cite>; He et al., 2018) .",
  "y": "uses"
 },
 {
  "id": "7936967a70c44890f3a61f6625c59d_3",
  "x": "With the capability to incorporate cues from natural language, such a framework can be used in the future to get negotiation feedback, in order to guide the planning of a negotiating agent. This can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning <cite>(Lewis et al., 2017</cite>; He et al., 2018) .",
  "y": "future_work"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_0",
  "x": "<cite>Tu and Gimpel (2018)</cite> developed an efficient framework for energy-based models by training \"inference networks\" to approximate structured inference instead of using gradient descent. However, <cite>their alternating optimization approach</cite> suffers from instabilities during training, requiring additional loss terms and careful hyperparameter tuning.",
  "y": "motivation"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_1",
  "x": "To stabilize training, <cite>Tu and Gimpel (2018)</cite> experimented with several additional terms in the training objectives, finding performance to be dependent on their inclusion.",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_2",
  "x": "Also, when using the approach of <cite>Tu and Gimpel (2018)</cite> , there is a mismatch between the training and test-time uses of the trained inference network.",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_3",
  "x": "<cite>Tu and Gimpel (2018)</cite> fine-tuned the cost-augmented network to match the test-time criterion, but found only minimal change from this fine-tuning.",
  "y": "motivation background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_4",
  "x": "While SPENs have been used for multiple NLP tasks, including multi-label classification (Belanger and McCallum, 2016) , part-of-speech tagging <cite>(Tu and Gimpel, 2018)</cite> , and semantic role labeling (Belanger et al., 2017) , they are not widely used in NLP.",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_5",
  "x": "<cite>Tu and Gimpel (2018)</cite> propose an alternative that replaces gradient descent with a neural network trained to do inference, i.e., to mimic the function performed in equation (1).",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_6",
  "x": "When training the energy function parameters \u0398, <cite>Tu and Gimpel (2018)</cite> replaced the cost-augmented inference step in the structured hinge loss from Belanger and McCallum (2016) with a costaugmented inference network F \u03a6 and trained the energy function and inference network parameters jointly:",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_7",
  "x": "<cite>Tu and Gimpel (2018)</cite> alternatively optimized \u0398 and \u03a6, which is similar to training in generative adversarial networks (Goodfellow et al., 2014) .",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_8",
  "x": "As alternating optimization can be difficult in practice (Salimans et al., 2016) , <cite>Tu & Gimpel</cite> experimented with including several additional terms in the above objective to stabilize training.",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_9",
  "x": "We adopt the same learning framework as <cite>Tu & Gimpel</cite> of jointly learning the energy function and inference network, but we propose a novel objective function that jointly trains a cost-augmented inference network, a test-time inference network, and the energy function.",
  "y": "extends uses differences similarities"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_10",
  "x": "The energy functions we use for our sequence labeling tasks are taken from <cite>Tu and Gimpel (2018)</cite> and are described in detail in the appendix.",
  "y": "uses"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_11",
  "x": "<cite>Tu and Gimpel (2018)</cite> used the same inference network for solving both problems, which led <cite>them</cite> to fine-tune the network at test-time with a different objective. We avoid this issue by training two inference networks, A \u03a8 for test-time inference and F \u03a6 for cost-augmented inference:",
  "y": "motivation"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_12",
  "x": "We treat this optimization problem as a minmax game and find a saddle point for the game similar to <cite>Tu and Gimpel (2018)</cite> and Goodfellow et al. (2014) .",
  "y": "similarities"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_13",
  "x": "Joint Parameterizations. If we were to train independent inference networks A \u03a8 and F \u03a6 , this new objective could be much slower than the original approach of <cite>(Tu and Gimpel, 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_14",
  "x": "However, <cite>Tu and Gimpel (2018)</cite> found that the trained cost-augmented network was barely affected by fine-tuning for the test-time inference objective.",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_15",
  "x": "<cite>Tu and Gimpel (2018)</cite> used the following objective for the cost-augmented inference network (maximizing it with respect to \u03a6):",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_16",
  "x": "This is likely why <cite>Tu and Gimpel (2018)</cite> found it important to add several stabilization terms to the l 0 objective. We find that by instead removing the truncation, learning stabilizes and becomes less dependent on these additional terms.",
  "y": "differences"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_17",
  "x": "<cite>Tu and Gimpel (2018)</cite> pretrained their tag language model (TLM) on a large, automatically-tagged corpus and fixed its parameters when optimizing \u0398. We instead do not pretrain the TLM and learn its parameters when training \u0398.",
  "y": "differences"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_18",
  "x": "We experiment with three settings for the global energy: GE(a): forward TLM as in <cite>Tu and Gimpel (2018)</cite> ; GE(b): forward and backward TLMs (\u03b3 = 0); GE(c): all four TLMs in Eq. (7).",
  "y": "similarities"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_19",
  "x": "The importance of CE in prior work <cite>(Tu and Gimpel, 2018)</cite> is likely due to the fact that truncation was being used.",
  "y": "background"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_20",
  "x": "The \"marginrescaled\" row uses a SPEN with the local CE term and without zero truncation, where A \u03a8 is obtained by finetuning F \u03a6 as done by <cite>Tu and Gimpel (2018)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_21",
  "x": "Adding the backward (b) and word-augmented TLMs (c) improves over only using the forward TLM from <cite>Tu and Gimpel (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_22",
  "x": "In the relaxed output space Y R (x), y t,j can be interpreted as the probability of the tth position being labeled with label j. We then use the following energy for sequence labeling <cite>(Tu and Gimpel, 2018)</cite> :",
  "y": "uses"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_23",
  "x": "<cite>Tu and Gimpel (2018)</cite> also added a global energy term that they referred to as a \"tag language model\" (TLM). We use h to denote an LSTM TLM that takes a sequence of labels as input and returns a distribution over next labels.",
  "y": "similarities"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_24",
  "x": "For inference networks, we use architectures similar to those used by <cite>(Tu and Gimpel, 2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_25",
  "x": "Like <cite>Tu and Gimpel (2018)</cite> , we use a BiLSTM to compute the input feature vector for each position, using hidden dimension of size 100.",
  "y": "similarities uses"
 },
 {
  "id": "79b3933e51c5fd412d00829815a958_26",
  "x": "<cite>Tu and Gimpel (2018)</cite> use truncation and CE during training.",
  "y": "background"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_0",
  "x": "BLE can be used to address the accuracy problem of SMT, which estimates comparable features for the translation pairs in the translation model <cite>(Klementiev et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_1",
  "x": "BLE can be used to address the accuracy problem of SMT, which estimates comparable features for the translation pairs in the translation model <cite>(Klementiev et al., 2012)</cite> . Our study focuses on addressing the accuracy problem of SMT with BLE.",
  "y": "motivation background"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_2",
  "x": "In this paper, we estimate topical feature in a scalable way following <cite>(Klementiev et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_3",
  "x": "The intuition of temporal similarity is that news stories across languages tend to discuss the same world events on the same day, and the occurrences of a translated phrase pair over time tend to spike on the same dates (Klementiev and Roth, 2006;<cite> Klementiev et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_4",
  "x": "We estimate temporal feature following (Klementiev and Roth, 2006;<cite> Klementiev et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_5",
  "x": "In our experiments, we compared our proposed method with <cite>(Klementiev et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_6",
  "x": "We estimated comparable features from comparable corpora using the method of <cite>(Klementiev et al., 2012)</cite> and our proposed method respectively.",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_7",
  "x": "For decoding, we used the state-of-theart PBSMT toolkit Moses (Koehn et al., 2007) with default options, except for the phrase length limit (7\u21923) following <cite>(Klementiev et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_8",
  "x": "We treated the two sides of the parallel corpus as independent monolingual corpora, following (Haghighi et al., 2008;<cite> Klementiev et al., 2012</cite> We used an open-source Python script 13 to extract and clean the text from the dumps.",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_9",
  "x": "\"Klementiev+\" denotes the system that appends the comparable features estimated following <cite>(Klementiev et al., 2012)</cite> to the phrase table. \"Proposed\" denotes the system that uses the comparable features estimated by our proposed method.",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_10",
  "x": "The reason for this is that the comparable features estimated by <cite>(Klementiev et al., 2012)</cite> are inaccurate. \"Proposed\" performs significantly better than both \"Baseline\" and \"Klementiev+\".",
  "y": "differences"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_11",
  "x": "We also investigated the comparable features estimated by the method of <cite>(Klementiev et al., 2012)</cite> and our proposed method.",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_12",
  "x": "Based on our investigation, most comparable features estimated by our proposed method are more accurate than the ones estimated by the method of (Klementiev et al., 2012 Table 8 : Examples of comparable feature scores estimated by the method of <cite>(Klementiev et al., 2012)</cite> (above the bold line) and our proposed method (below the bold line) for the phrase pairs shown in Table 1 (\"con\", \"top\" and \"tem\" denote phrasal contextual, topical and temporal features respectively, \"con lex\", \"top lex\" and \"tem lex\" denote lexical contextual, topical and temporal features respectively).",
  "y": "differences"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_13",
  "x": "Table 8 shows the comparable feature scores estimated by the method of <cite>(Klementiev et al., 2012)</cite> (above the bold line) and our proposed method (below the bold line).",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_14",
  "x": "We can see that the method of <cite>(Klementiev et al., 2012)</cite> suffers from the data sparseness problem.",
  "y": "uses"
 },
 {
  "id": "79e36756354f61b087655bc6afede8_15",
  "x": "We can see that the method of <cite>(Klementiev et al., 2012)</cite> suffers from the data sparseness problem. Our proposed method addresses the data sparseness problem by using paraphrases for vector smoothing.",
  "y": "differences"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_0",
  "x": "One of the earlier successful approaches (Blitzer et al. 2006<cite> (Blitzer et al. , 2007</cite> involved Structural Correspondence Learning (SCL).",
  "y": "background"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_1",
  "x": "Li and Zong (NLP-KE 2008) explore a classifier combination technique they call \"MultipleLabel Consensus Training\" which results in better accuracy than non-adapted models on the data sets used in <cite>Blitzer et al. (2007)</cite> .",
  "y": "background"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_2",
  "x": "The feature groups are Chen et al. (2011) use a specific co-training algorithm for domain adaptation on the <cite>Blitzer et al. (2007)</cite> data set.",
  "y": "background"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_3",
  "x": "Glorot et al. (2011) investigate a deep learning approach to domain adaptation and report increased accuracy across domains both on the <cite>Blitzer et al. (2007)</cite> 4-domain data set and the larger Amazon review data set (25 domains) also made available in that release.",
  "y": "background"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_4",
  "x": "4. We also compared the results of approaches 1 and 2 to published results on Structural Correspondence Learning (SCL) by using the same datasets as in <cite>Blitzer et al. (2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_5",
  "x": "<cite>Blitzer et al. (2007)</cite> employ the Structural Correspondence Learning (SCL) algorithm for sentiment domain adaptation.",
  "y": "background"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_6",
  "x": "The baseline in <cite>Blitzer et al. (2007)</cite> is a linear classifier trained without adaptation, while their ceiling reference is the same as ours, which is the in-domain classifier trained and tested on the same domain.",
  "y": "similarities"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_7",
  "x": "In these experiments, we compare the results of our all-in-one classifier and the ensemble classifier trained and tested on the four datasets to the results of SCL and its variation SCL-MI domain adaptation as reported by <cite>Blitzer et al. (2007)</cite> baseline and ceiling in-domain classifiers for the four domains.",
  "y": "uses"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_8",
  "x": "We employed the four domains datasets used in <cite>Blitzer et al. (2007)</cite> to train and test the all-in one and the ensemble classifiers.",
  "y": "uses"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_9",
  "x": "We compare the results of the all-in-one and the ensemble classifier to the SCL and its variation SCL-MI adaptation techniques using the four datasets used to evaluate SCL and SCL-MI in <cite>Blitzer et al. (2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_10",
  "x": "The results in the previous section indicate that both the all-in-one and the ensemble approaches exceed both Daum\u00e9's domain adaptation technique on the 27 datasets (given our current implementation of Daum\u00e9's approach) and SCL on the four datasets in <cite>Blitzer et al. (2007)</cite> and that the all-in-one approach achieves comparable results in terms of transfer ratio to Glorot et al. (2011) .",
  "y": "differences"
 },
 {
  "id": "79e96060492c3978dc5a7a0d5f293f_11",
  "x": "They both are very close in some domains like When comparing the all-in-one and the ensemble approaches on the four datasets in <cite>Blitzer et al. (2007)</cite> , the all-in-one exceeds the ensemble only in the DVD domain.",
  "y": "uses"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_0",
  "x": "First, we discuss our baseline model which is similar to the machine translation encoder-alignerdecoder model of<cite> Luong et al. (2015)</cite> , and presented by Chopra et al. (2016) .",
  "y": "similarities"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_1",
  "x": "Our baseline model is a strong, multi-layered encoder-attention-decoder model with bilinear attention, similar to<cite> Luong et al. (2015)</cite> and following the details in Chopra et al. (2016) .",
  "y": "similarities"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_2",
  "x": "The context vector c t = \u03b1 t,i h i is a weighted combination of encoder hidden states h i , where the attention weights are learned through the bilinear attention mechanism proposed in<cite> Luong et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_3",
  "x": "Multi-task learning helps in sharing knowledge between related tasks across domains <cite>(Luong et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_4",
  "x": "Multi-task learning helps in sharing knowledge between related tasks across domains <cite>(Luong et al., 2015)</cite> . In this work, we show improvements on the task of abstractive summarization by sharing its parameters with the task of entailment generation.",
  "y": "differences"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_5",
  "x": "Baseline Results and Previous Work Our baseline is a strong encoder-attention-decoder model based on<cite> Luong et al. (2015)</cite> and presented by Chopra et al. (2016) .",
  "y": "uses"
 },
 {
  "id": "7a1a1593a9480b6ee246ff4248668e_6",
  "x": "In Table 2 , we again see that et al. (2015) 28.18 8.49 23.81 Chopra et al. (2016) 28.97 8.26 24.06 Nallapati et al. (2016) our<cite> Luong et al. (2015)</cite> baseline model achieves competitive performance with previous work, esp.",
  "y": "similarities"
 },
 {
  "id": "7a437574a9a7fff56a480801e47711_0",
  "x": "Robust grammar-based language modeling is a topic that has received a fair bit of attention over the past decade (Chelba and Jelinek 2000; Charniak 2001; <cite>Roark 2001</cite>; Wang, Stolcke, and Harper 2004, among others) , and while this line of research has not focused on the use of manually built, narrow-domain feature grammars, there is enough similarity between the approach described in this book and the cited papers that the papers would seem to be better comparison points than the class-based language models that are chosen to represent robust approaches in the comparison.",
  "y": "background"
 },
 {
  "id": "7a5ebe06eebebabf4340f1cf583d86_0",
  "x": "The lexicon can be considered the most dynamic part of all linguistic knowledge sources over time. There are two innovative change strategies typical for lexical systems: the creation of entirely new lexical items, commonly reflecting the emergence of novel ideas, technologies or artifacts, on the one hand, and, on the other hand, shifts in the meaning of already existing lexical items, a process which usually takes place over larger periods of time. Tracing semantic changes of the latter type is the main focus of our research. Meaning shift has recently been investigated with emphasis on neural language models (Kim et al., 2014;<cite> Kulkarni et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "7a5ebe06eebebabf4340f1cf583d86_1",
  "x": "Neural language models, originating from the word2vec algorithm (Mikolov et al., 2013a; Mikolov et al., 2013b; Mikolov et al., 2013c) , are currently considered as state-of-the-art solutions for implementing this assumption (Schnabel et al., 2015) . Within this approach, changes in similarity relations between lexical items at two different points of time are interpreted as a signal for meaning shift. Accordingly, lexical items which are very similar to the lexical item under scrutiny can be considered as approximating its meaning at a given point in time. Both techniques were already combined in prior work to show, e.g., the increasing association of the lexical item \"gay\" with the meaning dimension of \"homosexuality\" (Kim et al., 2014;<cite> Kulkarni et al., 2015)</cite> . We here investigate the accuracy and reliability of such similarity judgments derived from different training protocols dependent on word frequency, word ambiguity and the number of training epochs (i.e., iterations over all training material).",
  "y": "motivation background"
 },
 {
  "id": "7a5ebe06eebebabf4340f1cf583d86_2",
  "x": "Neural language models for tracking semantic changes over time typically distinguish between two different training protocols-continuous training of models (Kim et al., 2014) where the model for each time span is initialized with the embeddings of its predecessor, and, alternatively, independent training with a mapping between models for different points in time<cite> (Kulkarni et al., 2015)</cite> . A comparison between these two protocols, such as the one proposed in this paper, has not been carried out before.",
  "y": "motivation background"
 },
 {
  "id": "7a5ebe06eebebabf4340f1cf583d86_3",
  "x": "For comparability with earlier studies (Kim et al., 2014;<cite> Kulkarni et al., 2015)</cite> , we use the fiction part of the GOOGLE BOOKS NGRAM corpus (Michel et al., 2011; Lin et al., 2012) .",
  "y": "uses"
 },
 {
  "id": "7a5ebe06eebebabf4340f1cf583d86_4",
  "x": "We thus concentrate on two experimental protocols-the one described by Kim et al. (2014) (referred to as Kim protocol) and the one from <cite>Kulkarni et al. (2015)</cite> (referred to as Kulkarni protocol), including close variations thereof. Kulkarni's protocol operates on all 5-grams occurring during five consecutive years (e.g., [1900] [1901] [1902] [1903] [1904] and trains models independently of each other.",
  "y": "uses background"
 },
 {
  "id": "7a5ebe06eebebabf4340f1cf583d86_5",
  "x": "Our investigation in the performance of two common protocols for training neural language models on historical text data led to several hitherto unknown results. We could show that negative sampling outperforms hierarchical softmax both in terms of accuracy and reliability, especially 4 <cite>Kulkarni et al. (2015)</cite> compiled the following list based on prior work (Wijaya and Yeniterzi, 2011; Gulordava and Baroni, 2011; Jatowt and Duh, 2014; Kim et al., 2014): card, sleep, parent, address, gay, mouse, king, checked, check, actually, supposed, guess, cell, headed, ass, mail, toilet, cock, bloody, nice and guy.",
  "y": "differences"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_0",
  "x": "Multimodal corpora such as Flickr30k [1] or MSCOCO [2] containing images along with natural language captions were made available for research. They were soon extended with speech modality: speech recordings for the captions of Flickr8k were collected by [3] via crowdsourcing; spoken captions for MSCOCO were generated using Google Text-To-Speech (TTS) by<cite> [4]</cite> and using Voxygen TTS by [5] ; extensions of these corpora to other languages than English, such as Japanese, were also introduced by [6] .",
  "y": "background"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_1",
  "x": "These corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks<cite> [4,</cite> 7, 8, 9, 10, 11, 12, 13] .",
  "y": "background"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_2",
  "x": "This paper focuses on computational models of visually grounded speech that were introduced by [14,<cite> 4]</cite> .",
  "y": "background"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_3",
  "x": "Learned representations of such models were analyzed by [11, 7,<cite> 4]</cite> : [11] introduced novel methods for interpreting the activation patterns of recurrent neural networks (RNN) in a model of visually grounded meaning representation from textual and visual input and showed that RNN pay attention to word tokens belonging to specific lexical categories. [4] found that final layers tend to encode semantic information whereas lower layers tend to encode form-related information.",
  "y": "background"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_4",
  "x": "While [11, 7,<cite> 4]</cite> focused on analyzing speech representations learnt by speech-image neural models from a phonological and semantic point of view, the present work focuses on lexical acquisition and the way speech utterances are segmented into lexical units and processed by a computational model of visually grounded speech. We analyze a key component of the neural model -the attention mechanism -and we observe its behaviour and draw parallels between artificial neural attention and human attention.",
  "y": "differences"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_5",
  "x": "The model we use for our experiments is based on that of<cite> [4]</cite> . It is trained to solve an image retrieval task: given a spoken description it retrieves the closest image that matches the description. To do so, the model projects an image and its spoken description in a common representation space, so that matching image/utterance pairs lie near while mismatching image/utterance pairs lie apart.",
  "y": "uses"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_6",
  "x": "Contrary to the original model (<cite> [4]</cite> ), we used GRU units instead of RHN units.",
  "y": "differences"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_7",
  "x": "In the original architecture (<cite> [4]</cite> ), attention follows the last recurrent layer. To have more insight on the representation learnt by the network, we added an attention mechanism after the first recurrent layer.",
  "y": "extends"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_8",
  "x": "Spoken COCO dataset was introduced by<cite> [4]</cite> for English.",
  "y": "uses"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_9",
  "x": "We followed the same methodology as<cite> [4]</cite> and generated synthetic speech for each caption in the Japanese STAIR dataset.",
  "y": "uses"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_10",
  "x": "We created the spoken STAIR dataset so it would follow the exact same train/val/test 5 split as<cite> [4]</cite> . We thus have two comparable corpora: one featuring images and spoken captions in English, and another one featuring the same images and spoken captions in Japanese. This allowed us to compare the behaviour of the same architecture on two typologically different languages.",
  "y": "uses"
 },
 {
  "id": "7ac01a84ab696e7fa9d0ce336a393e_11",
  "x": "Original implementation by<cite> [4]</cite> with RHN reports median rank r = 13 on English dataset.",
  "y": "background"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_0",
  "x": "The recently available Stanford Sentiment Treebank <cite>(Socher et al., 2013)</cite> renders manually annotated, real-valued sentiment scores for all phrases in parse trees.",
  "y": "background"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_1",
  "x": "Next, we evaluate a recently proposed composition model<cite> (Socher, 2013)</cite> that relies on both the negator and the argument.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_2",
  "x": "Much recent work considers sentiment analysis from a semantic-composition perspective (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Socher et al., 2012;<cite> Socher et al., 2013)</cite> , which achieved the state-of-the-art performance.",
  "y": "background"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_3",
  "x": "The more recent work of (Socher et al., 2012;<cite> Socher et al., 2013)</cite> proposed models based on recursive neural networks that do not rely on any heuristic rules.",
  "y": "background"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_4",
  "x": "In principle neural network is able to fit very complicated functions (Mitchell, 1997) , and in this paper, we adapt the state-of-the-art approach described in <cite>(Socher et al., 2013)</cite> to help understand the behavior of negators specifically.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_5",
  "x": "For the former, we adopt the recursive neural tensor network (RNTN) proposed recently by<cite> Socher et al. (2013)</cite> , which has showed to achieve the state-of-the-art performance in sentiment analysis.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_6",
  "x": "More details can be found in <cite>(Socher et al., 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_7",
  "x": "Inference and learning in PSTN follow a forwardbackward propagation process similar to that in <cite>(Socher et al., 2013)</cite> , and for completeness, we depict the details as follows.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_8",
  "x": "During learning, following the method used by the RNTN model in <cite>(Socher et al., 2013)</cite> , PSTN also aims to minimize the cross-entropy error between the predicted distribution y i \u2208 R m\u00d71 at node i and the target distribution t i \u2208 R m\u00d71 at that node.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_9",
  "x": "Note that the gradient calculations for the V, W, W label , L are the same as that of presented in <cite>(Socher et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_10",
  "x": "The original RNTN and the PSTN predict 5-class sentiment for each negated phrase; we map the output to real-valued scores based on the scale that<cite> Socher et al. (2013)</cite> used to map real-valued sentiment scores to sentiment categories.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_11",
  "x": "Data As described earlier, the Stanford Sentiment Treebank <cite>(Socher et al., 2013)</cite> has manually annotated, real-valued sentiment values for all phrases in parse trees.",
  "y": "background"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_12",
  "x": "Data As described earlier, the Stanford Sentiment Treebank <cite>(Socher et al., 2013)</cite> has manually annotated, real-valued sentiment values for all phrases in parse trees. This provides us with the training and evaluation data to study the effect of negators with syntax and semantics of different complexity in a natural setting.",
  "y": "uses"
 },
 {
  "id": "7adc4bb66b9173ccee2adc4b64c945_13",
  "x": "The split of training and test data is same as specified in <cite>(Socher et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_0",
  "x": "Experimental results show that DCR achieves stateof-the-art exact match and F1 scores on the SQuAD dataset<cite> (Rajpurkar et al. 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_1",
  "x": "However, it is also challenging for RCQA to identify answer in arbitrary position in the passage with arbitrary length, especially for nonfactoid answers which might be clauses or sentences. As a result, apart from a few exceptions<cite> (Rajpurkar et al. 2016</cite>; Wang and Jiang 2016) , this research direction has not been fully explored yet.",
  "y": "motivation background"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_2",
  "x": "More recently, Wang and Jiang (2016) proposed two endto-end neural network models, one of which chunks a candidate answer by predicting the answer's two boundary indices and the other classifies each passage word into answer/notanswer. Both models improved significantly over the method proposed by <cite>Rajpurkar et al. (2016)</cite> .",
  "y": "background"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_3",
  "x": "First, our model uses deep networks to learn better representations for candidate answer chunks, instead of using fixed feature representations as in<cite> (Rajpurkar et al. 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_4",
  "x": "Second, it represents answer candidates as chunks, as in<cite> (Rajpurkar et al. 2016</cite> ), instead of word-level representations (Wang and Jiang 2016) , to make the model aware of the subtle differences among candidates (importantly, overlapping candidates).",
  "y": "similarities"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_5",
  "x": "The experiments on the Stanford Question Answering Dataset (SQuAD)<cite> (Rajpurkar et al. 2016)</cite> , which contains a variety of human-generated factoid and non-factoid questions, have shown the effectiveness of above three contributions.",
  "y": "uses"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_6",
  "x": "For the answer selection task this paper focuses on, several datasets exist, e.g. TREC-QA for factoid answer extraction from multiple given passages, bAbI (Weston, Chopra, and Bordes 2014) designed for inference purpose, and the SQuAD dataset<cite> (Rajpurkar et al. 2016)</cite> used in this paper.",
  "y": "uses"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_7",
  "x": "In order to make the cloze-style RC system to make chunk-level decision, we use the RC model to generate features for chunks, which are further used in a feature-based ranker like in<cite> (Rajpurkar et al. 2016)</cite> . As a result, this baseline can be viewed as a deep learning based counterpart of the system in<cite> (Rajpurkar et al. 2016</cite> ).",
  "y": "similarities"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_8",
  "x": "Answer Chunking To reduce the errors generated by the rule-based chunker in<cite> (Rajpurkar et al. 2016)</cite> , first, we capture the part-of-speech (POS) pattern of all answer subsequences in the training dataset to form a POS pattern trie tree, and then apply the answer POS patterns to passage P i to acquire a collection of all subsequences (chunk candidates) C i whose POS patterns can be matched to the POS pattern trie.",
  "y": "uses"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_9",
  "x": "Dataset We used the Stanford Question Answering Dataset (SQuAD)<cite> (Rajpurkar et al. 2016)</cite> for the experiment.",
  "y": "uses"
 },
 {
  "id": "7b5ca6526f460139f273484bd276bc_10",
  "x": "As the first row of Table 3 shows, our baseline system improves 10% (EM) over <cite>Rajpurkar et al. (2016)</cite> (Table 2 , row 1), the feature-based ranking system.",
  "y": "differences"
 },
 {
  "id": "7c5c5f13205c40a27d2629727df840_0",
  "x": "For representing quantification, we actually prefer to use Hilbert's \u01eb and \u03c4 -terms constructed with two constants \u01eb, \u03c4 : \u039b\u03b1. (\u03b1 \u2192 t) \u2192 \u03b1 and one for generic elements <cite>[8]</cite> .",
  "y": "uses"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_0",
  "x": "The major distinction between these methods is in the contrast between the approaches based exclusively on the information contained in the text to be segmented, such as lexical repetition (e.g., Choi 2000; Hearst 1997; Heinonen 1998; Kehagias, Pavlina, and Petridis 2003; Utiyama and Isahara 2001) , and those approaches that rest on complementary semantic knowledge extracted from dictionaries and thesauruses (e.g., Kozima 1993; Lin et al. 2004; Morris and Hirst 1991) , or from collocations collected in large corpora (Bolshakov and Gelbukh 2001; Brants, Chen, and Tsochantaridis 2002; <cite>Choi et al. 2001</cite>; Ferret 2002; Kaufmann 1999; Ponte and Croft 1997) .",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_1",
  "x": "Empirical arguments in favor of these methods have been provided recently by <cite>Choi et al. (2001)</cite> in a study using Latent Semantic Analysis (Latent Semantic Indexing, Deerwester et al. 1990 ) to extract a semantic space from a corpus allowing determination of the similarity of meanings of words, sentences, or paragraphs.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_2",
  "x": "By comparing the accuracy of the very same algorithm according to whether or not it takes into account complementary semantic knowledge, <cite>they</cite> were able to show the benefit derived from such knowledge.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_3",
  "x": "However, implications of <cite>Choi et al.'s study</cite> for text segmentation and for the use of LSA in natural language processing are unclear due to the methodology employed. In <cite>their experiments</cite>, semantic knowledge was acquired from a corpus containing the materials to be segmented in the test phase.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_4",
  "x": "First, <cite>Choi et al.'s</cite> segmentation procedure does not rely on supervised learning in which a system learns how to efficiently segment a text from training data.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_5",
  "x": "Second, <cite>Choi et al.</cite> employed a large number of small test samples to evaluate their algorithm, each making up-on average-0.15% of the LSA corpus.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_6",
  "x": "First, <cite>Choi et al.'s</cite> segmentation procedure does not rely on supervised learning in which a system learns how to efficiently segment a text from training data. The LSA corpus only intervenes in an indirect manner by allowing the extraction of semantic proximities between words that are then used to compute similarities between parts of the text to segment (see Section 2 for details). Second, <cite>Choi et al.</cite> employed a large number of small test samples to evaluate their algorithm, each making up-on average-0.15% of the LSA corpus. The present study shows, however, that the presence of the test materials in the LSA corpus has an important effect, but also that the generic semantic knowledge derived from large corpora clearly improves the segmentation accuracy.",
  "y": "differences"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_7",
  "x": "The first experiment is based on the original materials from <cite>Choi et al.</cite>, which consisted of a small corpus (1,000,000 words).",
  "y": "uses"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_8",
  "x": "The first experiment is based on the original materials from <cite>Choi et al.</cite>, which consisted of a small corpus (1,000,000 words). The second experiment is based on a much larger corpus (25,000,000 words).",
  "y": "differences"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_9",
  "x": "<cite>Choi et al. (2001)</cite> claimed that it was possible to improve the inter-sentence similarities index by taking into account the semantic proximities between words estimated on the basis of Latent Semantic Analysis (LSA).",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_10",
  "x": "<cite>Choi et al. (2001)</cite> have shown that using this procedure to compute the inter-sentence similarities results in the previous version of the algorithm (based solely on word repetition) being outperformed.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_11",
  "x": "<cite>Choi et al. (2001)</cite> have shown that using this procedure to compute the inter-sentence similarities results in the previous version of the algorithm (based solely on word repetition) being outperformed. The aim of this experiment is to determine the impact of the presence of the test materials in the LSA corpus on the results obtained by <cite>Choi et al. (2001)</cite> .",
  "y": "motivation"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_12",
  "x": "One Within semantic space, which corresponds to the one used by <cite>Choi et al.</cite>, was built using the entire Brown corpus as the LSA corpus.",
  "y": "background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_13",
  "x": "To extract the LSA space and to apply the segmentation algorithm, a series of parameters had to be set. First of all, paragraphs were used as documents for building the lexical tables because <cite>Choi et al.</cite> observed that such middle-sized units were more effective than shorter units (i.e., sentences).",
  "y": "uses background"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_14",
  "x": "Words were not stemmed, as in <cite>Choi et al. (2001)</cite> .",
  "y": "uses"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_15",
  "x": "The segmentation accuracy was evaluated by means of the index reported by <cite>Choi et al. (2001)</cite> : the Pk measure of segmentation inaccuracy (Beeferman, Berger, and Lafferty 1999) , which gives the proportion of sentences that are wrongly predicted to belong to the same segment or wrongly predicted to belong to different segments.",
  "y": "uses"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_16",
  "x": "The C99 algorithm, which does not employ LSA to estimate the similarities between the sentences, produces a Pk of 0.13 (<cite>Choi et al. 2001</cite>, Table 3, line 3: No stemming) .",
  "y": "uses"
 },
 {
  "id": "7c8ec9e38bf4c0c458d60af014e102_17",
  "x": "Experiment 1 was conducted on the <cite>Choi et al. (2001)</cite> LSA corpus, a 1,000,000-word collection of texts from very different genres and with varied themes.",
  "y": "uses"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_0",
  "x": "Consequently, the main previous work on AMR-based abstractive summarization <cite>(Liu et al., 2015)</cite> only generated bag-of-words from the summary AMR graph.",
  "y": "motivation"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_1",
  "x": "Abstractive Summarization using AMR: In<cite> Liu et al. (2015)</cite> work, the source document's sentences were parsed into AMR graphs, which were then combined through merging, collapsing and graph expansion into a single AMR graph representing the source document.",
  "y": "background"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_2",
  "x": "We first briefly describe the AMR-based summarization method of<cite> Liu et al. (2015)</cite> and then our guided NLG approach.",
  "y": "background"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_3",
  "x": "In<cite> Liu et al. (2015)</cite> 's work, each of the sentence of the source document was parsed into an AMR graph, and combined into a source graph, G = (V, E) where v \u2208 V and e \u2208 E are the unique concepts and the relations between pairs of concepts.",
  "y": "background"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_4",
  "x": "The encoder computes the hidden representation of the input, {z 1 , z 2 , . . . , z k }, which is the linearized summary AMR graph, G \u2032 from<cite> Liu et al. (2015)</cite> , following Van Noord and Bos (2017)'s preprocessing steps.",
  "y": "background"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_5",
  "x": "Guided NLG for full summarization In this experiment we combine our guided NLG model with<cite> Liu et al. (2015)</cite> 's work in order to generate fluent texts from their summary AMR graphs using the hyper-parameters tuned in the previous paragraph.",
  "y": "similarities uses"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_6",
  "x": "We compare our result against<cite> Liu et al. (2015)</cite> 's bag of words 1 , the unguided AMR-to-text model from \u00a73.2, and a seq2seq summarization model (Open-NMT BRNN) 2,3 which summarizes directly from the source document to summary sentence without using AMR as an interlingua and is trained on CNN/DM corpus (Hermann et al., 2015) using the same settings as See et al. (2017) .",
  "y": "similarities"
 },
 {
  "id": "7cb7cfed8b7e7bf2f0a810e02e6cbc_7",
  "x": "This phenomenon was also observed in<cite> Liu et al. (2015)</cite> 's experiment where the summary graphs extracted from automatic parses had higher accuracy than those extracted from manual parses.",
  "y": "similarities"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_0",
  "x": "Some of these features are borrowed from our previous system in the Semantic Textual Similarity (STS) task in * SEM Shared Task 2013 <cite>(Zhu and Lan, 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_1",
  "x": "We chose the Longest Common Sequence (LCS) feature <cite>(Zhu and Lan, 2013)</cite> , the Ngram Overlap feature (n=1,2,3) and the Weighted Word Overlap feature (\u0160aric et al., 2012) .",
  "y": "uses"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_2",
  "x": "In this work we used the knowledge based features in our previous work <cite>(Zhu and Lan, 2013)</cite> , which include four word similarity metrics based on WordNet: Path similarity (Banea et al., 2012) , WUP similarity (Wu and Palmer, 1994) , LCH similarity (Leacock and Chodorow, 1998) and Lin similarity (Lin, 1998) .",
  "y": "uses"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_3",
  "x": "In addition, we use the Co-occurrence Retrieval Model (CRM) feature from our previous work <cite>(Zhu and Lan, 2013)</cite> as another corpus-based feature.",
  "y": "uses"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_4",
  "x": "In this work we follow two syntactic dependency similarity features presented in our previous work <cite>(Zhu and Lan, 2013)</cite>, i.e., Simple Dependency Overlap and Special Dependency Overlap.",
  "y": "uses"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_5",
  "x": "This type of feature has been proved to be effective in our previous work <cite>(Zhu and Lan, 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "7cbe7dc02bbb53fe06d9215ed88fe0_6",
  "x": "This type of feature has been proved to be effective in our previous work <cite>(Zhu and Lan, 2013)</cite> . As a result, we extend the original 6 lexical level MT metrics to 10 metrics, i.e., WER, TER, PER, BLEU, NIST, ROUGE-L, GTM-1,GTM-2, GTM-3 and METEOR-ex.",
  "y": "extends"
 },
 {
  "id": "7ce7cfb0f918a46a1000e25b2e9eea_0",
  "x": "The COCO-QA dataset<cite> (Ren et al., 2015)</cite> for VQA was created by parsing COCO captions with a syntactic parser, and then used this to create QA pairs for four kinds of questions using hand-crafted rules. However, due to inability of the algorithm to cope with complex sentence structures, a significant portion of COCO-QA questions have grammatical errors or are oddly phrased.",
  "y": "motivation"
 },
 {
  "id": "7ce7cfb0f918a46a1000e25b2e9eea_1",
  "x": "We conduct experiments on two of the most popular VQA datasets: 'The VQA Dataset' (Antol et al., 2015) and COCO-QA<cite> (Ren et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "7ce7cfb0f918a46a1000e25b2e9eea_2",
  "x": "COCO-QA<cite> (Ren et al., 2015)</cite> also uses images from COCO, with the questions generated by an NLP algorithm that uses COCO's captions.",
  "y": "background"
 },
 {
  "id": "7ce7cfb0f918a46a1000e25b2e9eea_3",
  "x": "These baseline methods predict the answer using a vector of image features concatenated to a vector of question features<cite> (Ren et al., 2015</cite>; Zhou et al., 2015; Kafle and Kanan, 2016) .",
  "y": "background"
 },
 {
  "id": "7ce7cfb0f918a46a1000e25b2e9eea_4",
  "x": "First, we use the simple MLP baseline model used in Kafle and Kanan (2016) to assess the two data augmentation methods. The MLP model treats VQA as a classification problem with concatenated image and question features given to the model as features and answers as categories. CNN features from ResNet-152 and the skip-thought vectors<cite> (Kiros et al., 2015)</cite> are used as image and question features respectively.",
  "y": "uses"
 },
 {
  "id": "7d29a7d7c19d097758481b466360b1_0",
  "x": "Since the first approach [Wright and Wrigley 1991] of combining a probabilistic method into the GLR technique was published, Some probabilistic GLR parsers also have been implemented in which probabilities are assigned to actions of LR parsing tables by using lookaheads or LR states as simple context information of [Briscoe and Carroll 1993] , [Kentaro et al. 1998 ], and <cite>[Ruland, 2000]</cite> which does not use the stack information of the GLR parser effectively, because of highly complex internal GLR stack.",
  "y": "background"
 },
 {
  "id": "7d29a7d7c19d097758481b466360b1_1",
  "x": "Since the first approach [Wright and Wrigley 1991] of combining a probabilistic method into the GLR technique was published, Some probabilistic GLR parsers also have been implemented in which probabilities are assigned to actions of LR parsing tables by using lookaheads or LR states as simple context information of [Briscoe and Carroll 1993] , [Kentaro et al. 1998 ], and <cite>[Ruland, 2000]</cite> which does not use the stack information of the GLR parser effectively, because of highly complex internal GLR stack. As a result, they have used relatively limited contextual information for disambiguation. [Kwak et al., 2001] have proposed a conditional action model that uses the partially constructed parse represented by the graph-structured stack as the additional context. However, this method inappropriately defined sub-tree structure. Our proposed model uses Surface Phrasal Types representing the structural characteristics of the sub-trees for its additional contextual information.",
  "y": "motivation"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_0",
  "x": "We present extensions to the DocQA <cite>[2]</cite> model to allow incremental reading without loss of accuracy.",
  "y": "extends"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_1",
  "x": "However, on tasks like Question Answering, in all the existing well-performing models, RNNs are employed in a bidirectional way, or a self-attention mechanism is employed [11,<cite> 2,</cite> 4, 8] .",
  "y": "background"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_2",
  "x": "However, on tasks like Question Answering, in all the existing well-performing models, RNNs are employed in a bidirectional way, or a self-attention mechanism is employed [11,<cite> 2,</cite> 4, 8] . This means these models need to processes the whole input sequence to compute the final answer. This is a reasonable approach if the input sequence is as short as a sentence, but it becomes less effective and efficient as the length of the input sequence increases.",
  "y": "background motivation"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_3",
  "x": "We introduce a new incremental model based on DocQA <cite>[2]</cite> , which is an RNN based model proposed for QA.",
  "y": "extends"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_4",
  "x": "We use DocQA as the baseline model <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_5",
  "x": "In standard question answering, we do not care how the context is presented to the model, and for the models that achieve state of the art results, e.g. [11,<cite> 2]</cite> , they process the full context before making any decisions.",
  "y": "differences"
 },
 {
  "id": "7d7895690c84fb1af46c30f858470e_6",
  "x": "In standard question answering, we do not care how the context is presented to the model, and for the models that achieve state of the art results, e.g. [11,<cite> 2]</cite> , they process the full context before making any decisions. We show that it is possible to modify these models to be incremental while achieving similar performance.",
  "y": "extends differences"
 },
 {
  "id": "7d89a96743d9db5667d90cbd3ebd30_0",
  "x": "This task is often considered as one of the simplest in NLP because basic machine learning techniques can yield strong baselines <cite>(Wang & Manning, 2012)</cite> , often beating much more intricate approaches (Socher et al., 2011) .",
  "y": "background"
 },
 {
  "id": "7d89a96743d9db5667d90cbd3ebd30_1",
  "x": "One can use advanced machine learning techniques such as recurrent neural networks and their variations (Mikolov et al., 2010; Socher et al., 2011) , however it is not clear if these provide any significant gain over simple bag-of-words and bag-of-ngram techniques (Pang & Lee, 2008;<cite> Wang & Manning, 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "7d89a96743d9db5667d90cbd3ebd30_2",
  "x": "The large pool of diverse models is a) simple to implement (in line with previous work by Wang and Manning <cite>(Wang & Manning, 2012)</cite> ) and b) it yields state of the art performance on one of the largest publicly available benchmarks of movie reviews, the Stanford IMDB dataset of reviews.",
  "y": "similarities"
 },
 {
  "id": "7d89a96743d9db5667d90cbd3ebd30_3",
  "x": "In our ensemble, we used a supervised reweighing of the counts as in the Naive Bayes Support Vector Machine (NB-SVM) approach <cite>(Wang & Manning, 2012)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "7d89a96743d9db5667d90cbd3ebd30_4",
  "x": "Our implementation 1 slightly improved the performance reported in <cite>(Wang & Manning, 2012)</cite> by adding tri-grams (improvement of +0.6%), as shown in Table 1 .",
  "y": "differences"
 },
 {
  "id": "7d89a96743d9db5667d90cbd3ebd30_6",
  "x": "When we interpolate the scores of RNN, sentence vectors and NB-SVM, we achieve a new state-of-the-art performance of 92.57%, to be compared to 91.22% reported by <cite>(Wang & Manning, 2012)</cite> .",
  "y": "differences"
 },
 {
  "id": "7e380d496bb253885218465b778cc1_0",
  "x": "We use Average Normalized Entropy (ANE) <cite>(Boito et al., 2019a)</cite> computed over these matrices for selecting the most confident one for segmenting each phoneme sequence.",
  "y": "uses"
 },
 {
  "id": "7e380d496bb253885218465b778cc1_1",
  "x": "The experiment settings from this paper and evaluation protocol for the Mboshi corpus (Boundary F-scores using the ZRC speech reference) are the same from <cite>Boito et al. (2019a)</cite> .",
  "y": "uses"
 },
 {
  "id": "7e380d496bb253885218465b778cc1_2",
  "x": "Lastly, following the methodology from <cite>Boito et al. (2019a)</cite> , we extract the most confident alignments (in terms of ANE) discovered by the bilingual models.",
  "y": "uses"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_0",
  "x": "Our model is empirically justified and deals with the dirtiness [16] of loosely related tasks. We show that it is a generalization of various multi-task learning algorithms such as hard parameter sharing [7] , low supervision<cite> [25]</cite> , and cross-stitch networks [21] , as well as transfer learning algorithms such as frustratingly easy domain adaptation [9] .",
  "y": "uses"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_1",
  "x": "With loosely related tasks, one task may be better modeled with one hidden layer; another one with two<cite> [25]</cite> .",
  "y": "background"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_2",
  "x": "Recall that our architecture is partly motivated by the observation that for loosely related tasks, only certain features in specific layers should be shared, while many of the layers and subspaces may remain more taskspecific<cite> [25]</cite> .",
  "y": "motivation"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_3",
  "x": "**LEARNING MIXTURES MANY TASKS HAVE AN IMPLICIT HIERARCHY THAT INFORMS THEIR INTERACTION. RATHER THAN** predefining it <cite>[25,</cite> 11] , we enable our model to learn hierarchical relations by associating different tasks with different layers if this is beneficial for learning.",
  "y": "differences"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_4",
  "x": "The architecture is very flexible and can be seen as a generalization over several existing algorithms for transfer and multi-task learning, including [7, 9,<cite> 25,</cite> 21] .",
  "y": "uses similarities"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_5",
  "x": "Low Supervision<cite> [25]</cite> propose a model where only the inner layers of two deep recurrent works are shared.",
  "y": "background"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_6",
  "x": "As main tasks, we use chunking (CHUNK), named entity recognition (NER), and a simplified version of semantic role labeling (SRL) where we only identify headwords, and pair them with part-of-speech tagging (POS) as an auxiliary task, following<cite> [25]</cite> .",
  "y": "uses"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_7",
  "x": "Baseline Models As baselines, we compare against i) a single-task model only trained on chunking; ii) the low supervision model by<cite> [25]</cite> , which predicts the auxiliary task at the first layer; iii) an MTL model based on hard parameter sharing [6] ; and iv) cross-stitch networks [21] .",
  "y": "uses"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_8",
  "x": "We see that a) for the low-level simplified SRL, there is more sharing at inner layers, which is in line with<cite> [25]</cite> , while Chunking and NER also rely on the outer layer, and b) more information is shared from the more complex target tasks than vice versa.",
  "y": "similarities"
 },
 {
  "id": "7f234ecfb4cf880502faa8b89cd07b_9",
  "x": "The figure in 3 shows that hard parameter sharing, while learning faster because of the smoother loss surface in multi-task learning, is a good regularizer, confirming the findings in<cite> [25]</cite> , whereas the sluice network is even better at fitting noise than the single-task models.",
  "y": "similarities"
 },
 {
  "id": "7f2383426952ddde6fd527cf0d63bd_0",
  "x": "The most straightforward novel application is the possibility to embed the documents of all project languages into the same shared semantics vectorspace and compute document semantic similarity <cite>(Hill, Cho & Korhonen, 2016)</cite> irrespective of the document language.",
  "y": "background"
 },
 {
  "id": "7f2383426952ddde6fd527cf0d63bd_1",
  "x": "It is still an open issue which vectorspace projections yield the semantically best clusters <cite>(Hill, Cho & Korhonen, 2016)</cite> and further experiments are needed.",
  "y": "future_work"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_0",
  "x": "There are some interesting problems around written language identification that have attracted some attention recently, as native language identification (NLI, Tetreault et al., 2013) , the identification of the country of origin or the discrimination between similar or closely related languages (DSL, <cite>Tiedemann and Ljube\u0161i\u0107, 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_1",
  "x": "According to<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> , character-based n-gram methods fail for languages with a high lexical overlap, since the more shared words between two languages, the more similar will their n-gram character frequency profiles be.",
  "y": "background"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_2",
  "x": "As Baldwin and Lui (2010) or<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> point out, language identification is erroneously considered an easy and solved problem 2 , in part because of some general purpose systems being available, notably TextCat 3 , Xerox Language Identifier 4 and, more recently, langid.py (Lui and Baldwin, 2012) .",
  "y": "background"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_3",
  "x": "This work is followed up in<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> where 9% of improvement over standard approaches is reported and where support for Bosnian discrimination is included.",
  "y": "background"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_4",
  "x": "We will also refer to the lists of the 10,000 most frequent words as 'white list', which have a complementary role to the 'black lists' of<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_5",
  "x": "Despite findings by<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> , character n-grams performed better during tenfold cross-validation on the training dataset for different feature settings on the DSL dataset for group A (Bosnian, Croatian and Serbian).",
  "y": "differences"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_6",
  "x": "Moreover, the classifier could be used, as<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> suggest, to learn varieties discriminators to label texts beyond national classes (e.g. both Caribbean and Andean Spanish cross-cut national borders and, conversely, nations involved are known not to be dialectally uniform).",
  "y": "similarities"
 },
 {
  "id": "8084b5077b2a8db755b1bbd0f6fe60_7",
  "x": "Following the suggestion of<cite> Tiedemann and Ljube\u0161i\u0107 (2012)</cite> , we envisage the use of parallel texts such as versions of the Bible from different areas to learn the differences among varieties.",
  "y": "uses"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_1",
  "x": "There are several recently proposed VQA datasets on real images e.g.<cite> [2,</cite> 24, 25, 14, 29] , as well as on abstract scenes <cite>[2]</cite> .",
  "y": "background"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_2",
  "x": "For example, in the VQA dataset (with images from MS COCO) <cite>[2]</cite> , the most common sport answer \"tennis\" is the correct answer for 41% of the questions starting with \"What sport is\". Similarly, \"white\" alone is the correct answer for 23% of the questions starting with \"What color are the\". Almost half of all questions in the VQA datatset <cite>[2]</cite> can be answered correctly by a neural network that ignores the image completely and uses the question alone, relying on systematic regularities in the kinds of questions that are asked and what answers they tend to have.",
  "y": "background"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_3",
  "x": "Although our approach of visual verification is applicable to real images (more discussion in Sec. 6), we choose to use abstract images<cite> [2,</cite> 3, 39, 38, 40] as a test bed because abstract scene images allow us to focus on high-level semantic reasoning.",
  "y": "uses"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_4",
  "x": "Our main contributions are as follows: (1) We balance the existing abstract binary VQA dataset <cite>[2]</cite> by creating complementary scenes so that all questions 1 have an answer of \"yes\" for one scene and an answer of \"no\" for another closely related scene.",
  "y": "uses"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_5",
  "x": "Recent work has proposed several datasets and methods to promote research on the task of visual question answering [15, 4, 33, 24,<cite> 2,</cite> 25, 14, 29] , ranging from constrained settings [15, 24, 29] to freeform natural language questions and answers [4, 33,<cite> 2,</cite> 25, 14] .",
  "y": "background"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_6",
  "x": "A number of recent papers<cite> [2,</cite> 14, 25, 29] proposed neural network models for VQA composing LSTMs (for questions) and CNNs (for images). <cite>[2]</cite> introduced a large-scale dataset for free-form and open-ended VQA, along with several natural VQA models.",
  "y": "background"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_7",
  "x": "We first describe the VQA dataset for abstract scenes collected by <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_8",
  "x": "We first describe the VQA dataset for abstract scenes collected by <cite>[2]</cite> . We then describe how we balance this dataset by collecting more scenes.",
  "y": "extends"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_12",
  "x": "Our model is an ensemble of two similar models-Q-model and Tuple-model, whose common architecture is inspired from a recently proposed VQA approach <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_13",
  "x": "SOTA Q+Tuple+H-IMG: This VQA model has a similar architecture as our approach, except that it uses holistic image features (H-IMG) that describe the entire scene layout, instead of focusing on specific regions in the scene as determined by P and S. This model is analogous to the state-ofthe-art models presented in<cite> [2,</cite> 25, 29, 14] , except applied to abstract scenes.",
  "y": "similarities"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_15",
  "x": "Note that the accuracy is higher than 50% because this is not binary classification accuracy but the VQA accuracy <cite>[2]</cite> , which provides partial credit when there is inter-human disagreement in the ground-truth answers.",
  "y": "uses"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_16",
  "x": "Specifically, our model gives improvement in performance relative to the state-of-the-art VQA model from <cite>[2]</cite> (Q+Tuple+H-IMG), showing that attending to relevant regions and describing them in detail helps, as also seen in Sec. 5.2.",
  "y": "differences"
 },
 {
  "id": "809ad258132199e3eae8add5d1bfdf_17",
  "x": "We observe that our model trained on the balanced dataset performs the best. And again, our model that focuses on relevant regions in the image to answer the question outperforms the state-of-the-art approach of <cite>[2]</cite> (Q+Tuple+H-IMG) that does not model attention.",
  "y": "differences"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_0",
  "x": "Hence, the Connectionist Temporal Classification (CTC) approach [15] [16] <cite>[17]</cite> [18] was introduced to map the speech input frames into an output label sequence.",
  "y": "background"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_1",
  "x": "In the deep speech [19] [20] and EESEN [21] [22] work, the end-to-end speech recognition system was explored to directly predict characters instead of phonemes, hence removing the need of using lexicons and decision trees which are the building blocks in <cite>[17]</cite> [18] .",
  "y": "background"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_2",
  "x": "In <cite>[17]</cite> , the CTC with up to 27 thousand (k) word output targets was explored but the ASR accuracy is not very good, partially due to the high out-of-vocabulary (OOV) rate when using only around 3k hours training data.",
  "y": "background"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_3",
  "x": "In <cite>[17]</cite> [23] [24] , only frequent words in the training set are used as the targets and the remaining words are just tagged as the OOV.",
  "y": "background"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_4",
  "x": "In this study, we focus on how to improve the CTC with word output units. There are two challenges to the word-based CTC. The first one is the OOV issue. In <cite>[17]</cite> [23] [24] , only frequent words in the training set are used as the targets and the remaining words are just tagged as the OOV.",
  "y": "motivation"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_5",
  "x": "The CTC criterion [15] was introduced to map the speech input frames into an output label sequence [16] <cite>[17]</cite> [18] .",
  "y": "background"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_6",
  "x": "The CTC output labels can be phonemes [16] <cite>[17]</cite> [18] , characters [19] [20] [21] [22] [36] or even words <cite>[17]</cite> [23] [24] .",
  "y": "background"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_7",
  "x": "Eight frames of 80-dim log Mel-filter-bank features are stacked together as the input, and the time step shift is three frames as in <cite>[17]</cite> .",
  "y": "uses"
 },
 {
  "id": "80e3aec943c37927050f97459360b4_8",
  "x": "The WER gap is consistent with what has been observed in <cite>[17]</cite> [24] .",
  "y": "similarities"
 },
 {
  "id": "81499fd759b958a0c02d9ed9d72a46_0",
  "x": "We also extend <cite>Duong et al. (2016)</cite> , which used a lexicon to learn bilingual word embeddings.",
  "y": "extends"
 },
 {
  "id": "81499fd759b958a0c02d9ed9d72a46_1",
  "x": "<cite>Duong et al. (2016)</cite> constructed bilingual word embeddings based on monolingual data and PanLex.",
  "y": "background"
 },
 {
  "id": "81499fd759b958a0c02d9ed9d72a46_2",
  "x": "<cite>Duong et al. (2016)</cite> constructed bilingual word embeddings based on monolingual data and PanLex. In this way, <cite>their</cite> approach can be applied to more languages as PanLex covers more than a thousand languages. <cite>They</cite> solve the polysemy problem by integrating an EM algorithm for selecting a lexicon. Relative to many previous crosslingual word embeddings, <cite>their</cite> joint training algorithm achieved state-of-the-art performance for the bilingual lexicon induction task, performing significantly better on monolingual similarity and achieving a competitive result on cross lingual document classification.",
  "y": "background"
 },
 {
  "id": "81499fd759b958a0c02d9ed9d72a46_3",
  "x": "<cite>Duong et al. (2016)</cite> constructed bilingual word embeddings based on monolingual data and PanLex. Here we also adopt <cite>their</cite> approach, and extend it to multilingual embeddings.",
  "y": "extends uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_0",
  "x": "In this paper, we study the critical yet under-addressed Answer Triggering<cite> (Yang et al., 2015)</cite> problem: Given a question and a set of answer candidates, determine whether the candidate set contains any correct answer, and if so, select a correct answer as system output.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_1",
  "x": "Previous work <cite>(Yang et al., 2015</cite>; Jurczyk et al., 2016) attack the problem via a pipeline approach: First solve P 1 as a ranking task and then solve P 2 by choosing an optimal threshold upon the previous step's highest ranking score.",
  "y": "background"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_2",
  "x": "Previous work <cite>(Yang et al., 2015</cite>; Jurczyk et al., 2016) attack the problem via a pipeline approach: First solve P 1 as a ranking task and then solve P 2 by choosing an optimal threshold upon the previous step's highest ranking score. We propose Group-level Answer Triggering (GAT), an end-to-end framework for jointly optimizing P 1 and P 2 .",
  "y": "differences"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_3",
  "x": "We conduct evaluation using the same dataset and measure as in previous work <cite>(Yang et al., 2015</cite>; Jurczyk et al., 2016) , and our framework improves the F 1 score by 6.6% (from 36.65% to 43.27%), compared with the state of the art.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_4",
  "x": "We use the WIKIQA dataset<cite> (Yang et al., 2015)</cite> for evaluation.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_5",
  "x": "We can see that GAT combined with Cnt features improves the F 1 score from<cite> Yang et al. (2015)</cite> and Jurczyk et al. (2016) by around 11.1% and 6.6% (from 32.17 and 36.65 to 43.27), which shows the effectiveness of our framework.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_6",
  "x": "Through the comparison between Naive and GAT, Model Prec Rec F1<cite> (Yang et al., 2015)</cite> 27.96 37.86 32.17 (Jurczyk et al., 2016) we can see that our proposed objective function has a great advantage over the Naive one which does not model the complexity of answer triggering for positive candidate sets.",
  "y": "differences"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_7",
  "x": "Different from<cite> Yang et al. (2015)</cite>'s results, combining with the QLen feature does not further improve the performance in our case, possibly because we choose Bi-RNN as our encoder, which may capture some question characteristics better than a length feature.",
  "y": "differences"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_8",
  "x": "Since the code from<cite> (Yang et al., 2015)</cite> is available, we use it (rather than (Jurczyk et al., 2016) ) to assist our analysis.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_9",
  "x": "We first test a variant of our full framework by replacing the Encoder and QA Matching component with the CNN based model from<cite> (Yang et al., 2015)</cite> 2 , denoted as GAT w/ CNN, and train it with our objective.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_10",
  "x": "However, we leave more advanced encoder and QA matching design for future work, and anticipate that more complex CNN based models can achieve similar or better results than our current design, as in many other QA-related work (Hu et al., 2014; . (2) Compared with the best result from<cite> (Yang et al., 2015)</cite> in Table 1 , training the CNN based model end-to-end using our objective improves from 32.17% to 35.03%.",
  "y": "differences"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_11",
  "x": "This directly shows an end-to-end learning strategy works better than the pipeline approach in<cite> (Yang et al., 2015)</cite> .",
  "y": "differences"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_12",
  "x": "To obtain semantic vectors of questions and candidate answers as input to the subsequent QA Matching component, we leverage<cite> Yang et al.(2015)</cite> 's released code to train the Encoder component (with CNN) through their well-tuned individual-level optimization, and use their learnt semantic vectors.",
  "y": "uses"
 },
 {
  "id": "81bdddc7d6b04c88407537f57c0580_13",
  "x": "We further detach the QA matching component QAM in a similar way: We directly use the matching score between a question and a candidate answer obtained by<cite> Yang et al. (2015)</cite> , and concatenate it with Cnt features as input to the Softmax layer, which is our framework without ENC or QAM, denoted as -ENC -QAM, and trained by our group-level objective.",
  "y": "uses"
 },
 {
  "id": "81dd7a27479f0cec3a01337c57ca95_0",
  "x": "Text compression can be applied to various tasks such as Summarization, Text Editing and even Data Augmentation where the compressed text can be employed as additional training examples. However, almost all existing approaches require either parallel data, hand-crafted rules, or extra syntactic information such as dependency labels or part-of-speech tag features trees (McDonald, 2006; Filippova and Strube, 2008;<cite> Zhao et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "81dd7a27479f0cec3a01337c57ca95_1",
  "x": "The Gigaword dataset (Napoles et al., 2012) with 1.02 million examples, where the first 200 are labeled for extractive Sentence Compression by two annotators <cite>(Zhao et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "81dd7a27479f0cec3a01337c57ca95_2",
  "x": "Thus to faithfully evaluate the quality of the compressions generated by our model, we follow<cite> Zhao et al. (2018)</cite> and conducted human studies on the Gigaword dataset with Amazon Mechanical Turk (MTurk).",
  "y": "uses"
 },
 {
  "id": "81dd7a27479f0cec3a01337c57ca95_3",
  "x": "Following <cite>(Zhao et al., 2018)</cite> , we employed Readability and Informativeness as criteria on a five-point Likert scale.",
  "y": "uses"
 },
 {
  "id": "81dd7a27479f0cec3a01337c57ca95_4",
  "x": "Since each of the 200 sentences from Giga test set has two references (by Annotator 1 and 2, respectively), we report two F1's following<cite> Zhao et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "81dd7a27479f0cec3a01337c57ca95_5",
  "x": "Similar to our AvgPPL,<cite> Zhao et al. (2018)</cite> also employed average Perplexity (though without our length correction terms) as the reward to a policy network trained with reinforcement learning.",
  "y": "similarities"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_0",
  "x": "The Transformer neural sequence model <cite>[Vaswani et al., 2017]</cite> has emerged as a popular alternative to recurrent sequence models.",
  "y": "background"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_1",
  "x": "The \"Transformer\" seuqence-to-sequence model <cite>[Vaswani et al., 2017]</cite> uses h different attention layers (heads) in parallel, which the authors refer to as \"Multi-head attention\".",
  "y": "background"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_2",
  "x": "einsum ( \" hv , hdv\u2212>d \" , o , P_o) r e t u r n y Note: <cite>[Vaswani et al., 2017]</cite> include a constant scaling factor on the logits. We omit this in our code, as it can be folded into the linear projections P q or P k .",
  "y": "extends differences"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_3",
  "x": "Following <cite>[Vaswani et al., 2017]</cite> , in an autoregressive model, we can prevent backward-information-flow by adding a \"mask\" to the logits containing the value \u2212\u221e in the illegal positions.",
  "y": "uses"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_4",
  "x": "To simplify the performance analysis, we will make several simplifying assumptions: h , as suggested by <cite>[Vaswani et al., 2017]</cite>",
  "y": "uses similarities"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_5",
  "x": "An example is a self-attention layer in an autoregressive language model such as Transformer <cite>[Vaswani et al., 2017]</cite> .",
  "y": "similarities"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_6",
  "x": "We introduce multi-query Attention as a variation of multi-head attention as described in <cite>[Vaswani et al., 2017]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "820fa732cc4cedf2d5d94b2afb90fc_7",
  "x": "Following <cite>[Vaswani et al., 2017]</cite> , we evaluate on the WMT 2014 English-German translation task.",
  "y": "uses similarities"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_0",
  "x": "Transfer Learning <cite>(Zoph et al., 2016 )</cite> is a simple approach in which we can simply initialize an NMT model (child model) for a resource poor language pair using a previously trained model (parent model) for a resource rich language pair where the target languages are the same.",
  "y": "motivation"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_1",
  "x": "In the case of low resource languages like Hausa, vanilla NMT is either worse than or comparable to PBSMT <cite>(Zoph et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_2",
  "x": "However, it is possible to use a previously trained X-Y model (parent model; X-Y being the resource rich language pair where X and Y represent the source and target languages respectively) to initialize the parameters of a Z-Y model (child model; Z-Y being the resource poor language pair) leading to significant improvements <cite>(Zoph et al., 2016)</cite> for the latter.",
  "y": "background"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_3",
  "x": "Transfer learning for NMT <cite>(Zoph et al., 2016)</cite> is an approach where previously trained NMT models for French and German to English (resource rich pairs) were used to initialize models for Hausa, Uzbek, Spanish to English (resource poor pairs).",
  "y": "background"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_4",
  "x": "It is essentially the same as described in <cite>(Zoph et al., 2016)</cite> where we learn a model (parent model) for a resource rich language pair (Hindi-English) and use it to initialize the model (child model) for the resource poor pair (Marathi-English).",
  "y": "similarities"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_5",
  "x": "Refer to Figure 1 for an overview of the method. It is essentially the same as described in <cite>(Zoph et al., 2016)</cite> where we learn a model (parent model) for a resource rich language pair (Hindi-English) and use it to initialize the model (child model) for the resource poor pair (Marathi-English).",
  "y": "similarities uses"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_6",
  "x": "To ensure replicability we use the same NMT model design as in <cite>the original work</cite> <cite>(Zoph et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_7",
  "x": "Our choice of languages was influenced by two factors: \u2022 a. We wanted to replicate the basic transfer learning results <cite>(Zoph et al., 2016)</cite> and hence chose French, German for Hausa and Uzbek.",
  "y": "motivation"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_8",
  "x": "The model and training details are the same as that in <cite>the original work</cite> <cite>(Zoph et al., 2016)</cite> Note that the target language (English) vocabulary is same for all settings and the WPM is learned on the English side of the French-English corpus since it is the largest one amongst all our pairs.",
  "y": "similarities"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_9",
  "x": "The parent source vocabulary (and hence embeddings) is randomly mapped to child source vocabulary since it was shown that NMT is less sensitive to it <cite>(Zoph et al., 2016</cite>",
  "y": "motivation"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_10",
  "x": [
   "They showed that French-English as a parent model was better than German-English when trying to improve the Spanish-English translation quality (since Spanish is linguistically closer to French than German) but they did not conduct an exhaustive investigation for multiple language pairs."
  ],
  "y": "background"
 },
 {
  "id": "822b2010b07d3e1103f904fa45388a_11",
  "x": [
   "In this paper we extend this work to explore how language relatedness impacts transfer learning."
  ],
  "y": "extends"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_0",
  "x": "While this approach is suitable for entity linking settings such as newswire (Bentivogli, 2010) and Wikipedia (Ratinov et al., 2011) , we cannot always rely on this information in other settings like Twitter (Guo et al., 2013; Fang and Chang, 2014; Huang et al., 2014; Dredze et al., 2016) , Snapchat (Moon et al., 2018) , other web platforms<cite> (Eshel et al., 2017)</cite> , or dialogue systems (Bowden et al., 2018) .",
  "y": "background"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_1",
  "x": "In this work, we investigate this problem of effectively using context in the setting of the WikilinksNED dataset from <cite>Eshel et al. (2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_2",
  "x": "We build off a state-of-the-art attentive LSTM model from prior work<cite> (Eshel et al., 2017)</cite> and show that despite its good performance, it fails to resolve some examples that human readers would find trivial.",
  "y": "similarities uses"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_3",
  "x": "We therefore follow prior work<cite> (Eshel et al., 2017)</cite> and take as candidates all gold entities in the training set whose mention was m rather than relying on a separate candidate generation scheme.",
  "y": "similarities uses"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_4",
  "x": "This model, depicted in Figure 1 , roughly follows that of <cite>Eshel et al. (2017)</cite> , with some key differences, as we discuss in the rest of this section.",
  "y": "extends differences"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_5",
  "x": "Embedding entities We follow the method of <cite>Eshel et al. (2017)</cite> for generating entity embeddings, using word2vecf (Levy and Goldberg, 2014) to jointly train word and entity embeddings simultaneously using Wikipedia article text.",
  "y": "similarities uses"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_6",
  "x": "Unlike <cite>Eshel et al. (2017)</cite>, we structure training as a multiclass decision among these titles rather than a binary prediction problem over each title as gold or not.",
  "y": "differences"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_7",
  "x": "<cite>Eshel et al. (2017)</cite> , allowing the model to weight the importance of the outputs of the GRU at each time step.",
  "y": "background"
 },
 {
  "id": "836992d035c4be0c8eacdd419f151e_8",
  "x": "It also outperforms the roughly similar model of <cite>Eshel et al. (2017)</cite> on the test set: this gain is due to a combination of factors including the improved training procedure and some small modeling changes.",
  "y": "differences"
 },
 {
  "id": "854679aec9cf4f53e97936f865f49c_0",
  "x": "It is, however, affected by domain variation - <cite>Foster et al. (2007)</cite> report that its f-score drops by approximately 8 percentage points when applied to the BNC domain.",
  "y": "background"
 },
 {
  "id": "854679aec9cf4f53e97936f865f49c_1",
  "x": "The new system is trained on f-structureannotated parser output trees, and the performance of Charniak and Johnson's parser degrades when applied to BNC data<cite> (Foster et al., 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "854679aec9cf4f53e97936f865f49c_2",
  "x": "We intend to continue this research by training our generator on parse trees produced by a BNC-self-trained version of the Charniak and Johnson reranking parser<cite> (Foster et al., 2007)</cite> .",
  "y": "extends"
 },
 {
  "id": "8622616ffd4db96058a9b8aff54212_0",
  "x": "The keyword extraction discussed in this paper is based on work presented in <cite>Hulth (2003a)</cite> and Hulth (2003b) .",
  "y": "uses"
 },
 {
  "id": "8622616ffd4db96058a9b8aff54212_1",
  "x": "In <cite>Hulth (2003a)</cite> an evaluation of three different methods to extract candidate terms from documents is presented.",
  "y": "background"
 },
 {
  "id": "8622616ffd4db96058a9b8aff54212_2",
  "x": "For these experiments, the same machine learning system-RDS-is used as for the experiments presented by <cite>Hulth (2003a)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "8622616ffd4db96058a9b8aff54212_3",
  "x": "In the experiments presented in <cite>Hulth (2003a)</cite> , only the documents present in the training, validation, and test set respectively are used for calculating the collection frequency.",
  "y": "background"
 },
 {
  "id": "8622616ffd4db96058a9b8aff54212_5",
  "x": "In the experiments presented in <cite>Hulth (2003a)</cite> , the automatic keyword indexing task is treated as a binary classification task, where each candidate term is classified either as a keyword or a non-keyword.",
  "y": "background"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_0",
  "x": "Specifically, we extend the method recently proposed by<cite> T\u00e4ckstr\u00f6m et al. (2012)</cite> , which is based on cross-lingual word cluster features.",
  "y": "extends differences"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_1",
  "x": "Although semi-supervised approaches have been shown to reduce the need for manual annotation (Freitag, 2004; Miller et al., 2004; Ando and Zhang, 2005; Suzuki and Isozaki, 2008; Lin and Wu, 2009; Turian et al., 2010; Dhillon et al., 2011; <cite>T\u00e4ckstr\u00f6m et al., 2012)</cite> , these methods still require a substantial amount of manual annotation for each target language.",
  "y": "background"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_2",
  "x": "In this study, we turn to direct transfer methods <cite>T\u00e4ckstr\u00f6m et al., 2012)</cite> as a way to combat the need for annotated resources in all languages.",
  "y": "similarities uses"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_3",
  "x": "Specifically, we extend the direct transfer method proposed by<cite> T\u00e4ckstr\u00f6m et al. (2012)</cite> in two ways.",
  "y": "extends differences"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_4",
  "x": "This idea is at the heart of both direct transfer methods <cite>T\u00e4ckstr\u00f6m et al., 2012)</cite> and of annotation projection methods (Yarowsky et al., 2001; Diab and Resnik, 2002; Hwa et al., 2005) .",
  "y": "background"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_5",
  "x": "Recently,<cite> T\u00e4ckstr\u00f6m et al. (2012)</cite> developed an algorithm for inducing cross-lingual word clusters and proposed to use these clusters to enrich the feature space of direct transfer systems.",
  "y": "background"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_6",
  "x": "Learning from multiple languages have been shown to be of benefit both in unsupervised learning of syntax and part-of-speech (Snyder et al., 2009; BergKirkpatrick and Klein, 2010) and in transfer learning of dependency syntax (Cohen et al., 2011; 256 cross-lingual word clusters and the same feature templates as<cite> T\u00e4ckstr\u00f6m et al. (2012)</cite> , with the exception that the transition factors are not conditioned on the input.",
  "y": "differences"
 },
 {
  "id": "86af8f2cc08b00821a7a83abdfd964_7",
  "x": "We therefore suggest that such clusters could be of general use in multilingual learning of linguistic structure, in the same way that monolingual word clusters have been shown to be a robust way to bring improvements in many monolingual applications (Turian et al., 2010; <cite>T\u00e4ckstr\u00f6m et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_0",
  "x": "We used the dataset provided by <cite>[9]</cite> to extract the othering lexicon content.",
  "y": "similarities uses"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_1",
  "x": "The dataset was provided by <cite>[9]</cite> .",
  "y": "uses"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_2",
  "x": "<cite>[9]</cite> prepared their data by stemming and then creating unigram, bigram and trigram features, each of which was weighted by its TF-IDF metric.",
  "y": "background"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_3",
  "x": "In addition to that, we implemented semi-supervised classification by training in the positive samples of the <cite>[9]</cite> dataset and training in only the lexicon as negative samples.",
  "y": "similarities uses"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_4",
  "x": "This row is then converted to vector space using the paragraph2vec algorithm: <Othering Terms Permutation><Othering Pattern><Hateful Words> Each part was extracted as following: <All two-sided Pronouns><dependency(nsubj,dobj,det,compound)><POS (VB, NN, JJ)> Our lexicon content was extracted from negative samples of an annotated dataset <cite>[9]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_5",
  "x": "For semi-supervised learning, when we tested our lexicon on unseen datasets, we trained the embedding algorithm in our othering lexicon as negative and the positive samples of the <cite>[9]</cite> dataset (see Figure 9 ).",
  "y": "similarities"
 },
 {
  "id": "874a8d4f847aff2895deb7c7560c56_6",
  "x": "For Religion data set, this data set collected after Woolwich event, which contains language about Muslim and African man (religion and race), according to <cite>[9]</cite> Twitter users use this type of language in their everyday communications which could be contained in the benign tweets.",
  "y": "background"
 },
 {
  "id": "877a0b5b5d25b3849ca44ed42b8d6d_0",
  "x": "The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007;<cite> Zhang et al., 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "877a0b5b5d25b3849ca44ed42b8d6d_1",
  "x": "For instance, in our investigations for SMT (Section 3.1), the Formally SCFG based hierarchical phrase-based model (hereinafter FSCFG) (Chiang, 2007) has a better generalization capability than a Linguistically motivated STSSG based model (hereinafter LSTSSG) <cite>(Zhang et al., 2008)</cite> , with 5% rules of the former matched by NIST05 test set while only 3.5% rules of the latter matched by the same test set.",
  "y": "differences"
 },
 {
  "id": "877a0b5b5d25b3849ca44ed42b8d6d_2",
  "x": "The rule extraction in current implementation can be considered as a combination of the ones in (Chiang, 2007) and <cite>(Zhang et al., 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "877a0b5b5d25b3849ca44ed42b8d6d_3",
  "x": "For the page limit and the fair comparison, we only adopt the conventional features as in <cite>(Zhang et al., 2008)</cite> in our current implementation.",
  "y": "uses"
 },
 {
  "id": "877a0b5b5d25b3849ca44ed42b8d6d_4",
  "x": "For comparisons, we used the following three baseline systems: LSTSSG An in-house implementation of linguistically motivated STSSG based model similar to <cite>(Zhang et al., 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_0",
  "x": "Recently, <cite>Thorne et al. (2018)</cite> proposed a public dataset to explore the complete process of the large-scale fact-checking.",
  "y": "background"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_1",
  "x": "Instead of selecting the sentences by recomputing sentence-level TF-IDF features between claim and document text as in <cite>Thorne et al. (2018)</cite> , we propose a neural ranker using decomposable attention (DA) model (Parikh et al., 2016) to perform evidence selection.",
  "y": "differences"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_2",
  "x": "Same as <cite>Thorne et al. (2018)</cite> , we use the decomposable attention (DA) between the claim and the evidence for RTE.",
  "y": "similarities"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_3",
  "x": "To overcome this issue, same as<cite> (Thorne et al., 2018)</cite> , the most probable NEI evidence are simulated by sampling sentences from the nearest page to the claim using the document retrieval module.",
  "y": "similarities"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_4",
  "x": "Dataset: FEVER dataset<cite> (Thorne et al., 2018</cite> ) is a relatively large-scale dataset compared to other previous fact extraction and verification works, with around 5.4M Wikipedia documents and 185k samples.",
  "y": "uses"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_5",
  "x": "For the final fullpipeline, we compare to and follow the metric defined in <cite>Thorne et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_6",
  "x": "The MLP is a simple multi-layer perceptron using TF and TF-IDF cosine similarity between the claim and evidence as features as shown in <cite>Thorne et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "878c6cf1c47c86f36a7ff3f04e2998_7",
  "x": "Most closely related to our work, <cite>Thorne et al. (2018)</cite> addresses large-scale fact extraction and verification task using a pipeline approach.",
  "y": "similarities"
 },
 {
  "id": "887864e173d7f7c164fe9f9d940727_0",
  "x": "We propose a novel Aspect-based Rating Prediction Model (AspeRa) for aspect-based representation learning for items by encoding word-occurrence statistics into word embeddings and applying dimensionality reduction to extract the most important aspects that are used for the user-item rating estimation. We investigate how and in what settings such neural autoencoders can be applied to contentbased recommendations for text items. ---------------------------------- **ASPERA MODEL** The AspeRa model combines the advantages of deep learning (end-to-end learning, spatial text representation) and topic modeling (interpretable topics) for text-based recommendation systems. Fig. 1 shows the overall architecture of AspeRa. The model receives as input two reviews at once, treating both identically. Each review is embedded with self-attention to produce two vectors, one for author (user) features and the other for item features. These two vectors are used to predict a rating corresponding to the review. All vectors are forced to belong to the same feature space. The embedding is produced by the Neural Attention-Based Aspect Extraction Model (ABAE) <cite>[7]</cite> .",
  "y": "uses"
 },
 {
  "id": "887864e173d7f7c164fe9f9d940727_1",
  "x": "Following ABAE <cite>[7]</cite> , we set the aspects matrix ortho-regularization coefficient equal to 0.1.",
  "y": "similarities uses"
 },
 {
  "id": "887864e173d7f7c164fe9f9d940727_2",
  "x": "Qualitative analysis shows that some aspects describe what could be called a topic (a set of words diverse by part of speech and function describing a certain domain), some encode sentiment (top words are adjectives showing attitude to certain objects discussed in the text), and some encode names (actors, directors, etc.). We also found similar patterns in the output of the basic ABAE model <cite>[7]</cite> .",
  "y": "similarities"
 },
 {
  "id": "887864e173d7f7c164fe9f9d940727_3",
  "x": "He et al. <cite>[7]</cite> proposed an unsupervised neural attention-based aspect extraction (ABAE) approach that encodes word-occurrence statistics into word embeddings and applies an attention mechanism to remove irrelevant words, learning a set of aspect embeddings.",
  "y": "background"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_0",
  "x": "Some recent attempts [5, 8, 11, 12, 15] also have been made to model the dynamics of language in terms of word senses. One of the studies in this area has been presented by <cite>Mitra et al. [19]</cite> where <cite>the authors show</cite> that at earlier times, the sense of the word 'sick' was mostly associated to some form of illness; however, over the years, a new sense associating the same word to something that is 'cool' or 'crazy' has emerged. <cite>Their study</cite> is based on a unique network representation of the corpus called a distributional thesauri (DT) network built using Google books syntactic n-grams. <cite>They have used</cite> unsupervised clustering techniques to induce a sense of a word and then compared the induced senses of two time periods to get the new sense for a particular target word.",
  "y": "background"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_1",
  "x": "While <cite>Mitra et al. [19]</cite> reported a precision close to 0.6 over a random sample of 49 words, we take another random sample of 100 words separately and repeat manual evaluation.",
  "y": "extends"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_2",
  "x": "Using a set intersecting with the 100 random samples for <cite>Mitra et al. [19]</cite> , we obtain the precision values of 0.21 and 0.28, respectively.",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_3",
  "x": "We propose a method based on the network features to reduce the number of false positives and thereby, increase the overall precision of the method proposed by <cite>Mitra et al. [19]</cite> .",
  "y": "extends"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_4",
  "x": "We now describe the two baselines that are relevant for our work. Baseline 1: <cite>Mitra et al. [19]</cite> <cite>The authors proposed</cite> an unsupervised method to identify word sense changes automatically for nouns.",
  "y": "background"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_5",
  "x": "We now describe the two baselines that are relevant for our work. Baseline 1: <cite>Mitra et al. [19]</cite> <cite>The authors proposed</cite> an unsupervised method to identify word sense changes automatically for nouns. Datasets and graph construction: <cite>The authors used</cite> the Google books corpus, consisting of texts from over 3.4 million digitized English books published between 1520 and 2008. <cite>The authors constructed</cite> distributional thesauri (DT) networks from the Google books syntactic n-grams data [9] .",
  "y": "motivation background"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_6",
  "x": "<cite>The authors then compare</cite> the sense clusters extracted across two different time points to obtain the suitable signals of sense change.",
  "y": "background"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_7",
  "x": "<cite>The authors then apply</cite> multi-stage filtering in order to obtain meaningful candidate words.",
  "y": "background"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_8",
  "x": "From both the time point pairs (T 1 and T 2 ), we take 100 random samples from the birth cases reported by <cite>Mitra et al. [19]</cite> and get these manually evaluated.",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_9",
  "x": "Secondly, we also take 100 random samples for each time point pair Word Word for computing precision of our approach independently of <cite>Mitra et al. [19]</cite> , i.e., the proposed approach is not informed of the 'birth' cluster reported by <cite>Mitra et al. [19]</cite> , instead all the clusters in old and new time point are shown.",
  "y": "extends"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_10",
  "x": "Table 3 shows three example words from T 1 , their 'birth' clusters as reported in <cite>Mitra et al. [19]</cite> and the manual evaluation result.",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_11",
  "x": "Since the reported novel sense cluster can in principle be different from the 'birth' sense reported by the method of <cite>Mitra et al. [19]</cite> for the same word, we get the novel sense cases manually evaluated by 3 annotators (42 and 28 cases for the two time periods, respectively).",
  "y": "differences"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_12",
  "x": "Note that for these 100 random samples (that are all marked 'true' by <cite>Mitra et al. [19]</cite> ), it is possible to find an upper bound on the recall of Lau et al. [16] 's approach automatically.",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_13",
  "x": "While the low recall might be justified because this is a different approach, even the precision is found to be in the same range as that of <cite>Mitra et al. [19]</cite> .",
  "y": "similarities"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_14",
  "x": "We see that the filtering using SVM classification improves the precision for both the time point pairs (T 1 and T 2 ) significantly, boosting it from the range of 0.23-0.32 to 0.74-0.86. Note that, as per our calculations, indeed the recall of <cite>Mitra et al. [19]</cite> would be 100% (as we are taking random samples for annotation from the set of reported 'birth' cases by <cite>Mitra et al. [19]</cite> only).",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_15",
  "x": "Even then <cite>Mitra et al. [19]</cite> 's F-measure ranges from 0.37-0.48 while ours is 0.67-0.68.",
  "y": "differences"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_16",
  "x": "Table 7 represents some of the examples which were declared as 'birth' by <cite>Mitra et al. [19]</cite> but SVM filtering correctly flagged them as 'false birth'.",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_17",
  "x": "Further, we check if we can meaningfully combine the results reported by both the methods of <cite>Mitra et al. [19]</cite> and Lau et al. [16] for more accurate sense detection; and how does this compare with Table 8 ; both the senses look quite similar.",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_18",
  "x": "We did another experiment in order to estimate the performance of our model for detecting novel sense, independent of the method of <cite>Mitra et al. [19]</cite> .",
  "y": "differences"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_19",
  "x": "We find that in most of such cases, the sense cluster reported as 'birth' contained many new terms (and therefore, the network properties have undergone change) but the implied sense was already present in one of the previous clusters with very few common words (and therefore, the new cluster contained > 80% new words, and is being reported as 'birth' in <cite>Mitra et al. [19]</cite> ).",
  "y": "differences"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_20",
  "x": "We find that in most of such cases, the sense cluster reported as 'birth' contained many new terms (and therefore, the network properties have undergone change) but the implied sense was already present in one of the previous clusters with very few common words (and therefore, the new cluster contained > 80% new words, and is being reported as 'birth' in <cite>Mitra et al. [19]</cite> ). Two such examples are given in Table 13 . The <cite>split-join algorithm</cite> proposed in <cite>Mitra et al. [19]</cite> needs to be adapted for such cases.",
  "y": "motivation future_work"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_21",
  "x": "We now compare the sense clusters extracted across two different time points to obtain the suitable signals of sense change following the approach proposed in Mitra et al. <cite>Mitra et al. [19]</cite> .",
  "y": "uses"
 },
 {
  "id": "8a1d4802c170fa8a71504533437e8f_22",
  "x": "For 'gay', since there is no sense cluster in the older time period with 'gay' being a noun, cluster comparison does not even detect the 'birth' cluster of 'gay'. The 'birth' sense clusters for 'guy', 'bush' in the new time period, as detected by <cite>split-join algorithm</cite> contain general terms like \"someone, anyone, men, woman, mother, son\" and \"cloud, air, sky, sunlight\" respectively. As the network around these words did not change much over time, our method found it difficult to detect.",
  "y": "differences"
 },
 {
  "id": "8ace0627a085efd0cf0ccc211c556f_0",
  "x": "We use XLNet <cite>[11]</cite> to attempt to capture long range language dependencies.",
  "y": "uses"
 },
 {
  "id": "8ace0627a085efd0cf0ccc211c556f_1",
  "x": "XLNet is a generalized auto-regressive model that can be used for language modeling based on the transformer-XL architecture <cite>[11]</cite> .",
  "y": "background"
 },
 {
  "id": "8ace0627a085efd0cf0ccc211c556f_2",
  "x": "During training, a certain percentage of words are masked for use in prediction. If both \"San\" and \"Francisco\" were masked, BERT would not be able to use information when decoding one of the words to help in decoding the other. masking the input introduces a few disadvantages mentioned in <cite>[11]</cite> .",
  "y": "motivation"
 },
 {
  "id": "8ace0627a085efd0cf0ccc211c556f_3",
  "x": "During training, a certain percentage of words are masked for use in prediction. masking the input introduces a few disadvantages mentioned in <cite>[11]</cite> .",
  "y": "motivation"
 },
 {
  "id": "8ace0627a085efd0cf0ccc211c556f_4",
  "x": "We use a library that contains a pre-trained version of XLNet, an implementation of the transformer-XL architecture [14] . It was previously trained on BooksCorpus [15] and English Wikipedia which have 13GB of plain text combined <cite>[11]</cite> .",
  "y": "uses"
 },
 {
  "id": "8ace0627a085efd0cf0ccc211c556f_5",
  "x": "Given the size of the model, and the fact that it was pre-trained on 512 TPUs <cite>[11]</cite> , we expect that training for 20 epochs on TED-LIUM's text is not enough to overcome the differences between written text and conversational speech.",
  "y": "uses"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_0",
  "x": "We build on the paraphrasing approach of <cite>[1]</cite> in that we use a fixed set of templates to generate a set of candidate logical forms to answer a given query and map each logical form to a natural language expression, its canonical utterance.",
  "y": "similarities uses"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_1",
  "x": "Approaches to this task include schema matching [9] , inducing latent logical forms [10] , application of paraphrasing techniques<cite> [1,</cite><cite> 1</cite>1] , information extraction [12] , learning low dimensional embeddings of words and knowledge base constituents [13] and application of logical reasoning in conjunction with statistical techniques [11] .",
  "y": "similarities uses"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_2",
  "x": "The ParaSempre system of <cite>[1]</cite> is based on the idea of generating a set of candidate logical forms from the query using a set of templates.",
  "y": "background"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_3",
  "x": "One way of doing this to consider a fixed number of logical forms for each query sentence, and train a classifier to choose the best logical form given a sentence <cite>[1]</cite> .",
  "y": "motivation"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_4",
  "x": "We built our implementation on top of the ParaSempre system <cite>[1]</cite> , and so our evaluation exactly matches theirs.",
  "y": "similarities uses"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_5",
  "x": "Since we have adopted the logical form templates of ParaSempre, our upper bound or oracle F1 score is the same, 63% <cite>[1]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "8ad5f7a658a8bb5377981ba6b098dc_6",
  "x": "Average F1 score Sempre [10] 35.7 ParaSempre <cite>[1]</cite> 39.9 Facebook [13] 41.8 DeepQA [11] 45.3 Tensor kernel with unigrams 40.1 In development, we found that ordering the training alphabetically by the text of the query lead to a large reduction in accuracy.",
  "y": "extends differences"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_0",
  "x": "The recent metaphor paraphrasing approach of <cite>Shutova (2010)</cite> was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases.",
  "y": "motivation"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_1",
  "x": "The recent metaphor paraphrasing approach of <cite>Shutova (2010)</cite> was designed with this requirement in mind and used statistical methods, but still relied on the WordNet (Fellbaum, 1998) database to generate the initial set of paraphrases. In this paper, we take the metaphor paraphrasing task a step further and present a fully unsupervised approach to this problem.",
  "y": "extends"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_2",
  "x": "<cite>Shutova (2010)</cite> used a selectional preference-based model for this purpose, obtaining encouraging results in a supervised setting.",
  "y": "background"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_3",
  "x": "We evaluate the capacity of our vector space model to discriminate between literal and figurative paraphrases on its own, as well as integrating it with a selectional preference-based model similar to that of <cite>Shutova (2010)</cite> and thus evaluating the latter in an unsupervised setting.",
  "y": "similarities"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_4",
  "x": "We focus on paraphrasing metaphorical verbs and evaluate our system using the dataset of <cite>Shutova (2010)</cite> especially designed for this task.",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_5",
  "x": "The comparison against a paraphrasing gold standard provided by <cite>Shutova (2010)</cite> is complemented by an evaluation against direct human judgements of system output.",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_6",
  "x": "Following <cite>Shutova (2010)</cite> , we use a selectional preference model to discriminate between literally and metaphorically used substitutes.",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_7",
  "x": "We thus evaluated the ability of VS on its own to detect literal paraphrases, as well as the effectiveness of the SP model of <cite>Shutova (2010)</cite> in an unsupervised setting and in combination with VS.",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_8",
  "x": "To our knowledge, the only metaphor paraphrasing dataset and gold standard available to date is that of <cite>Shutova (2010)</cite> .",
  "y": "background"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_9",
  "x": "To our knowledge, the only metaphor paraphrasing dataset and gold standard available to date is that of <cite>Shutova (2010)</cite> . We used this dataset to develop and test our system.",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_10",
  "x": "<cite>Shutova (2010)</cite> annotated metaphorical expressions in a subset of the BNC sampling various genres: literature, newspaper/journal articles, essays on politics, international relations and sociology, radio broadcast (transcribed speech).",
  "y": "background"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_11",
  "x": "The gold standard was created by <cite>Shutova (2010)</cite> as follows.",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_12",
  "x": "At first sight, these improvements of our unsupervised system may not seem very high, in particular when compared to the results of the supervised system of <cite>Shutova (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "8ae44e74146d3f40845741fac4dff9_13",
  "x": "Following <cite>Shutova (2010)</cite> , the current experimental design and test set focuses on subject-verb and verb-object metaphors only, but we expect the method to be equally applicable to other parts of speech and a wider range of syntactic constructions.",
  "y": "uses"
 },
 {
  "id": "8b2bb6753dc72a048ec28958e943fb_0",
  "x": "<cite>Y\u00fcret and T\u00fcre (2006)</cite> proposed a decision list learning algorithm for extraction of Finally, hybrid models which combine statistical and rule based approaches are also proposed (Oflazer and Tur 1996; Kutlu and Cicekli 2013) .",
  "y": "background"
 },
 {
  "id": "8b2bb6753dc72a048ec28958e943fb_1",
  "x": "<cite>Y\u00fcret and T\u00fcre (2006)</cite> observe that more than ten thousand tag types exists in a corpus comprised of a million Turkish words.",
  "y": "background"
 },
 {
  "id": "8b2bb6753dc72a048ec28958e943fb_2",
  "x": "<cite>Y\u00fcret and T\u00fcre (2006)</cite> extract Turkish morphological disambiguation rules using a decision list learner, Greedy Prepend Algorithm (GPA), and they achieve 95.8% accuracy on manually disambiguated data consisting of around 1K words.",
  "y": "background"
 },
 {
  "id": "8b2bb6753dc72a048ec28958e943fb_3",
  "x": "For Turkish, we used a semi-automatically disambiguated corpus containing 1M tokens<cite> (Y\u00fcret and T\u00fcre 2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "8b2bb6753dc72a048ec28958e943fb_5",
  "x": "<cite>Y\u00fcret and T\u00fcre (2006)</cite> report that the accuracy of the training data is below 95%.",
  "y": "background"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_0",
  "x": "Recent advances have shown that E2E models can outperform the state-of-the-art conventional system when trained on thousands of hours of data [5, <cite>6]</cite> .",
  "y": "background"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_1",
  "x": "Further improvements such as biasing before beam pruning, and wordpiece-based biasing have been proposed to achieve state-of-the-art biasing results [12,<cite> 6,</cite> 13] .",
  "y": "background"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_2",
  "x": "Shallow fusion has been used in E2E models for decoding [10] and contextual biasing<cite> [6]</cite> .",
  "y": "background"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_3",
  "x": "In [13] , wordpieces have been shown to outperform graphemes in biasing since they create a sparser match of biasing units. All these improvements lead to significantly better biasing which is comparable to the state-of-the-art conventional model<cite> [6]</cite> .",
  "y": "background"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_4",
  "x": "Since phonemes show strength in recognizing rare words [1<cite>6]</cite> , we want to present these words as phonemes more often.",
  "y": "background"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_5",
  "x": "We use context-independent phonemes as in [1<cite>6]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_6",
  "x": "To generate words as outputs, we search through a decoding graph similar to [1<cite>6]</cite> but accept both phonemes and wordpieces.",
  "y": "extends differences"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_7",
  "x": "Based on [1<cite>6]</cite> , we add two improvements to the decoding strategy.",
  "y": "similarities uses"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_8",
  "x": "Similarly to<cite> [6]</cite> , an input utterance is divided to 25-ms frames, windowed and shifted at a rate of 10 ms.",
  "y": "similarities uses"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_9",
  "x": "Similar to<cite> [6]</cite> , the encoder of the RNN-T consists of 8 Long Short-Term Memory (LSTM) [21] layers and the prediction network contains 2 layers.",
  "y": "similarities uses"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_10",
  "x": "We attribute the superior per- formance of the wordpiece-phoneme model to the robustness of phonemes to OOV words, as observed in [1<cite>6]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_11",
  "x": "As shown in the last column of Table 1 , the wordpiece model performs better than the grapheme model as in<cite> [6]</cite> . However, we note that the regression is significantly smaller than the all-phoneme model in [1<cite>6]</cite> .",
  "y": "differences"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_12",
  "x": "However, we note that the regression is significantly smaller than the all-phoneme model in [1<cite>6]</cite> .",
  "y": "differences"
 },
 {
  "id": "8bd97eb118175c9fd2147b6456421c_13",
  "x": "Lastly, since wordpieces perform better than graphemes<cite> [6]</cite> in E2E modeling, it would be interesting to explore longer phonemic units such as phoneme pieces for biasing.",
  "y": "future_work"
 },
 {
  "id": "8bdfc9e82e474413f29ee92f81467e_0",
  "x": "In contrast to standard sequenceto-sequence models <cite>(Cho et al., 2014</cite>; Sutskever et al., 2014; Bahdanau et al., 2015) , HREDs model the dialogue context by introducing a context Recurrent Neural Network (RNN) over the encoder RNN, thus forming a hierarchical encoder.",
  "y": "differences"
 },
 {
  "id": "8bdfc9e82e474413f29ee92f81467e_2",
  "x": "For each m = 1, . . . , M n , we have hidden states of each module defined as: where f text \u03b8 ,f cxt \u03b8 and f dec \u03b8 are GRU cells<cite> (Cho et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "8bdfc9e82e474413f29ee92f81467e_3",
  "x": "2 We used 512 as the word embedding size as well as hidden dimension for all the RNNs using GRUs<cite> (Cho et al., 2014)</cite> with tied embeddings for the (bidirectional) encoder and decoder.",
  "y": "uses"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_0",
  "x": "We conduct our experiments on Trafficking-10k<cite> (Tong et al., 2017)</cite> , a dataset of escort ads for which anti-trafficking experts assigned each sample one of seven ordered labels ranging from \"1: Very Unlikely (to come from traffickers)\" to \"7: Very Likely\".",
  "y": "uses background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_1",
  "x": "Our proposed model significantly outperforms previously published models<cite> (Tong et al., 2017)</cite> on Trafficking-10k as well as a variety of baseline ordinal regression models.",
  "y": "background differences"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_2",
  "x": "Closest to our work is the Human Trafficking Deep Network (HTDN)<cite> (Tong et al., 2017)</cite> . HTDN has three main components: a language network that uses pretrained word embeddings and a long shortterm memory network (LSTM) to process text input; a vision network that uses a convolutional network to process image input; and another convolutional network to combine the output of the previous two networks and produce a binary classification. Compared to the language network in HTDN, our model replaces LSTM with a gatedfeedback recurrent neural network, adopts certain regularizations, and uses an ordinal regression layer on top. It significantly improves HTDN's benchmark despite only using text input.",
  "y": "differences background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_3",
  "x": "As in the work of E. <cite>Tong et al. (2017)</cite> , we pre-train word embeddings using a skip-gram model (Mikolov et al., 2013b) applied to unlabeled data from escort ads, however, we go further by analyzing the emojis' embeddings and thereby expand the trafficking lexicon.",
  "y": "extends differences background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_4",
  "x": "Vector representations of words, also known as word embeddings, can be obtained through unsupervised learning on a large text corpus so that certain linguistic regularities and patterns are encoded. Unfortunately, the escort ads contain a plethora of emojis, acronyms, and (sometimes deliberate) typographical errors that are not encountered in more standard text data, which suggests that it is likely better to learn word embeddings from scratch on a large collection of escort ads instead of using previously published embeddings<cite> (Tong et al., 2017)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_5",
  "x": "Then we present a detailed comparison of our proposed model with commonly used ordinal regression models as well as the previous state-of-the-art classification model by E. <cite>Tong et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_6",
  "x": "We use raw texts scraped from Backpage and TNABoard to pre-train the word embeddings, and use the same labeled texts E. <cite>Tong et al. (2017)</cite> used to conduct model comparisons. The raw text dataset consists of 44,105 ads from TNABoard and 124,220 ads from Backpage.",
  "y": "uses background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_7",
  "x": "The labeled dataset is called Trafficking-10k. It consists of 12,350 ads from Backpage labeled by experts in human trafficking detection 6<cite> (Tong et al., 2017)</cite> . Each label is one of seven ordered levels of likelihood that the corresponding ad comes from a human trafficker. Descriptions and sample proportions of the labels are in Table 1 . The original Trafficking-10K includes both texts and images, but as mentioned in Section 1, only the texts are used in our case. We apply the same preprocessing to Trafficking-10k as we do to raw data.",
  "y": "uses background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_8",
  "x": "To compare our model with the previous stateof-the-art classification model for escort ads, the Human Trafficking Deep Network (HTDN)<cite> (Tong et al., 2017)</cite> , we also polarize the true and predicted labels into two classes, \"1-4: Unlikely\" and \"5-7: Likely\"; then we compute the binary classification accuracy (Acc.) as well as the weighted binary classification accuracy (Wt. Acc.) The text data need to be vectorized before they can be fed into the baseline models (whereas vectorization is built into ORNN).",
  "y": "uses similarities"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_9",
  "x": "All models are trained and evaluated using the same (w.r.t. data shuffle and split) 10-fold crossvalidation (CV) on Trafficking-10k, except for HTDN, whose result is read from the original paper<cite> (Tong et al., 2017)</cite> 7 .",
  "y": "background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_10",
  "x": "Traffickers often avoid using explicit keywords when advertising victims, but instead use acronyms, intentional typos, and emojis<cite> (Tong et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_11",
  "x": "To make matters worse, traffickers change their dictionaries over time and regularly switch to new emojis to replace certain keywords<cite> (Tong et al., 2017)</cite> . In such a dynamic and adversarial environment, the need for a data-driven approach in updating the existing lexicon is evident.",
  "y": "motivation background"
 },
 {
  "id": "8c26fb4c81c121103c1d5851edb41e_12",
  "x": "Our ORNN achieved the state-of-the-art performance on Trafficking-10K<cite> (Tong et al., 2017)</cite> , outperforming all baseline ordinal regression models as well as improving the classification accuracy over the Human Trafficking Deep Network<cite> (Tong et al., 2017)</cite> .",
  "y": "background differences"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_0",
  "x": "Our work builds on sequence-to-sequence models (Sutskever et al., 2014; Bahdanau et al., 2015) , which have been extensively applied to the task of abstractive summarization (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; See et al., 2017; <cite>Paulus et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_1",
  "x": "Recent summarization models build upon pointer networks (Nallapati et al., 2016; See et al., 2017; <cite>Paulus et al., 2017)</cite> and have a few main architectural differences.",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_2",
  "x": "For instance, (See et al., 2017) pairs attention with a coverage mechanism to avoid repetition and<cite> (Paulus et al., 2017)</cite> relies on intra-decoder attention to enable generating coherent multi-sentence summaries.",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_3",
  "x": "The mechanism allows the decoder to keep track of its progress and dissuades the decoder from generating repeated information (Vaswani et al., 2017; <cite>Paulus et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_4",
  "x": "Recently, sequence-to-sequence neural networks (Sutskever et al., 2014) have been applied to abstractive summarization (Nallapati et al., 2016; See et al., 2017; <cite>Paulus et al., 2017)</cite> following their success in both machine translation (Bahdanau et al., 2015; Luong et al., 2015b) , parsing (Luong et al., 2015a) and image captioning (Vinyals et al., 2015b) .",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_5",
  "x": "Research in abstractive summarization with sequence-to-sequence models focuses on neural architectures (Rush et al., 2015; Chopra et al., 2016; Nallapati et al., 2016; See et al., 2017; <cite>Paulus et al., 2017)</cite> and learning objectives<cite> (Paulus et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_6",
  "x": "Pointer mechanisms have been useful for abstractive summarization where copying entities and other rare words from the input is highly advantageous (See et al., 2017; <cite>Paulus et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_7",
  "x": "To address this impediment, (See et al., 2017) introduce coverage modeling,<cite> (Paulus et al., 2017)</cite> propose intra-decoder attention, and (Suzuki and Nagata, 2017) equip the decoder with an estimator of unigram frequency.",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_8",
  "x": "Regarding learning objectives,<cite> (Paulus et al., 2017)</cite> investigates the potential improvement from replacing maximum likelihood training with reinforcement learning to optimize ROUGE, the most common automatic metric to assess summarization.",
  "y": "background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_9",
  "x": "Regarding learning objectives,<cite> (Paulus et al., 2017)</cite> investigates the potential improvement from replacing maximum likelihood training with reinforcement learning to optimize ROUGE, the most common automatic metric to assess summarization. Our model builds upon this previous work.",
  "y": "extends background"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_10",
  "x": "Following (Gehring et al., 2017) , we rely on convolutional networks, in contrast to previous work using recurrent networks (Nallapati et al., 2016; See et al., 2017; <cite>Paulus et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_11",
  "x": "Like<cite> (Paulus et al., 2017)</cite> , we rely on intra-attention for generating multi-sentence text.",
  "y": "similarities"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_12",
  "x": "Like<cite> (Paulus et al., 2017)</cite> , we share the word embeddings in the encoder and decoder lookup tables with the embeddings from the output layer of the decoder.",
  "y": "similarities"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_13",
  "x": "Contrary to<cite> (Paulus et al., 2017</cite>; See et al., 2017; Nallapati et al., 2016) , we rely on Byte-Pair Encoding (BPE) (Sennrich et al., 2016) to improve the model copy mechanism instead of using an additional pointer mechanism.",
  "y": "differences"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_14",
  "x": "Contrary to<cite> (Paulus et al., 2017)</cite> , we did not explore training objectives and our training procedure aims at maximizing the likelihood of the training summaries given the source document.",
  "y": "differences"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_15",
  "x": "We evaluate on two versions of this dataset, the entity anonymized version (Hermann et al., 2015; Nallapati et al., 2016; <cite>Paulus et al., 2017)</cite> and the full text version (See et al., 2017) 1 .",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_16",
  "x": "To avoid repetition, we prevent the decoder from generating the same trigram more than once during test, following<cite> (Paulus et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_17",
  "x": "We evaluate using the standard ROUGE metric (Lin, 2004) and report the F1 scores for ROUGE-1, ROUGE-2, and ROUGE-L. We compare to existing abstractive baselines (Nallapati et al., 2016; See et al., 2017; <cite>Paulus et al., 2017)</cite> and report results on the Lead-3 extraction baseline which simply selects the first three sentences of the input article as its summary.",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_18",
  "x": "This simulates a user which expresses preferences through specifying values of Model ROUGE-1 ROUGE-2 ROUGE-L Lead-3 (Nallapati et al., 2017) 39.2 15.7 35.5 ML words-lvt2k-temp-att (Nallapati et al., 2016) 35.46 13.30 32.65 ML, no intra-attention<cite> (Paulus et al., 2017)</cite> 37.86 14.69 34.99 ML, with intra-attention<cite> (Paulus et al., 2017)</cite> 38 the control variables.",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_19",
  "x": "Table 4 shows results on the entity-anonymized version of the dataset used by (Nallapati et al., 2016; <cite>Paulus et al., 2017)</cite> and Table 5 reports results on the original version of the dataset used by (See et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_20",
  "x": "On the entity-anonymized text, we report 38.68 F1-ROUGE1 as opposed to 38.30 for the best maximum likelihood training setting of<cite> (Paulus et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "8c57f595f1acecd03c32181cad444b_21",
  "x": "Our model does not outperform the reinforcement learning model of<cite> (Paulus et al., 2017)</cite> which optimizes ROUGE.",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_0",
  "x": "On the other hand, we can impose limited architectural constraints in the form of selective rationalization<cite> (Lei et al., 2016</cite>; Li et al., 2016b; Chen et al., 2018a,b) where the goal is to only expose the portion of the text relevant for prediction.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_1",
  "x": "On the other hand, we can impose limited architectural constraints in the form of selective rationalization<cite> (Lei et al., 2016</cite>; Li et al., 2016b; Chen et al., 2018a,b) where the goal is to only expose the portion of the text relevant for prediction. In this paper, we build on and extend selective rationalization.",
  "y": "extends"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_2",
  "x": "Moreover, we empirically show that (1) the three-player framework on its own helps cooperative games such as<cite> (Lei et al., 2016)</cite> to improve both predictive accuracy and rationale quality; (2) by combining the two solutions -introspective generator and the three player game -we can achieve high predictive accuracy and non-degenerate rationales.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_3",
  "x": "Many previous works<cite> (Lei et al., 2016</cite>; Chen et al., 2018a) follows the above definition of rationales.",
  "y": "background similarities"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_4",
  "x": "Compared with<cite> (Lei et al., 2016)</cite> , as shown in Figure 1(a) , the three-player model introduces an additional complement predictor, which plays a minimax game in addition to the cooperative game in<cite> (Lei et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_5",
  "x": "Without the complement predictor, and thus the loss Lg, the framework reduces to the method in<cite> (Lei et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_6",
  "x": "Finally, as suggested by an anonymous reviewer, we evaluate on the text matching benchmark AskUbuntu, following<cite> Lei et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_7",
  "x": "Multi-aspect beer review This is the same data used in<cite> (Lei et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_8",
  "x": "When only 10% of the words are used,<cite> Lei et al. (2016)</cite> has a significant performance downgrade compared to the accuracy when using the whole passage (82.05 v.s. 87.59).",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_9",
  "x": "On the other hand, our introspection models are able to maintain higher predictive accuracy (86.16 v.s. 82.05) compared to<cite> (Lei et al., 2016)</cite> , while only sacrificing a little loss on highlighting precision (0.47% drop).",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_10",
  "x": "Comparing the model of<cite> (Lei et al., 2016)</cite> with and without the proposed mini-max module, there is a huge gap of more than 5% on recall of generated rationales.",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_11",
  "x": "Moreover, our reimplementation of<cite> (Lei et al., 2016)</cite> for the original regression task achieves 90.1% precision when highlighting 10% words, which suggest that rationalization for binary classification is more challenging compared to the regression where finer supervision is available.",
  "y": "extends"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_12",
  "x": "In summary, our three-player framework consistently improves the quality of extracted rationales on both of the original<cite> (Lei et al., 2016)</cite> and the introspective framework.",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_13",
  "x": "For both cooperative methods, i.e.<cite> (Lei et al., 2016)</cite> with and without introspection, we train an independent extra predictor on the unselected words from the generator, which does not affect the training of the generator-predictor framework.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_14",
  "x": "From the left part of Table 4 , we observe that the original model of<cite> (Lei et al., 2016</cite> ) has a hard time maintaining the accuracy compared to the classifier trained with full texts.",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_15",
  "x": "We further conduct subjective evaluations by comparing the original model of<cite> (Lei et al., 2016)</cite> with our introspective threeplayer model.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_16",
  "x": "Since there is a rich form of su- pervised signal, i.e., the number of class labels is large, the chance of any visible degeneration of the<cite> Lei et al. (2016)</cite> 's model should be low.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_17",
  "x": "In the first example,<cite> Lei et al. (2016)</cite> fails to highlight the second entity while ours does.",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_18",
  "x": "In the second example, the introspective three-player model selects more words than<cite> (Lei et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_19",
  "x": "According to Lemma 1.1, Lg can be rewritten as Table 1 and Degeneration Cases of<cite> (Lei et al., 2016)</cite> This section provides the details to obtain the results in Table 1 in the introduction section, where the method of<cite> (Lei et al., 2016)</cite> generates degenerated rationales.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_20",
  "x": "The method of<cite> (Lei et al., 2016)</cite> works well in many applications.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_21",
  "x": "In this section, we design an experiment to confirm the existence of the problem in the original<cite> (Lei et al., 2016)</cite> model.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_22",
  "x": "During the training of<cite> (Lei et al., 2016)</cite> , we stipulate that the generated rationales are very concise: we punish it when the rationales have more than 3 pieces or more than 20% of the words are generated (both with hinge losses).",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_23",
  "x": "From the results, we can see that<cite> Lei et al. (2016)</cite> tends to predict color words, like dark-brown, yellow, as rationales.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_24",
  "x": "Rationale from<cite> (Lei et al., 2016)</cite> (Acc: 76.4%):",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_25",
  "x": "Rationale from<cite> (Lei et al., 2016)</cite> (Acc: 76.4%): [\"dark-brown/black color\"] Rationale from our method (Acc: 80.4%):",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_26",
  "x": "Rationale from<cite> (Lei et al., 2016)</cite> (Acc: 76.4%):",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_27",
  "x": "Rationale from<cite> (Lei et al., 2016)</cite> (Acc: 76.4%): [\"really cloudy lots\", \"yellow\", \"no\", \"no\"] Rationale from our method (Acc: 80.4%):",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_28",
  "x": "To this end, we mask the original texts with the rationales generated by<cite> (Lei et al., 2016)</cite> and our method.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_29",
  "x": "Setting Following the suggestion from the reviews, we evaluate the proposed method on the question retrieval task on AskUbuntu<cite> (Lei et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_30",
  "x": "We use the same data split provided by<cite> (Lei et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_31",
  "x": "In our experiments, we follow the same setting from<cite> (Lei et al., 2016)</cite> by only using the question bodies.",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_32",
  "x": "In our experiments, we follow the same setting from<cite> (Lei et al., 2016)</cite> by only using the question bodies. Different from their work, we do not pretrain an encoder by predicting a question title using the corresponding question body.",
  "y": "uses differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_33",
  "x": "8 We use the same word embeddings as released by<cite> (Lei et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_34",
  "x": "The original model from<cite> (Lei et al., 2016)</cite> fails to maintain the performance compared to the model trained with full texts.",
  "y": "differences"
 },
 {
  "id": "8c7722ecab0d6a21e15ce63b8a47f5_35",
  "x": "Adding the proposed minimax game helps both the<cite> (Lei et al., 2016</cite> ) and the introspection model to generate more informative texts as the rationales, which improves the MAP of the prediction while lowering the complement MAP.",
  "y": "extends"
 },
 {
  "id": "8d3a20b4e50f81c94e884a0b978575_0",
  "x": "The images can be natural scenes taken by real people, or artificial scenes created with clip arts like in <cite>[1]</cite> .",
  "y": "similarities"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_0",
  "x": "While recent work on generation in restricted domains, such as (Belz, 2007) , has shown promising results there remains much room for improvement particularly for broad coverage and robust generators, like those of Nakanishi et al. (2005) and<cite> Cahill and van Genabith (2006)</cite> , which do not rely on handcrafted grammars and thus can easily be ported to new languages.",
  "y": "background"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_1",
  "x": "In the LFG-based generation algorithm presented by<cite> Cahill and van Genabith (2006)</cite> complex named entities (i.e. those consisting of more than one word token) and other multi-word units can be fragmented in the surface realization.",
  "y": "background"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_2",
  "x": "In the LFG-based generation algorithm presented by<cite> Cahill and van Genabith (2006)</cite> complex named entities (i.e. those consisting of more than one word token) and other multi-word units can be fragmented in the surface realization. We show that the identification of such units may be used as a simple measure to constrain the generation model's output.",
  "y": "motivation"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_3",
  "x": "We take the generator of<cite> (Cahill and van Genabith, 2006)</cite> as our baseline generator.",
  "y": "uses"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_4",
  "x": "These rules can be handcrafted grammar rules, such as those of (LangkildeGeary, 2002; Carroll and Oepen, 2005) , created semi-automatically (Belz, 2007) or, alternatively, extracted fully automatically from treebanks (Bangalore and Rambow, 2000; Nakanishi et al., 2005;<cite> Cahill and van Genabith, 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_5",
  "x": "The generation model of<cite> (Cahill and van Genabith, 2006)</cite> maximises the probability of a tree given an f-structure (Eqn. 1), and the string generated is the yield of the highest probability tree.",
  "y": "background"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_6",
  "x": "To solve the problem,<cite> Cahill and van Genabith (2006)</cite> apply an automatic generation grammar transformation to their training data: they automatically label CFG nodes with additional case information and the model now learns the new improved generation rules of Tables 4 and 5 . Note how the additional case labelling subverts the problematic independence assumptions of the probability model and communicates the fact that a subject NP has to be realised as nominative case from the S \u2192 NP-nom VP production, via the intermediate NP-nom \u2192 PRP-nom, down to the lexical production PRP-nom \u2192 she.",
  "y": "background"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_7",
  "x": "The automatic generation grammar transform presented in<cite> (Cahill and van Genabith, 2006)</cite> provides a solution to coarse-grained and (in fact) inappropriate independence assumptions in the basic generation model.",
  "y": "background"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_8",
  "x": "This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of<cite> (Cahill and van Genabith, 2006)</cite> .",
  "y": "differences"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_9",
  "x": "F-Struct Feats Grammar Rules Note, that for our example the effect of the uniform additional conditioning on mother grammatical function has the same effect as the generation grammar transform of <cite>(Cahill and van Genabith, 2006</cite> ), but without the need for the gram- mar transform.",
  "y": "similarities differences"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_10",
  "x": "In addition, uniform conditioning on mother grammatical function is more general than the case-phenomena specific generation grammar transform of<cite> (Cahill and van Genabith, 2006)</cite> , in that it applies to each and every sub-part of a recursive input f-structure driving generation, making available relevant generation history (context) to guide local generation decisions.",
  "y": "differences"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_11",
  "x": "As in<cite> (Cahill and van Genabith, 2006)</cite> fstructures are generated from the (now altered) treebank and from this data, along with the treebank trees, the PCFG-based grammar, which is used for training the generation model, is extracted.",
  "y": "similarities uses"
 },
 {
  "id": "8dd8c0e61010d97d0ddae6d81a9067_12",
  "x": "In Table 10 , Baseline gives the results of the generation algorithm of<cite> (Cahill and van Genabith, 2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_0",
  "x": "Recently, <cite>(Cherry et al., 2018)</cite> extended the approach of NMT based on subword units to implement the translation model directly at the level of characters, which could reach comparable performance to the subword-based model, although this would require much larger networks which may be more difficult to train.",
  "y": "background"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_1",
  "x": "Although character-level NMT models have shown the potential to obtain comparable performance with subwordbased NMT models, this would require increasing the computational cost of the model, defined by the network parameters (Kreutzer and Sokolov, 2018;<cite> Cherry et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_2",
  "x": "We evaluate decoding architectures using different levels of granularity in the vocabulary units and the attention mechanism, including the standard decoding architecture implemented either with subword (Sennrich et al., 2016) or fully character-level <cite>(Cherry et al., 2018)</cite> units, which constitute the baseline approaches, and the hierarchical decoding architecture, by implementing all in Pytorch (Paszke et al., 2017) within the OpenNMT-py framework (Klein et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_3",
  "x": "As the training data size increases, one would expect the likelihood of observing rare words to decrease, especially in languages with low morphological complexity, along with the significance of representing rare and unseen words <cite>(Cherry et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_4",
  "x": "As the training data size increases, one would expect the likelihood of observing rare words to decrease, especially in languages with low morphological complexity, along with the significance of representing rare and unseen words <cite>(Cherry et al., 2018)</cite> . Our results support this hypothesis, where decreasing lexical sparsity, either in the form of the training data size, or the morphological complexity of the target language, eliminates the advantage of character-level translation.",
  "y": "similarities"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_5",
  "x": "Studies have shown that character-level NMT models could potentially reach the same performance with the subword-based NMT models <cite>(Cherry et al., 2018)</cite> , although this might require increasing the capacity of the network.",
  "y": "background"
 },
 {
  "id": "8e59c2c48e27b2abd5f63d6b4ce23d_6",
  "x": "In this paper, we limit the evaluation to recurrent architectures for comparison to previous work, including (Luong and Manning, 2016) , (Sennrich et al., 2016) and <cite>(Cherry et al., 2018)</cite> , and leave implementation of hierarchical decoding with feed-forward architectures to future work.",
  "y": "uses"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_0",
  "x": "Lexical simplification is the task to find and substitute a complex word or phrase in a sentence with its simpler synonymous expression. This task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context<cite> (Specia et al., 2012</cite>; Kajiwara and Yamamoto, 2015) .",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_1",
  "x": "The evaluation dataset for the English Lexical Simplification task<cite> (Specia et al., 2012)</cite> Figure 1: A part of the dataset of Kajiwara and Yamamoto (2015) . notated on top of the evaluation dataset for English lexical substitution (McCarthy and Navigli, 2007) .",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_2",
  "x": "In addition, De Belder and Moens (2012) built an evaluation dataset for English lexical simplification based on that developed by McCarthy and Navigli (2007) . Unlike the dataset of<cite> Specia et al. (2012)</cite> , sentences in their dataset contain at least one complex word, but they might contain more than one complex word.",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_3",
  "x": "3 Problems in previous datasets for Japanese lexical simplification Kajiwara and Yamamoto (2015) followed<cite> Specia et al. (2012)</cite> to construct an evaluation dataset for Japanese lexical simplification.",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_4",
  "x": "These procedures were the same as for De Belder and Moens (2012) . Spearman's score of this work was lower than that of<cite> Specia et al. (2012)</cite> by 0.064.",
  "y": "differences"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_5",
  "x": "3 Problems in previous datasets for Japanese lexical simplification Kajiwara and Yamamoto (2015) followed<cite> Specia et al. (2012)</cite> to construct an evaluation dataset for Japanese lexical simplification. Namely, they split the data creation process into two steps: substitute extraction and simplification ranking. These procedures were the same as for De Belder and Moens (2012) . Spearman's score of this work was lower than that of<cite> Specia et al. (2012)</cite> by 0.064.",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_6",
  "x": "Because Kajiwara and Yamamoto (2015) extracted sentences from a newswire corpus, their dataset has a poor variety of expression. English lexical simplification datasets<cite> (Specia et al., 2012</cite>; De Belder and Moens, 2012) do not have this problem because both of them use a balanced corpus of English (Sharoff, 2006) .",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_7",
  "x": "Therefore, in this work, we extract sentences containing only one complex word. Ties are not permitted in simplification ranking. When each annotator assigns a simplification ranking to a substitution list, a tie cannot be assigned in previous datasets<cite> (Specia et al., 2012</cite>; Kajiwara and Yamamoto, 2015) .",
  "y": "uses"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_8",
  "x": "De Belder and Moens (2012) allow ties in simplification ranking and report considerably higher agreement among annotators than<cite> Specia et al. (2012)</cite> .",
  "y": "background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_9",
  "x": "Kajiwara and Yamamoto (2015) and<cite> Specia et al. (2012)</cite> use an average score to integrate rankings, but it might be biased by outliers.",
  "y": "motivation background"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_10",
  "x": "Table 1 shows the characteristics of our dataset. It is about the same size as previous work<cite> (Specia et al., 2012</cite>; Kajiwara and Yamamoto, 2015) .",
  "y": "similarities"
 },
 {
  "id": "8e738a8f52e5931a92c9e4577a1ad3_11",
  "x": "Our method achieved better accuracy in ranking integration than previous methods<cite> (Specia et al., 2012</cite>; Kajiwara and Yamamoto, 2015) and is similar to the results from De Belder and Moens (2012) .",
  "y": "differences"
 },
 {
  "id": "8fc0d25eb177ea876c2b69096f0145_0",
  "x": "Consequently, it is unknown if Indonesian word embeddings introduced in, e.g.,<cite> (Al-Rfou et al., 2013)</cite> and (Grave et al., 2018) , capture syntactic or semantic information as measured by analogy tasks.",
  "y": "motivation"
 },
 {
  "id": "8fc0d25eb177ea876c2b69096f0145_1",
  "x": "Also, such embeddings are usually trained on Indonesian Wikipedia <cite>(Al-Rfou et al., 2013</cite>; Bojanowski et al., 2017) whose size is relatively small, approximately 60M tokens.",
  "y": "background motivation"
 },
 {
  "id": "8fc0d25eb177ea876c2b69096f0145_2",
  "x": "We also used another two pretrained embeddings: polyglot embedding trained on Indonesian Wikipedia<cite> (Al-Rfou et al., 2013)</cite> and NLPL embedding trained on the Indonesian portion of CoNLL 2017 corpus (Fares et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_0",
  "x": "The production of knowledge bases and the need to answer questions over such resources received researchers attentions to propose different models to find the answer of questions from the knowledge bases, known as KBQA 1 . Answering factoid questions with one relation, also known as simple question answering, has been widely studied in recent years (Dai et al., 2016;<cite> Yin et al., 2016</cite>; He and Golub, 2016; Yu et al., 2017) .",
  "y": "background"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_1",
  "x": "Moreover, matching question content with relations has also been proposed and shown promising results<cite> (Yin et al., 2016</cite>; Yu et al., 2017) .",
  "y": "background"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_2",
  "x": "One paradigm in proposed approaches for relation extraction in KBQA is based on semantic parsing in which questions were parsed and turned into logical forms in order to query the knowledge base (Berant et al., 2013; Berant and Liang, 2014) . From another point of view, two mainstreams for extracting relations in KBQA are studied: (a) using a classifier which chooses the most probable relation among all (Mohammed et al., 2018) ; (b) matching questions and relations through learning of an embedding space for representing all relations and question words (Bordes et al., 2015; Dai et al., 2016;<cite> Yin et al., 2016</cite>; He and Golub, 2016; Yu et al., 2017) , in which each relation is considered either as a meaningful sequence of words or as a unique entity.",
  "y": "background"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_3",
  "x": "In this regard, following <cite>Yin et al. (2016)</cite> , we first extract the entity mentions out of question words and put a symbol (e.g. < e >) in its place, so that we will have a question pool in which each question is labeled with its relation that can be considered as a paraphrase of that question.",
  "y": "uses"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_4",
  "x": "Following the previous works by <cite>Yin et al. (2016)</cite> and Yu et al. (2017) , we use the common benchmark dataset of the simple question answering, namely SimpleQuestions, which was originally introduced by Bordes et al. (2015) .",
  "y": "uses"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_5",
  "x": "<cite>Yin et al. (2016)</cite> proposed a new benchmark for evaluating relation extraction task on SimpleQuestion.",
  "y": "background"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_6",
  "x": "<cite>Yin et al. (2016)</cite> proposed a new benchmark for evaluating relation extraction task on SimpleQuestion. We use the same dataset which contains 72239, 10310 and 20610 question samples as train, validation, and test sets respectively.",
  "y": "uses"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_7",
  "x": "In this table, AMPCNN<cite> (Yin et al., 2016)</cite> is an attentive max-pooling CNN for matching a question with all relations. APCNN (dos Santos et al., 2016) and ABCNN<cite> (Yin et al., 2016)</cite> both employ an attentive pooling mechanism. These two models Model Accuracy (%) AMPCNN<cite> (Yin et al., 2016)</cite> 91.3 OWA-ABCNN<cite> (Yin et al., 2016)</cite> 90.2 Proposed Q'-Q + Q'-R model 93.41 are not originally evaluated on relation prediction of simple questions.",
  "y": "differences"
 },
 {
  "id": "8ff1560ac0241a763b4b0d93718b40_8",
  "x": "Proposed Q'-Q + Q'-R model 93.41 are not originally evaluated on relation prediction of simple questions. In fact, the authors of AMPCNN<cite> (Yin et al., 2016)</cite> , conducted the corresponding experiments on a one-way-attention adaptation of these two models to compare them with the available methods in this task.",
  "y": "background"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_0",
  "x": "This problem has lately raised severe concerns in the word embedding community (e.g., Hellrich and Hahn (2016b) ;<cite> Antoniak and Mimno (2018)</cite> ; Wendlandt et al. (2018) ) and is also of interest to the wider machine learning community due to the influence of probabilistic-and thus unstablemethods on experimental results (Reimers and Gurevych, 2017; Henderson et al., 2018) , as well as replicability and reproducibility (Ivie and Thain, 2018, pp.",
  "y": "motivation"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_1",
  "x": "We show how the choice of down-sampling strategies, a seemingly minor detail, leads to major differences in the characterization of SVD PPMI in recent studies (Hellrich and Hahn, 2017;<cite> Antoniak and Mimno, 2018)</cite> .",
  "y": "motivation"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_2",
  "x": "Most stability experiments focused on repeatedly training the same algorithm on one corpus Hahn, 2016a,b, 2017;<cite> Antoniak and Mimno, 2018</cite>; Pierrejean and Tanguy, 2018; Chugh et al., 2018) , whereas Wendlandt et al. (2018) quantified stability by comparing word similarity for models trained with different algorithms.",
  "y": "background"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_3",
  "x": "Reasonable metrical choices are, e.g., the Jaccard coefficient (Jaccard, 1912) between these sets<cite> (Antoniak and Mimno, 2018</cite>; Chugh et al., 2018) , or a percentage based coefficient (Hellrich and Hahn, 2016a,b; Wendlandt et al., 2018; Pierrejean and Tanguy, 2018) .",
  "y": "background"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_4",
  "x": "For instance, the largest corpus in<cite> Antoniak and Mimno (2018)</cite> contains 15M tokens, whereas the corpus used by Hellrich and Hahn (2017) and the largest corpus from Wendlandt et al. (2018) each contain about 60M tokens.",
  "y": "background"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_5",
  "x": "We used both the corpora as-is, as well as independently drawn random subsamples (see also Hellrich and Hahn (2016a) ;<cite> Antoniak and Mimno (2018)</cite> ) to simulate the arbitrary content selection in most corpora-texts could be removed or replaced with similar ones without changing the overall nature of a corpus, e.g., Wikipedia articles are continuously edited.",
  "y": "similarities uses"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_6",
  "x": "As proposed by<cite> Antoniak and Mimno (2018)</cite> , we further modified our SVD PPMI implementation to use random numbers generated with a non-fixed seed for probabilistic down-sampling.",
  "y": "extends differences"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_7",
  "x": "Diverging reports on SVD PPMI stability-described as perfectly reliable in Hellrich and Hahn (2017) , yet not in<cite> Antoniak and Mimno (2018)</cite> -can thus be explained by their difference in down-sampling options, i.e., no down-sampling or probabilistic down-sampling.",
  "y": "background"
 },
 {
  "id": "90522b5ac99d1657bf9af9d165c36e_8",
  "x": "GLOVE's high stability in other studies<cite> (Antoniak and Mimno, 2018</cite>; Wendlandt et al., 2018) seems to be counterbalanced by its low accuracy and also appears to be limited to training on small corpora.",
  "y": "background"
 },
 {
  "id": "90962438b8efa0f7a14fd050365310_0",
  "x": "A breakthrough has come in the form of research by McClosky et al. (2006a; 2006b ) who show that self-training can be used to improve parser performance when combined with a two-stage reranking parser model <cite>(Charniak and Johnson, 2005)</cite> .",
  "y": "background"
 },
 {
  "id": "90962438b8efa0f7a14fd050365310_1",
  "x": "We parse the BNC (Burnard, 2000) in its entirety using the reranking parser of<cite> Charniak and Johnson (2005)</cite> .",
  "y": "uses"
 },
 {
  "id": "90962438b8efa0f7a14fd050365310_2",
  "x": "The reranking parser of<cite> Charniak and Johnson (2005)</cite> was used to parse the BNC.",
  "y": "uses"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_0",
  "x": "This shortcoming of aggregate parsing metrics was highlighted in a recent study by <cite>Rimell et al. (2009)</cite> , introducing a new parser evaluation corpus containing around 700 sentences annotated with unbounded dependencies in seven different grammatical constructions.",
  "y": "background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_1",
  "x": "In this paper, we extend the evaluation of <cite>Rimell et al. (2009)</cite> to two dependency parsers, MSTParser (McDonald, 2006) and MaltParser (Nivre et al., 2006a) , trained on data from the PTB, converted to Stanford typed dependencies (de Marneffe et al., 2006) , and combined with a simple post-processor to extract unbounded dependencies from the basic dependency tree.",
  "y": "extends"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_2",
  "x": "Unlike the best performing grammar-based parsers studied in <cite>Rimell et al. (2009)</cite> , neither MSTParser nor MaltParser was developed specifically as a parser for English, and neither has any special mechanism for dealing with unbounded dependencies.",
  "y": "differences"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_3",
  "x": "Nevertheless, the two dependency parsers are found to perform only slightly worse than the best grammar-based parsers evaluated in <cite>Rimell et al. (2009)</cite> and considerably better than the other statistical parsers in that evaluation.",
  "y": "differences"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_4",
  "x": "The unbounded dependency corpus of <cite>Rimell et al. (2009)</cite> includes seven grammatical constructions: object extraction from a relative clause (ObRC), object extraction from a reduced relative clause (ObRed), subject extraction from a relative clause (SbRC), free relatives (Free), object questions (ObQ), right node raising (RNR), and subject extraction from an embedded clause (SbEm), all chosen for being relatively frequent and easy to identify in PTB trees.",
  "y": "background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_5",
  "x": "Moreover, <cite>Rimell et al. (2009)</cite> show that, although individual types of unbounded dependencies may be rare, the unbounded dependency types in the corpus, considered as a class, occur in as many as 10% of sentences in the PTB. In <cite>Rimell et al. (2009)</cite> , five state-of-the-art parsers were evaluated for their recall on the goldstandard dependencies.",
  "y": "background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_6",
  "x": "In this paper we repeat the study of <cite>Rimell et al. (2009)</cite> for two dependency parsers, with the goal of evaluating how parsers based on dependency grammars perform on unbounded dependencies.",
  "y": "uses"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_7",
  "x": "One important difference between MSTParser and MaltParser, on the one hand, and the best performing parsers evaluated in <cite>Rimell et al. (2009)</cite> , on the other, is that the former were never developed specifically as parsers for English.",
  "y": "differences"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_8",
  "x": "It is well known that questions are very rare in the WSJ data, and <cite>Rimell et al. (2009)</cite> found that parsers trained only on WSJ data generally performed badly on the questions included in the evaluation corpus, while the C&C parser equipped with a model trained on a combination of WSJ and question data had much better performance.",
  "y": "background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_9",
  "x": "In comparison to the five parsers evaluated in <cite>Rimell et al. (2009)</cite> , it is worth noting that MSTParser and MaltParser were trained on the same basic data as four of the five, but with a different kind of syntactic representation -dependency trees instead of phrase structure trees or theoryspecific representations from CCG and HPSG.",
  "y": "uses differences"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_10",
  "x": "All the development and test sets in the corpus of <cite>Rimell et al. (2009)</cite> were parsed using MSTParser and MaltParser after part-of-speech tagging the input using SVMTool (Gim\u00e9nez and M\u00e0rquez, 2004 ) trained on section 2-21 of the WSJ data in Stanford basic dependency format.",
  "y": "uses"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_11",
  "x": "The evaluation was performed using the same criteria as in <cite>Rimell et al. (2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_12",
  "x": "The evaluation in <cite>Rimell et al. (2009)</cite> took into account a wide variety of parser output formats, some of which differed significantly from the gold-standard.",
  "y": "background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_13",
  "x": "The evaluation was performed using the same criteria as in <cite>Rimell et al. (2009)</cite> . The evaluation in <cite>Rimell et al. (2009)</cite> took into account a wide variety of parser output formats, some of which differed significantly from the gold-standard.",
  "y": "uses background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_14",
  "x": "WAvg excludes ObQ sentences, since frequency statistics were not available for this construction in <cite>Rimell et al. (2009)</cite> .",
  "y": "background"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_15",
  "x": "Table 2 shows the results for MSTParser and MaltParser in the context of the other parsers evaluated in <cite>Rimell et al. (2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "9158f716efae0d1f38510dd0847c45_16",
  "x": "Perhaps more interestingly, the accuracies of MSTParser and MaltParser are only slightly below the best performing systems in <cite>Rimell et al. (2009)</cite> -C&C and Enju .",
  "y": "differences"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_0",
  "x": "In this paper, we generalize the violation-fixing perceptron of Huang et al. (2012) to hypergraphs and apply it to the cube-pruning parser of <cite>Zhang and McDonald (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_1",
  "x": "This idea was adapted to graph-based dependency parsers by <cite>Zhang and McDonald (2012)</cite> and shown to outperform left-to-right beam search.",
  "y": "background"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_2",
  "x": "We empirically validate the benefit of this approach within the cube-pruning dependency parser of <cite>Zhang and McDonald (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_3",
  "x": "This is the strategy used by <cite>Zhang and McDonald (2012)</cite> .",
  "y": "background"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_4",
  "x": "In our experiments, we compare the performance of the two violation-fixing update strategies against two baselines. This is the strategy used by <cite>Zhang and McDonald (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_5",
  "x": "We ran a number of experiments on the cubepruning dependency parser of <cite>Zhang and McDonald (2012)</cite> , <cite>whose</cite> search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the Eisner algorithm (Eisner, 1996) .",
  "y": "uses"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_6",
  "x": "The feature templates we used are a superset of <cite>Zhang and McDonald (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_7",
  "x": "All other highorder features of <cite>Zhang and McDonald (2012)</cite> only look at arcs on the same side of their head.",
  "y": "background"
 },
 {
  "id": "91c1a4ab0347fb8b11ff213a97e864_8",
  "x": "It also improves over the baseline cube-pruning parser without max-violation update strategies (<cite>Zhang and McDonald, 2012</cite>) , showing the importance of update strategies in inexact hypergraph search.",
  "y": "differences"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_0",
  "x": "In recent works, short phrases (Lau et al., 2011) or images (<cite>Aletras and Stevenson, 2013</cite>) have been used as alternatives.",
  "y": "background"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_1",
  "x": "The method presented by <cite>Aletras and Stevenson (2013)</cite> selects an image from a small set of candidates by re-ranking them using an unsupervised graph-based method.",
  "y": "background"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_2",
  "x": "The method presented by <cite>Aletras and Stevenson (2013)</cite> selects an image from a small set of candidates by re-ranking them using an unsupervised graph-based method. <cite>It is</cite> an iterative method that has a runtime complexity of O(n 2 ) which makes it infeasible to run over large number of images.",
  "y": "background"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_3",
  "x": "The method presented by <cite>Aletras and Stevenson (2013)</cite> selects an image from a small set of candidates by re-ranking them using an unsupervised graph-based method. Thus the scope of <cite>this method</cite> gets limited to solving a local problem of re-ordering a small set of candidate images for a given topic.",
  "y": "background"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_4",
  "x": "The method presented by <cite>Aletras and Stevenson (2013)</cite> selects an image from a small set of candidates by re-ranking them using an unsupervised graph-based method. Furthermore, <cite>its</cite> accuracy is limited by the recall of the information retrieval engine.",
  "y": "background"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_5",
  "x": "We evaluate our model on the publicly available data set provided by <cite>Aletras and Stevenson (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_6",
  "x": "The 20 candidate image labels per topic are collected by <cite>Aletras and Stevenson (2013)</cite> using an information retrieval engine (Google).",
  "y": "background"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_7",
  "x": "Our evaluation follows prior work (Lau et al., 2011; <cite>Aletras and Stevenson, 2013</cite>) using two metrics.",
  "y": "uses"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_8",
  "x": "We compare our approach to the state-of-the-art method that uses Personalized PageRank (<cite>Aletras and Stevenson, 2013</cite>) to re-rank image candidates.",
  "y": "uses"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_9",
  "x": "We adapt the original method of <cite>Aletras and Stevenson (2013)</cite> to compute the PageRank scores of all the available images in the test set of each fold for each topic (Global PPR).",
  "y": "extends"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_10",
  "x": "Top-1 aver. rating nDCG-1 nDCG-3 nDCG-5 <cite>Global PPR</cite> (<cite>Aletras and Stevenson, 2013</cite>) 1 (<cite>Aletras and Stevenson, 2013</cite>) 2.24 --- The DNN (Topic+Caption) model that uses only textual information, obtains a Top-1 Average performance of 1.94.",
  "y": "differences"
 },
 {
  "id": "926e7df3c367ae29da574ba465504f_11",
  "x": "Our evaluation results show that our proposed approach significantly outperforms the state-of-the-art method of <cite>Aletras and Stevenson (2013)</cite> and a relevant method originally utilized for image annotation proposed by Weston et al. (2010) .",
  "y": "differences"
 },
 {
  "id": "9272b3f7e628a156caed328d475d0c_0",
  "x": "It is only very recently that some groups of researchers looked into readability assessment in Bengali. They observed that English readability formulas did not work well on Bengali texts [11] , <cite>[21]</cite> .",
  "y": "background"
 },
 {
  "id": "9272b3f7e628a156caed328d475d0c_1",
  "x": "Recently Lahiri et al. showed moderate correlation between readability indices and formality score ( [10] ) in four different domains [14] . <cite>Sinha et al.</cite> classified English readability formulas into three broad categories -traditional methods, cognitively motivated methods, and machine learning methods <cite>[21]</cite> .",
  "y": "background"
 },
 {
  "id": "9272b3f7e628a156caed328d475d0c_2",
  "x": "We found only three lines of work that specifically looked into Bengali readability [6] , [11] , <cite>[21]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "9272b3f7e628a156caed328d475d0c_3",
  "x": "<cite>Sinha et al.</cite> alleviated these problems by considering six parameters instead of just two <cite>[21]</cite> . <cite>They</cite> further showed that English readability indices were inadequate for Bengali, and built <cite>their</cite> own readability model on 16 texts.",
  "y": "background"
 },
 {
  "id": "9272b3f7e628a156caed328d475d0c_4",
  "x": "We only have 30 annotated passages at our disposal, whereas Islam et al. [11] had around 300. But Islam et al.'s dataset is not annotated in as fine-grained a fashion as ours. Note also that our dataset is larger than both <cite>Sinha et al.'s</cite> 16document dataset <cite>[21]</cite> , and Das and Roychoudhury's seven document dataset [6] .",
  "y": "differences"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_0",
  "x": "In particular, several related techniques approach the problem of script induction as one of learning narrative chains from text corpora (Chambers and Jurafsky, 2008; Chambers and Jurafsky, 2009;<cite> Jans et al., 2012</cite>; Pichotta and Mooney, 2014) .",
  "y": "background"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_1",
  "x": "Several followup papers introduce variations and improvements on this original model for learning narrative chains (Chambers and Jurafsky, 2009;<cite> Jans et al., 2012</cite>; Pichotta and Mooney, 2014) .",
  "y": "background"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_2",
  "x": "To learn the restaurant script from our dataset, we implement the models of Chambers and Jurafsky (2008) and<cite> Jans et al. (2012)</cite> , as well as the unigram baseline of Pichotta and Mooney (2014) .",
  "y": "similarities uses"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_3",
  "x": "This section provides an overview of each of the different methods and parameter settings we employ to learn narrative chains from the Dinners from Hell corpus, starting with the original model (Chambers and Jurafsky, 2008) and extending to the modifications of<cite> Jans et al. (2012)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_4",
  "x": "<cite>(Jans et al., 2012)</cite> Coreference Chain Length The original model counts co-occurrences in all coreference chains; we include<cite> Jans et al. (2012)</cite> 's option to count over only the longest chains in each document, or to count only over chains of length 5 or greater (long).",
  "y": "extends differences"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_5",
  "x": "Two additional models are introduced by<cite> Jans et al. (2012)</cite> and we use them here, as well.",
  "y": "future_work"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_6",
  "x": "Scoring We employ three different scoring metrics: average rank (Chambers and Jurafsky, 2008) , mean reciprocal rank, and recall at 50 <cite>(Jans et al., 2012)</cite> .",
  "y": "similarities"
 },
 {
  "id": "92e43071b2a9b05b5d96277c1aa250_7",
  "x": "Furthermore, it is apparent from the results that the bigram probability models perform better overall than PMI-based models, a finding also reported in<cite> Jans et al. (2012)</cite> .",
  "y": "differences"
 },
 {
  "id": "932a13e179da50c9189bd0c612cb9c_0",
  "x": "It differs from similar algorithms that select translation correspondences explicitly at the document level (Fung and Cheung, 2004; Resnik and Smith, 2003; Snover et al., 2008; <cite>Munteanu and Marcu, 2005</cite>; Quirk et al., 2007; Utiyama and Isahara, 2003) .",
  "y": "differences"
 },
 {
  "id": "932a13e179da50c9189bd0c612cb9c_1",
  "x": "\u2022 Sentence-level filter: The word-overlap filter in<cite> (Munteanu and Marcu, 2005)</cite> has been implemented: for a sentence pair (S, T ) to be considered parallel the ratio of the lengths of the two sentences has to be smaller than two.",
  "y": "uses"
 },
 {
  "id": "932a13e179da50c9189bd0c612cb9c_2",
  "x": "The baseline uses only the length-based filtering and the coverage filtering without caching the coverage decisions<cite> (Munteanu and Marcu, 2005)</cite> .",
  "y": "uses"
 },
 {
  "id": "932a13e179da50c9189bd0c612cb9c_3",
  "x": "With the help of an efficient implementation, it avoids any translation candidate selection at the document level (Resnik and Smith, 2003; Smith, 2002; Snover et al., 2008; Utiyama and Isahara, 2003; <cite>Munteanu and Marcu, 2005</cite>; Fung and Cheung, 2004) .",
  "y": "uses"
 },
 {
  "id": "932a13e179da50c9189bd0c612cb9c_4",
  "x": "Currently, we are working on a feature-rich approach<cite> (Munteanu and Marcu, 2005)</cite> to improve the sentence-pair selection accuracy.",
  "y": "uses"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_0",
  "x": "Recently, <cite>Verga et al. (2018)</cite> introduced multi-instance learning (MIL) (Riedel et al., 2010; Surdeanu et al., 2012) to treat multiple mentions of target entities in a document.",
  "y": "background"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_1",
  "x": "We infer relations between entities using MIL-based bi-affine pairwise scoring function<cite> (Verga et al., 2018)</cite> on the entity node representations.",
  "y": "similarities uses"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_2",
  "x": "Next, it encodes the graph structure using a stacked GCNN layer and classifies the relation between the target entities by applying MIL<cite> (Verga et al., 2018)</cite> to aggregate all 1 The dataset is publicly available at http://nactem.",
  "y": "uses similarities"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_3",
  "x": "Since each target entity can have multiple mentions in a document, we employ a multi-instance learning (MIL)-based classification scheme to aggregate the predictions of all target mention pairs using bi-affine pairwise scoring<cite> (Verga et al., 2018)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_4",
  "x": "For the CDR dataset, we performed hypernym filtering similar to Gu et al. (2017) and <cite>Verga et al. (2018)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_5",
  "x": "For the CDR dataset, we compare with five stateof-the-art models: SVM , ensemble of feature-based and neural-based models (Zhou et al., 2016a) , CNN and Maximum Entropy (Gu et al., 2017) , Piece-wise CNN (Li et al., 2018) and Transformer<cite> (Verga et al., 2018)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_6",
  "x": "Unlike <cite>Verga et al. (2018)</cite>, we used the pre-trained word embeddings in place of sub-word embeddings to align with our word graphs.",
  "y": "extends differences"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_7",
  "x": "Our work is different from <cite>Verga et al. (2018)</cite> in that we replace Transformer with a GCNN model for full-abstract encoding using non-local dependencies such as entity coreference.",
  "y": "extends differences"
 },
 {
  "id": "939274ae40a68acc322b34d8f91f7e_8",
  "x": "<cite>Verga et al. (2018)</cite> considered multi-instance learning for document-level RE.",
  "y": "background"
 },
 {
  "id": "93cf4d4fd9cd875e8e148d1bbd8e2c_1",
  "x": "Second, we perform qualitative and quantitative comparison of the maps generated by state-of-the-art attention-based VQA models (Yang et al., 2015;<cite> Lu et al., 2016</cite> ) and a task-independent saliency baseline (Judd et al., 2009 ) against our human attention maps through visualizations and rank-order correlation.",
  "y": "motivation background"
 },
 {
  "id": "93cf4d4fd9cd875e8e148d1bbd8e2c_2",
  "x": "Hierarchical Co-Attention Network<cite> (Lu et al., 2016)</cite> generates multiple levels of image attention based on words, phrases and complete questions, and is the top entry on the VQA Challenge 1 as of the time of this submission.",
  "y": "background"
 },
 {
  "id": "93cf4d4fd9cd875e8e148d1bbd8e2c_3",
  "x": "\u2022 Hierarchical Co-Attention Network (HieCoAtt)<cite> (Lu et al., 2016)</cite> with word-level (HieCoAtt-W), phrase-level (HieCoAtt-P) and question-level (HieCoAtt-Q) attention maps; we evaluate all three maps 3 .",
  "y": "motivation"
 },
 {
  "id": "93cf4d4fd9cd875e8e148d1bbd8e2c_4",
  "x": "HieCoAtt-W<cite> (Lu et al., 2016)</cite> 0.246 \u00b1 0.004 HieCoAtt-P<cite> (Lu et al., 2016)</cite> 0.256 \u00b1 0.004 HieCoAtt-Q<cite> (Lu et al., 2016)</cite> 0.264 \u00b1 0.004 Table 2 : Mean rank-correlation coefficients (higher is better); error bars show standard error of means. HieCoAtt-W<cite> (Lu et al., 2016)</cite> 0.062 \u00b1 0.012 HieCoAtt-P<cite> (Lu et al., 2016)</cite> 0.048 \u00b1 0.010 HieCoAtt-Q<cite> (Lu et al., 2016)</cite> 0 Table 3 : Mean rank-correlation coefficients (higher is better) on the reduced set without center bias; error bars show standard error of means.",
  "y": "uses similarities"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_0",
  "x": "Wish Detection: <cite>Goldberg et al. (2009)</cite> performed wish detection on datasets obtained from political discussion forums and product reviews.",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_1",
  "x": "Wish Detection: <cite>Goldberg et al. (2009)</cite> performed wish detection on datasets obtained from political discussion forums and product reviews. <cite>They automatically extracted</cite> sentence templates from a corpus of new year wishes, and used them as features with a statistical classifier.",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_2",
  "x": "Wish Detection: <cite>Goldberg et al. (2009)</cite> performed wish detection on datasets obtained from political discussion forums and product reviews. <cite>They automatically extracted</cite> sentence templates from a corpus of new year wishes, and used them as features with a statistical classifier. None of these works aligned the problem of wish and suggestion detection with subjunctive mood, or identified features related to it. Wish and suggestion detection remain young problems, and our work contributes towards the same.",
  "y": "motivation"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_3",
  "x": "\u2022 Wish Detection Oxford dictionary defines the noun wish as, A desire or hope for something to happen. <cite>Goldberg et al. (2009)</cite> follow this definition of wish and provide <cite>manually annotated datasets</cite>, where each sentence is labelled as wish or non-wish.",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_4",
  "x": "<cite>Goldberg et al. (2009)</cite> follow this definition of wish and provide <cite>manually annotated datasets</cite>, where each sentence is labelled as wish or non-wish. <cite>Following two datasets</cite> are made available: a. <cite>Political Discussions</cite>: 6379 sentences, out of which 34% are annotated wishes. b. <cite>Product Reviews</cite>: 1235 sentences, out of which 12% are annotated as wishes. Table 1 presents some examples from <cite>these datasets</cite>.",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_5",
  "x": "Ramanand et al. (2010) worked on <cite>product review dataset</cite> of the <cite>wish corpus</cite>, with an objective to extract suggestions for improvements.",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_6",
  "x": "\u2022 Suggestion Detection Product reviews (new): We re-annotated the <cite>product review dataset</cite> from <cite>Goldberg et al. (2009)</cite> , for suggestions.",
  "y": "extends"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_7",
  "x": "\u2022 Suggestion Detection Product reviews (new): We re-annotated the <cite>product review dataset</cite> from <cite>Goldberg et al. (2009)</cite> , for suggestions. This also includes wishes for improvements and new features.",
  "y": "extends"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_9",
  "x": "5 Subjunctive Feature Evaluation <cite>Goldberg et al. (2009)</cite> evaluated <cite>their approach</cite> using a 10 fold cross validation on <cite>their datasets</cite>.",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_10",
  "x": "5 Subjunctive Feature Evaluation <cite>Goldberg et al. (2009)</cite> evaluated <cite>their approach</cite> using a 10 fold cross validation on <cite>their datasets</cite>. In order to compare subjunctive features against <cite>their wish template features</cite>, we also perform 10 fold cross validation on <cite>their wish datasets</cite> (politics and products).",
  "y": "uses"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_11",
  "x": "AUC was also used by <cite>Goldberg et al. (2009)</cite> .",
  "y": "background"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_12",
  "x": "Table 2 compares the AUC values obtained with unigrams, subjunctive features, a combination of both, and the results from <cite>Goldberg et al. (2009)</cite> for wish detection.",
  "y": "similarities differences"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_13",
  "x": "Wish Detection: Unigrams vs Subjunctive: One probable reason for the better performance of subjunctive features over unigrams in the case of <cite>product dataset</cite>, could be the small size of the dataset.",
  "y": "differences"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_14",
  "x": "In the case of <cite>politics dataset</cite>, similar reason (big dataset) can be attributed for the better performance of unigrams over subjunctive features.",
  "y": "differences"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_15",
  "x": "<cite>Goldberg et al. (2009)</cite> perform better than our subjunctive features for the politics data.",
  "y": "differences"
 },
 {
  "id": "950263323d351bcb483be7cdf15a7e_16",
  "x": "<cite>Goldberg et al. (2009)</cite> perform better than our subjunctive features for the politics data. However, subjunctive features perform much better with product data as compared to the wish templates (Table 3 ).",
  "y": "differences"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_0",
  "x": "We test our approach on the Yahoo! Answers dataset of manner or How questions introduced by<cite> Jansen et al. (2014)</cite> , who describe answer reranking experiments on this dataset using a diverse range of features incorporating syntax, lexical semantics and discourse.",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_1",
  "x": "The best performance on this dataset -33.01 P@1 and 53.96 MRR -is reported by Fried et al. (2015) who improve on the lexical semantic models of<cite> Jansen et al. (2014)</cite> by exploiting indirect associations between words using higher-order models.",
  "y": "background"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_2",
  "x": "For comparison with recent work in answer reranking<cite> (Jansen et al., 2014</cite>; Sharp et al., 2015) , we also evaluate the averaged word embedding vectors obtained with the skip-gram model (Mikolov et al., 2013 ) (henceforth referred to as the SkipAvg model).",
  "y": "uses background"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_3",
  "x": "In order to be able to compare our work with previous research, we use the Yahoo! Answers dataset that was first introduced by<cite> Jansen et al. (2014)</cite> and was later used by Sharp et al. (2015) and Fried et al. (2015) .",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_4",
  "x": "Further information about the dataset can be found in<cite> Jansen et al. (2014)</cite> .",
  "y": "background"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_5",
  "x": "In order to be able to compare our work with previous research, we use the Yahoo! Answers dataset that was first introduced by<cite> Jansen et al. (2014)</cite> and was later used by Sharp et al. (2015) and Fried et al. (2015) . Further information about the dataset can be found in<cite> Jansen et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_6",
  "x": "5 The Yahoo! Answers manner question dataset prepared by<cite> Jansen et al. (2014)</cite> and described in the previous paragraph, was initially sampled from this larger dataset.",
  "y": "background"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_7",
  "x": "For these purposes we use the L6 Yahoo! Answers Comprehensive Questions and Answers corpus obtained via Webscope. 5 The Yahoo! Answers manner question dataset prepared by<cite> Jansen et al. (2014)</cite> and described in the previous paragraph, was initially sampled from this larger dataset.",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_8",
  "x": "Following<cite> Jansen et al. (2014)</cite> and Fried et al. (2015) , we implement two baselines: the baseline that selects an answer randomly and the candidate retrieval (CR) baseline.",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_9",
  "x": "The CR baseline uses the same scoring as in<cite> Jansen et al. (2014)</cite> : the questions and the candidate answers are represented using tf-idf (Salton, 1991) over lemmas; the candidate answers are ranked according to their cosine similarity to the respective question.",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_10",
  "x": "In Table 1 , we report best development P@1 and MRR of the multilayer perceptron trained on Yahoo! Answers<cite> (Jansen et al., 2014)</cite> 200 outperforming the rest by a small margin.",
  "y": "uses"
 },
 {
  "id": "950cc4a7fa2db3aa6786cc0ae802b5_11",
  "x": "We only evaluate the 200-dimension DBOW model and its combinations with other models, comparing these to the baselines and the previous results on the same dataset (we use the same train/dev/test split as<cite> Jansen et al. (2014)</cite> ).",
  "y": "uses"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_0",
  "x": "Specifically, we find that the bias metric proposed by <cite>(Bolukbasi et al. 2016 )</cite> is highly sensitive to embedding hyperparameter selection, and that in many cases, the variance due to the selection of some hyper-parameters, notably the embedding space dimensionality, is greater than the variance in the metric due to corpus selection, while in fewer cases, even the relative rankings of the bias measured in the embedding spaces of various corpora varies with hyper-parameter selection.",
  "y": "differences"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_1",
  "x": "Initial attempts have been made to develop metrics which seek to describe the geometric properties of the embedding space with respect to various axes of interest which are empirically determined to correspond to our intuitions of the hypothetical biases under study to quantify the degrees to which various biases exist within the embedding space, and presumably, the underlying text corpus (<cite>Bolukbasi et al. 2016</cite>; Caliskan, Bryson, and Narayanan 2017; Garg et al. 2018) .",
  "y": "background"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_2",
  "x": "For instance, using such a bias measure, <cite>(Bolukbasi et al. 2016)</cite> concluded that \"word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent\".",
  "y": "background"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_3",
  "x": "In this section, we evaluate the stability of the bias measure developed in <cite>(Bolukbasi et al. 2016)</cite> which is claimed to measure societal biases in word embeddings.",
  "y": "motivation background"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_4",
  "x": "For the sake of com-pleteness, we repeat the definition of <cite>(Bolukbasi et al. 2016 )</cite>'s bias metric:",
  "y": "background"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_5",
  "x": "Figure 1 illustrates the results of <cite>(Bolukbasi et al. 2016 )</cite> bias detection algorithm for a list of profession names with word embedding vectors of dimension 256 trained using the Skipgram algorithm (Mikolov et al. 2013 ) on a sample of 23k Wikipedia articles with 50k term vocabulary. As one can observe, this bias measure identifies some profession names such as commander and nurse, which historically were predominantly male and female jobs, respectively. Moreover, we trained word embeddings with differing dimension on the same sampled Wikipedia corpus using Skip-gram algorithm, and calculated Kendall tau rank correlation coefficients for the bias metrics corresponding to terms in the above list of professions. As illustrated in Figure 2 , we found that though rankings for low dimensional embeddings were unstable, for larger dimensions (\u2265 128) rankings of the biases of the profession terms achieve superior Kendall tau scores.",
  "y": "differences"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_6",
  "x": "Next, we evaluated the stability of the direct bias measure proposed in <cite>(Bolukbasi et al. 2016)</cite> . <cite>The authors</cite> assert that the direct bias measure can be used as a metric to conclude how much an embedding is biased. For instance, for word embeddings trained on Google News articles, <cite>they</cite> reported that direct gender bias on 327 profession names is 0.08 and thus <cite>they</cite> concluded that this embedding is biased. However, as we have illustrated in Figure 3a , this bias score is not stable, i.e., direct bias measure decays exponentially with increasing word embedding dimension.",
  "y": "differences"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_8",
  "x": "We conclude that while meta analyses of the bias metrics proposed by <cite>(Bolukbasi et al. 2016)</cite> indicate that the metrics capture and somewhat quantify sociologically meaningful biases present in learned embedding spaces, the metrics are highly sensitive to the hyperparameter configurations of the algorithms used to learn them.",
  "y": "differences"
 },
 {
  "id": "95883b369c4b019fa98493a728c1a0_9",
  "x": "While it is the case that the bias metrics in <cite>(Bolukbasi et al. 2016 )</cite> may provide meaningful rankings of corpora when controlling for model hyper-parameter configuration, publishing the average absolute value of the metric without a complete account for model configuration is suspect.",
  "y": "differences"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_0",
  "x": "datato-document generation is a slightly more challenging setting in which a system generates multisentence summaries based on input data<cite> (Wiseman et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_1",
  "x": "Previous work<cite> (Wiseman et al., 2017)</cite> notices the problem and proposes an extractive metric to evaluate the consistency between the generation and its input structured data.",
  "y": "background"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_2",
  "x": "Previous work<cite> (Wiseman et al., 2017)</cite> notices the problem and proposes an extractive metric to evaluate the consistency between the generation and its input structured data. However, such consistency is not involved in the training process to guide model learning. In this paper, we propose to use a new training framework that directly incorporates consistency verification to guide the generation during the training process.",
  "y": "differences"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_3",
  "x": "We evaluate our proposed method on the RO-TOWIRE dataset<cite> (Wiseman et al., 2017)</cite> , which targets at generating multi-sentence game summaries.",
  "y": "uses"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_4",
  "x": "To extract information describing the input data from the generated texts, we apply a simple information extraction system similar to<cite> (Wiseman et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_5",
  "x": "Data: We use ROTOWIRE dataset<cite> (Wiseman et al., 2017)</cite> , which is a collection of articles summarizing NBA basketball games, paired with their corresponding box-and line-score tables.",
  "y": "uses"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_6",
  "x": "For relation extractor model, we use an ensemble of CNNs and LSTMs relation classification models<cite> (Wiseman et al., 2017)</cite> , which achieves the precision of 94.7% and recall of 75.3% given the reference.",
  "y": "uses"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_7",
  "x": "Evaluation: We use automatic evaluation metric BLEU-4 (Papineni et al., 2002) and the extractive evaluation metrics proposed by<cite> (Wiseman et al., 2017)</cite> , which contains three criteria: content selection (CS), relation generation (RG), content ordering (CO).",
  "y": "uses"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_9",
  "x": "Below: First three sentences produced by baseline and our proposed model. blue words denotes facts consistency with input, red words denotes facts contradicting with input and italic words denote facts not mentioned in input MLE training on our baseline model and achieve comparable results on ROTOWIRE dataset w.r.t. the previous work<cite> (Wiseman et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_10",
  "x": "The differences between our method and<cite> (Wiseman et al., 2017</cite> ) is that we adopt a LSTM for the encoder, while<cite> (Wiseman et al., 2017</cite> ) uses a table encoder similar to (Yang et al., 2017) .",
  "y": "differences"
 },
 {
  "id": "9655fb9abfb1c30b39f3261680fafc_11",
  "x": "3 Hand crafted templates from<cite> (Wiseman et al., 2017</cite> ), e.g. <player> scored <pts> points (<fgm>-<fga> FG, <tpm>-<tpa> 3PT, <ftm>-<fta> FT) 4 The whole game input data and the summaries are relatively lengthy, we presents the first three sentences in the summary and its corresponding game statistics for brevity.",
  "y": "uses"
 },
 {
  "id": "9731b4cea1405b7cbf3792aed5b1e4_0",
  "x": "Therefore, our setting resembles the established task of entity recognition (Finkel et al., 2005; <cite>Ratinov and Roth, 2009</cite>) , with the difference being that we focus on un-named entities.",
  "y": "differences background"
 },
 {
  "id": "9731b4cea1405b7cbf3792aed5b1e4_1",
  "x": "We treat sense recognition in text as a sequence labeling task where each sentence is a sequence of tokens labeled using the BIO tagging scheme <cite>(Ratinov and Roth, 2009 )</cite>.",
  "y": "uses"
 },
 {
  "id": "9731b4cea1405b7cbf3792aed5b1e4_2",
  "x": "Conditional Random Fields (CRFs) (Lafferty et al., 2001 ) have been widely used named entity recognition <cite>(Ratinov and Roth, 2009</cite>; Finkel et al., 2005) , a task similar to our own.",
  "y": "background"
 },
 {
  "id": "9731b4cea1405b7cbf3792aed5b1e4_3",
  "x": "For the CRF, we use the commonly used features for named entity recognition: words, prefix/suffices, and part-of-speech tag <cite>(Ratinov and Roth, 2009 )</cite>.",
  "y": "uses"
 },
 {
  "id": "9731b4cea1405b7cbf3792aed5b1e4_4",
  "x": "Entity recognition systems are traditionally based on a sequential model, for example a CRF, and involve feature engineering (Lafferty et al., 2001; <cite>Ratinov and Roth, 2009 )</cite>.",
  "y": "background"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_0",
  "x": "Textual relation (Bunescu and Mooney, 2005) , defined as the shortest path between two entities in the dependency parse tree of a sentence, has been widely shown to be the main bearer of relational information in text and proved effective in relation extraction tasks (Xu et al., 2015;<cite> Su et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_1",
  "x": "Recently<cite> Su et al. (2018)</cite> propose to leverage global co-occurrence statistics of textual and KB relations to learn embeddings of textual relations, and show that it can effectively combat the wrong labeling problem of distant supervision (see Figure 1 for example).",
  "y": "background"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_3",
  "x": "<cite>(Su et al., 2018)</cite> use global co-occurrence statistics of 1 https://github.com/czyssrs/GloREPlus textual and KB relations to effectively combat the wrong labeling problem. But the global statistics in their work is limited to NYT dataset, capturing domain-specific distributions.",
  "y": "background"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_4",
  "x": "Following <cite>(Su et al., 2018)</cite> , we then collect the global co-occurrence statistics of textual and KB relations.",
  "y": "uses"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_5",
  "x": "We also compare with using vanilla RNN in GloRE <cite>(Su et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_6",
  "x": "Following GloRE <cite>(Su et al., 2018)</cite> , we aim at augmenting existing relation extractors with the textual relation embeddings.",
  "y": "uses"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_7",
  "x": "Same as <cite>(Su et al., 2018)</cite> , we use PCNN+ATT (Lin et al., 2016 ) as our base model.",
  "y": "similarities uses"
 },
 {
  "id": "975413dd6b3d3df9c5d111d94e8eb7_8",
  "x": "As shown in previous work <cite>(Su et al., 2018)</cite> , on NYT dataset, due to a significant amount of false negatives, the PR curve on the held-out set may not be an accurate measure of performance. Therefore, we mainly employ manual evaluation.",
  "y": "motivation"
 },
 {
  "id": "976e5cf02dc5430c0b1393d3cb38e5_0",
  "x": "Although the syntax-based translation model in<cite> Galley et al. (2006)</cite> falls under the string-to-tree category, I wonder why hierarchical phrasebased SMT, or Hiero (Chiang 2007) , is not explicitly put under the string-to-string category, since Hiero also uses \"unlabeled hierarchical phrases where there is no representation of linguistic categories.\"",
  "y": "background"
 },
 {
  "id": "976e5cf02dc5430c0b1393d3cb38e5_1",
  "x": "The remainder of the chapter introduces three predominant instantiations of syntax-based models: hierarchical phrase-based SMT (Hiero) (Chiang 2007) , which is a non-labeled syntax-based SMT approach arising from the phrase-based approach; syntax-augmented machine translation (SAMT), which introduces the notion of soft labels while keeping the nonlinguistic phrase notion; and GHKM <cite>(Galley et al. 2004</cite> ), which only extracts translation rules consistent with constituency parse subtrees.",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_0",
  "x": "This assumption is often violated in reality and exemplified in the fact that the performance of the traditional RE techniques degrades significantly in such a domain mismatch case<cite> (Plank and Moschitti, 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_1",
  "x": "We here focus on the unsupervised domain adaptation (i.e., no labeled target data) and singlesystem DA (Petrov and McDonald, 2012;<cite> Plank and Moschitti, 2013)</cite> , i.e., building a single system that is able to cope with different, yet related target domains.",
  "y": "uses"
 },
 {
  "id": "97852048a123350455f398728d6d34_2",
  "x": "To the best of our knowledge, there have been only three studies on DA for RE <cite>(Plank and Moschitti, 2013</cite>; Nguyen and Grishman, 2014; .",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_3",
  "x": "In contrast,<cite> Plank and Moschitti (2013)</cite> and Nguyen and Grishman (2014) work on the unsupervised DA.",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_4",
  "x": "One way is to use word embeddings to compute similarities between words and embed these similarity scores into the kernel functions, e.g., by resembling the method of<cite> Plank and Moschitti (2013)</cite> that exploited LSA (in the semantic syntactic tree kernel (SSTK), cf.",
  "y": "uses background"
 },
 {
  "id": "97852048a123350455f398728d6d34_5",
  "x": "(ii) Between the feature-based method in Nguyen and Grishman (2014) and the SSTK method in<cite> Plank and Moschitti (2013)</cite> , which method is better for DA of RE, given the recent discovery of word embeddings for both methods?",
  "y": "background motivation"
 },
 {
  "id": "97852048a123350455f398728d6d34_6",
  "x": "In particular, while<cite> Plank and Moschitti (2013)</cite> only use the path-enclosed trees induced from the constituent parse trees as the representation for relation mentions, Nguyen and Grishman (2014) include a rich set of features extracted from multiple resources such as constituent trees, dependency trees, gazetteers, semantic resources in the representation.",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_7",
  "x": "Besides,<cite> Plank and Moschitti (2013)</cite> consider the direction of relations in their evaluation (i.e, distinguishing between relation classes and their inverses) but Nguyen and Grishman (2014) disregard this relation direction.",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_8",
  "x": "In fact, the problem of incompatible comparison is unfortunately very common in the RE literature (Wang, 2008;<cite> Plank and Moschitti, 2013)</cite> and we believe there is a need to tackle this increasing confusion in this line of research.",
  "y": "motivation"
 },
 {
  "id": "97852048a123350455f398728d6d34_9",
  "x": "In the tree kernel-based method (Moschitti, 2006; Moschitti, 2008;<cite> Plank and Moschitti, 2013)</cite> , a relation mention (the two entity mentions and the sentence containing them) is represented by the path-enclosed tree (PET), the smallest constituency-based subtree including the two target entity mentions (Zhang et al., 2006) .",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_10",
  "x": "For instance, in the following example taken from<cite> Plank and Moschitti (2013)</cite> , the two fragments \"governor from Texas\" and \"head of Mary-land\" would not match in STK although they have very similar syntactic structures and basically convey the same relationship.",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_11",
  "x": "In order to ensure the two methods <cite>(Plank and Moschitti, 2013</cite>; Nguyen and Grishman, 2014 ) are compared compatibly on the same resources, we make sure the two systems have access to the same amount of information.",
  "y": "uses"
 },
 {
  "id": "97852048a123350455f398728d6d34_12",
  "x": "Thus, we follow<cite> Plank and Moschitti (2013)</cite> and use the PET trees (beside word clusters and word embeddings) as the only resource the two methods can exploit.",
  "y": "uses"
 },
 {
  "id": "97852048a123350455f398728d6d34_13",
  "x": "In particular, one limitation of the syntactic semantic tree kernel presented in<cite> Plank and Moschitti (2013)</cite> ( \u00a72.1) is that semantics is highly tied to syntax (the PET trees) in the kernel computation, limiting the generalization capacity of semantics to the extent of syntactic matches.",
  "y": "background motivation"
 },
 {
  "id": "97852048a123350455f398728d6d34_14",
  "x": "SIM: Finally, for completeness, we experiment with a more obvious way to introduce word embeddings into tree kernels, resembling more closely the approach of<cite> Plank and Moschitti (2013)</cite> .",
  "y": "similarities"
 },
 {
  "id": "97852048a123350455f398728d6d34_15",
  "x": "We use the word clusters trained by<cite> Plank and Moschitti (2013)</cite> on the ukWaC corpus (Baroni et al., 2009 ) with 2 billion words, and the C&W word embeddings from Turian el al. (2010) 2 with 50 dimensions following Nguyen and Grishman (2014) .",
  "y": "uses"
 },
 {
  "id": "97852048a123350455f398728d6d34_16",
  "x": "In order to make the comparisons compatible, we introduce word embeddings into the tree kernel by extending the package provided by<cite> Plank and Moschitti (2013)</cite> , which uses the Charniak parser to obtain the constituent trees, the SVM-light-TK for the SSTK kernel in SVM, the directional relation classes, etc.",
  "y": "extends"
 },
 {
  "id": "97852048a123350455f398728d6d34_17",
  "x": "The dataset partition is exactly the same as in<cite> Plank and Moschitti (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "97852048a123350455f398728d6d34_18",
  "x": "In particular, we take the systems using the PET trees, word clusters and LSA in<cite> Plank and Moschitti (2013)</cite> as the baselines and augment them with the embeddings WED = HEAD+PHRASE.",
  "y": "extends"
 },
 {
  "id": "97852048a123350455f398728d6d34_19",
  "x": "Third and most importantly, for all the systems in<cite> Plank and Moschitti (2013)</cite> (the baselines) and for all the target domains, whether word clusters and LSA are utilized or not, we consistently witness the performance improvement of the baselines when combined with word embedding (comparing systems X and X+WED where X is some baseline system).",
  "y": "differences"
 },
 {
  "id": "97852048a123350455f398728d6d34_20",
  "x": "To be more concrete, the best system with word embeddings (row 12 in Table 2 ) significantly outperforms the best system in<cite> Plank and Moschitti (2013)</cite> with p < 0.05, an improvement of 3.7%, 1.1% and 2.7% on the target domains bc, cts and wl respectively, demonstrating the benefit of word embeddings for DA of RE in the tree kernel-based method.",
  "y": "differences"
 },
 {
  "id": "97852048a123350455f398728d6d34_21",
  "x": "This section aims to compare the tree kernel-based method in<cite> Plank and Moschitti (2013)</cite> and the feature-based method in Nguyen and Grishman (2014) for DA of RE on the same settings (i.e, same dataset partition, the same pre-processing Table 3 : Tree kernel-based in<cite> Plank and Moschitti (2013)</cite> vs feature-based in Nguyen and Grishman (2014) .",
  "y": "uses"
 },
 {
  "id": "97852048a123350455f398728d6d34_22",
  "x": "Word Embeddings for the Tree-kernel based Method We focus on the comparison of the best model in<cite> Plank and Moschitti (2013)</cite> (row 11 in Table 2 ) (called P) with the same model but augmented with the embedding WED (row 12 in Tabel 2) (called P+WED).",
  "y": "extends"
 },
 {
  "id": "97852048a123350455f398728d6d34_23",
  "x": "However, as shown by<cite> Plank and Moschitti (2013)</cite> , instance weighting is not very useful for DA of RE.",
  "y": "background"
 },
 {
  "id": "97852048a123350455f398728d6d34_24",
  "x": "The method demonstrates strong promise for the DA of RE, i.e, it significantly improves the best system of<cite> Plank and Moschitti (2013)</cite> (up to 7% relative improvement).",
  "y": "differences"
 },
 {
  "id": "97852048a123350455f398728d6d34_25",
  "x": "Moreover, we perform a compatible comparison between the tree kernel-based method and the feature-based method on the same settings and resources, which suggests that the tree kernel-based method<cite> (Plank and Moschitti, 2013)</cite> is better than the feature-based method (Nguyen and Grishman, 2014) for DA of RE.",
  "y": "uses"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_0",
  "x": "<cite>Aharoni and Goldberg (2018)</cite> improve WebSplit by reducing overlap in the data splits, and * Both authors contributed equally.",
  "y": "background"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_1",
  "x": "\u2022 By incorporating WikiSplit into training, we more than double (30.5 to 62.4) the BLEU score obtained on WebSplit by <cite>Aharoni and Goldberg (2018)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_2",
  "x": "Our extraction heuristic is imperfect, so we manually assess corpus quality using the same categorization schema proposed by <cite>Aharoni and Goldberg (2018)</cite> ; see Table 1 for examples of correct, unsupported and missing sentences in splits extracted from Wikipedia.",
  "y": "similarities uses"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_3",
  "x": "Text-to-text training instances are defined as all the unique pairs of (C, S), where C is a complex sentence and S is its simplification into multiple simple sentences<cite> Aharoni and Goldberg, 2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_4",
  "x": "We use the same sequence-to-sequence architecture that produced the top result for <cite>Aharoni and Goldberg (2018)</cite> , \"Copy512\", which is a one-layer, bi-directional LSTM (cell size 512) with attention (Bahdanau et al., 2014 ) and a copying mechanism (See et al., 2017 ) that dynamically interpolates the standard word distribution with a distribution over the words in the input sentence.",
  "y": "similarities uses"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_5",
  "x": "Training details are as described in the Appendix of <cite>Aharoni and Goldberg (2018)</cite> using the OpenNMT-py framework (Klein et al., 2017) .",
  "y": "similarities uses"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_6",
  "x": "5 Past work on WebSplit<cite> Aharoni and Goldberg, 2018)</cite> reported macro-averaged sentence-level BLEU, calculated without smoothing precision values of zero.",
  "y": "differences"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_7",
  "x": "AG18 is the previous best model by <cite>Aharoni and Goldberg (2018)</cite> , which used the full WebSplit training set, whereas we downsampled it.",
  "y": "extends differences"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_8",
  "x": "Our manual evaluation includes the corresponding outputs from <cite>Aharoni and Goldberg (2018)</cite> (AG18), which were 22% accurate.",
  "y": "uses"
 },
 {
  "id": "983ef31a44646d8e6276ee1933e41d_9",
  "x": "Our best performance in BLEU is again obtained by combining the proposed WikiSplit dataset with the downsampled WebSplit, yielding <cite>Aharoni and Goldberg (2018)</cite> , while the other outputs are from our models trained on the corresponding data.",
  "y": "extends differences"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_0",
  "x": "We introduce a very simple change to the loss function used in the original formulation by<cite> Kiros et al. (2014)</cite> , which leads to drastic improvements in the retrieval performance.",
  "y": "extends"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_1",
  "x": "On Flickr30K, we more than double R@1 as reported by<cite> Kiros et al. (2014)</cite> in both image and caption retrieval, and achieve near state-of-the-art performance.",
  "y": "differences"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_2",
  "x": "Learning such embeddings using powerful neural networks has led to significant advancements in image-caption retrieval and generation<cite> Kiros et al. (2014)</cite> ; Karpathy & Fei-Fei (2015) , video-to-text alignment Zhu et al. (2015) , and question-answering Malinowski et al. (2015) .",
  "y": "background"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_3",
  "x": "This paper investigates the visual-semantic embeddings (VSE) of<cite> Kiros et al. (2014)</cite> for imagecaption retrieval.",
  "y": "uses"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_4",
  "x": "Works such as<cite> Kiros et al. (2014)</cite> , Karpathy & Fei-Fei (2015) , Zhu et al. (2015) , Socher et al. (2014) use a rank loss to learn the joint visual-semantic embedding.",
  "y": "background"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_5",
  "x": "Our work builds upon the work by<cite> Kiros et al. (2014)</cite> , in which the authors use a rank loss to optimize the embedding.",
  "y": "extends"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_6",
  "x": "Our work builds on Visual-Semantic Embeddings<cite> Kiros et al. (2014)</cite> .",
  "y": "extends"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_7",
  "x": "We define the similarity measure s(i, c) in the joint embedding space following<cite> Kiros et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_9",
  "x": "The rank loss used in<cite> Kiros et al. (2014)</cite> , Socher et al. (2014) , and Karpathy & Fei-Fei (2015) is defined as follows: where \u03b1 represents the margin,\u0109 denotes a negative caption for the query image i, and\u00ee a negative image for the query caption c. Here, we used a shorthand notation [x] + \u2261 max(x, 0).",
  "y": "uses"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_10",
  "x": "Note that since we use SGD to learn our parameters, we take the max over each mini-batch (this is similar to<cite> Kiros et al. (2014)</cite> , while empty circles are negative samples for the query i. The dashed circles on the two sides are drawn at the same radii.",
  "y": "similarities"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_11",
  "x": "We perform experiments with our VSE++ and compare it to the original formulation of<cite> Kiros et al. (2014)</cite> (referred to as VSE), as well as state-of-the-art approaches.",
  "y": "uses"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_12",
  "x": "For the caption encoder, we use a GRU similar to the one used in<cite> Kiros et al. (2014)</cite> .",
  "y": "similarities"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_13",
  "x": "We further note that in<cite> Kiros et al. (2014)</cite> , the caption embedding is normalized, while the image embedding is not.",
  "y": "background"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_14",
  "x": "We further note that in<cite> Kiros et al. (2014)</cite> , the caption embedding is normalized, while the image embedding is not. In VSE++ we normalize both vectors.",
  "y": "differences"
 },
 {
  "id": "9aa9fa6b94aa24939b50effa0e575b_15",
  "x": "We have shown that a new loss function that uses only violation incurred by hard negatives drastically improves performance over the typical loss that sums the violations across the negatives, typically used in previous work <cite>(Kiros et al. (2014)</cite> ; Vendrov et al. (2015) ).",
  "y": "differences"
 },
 {
  "id": "9ac581130218d6c68ca785e3d5ba99_0",
  "x": "The author found in the investigations of his thesis (Manion, 2014) that the iterative approach performed best on the SemEval 2013 Multilingual WSD Task <cite>(Navigli et al., 2013)</cite> , as opposed to earlier tasks such as SensEval 2004 English All Words WSD Task (Snyder and Palmer, 2004) and the SemEval 2010 All Words WSD task on a Specific Domain (Agirre et al., 2010) .",
  "y": "background"
 },
 {
  "id": "9ac581130218d6c68ca785e3d5ba99_1",
  "x": "In the previous SemEval WSD task <cite>(Navigli et al., 2013)</cite> team UMCC DLSI (Gutierrez et al., 2013) implemented this method and achieved the best performance by biasing probability mass based on SemCor (Miller et al., 1993 ) sense frequencies.",
  "y": "background"
 },
 {
  "id": "9ac581130218d6c68ca785e3d5ba99_2",
  "x": "The author could not improve on their superior results achieved in English, however for Spanish and Italian the BabelNet First Sense (BFS) baseline was much lower since it often resorted to lexicographic sorting in the absence of WordNet synsets -see <cite>(Navigli et al., 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "9af4a895dd4b45bb3827c74bdc7f05_0",
  "x": "Very recently, however, Somasundaran and Chodorow (2014) and <cite>Somasundaran et al. (2015)</cite> Even if these results were extremely promising, they leave a number of questions unanswered.",
  "y": "motivation"
 },
 {
  "id": "9af4a895dd4b45bb3827c74bdc7f05_1",
  "x": "In order to extract more information from the distribution of the ASs in each text than the mean or the median, Durrant and Schmitt (2009) and <cite>Somasundaran et al. (2015)</cite> used a standard procedure in descriptive statistics and automatic information processing known as discretization, binning or quantization (Garcia et al., 2013) .",
  "y": "background"
 },
 {
  "id": "9af4a895dd4b45bb3827c74bdc7f05_2",
  "x": "Collocational Features: The global statistical features in <cite>Somasundaran et al. (2015)</cite> and were used: the mean, the median, the maximum and the minimum of the ASs, and the proportion of bigrams that are present in the learner text but absent from the reference corpus.",
  "y": "uses"
 },
 {
  "id": "9af4a895dd4b45bb3827c74bdc7f05_3",
  "x": "To determine if the automatic procedure for discretizing the ASs is at least as effective as the bin boundaries manually set by <cite>Somasundaran et al. (2015)</cite> , I used them instead of the automatic bins for the model with eight bins based on MI.",
  "y": "uses"
 },
 {
  "id": "9af4a895dd4b45bb3827c74bdc7f05_4",
  "x": "Unlike <cite>Somasundaran et al. (2015)</cite> , I only used bigrams' collocational features.",
  "y": "differences"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_0",
  "x": "Recent attempts to solve this task deal with proposing similarity measures based on distributional semantic models (Roller et al., 2014; Weeds et al., 2014;<cite> Santus et al., 2016</cite>; Shwartz et al., 2017; Roller and Erk, 2016) .",
  "y": "background"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_1",
  "x": "<cite>Santus et al. (2016)</cite> proposed a supervised method based on a Random Forest algorithm to learn taxonomical semantic relations and they have shown that the model performs well for co-hyponymy detection.",
  "y": "background"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_2",
  "x": "Evaluation results: We evaluate the usefulness of DT embeddings against three benchmark datasets for cohyponymy detection (Weeds et al., 2014;<cite> Santus et al., 2016</cite>; Jana and Goyal, 2018b) , following their experimental setup.",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_3",
  "x": "Evaluation results: We evaluate the usefulness of DT embeddings against three benchmark datasets for cohyponymy detection (Weeds et al., 2014;<cite> Santus et al., 2016</cite>; Jana and Goyal, 2018b) , following their experimental setup. We show that the network embeddings outperform the baselines by a huge margin throughout all the experiments, except for co-hyponyms vs. random pairs, where the baselines already have very high accuracy and network embeddings are able to match the results.",
  "y": "differences"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_4",
  "x": "We perform experiments using three benchmark datasets for co-hyponymy detection (Weeds et al., 2014;<cite> Santus et al., 2016</cite>; Jana and Goyal, 2018b) .",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_5",
  "x": "We perform the analysis of three datasets to investigate the extent of overlap present in these publicly available benchmark datasets and find out that 45.7% word pairs of dataset prepared by Weeds et al. (2014) are present in dataset ROOT9 prepared by <cite>Santus et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_7",
  "x": "Co-Hyp vs Hyper<cite> (Santus et al., 2016)</cite> 97.8 95.7 (Jana and Goyal, 2018b) 99 Table 4 : Percentage F1 scores on a ten-fold cross validation of our models along with the best models described in<cite> (Santus et al., 2016)</cite> and (Jana and Goyal, 2018b) for ROOT9 dataset a set of baseline methodologies, the descriptions of which are presented in Table 1 . Following the same experimental setup, we report the accuracy measure for ten-fold cross validation and compare our models with the baselines in proposed by Weeds et al. (2014) .",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_8",
  "x": "3.2. Experiment-2<cite> (Santus et al., 2016)</cite> In the second experiment, we use ROOT9 dataset prepared by <cite>Santus et al. (2016)</cite> , containing 9,600 labeled pairs extracted from three datasets: EVALution (Santus et al., 2015) , Lenci/Benotto (?) and BLESS (Baroni and Lenci, 2011) .",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_9",
  "x": "Following the same experimental setup as<cite> (Santus et al., 2016)</cite> , we report percentage F1 scores on a ten-fold cross validation for binary classification of co-hyponyms vs random pairs, as well as co-hyponyms vs. hypernyms using both SVM and Random Forest classifiers.",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_10",
  "x": "Table 4 represents the performance comparison of our models with the best stateof-the-art models reported in<cite> (Santus et al., 2016)</cite> and (Jana and Goyal, 2018b) .",
  "y": "uses"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_11",
  "x": "Here, the best model proposed by <cite>Santus et al. (2016)</cite> uses Random Forest classifier which is fed with nine corpus based features like frequency of words, co-occurrence frequency etc., and the best model proposed by Jana and Goyal (2018b) use Random Forest classifier which is fed with five complex network features like structural similarity, shortest path etc.",
  "y": "background"
 },
 {
  "id": "9b203bfa690c4a79c1324360a4b8dc_12",
  "x": "Here, the best model proposed by <cite>Santus et al. (2016)</cite> uses Random Forest classifier which is fed with nine corpus based features like frequency of words, co-occurrence frequency etc., and the best model proposed by Jana and Goyal (2018b) use Random Forest classifier which is fed with five complex network features like structural similarity, shortest path etc. The results in Table 4 shows that, for the binary classification task of co-hyponymy vs random pairs, we achieve percentage F1 score of 99.0 with RF CC which is at par with the state-of-the-art models.",
  "y": "similarities"
 },
 {
  "id": "9b594c5b29175fc8ee598f61609c79_0",
  "x": "In previous work, we have also studied the problem of predicting topic boundaries at dierent levels of granularity and showed that a supervised classication approach performs better on predicting a coarser level of topic segmentation <cite>(Hsueh et al., 2006</cite>",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_0",
  "x": "Recently, sequence-to-sequence models<cite> [Sutskever et al., 2014</cite>; have gain superior performance in machine translation Vaswani et al., 2017 ].",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_1",
  "x": "Recently, sequence-to-sequence models<cite> [Sutskever et al., 2014</cite>; have gain superior performance in machine translation Vaswani et al., 2017 ]. Yet these state-of-the-art neural machine translation (NMT) models still fail to generation target sentences with comparable quality as human translators.",
  "y": "background motivation"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_2",
  "x": "For example, previous interactive NMT [ Sanchis-Trilles et al., 2014; Alvaro Peris et al., 2016;<cite> Knowles and Koehn, 2016]</cite> proposes to ask human to revise the translation output from the beginning of a sentence to the end (i.e. from the left to right), and regenerates the partial translation on the right side of the * Equal contribution, part of this work was done while Rongxiang Weng was a research intern at ByteDance AI Lab.",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_3",
  "x": "be directly applied to current uni-directional NMT models, because after revising critical mistakes, uni-directional interactive models cannot correct minor mistakes to the left of the revision, even with advanced decoding algorithm [Hokamp and Liu, 2017; Post and Vilar, 2018;<cite> Hasler et al., 2018]</cite> .",
  "y": "background motivation"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_4",
  "x": "Different from previous work about bi-directional decoder Mou et al., 2016;<cite> Liu et al., 2018]</cite> , our method is designed to take human revisions for interactive NMT.",
  "y": "differences"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_5",
  "x": "Neural machine translation (NMT) is based on a standard Seq2Seq model, which adopts an encoder-decoder architecture for sentence modeling and generation<cite> [Sutskever et al., 2014</cite>; Vaswani et al., 2017] .",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_7",
  "x": "Here \u2212 \u2192 f is a recurrent unit or self-attention network [Vaswani et al., 2017] . c j is a vector summarizing relevant source information. It is computed by the attention mechanism<cite> [Luong et al., 2015b</cite>; Vaswani et al., 2017] .",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_8",
  "x": "Following previous work<cite> [\u00c1lvaro Peris et al., 2016</cite>;<cite> Knowles and Koehn, 2016</cite>; Cheng et al., 2016] , we focus on the replacement and others can be implemented with several replacement operations.",
  "y": "uses"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_9",
  "x": "Uni-directional interactive model only updates the right part<cite> [\u00c1lvaro Peris et al., 2016</cite>;<cite> Knowles and Koehn, 2016]</cite> , ignoring potential mistakes in the left part, which means the revised word should always be the left most error, otherwise the errors in the left part will never be corrected.",
  "y": "motivation background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_10",
  "x": "Uni-directional interactive model only updates the right part<cite> [\u00c1lvaro Peris et al., 2016</cite>;<cite> Knowles and Koehn, 2016]</cite> , ignoring potential mistakes in the left part, which means the revised word should always be the left most error, otherwise the errors in the left part will never be corrected. We purpose a sequential bi-directional decoder for interactive NMT, which can update both parts of the sentence.",
  "y": "differences"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_11",
  "x": "The training stage is similar with multi-task models [Dong et al., 2015; <cite>Luong et al., 2015a]</cite> , both decoders could be trained using cross-entropy as the objective:",
  "y": "similarities"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_12",
  "x": "To solve the problem, we propose to combine the grid beam search<cite> [Hokamp and Liu, 2017]</cite> with our bi-directional decoder.",
  "y": "extends"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_13",
  "x": "When generating a word in decoding, the model will read the revision memory, trying to automatically fix mistakes with a copy mechanism<cite> [Gu et al., 2016]</cite> .",
  "y": "uses"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_14",
  "x": "By learning from the sentence level interaction history, our Seq2Seq model better fits We measure the translation quality with the IBM-BLEU score<cite> [Papineni et al., 2002]</cite> .",
  "y": "uses"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_15",
  "x": "Following previous work [Cheng et al., 2016;<cite> \u00c1lvaro Peris et al., 2016</cite>;<cite> Hokamp and Liu, 2017]</cite> , we experiment on both the ideal and real environments.",
  "y": "uses"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_16",
  "x": "Interactive machine translation has been widely exploited to improve the translation by using interaction feedback from human users<cite> [Langlais et al., 2000</cite>; Simard et al., 2007; Barrachina et al., 2009; Gonz\u00e1lez-Rubio et al., 2013; Cheng et al., 2016] in statistic machine translation (SMT) [Yamada and Knight, 2001;<cite> Koehn et al., 2003</cite>; Chiang, 2007] .",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_17",
  "x": "Barrachina et al. [2009] , Gonz\u00e1lez-Rubio et al. [2013] and<cite> Knowles and Koehn [2016]</cite> present an interactive NMT model with the uni-directional interaction protocol (UniDiR), in which users can only interact with the model from left to right.",
  "y": "background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_18",
  "x": "Barrachina et al. [2009] , Gonz\u00e1lez-Rubio et al. [2013] and<cite> Knowles and Koehn [2016]</cite> present an interactive NMT model with the uni-directional interaction protocol (UniDiR), in which users can only interact with the model from left to right. In our proposed model, human can revise the most critical mistake first in arbitrary position of the sentence; and after that the whole sentence will updated, fixing minor mistakes automatically.",
  "y": "differences background"
 },
 {
  "id": "9b6c02d11028b5bf3813a7d61fed28_19",
  "x": "Our proposed revision memory is inspired by the CopyNet<cite> [Gu et al., 2016]</cite> and history cache [Tu et al., 2017] , which only focus on better using source or global context in supervised learning, and is different from our model.",
  "y": "differences motivation"
 },
 {
  "id": "9c3c35343aeaae0520d92f64e118a2_0",
  "x": "At <cite>(Chen et al., 2017)</cite> , a Chinese dataset for aspectbased sentiment analysis from comments about the news with 6365 positive, 9457 neutral and 6839 negative annotated data samples was proposed.",
  "y": "background"
 },
 {
  "id": "9c3c35343aeaae0520d92f64e118a2_1",
  "x": "\uf0b7 RAM <cite>(Chen et al., 2017)</cite> : This method makes a memory from the input and with using multiple attention mechanism, it extracts important information from memory and for prediction it uses a combination of the extracted features of different attentions non-linearly.",
  "y": "background"
 },
 {
  "id": "9c3c35343aeaae0520d92f64e118a2_2",
  "x": "Table 3 compares the performance of these models on English datasets based on f1 score macro and accuracy metrics. \uf0b7 RAM <cite>(Chen et al., 2017)</cite> : This method makes a memory from the input and with using multiple attention mechanism, it extracts important information from memory and for prediction it uses a combination of the extracted features of different attentions non-linearly.",
  "y": "uses background"
 },
 {
  "id": "9c3c35343aeaae0520d92f64e118a2_3",
  "x": "The authors of RAM <cite>(Chen et al., 2017)</cite> claimed that their model is language insensitive, which mean it can perform on all languages and, compared to TD-LSTM (Tang et al., 2016) which might lose feature if the opinion word is far from the target, they employed the recurrent attention to solving this problem.",
  "y": "background"
 },
 {
  "id": "9c3c35343aeaae0520d92f64e118a2_4",
  "x": "The authors of RAM <cite>(Chen et al., 2017)</cite> claimed that their model is language insensitive, which mean it can perform on all languages and, compared to TD-LSTM (Tang et al., 2016) which might lose feature if the opinion word is far from the target, they employed the recurrent attention to solving this problem. But by comparing results, it's obvious that TD-LSTM (Tang et al., 2016) outperforms their method in Persian.",
  "y": "differences"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_0",
  "x": "The analyses have focused on wordlevel models, yet character-level models have been shown to outperform word-level models in some NLP tasks, such as text classification (Zhang et al., 2015) , named entity recognition (Kuru et al., 2016) , and time normalization<cite> (Laparra et al., 2018a)</cite> .",
  "y": "background"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_1",
  "x": "The analyses have focused on wordlevel models, yet character-level models have been shown to outperform word-level models in some NLP tasks, such as text classification (Zhang et al., 2015) , named entity recognition (Kuru et al., 2016) , and time normalization<cite> (Laparra et al., 2018a)</cite> . Thus, there is a need to study pre-trained contextualized character embeddings, to see if they also yield improvements, and if so, to analyze where those benefits are coming from.",
  "y": "motivation"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_2",
  "x": "We focus on the task of parsing time normalizations (Laparra et al., 2018b) , where large gains of character-level models over word-level models have been observed<cite> (Laparra et al., 2018a)</cite> .",
  "y": "uses background"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_3",
  "x": "We first take a state-of-the-art neural network for parsing time normalizations<cite> (Laparra et al., 2018a)</cite> and replace its randomly initialized character embeddings with pre-trained contextual character embeddings.",
  "y": "extends"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_4",
  "x": "\u2022 We derive pre-trained contextual character embeddings from Flair (Akbik et al., 2018) , apply them to a state-of-the art time normalizer<cite> (Laparra et al., 2018a)</cite> , and obtain major performance improvements over the previous state-of-the-art: 51% error reduction in news and 33% error reduction in clinical notes.",
  "y": "uses"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_6",
  "x": "In this paper, We focus on the character-level time entity identifier that is the foundation of <cite>Laparra et al. (2018a)</cite> 's model.",
  "y": "uses"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_7",
  "x": "There are three types of outputs per <cite>Laparra et al. (2018a)</cite> 's encoding of the SCATE schema, so there is a separate stack of bi-GRUs and a softmax for each output type.",
  "y": "background"
 },
 {
  "id": "9c5baf669470fe4dd18277591591f1_8",
  "x": "We keep the original neural architecture and parameter settings in <cite>Laparra et al. (2018a)</cite> , and experiment with the following embedding layers: Rand(128): the original setting of <cite>Laparra et al. (2018a)</cite> , where 128-dimensional character embeddings are randomly initialized.",
  "y": "extends"
 },
 {
  "id": "9d12c4d6aea96ff3e1b93faf1eb961_0",
  "x": "This tutorial introduces the advances in deep Bayesian learning with abundant applications for natural language understanding ranging from speech recognition (Saon and Chien, 2012; Chan et al., 2016) to document summarization (Chang and Chien, 2009 ), text classification (Blei et al., 2003; Zhang et al., 2015) , text segmentation (Chien and Chueh, 2012) , information extraction (Narasimhan et al., 2016) , image caption generation (Vinyals et al., 2015; Xu et al., 2015) , sentence generation (Li et al., 2016b) , dialogue control <cite>(Zhao and Eskenazi, 2016</cite>; Li et al., 2016a) , sentiment classification, recommendation system, question answering (Sukhbaatar et al., 2015) and machine translation , to name a few.",
  "y": "background"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_0",
  "x": "In order to make it compatible with the previous work, we follow the procedure in<cite> (Nguyen and Grishman, 2015b)</cite> to process the trigger candidates for CNN.",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_1",
  "x": "3. The real-valued embedding vector for the entity type of w i : This vector is generated by looking up the entity type embedding table (initialized randomly) for the entity type of w i . Note that we employ the BIO annotation schema to assign entity type labels to each token in the sentences using the entity mention heads as in<cite> (Nguyen and Grishman, 2015b)</cite> .",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_2",
  "x": "We apply the same parameters and resources as<cite> (Nguyen and Grishman, 2015b)</cite> to ensure the compatible comparison.",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_3",
  "x": "Following the previous studies (Li et al., 2013; Chen et al., 2015;<cite> Nguyen and Grishman, 2015b)</cite> , we evaluate the models on the ACE 2005 corpus with 33 event subtypes.",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_4",
  "x": "All the data preprocessing and evaluation criteria follow those in<cite> (Nguyen and Grishman, 2015b)</cite>.",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_6",
  "x": "We compares the non-consecutive CNN model (NC-CNN) with the state-of-the-art systems on the ACE 2005 dataset in Table 1 . These systems include: 2) The neural network models, i.e, the CNN model in<cite> (Nguyen and Grishman, 2015b)</cite> (CNN), the dynamic multi-pooling CNN model (DM-CNN) in (Chen et al., 2015) and the bidirectional recurrent neural networks (B-RNN) in (Nguyen et al., 2016a) .",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_7",
  "x": "Finally, comparing NC-CNN and the CNN model in<cite> (Nguyen and Grishman, 2015b)</cite>, we see that the non-consecutive mechanism significantly improves the performance of the traditional CNN model for ED (up to 2.3% in absolute Fmeasures with p < 0.05).",
  "y": "differences"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_8",
  "x": "The best reported system in the DA setting for ED is<cite> (Nguyen and Grishman, 2015b)</cite> , which demonstrated that the CNN model outperformed the feature-based models in the cross-domain setting.",
  "y": "background"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_9",
  "x": "In this section, we compare NC-CNN with the CNN model in<cite> (Nguyen and Grishman, 2015b)</cite> (as well as the other models above) in the DA setting to further investigate their effectiveness.",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_10",
  "x": "Following<cite> (Nguyen and Grishman, 2015b)</cite>, we use news (the union of bn and nw) as the source domain and bc, cts, wl and un as four different target domains 3 .",
  "y": "uses"
 },
 {
  "id": "9dd9ac975c6f55797615f0e52aa296_11",
  "x": "We emphasize that the performance of the systems MaxEnt, Joint+Local, Joint+Local+Global, B-RNN, and CNN is obtained from the actual systems in the original work (Li et al., 2013; <cite>Nguyen and Grishman, 2015b</cite>; Nguyen et al., 2016a) .",
  "y": "uses"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_0",
  "x": "The work of <cite>Shwartz et al. (2016)</cite> , that we closely follow, is also using both semantic and syntactic features, by combining the dependency paths between entities, with word embedding representations of both the entities and the lemmas in the dependency paths.",
  "y": "uses similarities"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_1",
  "x": "This is the approach that <cite>Shwartz et al. (2016)</cite> and the current work follow.",
  "y": "uses"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_2",
  "x": "A recent paper<cite> (Shwartz et al., 2016)</cite> proposed HypeNET, a new method for RE that integrated dependency path information with distributional semantic vector representation of the entities.",
  "y": "background"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_3",
  "x": "The bottom half of Figure 1 presents the distant supervision generation process adapted from <cite>Shwartz et al. (2016)</cite> to work with our data.",
  "y": "extends"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_4",
  "x": "Following <cite>Shwartz et al. (2016)</cite> , we use a 4:1 negative to positive ratio.",
  "y": "uses"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_5",
  "x": "To discover the effectiveness of the approach of <cite>Shwartz et al. (2016)</cite> , we wanted to separate HypeNET's neural architecture from its input features and use those features with different (and simpler) classifiers.",
  "y": "motivation"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_6",
  "x": "As our goal was to generate discrete features to be used with more traditional classifiers, we opted for using Brown clusters (Brown et al., 1992) instead of the 50-dimensional GloVe vectors (Pennington et al., 2014) used by <cite>Shwartz et al. (2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_10",
  "x": "In <cite>Shwartz et al. (2016)</cite> , the grouping was performed by the mean pooling layer; in the case of the fastText-based system, we simply concatenate the feature tokens from all the supports and feed them into the single hidden layer.",
  "y": "differences"
 },
 {
  "id": "9e0a44722390d0508fbe56785701e6_12",
  "x": "We also looked at the role of the dependency path satellite nodes (words to the left and right of the entities). This type of features has also been adopted by various systems including Mintz et al. (2009) and <cite>Shwartz et al. (2016)</cite> , and we wanted to establish a basis for its effectiveness across multiple relations.",
  "y": "similarities uses"
 },
 {
  "id": "9e491cad55265802275e9aaea9faae_0",
  "x": "In sentence-level QA, the task is to pick sentences that are most relevant to the question among a list of candidates <cite>(Yang et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "9e491cad55265802275e9aaea9faae_1",
  "x": "For the target datasets, we evaluate on two recent QA datasets, WikiQA <cite>(Yang et al., 2015)</cite> and Se-mEval 2016 (Task 3A) , which possess sufficiently different characteristics from that of SQuAD.",
  "y": "uses"
 },
 {
  "id": "9e491cad55265802275e9aaea9faae_2",
  "x": "The recent advances in neural question answering lead to numerous datasets and successful models in these paradigms (Rajpurkar et al., 2016;<cite> Yang et al., 2015</cite>; Nguyen et al., 2016; Trischler et al., 2016 ).",
  "y": "background"
 },
 {
  "id": "9e491cad55265802275e9aaea9faae_3",
  "x": "WikiQA <cite>(Yang et al., 2015)</cite> is a sentence-level QA dataset, containing 1.9k/0.3k train/dev answerable examples.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_0",
  "x": "Spell checkers, typically developed for native speakers, fail to address many of the types of spelling errors peculiar to non-native speakers, especially those errors influenced by differences in phonology. Our model of pronunciation variation is used to extend a pronouncing dictionary for use in the spelling correction algorithm developed by <cite>Toutanova and Moore (2002)</cite>, which includes models for both orthography and pronunciation.",
  "y": "extends motivation"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_1",
  "x": "Our model of pronunciation variation is used to extend a pronouncing dictionary for use in the spelling correction algorithm developed by <cite>Toutanova and Moore (2002)</cite>, which includes models for both orthography and pronunciation.",
  "y": "extends"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_2",
  "x": "The pronunciation variation model is used to generate multiple pronunciations for each canonical pronunciation in a pronouncing dictionary and these variations are used in the spelling correction approach developed by <cite>Toutanova and Moore (2002)</cite> , which uses statistical models of spelling errors that consider both orthography and pronunciation.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_3",
  "x": "We propose a method for creating a model of pronunciation variation from a phonetically untranscribed corpus of read speech recorded by nonnative speakers. The pronunciation variation model is used to generate multiple pronunciations for each canonical pronunciation in a pronouncing dictionary and these variations are used in the spelling correction approach developed by <cite>Toutanova and Moore (2002)</cite> , which uses statistical models of spelling errors that consider both orthography and pronunciation.",
  "y": "motivation"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_4",
  "x": "<cite>Toutanova and Moore (2002)</cite> extend Brill and Moore (2000) to consider edits over both letter sequences and sequences of phones in the pronunciations of the word and misspelling.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_5",
  "x": "The spelling correction models from Brill and Moore (2000) and <cite>Toutanova and Moore (2002)</cite> use the noisy channel model approach to determine the types and weights of edit operations.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_6",
  "x": "<cite>Toutanova and Moore (2002)</cite> describe an extension to Brill and Moore (2000) where the same noisy channel error model is used to model phone sequences instead of letter sequences.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_8",
  "x": "Since a spelling correction model needs to rank candidate words rather than candidate pronunciations, <cite>Toutanova and Moore (2002)</cite> derive an error model that determines the probability that a word w was spelled as the non-word r based on their pronunciations.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_9",
  "x": "Like <cite>Toutanova and Moore (2002)</cite> , we use the n-gram LTP model from Fisher (1999) to predict these pronunciations.",
  "y": "uses"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_10",
  "x": "The pronunciationbased spelling correction approach developed in <cite>Toutanova and Moore (2002)</cite> requires a list of possible pronunciations in order to compare the pronunciation of the misspelling to the pronunciation of correct words.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_11",
  "x": "The pronunciationbased spelling correction approach developed in <cite>Toutanova and Moore (2002)</cite> requires a list of possible pronunciations in order to compare the pronunciation of the misspelling to the pronunciation of correct words. To account for target pronunciations specific to Japanese speakers, we observe the pronunciation variation in the ERJ and generate additional pronunciations for each word in the word list.",
  "y": "uses"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_12",
  "x": "In order to evaluate the effect of pronunciation variation in <cite>Toutanova and Moore (2002)</cite> 's spelling correction approach, we compare the performance of the pronunciation model and the combined model with and without pronunciation variation.",
  "y": "uses"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_13",
  "x": "The noisy channel spelling correction approach developed by Brill and Moore (2000) and <cite>Toutanova and Moore (2002)</cite> appears well-suited for writers of English as a foreign language.",
  "y": "background"
 },
 {
  "id": "9e8af6ca401cd74adc9a4137ae05ec_14",
  "x": "We incorporated a pronouncing dictionary extended for Japanese writers of English into the spelling correction model developed by <cite>Toutanova and Moore (2002)</cite> , which combines orthography-based and pronunciation-based models.",
  "y": "uses"
 },
 {
  "id": "9e8c386b7ea3b5e4e2843fb8382fd8_0",
  "x": "1 This deficiency can be addressed by summing surprisal measures over the saccade region (see Figure 1) , and the resulting cumulative n-grams have been shown to be more predictive of reading times than the usual non-cumulative n-grams <cite>(van Schijndel and Schuler, 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "9e8c386b7ea3b5e4e2843fb8382fd8_1",
  "x": "In line with previous findings on the Dundee corpus <cite>(van Schijndel and Schuler, 2015)</cite> , cumulative 5-grams provide a significant improvement over basic n-grams (p < 0.001), but unlike previous work, basic n-grams do not improve over cumulative n-grams on this corpus (p > 0.05).",
  "y": "similarities differences"
 },
 {
  "id": "9e8c386b7ea3b5e4e2843fb8382fd8_2",
  "x": "Accumulated PCFG surprisal (see Equation 4) did not improve reading time fit (p > 0.05), unlike n-gram surprisal, which replicates a previous result using the Dundee corpus <cite>(van Schijndel and Schuler, 2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "9e8c386b7ea3b5e4e2843fb8382fd8_3",
  "x": "This work has confirmed previous findings that cumulative n-grams provide a better model of reading times than the typical non-cumulative reading times <cite>(van Schijndel and Schuler, 2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_0",
  "x": "In this pretext, we revisit the problem of compound type identification in Sanskrit<cite> (Krishna et al., 2016)</cite> and experiment with various neural architectures for solving the task.",
  "y": "background"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_1",
  "x": "In Sanskrit,<cite> Krishna et al. (2016)</cite> have proposed a framework for semantic type classification of compounds in Sanskrit.",
  "y": "background"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_2",
  "x": "Unlike the feature-rich representation of<cite> Krishna et al. (2016)</cite> , we rely on various word embedding approaches, which include character level, sub-word level, and word-level embedding approaches.",
  "y": "differences"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_3",
  "x": "The best system of ours, an end-to-end LSTM architecture initialised with fasttext embeddings has shown promising results in terms of F-score (0.73) compared to the state of the art classifier from<cite> Krishna et al. (2016)</cite> (0.74) and outperformed it in terms of accuracy (77.68%).",
  "y": "similarities uses"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_4",
  "x": "Here, similar to<cite> Krishna et al. (2016)</cite> , we expect the users to provide a compound in its component-wise segmented form as input to the model.",
  "y": "similarities uses"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_5",
  "x": "But our model relies on distributed representations or embeddings of the input as features, instead of the linguistically involved feature set proposed in<cite> Krishna et al. (2016)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_6",
  "x": "In Sanskrit,<cite> Krishna et al. (2016)</cite> proposed a similar statistical approach which combined lexical and distributional information by using information from the lexical network Amarakos .",
  "y": "similarities"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_7",
  "x": "Similar to prior computational approaches in Sanskrit compounding <cite>(Krishna et al., 2016</cite>; Kumar et al., 2010) , we follow this four class coarse level categorization of the semantic classes in compounds.",
  "y": "similarities uses"
 },
 {
  "id": "9ea14a9fe422451901ad221bee5714_8",
  "x": "We have used the same experimental setting as<cite> Krishna et al. (2016)</cite> for the classification task. a class,<cite> Krishna et al. (2016)</cite> down-sampled it to 4,000, which takes it close to the count of the second most highly populated class Bahuvr\u012bhi.",
  "y": "similarities uses"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_0",
  "x": "The word order between source and target languages significantly influences the translation quality in statistical machine translation (SMT) (Tillmann, 2004; Hayashi et al., 2013; <cite>Nakagawa, 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_1",
  "x": "To address these problems, preordering (Xia and McCord, 2004; Wang et al., 2007; Xu et al., 2009; Isozaki et al., 2010b; Gojun and Fraser, 2012; <cite>Nakagawa, 2015</cite>) and postordering (Goto et al., 2012 (Goto et al., , 2013 Hayashi et al., 2013 ) models have been proposed.",
  "y": "background"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_2",
  "x": "In particular, preordering effectively improves the translation quality because it solves long-distance reordering and computational complexity issues (Jehl et al., 2014; <cite>Nakagawa, 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_3",
  "x": "On the other hand, studies in (Neubig et al., 2012; Lerner and Petrov, 2013; Hoshino et al., 2015; <cite>Nakagawa, 2015</cite>) apply machine learning to the preordering problem.",
  "y": "background"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_4",
  "x": "Neubig et al. (2012) and <cite>Nakagawa (2015)</cite> proposed methods that construct a binary tree and reordering simultaneously from a source sentence.",
  "y": "background"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_5",
  "x": "The results confirm that the proposed method achieves comparable translation quality to the state-of-the-art preordering method <cite>(Nakagawa, 2015)</cite> that requires a manual feature design.",
  "y": "similarities"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_6",
  "x": "5 Source-totarget and target-to-source word alignments were calculated using IBM model 1 and hidden Markov model, and they were combined with the intersection heuristic following <cite>(Nakagawa, 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_8",
  "x": "Compared to the plain PBSMT without preordering, both BLEU and RIBES increased significantly with preordering by RvNN and <cite>BTG</cite>.",
  "y": "uses"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_9",
  "x": "These scores were comparable (statistically insignificant at p < 0.05) between RvNN and <cite>BTG</cite>, 12 indicating that the proposed method achieves a translation quality comparable to <cite>BTG</cite>.",
  "y": "similarities"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_10",
  "x": "The label is determined based on Kendall's \u03c4 (Kendall, 1938) as in <cite>(Nakagawa, 2015)</cite> , which is calculated by Equation (1).",
  "y": "uses similarities"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_14",
  "x": "Furthermore, the ratio of high Kendall's \u03c4 by RvNN is more than that of <cite>BTG</cite>, implying that preordering by RvNN is better than that by <cite>BTG</cite>.",
  "y": "differences"
 },
 {
  "id": "9ee702243b3976ee4261f433d75528_15",
  "x": "The experiments confirmed that the proposed method achieved a translation quality comparable to the <cite>state-of-the-art preordering method</cite> that requires a manual feature design.",
  "y": "similarities"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_0",
  "x": "A spike in attention directed toward a particular location may signal an important update, such as the need for aid for the location<cite> (Varga et al. 2013)</cite> . While collective attention is often measured with activity metrics such as post volume (Mitra, Wright, Copyright c 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). and Gilbert 2016), such metrics often focus on an aggregate quantity summary of attention without considering the nuanced content side of attention dynamics.",
  "y": "motivation"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_1",
  "x": "A spike in attention directed toward a particular location may signal an important update, such as the need for aid for the location<cite> (Varga et al. 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_2",
  "x": "Such descriptor phrases provide additional contextual information for named entities (people, organizations and locations)<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> , helping to locate unfamiliar entities and disambiguate names that could have multiple referents.",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_3",
  "x": "Left y-axis (black solid line) indicates the location's daily log frequency, right y-axis (red dotted line) indicates the location's weekly probability of receiving a descriptor phrase like \"Puerto Rico\". Hurricane Maria in 2017, the location \"San Juan\" was less likely to receive a descriptor (e.g., \"San Juan, PR\") following the peak in collective attention volume. While this shift appears to be due to time<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> , the shift in descriptor use may also stem from non-temporal factors as well, such as an author's expectations of their audience (audience design) and additional information such as links to external news articles, included in the same sentence with the location (a micro-level aspect of the discussion).",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_4",
  "x": "By looking at public posts written on Twitter concerning natural disasters, we found that the aggregate rate of descriptor phrases decreased following the peaks in these locations' collective attention, supporting prior findings in the change in named entity use<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_5",
  "x": "Collective attention is an important component in the spread of information (Wu and Huberman 2007) , and it can shift either vary rapidly or gradually in response to particular events such as sports games (Lehmann et al. 2012) , natural disasters<cite> (Varga et al. 2013)</cite> , and political controversy (Garimella et al. 2017) .",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_6",
  "x": "The dependent clause may describe attributes of the entity that are relevant to a specific topic, such as \"San Juan, epicenter of Hurricane Maria relief effort,\" or attributes that are generally relevant, such as \"San Juan, Puerto Rico.\" From a collective perspective, prior work that examined the use of descriptor phrases in news media found that writers tend to drop such phrases as the entities gradually become more and more familiar (i.e., shared knowledge) among discussion participants over time<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_7",
  "x": "Crisis events such as hurricanes present a useful case study for the development of collective attention, due to the large volume of online participation and large uncertainty among event observers towards the situation during the crisis events<cite> (Varga et al. 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_8",
  "x": "Following<cite> Stali\u016bnait\u0117 et al. (2018)</cite> , we used a small set of dependencies to capture the \"MODIFIER\" phrase type in a subclause (adjectival clause, appositional modifier, prepositional modifier, numeric modifier) and another set of dependencies to capture the \"COMPOUND\" type in a super-clause (nominal modifier, compound, appositional modifier).",
  "y": "uses"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_9",
  "x": "In addition to the aforementioned explanatory factors used, we incorporated an additional set of variables to capture this temporal dynamics: relative peak time, i.e. whether the location is mentioned during or after the peak in post volume; and time since start, i.e. days since the beginning of the hurricane. Here, the definition of peak in collective attention is critical, because it determines the point at which an entity is expected to become shared knowledge<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> .",
  "y": "uses background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_10",
  "x": "Here, the definition of peak in collective attention is critical, because it determines the point at which an entity is expected to become shared knowledge<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_11",
  "x": "To summarize, we found consistently less descriptor use over the course of crisis events even after controlling for other explanatory factors, supporting prior work in long-term descriptor phrase change <cite>(Stali\u016bnait\u0117 et al. 2018</cite> ).",
  "y": "similarities"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_12",
  "x": "Future work can build upon our work and generalize it to other different types of crisis events. In addition, we are unable to rule out the possibility that another event attracted attention to the locations under discussion before the crises began (e.g. a political news story relevant to the event's region) Lastly, the study focuses exclusively on location names because of their geographic relevance to events, but other types of named entities (people, organizations) are also likely to undergo changes in descriptor use in response to increased attention<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> .",
  "y": "future_work"
 },
 {
  "id": "a0af9cf22996a245af9d66cf1d358f_13",
  "x": "In addition, we are unable to rule out the possibility that another event attracted attention to the locations under discussion before the crises began (e.g. a political news story relevant to the event's region) Lastly, the study focuses exclusively on location names because of their geographic relevance to events, but other types of named entities (people, organizations) are also likely to undergo changes in descriptor use in response to increased attention<cite> (Stali\u016bnait\u0117 et al. 2018)</cite> .",
  "y": "motivation background future_work"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_0",
  "x": "We present a deep learning system that advances the state of the art for the MIMIC-III dataset, achieving a new best micro F1-measure of 55.85%, significantly outperforming the previous best result<cite> (Mullenbach et al., 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_1",
  "x": "We present a deep learning system that advances the state of the art for the MIMIC-III dataset, achieving a new best micro F1-measure of 55.85%, significantly outperforming the previous best result<cite> (Mullenbach et al., 2018)</cite> . We achieve this through a number of enhancements, including two major novel contributions: multiview convolutional channels, which effectively learn to adjust kernel sizes throughout the input; and attention regularization, mediated by natural-language code descriptions, which helps overcome sparsity for thousands of uncommon codes.",
  "y": "extends differences"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_2",
  "x": "<cite>Mullenbach et al. (2018)</cite> presented a model capable of predicting full codes for both ICD-9 diagnoses and procedures composed of shared embedding and CNN layers between all codes and an individual attention layer for each code.",
  "y": "background"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_3",
  "x": "Our approach is most similar to the current state-of-the-art model by <cite>Mullenbach et al. (2018)</cite> . As in their study, we use a CNN layer with attention modules by code and approach regularization using code descriptions.",
  "y": "uses similarities"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_4",
  "x": "Our approach is most similar to the current state-of-the-art model by <cite>Mullenbach et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_5",
  "x": "Our approach is most similar to the current state-of-the-art model by <cite>Mullenbach et al. (2018)</cite> . Our model has notable departures from theirs, however: firstly, we use multi-view CNN channels with max pooling across the channels, which in itself leads to improvements over their model (even before attention regularization).",
  "y": "extends differences"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_6",
  "x": "Also, some of the hospital stays do not have discharge summaries; following previous studies for automated coding, we only consider those that do (Perotte et al., 2013; Baumel et al., 2018;<cite> Mullenbach et al., 2018</cite>; Wang et al., 2018) .",
  "y": "similarities"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_7",
  "x": "We have three sets for our experiments: one including only the discharge summaries, which allows us to compare our results with previous studies on this corpus<cite> (Mullenbach et al., 2018</cite>; Perotte et al., 2013) , hereon the Dis set; one on the concatenation of all patient notes, hereon, Full set; and one on another set which includes only discharge summary samples with the 50 most frequent codes, hereon, Dis-50 set, for comparison to previous studies<cite> (Mullenbach et al., 2018</cite>; Wang et al., 2018) .",
  "y": "similarities"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_8",
  "x": "3 We follow the train, test, and development splits publicly shared by the recent study on this dataset<cite> (Mullenbach et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_9",
  "x": "We compare our approach with four baselines: flat and hierarchical SVMs (Perotte et al., 2013), LEAM (Wang et al., 2018) , and CAML<cite> (Mullenbach et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_10",
  "x": "CAML<cite> (Mullenbach et al., 2018)</cite> has achieved the best state-of-the-art results on MIMIC-III.",
  "y": "background"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_11",
  "x": "CAML<cite> (Mullenbach et al., 2018)</cite> has achieved the best state-of-the-art results on MIMIC-III. We run their model on the Dis set using their publicly available code.",
  "y": "uses"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_12",
  "x": "The most widely used metric for evaluating ICD code prediction is micro F1-score (Perotte et al., 2013; Wang et al., 2018;<cite> Mullenbach et al., 2018</cite>; Kavuluru et al., 2015) .",
  "y": "background"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_13",
  "x": "New studies have reported results on macro F1-score, precision@n, and AUC of ROC as well (Wang et al., 2018;<cite> Mullenbach et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_14",
  "x": "We evaluate the baseline models on the Dis set and Dis-50 sets and provide micro F1 scores for diagnosis and procedure codes for comparability with previous studies<cite> (Mullenbach et al., 2018</cite>; Perotte et al., 2013) .",
  "y": "similarities"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_15",
  "x": "6 When the models are trained and tested on Dis-50 set, our models outperform the previous studies in terms of micro and macro F1, P@5, and PR AUC. This is due to the architecture differences, such as the use of multi-view CNN and 6 The authors of CAML<cite> (Mullenbach et al., 2018)</cite> reported micro F1-Proc=60.9%, micro F1-Diag=52.4%, micro F1=53.9%, P@8=70.9% and P@15=56.1% on the Dis set.",
  "y": "differences"
 },
 {
  "id": "a0bd41c3653073dd79e19d3ddc8d14_16",
  "x": "For instance, we trained the model on all ground-truth codes equally, similarly to previous approaches (Baumel et al., 2018; Wang et al., 2018;<cite> Mullenbach et al., 2018</cite>; Perotte et al., 2013) .",
  "y": "similarities"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_0",
  "x": "More recently, <cite>Kisselew et al. (2015)</cite> put the task of modeling derivation into the perspective of zero-shot-learning: instead of using cosine similarities they predicted the derived term by learning a mapping function between the base term and the derived term.",
  "y": "background"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_1",
  "x": "The experiments by <cite>Kisselew et al. (2015)</cite> were performed over six derivational patterns for German (cf.",
  "y": "background"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_2",
  "x": "As in <cite>Kisselew et al. (2015)</cite> , we treat every derivation type as a specific learning problem: we take a set of word pairs with a particular derivation pattern (e.g., \"-in\", B\u00e4cker::B\u00e4ckerin), and divide this set into training and test pairs by performing 10-fold cross-validation.",
  "y": "similarities uses"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_3",
  "x": "We created a new collection of German particle verb derivations 1 relying on the same resource as <cite>Kisselew et al. (2015)</cite> , the semiautomatic derivational lexicon for German DErivBase (Zeller et al., 2013) .",
  "y": "similarities"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_4",
  "x": "In addition, we apply our models to two existing collections for derivational patterns, the German dataset from <cite>Kisselew et al. (2015)</cite> , comprising six derivational patterns with 80 in-stances each (cf.",
  "y": "uses"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_5",
  "x": "We thus apply a more informed baseline, the same as in <cite>Kisselew et al. (2015)</cite> , and predict the derived term at exactly the same position as the base term.",
  "y": "similarities uses"
 },
 {
  "id": "a0c0076fa8c3be914d93ec1d66d0c1_6",
  "x": "AvgAdd is a re-implementation of the best method in <cite>Kisselew et al. (2015)</cite> :",
  "y": "background"
 },
 {
  "id": "a26260547114750ba2aa49e5f96136_0",
  "x": "For answer generation we used S-net <cite>(Tan et al., 2017)</cite> model trained on SQuAD and To evaluate our model we used Large-scale RACE (ReAding Comprehension Dataset From Examinations) (Lai et al., 2017).",
  "y": "uses"
 },
 {
  "id": "a26260547114750ba2aa49e5f96136_1",
  "x": "Then we use answer generation using state-of-art S-Net model <cite>(Tan et al., 2017)</cite> which extract and generate answer figure 2.",
  "y": "uses"
 },
 {
  "id": "a26260547114750ba2aa49e5f96136_2",
  "x": "Answer extraction and Generation will be done using state-of-art S-NET model <cite>(Tan et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "a26260547114750ba2aa49e5f96136_3",
  "x": "Figure 4 : Answer Synthesis/Generation Model <cite>(Tan et al., 2017)</cite> The produced answer will be stored in Answer vector.",
  "y": "uses"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_0",
  "x": "The advantage of having a simple annotation scheme is two-fold: it allows for more reliable human annotations and it enables better performance for argumentation mining systems designed to automatically identify the argumentative structure <cite>(Stab and Gurevych, 2014b)</cite> .",
  "y": "background"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_1",
  "x": "Second, we show that the argumentation features extracted based on argumentative structures automatically predicted by a state-of-the-art argumentation mining system <cite>(Stab and Gurevych, 2014b)</cite> are also good predictors of essays scores (Section 4).",
  "y": "uses"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_2",
  "x": "In addition, we notice that attack relations are sparse, as was the case in <cite>Stab and Gurevych (2014b)</cite> dataset and thus the coefficients for attack relations features (#10, #11 in Table 1 ) are negligible.",
  "y": "similarities"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_3",
  "x": "We use the approach proposed by <cite>Stab and Gurevych (2014b)</cite> .",
  "y": "uses"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_4",
  "x": "In the first setting, we used the dataset of 90 high quality persuasive essays from <cite>(Stab and Gurevych, 2014b )</cite> (<cite>S&G</cite>) as training and use T OEF L arg for testing (out-of-domain setting).",
  "y": "uses"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_5",
  "x": "We ran experiments for all different features groups and observe that with the exception of the P class, the F1 scores for all the other classes is comparable to the results reported by <cite>Stab and Gurevych (2014b)</cite> .",
  "y": "similarities"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_6",
  "x": "We ran experiments for all different features groups and observe that with the exception of the P class, the F1 scores for all the other classes is comparable to the results reported by <cite>Stab and Gurevych (2014b)</cite> . One explanation of having lower performance on the P (premise) category is that the <cite>S&G</cite> dataset used for training has higher quality essays, while 2/3 of our T OEF L arg dataset consists of medium and low scoring essays (the writing style for providing reasons or example can differ between high and low scoring essays).",
  "y": "differences"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_7",
  "x": "The F1 score of identifying support relations is 84.3% (or 89% using top100), much higher than reported by <cite>Stab and Gurevych (2014b)</cite> .",
  "y": "differences"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_8",
  "x": "We observe that two specific feature groups, Structural and Lexical, individually achieve high F1 scores and when combined with other features, they assist the classifier in reaching F1 scores in high 80s%. There can be two explanations for this: 1) essays in T OEF L arg have multiple short paragraphs where the position features such as position of the arguments in the essay and paragraph (Structural group) are strong indicators for argument relations; and 2) due to short paragraphs, the percentage of N S instances are less than in the <cite>S&G</cite> dataset, hence the Lexical features (i.e., word-pairs between Arg 1 and Arg 2 ) perform very well.",
  "y": "differences"
 },
 {
  "id": "a2b945e18ab6b73b4021a2db8bda4f_9",
  "x": "Since our goal is to compare with the manual annotation setup, we use the first setting, where we train on the <cite>S&G</cite> dataset and test on our T OEF L arg dataset.",
  "y": "uses"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_0",
  "x": "Following<cite> Seo et al. (2019)</cite> , we concatenate both sparse and dense vectors to encode every phrase in Wikipedia and use maximum similarity search to find the closest candidate phrase to answer each question.",
  "y": "uses"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_1",
  "x": "Notably, our method significantly outperforms DENSPI <cite>(Seo et al., 2019)</cite> , the previous end-toend QA model, by more than 4% with negligible drop in inference speed.",
  "y": "differences"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_2",
  "x": "To mitigate this problem,<cite> Seo et al. (2019)</cite> propose to learn query-agnostic representations of phrases in Wikipedia and retrieve phrases that best answers a question.",
  "y": "background"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_3",
  "x": "While<cite> Seo et al. (2019)</cite> have shown that encoding both dense and sparse representations for each phrase could keep the lexically important words of a phrase to some extent, their sparse representations are based on static tf-idf vectors which have globally the same weight for each n-gram.",
  "y": "motivation"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_4",
  "x": "Refer to<cite> Seo et al. (2019)</cite> for details; we mostly reuse its architecture.",
  "y": "background"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_5",
  "x": "Unlike<cite> Seo et al. (2019)</cite> , each phrase's sparse embedding is also trained, so it needs to be considered in the loss function.",
  "y": "differences"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_6",
  "x": "While the loss above is an unbiased estimator, in practice, we adopt early loss summation as suggested by<cite> Seo et al. (2019)</cite> for larger gradient signals in early training.",
  "y": "uses"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_7",
  "x": "Additionally, we also add dense-only loss that omits the sparse logits (i.e. original loss in<cite> Seo et al. (2019)</cite> ) to the final loss, in which case we find that we obtain higher-quality dense phrase representations.",
  "y": "uses"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_8",
  "x": "To each paragraph x, we concatenate the paragraph x neg which was paired with the question whose dense representation h neg is most similar to the original dense question representation h , following<cite> Seo et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_9",
  "x": "We use the same storage reduction and search techniques by<cite> Seo et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_10",
  "x": "We evaluate the effectiveness of COSPR by augmenting DENSPI <cite>(Seo et al., 2019)</cite> with contextualized sparse representations (DENSPI+COSPR).",
  "y": "extends"
 },
 {
  "id": "a301586ed006905275ab42c5e40d88_12",
  "x": "Table 4 shows the outputs of three OpenQA models: DrQA (Chen et al., 2017) , DENSPI <cite>(Seo et al., 2019)</cite> , and our DENSPI+COSPR.",
  "y": "uses"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_0",
  "x": "Figure 1: Generated example on ROTOWIRE by using Conditional Copy (CC) as baseline <cite>(Wiseman et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_1",
  "x": [
   "Wiseman et al. (2017) explored two types of copy mechanism and found conditional copy model (Gulcehre et al., 2016) perform better ."
  ],
  "y": "background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_2",
  "x": "The word embeddings for each type of information are trainable and randomly initialized before training following<cite> Wiseman et al. (2017)</cite> .",
  "y": "background similarities"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_3",
  "x": "We conducted experiments on ROTOWIRE <cite>(Wiseman et al., 2017)</cite> . For each example, it provides three tables as described in Section 2.1 which consists of 628 records in total with a long game summary.",
  "y": "uses"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_4",
  "x": "In this paper, we followed the data split introduced in<cite> Wiseman et al. (2017)</cite>",
  "y": "uses"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_5",
  "x": "We chose Conditional Copy (CC) model as our baseline, which is the best model in<cite> Wiseman et al. (2017)</cite> .",
  "y": "uses background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_6",
  "x": "Also we implemented a template system same as the one used in<cite> Wiseman et al. (2017)</cite> which outputted eight sentences: an introductory sentence (two teams' points and who win), six top players' statistics (ranked by their points) and a conclusion sentence.",
  "y": "similarities uses"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_7",
  "x": "We refer the readers to<cite> Wiseman et al. (2017)</cite> 's paper for more detailed information on templates.",
  "y": "background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_9",
  "x": "Row, column and time dimension information are important to the modeling of tables because subtracting any of them will result in performance Table 2 : Automatic evaluation results on test set. Results were obtained using<cite> Wiseman et al. (2017)</cite> 's trained extractive evaluation models with relexicalization (Li and Wan, 2018) .",
  "y": "uses background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_10",
  "x": "In addition, we compare our model with delayed copy model (DEL) (Li and Wan, 2018) along with gold text, template system (TEM), conditional copy (CC) <cite>(Wiseman et al., 2017)</cite> and NCP+CC (NCP) (Puduppully et al., 2019) .",
  "y": "background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_11",
  "x": "Since its result in Li and Wan (2018) 's paper was evaluated by IE model trained by<cite> Wiseman et al. (2017)</cite> and \"relexicalization\" by Li and Wan (2018) , we adopted the corresponding IE model and re-implement \"relexicalization\" as suggested by Li and Wan (2018) for fair comparison.",
  "y": "uses background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_12",
  "x": "We compared our full model with gold texts, template-based system, CC <cite>(Wiseman et al., 2017)</cite> and NCP+CC (NCP) (Puduppully et al., 2019) . We randomly sampled 30 examples from test set. Then, we randomly sampled 4 sentences from each model's output for each example. We provided the raters of those sampled sentences with the corresponding NBA game statistics. They were asked to count the number of supporting and contradicting facts in each sentence. Each sentence is rated independently. We report the average number of supporting facts (#Sup) and contradicting facts (#Cont) in Table 3 . Unsurprisingly, template-based system includes most supporting facts and least contradicting facts in its texts because the template consists of a large number of facts and all of those facts are extracted from the table. Also, our model produces less contradicting facts than other two neural models.",
  "y": "differences background"
 },
 {
  "id": "a3dbc3362016cdcfc0c4da429b98cc_13",
  "x": [
   "Wiseman et al. (2017) introduced a document-scale data-totext dataset, consisting of long text with more redundant records, which requires the model to select important information to generate."
  ],
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_0",
  "x": "Stance detection (also called stance identification or stance classification) is one of the considerably recent research topics in natural language processing (NLP). It is usually defined as a classification problem where for a text and target pair, the stance of the author of the text for that target is expected as a classification output from the set: {Favor, Against, Neither} <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_1",
  "x": "Like sentiment analysis, stance detection systems can be valuable components of information retrieval and other text analysis systems <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_2",
  "x": "The authors state that their approach achieves state-ofthe art performance rates [1] on SemEval 2016 Twitter Stance Detection corpus <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_3",
  "x": "Lastly, in <cite>[12]</cite> , Se-mEval 2016's aforementioned shared task on Twitter Stance Detection is described.",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_4",
  "x": "Also provided are the results of the evaluations of 19 systems participating in two subtasks (one with training data set provided and the other without an annotated data set) of the shared task <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_5",
  "x": "It is emphasized in the related literature that unigram-based methods are reliable for the stance detection task [16] and similarly unigram-based models have been used as baseline models in studies such as <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_6",
  "x": "The 10-fold cross-validation results of the two classifiers are provided in Table 1 using the metrics of precision, recall, and F-Measure. The evaluation results are quite favorable for both targets and particularly higher for Target-1, considering the fact that they are the initial experiments on the data set. Yet, completely the opposite pattern is observed in stance detection results of baseline systems given in <cite>[12]</cite> , i.e., better F-Measure rates have been obtained for the Against class when compared with the Favor class <cite>[12]</cite> .",
  "y": "differences"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_7",
  "x": "Some of the baseline systems reported in <cite>[12]</cite> are SVM-based systems using unigrams and ngrams as features similar to our study, but their data sets include all three stance classes of Favor, Against, and Neither, while our data set comprises only tweets classified as belonging to Favor or Against classes.",
  "y": "differences"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_8",
  "x": "Another difference is that the data sets in <cite>[12]</cite> have been divided into training and test sets, while in our study we provide 10-fold cross-validation results on the whole data set.",
  "y": "differences"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_9",
  "x": "We have also evaluated SVM classifiers which use only bigrams as features, as ngram-based classifiers have been reported to perform better for the stance detection problem <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "a557739447131395f7a76d87a4cd19_10",
  "x": "Particularly, related methods presented in recent studies such as <cite>[12]</cite> can be tested on our data set.",
  "y": "future_work"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_0",
  "x": "LSTM-based turn-taking models that operate in a similar predictive fashion were proposed by <cite>Skantze</cite> in <cite>[13]</cite> .",
  "y": "background"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_1",
  "x": "Using these predictions we are able to anticipate utterance endpoints, and start our turns accordingly. LSTM-based turn-taking models that operate in a similar predictive fashion were proposed by <cite>Skantze</cite> in <cite>[13]</cite> . In <cite>these models</cite> LSTMs are used to make continuous predictions of a person's speech activity at each individual time step of 50ms. <cite>The networks</cite> are trained to predict a vector of probability scores for speech activity in each individual frame within a set future window. Rather than designing classifiers to make specific decisions, <cite>these continuous models</cite> are able to capture general information about turn-taking in the data that <cite>they</cite> are trained on. <cite>They</cite> can therefore be applied to a wide variety of turn-taking prediction tasks and have been shown to outperform traditional classifiers when applied to HOLD/SHIFT predictions. A downside to the approach in <cite>[13]</cite> is that, since a single LSTM is being used, all input features must be processed at the same rate.",
  "y": "motivation background"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_2",
  "x": "In this paper we present significant extensions to the original work of <cite>Skantze</cite> in <cite>[13]</cite> .",
  "y": "extends"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_3",
  "x": "The main objective of continuous turn-taking prediction as proposed in <cite>[13]</cite> is to predict the future speech activity annotations of one of the speakers in a dyadic conversation using input speech features from both speakers (x t ).",
  "y": "background"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_4",
  "x": "In our discussion and results below, <cite>\"Ling 50ms\"</cite> refers to using word features that have been sampled at regular 50ms intervals, as was proposed in <cite>[13]</cite> .",
  "y": "uses"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_5",
  "x": "We note that combinations such as <cite>\"Ling 50ms\"</cite> with \"Acous 10ms\" are not possible when using the \"no subnets\" and \"one subnet\" configurations since the features are being input into the same LSTM and cannot operate at different temporal resolutions.",
  "y": "background"
 },
 {
  "id": "a6564c4b215e6c5ad4f53eeb5dd69c_6",
  "x": "Comparing our results with previously published baselines reported on the same dataset by <cite>Skantze</cite> in [13] , our best result on the PAUSE 500 task of 0.8553 is a large improvement over <cite>his reported score</cite> of 0.762. Looking at the results from the fusion of visual and acoustic modalities shown in in Table 2 , we were able to achieve our best BCE loss using our multiscale approach to fuse acoustic features at a 10ms timescale and visual features at a 58Hz timescale.",
  "y": "uses differences"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_0",
  "x": "Previous approaches (Riedel et al., 2010; Hoffmann et al., 2011;<cite> Surdeanu et al., 2012)</cite> bypassed this problem by heavily under-sampling the \"negative\" class.",
  "y": "background"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_1",
  "x": "Previous approaches (Riedel et al., 2010; Hoffmann et al., 2011;<cite> Surdeanu et al., 2012)</cite> bypassed this problem by heavily under-sampling the \"negative\" class. We instead deal with a learning scenario where we only have entity-pair level labels that are either positive or unlabeled.",
  "y": "differences"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_2",
  "x": "We proposed an extension to<cite> Surdeanu et al. (2012)</cite> that can train on this dataset.",
  "y": "extends"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_3",
  "x": "Since then, it has gain popularity (Mintz et al., 2009; Bunescu and Mooney, 2007; Wu and Weld, 2007; Riedel et al., 2010; Hoffmann et al., 2011;<cite> Surdeanu et al., 2012</cite>; Nguyen and Moschitti, 2011) .",
  "y": "background"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_4",
  "x": "MultiR (Hoffmann et al., 2011) and Multi-Instance Multi-Label (MIML) learning<cite> (Surdeanu et al., 2012)</cite> further improve it to support multiple relations expressed by different sentences in a bag.",
  "y": "background"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_5",
  "x": "We randomly picked 200 unlabeled bags 5 from each of the two datasets (Riedel et al., 2010;<cite> Surdeanu et al., 2012</cite> ) generated by DS, and we manually annotate all relation mentions in these bags.",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_6",
  "x": "Our goal is to model the bag-level label noise, caused by the incomplete KB problem, in addition Table 2 : False negative matches on the Riedel (Riedel et al., 2010) and KBP dataset<cite> (Surdeanu et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_7",
  "x": "to modeling the instance-level noise using a 3-layer MIL or MIML model (e.g.,<cite> Surdeanu et al. (2012)</cite> ).",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_8",
  "x": "The input to the model is a list of n bags with a vector of binary labels, either Positive (P), or Unlabled (U) for each relation r. Our model can be viewed as a semi-supervised 6 framework that extends a state-of-the-art Multi-Instance Multi-Label (MIML) model<cite> (Surdeanu et al., 2012)</cite> .",
  "y": "extends"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_9",
  "x": "Similar to<cite> Surdeanu et al. (2012)</cite> , we also define the following parameters and conditional probabilities (details are in<cite> Surdeanu et al. (2012)</cite> ):",
  "y": "similarities"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_10",
  "x": "We use the set of features in<cite> Surdeanu et al. (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_11",
  "x": "which can be solved with an approximate solution in<cite> Surdeanu et al. (2012)</cite> (step 9-11): update z i independently with:",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_12",
  "x": "More details can be found in<cite> Surdeanu et al. (2012)</cite> .",
  "y": "background"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_13",
  "x": "We implement our model on top of the MIML<cite> (Surdeanu et al., 2012)</cite> code base.",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_14",
  "x": "8 We use the same mention-level and aggregate-level feature sets as<cite> Surdeanu et al. (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_15",
  "x": "Data set: We use the KBP (Ji et al., 2011) dataset 9 prepared and publicly released by<cite> Surdeanu et al. (2012)</cite> for our experiment since it is 1) large and realistic, 2) publicly available, 3) most importantly, it is the only dataset that has associated human-labeled ground truth.",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_16",
  "x": "For a fair comparison, we follow<cite> Surdeanu et al. (2012)</cite> and begin by downsampling the \"negative\" class to 5%.",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_17",
  "x": "Evaluation: We compare our algorithm (MIMLsemi) to three algorithms: 1) MIML<cite> (Surdeanu et al., 2012)</cite> , the Multiple-Instance Multiple Label algorithm which labels the bags directly with the KB (y = \u2113).",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_18",
  "x": "It also imposes y = \u2113. 3) Mintz++<cite> (Surdeanu et al., 2012)</cite> , a variant of the single-instance learning algorithm (section 3).",
  "y": "uses"
 },
 {
  "id": "a672da8cba61074fe4b8ba1a452a47_19",
  "x": "Mintz++ is a strong baseline<cite> (Surdeanu et al., 2012)</cite> and an improved version of Mintz et al. (2009) .",
  "y": "uses background"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_0",
  "x": "Previous work addressing the problem can be roughly classified into three categories: (1) learning word embeddings from large collections of text using variants of neural networks (Mikolov et al. (2013a) ; Mikolov et al. (2013b) ; Mikolov et al. (2013c) ; Levy and Goldberg (2014) ) or global matrix factorization (Deerwester et al. (1990) ; Turney (2012) ); (2) extracting knowledge from existing semantic networks, such as WordNet (Yang and Powers (2005) ; Alvarez and Lim (2007) ; Hughes and Ramage (2007) ) and ConceptNet (Boteanu and Chernova (2015) ); (3) combining the above two models by various ways (Agirre et al. (2009) ;<cite> Zhila et al. (2013)</cite> ; Iacobacci et al. (2015) ; Summers-Stay et al. (2016) ).",
  "y": "background"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_1",
  "x": "(2) The two existing models for measuring relational similarity are: the directional similarity model <cite>(Zhila et al. (2013)</cite> ) and the dual-space model consisting of domain and function space (Turney (2012) ).",
  "y": "background"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_2",
  "x": "(2) The two existing models for measuring relational similarity are: the directional similarity model <cite>(Zhila et al. (2013)</cite> ) and the dual-space model consisting of domain and function space (Turney (2012) ). Both models suffer some drawbacks.",
  "y": "motivation"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_3",
  "x": "(2) The two existing models for measuring relational similarity are: the directional similarity model <cite>(Zhila et al. (2013)</cite> ) and the dual-space model consisting of domain and function space (Turney (2012) ). Both models suffer some drawbacks. The directional similarity model explores the difference of two relationships in multiple topicality dimensions in the vector space. However, it ignores the spatial distances between word vectors, which can reveal the function similarity of words in function space.",
  "y": "motivation"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_4",
  "x": "(2) The two existing models for measuring relational similarity are: the directional similarity model <cite>(Zhila et al. (2013)</cite> ) and the dual-space model consisting of domain and function space (Turney (2012) ). The directional similarity model explores the difference of two relationships in multiple topicality dimensions in the vector space.",
  "y": "background"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_5",
  "x": "(2) The two existing models for measuring relational similarity are: the directional similarity model <cite>(Zhila et al. (2013)</cite> ) and the dual-space model consisting of domain and function space (Turney (2012) ). The directional similarity model explores the difference of two relationships in multiple topicality dimensions in the vector space. However, it ignores the spatial distances between word vectors, which can reveal the function similarity of words in function space.",
  "y": "motivation"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_6",
  "x": "The directional similarity model <cite>(Zhila et al. (2013)</cite> ) explores the difference of two relationships in multiple topicality dimensions in the vector space.",
  "y": "background"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_7",
  "x": "The directional similarity model <cite>(Zhila et al. (2013)</cite> ) explores the difference of two relationships in multiple topicality dimensions in the vector space. However, it ignores the spatial distance between word vectors, which can reveal the function similarity of words in function space.",
  "y": "motivation"
 },
 {
  "id": "a67f40381e82afaf249f097a208555_8",
  "x": "Based on the directional similarity model<cite> (Zhila et al., 2013)</cite> , we define the domain similarity of two pairs of words as follows:",
  "y": "uses"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_0",
  "x": "In the following decade, great success in terms of parse disambiguation and even language modeling was achieved by various lexicalized PCFG models (Magerman, 1995; Charniak, 1997;<cite> Collins, 1999</cite>; Charniak, 2000; Charniak, 2001) .",
  "y": "background"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_1",
  "x": "In the following decade, great success in terms of parse disambiguation and even language modeling was achieved by various lexicalized PCFG models (Magerman, 1995; Charniak, 1997;<cite> Collins, 1999</cite>; Charniak, 2000; Charniak, 2001) .",
  "y": "background"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_2",
  "x": "Charniak (2000) shows the value his parser gains from parentannotation of nodes, suggesting that this information is at least partly complementary to information derivable from lexicalization, and <cite>Collins (1999)</cite> uses a range of linguistically motivated and carefully hand-engineered subcategorizations to break down wrong context-freedom assumptions of the naive Penn treebank covering PCFG, such as differentiating \"base NPs\" from noun phrases with phrasal modifiers, and distinguishing sentences with empty subjects from those where there is an overt subject NP.",
  "y": "background"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_3",
  "x": "Specifically, we construct an unlexicalized PCFG which outperforms the lexicalized PCFGs of Magerman (1995) and Collins (1996) (though not more recent models, such as Charniak (1997) or <cite>Collins (1999)</cite> ).",
  "y": "differences"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_4",
  "x": "The second basic deficiency is that many rule types have been seen only once (and therefore have their probabilities overestimated), and many rules which occur in test sentences will never have been seen in training (and therefore have their probabilities underestimated -see <cite>Collins (1999)</cite> for analysis).",
  "y": "background"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_5",
  "x": "One successful method of combating sparsity is to markovize the rules<cite> (Collins, 1999)</cite> .",
  "y": "background"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_6",
  "x": "The raw treebank grammar corresponds to v = 1, h = \u221e (the upper right corner), while the parent annotation in (Johnson, 1998) corresponds to v = 2, h = \u221e, and the second-order model in <cite>Collins (1999)</cite> , is broadly a smoothed version of v = 2, h = 2.",
  "y": "similarities"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_7",
  "x": "Following <cite>Collins (1999)</cite> , the annotation GAPPED-S marks S nodes which have an empty subject (i.e., raising and control constructions).",
  "y": "uses"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_8",
  "x": "<cite>Collins (1999)</cite> captures this notion by introducing the notion of a base NP, in which any NP which dominates only preterminals is marked with a -B. Further, if an NP-B does not have a non-base NP parent, it is given one with a unary production.",
  "y": "background"
 },
 {
  "id": "a6954db741df61f014cc622c5b8263_9",
  "x": "This is a partial explanation of the utility of verbal distance in <cite>Collins (1999)</cite> .",
  "y": "background"
 },
 {
  "id": "a7223f2afa1afd5fbfa1257b98ec02_0",
  "x": "In the second half we discuss is detail relevant applications including text classification (Crammer and Singer, 2003) , named entity recognition <cite>(McDonald et al., 2005)</cite> , parsing (McDonald, 2006) , and other tasks.",
  "y": "uses"
 },
 {
  "id": "a7223f2afa1afd5fbfa1257b98ec02_1",
  "x": "In the second half we discuss is detail relevant applications including text classification (Crammer and Singer, 2003) , named entity recognition <cite>(McDonald et al., 2005)</cite> , parsing (McDonald, 2006) , and other tasks.",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_0",
  "x": "However, while excelling on benchmark domain adaptation tasks such as cross-domain product sentiment classification<cite> (Blitzer et al., 2007)</cite> , the reasons to this success are not entirely understood.",
  "y": "background"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_1",
  "x": "In the pre-NN era, a prominent approach to domain adaptation in NLP, and particularly in sentiment classification, has been structural correspondence learning (SCL) (Blitzer et al., 2006<cite> (Blitzer et al., , 2007</cite> .",
  "y": "background"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_2",
  "x": "We experiment with the task of cross-domain product sentiment classification of<cite> (Blitzer et al., 2007)</cite> , consisting of 4 domains (12 domain pairs) and further add an additional target domain, consisting of sentences extracted from social media blogs (total of 16 domain pairs).",
  "y": "extends"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_3",
  "x": "Pivot and Non-Pivot Features The definitions of this approach are given in Blitzer et al. (2006<cite> Blitzer et al. ( , 2007</cite> , where SCL is presented in the context of POS tagging and sentiment classification, respectively.",
  "y": "background"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_4",
  "x": "Following previous work (e.g. (Blitzer et al., 2006<cite> (Blitzer et al., , 2007</cite> Chen et al., 2012) our feature representation consists of binary indicators for the occurrence of word unigrams and bigrams in the represented document.",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_5",
  "x": "An important observation of <cite>Blitzer et al. (2007)</cite> , is that some pivot features are similar to each other to the level that they indicate the same information with respect to the classification task.",
  "y": "background"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_6",
  "x": "Cross-domain Sentiment Classification To demonstrate the power of our models for domain adaptation we experiment with the task of crossdomain sentiment classification<cite> (Blitzer et al., 2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_7",
  "x": "The first baseline is SCL with pivot features selected using the mutual information criterion (SCL-MI,<cite> (Blitzer et al., 2007)</cite> ).",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_8",
  "x": "We experiment with a 5-fold cross-validation on the source domain<cite> (Blitzer et al., 2007)</cite> : 1600 reviews for training and 400 reviews for development.",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_9",
  "x": "The test set for each target domain of <cite>Blitzer et al. (2007)</cite> consists of all 2000 labeled reviews of that domain, and for the Blog domain it consists of the 7086 labeled sentences provided with the task dataset.",
  "y": "background"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_10",
  "x": "Baselines: For SCL-MI, following<cite> (Blitzer et al., 2007)</cite> we tuned the number of pivot features (Gillick and Cox, 1989; Blitzer et al., 2006) between 500 and 1000 and the SVD dimensions among 50,100 and 150.",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_12",
  "x": "Variants of the Product Review Data There are two releases of the datasets of the <cite>Blitzer et al. (2007)</cite> cross-domain product review task. We use the one from http://www.cs.jhu.",
  "y": "uses"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_13",
  "x": "We believe that our setup is more realistic as when collecting unlabeled data, it is hard to get a balanced set. Note that <cite>Blitzer et al. (2007)</cite> used the other release where the unlabeled data consists of the same number of positive and negative reviews.",
  "y": "differences"
 },
 {
  "id": "a774b918013dbf60eb8cc0ad1de2f9_14",
  "x": "Test Set Size While <cite>Blitzer et al. (2007)</cite> used only 400 target domain reviews for test, we use the entire set of 2000 reviews.",
  "y": "differences"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_0",
  "x": "Recently, bidirectional long short-term memory networks (bi-LSTM) (Graves and Schmidhuber, 2005; Hochreiter and Schmidhuber, 1997) have been used for language modelling<cite> (Ling et al., 2015)</cite> , POS tagging<cite> (Ling et al., 2015</cite>;<cite> Wang et al., 2015)</cite> , transition-based dependency parsing (Ballesteros et al., 2015; Kiperwasser and Goldberg, 2016) , fine-grained sentiment analysis (Liu et al., 2015) , syntactic chunking (Huang et al., 2015) , and semantic role labeling (Zhou and Xu, 2015) .",
  "y": "background"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_1",
  "x": "Previous work on using deep learning-based methods for POS tagging has focused either on a single language (Collobert et al., 2011;<cite> Wang et al., 2015)</cite> or a small set of languages<cite> (Ling et al., 2015</cite>; Santos and Zadrozny, 2014 ).",
  "y": "background"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_2",
  "x": "These levels of representation were previously introduced in different efforts (Chrupa\u0142a, 2013; Zhang et al., 2015;<cite> Ling et al., 2015</cite>; Santos and Zadrozny, 2014; Gillick et al., 2016; Kim et al., 2015) , but a comparative evaluation was missing.",
  "y": "motivation background"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_3",
  "x": "These levels of representation were previously introduced in different efforts (Chrupa\u0142a, 2013; Zhang et al., 2015;<cite> Ling et al., 2015</cite>; Santos and Zadrozny, 2014; Gillick et al., 2016; Kim et al., 2015) , but a comparative evaluation was missing. Moreover, deep networks are often said to require large volumes of training data.",
  "y": "background"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_4",
  "x": "Our basic bi-LSTM tagging model is a context bi-LSTM taking as input word embeddings w. We incorporate subtoken information using an hierarchical bi-LSTM architecture<cite> (Ling et al., 2015</cite>; Ballesteros et al., 2015 ).",
  "y": "uses"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_5",
  "x": "We examined simple RNNs and confirm the finding of<cite> Ling et al. (2015)</cite> that they performed worse than their LSTM counterparts.",
  "y": "similarities"
 },
 {
  "id": "a7d6441ad365994edb41209e6405e0_7",
  "x": "Bi-LSTMs for POS tagging are also reported in<cite> Wang et al. (2015)</cite> , however, they only explore word embeddings, orthographic information and evaluate on WSJ only.",
  "y": "differences"
 },
 {
  "id": "a800862f17f7a8c13ed13fc6e9433f_0",
  "x": "Nevertheless, the best performing systems follow the traditional hybrid approach [3] , outperforming attention based encoder-decoder models<cite> [4,</cite> 5, 6, 7] , and when less training data is used, the gap between \"end-to-end\" and hybrid models is more prominent<cite> [4,</cite> 8] .",
  "y": "background"
 },
 {
  "id": "a800862f17f7a8c13ed13fc6e9433f_2",
  "x": "The final features presented to the network are also processed through a SpecAugment block that uses the SM policy <cite>[4]</cite> with p = 0.3 and no time warping.",
  "y": "uses"
 },
 {
  "id": "a800862f17f7a8c13ed13fc6e9433f_3",
  "x": "We note that this model already outperforms the best published attention based seq2seq model <cite>[4]</cite> , with roughly",
  "y": "differences"
 },
 {
  "id": "a800862f17f7a8c13ed13fc6e9433f_4",
  "x": "For comparison with results in the literature we refer to the Switchboard-300 results in<cite> [4,</cite> 8, 52, 53] and the Switchboard-2000 results in [51, 52, 54, 55, 56, 57] .",
  "y": "uses"
 },
 {
  "id": "a800862f17f7a8c13ed13fc6e9433f_5",
  "x": "Our 300hour model not only outperforms the previous best attention based encoder-decoder model <cite>[4]</cite> by a large margin, it also surpasses the best hybrid systems with multiple LMs [8] .",
  "y": "differences"
 },
 {
  "id": "a869bebe1744e3a7c71cb0f6fed12c_0",
  "x": "For the widely studied problem of polarity prediction in social media (positive vs. negative emotion or evaluation, only; Rosenthal et al. (2017) ), training data is relatively abundant. However, annotating for more complex representations of affective states-such as Basic Emotions (Ekman, 1992) or ValenceArousal-Dominance (Bradley and Lang, 1994 )-seems to be significantly harder in terms of both time consumption and inter-annotator agreement (IAA)<cite> (Strapparava and Mihalcea, 2007)</cite> .",
  "y": "background motivation"
 },
 {
  "id": "a869bebe1744e3a7c71cb0f6fed12c_1",
  "x": [
   "Both claims, the need for large amounts of gold data and the lack of affective information in pre-trained word embeddings, may largely impede the feasibility of DL in lowresource scenarios. Yet, in this paper, we provide strong, first-time evidence that both, in actuality, turn out to be misconceptions. (Strapparava and Mihalcea, 2007) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "a869bebe1744e3a7c71cb0f6fed12c_2",
  "x": "SE07: The test set of SemEval 2007 Task 14<cite> (Strapparava and Mihalcea, 2007)</cite> comprises 1000 English news headlines which are annotated according to six Basic Emotions, joy, anger, sadness, fear, disgust, and surprise on a [0; 100]-scale (BE6 annotation format).",
  "y": "uses"
 },
 {
  "id": "a869bebe1744e3a7c71cb0f6fed12c_3",
  "x": "We now compare our best performing model against previously reported results for the SE07 corpus. Table 5 provides the performance of the winning system of the original shared task (WIN-NER; Chaumartin (2007) ), the IAA as reported by the organizers<cite> (Strapparava and Mihalcea, 2007)</cite> , the performance by Beck (2017) , the highest one reported for this data set so far (BECK), as well as the results of our GRU from the 10\u00d710-CV.",
  "y": "uses"
 },
 {
  "id": "a869bebe1744e3a7c71cb0f6fed12c_4",
  "x": "As can be seen, the GRU established a new state-of-the-art result and even achieves superhuman performance. This may sound improbable at first glance. However, <cite>Strapparava and Mihalcea (2007)</cite> employ a rather weak notion of human performance which is-broadly speaking-based on the reliability of a single human rater.",
  "y": "differences motivation"
 },
 {
  "id": "a869bebe1744e3a7c71cb0f6fed12c_5",
  "x": "Our proposed GRU model even established a novel state-of-the-art result on the SemEval 2007 test set<cite> (Strapparava and Mihalcea, 2007)</cite> outperforming human reliability.",
  "y": "uses differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_0",
  "x": "Although the prediction of Evocation ratings has attracted some attention (Boyd-Graber et al., 2006; <cite>Hayashi, 2016</cite>) , to the best of our knowledge this is the first work to focus on the prediction of USF or EAT strengths.",
  "y": "background"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_1",
  "x": "Following <cite>Hayashi (2016)'s work</cite> on Evocation prediction, we frame word association prediction as a supervised regression task and introduce several new and modified features, including the first use of Gaussian embeddings (Vilnis and McCallum, 2014) to better capture the asymmetric nature of word associations.",
  "y": "extends"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_2",
  "x": "To this end, <cite>Hayashi (2016)</cite> framed Evocation prediction as a supervised regression task.",
  "y": "background"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_3",
  "x": "<cite>They</cite> employed a combination of WordNet structure-based features, word embedding-based features, and lexical features and found that vector offsets, i.e. the mathematical difference between vectors, were a strong indicator of Evocation ratings.",
  "y": "background"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_4",
  "x": "Our word association prediction system extends the method in <cite>Hayashi (2016)</cite> with several modifications to make it better suited to the USF and EAT datasets.",
  "y": "extends"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_5",
  "x": "First, we modify <cite>Hayashi (2016)'s</cite> lexVector.",
  "y": "extends"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_6",
  "x": "<cite>Hayashi (2016)</cite> represent each word's part-ofspeech (POS) using a one-hot encoded five dimensional vector (one of each POS in WordNet).",
  "y": "background"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_7",
  "x": "Similarly, <cite>they</cite> represent each word's lexical category using a one-hot encoded 45 dimensional vector (one for each WordNet lexicographer file).",
  "y": "background"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_8",
  "x": "Since words in USF and EAT can be associated with multiple synsets and we want to be able to capture associations related to polysemy, <cite>instead using a one-hot encoding</cite> we employ count vectors specifying the number of synsets from each POS/lexical category each word belongs to.",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_9",
  "x": "Second, <cite>instead of computing Wu-Palmer similarity</cite> (WUP, Wu and Palmer, 1994 ) between a single synset pair, we compute it for all cue synset/response synset pairs and record the maximum and average values.",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_10",
  "x": "Third, we extend the notion of dirRel, introduced in <cite>Hayashi (2016)</cite> to leverage the semantic network structure of WordNet.",
  "y": "extends"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_11",
  "x": "Given a graph where nodes represent synsets and arcs represent WordNet relations such as hypernym/hyponym and holonym/meronym, dirRel(s,t,k) is the proportion of k-step neighbours of s that are also k-step neighbours of t. <cite>In the original formula</cite>, s and t are nodes representing a single synset.",
  "y": "background"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_12",
  "x": "We <cite>instead consider</cite> a set of nodes S and a set of nodes T representing the set of synsets associated with the cue and response words, respectively, as shown in Equation 1.",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_13",
  "x": "This may increase the probability that |nb(S, k)\u2229nb(T, k)| > 0, a <cite>shortcoming of the original dirRel</cite> due to WordNet's \"relatively sparse connective structure\" (<cite>Hayashi, 2016</cite>) .",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_14",
  "x": "The embeddings have a dimensionality of 300 and are trained on English Wikipedia using the Word2Gauss 4 (w2g) and the hyperparameters reported by the developer 5 Sixth, since cue and response words are not associated with a single synset, the AutoEx embeddings employed in <cite>Hayashi (2016)</cite> to compute vector offsets are not well suited for our task.",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_15",
  "x": "<cite>Instead, we</cite> experiment with offsets calculated using w2v, GloVe, and w2g embeddings.",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_16",
  "x": "Finally, our 300 topic LDA model (Blei et al., 2003) was trained using Gensim 6 on full English Wikipedia instead of the subset of English Wikipedia used in <cite>Hayashi (2016</cite>) .",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_17",
  "x": "Following the setup used in <cite>Hayashi (2016)</cite> , all neural networks are trained using the Chainer 7 Python library with rectified linear units, dropout, and two hidden layers, each with 50% of the number of units in the input layer.",
  "y": "uses"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_18",
  "x": "To act as a baseline, we also reimplemented the system described in <cite>Hayashi (2016)</cite> and trained <cite>it</cite> on the same 80/20 split of Evocation as our system.",
  "y": "uses"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_19",
  "x": "The results of our <cite>Hayashi (2016)</cite> implementation are roughly comparable to those reported in the <cite>original paper</cite> (r = 0.374, \u03c1 = 0.401 compared to r = 0.439, \u03c1 = 0.400).",
  "y": "similarities"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_20",
  "x": "On Evocation, our system does not perform as well as <cite>Hayashi (2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "a99a393c83e47393400c72338faf80_21",
  "x": "Although we report a lower performance than that in <cite>Hayashi (2016)</cite> , potentially indicating that predicting association strengths in word-sense ambiguous contexts is a harder task, we believe our results are a promising start.",
  "y": "differences"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_0",
  "x": "The objective can be to predict either the next word given the initial words of a sentence [4, 14, 8] , or simply a nearby word given a single cue word<cite> [13,</cite> 15] .",
  "y": "background"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_1",
  "x": "More recent work has shown that high quality word embeddings can be learned via models with no nonlinear hidden layer<cite> [13,</cite> 15] .",
  "y": "background"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_2",
  "x": "For instance, in the skipgram approach <cite>[13]</cite> , for each 'cue word' w the 'context words' c are sampled from windows either side of tokens of w in the corpus (with c more likely to be sampled if it occurs closer to w).",
  "y": "background"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_3",
  "x": "For comparison, we trained a monolingual skipgram model <cite>[13]</cite> and its Glove variant [15] for the same number of epochs on the English half of the bilingual corpus.",
  "y": "uses"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_4",
  "x": "Lexical analogy questions are an alternative way of evaluating word representations<cite> [13,</cite> 15] .",
  "y": "background"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_5",
  "x": "For skipgram-style embeddings, it has been shown that if m, b and w are the embeddings for man, boy and woman respectively, the correct answer is often the nearest neighbour in the vocabulary (by cosine distance) to the vector v = w + b \u2212 m <cite>[13]</cite> .",
  "y": "background"
 },
 {
  "id": "aa87225d7d326adfb4a8b2702b8f25_6",
  "x": "We evaluated the embeddings on this task using the same vector-algebra method as <cite>[13]</cite> .",
  "y": "uses"
 },
 {
  "id": "ab08b0f3c8691852b3aab5e3575ebd_0",
  "x": "SODA is based on an iterative ensemble based adaptation technique<cite> (Bhatt et al., 2015)</cite> which gradually transfers knowledge from the source to the new target collection while being cognizant of similarity between the two collections.",
  "y": "uses background"
 },
 {
  "id": "ab08b0f3c8691852b3aab5e3575ebd_1",
  "x": "This is based on the observations from existing literature <cite>(Bhatt et al., 2015</cite>; Blitzer et al., 2007) which suggest that if the source and target collections are similar, the adaptation performance tends to be better than if the two collections are dissimilar.",
  "y": "uses background"
 },
 {
  "id": "ab08b0f3c8691852b3aab5e3575ebd_2",
  "x": "Algorithm 1 summarizes our approach (refer<cite> (Bhatt et al., 2015)</cite> for more details).",
  "y": "uses background"
 },
 {
  "id": "ab5788da3f24e01b0ec40fba0bdbec_0",
  "x": "For that purpose, state-of-the-art approaches rely on either a separately trained unsupervised Statistical Machine Translation (SMT) system, which is used for warmup during the initial back-translation iterations (Marie and Fujita, 2018;<cite> Artetxe et al., 2019)</cite> , or large-scale pre-training through masked denoising, which is used to initialize the weights of the underlying encoder-decoder (Conneau and Lample, 2019; Song et al., 2019; Liu et al., 2020) .",
  "y": "background"
 },
 {
  "id": "ab5788da3f24e01b0ec40fba0bdbec_1",
  "x": "For that purpose, we mimic the experimental settings of <cite>Artetxe et al. (2019)</cite> , and measure the effect of using different initial systems for warmup: the unsupervised SMT system proposed by <cite>Artetxe et al. (2019)</cite> themselves, supervised NMT and SMT systems trained on both small and large parallel corpora, and a commercial Rule-Based Machine Translation (RBMT) system.",
  "y": "uses"
 },
 {
  "id": "ab5788da3f24e01b0ec40fba0bdbec_2",
  "x": "We next describe the iterative back-translation implementation used in our experiments, which was proposed by <cite>Artetxe et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "ab5788da3f24e01b0ec40fba0bdbec_3",
  "x": "Following <cite>Artetxe et al. (2019)</cite> , we set N = 1, 000, 000 and a = 30, and perform a total of 60 such iterations.",
  "y": "uses"
 },
 {
  "id": "ab5788da3f24e01b0ec40fba0bdbec_4",
  "x": "\u2022 Unsupervised: We use the unsupervised SMT system proposed by <cite>Artetxe et al. (2019)</cite> , which induces an initial phrase-table using cross-lingual word embedding mappings, combines it with an n-gram language model, and further improves the resulting model through unsupervised tuning and joint refinement.",
  "y": "uses"
 },
 {
  "id": "ab5788da3f24e01b0ec40fba0bdbec_5",
  "x": "Iterative back-translation was also explored by Marie and Fujita (2018) and <cite>Artetxe et al. (2019)</cite> in the context of unsupervised machine translation, relying on an unsupervised SMT system (Lample et al., 2018b; Artetxe et al., 2018a) for warmup.",
  "y": "background"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_0",
  "x": "Recently, <cite>Wang et al. (2018)</cite> proposed a novel reconstruction-based approach to alleviating dropped pronoun (DP) translation problems for neural machine translation models.",
  "y": "background"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_1",
  "x": "Recently, <cite>Wang et al. (2018)</cite> proposed a novel reconstruction-based approach to alleviating dropped pronoun (DP) translation problems for neural machine translation models. In this work, we improve the original model from two perspectives.",
  "y": "uses"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_2",
  "x": "Recently, <cite>Wang et al. (2018)</cite> proposed a novel reconstruction-based approach to alleviating dropped pronoun (DP) translation problems for neural machine translation models. In this work, we improve the original model from two perspectives. First, we employ a shared reconstructor to better exploit encoder and decoder representations.",
  "y": "extends"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_3",
  "x": "A number of approaches have been investigated for DP translation (Le Nagard and Koehn, 2010; Xiang et al., 2013; Wang et al., 2016<cite> Wang et al., , 2018</cite> .",
  "y": "background"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_4",
  "x": "<cite>Wang et al. (2018)</cite> is a pioneering work to model DP translation for neural machine trans- * Zhaopeng Tu is the corresponding author of the paper.",
  "y": "background"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_5",
  "x": "In this work, we propose to improve the original model from two perspectives. First, we use a shared reconstructor to read hidden states from both encoder and decoder. Second, we integrate a DP predictor into NMT to jointly learn to translate and predict DPs. Incorporating these as two auxiliary loss terms can guide both the encoder and decoder states to learn critical information relevant to DPs. Experimental results on a largescale Chinese-English subtitle corpus show that the two modifications can accumulatively improve translation performance, and the best result is +1.5 BLEU points better than that reported by <cite>Wang et al. (2018)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_6",
  "x": "As shown in Figure 1 , <cite>Wang et al. (2018)</cite> introduced two independent reconstructors with their own parameters, which reconstruct the DPannotated source sentence from the encoder and decoder hidden states, respectively.",
  "y": "background"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_7",
  "x": "These annotated source sentences can be used to build a neural-based DP predictor, which can be used to annotate test sentences since the target sentence is not available during the testing phase. As shown in Table 1 , Wang et al. (2016<cite> Wang et al. ( , 2018</cite> explored to predict the exact DP words 1 , the accuracy of which is only 66% in F1-score.",
  "y": "background"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_8",
  "x": "Different from <cite>Wang et al. (2018)</cite>, we reconstruct DPP-annotated source sentence, which is predicted by an external model.",
  "y": "differences"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_9",
  "x": "To compare our work with the results reported by previous work<cite> (Wang et al., 2018)</cite> , we conducted experiments on their released Chinese\u21d2English TV Subtitle corpus.",
  "y": "uses"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_10",
  "x": "We implemented our models on the code repository released by <cite>Wang et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_11",
  "x": "It should be emphasized that we did not use the pre-train strategy as done in <cite>Wang et al. (2018)</cite> , since we found training from scratch achieved a better performance in the shared reconstructor setting.",
  "y": "differences"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_12",
  "x": "\"Separate-Recs\u21d2(+DPs)\" (Row 3) is the best model reported in <cite>Wang et al. (2018)</cite> , which we employed as another strong baseline.",
  "y": "uses"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_13",
  "x": "Among the variations of shared reconstructors (Rows 6-8), we found that an interaction attention from encoder to decoder (Row 7) achieves the best performance, which is +3.45 BLEU points better than our baseline (Row 4) and +1.45 BLEU points better than the best result reported by <cite>Wang et al. (2018)</cite> (Row 3) .",
  "y": "differences"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_14",
  "x": "Similar to <cite>Wang et al. (2018)</cite> , the proposed approach improves BLEU scores at the cost of decreased training and decoding speed, which is due to the large number of newly introduced parameters resulting from the incorporation of reconstructors into the NMT model.",
  "y": "similarities"
 },
 {
  "id": "ab6f114b2ce4e62e6d8a639e8183eb_15",
  "x": "We can see that the proposed model outperforms both the strong baseline and the best model reported in <cite>Wang et al. (2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_0",
  "x": "It has been recently studied in two distinct settings: (1) <cite>Rao and Tetreault (2018)</cite> addressed the task of Formality Transfer (FT) where given an informal sentence in English, systems are asked to output a formal equivalent, or vice-versa; (2) introduced the task of FormalitySensitive Machine Translation (FSMT), where given a sentence in French and a desired formality level (approximating the intended audience of the translation), systems are asked to produce an English translation of the desired formality level.",
  "y": "background"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_1",
  "x": "110K informal sentences were collected from Yahoo Answers and they were rewritten in a formal style via crowd-sourcing, which made it possible to benchmark style transfer systems based on both PBMT and NMT models<cite> (Rao and Tetreault, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_2",
  "x": "110K informal sentences were collected from Yahoo Answers and they were rewritten in a formal style via crowd-sourcing, which made it possible to benchmark style transfer systems based on both PBMT and NMT models<cite> (Rao and Tetreault, 2018)</cite> . In this work, we leverage this corpus to enable multi-task FT and FSMT.",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_3",
  "x": "<cite>Rao and Tetreault (2018)</cite> used independent neural machine translation models for each formality transfer direction (informal\u2192formal and formal\u2192informal).",
  "y": "background"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_4",
  "x": "<cite>Rao and Tetreault (2018)</cite> used independent neural machine translation models for each formality transfer direction (informal\u2192formal and formal\u2192informal). Inspired by the bi-directional NMT for low-resource languages , we propose a unified model that can handle either direction -we concatenate the parallel data from the two directions of formality transfer and attach a tag to the beginning of each source sentence denoting the desired target formality level i.e. <F> for transferring to formal and <I> for transferring to informal.",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_5",
  "x": "FT data: We use the GYAFC corpus introduced by <cite>Rao and Tetreault (2018)</cite> as our FT data.",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_6",
  "x": "2 For FT, <cite>Rao and Tetreault (2018)</cite> show that BLEU correlates well with the overall system ranking assigned by humans.",
  "y": "background"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_7",
  "x": "We report case-sensitive BLEU with standard WMT tokenization. 2 For FT, <cite>Rao and Tetreault (2018)</cite> show that BLEU correlates well with the overall system ranking assigned by humans.",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_8",
  "x": "Following <cite>Rao and Tetreault (2018)</cite>, we assess model outputs on three criteria: formality, fluency and meaning preservation.",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_9",
  "x": "For FT, we compare the top performing NMT benchmark model in <cite>Rao and Tetreault (2018)</cite> with our best FT model.",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_10",
  "x": "6 Formality Transfer Experiments 6.1 Baseline Models from <cite>Rao and Tetreault (2018)</cite> PBMT is a phrase-based machine translation model trained on the GYAFC corpus using a training regime consisting of self-training, data sub-selection and a large language model.",
  "y": "uses background"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_11",
  "x": "<cite>Rao and Tetreault (2018)</cite> use a pre-processing step to make source informal sentences more formal and source formal sentences more informal by rules such as re-casing.",
  "y": "background"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_12",
  "x": "As shown in Table 1 , our NMT baselines yield surprisingly better BLEU scores than those of <cite>Rao and Tetreault (2018)</cite> , even without using rule-processed source training data and pretrained word embeddings.",
  "y": "differences"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_13",
  "x": "We manually inspect 100 randomly selected samples from our evaluation set and compare the target-style output of our best model (MultiTask-tag-style) with that of the best baseline model (NMT-Combined) from <cite>Rao and Tetreault (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "ab8c43bf5a37c436d166960af459a8_14",
  "x": "On the FT task, the joint model significantly improves the quality of transfer between formal and informal styles in both directions, compared to prior work<cite> (Rao and Tetreault, 2018</cite> ).",
  "y": "differences"
 },
 {
  "id": "ab919bfae9ddf780cadcd491fe0a9b_0",
  "x": "<cite>White (2014)</cite> then showed that even better results can be achieved by inducing a grammar (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2013) that is directly compatible with (an enhanced version of) the SR-11 inputs.",
  "y": "background"
 },
 {
  "id": "ab919bfae9ddf780cadcd491fe0a9b_1",
  "x": "<cite>White (2014)</cite> then showed that even better results can be achieved by inducing a grammar (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2013) that is directly compatible with (an enhanced version of) the SR-11 inputs. However, as explained below, subsequent analysis revealed substantial remaining issues with the data, which this paper takes a step towards addressing.",
  "y": "motivation background"
 },
 {
  "id": "ab919bfae9ddf780cadcd491fe0a9b_2",
  "x": "With this issue in mind, <cite>White (2014)</cite> experimented with a version of the shallow SR-11 inputs (created by Richard Johansson) which included extra dependencies for unbounded dependencies and coordination, yielding dependency graphs extending core dependency trees.",
  "y": "background"
 },
 {
  "id": "ab919bfae9ddf780cadcd491fe0a9b_3",
  "x": "We have adapted and extended<cite> White's (2014)</cite> CCG induction algorithm to work with the augmented UDs that our system produces.",
  "y": "extends"
 },
 {
  "id": "abfc6373c577980154dbb93190d69b_0",
  "x": "Part-of-speech (POS) tagging has received a great deal of attention as it is a critical component of most natural language processing systems. In particular, there has been growing interest in both multilingual POS induction ) and cross-lingual POS induction via treebank projection (Yarowsky and Ngai, 2001; Xi and Hwa, 2005; <cite>Das and Petrov, 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "abfc6373c577980154dbb93190d69b_1",
  "x": "Underlying these studies is the idea that a set of (coarse) syntactic POS categories exist in similar forms across languages. These categories are often called universals to represent their cross-lingual nature (Carnie, 2002; Newmeyer, 2005) . When corpora with common tagsets are unavailable, a standard approach is to manually define a mapping from language and treebank specific fine-grained tagsets to a predefined universal set. This was the approach taken by<cite> Das and Petrov (2011)</cite> to evaluate their cross-lingual POS projection system for six different languages.",
  "y": "background"
 },
 {
  "id": "abfc6373c577980154dbb93190d69b_2",
  "x": "Second, we combine the cross-lingual projection part-of-speech taggers of<cite> Das and Petrov (2011)</cite> with the grammar induction system of Naseem et al. (2010) -which requires a universal tagset -to produce a completely unsupervised grammar induction system for multiple languages, that does not require gold POS tags in the target language.",
  "y": "extends"
 },
 {
  "id": "abfc6373c577980154dbb93190d69b_3",
  "x": "We present results on the same eight IndoEuropean languages as<cite> Das and Petrov (2011)</cite> , so that we can make use of their automatically projected POS tags.",
  "y": "uses"
 },
 {
  "id": "abfc6373c577980154dbb93190d69b_4",
  "x": "In our experiments, we did not make use of refined categories, as the POS tags induced by<cite> Das and Petrov (2011)</cite> were all coarse.",
  "y": "uses"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_0",
  "x": "The learned transformation can also be applied to words missing in the dictionary, which can be used to induce new translations with a direct application in machine translation <cite>(Mikolov et al., 2013b</cite>; Zhao et al., 2015) .",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_1",
  "x": "The first method to learn bilingual word embedding mappings was proposed by <cite>Mikolov et al. (2013b)</cite> , <cite>who</cite> learn the linear transformation that minimizes the sum of squared Euclidean distances for the dictionary entries.",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_2",
  "x": "Finally, additional techniques have been used to address the hubness problem in <cite>Mikolov et al. (2013b)</cite> , both through the neighbor retrieval method and the training itself .",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_3",
  "x": "We start with a basic optimization objective <cite>(Mikolov et al., 2013b)</cite> and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods (Faruqui and Dyer, 2014; Xing et al., 2015) .",
  "y": "extends"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_4",
  "x": "Our goal is to find a linear transformation matrix W so that XW best approximates Z, which we formalize minimizing the sum of squared Euclidean distances following <cite>Mikolov et al. (2013b)</cite> :",
  "y": "similarities"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_5",
  "x": "This last optimization objective coincides with Xing et al. (2015) , but their work was motivated by an hypothetical inconsistency in <cite>Mikolov et al. (2013b)</cite> , where the optimization objective to learn word embeddings uses dot product, the objective to learn mappings uses Euclidean distance and the similarity computations use cosine.",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_6",
  "x": "However, the fact is that, as long as W is orthogonal, optimizing the squared Euclidean distance of length-normalized embeddings is equivalent to optimizing the cosine, and therefore, the mapping objective proposed by Xing et al. (2015) is equivalent to that used by <cite>Mikolov et al. (2013b)</cite> with orthogonality constraint and unit vectors.",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_7",
  "x": "For that purpose, we use the translation induction task introduced by <cite>Mikolov et al. (2013b)</cite> , which learns a bilingual mapping on a small dictionary and measures its accuracy on predicting the translation of new words.",
  "y": "uses"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_8",
  "x": "Unfortunately, the dataset <cite>they</cite> use is not public.",
  "y": "uses"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_9",
  "x": "The code for <cite>Mikolov et al. (2013b)</cite> and Xing et al. (2015) is not publicly available, so we implemented and tested them as part of the proposed framework, which only differs from the original systems in the optimization method (exact solution instead of gradient descent) and the length normalization approach in the case of Xing et al. (2015) (postprocessing instead of constrained training).",
  "y": "uses"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_11",
  "x": "As discussed before, <cite>(Mikolov et al., 2013b)</cite> and (Xing et al., 2015) were implemented as part of our framework, so <cite>they</cite> correspond to our uncostrained mapping with no preprocessing and orthogonal mapping with length normalization, respectively.",
  "y": "similarities"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_12",
  "x": "As it can be seen, the method by Xing et al. (2015) performs better than that of <cite>Mikolov et al. (2013b)</cite> in the translation induction task, which is in line with what they report in their paper.",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_13",
  "x": "Moreover, thanks to the orthogonality constraint their monolingual performance in the word analogy task does not degrade, whereas the accuracy of <cite>Mikolov et al. (2013b)</cite> drops by 2.86% in absolute terms with respect to the original embeddings.",
  "y": "background"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_15",
  "x": "Moreover, it does not suffer from any considerable degradation in monolingual quality, with an anecdotal drop of only 0.07% in contrast with 2.86% for <cite>Mikolov et al. (2013b)</cite> and 7.02% for Faruqui and Dyer (2014) .",
  "y": "differences"
 },
 {
  "id": "ad770c1b473bc39e6ec989338357e6_16",
  "x": "When compared to Xing et al. (2015) , our results in Table 1 reinforce our theoretical interpretation for their method (cf. Section 2.2), as it empirically shows that its improvement with respect to <cite>Mikolov et al. (2013b)</cite> comes solely from the orthogonality constraint, and not from solving any inconsistency.",
  "y": "differences"
 },
 {
  "id": "ad9b663ac88667c1b88767ca4b2f8f_0",
  "x": "Target language side dependency structures have been successfully used in statistical machine translation (SMT) by<cite> Shen et al. (2008)</cite> and achieved state-of-the-art results as reported in the NIST 2008 Open MT Evaluation workshop and the NTCIR-9 Chinese-to-English patent translation task (Goto et al., 2011; Ma and Matsoukas, 2011) .",
  "y": "background"
 },
 {
  "id": "ad9b663ac88667c1b88767ca4b2f8f_1",
  "x": "The motivation of this paper is to investigate the impact of these non-isomorphic dependency structures to be used for SMT. That is, we would like to provide a comparative evaluation of these dependencies in a string-to-dependency decoder<cite> (Shen et al., 2008)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "ad9b663ac88667c1b88767ca4b2f8f_2",
  "x": "For extracting string-to-dependency transfer rules, we use well-formed dependency structures, either fixed or floating, as defined in<cite> (Shen et al., 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "ad9b663ac88667c1b88767ca4b2f8f_3",
  "x": "For PCFG parsing, we select the Berkeley parser (Petrov and Klein, 2007) . In order to generate wordlevel dependency trees from the PCFG tree, we use the LTH constituent-to-dependency conversion tool 3 written by Johansson and Nugues (2007) . The head finding rules 4 are according to Magerman (1995) and Collins (1997) . Similar approach has been originally used by<cite> Shen et al. (2008)</cite> .",
  "y": "similarities background"
 },
 {
  "id": "ad9b663ac88667c1b88767ca4b2f8f_4",
  "x": "We re-implemented the string-to-dependency decoder described in<cite> (Shen et al., 2008</cite> (Pauls and Klein, 2011) , was employed to train (1) a five-gram LM on the Xinhua portion of LDC English Gigaword corpus v3 (LDC2007T07) and (2) a tri-gram dependency LM on the English dependency structures of the training data.",
  "y": "uses"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_0",
  "x": "Fine-grained opinion mining aims to detect structured user opinions in text, which has drawn much attention in the natural language processing (NLP) community (Kim and Hovy, 2006; Breck et al., 2007; <cite>Ruppenhofer et al., 2008</cite>; Wilson et al., 2009; Qiu et al., 2011; Cardie, 2013, 2014; Liu et al., 2015; Wiegand et al., 2016) .",
  "y": "background"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_1",
  "x": "Earlier work attempts to exploit a well-trained SRL model to recognize possible semantic roles for a given opinion expression, and then map the semantic roles into opinion roles (Kim and Hovy, 2006;<cite> Ruppenhofer et al., 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_2",
  "x": "Results show that SRL is highly effective for ORL, which is consistent with previous findings (Kim and Hovy, 2006; <cite>Ruppenhofer et al., 2008</cite>; Marasovi\u0107 and Frank, 2018) .",
  "y": "similarities"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_3",
  "x": "Several works even directly transfer semantic roles into opinion roles for ORL (Kim and Hovy, 2006;<cite> Ruppenhofer et al., 2008)</cite> , treating opinion expressions as the major predicates.",
  "y": "background"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_4",
  "x": "Several works even directly transfer semantic roles into opinion roles for ORL (Kim and Hovy, 2006;<cite> Ruppenhofer et al., 2008)</cite> , treating opinion expressions as the major predicates. These systems can achieve good performances, indicating that SRL information can be greatly useful for ORL. Here we propose a novel method to encode the SRL information implicitly, enhancing ORL model with semantic-aware word representations from a neural SRL model (SRL-SAWR).",
  "y": "motivation"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_5",
  "x": "The results show that SRL information is very helpful for ORL, which is consistent with previous studies (Kim and Hovy, 2006; <cite>Ruppenhofer et al., 2008</cite>; Marasovi\u0107 and Frank, 2018) .",
  "y": "similarities"
 },
 {
  "id": "ada92083e8c012c328d5b6172b76ad_6",
  "x": "According to the above findings, we design a simple system by mapping SRL outputs into ORL directly (Kim and Hovy, 2006;<cite> Ruppenhofer et al., 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_0",
  "x": "Although a significant number of studies (e.g. (Huang et al., 2013; Ganguly et al., 2015; Zheng and Callan, 2015; Guo et al., 2016; Zamani and Croft, 2016;<cite> Dehghani et al., 2017</cite>; ) try to apply neural networks in IR, there have been few studies reporting the performance that is comparable to state-of-the-art IR models.",
  "y": "motivation"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_1",
  "x": "One can find from above discussions that the second category of approaches suffer from the data spareness problem, although there have been recent attempts (Gupta et al., 2017;<cite> Dehghani et al., 2017)</cite> trying to pseudo label query-document pairs automatically with unsupervised retrieval models such as BM25.",
  "y": "background"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_2",
  "x": "<cite>Dehghani et al. (2017)</cite> use BM25 to obtain relevant documents for a large set of AOL queries (Pass et al., 2006) which are then used as weakly supervised signals for joint embedding and ranking model training.",
  "y": "background"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_4",
  "x": "The actual probability in this paper is estimated in a similar way as in<cite> (Dehghani et al., 2017)</cite> , which is:",
  "y": "similarities"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_5",
  "x": "These collections have been broadly used in recent studies (Zheng and Callan, 2015; Guo et al., 2016;<cite> Dehghani et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_6",
  "x": "In order to build the labeled query-document pairs for supervised learning, we choose to use the more general methodology in (Gupta et al., 2017) instead of the one in<cite> (Dehghani et al., 2017)</cite> to relieve from data (i.e. AOL queries) only available from industrial labs.",
  "y": "differences"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_7",
  "x": "We set the hyper-parameters of our model by following similar tasks such as<cite> (Dehghani et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_8",
  "x": "More importantly, since our model learns from weakly supervised signals by BM25, we are more interested in the comparisons to BM25 and similar models using weakly supervised signals, an experimental strategy also employed in<cite> (Dehghani et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_9",
  "x": "\u2022 NRMS: It is a weakly-supervised neural IR model learned with automatically annotated querydocument pairs<cite> (Dehghani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "ae67018df3a74e0fd4ae90522499a3_10",
  "x": "Under such considerations, we perform experiments with the following baselines: \u2022 Classic models: The probabilistic BM25 model and query likelihood (QL) model based on Dirichlet smoothing are highly efficient IR models. \u2022 NRMS: It is a weakly-supervised neural IR model learned with automatically annotated querydocument pairs<cite> (Dehghani et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "aebac57baf260be18945feba38d6a1_0",
  "x": "Decompounders have been used successfully in Information Retrieval (Braschler and Ripplinger, 2004) , Machine Translation (Brown, 2002; <cite>Koehn and Knight, 2003)</cite> and Speech Recognition (Adda-Decker et al., 2000) .",
  "y": "background"
 },
 {
  "id": "aebac57baf260be18945feba38d6a1_1",
  "x": "By randomly sampling keywords we would get few compounds (as their frequency is small compared to that of non-compounds), so we have proceeded in the following way to ensure that the gold-standards contain a substantial amount of compounds: we started by building a very naive decompounder that splits a word in several parts using a frequency-based compound splitting method<cite> (Koehn and Knight, 2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "aebac57baf260be18945feba38d6a1_2",
  "x": "The evaluation is done using the metrics precision, recall and accuracy, defined in the following way<cite> (Koehn and Knight, 2003</cite> ):",
  "y": "uses"
 },
 {
  "id": "aebac57baf260be18945feba38d6a1_3",
  "x": "Table 2 lists the ones used in our system (Langer, 1998; Marek, 2006; Krott, 1999 Concerning the second step, there is some work that uses, for scoring, additional information such as rules for cognate recognition (Brown, 2002) or sentence-aligned parallel corpora and a translation model, as in the full system described by<cite> Koehn and Knight (2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "aebac57baf260be18945feba38d6a1_4",
  "x": "When those resources are not available, the most common methods used for compound splitting are using features such as the geometric mean of the frequencies of compound parts in a corpus, as in<cite> Koehn and Knight (2003)</cite> 's back-off method, or learning a language model from a corpus and estimating the probability of each sequence of possible compound parts (Schiller, 2005; Marek, 2006) .",
  "y": "uses"
 },
 {
  "id": "af0c9e20d34a080bac3304ded1f8d6_1",
  "x": "Qu et al. <cite>[14]</cite> apply a CNN-based text classifier proposed by Kim [8] using a fixed window to represent the context.",
  "y": "background"
 },
 {
  "id": "af0c9e20d34a080bac3304ded1f8d6_2",
  "x": "Although capable of classifying utterances with CDAs, Qu et al. <cite>[14]</cite> 's model only concerns a strictly-local context range and thus cannot include distant information. In this paper, we present a novel neural model that is adapted from Convolutional Recurrent Neural Network (CRNN) to both incorporate the interaction between distant utterances and generalize the DA recognition task to accommodate CDA.",
  "y": "motivation"
 },
 {
  "id": "af0c9e20d34a080bac3304ded1f8d6_3",
  "x": "We use the MSDialog-Intent dataset <cite>[14]</cite> to conduct experiments.",
  "y": "uses"
 },
 {
  "id": "af0c9e20d34a080bac3304ded1f8d6_4",
  "x": "Besides, unlike Qu et al. <cite>[14]</cite> , we keep all the DA annotations in the dataset to preserve the meaningful DA structures within and across utterances.",
  "y": "differences"
 },
 {
  "id": "af0c9e20d34a080bac3304ded1f8d6_7",
  "x": "Following previous work <cite>[14]</cite> on multi-label classification, we adopt label-based accuracy (i.e., Hamming score) and micro-F 1 score as our main evaluation metrics.",
  "y": "uses"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_0",
  "x": "Especially, it has been shown that the combination of LSTMs (Hochreiter and Schmidhuber, 1997; Gers et al., 2000) , convolutional neural networks (CNNs) (LeCun et al., 1989) , and word-level CRF achieves the state-of-the-art performance<cite> (Ma and Hovy, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_1",
  "x": "2 Word-level Neural CRF As a baseline method, we use word-level neural CRF proposed by<cite> (Ma and Hovy, 2016)</cite> since their method achieves state-of-the-art performance on NER.",
  "y": "motivation uses"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_2",
  "x": "Then, A \u2208 R |T |\u00d7|T | is a transition score matrix, A y i\u22121 ,y i is a transition 1 While<cite> (Ma and Hovy, 2016)</cite> define \u03d5(yi\u22121, yi, oi) = exp(Wy i\u22121 ,y i oi + Ay i\u22121 ,y i ) as the potential function where W is the weight vector corresponding to label pair (yi\u22121, yi), we use the simple potential function here.",
  "y": "differences"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_3",
  "x": "While it has been shown that the CRF layer is required to achieve the state-ofthe-art performance in<cite> Ma and Hovy (2016)</cite> , we observe that the CRF has no significant effect on the final performance for the lattice construction.",
  "y": "differences"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_4",
  "x": "Following previous work<cite> (Ma and Hovy, 2016)</cite> , we use BIOES tagging scheme in the wordlevel tagging model.",
  "y": "uses"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_5",
  "x": "To generate a segment lattice, we train word-level BLSTM-CNN with the same hyper-parameters used in<cite> Ma and Hovy (2016)</cite> level CNN, and 100 dimentional pre-trained word embedding of GloVe (Pennington et al., 2014) .",
  "y": "uses similarities"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_6",
  "x": "This result is consistent with the result of <cite>(Ma and Hovy, 2016</cite> In both experiments, it improves the F1 score by using segment-level CRF.",
  "y": "similarities"
 },
 {
  "id": "af9b884710f8198f008a9687153db6_7",
  "x": "Several different neural network methods have been proven to be effective for NER (Collobert et al., 2011; Chiu and Nichols, 2016; Lample et al., 2016;<cite> Ma and Hovy, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "afee292717afe1b0dcd77e155a5121_0",
  "x": "<cite>Dakka and Cucerzan (2008)</cite> explored the use of NB and SVM classifiers for categorising Wikipedia.",
  "y": "background"
 },
 {
  "id": "afee292717afe1b0dcd77e155a5121_1",
  "x": "<cite>Dakka and Cucerzan (2008)</cite> expanded their set of 800 hand-labelled articles using a semisupervised approach, extracting training samples from Wikipedia \"List\" pages -pages that group other articles by type.",
  "y": "background"
 },
 {
  "id": "afee292717afe1b0dcd77e155a5121_2",
  "x": "We experimented with a combination of the classification techniques used by <cite>Dakka and Cucerzan (2008)</cite> and the feature extraction methods used by Nothman et al. (2009) and others (Ponzetto and Strube, 2007; Hu et al., 2008; Biadsy et al., 2008) , focusing on the extraction of features from Wikipedia's rich metadata.",
  "y": "uses"
 },
 {
  "id": "afee292717afe1b0dcd77e155a5121_3",
  "x": "Tokens in the first paragraph were identified by <cite>Dakka and Cucerzan (2008)</cite> as useful features for a machine learner, an idea stemming from the fact that most human annotators will recognise an article's category after reading just the first paragraph. We extended this idea by also marking the first sentence and title tokens as separate from other tokens, as we found that often the first sentence was all that was required for a human annotator to classify an article.",
  "y": "extends"
 },
 {
  "id": "afee292717afe1b0dcd77e155a5121_5",
  "x": "There were also a number of complications when comparing our system with the system described by <cite>Dakka and Cucerzan (2008)</cite> : they used a different, and substantially smaller, hand-labelled data set; they did not specify how they handled disambiguation pages; they provided no results for experiments using only hand-labelled data, instead incorporating training data produced via their semi-automated approach into the final results; and they neglected to report the final size of the training data produced by their semi-automated annotation.",
  "y": "differences"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_0",
  "x": "Our model is similar to an architecture used in machine translation described in <cite>[13]</cite> .",
  "y": "similarities"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_1",
  "x": "The additional connections are marked in blue <cite>[13]</cite> .",
  "y": "background"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_2",
  "x": "Recently, the 2DLSTM layer also has been used for sequence-to-sequence modeling in machine translation <cite>[13]</cite> where it implicitly updates the source representation conditioned on the generated target words.",
  "y": "background"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_3",
  "x": "Similar to <cite>[13]</cite> , we apply a 2DLSTM layer to combine the acoustic model (the LSTM encoder) and the language model (the decoder) without any attention components.",
  "y": "similarities"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_4",
  "x": "Similar to <cite>[13]</cite> , we apply a 2DLSTM layer to combine the acoustic model (the LSTM encoder) and the language model (the decoder) without any attention components. Compared to <cite>[13]</cite> , our model is much deeper. We use max-pooling to select the most relevant encoder state whereas <cite>[13]</cite> uses the last horizontal state of the 2DLSTM.",
  "y": "extends differences"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_5",
  "x": "As written in Equation 5 , its activation is computed analogously to the other gates<cite> [13,</cite> 11] .",
  "y": "background"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_6",
  "x": "Similar to <cite>[13]</cite> , we then equip the network by a 2DLSTM layer to relate the encoder and the decoder states.",
  "y": "similarities"
 },
 {
  "id": "b0083488650bc98477fb10a9c5a808_8",
  "x": "This algorithm is faster than <cite>[13]</cite> , where at each output step, they recompute all previous states of 2DLSTM from scratch which are not required.",
  "y": "differences"
 },
 {
  "id": "b0701d41baf3b355d864f46821f34a_1",
  "x": "With combination of Conventional Neural Network (CNN) <cite>(Kalchbrenner et al., 2014)</cite> , Recurrent Neural Network (RNN), Recursive Neural Network (Socher et al., 2013) and Attention, hundreds of models had been proposed to model text for further classification, matching (Fan et al., 2017) or other tasks. However, these models are tested in different settings with various datasets, preprocessing and even evaluation.",
  "y": "motivation background"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_0",
  "x": "Some of the recent studies on this topic report performance evaluation results of different classifiers using different feature sets (Mohammad et al., 2016b ) while others present publicly-available stance-annotated data sets (Mohammad et al., 2016a; Sobhani et al., 2017;<cite> K\u00fc\u00e7\u00fck, 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_1",
  "x": "We have used the publicly-available tweet data set in Turkish annotated with stance information, together with the results of the corresponding SVM classifiers using unigrams as features in <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> as the baselines.",
  "y": "uses"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_2",
  "x": "In this study, we have used the stance-annotated tweet data set in Turkish <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> which includes 700 random tweets related to two sports clubs and these clubs constitute the stance targets.",
  "y": "uses"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_3",
  "x": "There are no tweet instances annotated with the class Neither in the data set <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_4",
  "x": "In this study, we have used the stance-annotated tweet data set in Turkish <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> which includes 700 random tweets related to two sports clubs and these clubs constitute the stance targets. There are no tweet instances annotated with the class Neither in the data set <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_5",
  "x": "In the current study, we have used the stance-annotated tweet data set described in <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_6",
  "x": "Also presented in <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> are the results of the following experiments on this data set:",
  "y": "background"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_7",
  "x": "The corresponding results have indicated that using unigrams as features leads to favorable performance rates and using unigrams together with hashtag features improves these results further, while using bigrams as features of the SVM classifiers results in poor performance <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_8",
  "x": "The favorable results corresponding to the former two settings are provided in Table 3 as excerpted from <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> , in order to be used as reference results for comparison purposes.",
  "y": "uses"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_9",
  "x": "As can be observed in Table 3 , using the existence of hashtags as an additional feature improves stance detection performance in terms of average F-Measure for Target-2 although it leads to a slight decrease in F-Measure for Target-1 <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_10",
  "x": "Similar to the settings in <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> , we have used the SVM classifier based on the SMO algorithm (Platt, 1999) , available in the Weka tool (Hall et al., 2009 ), during our stance detection experiments.",
  "y": "similarities"
 },
 {
  "id": "b124e65938672691a5589fb5cdb21e_11",
  "x": "\u2022 As has been reported in <cite>(K\u00fc\u00e7\u00fck, 2017)</cite> , the overall evaluation results of the stance detection task are considerably higher for the Favor class when compared with the results for the Against class, in all settings given in Table 4 and 5.",
  "y": "similarities"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_0",
  "x": "Since Tacotron [1] paved the way for end-to-end Text-To-Speech (TTS) using neural networks, researchers have attempted to generate more naturally sounding speech by conditioning a TTS model via speaker and prosody embedding [2, 3, <cite>4,</cite> 5, 6] .",
  "y": "background"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_1",
  "x": "( We use the term prosody as defined in earlier work<cite> [4]</cite> henceforth.) Because there is no available label for prosody, learning to control prosody in TTS is a difficult problem to tackle.",
  "y": "similarities uses"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_2",
  "x": "Recent approaches learn to extract prosody embedding from reference speech in an unsupervised manner and use prosody embedding to control the speech style<cite> [4,</cite> 5] .",
  "y": "background"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_3",
  "x": "Skerry-Ryan et al. used convolutional neural networks and a Gated Recurrent Unit (GRU) [9] to compress the prosody of the reference speech<cite> [4]</cite> .",
  "y": "background"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_4",
  "x": "Another problem was also reported [5] ; fixed-length prosody embedding worked poorly if the length of the reference speech was shorter than the speech to generate. In addition, variablelength prosody embedding was also implemented using the output of the GRU at every time step<cite> [4]</cite> .",
  "y": "differences"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_5",
  "x": "Although they used the same reference encoder architecture used in earlier work<cite> [4]</cite> , they did not use p itself for prosody embedding.",
  "y": "extends differences"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_6",
  "x": "Reference speech is encoded to prosody embedding using the reference encoder<cite> [4]</cite> .",
  "y": "background"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_7",
  "x": "Unless otherwise stated, we used the same hyperparameter settings used in earlier work<cite> [4]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_8",
  "x": "Previous works<cite> [4,</cite> 5] used large amounts of data to train the prosodic TTS model (296 hours of data for the multi-speaker model). To ensure a large amount of data, we used multiple datasets, in this case VCTK, CMU ARCTIC, and internal datasets.",
  "y": "uses similarities"
 },
 {
  "id": "b13bc55709f5040cf100bd5f466ff2_9",
  "x": "For the quantitative comparison, we used the Mean Cepstral Distortion (MCD) with the first 13 MFCCs, as proposed in earlier work<cite> [4]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "b1df73c14f53fea607c4c8b71740fe_0",
  "x": "<cite>Vlachos et al. (2009)</cite> applied the basic model of this class, the Dirichlet Process Mixture Model (DPMM), to lexical-semantic verb clustering with encouraging results.",
  "y": "background"
 },
 {
  "id": "b1df73c14f53fea607c4c8b71740fe_1",
  "x": "Furthermore, <cite>Vlachos et al. (2009)</cite> used a constrained version of the DPMM in order to guide clustering towards some prior intuition or considerations relevant to the specific task at hand.",
  "y": "background"
 },
 {
  "id": "b1df73c14f53fea607c4c8b71740fe_2",
  "x": "Following <cite>Vlachos et al. (2009)</cite> , for each instance that does not belong to a linked-group, the sampler is restricted to choose components that do not contain instances cannot-linked with it.",
  "y": "uses"
 },
 {
  "id": "b1df73c14f53fea607c4c8b71740fe_3",
  "x": "We evaluate our results using three information theoretic measures: Variation of Information (Meil\u0203, 2007) , V-measure (Rosenberg and Hirschberg, 2007) and V-beta<cite> (Vlachos et al., 2009</cite> ).",
  "y": "uses"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_0",
  "x": "Spectral-decomposition methods such as singular value decomposition (SVD) and principal component analysis (PCA) are usually used in this line of research (Caron 2001; Bullinaria and Levy 2012; Turney 2012; Levy and Goldberg 2014; Levy, Goldberg, and Dagan 2015;<cite> Mu and Viswanath 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_1",
  "x": "Among different unsupervised word vector postprocessing schemes, the all-but-the-top approach<cite> (Mu and Viswanath 2018</cite> ) is a prominent example.",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_2",
  "x": "Empirically studying the latent features encoded by principal components (PCs) of distributional word vectors, <cite>Mu and Viswanath (2018)</cite> found that the variances explained by the leading PCs \"encode the frequency of the word to a significant degree\".",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_3",
  "x": "The current work advances the findings of <cite>Mu and Viswanath (2018)</cite> and improves their post-processing scheme.",
  "y": "extends"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_4",
  "x": "Instead of discarding a fixed number of PCs, we softly filter word vectors using matrix conceptors (Jaeger 2014; 2017) , which characterize the linear space of those word vector features having high variances -the features most contaminated by word frequencies according to <cite>Mu and Viswanath (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_5",
  "x": "We first briefly review the principal component nulling approach for unsupervised word vector post-processing introduced in<cite> (Mu and Viswanath 2018)</cite> , upon which our work is based.",
  "y": "extends"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_6",
  "x": "This section is an overview of the all-but-the-top (ABTT) word vector post-processing approach introduced by <cite>Mu and Viswanath (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_7",
  "x": "First, using a PCA, <cite>Mu and Viswanath (2018)</cite> revealed that word vectors are strongly influenced by a few leading principal components (PCs).",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_8",
  "x": "In practice, <cite>Mu and Viswanath (2018)</cite> found that the improvements yielded by ABTT are particularly impressive for word similarity tasks.",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_9",
  "x": "Removing the leading PCs of word vectors using the ABTT algorithm described above is effective in practice, as seen in the elaborate experiments conducted by <cite>Mu and Viswanath (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_10",
  "x": "Recall that<cite> (Mu and Viswanath 2018)</cite> found that the directions with which x has the highest variances encode word frequencies, which are unrelated to word semantics.",
  "y": "background"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_11",
  "x": "For ABTT, we set d = 3 for Word2Vec and d = 2 for GloVe, as what has been suggested by <cite>Mu and Viswanath (2018)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_12",
  "x": "The baseline results (orig. and ABTT) are collected from<cite> (Mu and Viswanath 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_13",
  "x": "The baseline results (orig. and ABTT) are collected from<cite> (Mu and Viswanath 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_14",
  "x": "Following (Baroni, Dinu, and Kruszewski 2014; Schnabel et al. 2015;<cite> Mu and Viswanath 2018)</cite> , we used \"purity\" of clusters (Manning, Raghavan, and Sch\u00fctze 2008, Section 16.4) as the evaluation criterion.",
  "y": "uses"
 },
 {
  "id": "b2392c74f17fb2c0b6a0f19d16bc99_15",
  "x": "We follow previous research (Baroni, Dinu, and Kruszewski 2014; Schnabel et al. 2015;<cite> Mu and Viswanath 2018)</cite> to set k as the ground-truth number of categories.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_0",
  "x": "We use pretrained <cite>BERT</cite> <cite>(Devlin et al., 2018)</cite> architecture and investigate the effect of different fine tuning regimes on the final classification task.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_1",
  "x": "In earlier work, people mainly used the \"bag of words\" approach in algorithms such as Naive Bayes, Decision Tree, and SVM. However, recent studies (Peters et al., 2018; Radford et al., 2018; <cite>Devlin et al., 2018)</cite> showed that contextual word embeddings perform quite better than traditional word embeddings in many different NLP tasks as a result of their superior capacity of meaning representation.",
  "y": "background"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_2",
  "x": "Among those, <cite>BERT</cite> attracts researchers most because of (i) its transformer based architecture enabling faster training and (ii) state of the art results in many different tasks. Though it is quite new, <cite>BERT</cite> has been tried in many different domains than the one proposed in <cite>Devlin et al. (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_3",
  "x": "Though it is quite new, <cite>BERT</cite> has been tried in many different domains than the one proposed in <cite>Devlin et al. (2018)</cite> . However, almost all of these studies have two things in common: they don't start training <cite>BERT</cite> from scratch and the target domain contains very limited data (Zhu et al., 2018; Yang et al., 2019; Alberti et al., 2019) . In this study, on the other hand, we address (1) the performance of <cite>BERT</cite> by comparing its domain specific pre-trained and fine-tuned performances, and (2) in the setting where the target domain has extensively more data.",
  "y": "motivation"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_4",
  "x": "In the following sections, we first summarize the <cite>BERT</cite> architecture, then give details of shared task data set, and then describe experimental setups we used to train <cite>BERT</cite> model. In the results section, we compare the performance of <cite>BERT</cite> under different settings and share our submission results for the shared task.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_5",
  "x": "<cite>Devlin et al. (2018)</cite> introduced two unsupervised tasks to pretrain this architecture, Next Sentence Prediction and Masked Language Modeling.",
  "y": "background"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_6",
  "x": "In this study, we use an open source PyTorch implementation 3 of <cite>BERT</cite> architecture.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_7",
  "x": "We make use of <cite>BERT-Base</cite> pretrained model provided by <cite>Devlin et al. (2018)</cite> in order to avoid pretraining from scratch.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_8",
  "x": "Similar to <cite>Devlin et al. (2018)</cite> , we use the representation obtained from the last layer for the first token (i.e. \"[CLS]\") for the sentence representation and a softmax classifier on top of it for predicting hyperpartisanship.",
  "y": "similarities"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_9",
  "x": "Then, we give the details of our experiments and results with <cite>BERT</cite> under pretraining and finetuning settings.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_10",
  "x": "<cite>BERT</cite> restricts the input length to a maximum of 512 tokens.",
  "y": "background"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_11",
  "x": "We use the same tokenization method and embeddings as <cite>Devlin et al. (2018)</cite> to represent the words.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_12",
  "x": "In order to show how <cite>BERT</cite> performs in news domain, our first attempt was to use the training data to only fine-tune the pretrained model for classification.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_13",
  "x": "We used <cite>BERT-Base</cite> which consists of 12 transformer blocks on top of each other applying 12 headed attention mechanism, hidden size of 768 and a total of 110 million parameters.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_14",
  "x": "We set 16 as our batch size and 2e-5 as our learning rate as recommended by <cite>Devlin et al. (2018)</cite> Table 1 : Classification results on our portal-wise data splits with fine-tuned <cite>BERT</cite>.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_16",
  "x": "For Masked LM task, we follow the same approach with <cite>Devlin et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_17",
  "x": "At the end of pretraining data generation process, we accumulated near 3.5 million samples, only running the process once on our train split, so without any duplication unlike <cite>Devlin et al. (2018)</cite> because of time restrictions.",
  "y": "differences"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_18",
  "x": "Starting from the pretrained model of <cite>BERT-Base</cite> instead of a cold start, we trained the model with a learning rate of 3e-5 and 256 as the maximum sequence length for 290k iterations.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_19",
  "x": "Table 2 presents the combined loss of two unsupervised tasks on the held-out data for original <cite>BERT-Base</cite> and further pretrained model with the generated data.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_20",
  "x": "Results show that pretraining <cite>BERT</cite> further with data from an unseen domain greatly increases its representational power. Table 3 demonstrates that pretraining <cite>BERT</cite> with domain specific data using unsupervised tasks improves the performance of the model on the supervised classificiation task.",
  "y": "extends differences"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_21",
  "x": "In our first attempt, we fine-tuned <cite>BERT</cite> with portal-wise train split using development set to get the best model.",
  "y": "extends"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_22",
  "x": "In our last attempt, we pretrained <cite>BERT</cite> with our portal-wise train split, and then fine-tune it as described before.",
  "y": "extends"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_23",
  "x": "Looking at the results of second and third models on \"by-article-test-set\" shows us, although we fine-tune <cite>BERT</cite> with supervised data for the same classification task, fine-tuning on \"byarticle-train-set\" improves the results drastically.",
  "y": "differences"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_24",
  "x": "Although our experiments ( Table 3) show us that pretraining <cite>BERT</cite> further with data from news domain has a positive effect on overall accuracy, we are not able to observe the similar effect on \"by-article-test-set\".",
  "y": "differences"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_25",
  "x": "We presented a <cite>BERT</cite> baseline for the Hyperpartisan News Detection task.",
  "y": "uses"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_26",
  "x": "We demonstrated that pretraining <cite>BERT</cite> in an unseen domain improves the performance of the model on the domain specific supervised task.",
  "y": "differences"
 },
 {
  "id": "b27150a3506730c61dc78b3034887e_27",
  "x": "From our findings, we believe that domain adaptation is important for the <cite>BERT</cite> architecture and we would like to investigate the effect of from scratch unsupervised pretraining on the supervised task as future work.",
  "y": "extends future_work"
 },
 {
  "id": "b2a6ec11403fe73b9bae7742c1c5a2_0",
  "x": "Prior natural language processing (NLP) approaches to student revision analysis have focused on identifying revisions during argumentative writing and classifying their purposes and other properties<cite> [12,</cite> 11, 7, 1] .",
  "y": "background"
 },
 {
  "id": "b2a6ec11403fe73b9bae7742c1c5a2_1",
  "x": "Our work takes advantage of several corpora of multiple drafts of argumentative essays written by both high-school and college students<cite> [12,</cite> 11] , where all data has been annotated for revision using the framework of <cite>[12]</cite> .",
  "y": "uses"
 },
 {
  "id": "b2a6ec11403fe73b9bae7742c1c5a2_2",
  "x": "Nonidentical aligned sentences were extracted as the revisions, resulting in three types of revision operations -Add, Delete, M odif y. Each extracted revision was manually annotated with a purpose following the revision schema shown in Figure 1 (modified compared to <cite>[12]</cite> by adding the Precision category).",
  "y": "extends"
 },
 {
  "id": "b2a6ec11403fe73b9bae7742c1c5a2_3",
  "x": "A corpus study in <cite>[12]</cite> showed that content changes are correlated with argumentative writing improvement, reaffirming the statement of [4] .",
  "y": "background"
 },
 {
  "id": "b2a6ec11403fe73b9bae7742c1c5a2_4",
  "x": "A corpus study in <cite>[12]</cite> showed that content changes are correlated with argumentative writing improvement, reaffirming the statement of [4] . Using a similar method, we investigate if our editor roles are related to writing improvement.",
  "y": "similarities"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_0",
  "x": "We derive character-level contextual embeddings from Flair<cite> (Akbik et al., 2018)</cite> , and apply them to a time normalization task, yielding major performance improvements over the previous state-of-the-art: 51% error reduction in news and 33% in clinical notes.",
  "y": "uses"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_1",
  "x": "Pre-trained language models (LMs) such as ELMo (Peters et al., 2018) , ULMFiT (Howard and Ruder, 2018) , OpenAI GPT (Radford et al., 2018) , Flair<cite> (Akbik et al., 2018)</cite> and Bert (Devlin et al., 2018) have shown great improvements in NLP tasks ranging from sentiment analysis to named entity recognition to question answering.",
  "y": "background"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_2",
  "x": "All of the pre-trained word-level contextual embedding models include some character or subword components in their architecture. For example, Flair is a forward-backward LM trained over characters using recurrent neural networks (RNNs), that generates pre-trained contextual word embeddings by concatenating the forward LM's hidden state for the word's last character and the backward LM's hidden state for the word's first character. Flair achieves state-of-the-art or competitive results on part-of-speech tagging and named entity tagging<cite> (Akbik et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_3",
  "x": "However, both<cite> Akbik et al. (2018)</cite> and Bohnet et al. (2018) discard all other contextual character embeddings, and no analyses of the models are performed at the character-level.",
  "y": "motivation"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_4",
  "x": [
   "In the current paper, we derive pre-trained contextual character embeddings from Flair's forwardbackward LM trained on a 1-billion word corpus of English (Chelba et al., 2014) , and observe if these embeddings yield the same large improvements for character-level tasks as yielded by pre-trained contextual word embeddings for word-level tasks."
  ],
  "y": "extends"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_5",
  "x": "\u2022 We derive pre-trained contextual character embeddings from Flair<cite> (Akbik et al., 2018)</cite> , apply them to a state-of-the art time normalizer (Laparra et al., 2018a) , and obtain major performance improvements over the previous state-of-the-art: 51% error reduction in news and 33% error reduction in clinical notes.",
  "y": "extends"
 },
 {
  "id": "b31acd3535cd740e609d45986fbf33_7",
  "x": "We derive pre-trained character-level contextual embeddings from Flair<cite> (Akbik et al., 2018)</cite> , a wordlevel embedding model, inject these into a state-ofthe-art time normalization system, and achieve major performance improvements: 51% error reduction in news and 33% in clinical notes.",
  "y": "extends"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_0",
  "x": "One recent exception is<cite> Neubig and Hu (2018)</cite> which trained many-to-one models from 58 languages into English.",
  "y": "background"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_1",
  "x": "Our experiments on the publicly available TED talks dataset (Qi et al., 2018) show that massively multilingual many-to-many models with up to 58 languages to-and-from English are very effective in low resource settings, allowing to use high-capacity models while avoiding overfitting and achieving superior results to the current stateof-the-art on this dataset <cite>(Neubig and Hu, 2018</cite>; Wang et al., 2019) when translating into English.",
  "y": "uses"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_2",
  "x": "Regarding the languages we evaluate on, we begin with the same four languages as<cite> Neubig and Hu (2018)</cite> -Azerbeijani (Az), Belarusian (Be), Galician (Gl) and Slovak (Sk).",
  "y": "uses"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_3",
  "x": "We also compare our massively multilingual models to bilingual baselines and to two recently published results on this dataset<cite> (Neubig and Hu (2018)</cite> ; Wang et al. (2019) ).",
  "y": "uses"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_4",
  "x": "We use tokenized BLEU in order to be comparable with<cite> Neubig and Hu (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_5",
  "x": "We first note that our many-to-many model outperforms all other models when translating into English, with 1.82 BLEU improvement (when av-eraged across the four language pairs) over the best fine-tuned many-to-one models of<cite> Neubig and Hu (2018)</cite> and 2.44 BLEU improvement over our many-to-one model when averaged across the four low-resource language pairs (Table 1) .",
  "y": "differences"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_6",
  "x": "We also note that our many-to-one model is on average 0.75 BLEU behind the best many-to-one models in<cite> Neubig and Hu (2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "b335178d833e26190b7056469d3fa7_7",
  "x": "Regarding massively multilingual models,<cite> Neubig and Hu (2018)</cite> explored methods for rapid adaptation of NMT to new languages by training multilingual models on the 59-language TED Talks corpus and fine-tuning them using data from the new languages.",
  "y": "background"
 },
 {
  "id": "b3ef4c176720bdc89d2f73a2560673_0",
  "x": "Leveraging the recent advancements (Vaswani et al., 2017;<cite> Devlin et al., 2019)</cite> in pre-trained language encoders, we attempt to predict negotiation outcomes early on in the conversation, in a completely data-driven manner ( Figure  1 ).",
  "y": "uses"
 },
 {
  "id": "b3ef4c176720bdc89d2f73a2560673_1",
  "x": "Pre-trained language models, such as BERT (Vaswani et al., 2017; <cite>Devlin et al., 2019</cite> ) have recently gained huge success on a wide range of NLP tasks.",
  "y": "background"
 },
 {
  "id": "b3ef4c176720bdc89d2f73a2560673_2",
  "x": "Pre-trained language models, such as BERT (Vaswani et al., 2017; <cite>Devlin et al., 2019</cite> ) have recently gained huge success on a wide range of NLP tasks. However, since our framework deals with various auxiliary pieces (category, price, etc.), we cannot directly leverage these language models, which have only been trained on natural language inputs.",
  "y": "differences"
 },
 {
  "id": "b3ef4c176720bdc89d2f73a2560673_3",
  "x": "Training Details: Given the multiple segments in our model input and small data size, we use BERTbase<cite> (Devlin et al., 2019)</cite> , having output dimension of 768.",
  "y": "uses"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_0",
  "x": "As we summarize in Section 2, this paper relies on the same data set and evaluation metric as <cite>DeVault et al. (2011)</cite> , which reports results for learned policies based on maximum entropy models.",
  "y": "similarities uses"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_1",
  "x": "We refer the reader to <cite>DeVault et al. (2011)</cite> for additional details.",
  "y": "background"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_2",
  "x": "We perform our experiments and evaluation using an existing set of 19 annotated Amani dialogues<cite> (DeVault et al., 2011)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_3",
  "x": "The system builders' intended policy for Amani is detailed in <cite>DeVault et al. (2011)</cite> .",
  "y": "background"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_4",
  "x": "In other cases, up to 6 different system SAs were selected<cite> (DeVault et al., 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_5",
  "x": "To measure the performance of the dialogue policy, we follow the approach of <cite>DeVault et al. (2011)</cite> , which counts an automatically produced system SA as correct if that SA was chosen by at least one referee for that dialogue turn in the data set.",
  "y": "uses similarities"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_6",
  "x": "(We do not expect that an automatic system would outperform a human referee.) This score is .79; see <cite>DeVault et al. (2011)</cite> for discussion.",
  "y": "background"
 },
 {
  "id": "b3f7051cbba3344f0aec0f2e80d5e0_7",
  "x": "As previously reported in <cite>DeVault et al. (2011)</cite> , a performance of .66 is achieved with the MaxEnt policy when trained on text-based features.",
  "y": "background"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_0",
  "x": "The state-of-the-art approach<cite> (Shimaoka et al., 2017)</cite> for fine-grained entity typing employs an attentive neural architecture to learn representations of the entity mention as well as its context.",
  "y": "background"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_1",
  "x": "As shown in Figure 1 , featurizer \u03d5 in our model contains three encoders which encode entity e and its context x into feature vectors, and we consider both sentence-level context x s and document-level context x d in contrast to prior work which only takes sentence-level context (Gillick et al., 2014;<cite> Shimaoka et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_2",
  "x": "This is different from <cite>Shimaoka et al. (2017)</cite> who use two separate bi-directional RNNs for context on each side of the entity mention.",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_3",
  "x": "The dot-product attention differs from the self attention<cite> (Shimaoka et al., 2017)</cite> which only considers the context.",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_4",
  "x": "In prior work, a fixed threshold (r t = 0.5) is used for classification of all types (Ling and Weld, 2012;<cite> Shimaoka et al., 2017)</cite> . We instead assign a different threshold to each type that is optimized to maximize the overall strict F 1 on the dev set.",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_5",
  "x": "Note that (1) without adaptive thresholds or document-level contexts, our approach still outperforms other approaches on macro F 1 and micro F 1 ; (2) adding hand-crafted features<cite> (Shimaoka et al., 2017)</cite> does not improve the performance.",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_6",
  "x": "Ma et al. (2016) 49.30 68.23 61.27 AFET (Ren et al., 2016a) 55.10 71.10 64.70 FNET (Abhishek et al., 2017) 52.20 68.50 63.30 NEURAL<cite> (Shimaoka et al., 2017)</cite> This indicates the benefits of our proposed model architecture for learning fine-grained entity typing, which is discussed in detail in Section 3.4; and (3) BINARY and KWASIBIE were trained on a different dataset, so their results are not directly comparable.",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_7",
  "x": "Ling and Weld (2012) 52.30 69.90 69.30 PLE (Ren et al., 2016b) 49.44 68.75 64.54 Ma et al. (2016) 53.54 68.06 66.53 AFET (Ren et al., 2016a) 53.30 69.30 66.40 NEURAL<cite> (Shimaoka et al., 2017)</cite> proach still achieves the state-of-the-art strict and micro F 1 . If compared with the ablation variant of the NEURAL approach, i.e., w/o hand-crafted features, our approach gains significant improvement.",
  "y": "differences"
 },
 {
  "id": "b49807b058e5e1e50eae524e592401_8",
  "x": "Through experiments, we observe no improvement by encoding type hierarchical information<cite> (Shimaoka et al., 2017)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_0",
  "x": "Researchers have proposed systems to detect social power relations between participants of organizational email threads<cite> (Bramsen et al., 2011</cite>; Gilbert, 2012; , online forums (Danescu-NiculescuMizil et al., 2012; Biran et al., 2012; DanescuNiculescu-Mizil et al., 2013) , chats (Strzalkowski et al., 2012) , and off-line interactions such as presidential debates Nguyen et al., 2013) .",
  "y": "background"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_1",
  "x": "Early NLP-based approaches such as<cite> Bramsen et al. (2011) and</cite> Gilbert (2012) built systems to predict hierarchical power relations between people in the Enron email corpus using lexical features from all the messages exchanged between them.",
  "y": "background"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_2",
  "x": "**MOTIVATION** Early NLP-based approaches such as<cite> Bramsen et al. (2011) and</cite> Gilbert (2012) built systems to predict hierarchical power relations between people in the Enron email corpus using lexical features from all the messages exchanged between them. One limitation of this approach is that it relies solely on lexical cues and hence works best when large collections of messages exchanged between the pairs of people are available.",
  "y": "background motivation"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_3",
  "x": "For example,<cite> Bramsen et al. (2011)</cite> excluded sender-recipient pairs who exchanged fewer than 500 words from their evaluation set, since they found smaller text samples are harder to classify.",
  "y": "background"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_4",
  "x": "**MOTIVATION** Early NLP-based approaches such as<cite> Bramsen et al. (2011) and</cite> Gilbert (2012) built systems to predict hierarchical power relations between people in the Enron email corpus using lexical features from all the messages exchanged between them. One limitation of this approach is that it relies solely on lexical cues and hence works best when large collections of messages exchanged between the pairs of people are available. For example,<cite> Bramsen et al. (2011)</cite> excluded sender-recipient pairs who exchanged fewer than 500 words from their evaluation set, since they found smaller text samples are harder to classify.",
  "y": "background motivation"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_5",
  "x": "From<cite> (Bramsen et al., 2011)</cite> we retain the idea that we want to predict the power relation between pairs of people. But in contrast to their formulation, we retain the goal from ) that we want to study communication in the context of an interaction, and that we want to be able to make predictions using only the emails exchanged in a single thread.",
  "y": "differences"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_6",
  "x": "This problem formulation is similar to the ones in<cite> (Bramsen et al., 2011)</cite> and (Gilbert, 2012) .",
  "y": "similarities"
 },
 {
  "id": "b4d7e9b7942698ef0678d3b4a0ad7d_7",
  "x": "Lexical features have already been shown to be valuable in predicting power relations<cite> (Bramsen et al., 2011</cite>; Gilbert, 2012) .",
  "y": "background"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_0",
  "x": "We compare them with the original model released by <cite>Mikolov</cite>.",
  "y": "uses"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_1",
  "x": "Besides, using a small corpus, we obtain better human-assigned WordSim scores, corresponding Spearman correlation and better downstream (NER & SA) performance compared to <cite>Mikolov'</cite>s model, trained on 100 billion word corpus.",
  "y": "differences"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_2",
  "x": "There have been many implementations of the word2vec model in either of the two architectures it provides: continuous skipgram and continuous bag of words (CBoW) (<cite>Mikolov et al. (2013a)</cite> ).",
  "y": "motivation"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_3",
  "x": "Breaking away from the non-distributed (high-dimensional, sparse) representations of words, typical of traditional bag-of-words or one-hot-encoding (Turian et al. (2010) ), <cite>Mikolov et al. (2013a)</cite> created word2vec.",
  "y": "background"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_4",
  "x": "A loglinear classifier is used in both architectures (<cite>Mikolov et al. (2013a)</cite> ).",
  "y": "background"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_5",
  "x": "Besides, <cite>Mikolov et al. (2013a)</cite> showed with vector space algebra that relationships among words can be evaluated, expressing the quality of vectors produced from the model.",
  "y": "background"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_6",
  "x": "Combination of both syntactic and semantic analyses is possible and provided (totaling over 19,000 questions) as Google analogy test set by <cite>Mikolov et al. (2013a)</cite> .",
  "y": "background"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_7",
  "x": "<cite>Mikolov et al. (2013a)</cite> tried various hyper-parameters with both architectures of <cite>their</cite> model, ranging from 50 to 1,000 dimensions, 30,000 to 3,000,000 vocabulary sizes, 1 to 3 epochs, among others.",
  "y": "background"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_8",
  "x": "In both tasks, the default pytorch embedding was tested before being replaced by pre-trained embeddings released by <cite>Mikolov et al. (2013a)</cite> and ours.",
  "y": "uses"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_9",
  "x": "Meanwhile, increasing the corpus size to BW, w4s1h0 performs best in terms of analogy score while w8s1h0 maintains its position as the best in terms of WordSim and Spearman correlation. Besides considering quality metrics, it can be observed from table 4 that comparative ratio of values between the models is not commensurate with the results in intrinsic or extrinsic values, especially when we consider the amount of time and energy spent, since more training time results in more energy consumption Information on the length of training time for the released <cite>Mikolov</cite> model is not readily available.",
  "y": "differences"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_10",
  "x": "2 With regards to NER, most pretrained embeddings outperformed the default pytorch embedding, with our BW w4s1h0 model (which is best in BW analogy score) performing best in F1 score and closely followed by <cite>Mikolov et al. (2013a)</cite> model.",
  "y": "differences"
 },
 {
  "id": "b5097b3d901d073bfe06bcd88318ac_11",
  "x": "<cite>Mikolov et al. (2013a)</cite> performed second worst of all, despite originating from a very huge corpus.",
  "y": "differences"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_0",
  "x": "The semi-supervised approach circumvents the need to include word n-gram features from any tweets, and builds upon the successful usage of word representations (Collobert et al., 2011) , and word clusters (Lin & Wu, 2009; Miller et al., 2004; Ratinov & Roth, 2009;<cite> Turian et al., 2010)</cite> for NER by utilizing large amounts of unlabelled data or models pre-trained on a large vocabulary.",
  "y": "background"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_1",
  "x": "Distributed word representations have been shown to improve the accuracy of NER systems (Collobert et al., 2011;<cite> Turian et al., 2010)</cite> .",
  "y": "background"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_2",
  "x": "Word clusters are word groupings that get generated in an unsupervised fashion, and they have been successfully used as features for NER tasks (Lin & Wu, 2009; Miller et al., 2004; Ratinov & Roth, 2009;<cite> Turian et al., 2010)</cite> .",
  "y": "background"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_3",
  "x": "Although it might appear that our classifier has access to the unlabelled test data sequences while learning, it rather is the case that we resemble an online setting where we continuously update our unsupervised features using the new batch of unlabelled test data, and then retrain our model on the original training data (Blum, 1998; Blum & Mitchell, 1998; Carlson et al., 2010; Chapelle et al., 2009; Liang, 2005; <cite>Turian et al., 2010</cite>; Zhu & Goldberg, 2009) .",
  "y": "similarities"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_4",
  "x": "Prior work has shown that semi-supervised algorithms can perform decently for NER tasks with sparse labelled data (Blum, 1998; Carlson et al., 2010; Chapelle et al., 2009; Liang, 2005; <cite>Turian et al., 2010</cite>; Zhu & Goldberg, 2009 ).",
  "y": "background"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_5",
  "x": "Prior work has shown that semi-supervised algorithms can perform decently for NER tasks with sparse labelled data (Blum, 1998; Carlson et al., 2010; Chapelle et al., 2009; Liang, 2005; <cite>Turian et al., 2010</cite>; Zhu & Goldberg, 2009 ). We leverage this fact in our SI model via the use of unsupervised word clusters, word representations, and refined gazetteers; all of which contributed to a cumulative increase in accuracy over our initial submission [ST] by ~11% when using the test data for evaluation.",
  "y": "uses background"
 },
 {
  "id": "b624e8d3ad3d351d4cb27ea4b5c616_6",
  "x": "As identified by<cite> Turian et al. (2010)</cite> , the importance of word representations and word clusters increases as the availability of unlabelled data increases.",
  "y": "background"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_1",
  "x": "These give rise to the research problem * Work done when the first author was visiting SUTD. of effectively making use of multiple treebanks under heterogeneous annotations for improving output accuracies (Jiang et al., 2015; Johansson, 2013;<cite> Li et al., 2015)</cite> .",
  "y": "motivation"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_2",
  "x": "The second approach is based on multi-view learning (Johansson, 2013;<cite> Li et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_3",
  "x": "We follow<cite> Li et al. (2015)</cite> , taking POS-tagging for case study, using the methods of Jiang et al. (2009) and<cite> Li et al. (2015)</cite> as the discrete stacking and multi-view training baselines, respectively, and building neural network counterparts to their models for empirical comparison.",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_4",
  "x": "First, it is free from the necessity of manual cross-labelset interactive feature engineering, which is far from trivial for representing annotation correspondence <cite>(Li et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_5",
  "x": "We follow<cite> Li et al. (2015)</cite> , taking POS-tagging for case study, using the methods of Jiang et al. (2009) and<cite> Li et al. (2015)</cite> as the discrete stacking and multi-view training baselines, respectively, and building neural network counterparts to their models for empirical comparison. First, it is free from the necessity of manual cross-labelset interactive feature engineering, which is far from trivial for representing annotation correspondence <cite>(Li et al., 2015)</cite> .",
  "y": "uses background"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_6",
  "x": "As shown in Figure 1(b) , multi-view learning <cite>(Li et al., 2015)</cite> utilizes corpus A and corpus B simultaneously for training.",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_7",
  "x": "For neural multi-view model, we follow<cite> Li et al. (2015)</cite> and take a the corpus-weighting strategy to sample a number of training instances from both corpora for each training iteration, as shown in Algorithm 1.",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_8",
  "x": "We adopt the Penn Chinese Treebank version 5.0 (CTB5) (Xue et al., 2005) as our main corpus, with the standard data split following previous work (Zhang and Clark, 2008;<cite> Li et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_9",
  "x": "As a result, we choose a dropout rate of 20% for the remaining experiments, which strikes the balance between over-System Accuracy CRF Baseline <cite>(Li et al., 2015)</cite> 94.10 CRF Stacking <cite>(Li et al., 2015)</cite> 94.81 CRF Multi-view <cite>(Li et al., 2015)</cite> 95 Table 2 : Accuracies on CTB-test.",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_10",
  "x": "We lists the results of stacking method of Jiang et al. (2009) re-implemented by<cite> Li et al. (2015)</cite> , and CRF multi-view method reported by<cite> Li et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_11",
  "x": "With respect of the multiview training method, the NN model improves over the NN baseline from 94.24 to 95.40, by a margin of +1.16, which is higher than that of 0.90 brought by discrete method of<cite> Li et al. (2015)</cite> over its baseline, from 94.10 to 95.00.",
  "y": "differences"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_12",
  "x": "This is consistent with the observation of<cite> Li et al. (2015)</cite> , who showed that discrete label coupling training gives slightly better improvement compared with discrete stacking.",
  "y": "similarities"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_13",
  "x": "We compare the efficiencies of neural and discrete multi-view training by running our models and the model of<cite> Li et al. (2015)</cite> 4 with default configurations on the CTB5 training data.",
  "y": "uses"
 },
 {
  "id": "b645eee5044c17502bcdbc95934a01_14",
  "x": "The CRF baseline is adapted from<cite> Li et al. (2015)</cite> .",
  "y": "extends"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_0",
  "x": "It is able to surpass n-gram-based scores achieved previously by <cite>Du\u0161ek and Jur\u010d\u00ed\u010dek (2015)</cite> , offering a simpler setup and more relevant outputs.",
  "y": "differences"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_1",
  "x": "Both modes offer their advantages: The twostep mode simplifies generation by abstracting away from complex surface syntax and morphology, which can be handled by a handcrafted, domain-independent module to ensure grammatical correctness at all times<cite> (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015)</cite> , and the joint mode does not need to model structure explicitly and avoids accumulating errors along the pipeline (Konstas and Lapata, 2013) .",
  "y": "background"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_2",
  "x": "Our generator operates in two modes, producing either deep syntax trees (Du\u0161ek et al., 2012) or natural language strings (see Fig. 1 ). Both modes offer their advantages: The twostep mode simplifies generation by abstracting away from complex surface syntax and morphology, which can be handled by a handcrafted, domain-independent module to ensure grammatical correctness at all times<cite> (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015)</cite> , and the joint mode does not need to model structure explicitly and avoids accumulating errors along the pipeline (Konstas and Lapata, 2013) .",
  "y": "uses"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_3",
  "x": "10 The surface realizer works almost flawlessly on this lim-ited domain<cite> (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015)</cite> , leaving the seq2seq generator as the major error source.",
  "y": "uses"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_4",
  "x": "The best results of both setups surpass the best results on this dataset using training data without manual alignments<cite> (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015)</cite> in both automatic metrics 12 and the number of semantic errors.",
  "y": "differences"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_5",
  "x": "Works using the pipeline approach in SDS tend to focus on sentence planning, improving a handcrafted generator (Walker et al., 2001; Stent et al., 2004; Paiva and Evans, 2005) or using perceptron-guided A* search<cite> (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_6",
  "x": "Works using the pipeline approach in SDS tend to focus on sentence planning, improving a handcrafted generator (Walker et al., 2001; Stent et al., 2004; Paiva and Evans, 2005) or using perceptron-guided A* search<cite> (Du\u0161ek and Jur\u010d\u00ed\u010dek, 2015)</cite> . We extend the previous works by generating deep syntax trees as well as strings and directly comparing pipeline and joint generation.",
  "y": "extends"
 },
 {
  "id": "b6afd492c60af7ab1ba0be3cd654b2_7",
  "x": "Our generator was able to surpass the best BLEU/NIST scores on the same dataset previously achieved by a perceptron-based generator of <cite>Du\u0161ek and Jur\u010d\u00ed\u010dek (2015)</cite> while reducing the amount of irrelevant information on the output.",
  "y": "differences"
 },
 {
  "id": "b6c33fbb73cbf0af580e8dd14dc59a_0",
  "x": "For the task of text generation, MaskGAN [13] uses a Reinforcement Learning signal from the discriminator, FMD-GAN<cite> [14]</cite> uses an optimal transport mechanism as an objective function.",
  "y": "background"
 },
 {
  "id": "b6c33fbb73cbf0af580e8dd14dc59a_1",
  "x": "GANs have shown to be successful in image generation tasks [18] and recently, some progress has been observed in text generation <cite>[14,</cite> 13, 16] .",
  "y": "background"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_0",
  "x": "Assuming access to a small amount * Performed while faculty at Johns Hopkins University of parallel text is realistic, especially considering the recent success of crowdsourcing translations (Zaidan and Callison-Burch, 2011; Ambati, 2011; <cite>Post et al., 2012)</cite> .",
  "y": "motivation"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_1",
  "x": "5 The<cite> Post et al. (2012)</cite> also induce translations for source language words which are low frequency in the training data and supplement our SMT models with top-k translations, not just the highest ranked.",
  "y": "extends differences"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_2",
  "x": "We use the data splits given by<cite> Post et al. (2012)</cite> and, following that work, include the dictionaries in the training data and report results on the devtest set using case-insensitive BLEU and four references.",
  "y": "similarities uses"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_3",
  "x": "In order to make our results comparable to those of<cite> Post et al. (2012)</cite> , we follow that work and use Table 3 : Percent of word types in a held out portion of the training data which are translated correctly by our bilingual lexicon induction technique.",
  "y": "similarities uses"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_4",
  "x": "9<cite> Post et al. (2012)</cite> gathered up to six translations for each source word, so some have multiple correct translations appending the top-k translations for OOV words to our model instead of just the top-1.",
  "y": "extends differences"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_6",
  "x": "In the experiments above, we only evaluated our methods for improving the accuracy and coverage of models trained on small amounts of bitext using the full parallel training corpora released by<cite> Post et al. (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "b6efc2f5239a0c5d9210d7da8466ab_7",
  "x": "As<cite> Post et al. (2012)</cite> showed, it is reasonable to assume a small parallel corpus for training an SMT model even in a low resource setting.",
  "y": "similarities"
 },
 {
  "id": "b7158e8478b14cd8337f2aa8ee6193_0",
  "x": "We employ the publicly available parallel data-to-text corpus E2E <cite>(Novikova et al., 2017)</cite> consisting of tabulated data and English descriptions in the restaurant domain.",
  "y": "uses"
 },
 {
  "id": "b7158e8478b14cd8337f2aa8ee6193_1",
  "x": "We conduct experiments on the E2E corpus <cite>(Novikova et al., 2017)</cite> which amounts to roughly 42k samples in the training set.",
  "y": "uses"
 },
 {
  "id": "b7158e8478b14cd8337f2aa8ee6193_2",
  "x": "An example of the English/pidgin text in the restaurant domain <cite>(Novikova et al., 2017)</cite> is displayed in Table 1 .",
  "y": "uses"
 },
 {
  "id": "b71da01fb46900d81162b3a3c3cd41_0",
  "x": "Using this technique, the system of <cite>Nivre (2009)</cite> processes unrestricted non-projective structures with state-ofthe-art accuracy in observed linear time.",
  "y": "background"
 },
 {
  "id": "b71da01fb46900d81162b3a3c3cd41_1",
  "x": "In this paper, we show that the oracle used for training by <cite>Nivre (2009)</cite> is suboptimal because it eagerly swaps words as early as possible and therefore makes a large number of unnecessary transitions, which potentially affects both efficiency and accuracy.",
  "y": "differences"
 },
 {
  "id": "b71da01fb46900d81162b3a3c3cd41_2",
  "x": "This idea is implemented in the transition system proposed by <cite>Nivre (2009)</cite> .",
  "y": "background"
 },
 {
  "id": "b71da01fb46900d81162b3a3c3cd41_3",
  "x": "There may be more than one such permutation, but <cite>Nivre (2009)</cite> defines the canonical projective order < G for x given G as the order given by an inorder traversal of G that respects the order < between a node and its direct dependents.",
  "y": "background"
 },
 {
  "id": "b71da01fb46900d81162b3a3c3cd41_5",
  "x": "Our experiments are based on the same five data sets as <cite>Nivre (2009)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_0",
  "x": "It differs significantly from various spoken varieties of Arabic (Zaidan and Callison-Burch, 2011; Zaidan and Callison-Burch, 2014;<cite> Elfardy and Diab, 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_1",
  "x": "Similar to<cite> (Elfardy and Diab, 2013)</cite> , we present a sentence-level classifier that is trained in a supervised manner. Some improvements in terms of classification accuracy and 10-fold cross validation under the same data conditions as (Zaidan and Callison-Burch, 2011;<cite> Elfardy and Diab, 2013)</cite> are presented.",
  "y": "similarities"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_2",
  "x": "While most of the above work focuses on document-level language classification, recent work on handling Arabic dialect data addresses the problem of sentence-level classification (Zaidan and CallisonBurch, 2011; Zaidan and Callison-Burch, 2014; <cite>Elfardy and Diab, 2013</cite>; Zaidan and Callison-Burch, 2014 ).",
  "y": "motivation"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_3",
  "x": "For our experiments, we use the data set provided in (Zaidan and Callison-Burch, 2011 ) which also has been used in the experiments in<cite> (Elfardy and Diab, 2013</cite>; Zaidan and Callison-Burch, 2014) .",
  "y": "similarities uses"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_4",
  "x": "In addition, we have implemented a range of so-called 'meta' features similar to the ones defined in<cite> (Elfardy and Diab, 2013)</cite> .",
  "y": "similarities"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_5",
  "x": "Contrary to<cite> (Elfardy and Diab, 2013)</cite> we find that those features do not improve accuracy of our best model in the cross-validation experiments.",
  "y": "differences"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_6",
  "x": "The resulting (averaged) accuracy is 83.3 % for cross-validation and 82.2 % on the DEV12 tune set. In comparison,<cite> (Elfardy and Diab, 2013)</cite> reports an accuracy of 80.4 % as perplexity-based baseline.",
  "y": "differences"
 },
 {
  "id": "b86a5a8ec1f27354057bb45ff27588_7",
  "x": "Similarly, we use linear SVMs to train a classification model at the sentence level without access to sentence length statistics, i.e. our best performing classifier does not compute features like the percentage of punctuation, numbers, or averaged word length as has been proposed previously<cite> (Elfardy and Diab, 2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_0",
  "x": "One important avenue in this work is to understand the structure in argumentative text (Persing & Ng, 2016; Peldszus & Stede, 2015;<cite> Stab & Gurevych, 2016</cite>; Nguyen & Litman, 2016) .",
  "y": "uses"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_1",
  "x": "Second, we follow previous work that assumes a tree structure for the linking of ACs (Palau & Moens, 2009; Cohen, 1987; Peldszus & Stede, 2015;<cite> Stab & Gurevych, 2016)</cite> Figure 1: An example of argument structure with four ACs.",
  "y": "uses"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_2",
  "x": "Figure 1 shows an example that we will use throughout the paper to concretely explain how our approach works. First, the left side of the figure presents the raw text of a paragraph in a persuasive essay<cite> (Stab & Gurevych, 2016)</cite> , with the ACs contained in square brackets.",
  "y": "uses"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_3",
  "x": "Linking to the first argument component can provide a competitive baseline heuristic (Peldszus & Stede, 2015;<cite> Stab & Gurevych, 2016)</cite> .",
  "y": "uses background"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_4",
  "x": "We evaluate our models on the corpora of <cite>Stab & Gurevych (2016)</cite> and Peldszus (2014) , and compare our results with the results of the aformentioned authors.",
  "y": "uses"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_5",
  "x": "Various authors have also proposed to jointly model link extraction with other subtasks from the argumentation mining pipeline, using either an Integer Linear Programming (ILP) framework (Persing & Ng, 2016;<cite> Stab & Gurevych, 2016)</cite> or directly feeding previous subtask predictions into another model.",
  "y": "background"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_6",
  "x": "We follow the work of <cite>Stab & Gurevych (2016)</cite> and focus on three different types of features to represent our ACs: 1) Bag-of-Words of the AC; 2) Embedding representation based on GloVe embeddings (Pennington et al., 2014) ; 3) Structural features: Whether or not the AC is the first AC in a paragraph, and Whether the AC is in an opening, body, or closing paragraph.",
  "y": "uses"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_7",
  "x": "We test the effectiveness of our proposed model on a dataset of persuasive essays<cite> (Stab & Gurevych, 2016)</cite> , as well as a dataset of microtexts (Peldszus, 2014) .",
  "y": "uses"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_8",
  "x": "Conversely, the ILP Joint Model<cite> (Stab & Gurevych, 2016)</cite> provides constrains by sharing prediction information between the base classifier.",
  "y": "uses background"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_9",
  "x": "In both corpora we compare against the following previously proposed models: Base Classifier (Stab & Gurevych, 2016 ) is feature-rich, task-specific (AC type or link extraction) SVM classifier. Neither of these classifiers enforce structural or global constraints. Conversely, the ILP Joint Model<cite> (Stab & Gurevych, 2016)</cite> provides constrains by sharing prediction information between the base classifier.",
  "y": "uses motivation"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_10",
  "x": "The popular method of averaging embeddings (which is used by <cite>Stab & Gurevych (2016)</cite> in their system) is in fact the worst method, although its performance is still competitive with the previous state-of-the-art.",
  "y": "motivation"
 },
 {
  "id": "b87a8d14f1c2016caa7538aa08a33f_11",
  "x": "We evaluate our models on two corpora: a corpus of persuasive essays<cite> (Stab & Gurevych, 2016)</cite> , and a corpus of microtexts (Peldszus, 2014) .",
  "y": "uses"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_0",
  "x": "Recently, neural approaches have reached very competitive accuracy levels, improving over the state of the art in a number of settings<cite> (Plank et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_1",
  "x": "Such representations, often extracted from large amounts of raw text, have proved very useful for numerous tasks including PoS tagging, in particular when used in recurrent neural networks (RNNs) and more specifically in mono-or bi-directional, word-level or characterlevel long short-term memory networks (LSTMs) (Hochreiter and Schmidhuber, 1997; Ling et al., 2015; Ballesteros et al., 2015; <cite>Plank et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_2",
  "x": "As shown by<cite> Plank et al. (2016)</cite> , state-of-the-art performance can be achieved using a bi-LSTM architecture fed with word representations.",
  "y": "background"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_3",
  "x": "Further improvements can be obtained on most but not all languages by initialising the word embedding layer with pre-computed word embeddings. We refer to<cite> Plank et al. (2016)</cite> for further details.",
  "y": "motivation"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_4",
  "x": "Pre-computed embeddings Whenever available and following<cite> Plank et al. (2016)</cite> , we performed experiments using Polyglot pre-computed embeddings (Al-Rfou et al., 2013) .",
  "y": "uses"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_5",
  "x": "PoS accuracy scores are given for each language in the baseline configuration (the same as <cite>Plank et al., 2016)</cite> and in the lexicon-enabled configuration.",
  "y": "uses"
 },
 {
  "id": "b8d0e66901698d201b9fb1f362b8c6_6",
  "x": "We use as a baseline the state-of-the-art bi-LSTM PoS tagger bilty, a freely available 6 and \"significantly refactored version of the code originally used\" by<cite> Plank et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "b8f090dadfbd01a17912e006e7ccfc_0",
  "x": "Examples of combinations of distinct strategies are described in [9] , [<cite>19</cite>] and [20].",
  "y": "background"
 },
 {
  "id": "b8f090dadfbd01a17912e006e7ccfc_1",
  "x": "Examples of combinations of distinct strategies are described in [9] , [<cite>19</cite>] and [20] .",
  "y": "background"
 },
 {
  "id": "b9a748ac201b2d8f5d52abd60aa018_0",
  "x": "Several studies have examined listenability for English learners (Kiyokawa 1990;<cite> Kotani et al. 2014</cite>; Kotani & Yoshimi 2016; Yoon et al. 2016) ; however, to the best of our knowledge, no previous studies on listenability for learners of Asian languages such as Chinese, Korean, and Japanese have been conducted.",
  "y": "background"
 },
 {
  "id": "b9a748ac201b2d8f5d52abd60aa018_1",
  "x": "<cite>Kotani et al. (2014)</cite> suggested the possibility of using different linguistic elements such as phonological features, and addressed this question by measuring listenability based on various linguistic features, including speech rate and the frequency of phonological modification patterns such as linking. In addition, their method used listening test scores as a learner feature to measure listenability relative to proficiency. This is because sentences with less listenability for learners at the beginner level might be easy for those at the advanced level. However, because that study focused on the accuracy of measurement, the question of discriminability of This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/ linguistic and learner features for the measurement of listenability remained.",
  "y": "motivation background"
 },
 {
  "id": "b9a748ac201b2d8f5d52abd60aa018_2",
  "x": "The linguistic (Chall 1948; Fang 1966; Kiyokawa 1990; Messerklinger 2006;<cite> Kotani et al. 2014</cite>; Kotani & Yoshimi 2016; Yoon et al. 2016) , and learner features<cite> (Kotani et al. 2014</cite>; Kotani & Yoshimi 2016) used in this study were originally described elsewhere.",
  "y": "uses"
 },
 {
  "id": "b9a748ac201b2d8f5d52abd60aa018_3",
  "x": "Training/test data for a decision tree classification algorithm were constructed using the learner corpus of <cite>Kotani et al. (2014)</cite> , which includes learners' judgment of listenability. Listenability was judged by learners of English as a foreign language using scores on a five-point Likert scale (1: easy, 2: somewhat easy, 3: average, 4: somewhat difficult, or 5: difficult).",
  "y": "uses"
 },
 {
  "id": "b9e1a6bb7b6f2d55c6ea3bb2d3897d_0",
  "x": "The automatic identification of information status (Prince, 1981; 1992) , i.e. categorizing discourse entities into different classes on the given-new scale, has recently been identified as an important issue in natural language processing (Nissim, 2006;<cite> Rahman and Ng, 2011</cite>; .",
  "y": "motivation"
 },
 {
  "id": "b9e1a6bb7b6f2d55c6ea3bb2d3897d_1",
  "x": "Nissim (2006) and <cite>Rahman and Ng (2011)</cite> developed methods to automatically identify three different classes: OLD, MEDIATED and NEW expressions.",
  "y": "background"
 },
 {
  "id": "b9e1a6bb7b6f2d55c6ea3bb2d3897d_2",
  "x": "Based on work described in Nissim (2006) , <cite>Rahman and Ng (2011)</cite> develop a machine learning approach to information-status determination.",
  "y": "background"
 },
 {
  "id": "b9e1a6bb7b6f2d55c6ea3bb2d3897d_3",
  "x": "In manual annotation practice, it is very often impossible to decide whether an entity is hearerknown, since this depends on who we assume the hearer to be; and even if we agree on a recipient, we may still be mistaken about their knowledge. The fact that <cite>Rahman and Ng (2011)</cite> report the highest confusion rate between NEW and MEDIATED entities may have its roots in this issue.",
  "y": "background motivation"
 },
 {
  "id": "b9e1a6bb7b6f2d55c6ea3bb2d3897d_4",
  "x": "The fact that <cite>Rahman and Ng (2011)</cite> report the highest confusion rate between NEW and MEDIATED entities may have its roots in this issue.",
  "y": "background motivation"
 },
 {
  "id": "b9e1a6bb7b6f2d55c6ea3bb2d3897d_5",
  "x": "We also include a basic \"coreference\" feature, similar to the lexical features of <cite>Rahman and Ng (2011)</cite> , that fires if there is some lexical overlap of nouns (or compound nouns) in the preceding 10 sentences.",
  "y": "similarities"
 },
 {
  "id": "b9e9f358ace19da43bfe9e5bc380c5_0",
  "x": "In particular, we translate the Spider<cite> (Yu et al., 2018b)</cite> dataset into Chinese.",
  "y": "extends differences"
 },
 {
  "id": "b9e9f358ace19da43bfe9e5bc380c5_1",
  "x": "Recently, <cite>Yu et al. (2018b)</cite> released a manually labelled dataset for parsing natural language questions into complex SQL, which facilitates related research. <cite>Yu et al. (2018b)</cite> 's dataset is exclusive for English questions.",
  "y": "background"
 },
 {
  "id": "b9e9f358ace19da43bfe9e5bc380c5_2",
  "x": "<cite>Yu et al. (2018b)</cite> 's dataset is exclusive for English questions. Intuitively, the same semantic parsing task can be applied cross-lingual, since SQL is a universal semantic representation and database interface. However, for languages other than English, there can be added difficulties parsing into SQL. Take Chinese for example, the additional challenges can be at least two-fold. First, structures of relational databases, in particular names and column names of DB tables, are typically represented in English. This adds to the challenges to question-to-DB mapping.",
  "y": "motivation"
 },
 {
  "id": "b9e9f358ace19da43bfe9e5bc380c5_3",
  "x": "The second and dominant category of datasets uses SQL, which includes Restaurants (Tang and Mooney, 2001; Popescu et al., 2003) , Academic (Iyer et al., 2017) , Yelp and IMDB (Yaghmazadeh et al., 2017) , Ad-vising (Finegan-Dollak et al., 2018) and the recently proposed WikiSQL (Zhong et al., 2017) and Spider<cite> (Yu et al., 2018b)</cite> .",
  "y": "background"
 },
 {
  "id": "b9e9f358ace19da43bfe9e5bc380c5_4",
  "x": "Following the database split setting of <cite>Yu et al. (2018b)</cite> , we make training, development and test sets split in a way that no database overlaps in them as shown in Table 1 .",
  "y": "uses"
 },
 {
  "id": "b9e9f358ace19da43bfe9e5bc380c5_5",
  "x": "We follow <cite>Yu et al. (2018b)</cite> , evaluating the results using two major 2 https://nlp.stanford.edu/projects/glove/ 3 https://ai.tencent.com/ailab/nlp/embedding.html types of metrics.",
  "y": "uses"
 },
 {
  "id": "bbacc6539a7346e4f30a1ae42a636e_0",
  "x": "The remainder of the chapter introduces three predominant instantiations of syntax-based models: hierarchical phrase-based SMT (Hiero) <cite>(Chiang 2007)</cite> , which is a non-labeled syntax-based SMT approach arising from the phrase-based approach; syntax-augmented machine translation (SAMT), which introduces the notion of soft labels while keeping the nonlinguistic phrase notion; and GHKM (Galley et al. 2004 ), which only extracts translation rules consistent with constituency parse subtrees.",
  "y": "background"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_0",
  "x": "Many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of constituents (Collins 1997<cite> (Collins , 1999</cite> Eisner 1997) , leaving it as an open question whether there exist important statistical dependencies that go beyond linguistically motivated dependencies.",
  "y": "background"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_1",
  "x": "This distinguishes DOP1 from most other statistical parsing models that identify exactly one derivation for each parse tree and thus compute the probability of a tree by only one product of probabilities --see Collins (1997<cite> Collins ( , 1999</cite> , Charniak (1997 Charniak ( , 2000 and Eisner (1997 (Dempster et al. 1977) , but this resulted in a decrease in parse accuracy on the ATIS and OVIS corpora (Bod 2000a) , although it slightly improved the word error rate for OVIS word-graphs.",
  "y": "background"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_2",
  "x": "For our base line parse accuracy, we used the now standard division of the WSJ (see Collins 1997 <cite>Collins , 1999</cite> Charniak 1997 Charniak , 2000 Ratnaparkhi 1999 ) with sections 2 through 21 for training (approx. 40,000 sentences) and section 23 for testing (2416 sentences \u2264 100 words); section 22 was used as development set.",
  "y": "similarities"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_3",
  "x": "Such \"head-lexicalized stochastic grammars\" have recently become increasingly popular (e.g. Collins 1997 <cite>Collins , 1999</cite> Charniak 1997 Charniak , 2000 and are based on Magerman's head-percolation scheme to determine the headword of each nonterminal (Magerman 1995) .",
  "y": "background"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_4",
  "x": "We should note, however, that most other stochastic parsers do include counts of single nonheadwords: they appear in the backed-off statistics of these parsers (see Collins 1997 <cite>Collins , 1999</cite> Charniak 1997; Goodman 1998) .",
  "y": "background"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_5",
  "x": "A major difference between our approach and most other models tested on the WSJ is that the DOP model uses frontier lexicalization while most other models use, what we might call, constituent lexicalization (in that it associates each constituent nonterminal with its lexical head --see Collins 1997 <cite>Collins , 1999</cite> Charniak 1997; Eisner 1997) .",
  "y": "differences"
 },
 {
  "id": "bbd8c1007b573758fc78a6d16e2b77_6",
  "x": "The importance of including counts of (single) nonheadwords is now also quite uncontroversial (e.g. Collins 1997 <cite>Collins , 1999</cite> Charniak 2000) , and the current paper has shown the importance of including two and more nonheadwords.",
  "y": "similarities"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_0",
  "x": "As an example of such work, <cite>Zhang et al. (2008)</cite> have shown in the past that deep linguistic parsing outputs can be integrated to help improve the performance of the English semantic role labeling task.",
  "y": "background"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_1",
  "x": "It is similar to the architecture used by <cite>Zhang et al. (2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_2",
  "x": "Comparing to <cite>Zhang et al. (2008)</cite> , this architecture simplified the syntactic component, and puts more focus on the integration of deep parsing outputs.",
  "y": "differences"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_3",
  "x": "While <cite>Zhang et al. (2008)</cite> only used seman- tic features from HPSG parsing in the SRL task, we added extra syntactic features from deep parsing to help both tasks.",
  "y": "differences"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_4",
  "x": "Deep Semantic Features Similar to <cite>Zhang et al. (2008)</cite> , we extract a set of features from the semantic outputs (MRS) of the HPSG parses.",
  "y": "similarities"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_5",
  "x": "The semantic role labeling component used in the submitted system is similar to the one described by <cite>Zhang et al. (2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_6",
  "x": "Confirming the observation of <cite>Zhang et al. (2008)</cite> , the gain with HPSG features is more significant on outdomain tests, this time on German as well.",
  "y": "similarities"
 },
 {
  "id": "bce5c3bf551a8aa211dfd962cde7a8_7",
  "x": "The conclusion of <cite>Zhang et al. (2008)</cite> has been reconfirmed on multiple languages for which we handbuilt HPSG grammars exist, even where grammatical coverage is low.",
  "y": "background"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_0",
  "x": "As a consequence, in the last few years many diagnostic tasks and datasets have been proposed aiming at investigating the capabilities of such models in more detail to determine whether and how these models are capable of exploiting visual and/or linguistic information<cite> (Shekhar et al., 2017b</cite>; Johnson et al., 2017; Antol et al., 2015; Chen et al., 2015; Gao et al., 2015; Yu et al., 2015; Zhu et al., 2016) .",
  "y": "background"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_1",
  "x": "FOIL<cite> (Shekhar et al., 2017b</cite> ) is one such dataset.",
  "y": "background"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_2",
  "x": "We combine the tasks and data from<cite> Shekhar et al. (2017b)</cite> and Shekhar et al. (2017a) .",
  "y": "extends uses"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_3",
  "x": "The Verb, Adjective, Adverb and Preposition subsets were obtained using a slightly different methodology (see Shekhar et al. (2017a) ) than that used for Nouns<cite> (Shekhar et al., 2017b)</cite> .",
  "y": "background"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_4",
  "x": "The Verb, Adjective, Adverb and Preposition subsets were obtained using a slightly different methodology (see Shekhar et al. (2017a) ) than that used for Nouns<cite> (Shekhar et al., 2017b)</cite> . Therefore, we evaluate these two groups separately.",
  "y": "uses"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_5",
  "x": "Data: We use the dataset for nouns from<cite> Shekhar et al. (2017b)</cite> 1 and the datasets for other parts of speech from Shekhar et al. (2017a) 2 .",
  "y": "uses"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_7",
  "x": "We also note that the performance is better than human performance. We hypothesize the following reasons for this: (a) human responses were crowd-sourced, which could have resulted in some noisy annotations; (b) our gold object-based features closely resembles the information used for data-generation as described in<cite> Shekhar et al. (2017b)</cite> for the foil noun dataset.",
  "y": "uses"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_8",
  "x": "We hypothesize the following reasons for this: (a) human responses were crowd-sourced, which could have resulted in some noisy annotations; (b) our gold object-based features closely resembles the information used for data-generation as described in<cite> Shekhar et al. (2017b)</cite> for the foil noun dataset.",
  "y": "similarities"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_9",
  "x": "Our overall accuracy is substantially higher than that reported in<cite> Shekhar et al. (2017b)</cite> .",
  "y": "differences"
 },
 {
  "id": "bcf19914bb67ded47785d298969a7a_10",
  "x": "The accuracy of our models is substantially higher than that reported in<cite> Shekhar et al. (2017b)</cite> , even for equivalent models.",
  "y": "differences"
 },
 {
  "id": "bd12a9270c5f94056701b86eda9c8e_0",
  "x": "The tokenization used was the one provided by OpenNMT 3 and words were divided in subwords according to the BPE <cite>(Sennrich et al., 2016)</cite> approach.",
  "y": "uses"
 },
 {
  "id": "bd12a9270c5f94056701b86eda9c8e_1",
  "x": "The tokenization used was the one provided by OpenNMT 3 and words were divided in subwords according to the BPE <cite>(Sennrich et al., 2016)</cite> approach.",
  "y": "uses"
 },
 {
  "id": "bd64b244756259f18f7c3cb60989a2_0",
  "x": "Finally, a set of experiments was performed in which the synthetic parallel corpus, obtained via back-translation, was filtered with Bicleaner 2 <cite>(S\u00e1nchez-Cartagena et al. 2018</cite> ), a tool for misalignment detection.",
  "y": "uses"
 },
 {
  "id": "bd64b244756259f18f7c3cb60989a2_1",
  "x": "Finally, the misalignment detection tool Bicleaner <cite>(S\u00e1nchez-Cartagena et al. 2018</cite> ) was applied to these aligned sentences (the Bicleaner threshold was set to 0.5 8 ).",
  "y": "uses"
 },
 {
  "id": "bd64b244756259f18f7c3cb60989a2_3",
  "x": "Finally, we presented a lightweight method for filtering synthetic sentence pairs obtained via back-translation, using a tool for misalignment detection, Bicleaner<cite> (S\u00e1nchez-Cartagena et al. 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_0",
  "x": "In a previous paper<cite> [5]</cite> we have presented a methodology for the automatic summarization of documents, emitted by multiple sources, which describe the evolution of an event.",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_1",
  "x": "The creation of this graph can be considered as completing-as we have previously argued<cite> [5]</cite> -the Document Planning phase of a typical architecture of a Natural Language Generation (NLG) system [20] .",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_2",
  "x": "The end result of this methodology is a graph whose vertices are the SDRs and whose nodes are some structures which we call messages. The creation of this graph can be considered as completing-as we have previously argued<cite> [5]</cite> -the Document Planning phase of a typical architecture of a Natural Language Generation (NLG) system [20] .",
  "y": "uses"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_3",
  "x": "Although this holds true for the general case of Multi-document Summarization, for the case of summarizing evolving events the identification of the similarities and differences should be distinguished, as we have previously argued [1, 2, 4, <cite>5,</cite> 6] between two axes: the synchronic and the diachronic axes.",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_4",
  "x": "The initial inspiration for the SDRs was provided by the Rhetorical Structure Theory (RST) of Mann & Thompson [1<cite>5,</cite> 16] .",
  "y": "uses"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_5",
  "x": "Rhetorical Structure Theory-which was initially developed in the context of \"computational text generation\" 3 [1<cite>5,</cite> 16, 22] -is trying to connect several units of analysis with relations that are semantic in nature and are supposed to capture the intentions of the author.",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_6",
  "x": "The initial inspiration for the SDRs was provided by the Rhetorical Structure Theory (RST) of Mann & Thompson [1<cite>5,</cite> 16] . Rhetorical Structure Theory-which was initially developed in the context of \"computational text generation\" 3 [1<cite>5,</cite> 16, 22] -is trying to connect several units of analysis with relations that are semantic in nature and are supposed to capture the intentions of the author.",
  "y": "uses"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_7",
  "x": "Concerning the SDRs, in order to formally define a relation the following four fields ought to be defined (see also<cite> [5]</cite> ): The name of the relation carries semantic information which, along with the messages that are connected with the relation, are later being exploited by the NLG component (see<cite> [5]</cite> ) in order to produce the final summary.",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_8",
  "x": "2 Due to space limitations this section contains a very brief introduction to a methodology for the creation of summaries from evolving events that we have earlier presented<cite> [5]</cite> .",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_9",
  "x": "The interested reader is encouraged to consult [1, 2, 4, <cite>5,</cite> 6 ] for more information.",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_10",
  "x": "The creation of the grid can be considered as completing-as we have previously argued<cite> [5]</cite> -the Document Planning phase of a typical architecture of an NLG system [20] .",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_11",
  "x": "Concerning the first objection-i.e. the claim that the same trivial information might be contained in all the documents and thus such trivial information will have a high probability of being included in the final summary-this claim is rebuffed by the nature of the methodology that we have briefly presented in Section 2 and more fully exposed in [1] and<cite> [5]</cite> .",
  "y": "uses background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_12",
  "x": "As we have argued in<cite> [5]</cite> the creation of the ontology and the specifications of the messages require a considerable amount of human labor.",
  "y": "motivation"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_13",
  "x": "Nevertheless, in Section 9 of<cite> [5]</cite> we present specific propositions of how this problem can be alleviated.",
  "y": "uses"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_14",
  "x": "In [1] and<cite> [5]</cite> we thoroughly presented a methodology (and applied it in two different case studies) which aims towards the creation of summaries from descriptions of evolving events which are emitted from multiple sources.",
  "y": "background"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_15",
  "x": "In [1] and<cite> [5]</cite> we thoroughly presented a methodology (and applied it in two different case studies) which aims towards the creation of summaries from descriptions of evolving events which are emitted from multiple sources. The end result of this methodology is the computational extraction of a structure, which we called a grid. Nevertheless, it can be the case that the created grid can prove to be large enough in order for the final summary to exceed the required compression rate.",
  "y": "motivation"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_16",
  "x": "The creation of the grid can be considered as completing-as we have previously argued<cite> [5]</cite> -the Document Planning phase of a typical architecture of an NLG system [20] . Nevertheless, this graph can prove to be very large and thus the resulting summary can easily exceed the desired compression rate.",
  "y": "motivation"
 },
 {
  "id": "bdd0ebe147e277f8f7f04fc351464a_17",
  "x": "Concerning the SDRs, in order to formally define a relation the following four fields ought to be defined (see also<cite> [5]</cite> ): 1. The relation's type (i.e. Synchronic or Diachronic). 2. The relation's name. 3. The set of pairs of message types that are involved in the relation. 4. The constraints that the corresponding arguments of each of the pairs of message types should have.",
  "y": "background"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_0",
  "x": "We begin in \u00a72 by extending the online variational Bayes approach of Hoffman et al. (2010) to polylingual topic models<cite> (Mimno et al., 2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_1",
  "x": "In this paper, we focus on the Polylingual Topic Model, introduced by <cite>Mimno et al. (2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_2",
  "x": "In their original work <cite>Mimno et al. (2009)</cite> used the Gibbs sampling approach as a posterior inference algorithm to assign topics distributions over their test collection.",
  "y": "background"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_3",
  "x": "In their original work <cite>Mimno et al. (2009)</cite> used the Gibbs sampling approach as a posterior inference algorithm to assign topics distributions over their test collection. While more straightforward to implement, this sampling approach is inherently slow when applied to large collections which makes the original PLTM work practically infeasible to be used on real-world data sets. In this paper we use Hoffman et al. (2010) approach.",
  "y": "differences"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_4",
  "x": "<cite>Mimno et al. (2009)</cite> introduced polylingual topic models (PLTM), an extension of latent Dirichlet allocation (LDA), and, more recently, Platt et al. (2010) proposed extensions of principal component analysis (PCA) and probabilistic latent semantic indexing (PLSI).",
  "y": "background"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_5",
  "x": "<cite>Mimno et al. (2009)</cite> introduced polylingual topic models (PLTM), an extension of latent Dirichlet allocation (LDA), and, more recently, Platt et al. (2010) proposed extensions of principal component analysis (PCA) and probabilistic latent semantic indexing (PLSI). We use PLTM representations of bilingual documents.",
  "y": "uses"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_6",
  "x": "That paper used the Europarl (Koehn, 2005)<cite> (Mimno et al., 2009)</cite> , these performance comparisons are not done on the same training and test sets-a gap that we fill below.",
  "y": "background"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_7",
  "x": "We use Mallet's (McCallum, 2002) implementation of the PLTM to train and infer topics on the same data set used in Platt et al. (2010) . That paper used the Europarl (Koehn, 2005)<cite> (Mimno et al., 2009)</cite> , these performance comparisons are not done on the same training and test sets-a gap that we fill below.",
  "y": "uses background"
 },
 {
  "id": "bdeffcf02a86d06f57dbfae979b098_8",
  "x": "For all four topic models, we use the same settings for PLTM (hyperparameter values and number of Gibbs sampling iterations) as in<cite> (Mimno et al., 2009)</cite> 2 .",
  "y": "uses"
 },
 {
  "id": "be4144c60068cf242479ece304fd19_0",
  "x": "The last few years have seen an increased interest in narrative within the field of Natural Language Generation (Reiter et al., 2008; <cite>Elson and McKeown, 2010</cite>; Siddharthan et al., 2012; Lester, 2012) .",
  "y": "background"
 },
 {
  "id": "be4144c60068cf242479ece304fd19_1",
  "x": "The last few years have seen an increased interest in narrative within the field of Natural Language Generation (Reiter et al., 2008; <cite>Elson and McKeown, 2010</cite>; Siddharthan et al., 2012; Lester, 2012) .",
  "y": "background"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_0",
  "x": "Recently, a number of taskspecific attention variants have been proposed to deal with these issues: See et al. (2017) introduced a coverage mechanism<cite> (Tu et al., 2016</cite> ) * Work performed while at Apple.",
  "y": "background"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_1",
  "x": "Copynet (Gu et al., 2016) and pointer-generator networks (Vinyals et al., 2015) , for example, aim to reduce input-output vocabulary mismatch and, thereby, improve specificity, while the coveragebased techniques of<cite> Tu et al. (2016)</cite> tackle repetition and under-generation.",
  "y": "background"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_2",
  "x": "We find, for each task, that Scratchpad attains improvements over several strong baselines: Sequence-to-Sequence with attention Bahdanau et al., 2014) , copy-enhanced approaches (Gu et al., 2016; Vinyals et al., 2015) , and coverageenhanced approaches<cite> (Tu et al., 2016</cite>; See et al., 2017) .",
  "y": "background"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_3",
  "x": "For IWSLT15, we primarily compare to GNMT (Wu et al., 2016) , which incorporates Coverage<cite> (Tu et al., 2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_4",
  "x": "Accordingly, we compare our Scratchpad Mechanism against three baselines: (1) Seq2Seq, (2) Copynet and (3) Coverage, a method introduced by<cite> Tu et al. (2016)</cite> that aims to solve attention-related problems.",
  "y": "similarities uses"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_5",
  "x": "Previous work based on coverage based approaches<cite> (Tu et al., 2016</cite>; See et al., 2017) either imposed an extra term to the loss function or used an extra vector to keep track of which parts of the input sequences had been attended to, thereby focusing the attention weights in subsequent steps on tokens that received little attention before.",
  "y": "differences"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_6",
  "x": "Later on, many improvements were described in the Google neural machine translation system (Wu et al., 2016) , including utilizing coverage penalty<cite> (Tu et al., 2016)</cite> while decoding.",
  "y": "background"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_7",
  "x": "In Song et al. (2017) , a seq2seq model with copynet and a coverage mechanism<cite> (Tu et al., 2016</cite> ) is used to achieve state-of-the-art results.",
  "y": "similarities uses"
 },
 {
  "id": "be67496882917c2a44afb42e6f9f15_8",
  "x": "Attention Closest to our work, in the general paradigm of seq2seq learning, is the coverage mechanism introduced in<cite> Tu et al. (2016)</cite> and later adapted for summarization in See et al. (2017) .",
  "y": "similarities uses"
 },
 {
  "id": "c07bc362ac7ee1f64e149fe8907fee_0",
  "x": "However, there have been recent successes in adapting parsers and POS taggers to social media data <cite>(Foster et al., 2011</cite>; Gimpel et al., 2011) .",
  "y": "background"
 },
 {
  "id": "c0d2bbf9dc7615040763019f5c668b_0",
  "x": "Additionally, lexical normalisation and other preprocessing strategies have been shown to enhance the performance of NLP tools over social media data <cite>(Lui and Baldwin, 2012</cite>; Han et al., to appear) .",
  "y": "background"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_0",
  "x": "We train our classifiers on the exact training set defined by <cite>Zitouni et al. (2006)</cite> , a subpart of the third segment of the Penn Arabic Treebank (Maamouri et al., 2004 ) (\"ATB3-Train\", 288,000 words).",
  "y": "uses"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_1",
  "x": "We review three approaches that are directly relevant to us; we refer to the excellent literature review in <cite>(Zitouni et al., 2006)</cite> for a general review.",
  "y": "uses"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_2",
  "x": "<cite>Zitouni et al. (2006)</cite> use a maximum entropy classifier to assign a set of diacritics to the letters of each word.",
  "y": "background"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_3",
  "x": "<cite>Zitouni et al. (2006)</cite> use a maximum entropy classifier to assign a set of diacritics to the letters of each word. <cite>They</cite> use the output of a tokenizer (segmenter) and a part-of-speech tagger (which presumably tags the output of the tokenizer).",
  "y": "background"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_4",
  "x": "<cite>Zitouni et al. (2006)</cite> use a maximum entropy classifier to assign a set of diacritics to the letters of each word. <cite>They</cite> then use segment n-grams, segment position of the character being diacritized, the POS of the current segment, along with lexical features, including letter and word n-grams.",
  "y": "background"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_5",
  "x": "<cite>Zitouni et al. (2006)</cite> use a maximum entropy classifier to assign a set of diacritics to the letters of each word. Thus, while many of the same elements are used in <cite>their</cite> and our work (word n-grams, features related to morphological analysis), the basic approach is quite different: while we have one procedure that chooses a correct analysis (including to- Figure 1: Diacritization Results (all followed by single-choice-diac model); our best results are shown in boldface; Only-DLM-1 is the baseline; <cite>\"Zitouni\"</cite> is <cite>(Zitouni et al., 2006)</cite> kenization, morphological tag, and diacritization), they have a pipeline of processors.",
  "y": "similarities differences"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_6",
  "x": "Furthermore, <cite>Zitouni et al. (2006)</cite> do not use a morphological lexicon.",
  "y": "background"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_7",
  "x": "To our knowledge, <cite>their</cite> system is the best performing currently, and we have set up our experiments to allow us to compare our results directly to <cite>their</cite> results.",
  "y": "uses background"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_8",
  "x": "In order to assure maximal comparability with the work of <cite>Zitouni et al. (2006)</cite> , we adopt their metric.",
  "y": "uses"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_9",
  "x": "Finally, we give the results of <cite>Zitouni et al. (2006)</cite> on the last line, which we understand to be the best published results currently.",
  "y": "uses"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_10",
  "x": "This is because we are choosing among complete diacritization options for white space-tokenized words, while <cite>Zitouni et al. (2006)</cite> make choices for each diacritic.",
  "y": "differences"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_11",
  "x": "We can see the effect of our different approaches to diacritization in the numbers: while for WER we reduce the <cite>Zitouni et al</cite> error by 17.2%, the DER error reduction is only 10.9%.",
  "y": "differences"
 },
 {
  "id": "c126f8b9a5fcb2687494a8c0b1e859_12",
  "x": "We also note the issue of unknown words, which will affect our system much more than that of <cite>(Zitouni et al., 2006)</cite> .",
  "y": "differences"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_0",
  "x": "Since the phenomenon is elusive, researchers often use lists of offensive terms to collect datasets with the aim to increase the likelihood of catching instances of hate speech<cite> Waseem and Hovy, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_1",
  "x": "We consider a particular hate speech corpus -a Twitter corpus collected by <cite>Waseem and Hovy (2016)</cite> , which has been gaining traction as a resource for training hate speech detection models<cite> (Waseem and Hovy, 2016</cite>; Gamb\u00e4ck and Utpal, 2017; Park and Fung, 2017) -and analyse it critically to better understand its usefulness as a hate speech resource.",
  "y": "uses background"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_2",
  "x": "\u2022 We report the outcome of a reproduction experiment, where we attempt to replicate the results by <cite>Waseem and Hovy (2016)</cite> on hate speech detection using their Twitter corpus.",
  "y": "uses"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_3",
  "x": "We aim to replicate the results on hate speech detection by <cite>Waseem and Hovy (2016)</cite> using the hate speech Twitter corpus created by the authors.",
  "y": "uses"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_4",
  "x": "<cite>Waseem and Hovy (2016)</cite> state that they use a logistic regression classifier for their hate speech prediction task. What is not mentioned is which implementation of the algorithm is used, how the model was fit to the data, whether the features were scaled, and whether any other additional parameters had been used.",
  "y": "background"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_5",
  "x": "<cite>Waseem and Hovy (2016)</cite> explore several feature types: they employ n-gram features -specifically, they find that character n-grams of lengths up to 4 perform best -and in addition, they combine them with gender information, geographic location information and tweet length, finding that combining n-gram features with gender features yields slightly better results than just n-gram features do, while mixing in any of the other features results in slightly lower scores.",
  "y": "background"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_6",
  "x": "To date, most research on hate speech within the NLP community has been done in the area of automatic detection using a variety of techniques, from lists of prominent keywords (Warner and Hirschberg, 2012) to regression classifiers as seen in the previous section (Nobata et al., 2016;<cite> Waseem and Hovy, 2016)</cite> , naive Bayes, decision trees, random forests, and linear SVMs , as well as deep learning models with convolutional neural networks (Gamb\u00e4ck and Utpal, 2017; Park and Fung, 2017) .",
  "y": "background"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_7",
  "x": "Our intent in this section is to explore hate speech beyond just detection, using the Twitter corpus by <cite>Waseem and Hovy (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "c182062efc486f83eb27f9a3859a9a_10",
  "x": "According to the annotation guidelines devised by <cite>Waseem and Hovy (2016)</cite> for the purpose of annotating this corpus, a tweet is tagged as offensive if it: (1) uses a sexist or racial slur, (2) attacks a minority, (3) seeks to silence a minority, (4) criticizes a minority (without a well founded argument), (5) promotes, but does not directly use, hate speech or violent crime, (6) criticizes a minority and uses a straw man argument, (7) blatantly misrepresents truth or seeks to distort views on a minority with unfounded claims, (8) shows support of problematic hashtags (e.g. #BanIslam, #whori-ental, #whitegenocide), (9) negatively stereotypes a minority, (10) defends xenophobia or sexism, (11) the tweet is ambiguous (at best); and contains a screen name that is offensive as per the previous criteria; and is on a topic that satisfies any of the above criteria.",
  "y": "background"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_0",
  "x": "Conversation modelling is one such domain where end-to-end trained systems have matched or surpassed traditional dialog systems in both open-ended (Dodge et al., 2016) and goal-oriented applications <cite>(Bordes et al., 2017</cite> ).",
  "y": "background"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_1",
  "x": "(Illustration taken from<cite> Bordes et al., 2017)</cite> as location, type of cuisine and price range.",
  "y": "uses"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_2",
  "x": "With the ultimate aim of creating such a dataset, this paper aims to be an extension of the bAbI dialog dataset introduced by<cite> Bordes et al. (2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_3",
  "x": "This work builds upon the bAbI dialog dataset described in<cite> Bordes et al. (2017)</cite> , which is aimed at testing end-to-end dialog systems in the goal-oriented domain of restaurant reservations.",
  "y": "extends"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_4",
  "x": "Following<cite> Bordes et al. (2017)</cite> , we provide baselines on the modified dataset by evaluating several learning methods: rule-based systems, supervised embeddings, and end-to-end Memory networks.",
  "y": "uses"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_5",
  "x": "Supervised word embedding models which score (conversation history, response) pairs have been shown to be a strong baseline for both open-ended and goal-oriented dialog (Dodge et al., 2016;<cite> Bordes et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_6",
  "x": "The embedding vectors are trained specifically for the task of predicting the next response given the previous conversation: a candidate response y is scored against the input (Dodge et al., 2016;<cite> Bordes et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_7",
  "x": "Implementing the modifications to the Memory Network architecture described by<cite> Bordes et al. (2017)</cite> , we use the model as an end-to-end baseline and analyze its performance.",
  "y": "uses"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_8",
  "x": "Unlike<cite> Bordes et al. (2017)</cite>, we do not make use of any match type features.",
  "y": "differences"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_9",
  "x": "Compared to results reported on the bAbI dialog tasks in<cite> Bordes et al. (2017)</cite> , supervised embeddings performed significantly worse on the modified tasks.",
  "y": "differences"
 },
 {
  "id": "c1eefe276c0ed46d7cd50f3f3bc3f3_10",
  "x": "As this work builds on top of the bAbI dialog dataset proposed by<cite> Bordes et al. (2017)</cite> , crucial aspects of goal-oriented conversation have been split into various synthetically generated tasks to evaluate the strengths and weaknesses of models in a systematic way before applying them on real data.",
  "y": "extends"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_0",
  "x": "In other words, the biases detected in <cite>Elazar and Goldberg (2018)</cite> seem restricted to <cite>their particular data sample</cite>, and would therefore not bias the decisions of the model on new samples, whether in-domain or out-of-domain. In light of this, we discuss better methodologies for detecting bias in our models.",
  "y": "motivation"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_1",
  "x": "In other words, the biases detected in <cite>Elazar and Goldberg (2018)</cite> seem restricted to <cite>their particular data sample</cite>, and would therefore not bias the decisions of the model on new samples, whether in-domain or out-of-domain.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_2",
  "x": "<cite>Elazar and Goldberg (2018)</cite> argue, however, that adversarial learning does not fully remove sensitive demographic traits from the data representations. This conclusion is based on the observation that a diagnostic classifier trained over the supposedly debiased data representations could still predict gender, age and race above chance level in <cite>their</cite> experimental setup.",
  "y": "motivation"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_3",
  "x": "This paper presents a follow-up to the experiments in <cite>Elazar and Goldberg (2018)</cite> and examines what kind of correlation the data representations in their models exhibit with demographic attributes: PREVALENT, SAMPLE-SPECIFIC or AC-CIDENTAL correlations.",
  "y": "extends"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_4",
  "x": "We show that the diagnostic classifiers used to establish gender and age bias in <cite>Elazar and Goldberg (2018)</cite> (a) rely only on samplespecific patterns to predict gender and age, and (b) do therefore not generalize to new samples or domains.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_5",
  "x": "Surprisingly, we also show that this also holds for the biased baseline model in <cite>their experiments</cite>, suggesting that the particular representations induced for the mention detection task in <cite>Elazar and Goldberg (2018)</cite> were not biased with respect to protected demographic attributes.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_7",
  "x": "The architecture of <cite>Elazar and Goldberg (2018)</cite> consists of a single-layer LSTM encoder, and two multi-layer perceptrons -one for each task.",
  "y": "background"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_8",
  "x": "Since the dataset is balanced and the targets are binary, <cite>leakage</cite> is defined in <cite>Elazar and Goldberg (2018)</cite> as any demographic attribute prediction accuracy over 50.0% by the diagnostic classifier.",
  "y": "background"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_9",
  "x": "Our main dataset, PAN16 TWIT (Rangel et al., 2016) , is split into train and development, following <cite>Elazar and Goldberg (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_10",
  "x": "This means that we have 12,000 fewer sentences in our train split than <cite>Elazar and Goldberg (2018)</cite>, but we report results on exactly the same development split as well as on the new held-out test split.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_11",
  "x": "Using random subsamples this way is common in machine learning, including bias detection studies <cite>(Elazar and Goldberg, 2018</cite>; Zhao et al., 2019) and probing studies (Ravfogel et al., 2018; Lin et al., 2019) , but is known to overestimate performance (Globerson and Roweis, 2016), in particular for highdimensional problems.",
  "y": "background"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_12",
  "x": "Replication We start by replicating the experiment of <cite>Elazar and Goldberg (2018)</cite> using <cite>their code</cite> on PAN16 TWIT with <cite>their data splits</cite>.",
  "y": "similarities uses"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_13",
  "x": "Our development results (main and diagnostic classifier) which are comparable to <cite>Elazar and Goldberg (2018)</cite> are reported in Table 6 in the Appendix; test set results are also in Table 4 .",
  "y": "similarities"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_14",
  "x": "Our results remain comparable to those obtained in <cite>Elazar and Goldberg (2018)</cite> , albeit the diagnostic classifier is able to achieve 3.92 percentage points less leakage for gender and 2.59 percentage points for age, possibly due to the reduction in training data.",
  "y": "similarities"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_15",
  "x": "This experiment supplements our in-sample analysis in \u00a73 and shows that our models are not overly expressive, indicating that the sample-specific correlations detected in <cite>Elazar and Goldberg (2018)</cite> are relatively simple associations.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_16",
  "x": "This is the main result presented here: <cite>The leakage</cite> shown in <cite>Elazar and Goldberg (2018)</cite> does not transfer across domains, but also does not even generalize to a new sample within the same domain.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_17",
  "x": "We examined the methodology used in <cite>Elazar and Goldberg (2018)</cite> to establish bias in the representations of adversarial machine learning architectures designed to protect demographic attributes.",
  "y": "uses"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_19",
  "x": "Our contribution is mainly method-6 The methodology is not only found in <cite>Elazar and Goldberg (2018)</cite> . ological: What we have shown is that the methodology in <cite>Elazar and Goldberg (2018)</cite> , i.e., insample evaluation of diagnostic classifiers, is not sufficient to establish bias/leakage beyond the current data sample.",
  "y": "differences"
 },
 {
  "id": "c2633be695561ce3f5b39fccf38927_20",
  "x": "Our results are also orthogonal to the main contribution of <cite>Elazar and Goldberg (2018)</cite> , which is to show that adversarial debiasing is not always able to remove bias.",
  "y": "differences"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_0",
  "x": "Already many sentence alignment techniques have been implemented for some languages pairs such as English-French <cite>(Gale and Church, 1993</cite>; Brown et al., 1991; Chen, 1993; Braune and Fraser 2010; Lamraoui and Langlais, 2013) , English-German<cite> (Gale and Church, 1993)</cite> English-Chinese (Wu, 1994; Chuang and Yeh, 2005) and Hungarian-English (Varga et al., 2005; T\u00f3th et al., 2008) .",
  "y": "background"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_1",
  "x": "Already many sentence alignment techniques have been implemented for some languages pairs such as English-French <cite>(Gale and Church, 1993</cite>; Brown et al., 1991; Chen, 1993; Braune and Fraser 2010; Lamraoui and Langlais, 2013) , English-German<cite> (Gale and Church, 1993)</cite> English-Chinese (Wu, 1994; Chuang and Yeh, 2005) and Hungarian-English (Varga et al., 2005; T\u00f3th et al., 2008) . However, none of these techniques have been evaluated for Sinhala and Tamil, the two official languages in Sri Lanka. This paper presents the first ever study on automatically creating a sentence aligned parallel corpus for Sinhala and Tamil.",
  "y": "differences"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_2",
  "x": "The highest F-measure value of 0.791 was obtained for Varga et al.'s (2005) Hunalign method, the hybrid method that combined the use of a bilingual dictionary with the statistical method by<cite> Gale and Church (1993)</cite> .",
  "y": "uses"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_3",
  "x": "While the parameters such as mean and variance for<cite> Gale and Church's (1993)</cite> method are considered language independent for European languages, tuning these for non-'European language pairs has improved results (Zotti et al, 2014) .",
  "y": "background"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_4",
  "x": "The method used by Wu (1994) is a modification of<cite> Gale and Church's (1993)</cite> length-based statistical method for the task of aligning English with Chinese.",
  "y": "background"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_5",
  "x": "The method by Chen (1993) is a word-correspondence-based model that gives a better accuracy than length based methods, however, it was reported to be much slower than the algorithms of Brown et al., (1991) and<cite> Gale and Church (1993)</cite> .",
  "y": "background"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_6",
  "x": "According to<cite> Gale and Church (1993)</cite> a considerably large parallel corpus having a small error percentage can be built without lexical constraints.",
  "y": "background"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_7",
  "x": "This research used the method proposed by<cite> Gale and Church (1993)</cite> citing the close linguistic similarities between languages of these pairs, causing parallel sentences to be of similar lengths.",
  "y": "uses"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_8",
  "x": "Constrained by the available resources, we compared methods by<cite> Gale and Church (1993)</cite> , Moore (2002) , Varga et al. (2005) , Braune and Fraser (2010) , Lamraoui and Langlais (2013) , and Sennrich and Volk (2011) .",
  "y": "uses"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_9",
  "x": "The mean and variance for the number of Tamil characters per Sinhala was found and these values were used for the<cite> Gale and Church's (1993)</cite> method.",
  "y": "uses"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_10",
  "x": "Most of the above methods <cite>(Gale and Church, 1993</cite>; Brown et al., 1991; Chen and S.F, 1993; Braune and Fraser, 2010) have been first used for English and French sentence alignment.",
  "y": "background"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_11",
  "x": "We used<cite> Gale and Church (1993)</cite> method even though we could not align the paragraphs before aligning the sentences, due the dissimilarities among the text converted from pdfs.",
  "y": "uses"
 },
 {
  "id": "c327812b2369a1dfc8e2ce4077b997_13",
  "x": "Even after changing the parameters for Sinhala and Tamil in the<cite> Gale and Church (1993)</cite> method, we obtained a comparatively low precision because this method does not only look at one to one alignments but also one to zero, many to one, one to many or many to many alignments.",
  "y": "extends differences"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_0",
  "x": "By using a cascading minority preference system, we show that our approach outperforms the bridging recognition in<cite> Markert et al. (2012)</cite> by a large margin without impairing the performance on other IS classes.",
  "y": "differences"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_1",
  "x": "In recent work, these two tasks have been tackled separately, with bridging recognition handled as part of information status (IS) classification<cite> (Markert et al., 2012</cite>; Cahill and Riester, 2012; Rahman and Ng, 2012) .",
  "y": "background"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_2",
  "x": "Bridging recognition is a difficult task, so that we had to report very low results on this IS class in previous work<cite> (Markert et al., 2012)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_3",
  "x": "Bridging recognition is a difficult task, so that we had to report very low results on this IS class in previous work<cite> (Markert et al., 2012)</cite> . This is due to the phenomenon's variety, leading to a lack of clear surface features for recognition. Instead, we formulate in this paper novel discourse structure and lexicosemantic features as well as features that distinguish bridging from generics (see Section 3).",
  "y": "motivation"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_4",
  "x": "In addition, making up between 5% and 20% of definite descriptions (Gardent and Manu\u00e9lian, 2005; Caselli and Prodanof, 2006) and around 6% of all NPs<cite> (Markert et al., 2012)</cite> , bridging is still less frequent than many other IS classes and recognition of minority classes is well known to be more difficult.",
  "y": "background motivation"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_5",
  "x": "In addition, making up between 5% and 20% of definite descriptions (Gardent and Manu\u00e9lian, 2005; Caselli and Prodanof, 2006) and around 6% of all NPs<cite> (Markert et al., 2012)</cite> , bridging is still less frequent than many other IS classes and recognition of minority classes is well known to be more difficult. We therefore use a cascaded classification algorithm to address this problem (Omuya et al., 2013) .",
  "y": "motivation"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_6",
  "x": "Previous work on recognition is either limited to definite NPs based on heuristics evaluated on small datasets (Hahn et al., 1996; Vieira and Poesio, 2000) , or models it as a subtask of learning fine-grained IS (Rahman and Ng, 2012;<cite> Markert et al., 2012</cite>; Cahill and Riester, 2012) .",
  "y": "motivation"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_7",
  "x": "Previous work on recognition is either limited to definite NPs based on heuristics evaluated on small datasets (Hahn et al., 1996; Vieira and Poesio, 2000) , or models it as a subtask of learning fine-grained IS (Rahman and Ng, 2012;<cite> Markert et al., 2012</cite>; Cahill and Riester, 2012) . Results within this latter framework for bridging have been mixed: We reported in<cite> Markert et al. (2012)</cite> low results for bridging in written news text whereas Rahman and Ng (2012) report high results for the four subcategories of bridging annotated in the Switchboard dialogue corpus by Nissim et al. (2004) .",
  "y": "motivation"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_8",
  "x": "Similarly, Clark (1975) distinguishes between bridging via necessary, probable and inducible parts/roles and argues that only in the first and maybe the second case the antecedent triggers the 3 See also the high results for our specific category for comparative anaphora<cite> (Markert et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_9",
  "x": "We perform experiments on the corpus provided in<cite> Markert et al. (2012)</cite> 6 .",
  "y": "uses"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_10",
  "x": "rbls uses the same features as<cite> Markert et al. (2012)</cite> (Table 1) but replaces the local decision tree classifier with LibSVM as we will need to include lexical features.",
  "y": "extends"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_11",
  "x": "In<cite> Markert et al. (2012)</cite> we classify eight finegrained IS categories for NPs in written text: old, new and 6 mediated categories (syntactic, worldKnowledge, bridging, comparative, aggregate and function).",
  "y": "extends background"
 },
 {
  "id": "c34bbed419bddb6d63b3e3bccf595d_12",
  "x": "However, we observe that bridging anaphors are often licensed because of discourse structure<cite> Markert et al. (2012)</cite>",
  "y": "extends background"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_0",
  "x": "In order to promote research in this area, we propose a data generation paradigm adapted from CLEVR [<cite>11</cite>] .",
  "y": "extends"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_1",
  "x": "In the visual domain, several strategies have been proposed to make this kind of data available to the community [<cite>11</cite>, 2, 25, 7] .",
  "y": "background"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_2",
  "x": "Text-based QA, use text corpora as context ( [19, 20, 17, 9, 10, 16] ); in visual question answering (VQA), instead, the questions are related to a scene depicted in still images (e.g. [<cite>11</cite>, 2, 25, 7, 1, 23, 8, 10, 16] .",
  "y": "background"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_3",
  "x": "This motivated research [23, 8, <cite>11</cite>] on how to reduce the bias in VQA datasets.",
  "y": "background"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_4",
  "x": "The complexity around gathering good labeled data forced some authors [23, 8] to constrain their work to yes/no questions. <cite>Johnson et al. [11]</cite> made their way around this constraint by using synthetic data.",
  "y": "background"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_5",
  "x": "Inspired by the work on <cite>CLEVR</cite> [<cite>11</cite>] , we propose an acoustical question answering (AQA) task by defining a synthetic dataset that comprises audio scenes composed by sequences of elementary sounds and questions relating properties of the sounds in each scene.",
  "y": "motivation"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_6",
  "x": "To represent questions, we use the same semantic representation through functional programs that is proposed in [<cite>11</cite>, 12] .",
  "y": "uses"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_7",
  "x": "Questions are structured in a logical tree introduced in <cite>CLEVR</cite> [<cite>11</cite>] as a functional program.",
  "y": "uses"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_8",
  "x": "We adapted the original work of <cite>Johnson et al. [11]</cite> to our acoustical context by updating the function catalog and the relationships between the objects of the scene.",
  "y": "extends"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_9",
  "x": "A validation process [<cite>11</cite>] is responsible for rejecting both ill-posed and degenerate questions during the generation phase. Thanks to the functional representation we can use the reasoning steps of the questions to analyze the results.",
  "y": "uses"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_10",
  "x": "To evaluate our dataset, we performed preliminary experiments with a FiLM network [15] . It is a good candidate as it has been shown to work well on the <cite>CLEVR VQA task</cite> [<cite>11</cite>] that shares the same structure of questions as our CLEAR dataset.",
  "y": "uses"
 },
 {
  "id": "c3f71bea55f85633568c7ba57f6fd5_11",
  "x": "We also propose a paradigm for data generation that is an extension of the <cite>CLEVR</cite> paradigm: The acoustic scenes are generated by combining a number of elementary sounds, and the corresponding questions and answers are generated based on the properties of those sounds and their mutual relationships.",
  "y": "extends"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_0",
  "x": "Preliminary experiments using a similar collection used in<cite> Potthast et al. (2018)</cite> show that neural-based classification methods reach state-of-the art results.",
  "y": "background"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_1",
  "x": "Identifying partisan preferences in news, based only on text content, has been shown to be a challenging task <cite>(Potthast et al., 2018)</cite> .",
  "y": "background motivation"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_2",
  "x": "A recent paper <cite>(Potthast et al., 2018)</cite> claims that stylometric features are a key factor to tackle this task.",
  "y": "background"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_3",
  "x": "Identifying partisan preferences in news, based only on text content, has been shown to be a challenging task <cite>(Potthast et al., 2018)</cite> . Despite the fact that sharply polarized documents are not necessarily fake, it is an early problem to solve for the identification of fake content.",
  "y": "motivation"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_4",
  "x": "They achieve state-of-the-art results on a publicly available collection <cite>(Potthast et al., 2018)</cite> , showing that neural models can effectively address the task of hyperpartisan detection without including stylometric features.",
  "y": "background"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_5",
  "x": "Experiments were performed using two collections, the ACL2018 collection <cite>(Potthast et al., 2018)</cite> and the SemEval19 collection .",
  "y": "uses"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_6",
  "x": "As our results are not directly comparable with the values reported in<cite> Potthast et al. (2018)</cite> , we re-evaluated their approach on this single fold.",
  "y": "uses differences"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_7",
  "x": "Two state-of-the-art models (SpaCy and Kim (2014)) outperform the approach presented in<cite> Potthast et al. (2018)</cite> , showing that stylometric features are probably not necessary for the task.",
  "y": "background"
 },
 {
  "id": "c437e447603ecdbe4053651169770a_8",
  "x": "This deserves a set of extra experiments to better understand the real contribution of stylometric features when combined with strong representations/classifiers to validate the work of<cite> Potthast et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_0",
  "x": "However,<cite> Finegan-Dollak et al. (2018)</cite> demonstrated that both the approaches lack the ability to generate SQL of unseen templates.",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_1",
  "x": "Recently, template-based and sequence-to-sequence approaches were proposed to support complex queries, which contain join queries, nested queries, and other types. However,<cite> Finegan-Dollak et al. (2018)</cite> demonstrated that both the approaches lack the ability to generate SQL of unseen templates. In this paper, we propose a template-based one-shot learning model for the text-to-SQL generation so that the model can generate SQL of an untrained template based on a single example.",
  "y": "motivation"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_2",
  "x": "Moreover,<cite> Finegan-Dollak et al. (2018)</cite> demonstrated that the sequence-tosequence model also lack the ability to generate SQL queries of unseen templates.",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_3",
  "x": "Moreover,<cite> Finegan-Dollak et al. (2018)</cite> demonstrated that the sequence-tosequence model also lack the ability to generate SQL queries of unseen templates. In this work, we propose an extension of a template-based model with one-shot learning, which can generate SQL queries of untrained templates based on a single example.",
  "y": "extends"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_4",
  "x": "The proposed model has three advantages. 2. It minimizes unnecessary search space, unlike sequence-to-sequence approaches (Iyer et al., 2017;<cite> Finegan-Dollak et al., 2018)</cite> ; thus, the model is guaranteed to be free of SQL syntax errors.",
  "y": "differences"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_5",
  "x": "We conducted experiments with four different text-to-SQL datasets on both of the questionbased split and query-based split <cite>(Finegan-Dollak et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_6",
  "x": "However,<cite> Finegan-Dollak et al. (2018)</cite> showed that the sequence-to-tree approach was inefficient when generating complex SQL queries from a natural language question.",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_7",
  "x": "Iyer et al. (2017);<cite> Finegan-Dollak et al. (2018)</cite> focused on the dataset that contains more complex queries such as ATIS (Dahl et al., 1994) and GeoQuery (Zelle and Mooney, 1996) .",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_8",
  "x": "plied a sequence-to-sequence approach with attention mechanism, and<cite> Finegan-Dollak et al. (2018)</cite> proposed a template-based model and another sequence-to-sequence model with a copy mechanism.",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_9",
  "x": "plied a sequence-to-sequence approach with attention mechanism, and<cite> Finegan-Dollak et al. (2018)</cite> proposed a template-based model and another sequence-to-sequence model with a copy mechanism. However,<cite> Finegan-Dollak et al. (2018)</cite> showed that both approaches lack the ability to generate SQL of the unseen template in the training stage. One-shot Learning/Matching Network Deep learning models usually require hundreds or thousands of examples in order to learn a class. To overcome this limitation, one-shot learning aims to learn a class from a single labeled example. We applied one-shot learning to the text-to-SQL task so that our model could learn a SQL template from just a few examples and adapt easily and promptly to the SQL of untrained templates.",
  "y": "differences motivation"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_10",
  "x": "This architecture is based on an idea similar to the template-based model of<cite> Finegan-Dollak et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_11",
  "x": "This architecture is based on an idea similar to the template-based model of<cite> Finegan-Dollak et al. (2018)</cite> . However, the previous model requires a number of examples for each template and needs retraining to support new templates of SQL. Conversely, we applied one-shot learning so that our model could learn a template with just a single example.",
  "y": "differences"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_13",
  "x": "We used a SQL version of the dataset processed by<cite> Finegan-Dollak et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_14",
  "x": "We used a template and variables for each SQL from the preprocessed versions provided by<cite> Finegan-Dollak et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_15",
  "x": "For the query-based split, we used the same split as in<cite> Finegan-Dollak et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_16",
  "x": "We evaluated the query generation accuracy for both the question-based split and query-based split <cite>(Finegan-Dollak et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_17",
  "x": "We compare our results with three different previous approaches: a sequence-to-sequence model from Iyer et al. (2017) , template-based model, and another sequence-to-sequence model from<cite> Finegan-Dollak et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_18",
  "x": "Our model shows 3-27% query generation accuracy gain, compared to the sequence-to-sequence model, 5-9% gain, compared to template-based model <cite>(Finegan-Dollak et al., 2018)</cite> , and 15-56% gain, compared to Iyer et al. (2017) .",
  "y": "differences"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_19",
  "x": "Our model shows 3-27% query generation accuracy gain, compared to the sequence-to-sequence model, 5-9% gain, compared to template-based model <cite>(Finegan-Dollak et al., 2018)</cite> , and 15-56% gain, compared to Iyer et al. (2017) . The result demonstrates that our model is more efficient in generating SQL of the trained templates than the previous approaches.",
  "y": "differences"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_20",
  "x": "Sequence-to-sequence models (Iyer et al., 2017;<cite> Finegan-Dollak et al., 2018)</cite> , as shown in the Table 3 , showed poor performance for the query-based split in the zero-shot setting.",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_21",
  "x": "The model from<cite> Finegan-Dollak et al. (2018)</cite> showed accuracies of 0%, 32%, 20%, and 5% for each benchmark and accuracies of Iyer et al. (2017) showed 1%, 17%, 40%, and 3%, meaning that they also lack the capability to generate unseen templates of SQL.",
  "y": "background"
 },
 {
  "id": "c4cc8d4013b0259eb626d06750e4ab_22",
  "x": "Sequence-to-sequence models (Iyer et al., 2017;<cite> Finegan-Dollak et al., 2018)</cite> , as shown in the Table 3 , showed poor performance for the query-based split in the zero-shot setting. The model from<cite> Finegan-Dollak et al. (2018)</cite> showed accuracies of 0%, 32%, 20%, and 5% for each benchmark and accuracies of Iyer et al. (2017) showed 1%, 17%, 40%, and 3%, meaning that they also lack the capability to generate unseen templates of SQL. In a one-shot setting, where an example is added for each new template, our approach outperformed previous ones against every benchmark. Our model outperforms the sequence-to-sequence model <cite>(Finegan-Dollak et al., 2018)</cite> by 1-60%, the template-based model <cite>(Finegan-Dollak et al., 2018)</cite> by 17-52%, Iyer et al. (2017) by 14-62%.",
  "y": "differences"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_0",
  "x": "Recently, with the renaissance of artificial neural networks in the form of deep learning algorithms, neural network (NN) based KWS has become very popular [5, 6, 7,<cite> 8]</cite> .",
  "y": "background"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_1",
  "x": "\u2022 We first train the popular KWS neural net models from the literature [5, 6, 7,<cite> 8]</cite> on Google speech commands dataset [9] and compare them in terms of accuracy, memory footprint and number of operations per inference.",
  "y": "similarities uses"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_2",
  "x": "While all the prior KWS neural networks are trained with cross entropy loss function, a max-pooling based loss function for training KWS model with long short-term memory (LSTM) is proposed in <cite>[8]</cite> , which achieves better accuracy than the DNNs and LSTMs trained with cross entropy loss.",
  "y": "background"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_3",
  "x": "Although many neural network models for KWS are presented in literature, it is difficult to make a fair comparison between them as they are all trained and evaluated on different proprietary datasets (e.g. \"TalkType\" dataset in [7] , \"Alexa\" dataset in <cite>[8]</cite> , etc.) with different input speech features and audio duration.",
  "y": "background"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_4",
  "x": "Table 2 summarizes the accuracy, memory requirement and operations per inference for the network architectures for KWS from literature [5, 6, 7,<cite> 8]</cite> trained on Google speech commands dataset [9] .",
  "y": "similarities uses"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_6",
  "x": "Figure 5 shows the number of operations per inference, memory requirement and test accuracy of neural network models from prior work [5, 6, 7,<cite> 8]</cite> trained on Google speech commands dataset overlayed with the memory and compute bounding boxes for the neural network classes from section 4.",
  "y": "background"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_7",
  "x": "[5, 6, 7,<cite> 8]</cite> trained on the speech commands dataset [9] .",
  "y": "background"
 },
 {
  "id": "c4e0e12362bd7d505f6887abad78d4_8",
  "x": "The LSTM model mentioned in the table includes peephole connections and output projection layer similar to that in <cite>[8]</cite> , whereas basic LSTM model does not include those.",
  "y": "similarities"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_0",
  "x": "Multi-task learning (MTL) in deep neural networks is typically a result of parameter sharing between two networks (of usually the same dimensions)<cite> (Caruana 1993)</cite> .",
  "y": "background"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_1",
  "x": "We explicitly add inductive bias to the model via the regularizer \u2126 below, but our model also implicitly learns regularization through multi-task learning<cite> (Caruana 1993</cite> ) mediated by the \u03b1 parameters, while the \u03b2 parameters are used to learn the mixture functions f (\u00b7), as detailed in the following.",
  "y": "uses"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_2",
  "x": "Subspaces (Virtanen, Klami, and Kaski 2011;<cite> Bousmalis et al. 2016</cite> ) should allow the model to focus on task-specific and shared features in different parts of its parameter space.",
  "y": "background"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_3",
  "x": "For now just observe that if all \u03b1-values are set to 0.25 (or any other constant), we obtain hard parameter sharing<cite> (Caruana 1993)</cite> , which is equivalent to a heavy L 0 matrix regularizer.",
  "y": "similarities"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_4",
  "x": "We introduce an orthogonality constraint<cite> (Bousmalis et al. 2016</cite> ) between the layer-wise subspaces of each model:",
  "y": "uses"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_5",
  "x": "Baseline Models As baselines, we compare against i) a single-task model only trained on chunking; ii) the low supervision model , which predicts the auxiliary task at the first layer; iii) an MTL model based on hard parameter sharing<cite> (Caruana 1993)</cite> ; and iv) cross-stitch networks (Misra et al. 2016) .",
  "y": "uses"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_6",
  "x": "In contrast to previous studies on MTL (Mart\u00ednez Alonso and Plank 2017;<cite> Bingel and S\u00f8gaard 2017</cite>; Augenstein, Ruder, and S\u00f8gaard 2018) , our model also consistently outperforms single-task learning.",
  "y": "differences"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_7",
  "x": "Joint model Most work on MTL for NLP uses a single auxiliary task <cite>(Bingel and S\u00f8gaard 2017</cite>; Mart\u00ednez Alonso and Plank 2017) .",
  "y": "background"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_8",
  "x": "Joint model Most work on MTL for NLP uses a single auxiliary task <cite>(Bingel and S\u00f8gaard 2017</cite>; Mart\u00ednez Alonso and Plank 2017) . In this experiment, we use one sluice network to jointly learn our four tasks on the newswire domain and show results in Table 5 .",
  "y": "differences"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_9",
  "x": "Task Properties and Performance<cite> Bingel and S\u00f8gaard (2017)</cite> correlate meta-characteristics of task pairs and gains compared to hard parameter sharing across a large set of NLP task pairs.",
  "y": "background"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_10",
  "x": "Task Properties and Performance<cite> Bingel and S\u00f8gaard (2017)</cite> correlate meta-characteristics of task pairs and gains compared to hard parameter sharing across a large set of NLP task pairs. Similarly, we correlate various metacharacteristics with error reductions and \u03b1, \u03b2 values.",
  "y": "similarities"
 },
 {
  "id": "c4e2f43e223f61d81d81ac2c9aaa3f_11",
  "x": "Hard parameter sharing<cite> (Caruana 1993</cite> ) is easy to implement, reduces overfitting, but is only guaranteed to work for (certain types of) closely related tasks (Baxter 2000; Maurer 2007 ).",
  "y": "background"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_0",
  "x": "Most state-of-the-art event trigger labeling approaches (Ji and Grishman, 2008; Liao and Grishman, 2010b; Hong et al., 2011;<cite> Li et al., 2013)</cite> follow the standard supervised learning paradigm.",
  "y": "background"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_1",
  "x": "We developed a seed-based system (Section 3), based on a state-of-the-art fully-supervised event extraction system<cite> (Li et al., 2013)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_2",
  "x": "Therefore, we implemented our system by adapting the state-of-the-art fully-supervised event extraction system of<cite> Li et al. (2013)</cite> , modifying mechanisms relevant for features and for trigger labels, as described below.",
  "y": "extends differences"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_3",
  "x": "The event extraction system of<cite> Li et al. (2013)</cite> labels triggers and their arguments for a set of target event types L, for which annotated training documents are provided.",
  "y": "similarities"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_4",
  "x": "To implement the seed-based approach for trigger labeling, we adapt only the trigger classification part in the<cite> Li et al. (2013)</cite> fully-supervised system, ignoring arguments.",
  "y": "extends differences"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_5",
  "x": "We evaluate our seed-based approach (Section 2) in comparison to the fully-supervised approach implemented by<cite> Li et al. (2013)</cite> (Section 3) .",
  "y": "similarities"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_6",
  "x": "To maintain comparability, we use the ACE-2005 documents with the same split as in (Ji and Grishman, 2008; Liao and Grishman, 2010b;<cite> Li et al., 2013)</cite> to 40 test documents and 559 training documents.",
  "y": "similarities uses"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_7",
  "x": "However, some evaluation settings differ:<cite> Li et al. (2013)</cite> train a multi-class model for all 33 ACE-2005 event types, and classify all tokens in the test documents into these event types.",
  "y": "extends differences"
 },
 {
  "id": "c5a10f46c253f0da005622661b12a1_9",
  "x": "We compare our system's performance to the published trigger classification results of the baseline system of <cite>(Li et al., 2013</cite> ) (its globally optimized run, when labeling both triggers and arguments).",
  "y": "similarities"
 },
 {
  "id": "c5e1debe3fcab509737e092505a29e_0",
  "x": "It is known that SMT produces more unknown words resulting in the bad translation quality if the morphological divergence between the source and target language is high. Koehn and Knight (2003) , Popovic and Ney (2004) and<cite> Popovi\u0107 et al. (2006)</cite> have demonstrated ways to handle this issue with morphological segmentation of words before training the SMT system.",
  "y": "background"
 },
 {
  "id": "c5e1debe3fcab509737e092505a29e_1",
  "x": "We have used source side reordering developed by Patel et al. (2013), and <cite>Ramanathan et al. (2008</cite> We now discuss training and testing corpus from health, tourism and general domains for be-hi, mrhi, ta-hi, te-hi, and en-hi language pairs, followed by preprocessing, SMT system setup and evaluation metrics for experiments.",
  "y": "uses"
 },
 {
  "id": "c5e1debe3fcab509737e092505a29e_2",
  "x": "To handle the structural divergence for English-Hindi SMT, we exploited source side preordering (Patel et al., 2013;<cite> Ramanathan et al., 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "c5e1debe3fcab509737e092505a29e_3",
  "x": "Stemming was done using lightweight stemmer<cite> (Ramanathan and Rao, 2003)</cite> for Hindi.",
  "y": "uses"
 },
 {
  "id": "c5e1debe3fcab509737e092505a29e_4",
  "x": "Preordering of the source language sentence helps in the better alignment and decoding for English to Indian language<cite> (Ramanathan et al., 2008</cite>; Patel et al., 2013; Kunchukuttan et al., 2014) SMT.",
  "y": "background"
 },
 {
  "id": "c608567abe72c75bbbc8eb917ab5d3_0",
  "x": "Many neural network methods have recently been exploited in various natural language processing (NLP) tasks, such as parsing , POS tagging (Lample et al., 2016) , relation extraction (dos Santos et al., 2015) , translation (Bahdanau et al., 2015) , and joint tasks<cite> (Miwa and Bansal, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "c608567abe72c75bbbc8eb917ab5d3_2",
  "x": "Joint entity and relation extraction: Joint models (Li and Ji, 2014; Miwa and Sasaki, 2014) that are based on manually extracted features have been proposed for performing both the named entity recognition (NER) and relation extraction subtasks at once. These methods rely on the availability of NLP tools (e.g., POS taggers) or manually designed features leading to additional complexity. Neural network methods have been exploited to overcome this feature design issue and usually involve RNNs and CNNs<cite> (Miwa and Bansal, 2016</cite>; Zheng et al., 2017) . Specifically, <cite>Miwa and Bansal (2016)</cite> as well as Li et al. (2017) apply bidirectional tree-structured RNNs for different contexts (i.e., news, biomedical) to capture syntactic information (using external dependency parsers).",
  "y": "background"
 },
 {
  "id": "c608567abe72c75bbbc8eb917ab5d3_3",
  "x": "We evaluate our models on four datasets, using the code as available from our github codebase. 1 Specifically, we follow the 5-fold crossvalidation defined by <cite>Miwa and Bansal (2016)</cite> for the ACE04 (Doddington et al., 2004) dataset.",
  "y": "uses"
 },
 {
  "id": "c608567abe72c75bbbc8eb917ab5d3_4",
  "x": "Compared to <cite>Miwa and Bansal (2016)</cite> , who rely on NLP tools, the baseline performs within a reasonable margin (less than 1%) on the joint task.",
  "y": "differences"
 },
 {
  "id": "c663b64c73f2e583ea631c054824d8_0",
  "x": "A recent improved method for generating word embeddings is Glove <cite>[15]</cite> which makes efficient use of global statistics of text words and preserves the linear substructure of Skip-gram word2vec, the other popular method.",
  "y": "background"
 },
 {
  "id": "c663b64c73f2e583ea631c054824d8_1",
  "x": "It was created by authors of <cite>[15]</cite> to evaluate Glove performance.",
  "y": "background"
 },
 {
  "id": "c663b64c73f2e583ea631c054824d8_2",
  "x": "Even bigger is Common Crawl 840, a huge corpus of 840 billion tokens and 2.2 million word vectors also used at <cite>[15]</cite> .",
  "y": "background"
 },
 {
  "id": "c663b64c73f2e583ea631c054824d8_3",
  "x": "In this section we present the different word embedding models that we compare. It was created by authors of <cite>[15]</cite> to evaluate Glove performance. Even bigger is Common Crawl 840, a huge corpus of 840 billion tokens and 2.2 million word vectors also used at <cite>[15]</cite> .",
  "y": "uses background"
 },
 {
  "id": "c67297dc1c4376dc715bf5c1c9132f_0",
  "x": "One could expect considerable performance boosts by simply substituting distributional word embeddings with Flair (Akbik et al., 2018) , ELMo<cite> (Peters et al., 2018)</cite> , and BERT (Devlin et al., 2019) embeddings.",
  "y": "background"
 },
 {
  "id": "c67297dc1c4376dc715bf5c1c9132f_1",
  "x": "ELMo is a deep word-level bidirectional LSTM language model with character level convolution networks along with a final linear projection output layer<cite> (Peters et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "c67297dc1c4376dc715bf5c1c9132f_2",
  "x": "Melamud et al. (2016) and <cite>Peters et al. (2018)</cite> also adopt bi-LSTM networks with KNN classifiers.",
  "y": "background"
 },
 {
  "id": "c67297dc1c4376dc715bf5c1c9132f_3",
  "x": "K-Nearest Neighbor (KNN) approach is adopted from both ELMo<cite> (Peters et al., 2018)</cite> and con-text2vec (Melamud et al., 2016) to establish strong baseline approaches.",
  "y": "uses"
 },
 {
  "id": "c67297dc1c4376dc715bf5c1c9132f_4",
  "x": "Sense-based KNN Adapted from ELMo<cite> (Peters et al., 2018)</cite> with k = 1, words that have the same senses are clustered together, and the average of that cluster is used as the sense vector, which is then fitted using a one KNN classifier.",
  "y": "uses"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_0",
  "x": "An important contribution of our approach is that unlike previous approaches such as forced alignment<cite> (Wuebker et al., 2010)</cite> , reordering and language models can also be re-estimated.",
  "y": "differences"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_1",
  "x": "The forced alignment technique of <cite>Wuebker et al. (2010)</cite> forms the main motivation for our work.",
  "y": "motivation"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_2",
  "x": "Another relevant line of research relates tuning (weight optimisation), where our work lies between forced decoding<cite> (Wuebker et al., 2010)</cite> and the bold updating approach of (Liang et al., 2006) .",
  "y": "similarities"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_3",
  "x": "Within forced decoding, <cite>Wuebker et al. (2010)</cite> address this problem by using a leave-one-out approach where they modify the phrase translation probabilities for each sentence pair by removing the counts of all phrases that were extracted from that particular sentence.",
  "y": "background"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_4",
  "x": "Within forced decoding, <cite>Wuebker et al. (2010)</cite> address this problem by using a leave-one-out approach where they modify the phrase translation probabilities for each sentence pair by removing the counts of all phrases that were extracted from that particular sentence. However, in our approach, we do not impose a constraint to produce the exact translation, instead we use the highest BLEU translations which may be very different from the references.",
  "y": "differences"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_5",
  "x": "The best improvements over the baseline are obtained by using only 1-best (n= 1) alignments as shown in Table 1 . Surprisingly, this is in contrast with forced decoding as discussed in <cite>Wuebker et al. (2010)</cite> , where the best improvements are obtained for n = 100.",
  "y": "differences"
 },
 {
  "id": "c6ae69051a6d9111dea1a6e8405ac9_6",
  "x": "Additionally, we also compare oracle-BLEU re-estimation to forced decoding with leave-oneout<cite> (Wuebker et al., 2010)</cite> by evaluating both on a concatenation of 5 test sets (MT03, MT05-MT09).",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_0",
  "x": "Recently, with the arrival of large-scale collections of historic texts and online libraries such as Google books, a new paradigm has been added to this research area, whereby the prime interest is in identifying the temporal scope of a sense [10, 14, <cite>16,</cite> 25] which, in turn, can give further insights to the phenomenon of language evolution.",
  "y": "background"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_1",
  "x": "We then explore another unsupervised approach presented in Lau et al.<cite> [16]</cite> over the same Google books corpus 1 , apply topic modeling for sense induction and directly adapt their similarity measure to get the new senses.",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_2",
  "x": "Attempts have been made by Lau et al. [17] where they first introduced their topic modeling based word sense induction method to automatically detect words with emergent novel senses and in a subsequent work, Lau et al.<cite> [16]</cite> extended this task by leveraging the concept of predominant sense.",
  "y": "background"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_3",
  "x": "Baseline 2: Lau et al.<cite> [16]</cite> : The authors proposed an unsupervised approach based on topic modeling for sense induction, and showed novel sense identification as one of its applications.",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_4",
  "x": "We run Lau et al.<cite> [16]</cite> over these birth cases to detect 'novel' sense as per their algorithm.",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_5",
  "x": "For the same 100 random samples, we now use the outputs of Lau et al.<cite> [16]</cite> and the proposed approach, and estimate the precision as well as recall of these.",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_6",
  "x": "Similarly Table 4 shows manual evaluations results for 3 example cases, along with their novel sense as captured by Lau et al.<cite> [16]</cite> .",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_7",
  "x": "Note that for these 100 random samples (that are all marked 'true' by Mitra et al. [19] ), it is possible to find an upper bound on the recall of Lau et al.<cite> [16]</cite> 's approach automatically.",
  "y": "uses"
 },
 {
  "id": "c7778abb2f1890ba896ccef2c3e13b_8",
  "x": "Further, we check if we can meaningfully combine the results reported by both the methods of Mitra et al. [19] and Lau et al.<cite> [16]</cite> for more accurate sense detection; and how does this compare with Table 8 ; both the senses look quite similar.",
  "y": "uses"
 },
 {
  "id": "c796e11db9203d35c1fad61d1329ef_0",
  "x": "Indeed, this was the pattern demonstrated by<cite> Levy et al. (2015)</cite> :",
  "y": "similarities"
 },
 {
  "id": "c796e11db9203d35c1fad61d1329ef_1",
  "x": "In our experiments, we use the implementations of word2vec Skip-Gram with Negative Sampling (SGNS) and PMI matrix factorization via Singular Value Decomposition (SVD) by<cite> Levy et al. (2015)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "c796e11db9203d35c1fad61d1329ef_2",
  "x": "Finally, a parameter in SVD determines the asymmetry of factorization, which was simulated with 0, 0.5 and 1 eig (for more details refer to<cite> Levy et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "c796e11db9203d35c1fad61d1329ef_3",
  "x": "SVD also benefits from a w+c equivalent setting proposed by <cite>Levy & Goldberg (2015)</cite> in performing the syntagmatic task, however the enhancement is tightly bounded for this model.",
  "y": "differences"
 },
 {
  "id": "c796e11db9203d35c1fad61d1329ef_4",
  "x": "The equivalent post-processing of the matrices in SVD for explicit inclusion of firstorder similarity suggested by<cite> Levy et al. (2015)</cite> enhanced the performance of this model in the syntagmatic (relatedness) task only in the expense of making it worse for the paradigmatic (similarity) task.",
  "y": "extends differences"
 },
 {
  "id": "c7c9266b5063ec85494fde45d1dce1_0",
  "x": "Most of the earlier work revolves either around manual feature extraction <cite>[6]</cite> or use representation learning methods followed by a linear classifier [1, 4] of complex problems in speech, vision and text applications.",
  "y": "background"
 },
 {
  "id": "c7c9266b5063ec85494fde45d1dce1_1",
  "x": "As baselines, we compare with feature spaces comprising of char n-grams <cite>[6]</cite> , TF-IDF vectors, and Bag of Words vectors (BoWV).",
  "y": "uses"
 },
 {
  "id": "c7c9266b5063ec85494fde45d1dce1_2",
  "x": "(1) Char n-grams: It is the state-ofthe-art method <cite>[6]</cite> which uses character n-grams for hate speech detection.",
  "y": "background"
 },
 {
  "id": "c7c9266b5063ec85494fde45d1dce1_3",
  "x": "We experimented with a dataset of 16K annotated tweets made available by <cite>the authors of</cite> <cite>[6]</cite> .",
  "y": "uses"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_0",
  "x": "The work described in this paper uses probabilistic latent variable models to describe patterns of syntactic interaction, building on the selectional preference models of\u00d3 S\u00e9aghdha (2010) and Ritter et al. (2010) and the lexical substitution models of<cite> Dinu and Lapata (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_1",
  "x": "The work described in this paper uses probabilistic latent variable models to describe patterns of syntactic interaction, building on the selectional preference models of\u00d3 S\u00e9aghdha (2010) and Ritter et al. (2010) and the lexical substitution models of<cite> Dinu and Lapata (2010)</cite> . We propose novel methods for incorporating information about syntactic context in models of lexical choice, yielding a probabilistic analogue to dependency-based models of contextual similarity.",
  "y": "extends"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_2",
  "x": "As described in Section 3 below,<cite> Dinu and Lapata (2010)</cite> propose an LDA-based model for lexical substitution; the techniques presented in this paper can be viewed as a generalisation of theirs.",
  "y": "background"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_3",
  "x": "In particular, we follow recent work <cite>(Dinu and Lapata, 2010</cite>; \u00d3 S\u00e9aghdha, 2010; Ritter et al., 2010) in assuming a latent variable model that associates contexts with distributions over a shared set of variables and associates each variable with a distribution over the vocabulary of word types:",
  "y": "uses"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_4",
  "x": "A non-generative alternative is one that estimates the similarity of the latent variable distributions associated with seeing n and o in context C. The principle that similarity between topic distributions corresponds to semantic similarity is well-known in document modelling and was proposed in the context of lexical substitution by<cite> Dinu and Lapata (2010)</cite> .",
  "y": "background"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_5",
  "x": "However, Thater et al. (2010) and<cite> Dinu and Lapata (2010)</cite> both observe that contextualising both o and n can degrade performance; in view of this we actually compare P (z|o, C) with P (z|n) and make the further simplifying assumption that P (z|n) \u221d P (n|z).",
  "y": "motivation background"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_6",
  "x": "In terms of the equations presented above, we could compare the distributions P (z|o, C) with P (z|n, C) using equations (5) or (16). However, Thater et al. (2010) and<cite> Dinu and Lapata (2010)</cite> both observe that contextualising both o and n can degrade performance; in view of this we actually compare P (z|o, C) with P (z|n) and make the further simplifying assumption that P (z|n) \u221d P (n|z). The similarity measure we adopt is the Bhattacharyya coefficient, which is a natural measure of similarity between probability distributions and is closely related to the Hellinger distance used in previous work on topic modelling (Blei and Lafferty, 2007) :",
  "y": "motivation"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_7",
  "x": "We use two measures to evaluate performance: Generalised Averaged Precision (Kishida, 2005 ) and Kendall's \u03c4 b rank correlation coefficient, which were used for this task by Thater et al. (2010) and<cite> Dinu and Lapata (2010)</cite> , respectively.",
  "y": "uses"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_8",
  "x": "For the window-based context model we follow<cite> Dinu and Lapata (2010)</cite> in treating each word within five words of a target as a member of its context set.",
  "y": "uses"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_9",
  "x": "The choice of 70 for scaling Wikipedia counts is adopted from<cite> Dinu and Lapata (2010)</cite> , who used the same factor for the comparably sized English Gigaword corpus.",
  "y": "uses"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_10",
  "x": "As remarked in Section 3.1,<cite> Dinu and Lapata (2010)</cite> use a slightly different formulation of P (z|C, o).",
  "y": "differences"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_11",
  "x": "Using the window-based context model our formulation (5) outperforms (7) for both training corpora; the<cite> Dinu and Lapata (2010)</cite> Table 6 : Performance by part of speech Table 6 gives a breakdown of performance by target part of speech for the BNC+Wikipedia-trained W5 and W5 + T \u2194 C models, as well as figures provided by previous researchers. 7 W5 + T \u2194 C outperforms W5 on all parts of speech using both evaluation metrics.",
  "y": "differences"
 },
 {
  "id": "c870d761c6fcd24de73f5bf98a9fd3_12",
  "x": "As remarked above, previous researchers have used the corpus in slightly different ways; we believe that the results of<cite> Dinu and Lapata (2010)</cite> are fully comparable, while those of Thater et al. (2010) were attained on a slightly smaller dataset with parameters set through cross-validation.",
  "y": "similarities"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_0",
  "x": "Domain shift is a fundamental problem in machine learning, that has attracted a lot of attention in the natural language processing and vision communities [2, 6, 11,<cite> 13,</cite> 29, 30, 32, 37, 39, 40, 42] .",
  "y": "background"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_1",
  "x": "Domain shift is a fundamental problem in machine learning, that has attracted a lot of attention in the natural language processing and vision communities [2, 6, 11,<cite> 13,</cite> 29, 30, 32, 37, 39, 40, 42] . To understand and address this problem, generated by the lack of labeled data in a target domain, researchers have studied the behavior of machine learning methods in cross-domain settings [12,<cite> 13,</cite> 29] and came up with various domain adaptation techniques [6, 11, 28, 39] .",
  "y": "background"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_2",
  "x": "Interestingly, some recent works<cite> [13,</cite> 18] indicate that string kernels can yield robust results in the cross-domain setting without any domain adaptation. In fact, methods based on string kernels have demonstrated impressive results in various text classification tasks ranging from native language identification [22] [23] [24] 36] and authorship identification [34] to dialect identification [4, 18, 21] , sentiment analysis<cite> [13,</cite> 35] and automatic essay scoring [7] .",
  "y": "background"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_3",
  "x": "As long as a labeled training set is available, string kernels can reach state-of-the-art results in various languages including English [7,<cite> 13,</cite> 23] , Arabic [4, 17, 18, 24] , Chinese [35] and Norwegian [24] .",
  "y": "background"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_4",
  "x": "As long as a labeled training set is available, string kernels can reach state-of-the-art results in various languages including English [7,<cite> 13,</cite> 23] , Arabic [4, 17, 18, 24] , Chinese [35] and Norwegian [24] . Different from all these recent approaches, we use unlabeled data from the test set in a transductive setting in order to significantly increase the performance of string kernels.",
  "y": "differences"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_5",
  "x": "In recent years, methods based on string kernels have demonstrated remarkable performance in various text classification tasks [7, 10,<cite> 13,</cite> 18, 23, 27, 34] .",
  "y": "background"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_6",
  "x": "Gim\u00e9nez-P\u00e9rez et al. <cite>[13]</cite> have used string kernels for single-source and multi-source polarity classification.",
  "y": "background"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_7",
  "x": "Different from all these recent approaches<cite> [13,</cite> 18, 23] , we use unlabeled data from the target domain to significantly increase the performance of string kernels in cross-domain text classification, particularly in English polarity classification.",
  "y": "differences"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_8",
  "x": "We compare our approach with several methods [3, 12,<cite> 13,</cite> 15, 32, 40] in two cross-domain settings.",
  "y": "uses"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_9",
  "x": "Using string kernels, Gim\u00e9nez-P\u00e9rez et al. <cite>[13]</cite> reported better performance than SST [3] and KE-Meta [12] in the multi-source domain setting.",
  "y": "differences"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_11",
  "x": "Multi-source cross-domain polarity classification accuracy rates (in %) of our transductive approaches versus a state-of-the-art baseline based on string kernels <cite>[13]</cite> , as well as SST [3] and KE-Meta [12] .",
  "y": "uses"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_12",
  "x": "We follow the same evaluation methodology of Gim\u00e9nez-P\u00e9rez et al. <cite>[13]</cite> , to ensure a fair comparison.",
  "y": "uses"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_13",
  "x": "Although Gim\u00e9nez-P\u00e9rez et al. <cite>[13]</cite> used a different classifier, namely Kernel Discriminant Analysis, we observed that Kernel Ridge Regression produces similar results (\u00b10.1%) when we employ the same string kernels.",
  "y": "similarities differences"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_14",
  "x": "As Gim\u00e9nez-P\u00e9rez et al. <cite>[13]</cite> , we evaluate our approach in two cross-domain settings.",
  "y": "uses"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_15",
  "x": "Single-source cross-domain polarity classification accuracy rates (in %) of our transductive approaches versus a state-of-the-art baseline based on string kernels <cite>[13]</cite> , as well as SFA [32] , CORAL [40] and TR-TrAdaBoost [15] .",
  "y": "uses"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_16",
  "x": "Without exception, the accuracy rates reached by the transductive string kernels are significantly better than the best baseline string kernel <cite>[13]</cite> , according to the McNemar's test performed at a confidence level of 0.01.",
  "y": "differences"
 },
 {
  "id": "c897c2ea0d641f1f35072be4a5a7d3_17",
  "x": "Indeed, the polarity classification experiments demonstrate that our framework achieves better accuracy rates than other state-ofthe-art methods [3, 12,<cite> 13,</cite> 15, 32, 40] .",
  "y": "differences"
 },
 {
  "id": "c932ba05eb5cb30094dd98739daa95_0",
  "x": "Compared to other existing systems for predicate-argument extraction (Banko et al., 2007; Fader et al., 2011; <cite>Angeli et al., 2015)</cite> , the use of manual language-agnostic patterns on UD makes PredPatt a well-founded component across languages.",
  "y": "background"
 },
 {
  "id": "c932ba05eb5cb30094dd98739daa95_1",
  "x": "We convert the PropBank annotations for all verbal predicates in these two corpora, and ignore roles of directional (DIR), manner (MNR), modals (MOD), negation (NEG) and adverbials (ADV), as they aren't extracted as distinct argument but instead are folded into the complex predicate by PredPatt and other systems for predicate-argument extraction (Banko et al., 2007; Fader et al., 2011; <cite>Angeli et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "c932ba05eb5cb30094dd98739daa95_2",
  "x": "In this section, we evaluate the original PredPatt (PredPatt v1) and the improved PredPatt (PredPatt v2) on the English Web Treebank (EWT) and the Wall Street Journal corpus (WSJ), and compare their performance with four prominent Open IE systems: OpenIE 4, 6 OLLIE (Mausam et al., 2012) , ClausIE (Del Corro and Gemulla, 2013) , and Stanford Open IE<cite> (Angeli et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_0",
  "x": "Recently, <cite>Canny et al. (2013)</cite> presented an approach to GPU parsing that sacrifices traditional sparsity in exchange for raw computational power, obtaining a system that can compute Viterbi parses for a high-quality grammar at about 164 sentences per second on a mid-range GPU.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_1",
  "x": "Recently, <cite>Canny et al. (2013)</cite> proposed a GPU implementation of a constituency parser that sacrifices all sparsity in exchange for the sheer horsepower that GPUs can provide.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_2",
  "x": "A further drawback of the dense approach in <cite>Canny et al. (2013)</cite> is that it only computes Viterbi parses.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_3",
  "x": "1 We should note that our experimental condition differs from that of <cite>Canny et al. (2013)</cite> : they evaluate on sentences of length \u2264 30.",
  "y": "differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_4",
  "x": "Furthermore, they 1 The implementation of <cite>Canny et al. (2013)</cite> cannot handle batches so large, and so we tested it on batches of 1200 sentences.",
  "y": "uses differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_5",
  "x": "Our system uses a coarse-to-fine approach, where the coarse pass computes a pruning mask that is used by the CPU when deciding which items to queue during the fine pass. The original system of <cite>Canny et al. (2013)</cite> only used the fine pass, with no pruning.",
  "y": "differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_6",
  "x": "<cite>Canny et al. (2013)</cite> proposed an implementation of a PCFG parser that sacrifices standard sparse methods like coarse-to-fine pruning, focusing instead on maximizing the instruction and memory throughput of the parser.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_7",
  "x": "The <cite>Canny et al. (2013)</cite> system is benchmarked on a batch size of 1200 sentences, the others on 20,000.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_8",
  "x": "One important feature of <cite>Canny et al. (2013)</cite> 's system is grammar compilation.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_9",
  "x": "<cite>Canny et al. (2013)</cite> found they had to partition the grammar into multiple different kernels.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_10",
  "x": "All in all, <cite>Canny et al. (2013)</cite> 's system is able to compute Viterbi charts at 164 sentences per second, for sentences up to length 40. On larger batch sizes, our reimplementation of their approach is able to achieve 193 sentences per second on the same hardware.",
  "y": "differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_11",
  "x": "Once on the GPU, parse items are processed using the same style of compiled kernel as in <cite>Canny et al. (2013)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_12",
  "x": "<cite>Canny et al. (2013)</cite> clustered symbols of the grammar using a sophisticated spectral clustering algorithm to obtain a permutation of the symbols.",
  "y": "background"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_13",
  "x": "Clustering using this method is labeled 'Parent' in Table 1 . Now, when we use a coarse pruning pass, we are able to parse nearly 280 sentences per second, a 70% increase in parsing performance relative to <cite>Canny et al. (2013)</cite> 's system, and nearly 50% over our reimplemented baseline.",
  "y": "differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_14",
  "x": "The unpruned Viterbi computations in a fine grammar using the clustering method of <cite>Canny et al. (2013)</cite> yields a speed of 193 sentences per second, whereas the same computation using coarse parent clustering has a speed of 159 sentences per second.",
  "y": "uses differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_15",
  "x": "(See Table 1 .) This is not as efficient as <cite>Canny et al. (2013)</cite> 's highly tuned method, but it is still fairly fast, and much simpler to implement.",
  "y": "differences"
 },
 {
  "id": "ca1391f1f908fc081589b1a7dd8229_16",
  "x": "Apart from the model of <cite>Canny et al. (2013)</cite> , there have been a few attempts at using GPUs in NLP contexts before.",
  "y": "background"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_0",
  "x": "If we compare the widely used Conditional Random Fields (CRF) with newly proposed \"deep architecture\" sequence models<cite> (Collobert et al., 2011)</cite> , there are two things changing: from linear architecture to non-linear, and from discrete feature representation to distributional.",
  "y": "differences"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_1",
  "x": "Recently, <cite>Collobert et al. (2011)</cite> proposed \"deep architecture\" models for sequence labeling (named Sentence-level Likelihood Neural Nets, abbreviated as SLNN henceforth), and showed promising results on a range of tasks (POS tagging, NER, Chunking, and SRL).",
  "y": "motivation"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_2",
  "x": "1 Normalizing locally in a logistic regression is equivalent to adding a softmax layer to the output layer of the IONN, which was commonly done in neural networks, such as in <cite>Collobert et al. (2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_3",
  "x": "So far we have extended the potential function used in node cliques of a CRF to a non-linear DNN. And if we keep the potential function for edge cliques the same as before, then in fact we have arrived at an identical model to the SLNN in Collobert et al.<cite> (Collobert et al., 2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_4",
  "x": "Unfortunately, the connection to Collobert and Weston (2008) was not recognized in either of these two studies; vice versa, neither of the above were referenced in <cite>Collobert et al. (2011)</cite> .",
  "y": "differences"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_5",
  "x": "However, overall we found that the feature set we used is competitive with CRF results from earlier literature (Turian et al., 2010;<cite> Collobert et al., 2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_6",
  "x": "For experiments with continuous space feature representations (a.k.a., word embeddings), we took the word embeddings (130K words, 50 dimensions) used in <cite>Collobert et al. (2011)</cite> , which were trained for 2 months over Wikipedia text.",
  "y": "similarities uses"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_7",
  "x": "We attempt to replicate the model described in <cite>Collobert et al. (2011)</cite> without task-specific fine-tuning, with a few exceptions: 1) we used the soft tanh activation function instead of hard tanh; 2) we use the BIO2 tagging scheme instead of BIOES; 3) we use L-BFGS optimization algorithm instead of stochastic gradient descent; 4) we did not use Gazetteer features; 5) <cite>Collobert et al. (2011)</cite> mentioned 5 binary features that look at the capitalization pattern of words to append to the embedding as additional dimensions, but only 4 were described in the paper, which we implemented accordingly.",
  "y": "extends differences"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_8",
  "x": "Four binary features are also appended to each word embedding to capture capitalization patterns, as described in <cite>Collobert et al. (2011)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "ca7db62af4457ca887fe220c43b10e_9",
  "x": "We carefully compared and analyzed the nonlinear neural networks used in <cite>Collobert et al. (2011)</cite> and the widely adopted CRF, and revealed their close relationship.",
  "y": "similarities uses"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_0",
  "x": "With the development of deep learning, sequence-to-sequence (Seq2Seq) neural networks or more generally encoder-decoder frameworks, are among the most popular models for text-based response generation in dialog systems [1, 2,<cite> 3,</cite> 4] .",
  "y": "background"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_1",
  "x": "A severe problem is that the Seq2Seq model tends to generate short and meaningless replies, e.g., \"I don't know\" [2] and \"Me too\" <cite>[3]</cite> .",
  "y": "background"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_2",
  "x": "They are universally relevant to most utterances, called universal replies in <cite>[3]</cite> , and hence less desired in real-world conversation systems.",
  "y": "background"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_3",
  "x": "In previous studies, researchers have proposed a variety of approaches to address the problem of universal replies, ranging from heuristically modified training objectives [2] , diversified decoding algorithms [9] , to content-introducing approaches<cite> [3,</cite> 10] .",
  "y": "background"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_4",
  "x": "This conjecture is casually expressed in previous work <cite>[3]</cite> , but is so far not supported by experiments.",
  "y": "background"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_5",
  "x": "Although it is tempting to think of Seq2Seq's performance in this way <cite>[3]</cite> , barely a practical approach exists to verify the conjecture in the dialog setting alone.",
  "y": "background"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_8",
  "x": "These metrics are used in previous work [4,<cite> 3]</cite> , and are related to our research question.",
  "y": "similarities uses"
 },
 {
  "id": "ca98f16fa3a118f83b16586bba04c8_9",
  "x": "Our findings also explain why referring to additional information-including dialog context [19] , keywords <cite>[3]</cite> and knowledge bases [20]-helps dialog systems: the number of plausible target sentences decreases if the generation is conditioned on more information; this intuition is helpful for future development of text-based response generation in Seq2Seq dialog systems.",
  "y": "similarities"
 },
 {
  "id": "cb81d56412d1e800074777687fb45a_0",
  "x": "Using the model of <cite>Yu et al. (2018a)</cite> , we compare several key model configurations.",
  "y": "uses"
 },
 {
  "id": "cb81d56412d1e800074777687fb45a_1",
  "x": "There has been a line of work improving the model of <cite>Yu et al. (2018a)</cite> since the release of the Spider dataset (Guo et al., 2019; Lin et al., 2019) . At the time of our investigation, however, the models are not published.",
  "y": "background motivation"
 },
 {
  "id": "cb81d56412d1e800074777687fb45a_2",
  "x": "We use the neural semantic parsing method of <cite>Yu et al. (2018a)</cite> as the baseline model, which can be regarded as a sequence-to-tree model.",
  "y": "uses"
 },
 {
  "id": "cb81d56412d1e800074777687fb45a_3",
  "x": "Our hyperparameters are mostly taken from <cite>Yu et al. (2018a)</cite> , but tuned on the Chinese Spider development set.",
  "y": "extends uses"
 },
 {
  "id": "cb81d56412d1e800074777687fb45a_4",
  "x": "Figure 2 shows F1 scores of several typical components, including 4 Note that the results are lower than those reported by <cite>Yu et al. (2018a)</cite> under their split due to different training/test splits. Our split has less training data and more test instances in the \"Hard\" category and less in \"Easy\" and \"Medium\".",
  "y": "differences"
 },
 {
  "id": "cb81d56412d1e800074777687fb45a_5",
  "x": "In this table, ENG represents the results of <cite>Yu et al. (2018a)</cite> 's model on their English dataset but under our split. C-ML and C-S denote the results of our Chinese models based on characters with multi-lingual embeddings and monolingual embeddings, respectively, while WY-ML, WY-S denote the wordbased models applying YZ segmentor with multilingual embeddings and monolingual embeddings, respectively. First, compared to the best results of human translation (C-ML and WY-ML), machine translation results show a large disadvantage (e.g. 7.1% vs 12.1% using C-ML). Out of the 100 translated Second, comparisons among C-ML, WY-ML and WJ-ML, and among C-S, WY-S and WJ-S show that multi-lingual embeddings give superior results compared to monolingual embeddings, which is likely because they bring a better connection between natural language questions and database columns.",
  "y": "differences"
 },
 {
  "id": "cbe9e36f371c072432ca25800c96d3_0",
  "x": "Furthermore, this learning can take place jointly with ASR [15] , or separately with some tasks that have aligned objectives [16,<cite> 17,</cite> 18] .",
  "y": "background"
 },
 {
  "id": "cbe9e36f371c072432ca25800c96d3_1",
  "x": "To evaluate transfer learning performance, we consider three criteria: (1) inclusion of phonetic content, (2) exclusion of nuisance factors, and (3) transferrability across datasets. The first two are evaluated using a protocol similar to <cite>[17]</cite> , where an ASR model is trained on a set of domains, and evaluated on both in-domain and out-of-domain speech (relative to the training data).",
  "y": "similarities"
 },
 {
  "id": "cbe9e36f371c072432ca25800c96d3_2",
  "x": "Other models capable of disentangling phonetic and domain information have recently been shown to learn acoustic features with a greater degree of domain invariance than traditional acoustic features [16, 7,<cite> 17]</cite> .",
  "y": "background"
 },
 {
  "id": "cbe9e36f371c072432ca25800c96d3_3",
  "x": "Similar to <cite>[17]</cite> , we use the clean set (A) for training ASR systems, and test on the four groups separately.",
  "y": "similarities"
 },
 {
  "id": "cbe9e36f371c072432ca25800c96d3_4",
  "x": "FHVAE learns to encode sequence-level and segment-level information into separate latent variables without supervision by optimizing an evidence lower bound derived from a factorized graphical model, and has been shown effective for extracting domain invariant ASR features <cite>[17]</cite> .",
  "y": "background"
 },
 {
  "id": "cbe9e36f371c072432ca25800c96d3_5",
  "x": "While previous work investigated usage of FHVAE for ASR by training FHVAE models on all domains of the target task (e.g., Aurora-4 with all four conditions)<cite> [17,</cite> 8] , we also evaluate FHVAE models trained on PlacesAudCap to test cross-dataset transferability, and on the subset of domains used for ASR training.",
  "y": "background"
 },
 {
  "id": "cbed76ac8086637fe1d2e30f39c585_0",
  "x": "The generalization of SMT-based GEC systems has been shown to improve further by adding neural network models <cite>(Chollampatt et al., 2016b)</cite> .",
  "y": "background"
 },
 {
  "id": "cbed76ac8086637fe1d2e30f39c585_1",
  "x": "It later became the most widely used approach and was used in state-of-the-art GEC systems<cite> Chollampatt et al., 2016b</cite>; JunczysDowmunt and Grundkiewicz, 2016; Rozovskaya and Roth, 2016) .",
  "y": "background"
 },
 {
  "id": "cbed76ac8086637fe1d2e30f39c585_2",
  "x": "Additionally, we use neural network joint models (Devlin et al., 2014) introduced in <cite>(Chollampatt et al., 2016b)</cite> and a character-level SMT component.",
  "y": "background"
 },
 {
  "id": "cbed76ac8086637fe1d2e30f39c585_3",
  "x": "Following<cite> Chollampatt et al. (2016b)</cite> , we add a neural network joint model (NNJM) feature to further improve the SMT component.",
  "y": "uses"
 },
 {
  "id": "cbed76ac8086637fe1d2e30f39c585_4",
  "x": "We show in this paper that performance continues to improve further after adding neural network joint models (NNJMs), as introduced in <cite>(Chollampatt et al., 2016b)</cite> .",
  "y": "similarities background"
 },
 {
  "id": "cbfa4d71f40d8008ebd90026dc1bcd_0",
  "x": "In this paper we focus only on the streaming shallow processing part of the SUMMA project (the dark block in Fig.1 ), where the recently developed neural machine translation techniques (Sutskerev, <cite>Vinyals & Le, 2014</cite>; Bahdanau, Cho & Bengio, 2014) enable radically new end-to-end approach to machine translation and clustering of the incoming news stories.",
  "y": "uses background"
 },
 {
  "id": "cbfa4d71f40d8008ebd90026dc1bcd_1",
  "x": "The key difference of the SUMMA project is that it has been incepted after the recent paradigm-shift (Manning, 2015) in the NLP community towards neural network inspired deep learning techniques such as end-to-end automatic speech recognition (Graves & Jaitly, 2014; Hannun et al., 2014; Amodei, 2015) , end-to-end machinetranslation (Sutskerev, <cite>Vinyals & Le, 2014</cite>; Bahdanau, Cho & Bengio, 2014; Luong et al., 2015) , efficient distributed vectorspace word embeddings (Mikolov et al., 2013) , image and video captioning Venugopalan et al., 2015) , unsupervised learning of document representations by autoencoders (Li, Luong & Jurafsky, 2015) .",
  "y": "background"
 },
 {
  "id": "cbfa4d71f40d8008ebd90026dc1bcd_2",
  "x": "Even training of a single state-of-the-art sentencelevel translational autoencoder requires days of GPU computing (Barzdins & Gosko, 2016) ) in TensorFlow (Abadi et al., 2015) seq2seq model (Sutskerev, <cite>Vinyals & Le, 2014</cite>; Bahdanau, Cho & Bengio, 2014) .",
  "y": "background"
 },
 {
  "id": "cbfa4d71f40d8008ebd90026dc1bcd_3",
  "x": "Table 2 illustrates the character-level neural translation from English to Latvian using modified 2 TensorFlow (Abadi et al., 2015) seq2seq (Sutskerev,<cite> Vinyals & Le, 2014)</cite> neural translation model.",
  "y": "uses"
 },
 {
  "id": "cc3d38692097020ee7f4f17cf9247d_0",
  "x": "Recent studies on relation extraction have shown that by combining kernels with Support-vector Machines (SVM), one can obtain results superior to feature-based methods (Bunescu and Mooney, 2005b;<cite> Bunescu and Mooney, 2005a</cite>; Culotta and Sorensen, 2004; Cumby and Roth, 2003; Zelenko et al., 2003; Zhang et al., 2006a; Zhang et al., 2006b; Zhao and Grishman, 2005) .",
  "y": "background"
 },
 {
  "id": "cc3d38692097020ee7f4f17cf9247d_1",
  "x": "Recent studies on relation extraction have shown that by combining kernels with Support-vector Machines (SVM), one can obtain results superior to feature-based methods (Bunescu and Mooney, 2005b;<cite> Bunescu and Mooney, 2005a</cite>; Culotta and Sorensen, 2004; Cumby and Roth, 2003; Zelenko et al., 2003; Zhang et al., 2006a; Zhang et al., 2006b; Zhao and Grishman, 2005) . Despite the large number of recently proposed kernels and their reported success, there lacks a clear understanding of their relative strength and weakness.",
  "y": "background motivation"
 },
 {
  "id": "cc3d38692097020ee7f4f17cf9247d_2",
  "x": "In this study, we provide a systematic comparison and analysis of three such kernels -subsequence kernel (Bunescu and Mooney, 2005b) , dependency tree kernel (Culotta and Sorensen, 2004) and dependency path kernel <cite>(Bunescu and Mooney, 2005a)</cite> .",
  "y": "uses"
 },
 {
  "id": "cc3d38692097020ee7f4f17cf9247d_3",
  "x": "In a later work also done by<cite> Bunescu & Mooney (2005a)</cite> , they proposed a kernel that computes similarities between nodes on the shortest dependency paths that connect the entities.",
  "y": "background"
 },
 {
  "id": "cc3d38692097020ee7f4f17cf9247d_4",
  "x": "We then present the algorithms behind three kernels that we are particularly interested in: subsequence kernel (Bunescu and Mooney, 2005b) , dependency tree kernel (Culotta and Sorensen, 2004) and shortest path dependency kernel <cite>(Bunescu and Mooney, 2005a)</cite> .",
  "y": "uses"
 },
 {
  "id": "cc3d38692097020ee7f4f17cf9247d_5",
  "x": "The shortest path dependency kernel proposed by<cite> Bunescu & Mooney (2005a)</cite> also works with dependency parse trees.",
  "y": "background"
 },
 {
  "id": "cd7bb4543828f915bc930841bb8d7c_0",
  "x": "One exception is<cite> (Goyal et al., 2016)</cite> , who employed a char-based seq2seq model where the input MR is simply represented as a character sequence, and the output is also generated char-by-char; this approach avoids the rare word problem, as the character vocabulary is very small.",
  "y": "background"
 },
 {
  "id": "cd7bb4543828f915bc930841bb8d7c_1",
  "x": "While<cite> (Goyal et al., 2016)</cite> used an additional finite-state mechanism to guide the production of well-formed (and input-motivated) character sequences, the performance of their basic char2char model was already quite good.",
  "y": "background"
 },
 {
  "id": "cd7bb4543828f915bc930841bb8d7c_2",
  "x": "One exception is<cite> (Goyal et al., 2016)</cite> , who employed a char-based seq2seq model where the input MR is simply represented as a character sequence, and the output is also generated char-by-char; this approach avoids the rare word problem, as the character vocabulary is very small. While<cite> (Goyal et al., 2016)</cite> used an additional finite-state mechanism to guide the production of well-formed (and input-motivated) character sequences, the performance of their basic char2char model was already quite good. We further explore how a recent out-of-the box seq2seq model would perform on E2E NLG Challenge, when used in a char-based mode.",
  "y": "extends background"
 },
 {
  "id": "cd7bb4543828f915bc930841bb8d7c_3",
  "x": "In particular, and contrary to the findings of <cite>(Goyal et al., 2016</cite> ) (on a different dataset), our char-based model never produced non-words.",
  "y": "differences"
 },
 {
  "id": "cd7bb4543828f915bc930841bb8d7c_4",
  "x": "There were no additions or non-words (which was one of the primary concerns for<cite> (Goyal et al., 2016)</cite> ).",
  "y": "background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_0",
  "x": "<cite>Covington (1996)</cite> presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once.",
  "y": "extends background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_1",
  "x": "Two ten-letter strings have anywhere from 26,797 to 8,079,453 different alignments depending on exactly what alignments are considered distinct<cite> (Covington 1996, Covington and</cite> Canfield 1996) .",
  "y": "background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_2",
  "x": "<cite>Covington (1996)</cite> presents a workable alignment algorithm for comparing two languages. In this paper I extend that algorithm to handle more than two languages at once.",
  "y": "extends background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_3",
  "x": "Two ten-letter strings have anywhere from 26,797 to 8,079,453 different alignments depending on exactly what alignments are considered distinct<cite> (Covington 1996, Covington and</cite> Canfield 1996) .",
  "y": "background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_4",
  "x": "The phonetic similarity criterion used by <cite>Covington (1996)</cite> is shown in Table 1 .",
  "y": "background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_5",
  "x": "Accordingly, when computing badness I count each skip only once (assessing it 50 points), then ignore skips when comparing the segments against each other. I have not implemented the rule from <cite>Covington (1996)</cite> that gives a reduced penalty for adjacent skips in the same string to reflect the fact that affixes tend to be contiguous.",
  "y": "motivation differences"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_6",
  "x": "Accordingly, I follow <cite>Covington (1996)</cite> in recasting the problem as a tree search.",
  "y": "uses"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_7",
  "x": "<cite>Covington (1996)</cite> treats this as a process that steps through both strings and, at each step, performs either a \"match\" (accepting a character from both strings), a \"skip-l\" (skipping a character in the first string), or a \"skip-2\" (skipping a character in the second string).",
  "y": "background"
 },
 {
  "id": "ce86cf36ee3b359c34b68e5d82b563_9",
  "x": "Following <cite>Covington (1996)</cite> , I implemented a very simple pruning strategy.",
  "y": "uses"
 },
 {
  "id": "ce990a3d035b8e57fe86b8d84ca479_0",
  "x": "This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process , Chinese restaurant process (Blei et al., 2010) , <cite>hierarchical Pitman-Yor process</cite> (<cite>Teh, 2006</cite>) , Indian buffet process (Ghahramani and Griffiths, 2005) , recurrent neural network (Mikolov et al., 2010; Van Den Oord et al., 2016) , long short-term memory (Hochreiter and Schmidhuber, 1997; , sequence-to-sequence model (Sutskever et al., 2014), variational auto-encoder (Kingma and Welling, 2014) , generative adversarial network (Goodfellow et al., 2014) , attention mechanism (Chorowski et al., 2015; Seo et al., 2016) , memory-augmented neural network (Graves et al., 2014; Graves et al., 2014) , stochastic neural network Miao et al., 2016) , predictive state neural network (Downey et al., 2017) , policy gradient (Yu et al., 2017) and reinforcement learning (Mnih et al., 2015) .",
  "y": "uses background"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_0",
  "x": "Also, such embeddings are usually trained on Indonesian Wikipedia (Al-Rfou et al., 2013; <cite>Bojanowski et al., 2017</cite>) whose size is relatively small, approximately 60M tokens.",
  "y": "motivation background"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_1",
  "x": "Despite the existence of various Indonesian pretrained word embeddings, there are no publicly available Indonesian analogy task datasets on which to evaluate these embeddings. Also, such embeddings are usually trained on Indonesian Wikipedia (Al-Rfou et al., 2013; <cite>Bojanowski et al., 2017</cite>) whose size is relatively small, approximately 60M tokens. Therefore, in this work, we introduce KaWAT (Kata Word Analogy Task), an Indonesian word analogy task dataset, and new Indonesian word embeddings pretrained on 160M tokens of online news corpus.",
  "y": "motivation"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_2",
  "x": "Also, such embeddings are usually trained on Indonesian Wikipedia (Al-Rfou et al., 2013; <cite>Bojanowski et al., 2017</cite>) whose size is relatively small, approximately 60M tokens. Therefore, in this work, we introduce KaWAT (Kata Word Analogy Task), an Indonesian word analogy task dataset, and new Indonesian word embeddings pretrained on 160M tokens of online news corpus.",
  "y": "motivation"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_3",
  "x": "We used <cite>fastText</cite> pretrained embeddings introduced in (<cite>Bojanowski et al., 2017</cite> ) and (Grave et al., 2018) , which have been trained on Indonesian Wikipedia and Indonesian Wikipedia plus Common Crawl data respectively.",
  "y": "uses"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_4",
  "x": "To train the word embeddings, we experimented with three algorithms: word2vec (Mikolov et al., 2013b) , <cite>fastText</cite> (<cite>Bojanowski et al., 2017</cite>) , and GloVe (Pennington et al., 2014) . We used gensim 3 to run word2vec and <cite>fastText</cite> and the original C implementation for GloVe.",
  "y": "uses"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_5",
  "x": "To train the word embeddings, we experimented with three algorithms: word2vec (Mikolov et al., 2013b) , <cite>fastText</cite> (<cite>Bojanowski et al., 2017</cite>) , and GloVe (Pennington et al., 2014) . We used gensim 3 to run word2vec and <cite>fastText</cite> and the original C implementation for GloVe. 4 For all three, we used <cite>their</cite> default hyperparameters, i.e. no tuning was performed.",
  "y": "uses"
 },
 {
  "id": "cf2cc67035107f5bdaab85a760e56e_6",
  "x": "We found that (1) in general, accuracies on the analogy tasks were low, suggesting that improvements for Indonesian word embeddings are still possible and KaWAT is hard enough to be the benchmark dataset for that purpose, (2) on syntactic analogies, embedding by (<cite>Bojanowski et al., 2017</cite>) performed best and yielded 20% fewer training epochs when employed for POS tagging, and (3) on semantic analogies, GloVe embedding trained on Tempo corpus performed best and produced significant gains on ROUGE-1 and ROUGE-L scores when used for text summarization.",
  "y": "uses"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_0",
  "x": "Building on the work reported in <cite>Zhang et al. (2007a)</cite> , we further propose a new partial parsing model that splits the parsing process into two stages, both of which use the bottom-up chart-based parsing algorithm.",
  "y": "extends"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_1",
  "x": "In <cite>(Zhang et al., 2007a)</cite> , we have pointed out that most applications are only interested in certain aspects of parsing results.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_2",
  "x": "In <cite>(Zhang et al., 2007a)</cite> , we have pointed out that most applications are only interested in certain aspects of parsing results.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_3",
  "x": "Based on this fact, <cite>(Zhang et al., 2007a)</cite> have proposed to use partial parsing models to recover the most useful fragment analyses from the intermediate parsing results in cases of unsuccessful parses.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_4",
  "x": "Along the lines of the analysis presented in <cite>(Zhang et al., 2007a)</cite> , in this paper we propose a more elaborated par-tial parsing model, in order to further simplify the training procedure, so that full parse disambiguation models can be reused in partial parsing.",
  "y": "extends"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_5",
  "x": "Section 2. provides background knowledge about the DELPH-IN HPSG grammars, the semantic and syntactic representations, and the partial parsing model presented in Kasper et al. (1999) and <cite>Zhang et al. (2007a)</cite> .",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_6",
  "x": "Based on a similar definition of partial parse, <cite>Zhang et al. (2007a)</cite> formulated the following statistical model:",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_7",
  "x": "Based on a similar definition of partial parse, <cite>Zhang et al. (2007a)</cite> formulated the following statistical model: <cite>The above model</cite> contains two probabilistic components: i) P (\u2126|w) is the conditional probability of a segmentation \u2126 given the input sequence w; and ii) P (t i |w i ) is the conditional probability of an analysis t i for a given subsequence w i in the segmentation.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_8",
  "x": "While there is no gold-standard corpus for the purpose of partial parse evaluation, <cite>Zhang et al. (2007a)</cite> manually compared the parser's partial derivation trees with the Penn Treebank annotation for syntactic similarity.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_9",
  "x": "Furthermore, <cite>Zhang et al. (2007a)</cite> evaluated the fragment semantic outputs based on a practical estimation of RMRS similarities described by Dridan and Bond (2006) .",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_10",
  "x": "One common shortcoming of the partial parsing models proposed in both (Kasper et al., 1999) and <cite>(Zhang et al., 2007a)</cite> is that the results of partial parsing are sets of disjoint sub-analyses, either in the form of derivation subtrees, or in the form of MRS fragments.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_11",
  "x": "As <cite>Zhang et al. (2007a)</cite> have also pointed out, the evaluation of a partial parser is a very difficult task as such, due to the lack of gold-standard annotation for sentences that are not fully analysed by the grammar.",
  "y": "background"
 },
 {
  "id": "d06a49ad232f73328874282d91cde0_12",
  "x": "For the purpose of evaluation, <cite>Zhang et al. (2007a)</cite> compared the partial derivation tree to the Penn Treebank bracketing, and partial RMRS fragments to the RASP RMRS outputs.",
  "y": "background"
 },
 {
  "id": "d0c12613f09b36e071b9a842a4d844_0",
  "x": "This paper presents some experiments carried out based on two syntactic tree alignment algorithms presented in<cite> [Lavie et al. 2008]</cite> and [Tinsley et al. 2007 ].",
  "y": "background"
 },
 {
  "id": "d0c12613f09b36e071b9a842a4d844_1",
  "x": "After the alignment of leaf nodes, the internal nodes are aligned following various approaches and distinct criteria. For instance, the method presented in <cite>[Lavie et al. 2008</cite> ] assigns a prime number to each pair of aligned leaf nodes in source and target trees based on the lexical alignment.",
  "y": "background"
 },
 {
  "id": "d0c12613f09b36e071b9a842a4d844_2",
  "x": "Similarly, in [Tinsley et al. 2007 ] the alignment of internal nodes is accomplished using the alignment probabilities of leaf nodes generated by GIZA++ [Och and Ney 2003] . In this case, the product of the probabilities of lexical alignment (not prime numbers as<cite> [Lavie et al. 2008]</cite> ) is assigned to parent nodes.",
  "y": "background"
 },
 {
  "id": "d0c12613f09b36e071b9a842a4d844_3",
  "x": "For the experiments presented in this paper, the baseline models were implemented based on<cite> [Lavie et al. 2008]</cite> and [Tinsley et al. 2007 ] mainly because they do not require rich resources such as [Marecek et al. 2008] neither use manually created composition rules as [Menezes and Richardson 2001] and [Groves et al. 2004 ].",
  "y": "uses"
 },
 {
  "id": "d0c12613f09b36e071b9a842a4d844_4",
  "x": "The alignment produced by the automatic methods can be very useful for Machine Translation (MT). This paper, therefore, proposes the combination of two syntactic tree alignment methods - <cite>[Lavie et al. 2008</cite> ] (a bottom-up approach) and [Tinsley et al. 2007 ] (a topdown approach) -aiming at improving their performance evaluated on Brazilian Portuguese (pt) and English (en) pair of languages.",
  "y": "extends motivation"
 },
 {
  "id": "d0c12613f09b36e071b9a842a4d844_5",
  "x": "Model 1 -Based on<cite> [Lavie et al. 2008]</cite> Following an idea similar to that described in<cite> [Lavie et al. 2008]</cite> , our implementation (model 1) assigns prime numbers to each pair of aligned terminal nodes 1 .",
  "y": "uses similarities"
 },
 {
  "id": "d13502d44435988822e59bcf66b635_0",
  "x": "The traditional approach to FSD<cite> (Petrovic et al., 2010)</cite> computes the distance of each incoming document 1 e.g. a natural disaster or a scandal 2 TDT by NIST -1998 NIST - -2004 .",
  "y": "background"
 },
 {
  "id": "d13502d44435988822e59bcf66b635_1",
  "x": "Because LSH alone performed ineffectively,<cite> Petrovic et al. (2010)</cite> additionally compared each incoming tweet with the k most recent tweets.",
  "y": "background"
 },
 {
  "id": "d13502d44435988822e59bcf66b635_3",
  "x": "It is known for its high effectiveness in the TDT2 and TDT3 competitions (Fiscus, 2001) and widely used as a benchmark for FSD systems<cite> (Petrovic et al., 2010</cite>; Kasiviswanathan et al., 2011; Petrovic 2013; ) .",
  "y": "background"
 },
 {
  "id": "d13502d44435988822e59bcf66b635_4",
  "x": "LSH-FSD is a highly-scalable system by<cite> Petrovic et al. (2010)</cite> .",
  "y": "background"
 },
 {
  "id": "d13502d44435988822e59bcf66b635_5",
  "x": "We configure their system using the default parameters<cite> (Petrovic et al., 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "d13502d44435988822e59bcf66b635_6",
  "x": "Although<cite> Petrovic et al. (2010)</cite> designed their system (LSH-FSD) to operate in constant space, we found that the memory requirement gradually increases with the number of documents processed, as seen in Figure 3 .",
  "y": "differences"
 },
 {
  "id": "d178b55f8d5928867b481ba89e165c_0",
  "x": "Recently many datasets have been produced for reading comprehension such as SQuAD<cite> [5]</cite> .",
  "y": "background"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_0",
  "x": "In order to better understand the components that lead to effective representations, we propose a lightweight version of InferSent<cite> (Conneau et al., 2017)</cite> , called InferLite, that does not use any recurrent layers and operates on a collection of pre-trained word embeddings.",
  "y": "extends"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_1",
  "x": "Recently, <cite>Conneau et al. (2017)</cite> showed that a bidirectional LSTM with max pooling trained to perform Natural Language Inference (NLI), called InferSent, outperforms several other encoding functions on a suite of downstream prediction tasks.",
  "y": "background"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_2",
  "x": "Despite its simplicity, our method obtains performances on par with InferSent<cite> (Conneau et al., 2017)</cite> when using Glove representations (Pennington et al., 2014) as the source of pre-trained word vectors.",
  "y": "similarities"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_3",
  "x": "<cite>Conneau et al. (2017)</cite> showed that similar or improved performance can be obtained using NLI datasets as a source of supervisory information.",
  "y": "background"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_4",
  "x": "Our method operates on a collection of pre-trained word representations and is then trained on the concatenation of SNLI (Bowman et al., 2015) and MultiNLI (Williams et al., 2018) datasets as in <cite>Conneau et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_5",
  "x": "For training on NLI, we follow existing work and compute the concatenation of the embeddings of premise and hypothesis sentences along with their componentwise and absolute difference<cite> (Conneau et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "d1bff202991116a6a957aa61c05770_6",
  "x": "We use 4096-dimensional embeddings as in <cite>Conneau et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_0",
  "x": "Semantic specialization techniques are therefore leveraged to stress a relation of interest such as semantic similarity (Wieting et al., 2015;<cite> Ponti et al., 2018)</cite> or lexical entailment (Nguyen et al., 2017; over other types of semantic association in the word vector space.",
  "y": "background"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_1",
  "x": "Moreover, we show that the proposed specialization transfer method consistently outperforms the direct specialization transfer based on the composition of the crosslingual projection and the post-specialization function<cite> (Ponti et al., 2018)</cite> , with substantial gains across all experimental setups.",
  "y": "differences"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_2",
  "x": "Conflating distinct (both paradigmatic and syntagmatic) lexico-semantic relations is a well-known property of distributional word vectors; semantic specialization of such spaces for a particular lexicosemantic relation (e.g., semantic similarity or lexical entailment) benefits a number of tasks, e.g., dialog state tracking<cite> Ponti et al., 2018)</cite> , spoken language understanding (Kim et al., 2016b,a) , text simplification (Glava\u0161 and Vuli\u0107, 2018b;<cite> Ponti et al., 2018)</cite> , and cross-lingual transfer of resources (Vuli\u0107 et al., 2017a) .",
  "y": "background"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_3",
  "x": "Post-specialization<cite> Ponti et al., 2018</cite>; Kamath et al., 2019) is a generalization of retrofitting that specializes the entire distributional space: 1) it learns a global specialization function using before-and after-retrofitting vectors of words from lexical constraints as training examples and 2) it applies the global specialization functions to vectors of words unseen in lexical constraints.",
  "y": "background"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_5",
  "x": "Our experiments show that the proposed specialization transfer via lexical relation induction (CLSRI) outperforms the previous state-of-the-art specialization transfer method of<cite> Ponti et al. (2018).</cite>",
  "y": "differences"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_6",
  "x": "As the final step, we generalize AR's specialization to the entire target vocabulary with a post-specialization model<cite> (Ponti et al., 2018)</cite> that learns the global specialization function from pairs of distributional and ARspecialized vectors of words from L t constraints.",
  "y": "uses"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_7",
  "x": "Our proposed CLSRI specialization conceptually differs from an existing cross-lingual specialization transfer methodology<cite> (Ponti et al., 2018</cite>; Glava\u0161 and Vuli\u0107, 2018b) , in which the global specialization function is learned in the source language L s and then transferred directly to the target language L s via a shared cross-lingual embedding space.",
  "y": "differences"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_8",
  "x": "In line with and <cite>Ponti et al. (2018)</cite>, we implement this function as a deep feed-forward neural network with l hidden layers of size h and a final linear layer with weight W \u2208 R h\u00d7d .",
  "y": "similarities"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_9",
  "x": "Note that with our proposed specialization approach CLSRI, we execute the retrofitting and postspecialization completely monolingually in the target language L t on the automatically induced constraints in the target language. In contrast, existing work Glava\u0161 and Vuli\u0107, 2018b;<cite> Ponti et al., 2018)</cite> transfers the post-specialization function learned for the source language L s to the target language L t via a cross-lingual vector space.",
  "y": "differences"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_10",
  "x": "The assortment of English constraints for specialization is the same as in prior work (Zhang et al., 2014; Ono et al., 2015;<cite> Ponti et al., 2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_11",
  "x": "6 https://github.com/facebookresearch/ fastText/tree/master/alignment Owing to the difference in the amount of supervision, the post-specialization model has partially non-overlapping configurations for the baseline model of <cite>Ponti et al. (2018)</cite> and our CLSRI model.",
  "y": "similarities"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_12",
  "x": "X-PS refers to the baseline model of <cite>Ponti et al. (2018)</cite> based on direct cross-lingual post-specialization.",
  "y": "differences"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_13",
  "x": "The full CLSRI-PS model outperforms both the distributional vectors and the baseline method for cross-lingual specialization<cite> (Ponti et al., 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_14",
  "x": "A standard language understanding evaluation task used in prior work on semantic specialization<cite> Ponti et al., 2018</cite>, inter alia) is dialog state tracking (DST) (Henderson et al., 2014; .",
  "y": "background"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_15",
  "x": "First, as already confirmed in prior work<cite> Ponti et al., 2018)</cite> , vectors specialized for semantic similarity are indeed important for DST: we observe improvements with all specialized vectors.",
  "y": "background"
 },
 {
  "id": "d1dce63d89e8cfc73962413734bf7b_17",
  "x": "As shown in previous work<cite> Ponti et al., 2018)</cite> , retrofitting (CLSRI-AR) and the cross-lingual post-specialization transfer (X-PS) are substantially better in the LS task than the original distributional space.",
  "y": "background"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_0",
  "x": "With proper averaging in place, we notice that the distillation model described in <cite>Hu et al. (2016)</cite> , which incorporates explicit logic rules for sentiment classification, is ineffective.",
  "y": "motivation differences"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_1",
  "x": "Recently, <cite>Hu et al. (2016)</cite> incorporate logical rules into a neural model and show that these rules increase the model's accuracy on sentences containing contrastive conjunctions, while Peters et al. (2018a) demonstrate increased overall accuracy on sentiment analysis by initializing a model with representations from a language model trained on millions of sentences.",
  "y": "background"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_2",
  "x": "In this work, we carry out an in-depth study of the effectiveness of the techniques in <cite>Hu et al. (2016)</cite> and Peters et al. (2018a) for sentiment classification of complex sentences.",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_3",
  "x": "Part of our contribution is to identify an important gap in the methodology used in <cite>Hu et al. (2016)</cite> for performance measurement, which is addressed by averaging the experiments over several executions.",
  "y": "extends motivation uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_4",
  "x": "Here we briefly review background from <cite>Hu et al. (2016)</cite> to provide a foundation for our reanalysis in the next section.",
  "y": "background"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_5",
  "x": "We focus on a logic rule for sentences containing an \"A-but-B\" structure (the only rule for which <cite>Hu et al. (2016)</cite> provide experimental results).",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_6",
  "x": "The first contribution of this analysis addresses reproducible research: to meaningfully compare different models, their accuracies must be averaged over far more random seeds than what has traditionally been reported. With proper averaging in place, we notice that the distillation model described in <cite>Hu et al. (2016)</cite> , which incorporates explicit logic rules for sentiment classification, is ineffective.",
  "y": "motivation uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_7",
  "x": "With the averaging in place, we obtain three key findings: (1) the improvements in <cite>Hu et al. (2016)</cite> can almost entirely be attributed to just one of their two proposed mechanisms and are also less pronounced than previously reported; (2) contextualized word embeddings (Peters et al., 2018a) incorporate the \"A-but-B\" rules more effectively without explicitly programming for them; and (3) an analysis using crowdsourcing reveals a bigger picture where the errors in the automated systems have a striking correlation with the inherent sentiment-ambiguity in the data.",
  "y": "extends uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_8",
  "x": "Next, we discuss the two techniques from <cite>Hu et al. (2016)</cite> for incorporating rules into models: projection, which directly alters a trained model, and distillation, which progressively adjusts the loss function during training.",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_9",
  "x": "<cite>Hu et al. (2016)</cite> computes q \u03b8 after every gradient update by projecting the current p \u03b8 , as described above.",
  "y": "background"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_10",
  "x": "All of our experiments (as well as those in <cite>Hu et al. (2016)</cite> ) use the SST2 dataset, a binarized subset of the popular Stanford Sentiment Treebank (SST) (Socher et al., 2013) .",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_11",
  "x": "The dataset includes phrase-level labels in addition to sentence-level labels (see Table 1 for detailed statistics); following <cite>Hu et al. (2016)</cite> , we use both types of labels for the comparisons in Section 3.2.",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_12",
  "x": "In this section we reanalyze the effectiveness of the techniques of <cite>Hu et al. (2016)</cite> and find that most of the performance gain is due to projection and not knowledge distillation.",
  "y": "extends uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_14",
  "x": "We carry out an averaged analysis of the publicly available implementation 4 of <cite>Hu et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_15",
  "x": "We carry out an averaged analysis of the publicly available implementation 4 of <cite>Hu et al. (2016)</cite> . Our analysis reveals that the reported performance of <cite>their two mechanisms</cite> (projection and distillation) is in fact affected by the high variability across random seeds.",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_16",
  "x": "In Figure 2 , the first two columns show the reported accuracies in <cite>Hu et al. (2016)</cite> for models trained with and without distillation (corresponding to using values \u03c0 = 1 and \u03c0 = 0.95 t in the t th epoch, respectively).",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_17",
  "x": "We keep our hyper-parameters identical to <cite>Hu et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_18",
  "x": "We confirm that ELMo's predictions are much closer to the A-but-B rule's manifold than those of the other models by computing KL(q \u03b8 ||p \u03b8 ) where p \u03b8 and q \u03b8 are the original and projected distributions: Averaged across all A-but-B sentences and 100 seeds, this gives 0.27, 0.26 and 0.13 for the Kim (2014) , <cite>Hu et al. (2016)</cite> with distillation and ELMo systems respectively.",
  "y": "uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_19",
  "x": "We discover that ELMo's performance improvements over the baseline are robust across varying levels of ambiguity, whereas the advantage of <cite>Hu et al. (2016)</cite> is reversed in sentences of low ambiguity (restricting to A-but-B style sentences).",
  "y": "extends differences uses"
 },
 {
  "id": "d3122aab8960a7c89afe87c73faa59_20",
  "x": "Across all thresholds, we notice trends similar to previous sections: 1) ELMo performs the best among all models on A-but-B style sentences, and projection results in only a slight improvement; 2) models in <cite>Hu et al. (2016)</cite> (with and without distillation) benefit considerably from projection; but 3) distillation offers little improvement (with or without projection).",
  "y": "extends differences"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_0",
  "x": "In particular, in <cite>(Linzen et al., 2016)</cite> we assess the ability of LSTMs to learn subject-verb agreement patterns in English, and evaluate on naturally occurring wikipedia sentences.",
  "y": "background"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_1",
  "x": "Indeed, Tran et al. (2018) finds that transformerbased models perform worse than LSTM models on the <cite>Linzen et al. (2016)</cite> agreement prediction dataset.",
  "y": "differences"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_2",
  "x": "Indeed, Tran et al. (2018) finds that transformerbased models perform worse than LSTM models on the <cite>Linzen et al. (2016)</cite> agreement prediction dataset. In contrast, (Tang et al., 2018) find that self-attention performs on par with LSTM for syntax sensitive dependencies in the context of machine-translation, and performance on syntactic tasks is correlated with the number of attention heads in multi-head attention. I adapt the evaluation protocol and stimuli of <cite>Linzen et al. (2016)</cite> , Gulordava et al. (2018) and Marvin and Linzen (2018) to the bidirectional setting required by BERT, and evaluate the pretrained BERT models (both the LARGE and the BASE models).",
  "y": "uses"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_3",
  "x": "I use the stimuli provided by (<cite>Linzen et al., 2016</cite>; Gulordava et al., 2018; Marvin and Linzen, 2018) , but change the experimental protocol to adapt it to the bidirectional nature of the BERT model.",
  "y": "extends"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_4",
  "x": "All three previous work use uni-directional language-model-like models. <cite>Linzen et al. (2016)</cite> start with existing sentences from wikipedia that contain a present-tense verb. <cite>They</cite> feed each sentence word by word into an LSTM, stop right before the focus verb, and ask the model to predict a binary plural/singular decision (supervised setup) or compare the probability assigned by a pre-trained language model (LM) to the plural vs singular forms of the verb (LM setup).",
  "y": "background"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_5",
  "x": "The evaluation is then performed similarly to the LM setup of <cite>Linzen et al. (2016)</cite> : the sentence is fed into a pretraiend LSTM LM up to the focus verb, and the model is considered correct if the probability assigned to the correct inflection of the original verb form given the prefix is larger than that assigned to the incorrect inflection.",
  "y": "background"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_7",
  "x": "This differs from <cite>Linzen et al. (2016)</cite> and Gulordava et al. (2018) by considering the entire sentence (excluding the verb) and not just its prefix leading to the verb, and differs from Marvin and Linzen (2018) by conditioning the focus verb on bidirectional context.",
  "y": "differences"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_8",
  "x": "I also discard the agreement cases involving the verbs is or are in <cite>Linzen et al. (2016)</cite> and in Gulordava et al. (2018) , because some of them are copular construction, in which strong agreement hints can be found also on the object following the verb.",
  "y": "extends"
 },
 {
  "id": "d5144370a9361ff870dd3cb2e064ff_9",
  "x": "I similarly discard 680 sentences from (<cite>Linzen et al., 2016</cite>) where the focus verb or its inflection were one of 108 out-ofvocabulary tokens, 6 and 28 sentence-pairs (8 tokens 7 ) from (Gulordava et al., 2018) .",
  "y": "extends"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_0",
  "x": "With advances in deep learning, neural models have given state-of-the-art results on many sequence labeling tasks (Ling et al., 2015; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_1",
  "x": "Many existing state-of-the-art neural sequence labeling models utilize word-level Long Short-Term Memory (LSTM) structures to represent global sequence information and a CRF layer to capture dependencies between neighboring labels Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_2",
  "x": "For example, Reimers and Gurevych (2017b) conduct a large number of experiments using the code of <cite>Ma and Hovy (2016)</cite> , but cannot obtain comparable results as reported in the paper.",
  "y": "motivation background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_3",
  "x": "Despite them being dominant in the research literature, reproducing published results for neural models can be challenging, even if the codes are available open source. For example, Reimers and Gurevych (2017b) conduct a large number of experiments using the code of <cite>Ma and Hovy (2016)</cite> , but cannot obtain comparable results as reported in the paper.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_4",
  "x": "Liu et al. (2018) report lower average F-scores on NER when reproducing the structure of Lample et al. (2016) , and on POS tagging when reproducing <cite>Ma and Hovy (2016)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_5",
  "x": "Despite them being dominant in the research literature, reproducing published results for neural models can be challenging, even if the codes are available open source. Liu et al. (2018) report lower average F-scores on NER when reproducing the structure of Lample et al. (2016) , and on POS tagging when reproducing <cite>Ma and Hovy (2016)</cite> .",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_6",
  "x": "For example, most work observes that stochastic gradient descent (SGD) gives best performance on NER task (Chiu and Nichols, 2016; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , while Reimers and Gurevych (2017b) report that SGD is the worst optimizer on the same datasets.",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_7",
  "x": "In addition, conclusions from different reports can be contradictory. For example, most work observes that stochastic gradient descent (SGD) gives best performance on NER task (Chiu and Nichols, 2016; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , while Reimers and Gurevych (2017b) report that SGD is the worst optimizer on the same datasets.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_8",
  "x": "Most work reports sequence labeling results on both CoNLL 2003 English NER (Tjong Kim Sang and De Meulder, 2003) and PTB POS (Marcus et al., 1993) datasets (Collobert et al., 2011; <cite>Ma and Hovy, 2016</cite>) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_9",
  "x": "We list six inconsistent configurations in literature, which lead to difficulties for fair comparison. \u2022 Dataset. Most work reports sequence labeling results on both CoNLL 2003 English NER (Tjong Kim Sang and De Meulder, 2003) and PTB POS (Marcus et al., 1993) datasets (Collobert et al., 2011; <cite>Ma and Hovy, 2016</cite>) . Ling et al. (2015) give results only on POS dataset, while some papers (Chiu and Nichols, 2016; Lample et al., 2016; Strubell et al., 2017) report results on the NER dataset only.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_10",
  "x": "Most work uses the development set to select hyperparameters (Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , while others add development set into training set (Chiu and Nichols, 2016; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_11",
  "x": "We list six inconsistent configurations in literature, which lead to difficulties for fair comparison. Most work uses the development set to select hyperparameters (Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , while others add development set into training set (Chiu and Nichols, 2016; Peters et al., 2017) . Different from <cite>Ma and Hovy (2016)</cite> and Liu et al. (2018) , choose a different data split on the POS dataset.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_12",
  "x": "Different from <cite>Ma and Hovy (2016)</cite> and Liu et al. (2018) , choose a different data split on the POS dataset.",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_13",
  "x": "<cite>Ma and Hovy (2016)</cite> do not use preprocessing.",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_14",
  "x": "We list six inconsistent configurations in literature, which lead to difficulties for fair comparison. A typical data preprocessing step is to normize digit characters (Chiu and Nichols, 2016; Lample et al., 2016; Yang et al., 2016; Strubell et al., 2017) . <cite>Ma and Hovy (2016)</cite> do not use preprocessing.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_15",
  "x": "Besides, Lample et al. (2016) and <cite>Ma and Hovy (2016)</cite> use end-to-end structure without handcrafted features.",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_16",
  "x": "We list six inconsistent configurations in literature, which lead to difficulties for fair comparison. Strubell et al. (2017) and Chiu and Nichols (2016) apply word spelling features and further integrate context features. Besides, Lample et al. (2016) and <cite>Ma and Hovy (2016)</cite> use end-to-end structure without handcrafted features.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_17",
  "x": "We list six inconsistent configurations in literature, which lead to difficulties for fair comparison. Some literature reports results using mean and standard deviation under different random seeds (Chiu and Nichols, 2016; Peters et al., 2017; Liu et al., 2018) . Others report the best result among different trials (<cite>Ma and Hovy, 2016</cite>) , which cannot be compared directly.",
  "y": "motivation"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_18",
  "x": "built a BiLSTM-CRF structure, which has been extended by adding character-level LSTM (Lample et al., 2016; Liu et al., 2018) , GRU (Yang et al., 2016) , and CNN (Chiu and Nichols, 2016; <cite>Ma and Hovy, 2016</cite>) features.",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_19",
  "x": "3) Our findings are more consistent with most previous work on configurations such as usefulness of character information (Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , optimizer (Chiu and Nichols, 2016; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) and tag scheme (Ratinov and Roth, 2009; Dai et al., 2015) .",
  "y": "similarities"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_20",
  "x": "Character information has been proven to be critical for sequence labeling tasks (Chiu and Nichols, 2016; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , with LSTM and CNN being used to model character sequence information (\"Char Rep.\").",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_21",
  "x": "Our neural sequence labeling framework contains three layers, i.e., a character sequence representation layer, a word sequence representation layer and an inference layer, as shown in Figure 1 . Character information has been proven to be critical for sequence labeling tasks (Chiu and Nichols, 2016; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) , with LSTM and CNN being used to model character sequence information (\"Char Rep.\").",
  "y": "uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_22",
  "x": "Character features such as prefix, suffix and capitalization can be represented with embeddings through a feature-based lookup table (Collobert et al., 2011; Strubell et al., 2017) , or neural networks without human-defined features (Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_23",
  "x": "Character features such as prefix, suffix and capitalization can be represented with embeddings through a feature-based lookup table (Collobert et al., 2011; Strubell et al., 2017) , or neural networks without human-defined features (Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) . In this work, we focus on neural character sequence representations without hand-engineered features.",
  "y": "uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_24",
  "x": "Using a CNN structure to encode character sequences was firstly proposed by Santos and Zadrozny (2014), and followed by many subsequent investigations (dos Santos et al., 2015; Chiu and Nichols, 2016; <cite>Ma and Hovy, 2016</cite>) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_25",
  "x": "In our experiments, we take the same structure as <cite>Ma and Hovy (2016)</cite> , using one layer CNN structure with max-pooling to capture character-level representations.",
  "y": "uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_26",
  "x": "LSTM has been widely used in sequence labeling (Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>; Chiu and Nichols, 2016; Liu et al., 2018) .",
  "y": "background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_27",
  "x": "The NER dataset has been standardly split in Tjong Kim Sang and De Meulder (2003 (Toutanova et al., 2003; Santos and Zadrozny, 2014; <cite>Ma and Hovy, 2016;</cite> Liu et al., 2018) , we adopt the standard splits by using sections 0-18 as training set, sections 19-21 as development set and sections 22-24 as test set.",
  "y": "uses background"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_28",
  "x": "Table 3 shows the hyperparameters used in our experiments, which mostly follow <cite>Ma and Hovy (2016)</cite> , including the learning rate \u03b7 = 0.015 for word LSTM models.",
  "y": "similarities uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_29",
  "x": "We re-implement the structure of several reports (Chiu and Nichols, 2016; <cite>Ma and Hovy, 2016</cite>; Peters et al., 2017) , which take the CCNN+WLSTM+CRF architecture.",
  "y": "uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_30",
  "x": "The results of Lample et al. (2016) , <cite>Ma and Hovy (2016)</cite> and Yang et al. (2017b) can be reproduced by our CLSTM+WLSTM+CRF and CCNN+WLSTM+CRF models.",
  "y": "similarities uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_31",
  "x": "The GloVe 100-dimension embeddings give higher F1-scores than SENNA (Collobert et al., 2011) on both models, which is consistent with the observation of <cite>Ma and Hovy (2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_32",
  "x": "Our observation is consistent with most literature (Chiu and Nichols, 2016; Lample et al., 2016; <cite>Ma and Hovy, 2016</cite>) .",
  "y": "similarities"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_33",
  "x": "Following <cite>Ma and Hovy (2016)</cite> , words in the test set are divided into four subsets: in-vocabulary words, out-of-training-vocabulary words (OOTV), out-of-embedding-vocabulary words (OOEV) and out-of-both-vocabulary words (OOBV).",
  "y": "uses"
 },
 {
  "id": "d52a1a26cbf8a6f528be5494f05e45_34",
  "x": "The OOV entities and chunks are categorized following <cite>Ma and Hovy (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_0",
  "x": "An important goal in argument mining is to understand the structure in argumentative text (Persing and Ng, 2016; Peldszus and Stede, 2015;<cite> Stab and Gurevych, 2016</cite>; Nguyen and Litman, 2016) .",
  "y": "background"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_1",
  "x": "The task of processing argument structure encapsulates four distinct subtasks (our work focuses on subtasks 2 and 3): (1) Given a sequence of tokens that represents an entire argumentative text, determine the token subsequences that constitute non-intersecting ACs; (2) Given an AC, determine the type of AC (claim, premise, etc.); (3) Given a set/list of ACs, determine which ACs have directed links that encapsulate overall argument structure; (4) Given two linked ACs, determine whether the link is a supporting or attacking relation. This can be labeled as a 'micro' approach to argument mining<cite> (Stab and Gurevych, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_2",
  "x": "Second, we follow previous work that assumes a tree structure for the linking of ACs (Palau and Moens, 2009; Cohen, 1987; Peldszus and Stede, 2015;<cite> Stab and Gurevych, 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_3",
  "x": "Figure 1 shows an example that we will use throughout the paper to concretely explain how our approach works. First, the left side of the figure presents the raw text of a paragraph in a persuasive essay<cite> (Stab and Gurevych, 2016)</cite> , with the ACs contained in square brackets.",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_4",
  "x": "Linking to the first argument component can provide a competitive baseline heuristic (Peldszus and Stede, 2015;<cite> Stab and Gurevych, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_5",
  "x": "Linking to the first argument component can provide a competitive baseline heuristic (Peldszus and Stede, 2015;<cite> Stab and Gurevych, 2016)</cite> . Given the above considerations, we propose that sequence-to-sequence attention modeling, in the spirit of a Pointer Network (PN) (Vinyals et al., 2015b) , can be effective for predicting argument structure.",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_6",
  "x": "We evaluate our models on the corpora of<cite> Stab and Gurevych (2016)</cite> and Peldszus (2014) , and compare our results with the results of the aformentioned authors.",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_7",
  "x": "Various authors have also proposed to jointly model link extraction with other subtasks from the argument mining pipeline, using either an Integer Linear Programming (ILP) framework (Persing and Ng, 2016;<cite> Stab and Gurevych, 2016)</cite> or directly feeding previous subtask predictions into a tree-based parser.",
  "y": "background"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_8",
  "x": "We evaluate our models on the corpora of<cite> Stab and Gurevych (2016)</cite> and Peldszus (2014) , and compare our results with the results of the aformentioned authors. Our results show that (1) joint modeling is imperative for competitive performance on the link extraction task, (2) the presence of the second recurrence improves performance over a non-sequence-to-sequence model, and (3) the joint model can outperform models with heavy featureengineering and corpus-specific constraints.",
  "y": "differences"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_9",
  "x": "We follow the work of<cite> Stab and Gurevych (2016)</cite> and focus on three different types of features to represent our ACs: (1) Bag-of-Words of the AC; (2) Embedding representation based on GloVe embeddings (Pennington et al., 2014) , which uses average, max, and min pooling across the token embeddings; (3) Structural features: Whether or not the AC is the first AC in a paragraph, and whether the AC is in an opening, body, or closing paragraph.",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_10",
  "x": "We test the effectiveness of our proposed model on a dataset of persuasive essays (PEC)<cite> (Stab and Gurevych, 2016)</cite> , as well as a dataset of microtexts (MTC) (Peldszus, 2014) .",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_11",
  "x": "We implement and compare four types of neural models: 1) The previously described joint model from In both corpora we compare against the following previously proposed models: Base Classifier <cite>(Stab and Gurevych, 2016</cite> ) is a feature-rich, taskspecific (AC type or link extraction) SVM classifier.",
  "y": "uses"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_12",
  "x": "We implement and compare four types of neural models: 1) The previously described joint model from In both corpora we compare against the following previously proposed models: Base Classifier <cite>(Stab and Gurevych, 2016</cite> ) is a feature-rich, taskspecific (AC type or link extraction) SVM classifier. Neither of these classifiers enforce structural or global constraints.",
  "y": "motivation"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_13",
  "x": "Conversely, the ILP Joint Model<cite> (Stab and Gurevych, 2016)</cite> provides constraints by sharing prediction information between the base classifiers.",
  "y": "background"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_14",
  "x": "The popular method of averaging embeddings (which is used by<cite> Stab and Gurevych (2016)</cite> in their system) is in fact the worst method, although its performance is still competitive with the previous state-of-the-art.",
  "y": "motivation"
 },
 {
  "id": "d576de5c19d7ff62a143b0d4d56135_15",
  "x": "We evaluate our models on two corpora: a corpus of persuasive essays<cite> (Stab and Gurevych, 2016)</cite> , and a corpus of microtexts (Peldszus, 2014) .",
  "y": "uses"
 },
 {
  "id": "d5d81a4c7759f9a4ab81195819c6d9_0",
  "x": "Variants of network structures have been applied in NMT such as LSTM (Wu et al., 2016) , CNN (Gehring et al., 2017) and Transformer<cite> (Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "d5d81a4c7759f9a4ab81195819c6d9_1",
  "x": "\u2020 denotes the result reported in<cite> (Vaswani et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "d5d81a4c7759f9a4ab81195819c6d9_2",
  "x": "The NMT models are generally constructed with up to 6 encoder and decoder blocks in both state-of-the-art research work and champion systems of machine translation competition. For example, the LSTM-based models are usually stacked for 4 (Stahlberg et al., 2018 ) or 6 (Chen et al., 2018 blocks, and the state-of-the-art Transformer models are equipped with a 6-block encoder and decoder<cite> (Vaswani et al., 2017</cite>; JunczysDowmunt, 2018; Edunov et al., 2018) .",
  "y": "background"
 },
 {
  "id": "d5d81a4c7759f9a4ab81195819c6d9_3",
  "x": "We adopt the big transformer configuration following<cite> Vaswani et al. (2017)</cite> , with the dimension of word embeddings, hidden states and non-linear layer set as 1024, 1024 and 4096 respectively.",
  "y": "uses"
 },
 {
  "id": "d5d81a4c7759f9a4ab81195819c6d9_4",
  "x": "Training We use Adam (Kingma and Ba, 2015) optimizer following the optimization settings and default learning rate schedule in<cite> Vaswani et al. (2017)</cite> for model training.",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_0",
  "x": "We present the first application of the head-driven statistical parsing model of <cite>Collins (1999)</cite> as a simultaneous language model and parser for largevocabulary speech recognition.",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_1",
  "x": "<cite>Collins (1999)</cite> presents three lexicalized models which consider long-distance dependencies within a sentence.",
  "y": "background"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_2",
  "x": "We find that the parsing model of <cite>Collins (1999)</cite> can be successfully adapted as a language model for speech recognition.",
  "y": "extends"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_3",
  "x": "Our work is different from Roark (2001) in that we use a bottom-up parsing algorithm with dynamic programming based on the parsing model II of <cite>Collins (1999)</cite> .",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_4",
  "x": "These models use much less conditioning information than the parsing models of <cite>Collins (1999)</cite> , and do not provide Penn Treebank format parse trees as output.",
  "y": "background"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_5",
  "x": "In this section we outline the adaptation of the <cite>Collins (1999)</cite> parsing model to word lattices.",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_6",
  "x": "The parameterization of model II of <cite>Collins (1999)</cite> is used in our word lattice parser.",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_7",
  "x": "One notable difference between the word lattice parser and the original implementation of <cite>Collins (1999)</cite> is the handling of part-of-speech (POS) tagging of unknown words (words seen fewer than 5 times in training).",
  "y": "differences"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_8",
  "x": "<cite>Collins (1999)</cite> falls back to the POS tagging of Ratnaparkhi (1996) for words seen fewer than 5 times in the training corpus.",
  "y": "background"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_9",
  "x": "Edges created by the bottom-up parsing are assigned a score which is the product of the inside and outside probabilities of the <cite>Collins (1999)</cite> model.",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_10",
  "x": "The parameter estimation techniques (smoothing and back-off) of <cite>Collins (1999)</cite> are reimplemented.",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_11",
  "x": "The main technique we employ is a variation of the beam search of <cite>Collins (1999)</cite> to restrict the chart size by excluding low probability edges.",
  "y": "extends"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_12",
  "x": "In practice, these heuristics have a negative effect on parse accuracy, but the amount of pruning can be tuned to balance relative time and space savings against precision and recall degradation<cite> (Collins, 1999)</cite> .",
  "y": "background"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_13",
  "x": "<cite>Collins (1999)</cite> uses a fixed size beam (10 000).",
  "y": "background"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_14",
  "x": "<cite>Collins (1999)</cite> uses a fixed size beam (10 000). We experiment with several variable beam (b) sizes, where the beam is some function of a base beam (b) and the edge width (the number of terminals dominated by an edge).",
  "y": "differences"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_15",
  "x": "Results show scores for parsing strings which are lower than the original implementation of <cite>Collins (1999)</cite> .",
  "y": "differences"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_16",
  "x": "The WER scores for this, the first application of the <cite>Collins (1999)</cite> model to parsing word lattices, are comparable to other recent work in syntactic language modelling, and better than a simple trigram model trained on the same data.",
  "y": "extends"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_17",
  "x": "The scores for our experiments are lower than the scores of the original implementation of model II<cite> (Collins, 1999)</cite> .",
  "y": "differences"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_18",
  "x": "Tag accuracy for our model was 93.2%, whereas for the original implementation of <cite>Collins (1999)</cite> , model II achieved tag accuracy of 96.75%.",
  "y": "differences"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_20",
  "x": "Two different corpora were used in training the parsing model on word lattices: sections<cite> (Collins, 1999)</cite> .",
  "y": "uses"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_21",
  "x": "By contrast,<cite> (Collins, 1999)</cite> calculates parameter values by looking up event counts at run-time.",
  "y": "differences"
 },
 {
  "id": "d636df7cc0eb06323ef159528caf49_22",
  "x": "In this work we present an adaptation of the parsing model of <cite>Collins (1999)</cite> for application to ASR.",
  "y": "extends"
 },
 {
  "id": "d6c8b712c8fe3dd87d23886d575098_0",
  "x": "Out-ofdomain training data can hurt the translation performance on News test sets (Wang et al., 2017) and also significantly increase training time. Therefore, we trained neural language models on a large monolingual News corpus to perform data selection<cite> (Schamper et al., 2018)</cite> .",
  "y": "motivation"
 },
 {
  "id": "d6c8b712c8fe3dd87d23886d575098_1",
  "x": "In-domain Fine-tuning The Transformer models were finally fine-tuned using the small in-domain parallel data provided for the News task (Luong and Manning, 2015; <cite>Schamper et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d6c8b712c8fe3dd87d23886d575098_2",
  "x": "Our final submission is an ensemble of both models<cite> (Schamper et al., 2018)</cite> .",
  "y": "extends"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_0",
  "x": "The hierarchical lexical database approach can be reclassified into three groups according to usages of the database: gloss based method [5] , conceptual density based method [6, 7] and relative based method<cite> [8,</cite> 9, 10] .",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_1",
  "x": "The hierarchical lexical database approach can be reclassified into three groups according to usages of the database: gloss based method [5] , conceptual density based method [6, 7] and relative based method<cite> [8,</cite> 9, 10] . Since our method is a kind of the relative based method, this section describes the related works of the relative based method. <cite>[8]</cite> introduced the relative based method using International Roget's Thesaurus as a hierarchical lexical database.",
  "y": "similarities"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_2",
  "x": "[9] followed the method of <cite>[8]</cite> , but tried to resolve the ambiguous relative problem by using just unambiguous relatives.",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_3",
  "x": "Another difference from <cite>[8]</cite> is on a lexical database: they utilized WordNet as a lexical database for acquiring relatives of target words instead of International Roget's Thesaurus.",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_4",
  "x": "However, the evaluation was conducted on a small part of senses of the target words like <cite>[8]</cite> .",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_5",
  "x": "Like <cite>[8]</cite> , the method also has a difficulty in disambiguating senses of many words because the method collects the example sentences of relatives of many words.",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_6",
  "x": "They built training datum of all noun words in WordNet whose size is larger than 7GB, but evaluated their method on a small number of nouns of lexical sample task of SENSEVAL-2 as <cite>[8]</cite> and [9] .",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_7",
  "x": "Our method makes use of ambiguous relatives as well as unambiguous relatives unlike [9] and hence overcomes the shortage problem of relatives and also reduces the problem of ambiguous relatives in <cite>[8]</cite> by handling relatives separately instead of putting example sentences of the relatives together into a pool.",
  "y": "differences"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_8",
  "x": "However, both of <cite>[8]</cite> and [9] did not evaluate their methods on a publicly available data.",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_9",
  "x": "However, both of <cite>[8]</cite> and [9] did not evaluate their methods on a publicly available data. We implemented their methods and compared our method with them on the same evaluation data.",
  "y": "uses"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_10",
  "x": "WordNet was utilized as a lexical database to acquire relatives of target words and the sense disambiguation modules were implemented by using on Na\u00efve Bayesian classifier, which [9] adopted though <cite>[8]</cite> utilized International Roget's Thesaurus and other classifier similar to decision lists.",
  "y": "uses"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_11",
  "x": "The main difference between <cite>[8]</cite> and [9] is whether ambiguous relatives are utilized or not.",
  "y": "background"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_12",
  "x": "The main difference between <cite>[8]</cite> and [9] is whether ambiguous relatives are utilized or not. Considering the difference, we implemented the method of <cite>[8]</cite> to include the ambiguous relatives into relatives, but the method of [9] to exclude the ambiguous relatives.",
  "y": "uses"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_13",
  "x": "7 In the table, All Relatives and Unambiguous Relatives represent the results of the reimplemented methods of <cite>[8]</cite> and [9] , respectively.",
  "y": "uses"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_14",
  "x": "7 In the table, All Relatives and Unambiguous Relatives represent the results of the reimplemented methods of <cite>[8]</cite> and [9] , respectively. It is observed in the table that our proposed method achieves better performance on all evaluation data than the previous methods though the improvement is not large.",
  "y": "differences"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_15",
  "x": "Hence, we may have an idea that our method handles relatives and in particular ambiguous relatives more effectively than <cite>[8]</cite> and [9] . Compared with [9] , <cite>[8]</cite> obtains a better performance, and the difference between the performance of them are totally more than 15 % on all of the evaluation data.",
  "y": "differences"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_16",
  "x": "When evaluated on the same nouns of the lexical sample task, our proposed method achieved 47.26%, and the method of <cite>[8]</cite> 45.61%, and the method of [9] 38.03%.",
  "y": "differences"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_17",
  "x": "The experimental results show that the proposed method effectively disambiguates many ambiguous words in SemCor and in test data for SENSEVAL all words task, as well as a small number of ambiguous words in test data for SENSEVAL lexical sample task. Also our method more correctly disambiguates senses than <cite>[8]</cite> and [9] .",
  "y": "differences"
 },
 {
  "id": "d6d8f08147e45acc0a61692abb37a9_18",
  "x": "In consequence, our method has two advantages over the previous methods ( <cite>[8]</cite> and [9] ): our method 1) handles the ambiguous relatives and unambiguous relatives more effectively, and 2) utilizes only one co-occurrence matrix for disambiguating all contents words instead of collecting training data of the content words.",
  "y": "differences"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_0",
  "x": "To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk et al., 2005; Liu et al., 2007; Zhang et al., 2007; <cite>Zhang et al., 2008a</cite>; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Bod, 2007) .",
  "y": "motivation background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_1",
  "x": "The basic motivation behind <cite>syntax-based model</cite> is that the syntax information has the potential to model the structure reordering and discontiguous corresponding by the intrinsic structural generalization ability. Although remarkable progresses have been reported, the strict syntactic constraint (the both sides of the rules should strictly be a subtree of the whole syntax parse) greatly hinders the utilization of the non-syntactic translation equivalents.",
  "y": "motivation background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_2",
  "x": "<cite>Zhang et al. (2008a)</cite> made it possible to utilize the non-syntactic rules and even the phrases which are used in phrase based model by advancing a general tree sequence to tree sequence framework based on the tree-to-tree model presented in (Zhang et al., 2007) .",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_3",
  "x": "Figure 2 lists some of the rules which can be extracted from the sentence pair in Figure 1 by the system used in (<cite>Zhang et al., 2008a</cite>) .",
  "y": "uses background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_4",
  "x": "A few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories (Liu et al., 2007; <cite>Zhang et al., 2008a</cite>; DeNeefe et al., 2007) .",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_5",
  "x": "As an extension, <cite>Zhang et al. (2008a)</cite> proposed two more categories: <cite>Structure Reordering Rules</cite> (<cite>SRR</cite>) and <cite>Discontiguous Phrase Rules</cite> (<cite>DPR</cite>).",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_6",
  "x": "The <cite>SRR</cite> stands for the rules which have at least two non-terminal leaf nodes with inverted order in the source and target side.",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_7",
  "x": "And <cite>DPR</cite> refers to the rules having at least one non-terminal leaf node between two terminal leaf nodes.",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_8",
  "x": "Our proposed rule classification is inspired by <cite>these works</cite>.",
  "y": "motivation"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_9",
  "x": "Further, the syntax rules can be divided into three categories according to the lexicalization levels (Liu et al., 2007; <cite>Zhang et al., 2008a</cite> source and target sides are non-lexicons (nonterminals)",
  "y": "uses background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_10",
  "x": "Then, the syntax rules can also fall into two categories according to whether equipping with generalization capability (Chiang, 2007; <cite>Zhang et al., 2008a</cite>) : 1) Initial rules (Initial): all leaf nodes of this rule are terminals.",
  "y": "uses background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_11",
  "x": "<cite>The Structure Reordering Rules</cite> (<cite>SRR</cite>) and <cite>Discontiguous Phrase Rules</cite> (<cite>DPR</cite>) mentioned by (<cite>Zhang et al., 2008a</cite>) can be regarded as more in-depth classification of the syntax rules.",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_12",
  "x": "In (<cite>Zhang et al., 2008a</cite>) , they are described as follows: Definition 1: The <cite>Structure Reordering Rule</cite> (<cite>SRR</cite>) refers to the structure reordering rule that has at least two non-terminal leaf nodes with inverted order in the source and target side.",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_13",
  "x": "Definition 2: The <cite>Discontiguous Phrase Rule</cite> (<cite>DPR</cite>) refers to the rule having at least one nonterminal leaf node between two lexicalized leaf nodes.",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_14",
  "x": "Based on <cite>these descriptions</cite>, R 7 , R 8 in Figure 2 belong to the category of <cite>SRR</cite> and R 6 , R 7 fall into the category of <cite>DPR</cite>.",
  "y": "background"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_15",
  "x": "Although <cite>these two definitions</cite> are easy implemented in practice, we argue that <cite>the definition</cite> of <cite>SRR</cite> is not complete.",
  "y": "motivation"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_16",
  "x": "The definition of <cite>DPR</cite> in (<cite>Zhang et al., 2008a</cite> ) is explicit but somewhat rough and not very accurate.",
  "y": "background motivation"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_17",
  "x": "According to Definition 2, it is a <cite>DPR</cite>. However, obviously it is not a discontiguous phrase actually.",
  "y": "differences"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_18",
  "x": "Given an abstract rule r =< Note that the intersection of <cite>SRR</cite> NT 2 and <cite>SRR</cite> NT-T is not necessary an empty set, i.e. a rule can be both <cite>SRR</cite> NT 2 and <cite>SRR</cite> NT-T rule.",
  "y": "differences"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_19",
  "x": "Through Definition 3, we know that the <cite>DPR</cite> is a sub-set of the <cite>SRR</cite> NT-T.",
  "y": "differences"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_20",
  "x": "In the future works, aiming to analyze the rule contributions and the redundances issues using the presented rule classification based on some real translation systems, we plan to implement some synchronous grammar based syntax translation models such as the one presented in (Liu et al., 2007) or in (<cite>Zhang et al., 2008a</cite>) .",
  "y": "future_work"
 },
 {
  "id": "d70b9838e8a32a8638d7aed0adc80a_21",
  "x": "Taking <cite>such a system</cite> as the experimental platform, we can perform comprehensive statistics about distributions of different rule categories.",
  "y": "future_work"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_0",
  "x": "Word embeddings representation spaces are known to present geometrical phenomena mimicking relations and analogies between words (e.g. man is to woman as king is to queen). Following this property of finding relations or analogies, one popular example of gender bias is the word association between man to computer programmer as woman to homemaker<cite> (Bolukbasi et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_1",
  "x": "Recent progress in word embedding techniques has been achieved with contextualized word embeddings (Peters et al., 2018) which provide different vector representations for the same word in different contexts. While gender bias has been studied, detected and partially addressed for standard word embeddings techniques<cite> (Bolukbasi et al., 2016</cite>; Zhao et al., 2018a; Gonen and Goldberg, 2019) , it is not the case for the latest techniques of contextualized word embeddings.",
  "y": "motivation background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_2",
  "x": "Only just recently, Zhao et al. (2019) present a first analysis on the topic based on the proposed methods in<cite> Bolukbasi et al. (2016)</cite> .",
  "y": "background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_3",
  "x": "Human-generated corpora suffer from social biases. Those biases are reflected in the cooccurrence statistics, and therefore learned into word embeddings trained in those corpora, amplifying them<cite> (Bolukbasi et al., 2016</cite>; Caliskan et al., 2017) .",
  "y": "motivation background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_4",
  "x": [
   "Bolukbasi et al. (2016) studied from a geometrical point of view the presence of gender bias in word embeddings. For this, they compute the subspace where the gender information concentrates by computing the principal components of the difference of vector representations of male and female gender-defining word pairs. With the gender subspace, the authors identify direct and indirect biases in profession words. Finally, they mitigate the bias by nullifying the information in the gender subspace for words that should not be associated to gender, and also equalize their distance to both elements of gender-defining word pairs."
  ],
  "y": "background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_5",
  "x": "Once the embeddings are trained, the gender protected attribute can be simply removed from the vector representation, therefore eliminating any gender bias present in it. The transformations proposed by both<cite> Bolukbasi et al. (2016)</cite> and Zhao et al. (2018b) are downstream task-agnostic. This fact is used in the work of Gonen and Goldberg (2019) to showcase that, while apparently the embedding information is removed, there is still gender information remaining in the vector representations.",
  "y": "motivation background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_6",
  "x": "To address these questions, we adapt and contrast with the evaluation measures proposed by<cite> Bolukbasi et al. (2016)</cite> and Gonen and Goldberg (2019) .",
  "y": "differences"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_7",
  "x": "To perform our analysis we used a set of lists from previous work<cite> (Bolukbasi et al., 2016</cite>; Gonen and Goldberg, 2019) . We refer to the list of definitional pairs 2 as 'Definitonal List' (e.g. shehe, girl-boy). We refer to the list of female and male professions 3 as 'Professional List' (e.g. accountant, surgeon). The 'Biased List' is the list used in the clustering experiment and it consists of biased male and female words (500 female biased tokens and 500 male biased token). This list is generated by taking the most biased words, where the bias of a word is computed by taking its projection on the gender direction ( \u2212 \u2192 he-\u2212\u2192 she) (e.g. breastfeeding, bridal and diet for female and hero, cigar and teammates for male). The 'Extended Biased List' is the list used in classification experiment , which contains 5000 male and female biased tokens, 2500 for each gender, generated in the same way of the Biased List 4 .",
  "y": "uses"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_8",
  "x": "A note to be considered, is that the lists we used in our experiments (and obtained from<cite> Bolukbasi et al. (2016)</cite> and Gonen and Goldberg (2019) ) may contain words that are missing in our corpus and so we can not obtain contextualized embeddings for them.",
  "y": "uses"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_9",
  "x": "In this section, we adapt gender bias measures for word embedding methods from previous work<cite> (Bolukbasi et al., 2016)</cite> and (Gonen and Goldberg, 2019) to be applicable to contextualized word embeddings.",
  "y": "extends"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_10",
  "x": "We compare our results to previous results from debiased and non-debiased word embeddings<cite> (Bolukbasi et al., 2016)</cite> . Bolukbasi et al. (2016) propose to identify gender bias in word representations by computing the direction between representations of male and female word pairs from the Definitional List ( \u2212 \u2192 he-\u2212\u2192 she, \u2212\u2212\u2192 man-\u2212 \u2212\u2212\u2212\u2212 \u2192 woman) and computing their principal components.",
  "y": "background"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_11",
  "x": "Similarly to<cite> Bolukbasi et al. (2016)</cite> , figure 1 shows that the first eigenvalue is significantly larger than the rest and that there is also a single direction describing the majority of variance in these vectors, still the difference between the percentage of variances is less in case of contextualized embeddings, which may refer that there is less bias in such embeddings. We can easily note the difference in the case of random, where there is a smooth and gradual decrease in eigenvalues, and hence the variance percentage.",
  "y": "background similarities"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_12",
  "x": "We applied the definition of direct bias from<cite> Bolukbasi et al. (2016)</cite> on the ELMo representations of the professional words in these sentences. where N is the amount of gender neutral words, g the gender direction, and w the word vector of each profession.",
  "y": "similarities"
 },
 {
  "id": "d70e69bb3eaa6b46ee3b7110126129_13",
  "x": "We got direct bias of 0.03, compared to 0.08 from standard word2vec embeddings described in<cite> Bolukbasi et al. (2016)</cite> . This reduction on the direct bias confirms that the substantial component along the gender direction that is present in standard word embeddings is less for the contextualized word embeddings. Probably, this reduction comes from the fact that we are using different word embeddings for the same profession depending on the sentence which is a direct consequence and advantage of using contextualized embeddings.",
  "y": "differences background"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_0",
  "x": "One promising approach for addressing this problem is to model argument sharing across multiple predicates (Iida et al., 2015; Ouchi et al., 2015;<cite> Ouchi et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_1",
  "x": "Identifying PASs in Japanese text is a long-standing challenge chiefly due to the abundance of omitted (elliptical) arguments. One promising approach for addressing this problem is to model argument sharing across multiple predicates (Iida et al., 2015; Ouchi et al., 2015;<cite> Ouchi et al., 2017)</cite> . However, the relation must be easy to identify for human readers who know that the person who asks a question is likely to be answered; namely, the nominative argument of ask is likely to be shared with the dative argument of answer.",
  "y": "motivation"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_2",
  "x": "More recently, as an end-to-end model considering multi-predicate dependencies, <cite>Ouchi et al. (2017)</cite> used Grid RNN to incorporate intermediate representations of the prediction for one predicate generated by an RNN layer into the inputs of the RNN layer for another predicate.",
  "y": "background"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_3",
  "x": "More recently, as an end-to-end model considering multi-predicate dependencies, <cite>Ouchi et al. (2017)</cite> used Grid RNN to incorporate intermediate representations of the prediction for one predicate generated by an RNN layer into the inputs of the RNN layer for another predicate. However, in this model, since the information of multiple predicates also propagates through the RNNs, the integration of the prediction information is influenced by word order and distance, which is not necessarily important for aspects of syntactic and semantic relations.",
  "y": "motivation"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_4",
  "x": "In this study, we follow the setting of Iida et al. (2015) , <cite>Ouchi et al. (2017)</cite> , and Matsubayashi and Inui (2017) , and focus only on analyzing arguments in a target sentence.",
  "y": "uses"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_5",
  "x": "In addition, we exclude argument instances that are in the same bunsetsu, a base phrase unit in Japanese, as the target predicate, following <cite>Ouchi et al. (2017)</cite> , which we will compare with the results in experiments.",
  "y": "uses"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_6",
  "x": "Our proposed models extend end-to-end style SRL systems using deep bi-RNN (Zhou and Xu, 2015; He et al., 2017;<cite> Ouchi et al., 2017)</cite> to combine mechanisms that consider multiple predicate interactions.",
  "y": "extends uses"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_7",
  "x": "In addition, we use the residual connections (He et al., 2016) following <cite>Ouchi et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_8",
  "x": "In contrast to the Grid RNN model of <cite>Ouchi et al. (2017)</cite> , where the information of multiple predicates propagates through the RNNs, our interaction layers use pooling and attention mechanisms to directly associate the label prediction information for a target (predicate, word) pair with that for words strongly related to the target pair, without being disturbed by word order and distance.",
  "y": "differences"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_9",
  "x": "In order to strictly compare the impact of our extensions to the method used for integrating multiple pieces of predicate information in the state-of-the-art end-to-end model, in addition to our base model, we replicated the method of <cite>Ouchi et al. (2017)</cite> by modifying Equations (1) of our base model as follows:",
  "y": "uses"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_10",
  "x": "The performance of this replicated model may not be strictly the same as that reported in <cite>Ouchi et al. (2017)</cite> due to discrepancies in the embeddings of inputs, hyperparameters (a training batch size, a hidden unit size, etc.), and training strategy (an optimizing algorithm, a regularization method, an early stopping method, etc.).",
  "y": "differences"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_11",
  "x": "Grid RNN of <cite>Ouchi et al. (2017)</cite> is a state-of-the-art end-to-end model, designed to capture interactions among multiple predicate-argument relations.",
  "y": "background"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_12",
  "x": "Unlike the results reported in <cite>Ouchi et al. (2017)</cite> , the GRID model in our experiment did not clearly outperform the model without the grid architecture, i.e., the Base model.",
  "y": "differences"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_13",
  "x": "We first suspected that this might have resulted from the difference in dimensionality d r of RNN hidden states: d r = 32 in <cite>Ouchi et al. (2017)</cite> , whereas d r = 256 in our experiments.",
  "y": "differences"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_14",
  "x": "We thus trained our GRID model with <cite>Ouchi et al. (2017)</cite> 's settings (d r = 32 and K = 8) and the best performing hyperparameters; however, we were not able to reproduce the reported gain from Grid RNN (see the row of \"GRID (d r = 32, K = 8)\" in Table 1 ).",
  "y": "uses differences"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_15",
  "x": "For an end-to-end neural model, <cite>Ouchi et al. (2017)</cite> used a Grid RNN to capture multiple predicate interactions.",
  "y": "background"
 },
 {
  "id": "d76946b009d67613326a8e7650ad36_16",
  "x": "For an end-to-end neural model, <cite>Ouchi et al. (2017)</cite> used a Grid RNN to capture multiple predicate interactions. Through experiments, we demonstrated that our proposed models outperformed these models in terms of the overall F 1 on a standard benchmark corpus.",
  "y": "differences"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_0",
  "x": "In this work we learn clusters of contextual annotations for non-terminals in the Penn Treebank. Perhaps the best way to think about this problem is to contrast our work with that of<cite> Klein and Manning (2003)</cite> . That research used treetransformations to create various grammars with different contextual annotations on the non-terminals. These grammars were then used in conjunction with a CKY parser. The authors explored the space of different annotation combinations by hand. Here we try to automate the process -to learn the \"right\" combination automatically. Our results are not quite as good as those carefully created by hand, but they are close (84.8 vs 85.7).",
  "y": "differences background"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_1",
  "x": "Instead researchers condition parsing decisions on many other features, such as parent phrase-marker, and, famously, the lexical-head of the phrase (Magerman, 1995; Collins, 1996; Collins, 1997; Johnson, 1998; Charniak, 2000; Henderson, 2003;<cite> Klein and Manning, 2003</cite>; Matsuzaki et al., 2005) (and others) .",
  "y": "background"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_2",
  "x": "One particularly perspicuous way to view the use of extra conditioning information is that of tree-transformation (Johnson, 1998;<cite> Klein and Manning, 2003)</cite> . Rather than imagining the parser roaming around the tree for picking up the information it needs, we rather relabel the nodes to directly encode this information.",
  "y": "background differences"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_3",
  "x": "Thus rather than have the parser \"look\" to find out that, say, the parent of some N P is an S, we simply relabel the N P as an N P [S] . This viewpoint is even more compelling if one does not intend to smooth the probabilities. For example, consider p(N P \u2192 P RN | N P [S]) If we have no intention of backing off this probability to p(N P \u2192 P RN | N P ) we can treat N P [S] as an uninterpreted phrasal category and run all of the standard PCFG algorithms without change. The result is a vastly simplified parser. This is exactly what is done by<cite> Klein and Manning (2003)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_4",
  "x": "The<cite> Klein and Manning (2003)</cite> parser is an unlexicalized PCFG with various carefully selected context annotations. Their model uses some parent annotations, and marks nodes which initiate or in certain cases conclude unary productions. They also propose linguistically motivated annotations for several tags, including V P , IN , CC,N P and S. This results in a reasonably accurate unlexicalized PCFG parser. The downside of this approach is that their features are very specific, applying different annotations to different treebank nonterminals. For instance, they mark right-recursive N P s and not V P s (i.e., an N P which is the right-most child of another N P ). This is because data sparsity issues preclude annotating the nodes in the treebank too liberally. The goal of our work is to automate the process a bit, by annotating with more general features that apply broadly, and by learning clus-ters of these annotations.",
  "y": "motivation background differences"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_5",
  "x": "Coming to this problem from the standpoint of tree transformation, we naturally view our work as a descendent of Johnson (1998) and<cite> Klein and Manning (2003)</cite> .",
  "y": "background similarities"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_6",
  "x": "As in (Johnson, 1998) and<cite> (Klein and Manning, 2003)</cite> , we annotate the Penn treebank nonterminals with various context information.",
  "y": "uses"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_7",
  "x": "However,<cite> Klein and Manning (2003)</cite> find that this hurts performance relative to just marking the NPs, and so our Base feature does not insert.",
  "y": "similarities"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_8",
  "x": "Related to this, we further noticed that several of<cite> Klein & Manning's (2003)</cite> features, such as marking N P s as right recursive or possessive have the property of annotating with the label of the rightmost child (when they are NP and POS respectively). We generalize this by marking all nodes both with their rightmost child and (an analogous feature) leftmost child. We also mark whether or not a node borders the end of a sentence, save for ending punctuation. (For instance, in this sentence, all the constituents with the second \"marked\" rightmost in their span would be marked).",
  "y": "extends background"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_9",
  "x": "Another<cite> Klein and Manning (2003)</cite> feature we try includes the temporal NP feature, where TMP markings in the treebank are retained, and propagated down the head inheritance path of the tree. It is worth mentioning that all the features here come directly from the treebank. For instance, the part of speech of the head feature has values only from the raw treebank tag set. When a preterminal cluster is split, this assignment does not change the value of this feature.",
  "y": "uses background"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_10",
  "x": "We perform this in a manner similar to<cite> Klein and Manning (2003)</cite> and Matsuzaki et al. (2005) Our mechanism lays out the unmarkovized intermediate rules in the same way, but we mostly use our clustering scheme to reduce sparsity. We do so by aligning the labels contained in the intermediate nodes in the order in which they would be added when increasing the markovization hori-1 The implementation we use was created by Mark Johnson and used for the research in (Johnson, 1998) .",
  "y": "extends similarities"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_11",
  "x": "We also always keep the heir label as a feature, following<cite> Klein and Manning (2003</cite> (D, F, E, D, \u2212) , where the first item is the heir of the parent's head. The \"-\" indicates that the fourth item to be expanded is here non-existent. The clusterer would consider each of these five features as for a single possible split.",
  "y": "uses background"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_12",
  "x": "In order to ease comparison between our work and that of<cite> Klein and Manning (2003)</cite> , we follow their lead in smoothing no production probabilities save those going from preterminal to nonterminal. Our smoothing mechanism runs roughly along the lines of theirs.",
  "y": "similarities"
 },
 {
  "id": "d785838888358a711fbf07c9dcf430_14",
  "x": "We have presented a scheme for automatically discovering phrasal categories for parsing with a standard CKY parser. The parser achieves 84.8% precision-recall f-measure on the standard testsection of the Penn WSJ-Treebank (section 23). While this is not as accurate as the hand-tailored grammar of<cite> Klein and Manning (2003)</cite> , it is close, and we believe there is room for improvement.",
  "y": "background"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_0",
  "x": "Most recently, several approaches based on cross-lingual entity embeddings (Hao et al., 2016; Chen et al., 2017; Sun, Hu, and Li, 2017) or graph neural networks <cite>Xu et al., 2019</cite>; Wu et al., 2019) have been proposed for this task.",
  "y": "background"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_1",
  "x": "In particular,<cite> Xu et al. (2019)</cite> introduces the topic entity graph to capture the local context information of an entity within the KG, and further tackles this task as a graph matching problem by proposing a graph matching network.",
  "y": "background"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_2",
  "x": "In particular, we analyze the results of<cite> Xu et al. (2019)</cite> and find that nearly 8% of the alignments are many-to-one mappings.",
  "y": "uses"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_3",
  "x": "Different with those methods that still follow previous works that rely on learned entity embeddings to rank alignments,<cite> Xu et al. (2019)</cite> views this task as a graph matching problem and further proposes a graph matching neural network that additionally considers the matching information of an entity's neighborhood to perform the prediction.",
  "y": "background"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_4",
  "x": "We analyze the alignment results of three baseline methods, i.e., Wang et al. (2018) ,<cite> Xu et al. (2019)</cite> and Wu et al. (2019) .",
  "y": "uses"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_5",
  "x": "In this paper, we use the state-of-the-art alignment model<cite> (Xu et al., 2019)</cite> as our baseline method and propose two ways to enhance this model by incorporating easy assignment information.",
  "y": "extends uses"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_6",
  "x": "In contrast to<cite> Xu et al. (2019)</cite> that only takes two topic graphs as input, we can utilize additional information such as easy assignments found in previous decoding steps to resolve hard assignments.",
  "y": "differences"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_7",
  "x": "In particular, we introduce two ways to enhance this baseline model by explicitly integrating the easy assignment information into two layers of<cite> Xu et al. (2019)</cite> :",
  "y": "extends"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_8",
  "x": "As concluded in<cite> Xu et al. (2019)</cite> , the node-level matching layer has a significant impact on the matching performance, since it captures the local entity matching information.",
  "y": "background"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_9",
  "x": "We compare our approach against existing alignment methods: JE (Hao et al., 2016) , MTransE (Chen et al., 2017) , JAPE (Sun, Hu, and Li, 2017) , IPTransE (Zhu et al., 2017) , BootEA (Sun, Hu, and Li, 2017) , GCN , GM<cite> (Xu et al., 2019)</cite> and RDGCN (Wu et al., 2019) .",
  "y": "uses"
 },
 {
  "id": "d7dba136667d6058bf46d6ede3f2ef_10",
  "x": "For the configurations of the alignment model, we use the same settings as<cite> Xu et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_0",
  "x": "We propose unsupervised approaches for morphological segmentation of low-resource polysynthetic languages based on Adaptor Grammars (AG) <cite>(Eskander et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_1",
  "x": "We propose unsupervised approaches for morphological segmentation of low-resource polysynthetic languages based on Adaptor Grammars (AG) <cite>(Eskander et al., 2016)</cite> . We experiment with four languages from the Uto-Aztecan family. Our AG-based approaches outperform other unsupervised approaches and show promise when compared to supervised methods, outperforming them on two of the four languages.",
  "y": "extends"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_2",
  "x": "Adaptor Grammars (AGs) are nonparametric Bayesian models that generalize probabilistic context free grammars (PCFG), and have proven to be successful for unsupervised morphological segmentation, where a PCFG is a morphological grammar that specifies word structure (Johnson, 2008; Sirts and Goldwater, 2013;<cite> Eskander et al., 2016</cite> Eskander et al., , 2018 .",
  "y": "background"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_3",
  "x": "We design several AG learning setups: 1) use the best-on-average AG setup from<cite> Eskander et al. (2016)</cite> ; 2) optimize for language using just the small training vocabulary (unsegmented) and dev vocabulary (segmented) from Kann et al. (2018) ; 3) approximate the effect of having some linguistic knowledge; 4) learn from all languages at once and 5) add additional unsupervised data for NH and WX (Section 3).",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_4",
  "x": "In this paper, we experiment with the grammars and the learning setups proposed by<cite> Eskander et al. (2016)</cite> , which we outline briefly below.",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_5",
  "x": "We use the nine grammars from<cite> Eskander et al. (2016</cite> Eskander et al. ( , 2018 that were designed based on three dimensions: 1) how the grammar models word structure (e.g., prefix-stem-suffix vs. morphemes), 2) the level of abstraction in nonterminals (e.g., compounds, morphemes and submorphemes) and 3) how the output boundaries are specified (see Table 2 for a sample grammars).",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_6",
  "x": "For example, the PrStSu+SM grammar models the Table 2 : Sample grammar setups used by Eskander et al. (2018<cite> Eskander et al. ( , 2016</cite> .",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_7",
  "x": "We consider the three learning settings in <cite>(Eskander et al., 2016)</cite> : Standard, Scholarseeded Knowledge and Cascaded.",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_8",
  "x": "LIMS is the best-on-average AG setup obtained by<cite> Eskander et al. (2016)</cite> when trained on six languages (English, German, Finnish, Estonian, Turkish and Zulu), which is the Cascaded PrStSu+SM configuration. We use this AG setup for each of the four languages.",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_9",
  "x": "LIMS is the best-on-average AG setup obtained by<cite> Eskander et al. (2016)</cite> when trained on six languages (English, German, Finnish, Estonian, Turkish and Zulu), which is the Cascaded PrStSu+SM configuration.",
  "y": "background"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_10",
  "x": "In this experimental setup, we consider all nine grammars from<cite> Eskander et al. (2016)</cite> using both the Standard and the Cascaded approaches and choosing the one that is best for each polysynthetic language by training on the training set and evaluating on the development set.",
  "y": "uses"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_11",
  "x": "To approximate the effect of Scholar-seeded-Knowledge in<cite> Eskander et al. (2016)</cite>, we used the training set to derive affixes and use them as scholar-seeded knowledge added to the grammars (before the learning happens).",
  "y": "similarities"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_12",
  "x": "To approximate the effect of Scholar-seeded-Knowledge in<cite> Eskander et al. (2016)</cite>, we used the training set to derive affixes and use them as scholar-seeded knowledge added to the grammars (before the learning happens). However, since affixes and stems are not distinguished in the training annotations from Kann et al. (2018) , we only consider the first and last morphemes that appear at least five times.",
  "y": "extends"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_13",
  "x": "This is an interesting finding as the Cascaded PrSTSu+SM setup is in fact AG LIM S -the best-on-average AG setup obtained by<cite> Eskander et al. (2016)</cite> Table 4 : Best AG results compared to supervised approaches from Kann et al. (2018) .",
  "y": "background"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_14",
  "x": "The best AG setup learned for each of the four polysynthetic languages (AG BestL ) is the PrStSu+SM grammar using the Cascaded learning setup. This is an interesting finding as the Cascaded PrSTSu+SM setup is in fact AG LIM S -the best-on-average AG setup obtained by<cite> Eskander et al. (2016)</cite> Table 4 : Best AG results compared to supervised approaches from Kann et al. (2018) .",
  "y": "similarities"
 },
 {
  "id": "d8168f4596878807d22ddc7474ffc8_15",
  "x": "We worked with the AG grammars developed by<cite> Eskander et al. (2016</cite> Eskander et al. ( , 2018 for languages that are not polysynthetic.",
  "y": "uses"
 },
 {
  "id": "d883c7bb1e95895cd4f57a8f430e35_0",
  "x": "Part-of-speech (POS) tagging has received a great deal of attention as it is a critical component of most natural language processing systems. In particular, there has been growing interest in both multilingual POS induction ) and cross-lingual POS induction via treebank projection (Yarowsky and Ngai, 2001; Xi and Hwa, 2005; <cite>Das and Petrov, 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "d883c7bb1e95895cd4f57a8f430e35_1",
  "x": "When corpora with common tagsets are unavailable, a standard approach is to manually define a mapping from language and treebank specific fine-grained tagsets to a predefined universal set. This was the approach taken by<cite> Das and Petrov (2011)</cite> to evaluate their cross-lingual POS projection system for six different languages. To facilitate future research and to standardize best-practices, we propose a tagset that consists of twelve universal POS categories.",
  "y": "differences background"
 },
 {
  "id": "d883c7bb1e95895cd4f57a8f430e35_2",
  "x": "Second, we combine the cross-lingual projection part-of-speech taggers of<cite> Das and Petrov (2011)</cite> with the grammar induction system of Naseem et al. (2010) -which requires a universal tagset -to produce a completely unsupervised grammar induction system for multiple languages, that does not require gold POS tags in the target language.",
  "y": "extends differences motivation"
 },
 {
  "id": "d883c7bb1e95895cd4f57a8f430e35_3",
  "x": "In our experiments, we did not make use of refined categories, as the POS tags induced by<cite> Das and Petrov (2011)</cite> were all coarse.",
  "y": "uses"
 },
 {
  "id": "d883c7bb1e95895cd4f57a8f430e35_4",
  "x": "We present results on the same eight IndoEuropean languages as<cite> Das and Petrov (2011)</cite> , so that we can make use of their automatically projected POS tags.",
  "y": "similarities uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_0",
  "x": "VQA Datasets: We conduct our analysis on a total of 459,861 visual questions and 4,598,610 answers coming from today's largest freely-available VQA benchmark <cite>[3]</cite> . The remaining 90,000 VQAs are about abstract scenes that were created with clipart and show 100 types of everyday objects often observed in real images <cite>[3]</cite> .",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_1",
  "x": "More generally, the goal for VQA is to have a single system that can accurately answer any natural language question about an image or video [2] , <cite>[3]</cite> , [4] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_2",
  "x": "Today's status quo is to assume a fixed number of human responses per visual question and so a fixed cost, delay, and potential diversity of answers for every visual question <cite>[3]</cite> , [1] , [5] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_3",
  "x": "Today's status quo is to assume a fixed number of human responses per visual question and so a fixed cost, delay, and potential diversity of answers for every visual question <cite>[3]</cite> , [1] , [5] . We instead propose to dynamically solicit the number of human responses based on each visual question.",
  "y": "differences background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_4",
  "x": "Specifically, researchers in fields as diverse as computer vision <cite>[3]</cite> , computational linguistics [2] , and machine learning [4] rely on large datasets to improve their VQA algorithms.",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_5",
  "x": "Current methods to create these datasets assume a fixed number of human answers per visual question <cite>[3]</cite> , [5] , thereby either compromising on quality by not collecting all plausible answers or cost by collecting additional answers when they are redundant.",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_6",
  "x": "Visual Question Answering Services: Researchers spanning communities as diverse as human computer interaction, machine learning, computational linguistics, and computer vision have proposed a variety of ways to answer questions about images [2] , <cite>[3]</cite> , [1] , [4] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_7",
  "x": "For example, crowd-powered systems aim to supply a prespecified, fixed number of answers per visual question [1] and automated systems return a single answer for every visual question [2] , <cite>[3]</cite> , [4] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_8",
  "x": "We demonstrate the predictive advantage of our system over relying on the uncertainty of a VQA algorithm in its predicted answer <cite>[3]</cite> .",
  "y": "differences"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_9",
  "x": "Other systems ensure a fixed number of answers are collected per visual question <cite>[3]</cite> , [5] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_10",
  "x": "Other systems ensure a fixed number of answers are collected per visual question <cite>[3]</cite> , [5] . Unlike prior work, our goal is to collect answers in a way that is both economical and complete in capturing the diversity of plausible answers for all visual questions.",
  "y": "background differences"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_11",
  "x": "VQA Datasets: We conduct our analysis on a total of 459,861 visual questions and 4,598,610 answers coming from today's largest freely-available VQA benchmark <cite>[3]</cite> .",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_12",
  "x": "The remaining 90,000 VQAs are about abstract scenes that were created with clipart and show 100 types of everyday objects often observed in real images <cite>[3]</cite> .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_13",
  "x": "Towards this aim, visual questions were collected by asking three Amazon Mechanical Turk (AMT) crowd workers to look at a given image and generate a text-based question about it that would \"stump a smart robot\" <cite>[3]</cite> .",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_14",
  "x": "Each answer was collected by showing a worker an image with associated question and asking him/her to respond with \"a brief phrase and not a complete sentence\" <cite>[3]</cite> .",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_15",
  "x": "We pre-process each answer by converting all letters to lower case, converting numbers to digits, and removing punctuation and articles (i.e., \"a\", \"an\", \"the\"), as was done in prior work <cite>[3]</cite> .",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_16",
  "x": "In practice, prior work deems answers as 100% valid using blind trust (i.e., m = 1 person) [22] as well as more conservative answer validation schemes (i.e., m = 3 people) <cite>[3]</cite> .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_17",
  "x": "We establish valid answers by tallying the number of times each unique answer is given and then only accepting answers observed from at least m people, where m is an application-specific parameter to set. In practice, prior work deems answers as 100% valid using blind trust (i.e., m = 1 person) [22] as well as more conservative answer validation schemes (i.e., m = 3 people) <cite>[3]</cite> .",
  "y": "background differences"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_18",
  "x": "We capitalize on today's largest visual question answering dataset <cite>[3]</cite> to evaluate our prediction system, which includes 369,861 visual questions about real images.",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_19",
  "x": "Therefore, we employ as a baseline a related VQA algorithm [25] , <cite>[3]</cite> which produces for a given visual question an answer with a confidence score.",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_20",
  "x": "Therefore, we employ as a baseline a related VQA algorithm [25] , <cite>[3]</cite> which produces for a given visual question an answer with a confidence score. However, it predicts the system's uncertainty in its own answer, whereas we are interested in the humans' collective disagreement on the answer.",
  "y": "uses differences"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_21",
  "x": "Both our proposed classification systems outperform the VQA Algorithm <cite>[3]</cite> baseline; e.g., Ours -RF yields a 12 percentage point improvement with respect to AP.",
  "y": "differences"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_22",
  "x": "Our overall finding that most of the predictive power stems from language-based features parallels feature analysis findings in the automated VQA literature <cite>[3]</cite> , [22] .",
  "y": "similarities"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_23",
  "x": "Today's status quo is to either uniformly collect N answers for every visual question <cite>[3]</cite> or collect multiple answers where the number is determined by external crowdsourcing conditions [1] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_24",
  "x": "Today's status quo is to either uniformly collect N answers for every visual question <cite>[3]</cite> or collect multiple answers where the number is determined by external crowdsourcing conditions [1] . Our system instead spends a human budget by predicting the number of answers to collect Fig. 6 : We propose a novel application of predicting the number of redundant answers to collect from the crowd per visual question to efficiently capture the diversity of all answers for all visual questions.",
  "y": "differences background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_26",
  "x": "Baselines: We compare our approach to the following baselines: VQA Algorithm <cite>[3]</cite> :",
  "y": "uses"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_27",
  "x": "This predictor illustrates the best a user can achieve today with crowd-powered systems [1] , [6] or with current dataset collection methods <cite>[3]</cite> , [5] .",
  "y": "background"
 },
 {
  "id": "d8a9f0578e389f8cbe153783dc47b3_28",
  "x": "Figure 6b also illustrates the advantage of our system over a related VQA algorithm <cite>[3]</cite> for our novel application of costsensitive answer collection from a crowd.",
  "y": "differences"
 },
 {
  "id": "d8c3d04514c0867d78a7603e49ea9b_0",
  "x": "The rest of the corpus was automatically validated synthetic material using general data from Leipzig (Goldhahn et al., 2012 Engine customization The data was cleaned using the Bicleaner tool <cite>(S\u00e1nchez-Cartagena et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d8c3d04514c0867d78a7603e49ea9b_1",
  "x": "Engine customization The data was cleaned using the Bicleaner tool <cite>(S\u00e1nchez-Cartagena et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_0",
  "x": "These methodologies evaluate coherence over the top-N topic words, where N is selected arbitrarily: for Chang et al. (2009) , N = 5, whereas for<cite> Newman et al. (2010)</cite> , Aletras and Stevenson (2013) and Lau et al. (2014) , N = 10.",
  "y": "background"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_1",
  "x": "We also test the PMI methodology<cite> (Newman et al., 2010)</cite> and make the same observation.",
  "y": "uses"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_2",
  "x": "Although there are existing datasets with human-annotated coherence scores<cite> (Newman et al., 2010</cite>; Aletras and Stevenson, 2013; Lau et al., 2014; Chang et al., 2009) , these topics were annotated using a fixed cardinality setting (e.g. 5 or 10).",
  "y": "background"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_3",
  "x": "Although there are existing datasets with human-annotated coherence scores<cite> (Newman et al., 2010</cite>; Aletras and Stevenson, 2013; Lau et al., 2014; Chang et al., 2009) , these topics were annotated using a fixed cardinality setting (e.g. 5 or 10). We thus develop a new dataset for this experiment.",
  "y": "differences"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_4",
  "x": "2 There are two primary approaches to assessing topic coherence: (1) via word intrusion (Chang et (2) by directly measuring observed coherence<cite> (Newman et al., 2010</cite>; Lau et al., 2014) .",
  "y": "background"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_5",
  "x": "2 There are two primary approaches to assessing topic coherence: (1) via word intrusion (Chang et (2) by directly measuring observed coherence<cite> (Newman et al., 2010</cite>; Lau et al., 2014) . As such, we use the second approach as the means for generating our gold standard, asking users to judge topic coherence directly over different topic cardinalities.",
  "y": "uses"
 },
 {
  "id": "d8e3cdea7f61152ed37395c5f9393e_6",
  "x": "3 To collect the coherence judgements, we used Amazon Mechanical Turk and asked Turkers to rate topics in terms of coherence using a 3-point ordinal scale, where 1 indicates incoherent and 3 very coherent<cite> (Newman et al., 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_0",
  "x": "The model relies heavily on an adversarial, unsupervised alignment of word embedding spaces for bilingual dictionary induction (<cite>Conneau et al., 2018</cite>), which we examine here.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_1",
  "x": "Some researchers have even presented unsupervised methods that do not rely on any form of cross-lingual supervision at all (Barone, 2016; <cite>Conneau et al., 2018</cite>; Zhang et al., 2017) .",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_2",
  "x": "Unsupervised approaches to learning crosslingual word embeddings are based on the assumption that monolingual word embedding graphs are approximately isomorphic, that is, after removing a small set of vertices (words) (Mikolov et al., 2013b; Barone, 2016; Zhang et al., 2017; <cite>Conneau et al., 2018</cite>) .",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_3",
  "x": "Contributions We focus on the recent stateof-the-art unsupervised model of <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_4",
  "x": "Our results indicate this assumption is not true in general, and that approaches based on this assumption have important limitations. Contributions We focus on the recent stateof-the-art unsupervised model of <cite>Conneau et al. (2018)</cite> .",
  "y": "motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_5",
  "x": "1 Our contributions are: (a) In \u00a72, we show that the monolingual word embeddings used in <cite>Conneau et al. (2018)</cite> are not approximately isomorphic, using the VF2 algorithm (Cordella et al., 2001 ) and we therefore introduce a metric for quantifying the similarity of word embeddings, based on Laplacian eigenvalues. (b) In \u00a73, we identify circumstances under which the unsupervised <cite>bilingual dictionary induction (BDI)</cite> algorithm proposed in <cite>Conneau et al. (2018)</cite> does not lead to good performance.",
  "y": "motivation uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_6",
  "x": "Our main finding is that the performance of unsupervised <cite>BDI</cite> depends heavily on all three factors: the language pair, the comparability of the monolingual corpora, and the parameters of the word embedding algorithms.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_7",
  "x": "As mentioned, recent work focused on unsupervised <cite>BDI</cite> assumes that monolingual word embedding spaces (or at least the subgraphs formed by the most frequent words) are approximately isomorphic.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_8",
  "x": "As mentioned, recent work focused on unsupervised <cite>BDI</cite> assumes that monolingual word embedding spaces (or at least the subgraphs formed by the most frequent words) are approximately isomorphic. In this section, we show, by investigating the nearest neighbor graphs of word embedding spaces, that word embeddings are far from isomorphic.",
  "y": "differences motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_9",
  "x": "In \u00a74.7, we correlate our similarity metric with performance on unsupervised <cite>BDI</cite>.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_10",
  "x": "If we take the top k most frequent words in English, and the top k most frequent words in German, and build nearest neighbor graphs for English and German using the monolingual word embeddings used in <cite>Conneau et al. (2018)</cite> , the graphs are of course very different.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_11",
  "x": "Eigenvector similarity Since the nearest neighbor graphs are not isomorphic, even for frequent translation pairs in neighboring languages, we want to quantify the potential for unsupervised <cite>BDI</cite> using a metric that captures varying degrees of graph similarity.",
  "y": "motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_12",
  "x": "We discuss the correlation between unsupervised <cite>BDI</cite> performance and approximate isospectrality or eigenvector similarity in \u00a74.7.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_13",
  "x": "Unsupervised neural machine translation relies on <cite>BDI</cite> using cross-lingual embeddings (Lample et al., 2018a; Artetxe et al., 2018) , which in turn relies on the assumption that word embedding graphs are approximately isomorphic.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_14",
  "x": "The work of <cite>Conneau et al. (2018)</cite> , which we focus on here, also makes several implicit assumptions that may or may not be necessary to achieve such isomorphism, and which may or may not scale to low-resource languages. <cite>The algorithms</cite> are not intended to be limited to learning scenarios where these assumptions hold, but since they do in the reported experiments, it is important to see to what extent these assumptions are necessary for <cite>the algorithms</cite> to produce useful embeddings or dictionaries.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_15",
  "x": "We focus on the work of <cite>Conneau et al. (2018)</cite> , who present a fully unsupervised approach to aligning monolingual word embeddings, induced using fastText (Bojanowski et al., 2017) . We describe the <cite>learning algorithm</cite> in \u00a73.2.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_16",
  "x": "<cite>Conneau et al. (2018)</cite> consider a specific set of learning scenarios:",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_17",
  "x": "3 We evaluate <cite>Conneau et al. (2018)</cite> on (English to) Estonian (ET), Finnish (FI), Greek (EL), Hungarian (HU), Polish (PL), and Turkish (TR) in \u00a74.2, to test whether the selection of languages in the original study introduces a bias.",
  "y": "motivation uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_18",
  "x": "We evaluate <cite>Conneau et al. (2018)</cite> on pairs of embeddings induced with different hyper-parameters in \u00a74.4.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_19",
  "x": "We also investigate the sensitivity of unsupervised <cite>BDI</cite> to the dimensionality of the monolingual word embeddings in \u00a74.5.",
  "y": "motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_21",
  "x": "We now introduce the method of <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_22",
  "x": "We now introduce the method of <cite>Conneau et al. (2018)</cite> . 4 <cite>The approach</cite> builds on existing work on learning a mapping between monolingual word embeddings (Mikolov et al., 2013b; Xing et al., 2015) and consists of the following steps: 1) Monolingual word embeddings: An off-the-shelf word embedding algorithm (Bojanowski et al., 2017 ) is used to learn source and target language spaces X and Y .",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_23",
  "x": "In the experiments in <cite>Conneau et al. (2018)</cite> , as well as in ours, the iterative Procrustes refinement improves performance across the board.",
  "y": "similarities"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_24",
  "x": "Using this seed dictionary, we then run the refinement step using <cite>Procrustes analysis</cite> of <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_25",
  "x": "In the following experiments, we investigate the robustness of unsupervised cross-lingual word embedding learning, varying the language pairs, monolingual corpora, hyper-parameters, etc., to obtain a better understanding of when and why unsupervised <cite>BDI</cite> works.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_26",
  "x": "We use bilingual dictionaries compiled by <cite>Conneau et al. (2018)</cite> as gold standard, and adopt <cite>their</cite> evaluation procedure: each test set in each language consists of 1500 gold translation pairs.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_27",
  "x": "Following a standard evaluation practice (Vuli\u0107 and Moens, 2013; Mikolov et al., 2013b; <cite>Conneau et al., 2018</cite>) , we report Precision at 1 scores (P@1): how many times one of the correct translations of a source word w is retrieved as the nearest neighbor of w in the target language.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_28",
  "x": "Our default experimental setup closely follows the setup of <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_29",
  "x": "The third columns lists eigenvector similarities between 10 randomly sampled source language nearest neighbor subgraphs of 10 nodes and the subgraphs of their translations, all from the benchmark dictionaries in <cite>Conneau et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_31",
  "x": "Agglutinative languages with mixed or double marking show more morphological variance with content words, and we speculate whether unsupervised <cite>BDI</cite> is challenged by this kind of morphological complexity.",
  "y": "motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_32",
  "x": "To evaluate this, we experiment with Estonian and Finnish, and we include Greek, Hungarian, Polish, and Turkish to see how their approach fares on combinations of these two morphological traits. The results are quite dramatic. The approach achieves impressive performance for Spanish, one of the languages <cite>Conneau et al. (2018)</cite> include in <cite>their</cite> paper. For the languages we add here, performance is less impressive.",
  "y": "extends motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_34",
  "x": "In general, unsupervised <cite>BDI</cite>, using the approach in <cite>Conneau et al. (2018)</cite> , seems challenged when pairing En-glish with languages that are not isolating and do not have dependent marking.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_35",
  "x": "Monolingual word embeddings used in <cite>Conneau et al. (2018)</cite> are induced from Wikipedia, a nearparallel corpus.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_36",
  "x": "In order to assess the sensitivity of unsupervised <cite>BDI</cite> to the comparability and domain similarity of the monolingual corpora, we replicate the experiments in <cite>Conneau et al. (2018)</cite> using combinations of word embeddings extracted from three different domains: 1) parliamentary proceedings from EuroParl.v7 (Koehn, 2005) , 2) Wikipedia (Al- Rfou et al., 2013) , and 3) the EMEA corpus in the medical domain (Tiedemann, 2009) .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_37",
  "x": "For each pair of monolingual corpora, we compute their domain (dis)similarity by calculating the Jensen-Shannon divergence (El-Gamal, 1991) , based on term distributions. 8 We show the results of unsupervised <cite>BDI</cite> in Figures 2g-i .",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_38",
  "x": "<cite>Conneau et al. (2018)</cite> use the same hyperparameters for inducing embeddings for all languages.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_39",
  "x": "<cite>Conneau et al. (2018)</cite> use the same hyperparameters for inducing embeddings for all languages. This is of course always practically possible, but we are interested in seeing whether <cite>their</cite> approach works on pre-trained embeddings induced with possibly very different hyper-parameters.",
  "y": "motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_41",
  "x": "<cite>BDI</cite> models are evaluated on a held-out set of query words.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_42",
  "x": "<cite>BDI</cite> models are evaluated on a held-out set of query words. Here, we analyze the performance of the unsupervised approach across different parts-ofspeech, frequency bins, and with respect to query words that have orthographically identical counterparts in the target language with the same or a different meaning.",
  "y": "motivation"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_43",
  "x": "Finally, in order to get a better understanding of the limitations of unsupervised <cite>BDI</cite>, we correlate the graph similarity metric described in \u00a72 (right column of Table 2 ) with performance across languages (left column).",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_44",
  "x": "Since we already established that the monolingual word embeddings are far from isomorphic-in contrast with the intuitions motivating previous work (Mikolov et al., 2013b; Barone, 2016; Zhang et al., 2017; <cite>Conneau et al., 2018</cite> )-we would like to establish another diagnostic metric that identifies embedding spaces for which the approach in <cite>Conneau et al. (2018)</cite> is likely to work.",
  "y": "motivation differences"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_46",
  "x": "Cross-lingual word embeddings Cross-lingual word embedding models typically, unlike <cite>Conneau et al. (2018)</cite> , require aligned words, sentences, or documents (Levy et al., 2017) .",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_47",
  "x": "Zhang et al. (2017) , in addition, use different forms of regularization for convergence, while <cite>Conneau et al. (2018)</cite> uses additional steps to refine the induced embedding space.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_48",
  "x": "All unsupervised NMT methods critically rely on accurate unsupervised <cite>BDI</cite> and back-translation.",
  "y": "background"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_49",
  "x": "We investigated when unsupervised <cite>BDI</cite> (<cite>Conneau et al., 2018</cite> ) is possible and found that differences in morphology, domains or word embedding algorithms may challenge this approach.",
  "y": "uses"
 },
 {
  "id": "d91913d0c8e669153e8d477e19aef2_50",
  "x": "Further, we found eigenvector similarity of sampled nearest neighbor subgraphs to be predictive of unsupervised <cite>BDI</cite> performance. We hope that this work will guide further developments in this new and exciting field.",
  "y": "future_work"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_0",
  "x": "These two lines of research converge in prior work to show, e.g., the increasing association of the lexical item 'gay' with the meaning dimension of homosexuality (Kim et al., 2014;<cite> Kulkarni et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_1",
  "x": "It is thus a continuation of prior work, in which we investigated historical English texts only (Hellrich and Hahn, 2016a) , and also influenced by the design decisions of Kim et al. (2014) and <cite>Kulkarni et al. (2015)</cite> which were the first to use word embeddings in diachronic studies.",
  "y": "uses background"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_2",
  "x": "These models must either be trained in a continuous manner where the model for each time span is initialized with its predecessor (Kim et al., 2014; Hellrich and Hahn, 2016b) , or a mapping between models for different points in time must be calculated<cite> (Kulkarni et al., 2015</cite>; Hamilton et al., 2016) .",
  "y": "background"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_3",
  "x": "These models must either be trained in a continuous manner where the model for each time span is initialized with its predecessor (Kim et al., 2014; Hellrich and Hahn, 2016b) , or a mapping between models for different points in time must be calculated<cite> (Kulkarni et al., 2015</cite>; Hamilton et al., 2016) . The first approach cannot be performed in parallel and is thus rather time-consuming, if texts are not subsampled.",
  "y": "motivation"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_4",
  "x": "Following <cite>Kulkarni et al. (2015)</cite> , we trained our models on all 5-grams occurring during five consecutive years for the two time spans, 5 1900-1904 and 2005-2009 ; the number of 5-grams 6 for each time span is listed in Table 1 .",
  "y": "uses"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_5",
  "x": "The averaged cosine values between word embeddings before and after an epoch are used as a convergence measure c (Kim et al., 2014;<cite> Kulkarni et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_6",
  "x": "The convergence criterion proposed by <cite>Kulkarni et al. (2015)</cite> , i.e., c = 0.9999, was never reached (this observation might be explained by Kulkarni et al.'s decision not to reset the learning rate for each training epoch, as was done by us and Kim et al. (2014) ).",
  "y": "differences"
 },
 {
  "id": "d9877fc29c2e4f20805076392a70d0_7",
  "x": "SVD PPMI , which are conceptually not bothered by the reliability problems we discussed here, were not a good fit for the hyperparameters we adopted from <cite>Kulkarni et al. (2015)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "d987872352e4602fd48936cf2fdab8_0",
  "x": "1 It is becoming more challenging since recent conversational interaction systems such as Amazon Alexa, Google Assistant, and Microsoft Cortana support more than thousands of domains developed by external developers [4, 3,<cite> 5]</cite> .",
  "y": "background"
 },
 {
  "id": "d987872352e4602fd48936cf2fdab8_1",
  "x": "Evaluating on an annotated dataset from the user logs of a large-scale conversation interaction system, we show that the proposed approach significantly improves the domain classification especially when hypothesis reranking is used [14,<cite> 5]</cite> .",
  "y": "differences"
 },
 {
  "id": "d987872352e4602fd48936cf2fdab8_2",
  "x": "We take a hypothesis reranking approach, which is widely used in large-scale domain classification for higher scalabil- ity [14,<cite> 5]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "d987872352e4602fd48936cf2fdab8_3",
  "x": "Figure 2 shows the overall architecture of the hypothesis reranker that is similar to<cite> [5]</cite> .",
  "y": "similarities"
 },
 {
  "id": "d987872352e4602fd48936cf2fdab8_4",
  "x": "We set k=3 in our experiments following<cite> [5]</cite> .",
  "y": "similarities"
 },
 {
  "id": "d987872352e4602fd48936cf2fdab8_5",
  "x": "We utilize utterances with explicit invocation patterns from an intelligent conversational system for the model training similarly to<cite> [5]</cite> and [18] .",
  "y": "uses"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_0",
  "x": "It has been done for constituency parsing for example by Collins (1999) but also for dependency parsing for example by <cite>Nilsson et al. (2007)</cite> .",
  "y": "background"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_1",
  "x": "<cite>Nilsson et al. (2007)</cite> modified the representation of several constructions in several languages and obtained a consistent improvement in parsing accuracy.",
  "y": "background"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_2",
  "x": "In this paper, we will investigate the case of the verb group construction and attempt to reproduce the study by <cite>Nilsson et al. (2007)</cite> on UD treebanks to find out whether or not the alternative representation is useful for parsing with UD.",
  "y": "uses"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_3",
  "x": "<cite>Nilsson et al. (2007)</cite> have shown that these same modifications as well as the modification of nonprojective structures helps parsing in four languages.",
  "y": "background"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_5",
  "x": "<cite>Nilsson et al. (2007)</cite> show that making the auxiliary the head of the dependency as in Figure 2 is useful for parsing Czech and Slovenian.",
  "y": "background"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_6",
  "x": "We will follow the methodology from <cite>Nilsson et al. (2007)</cite> , that is, to transform, parse and then detransform the data so as to compare the original and the transformed model on the original gold standard.",
  "y": "uses"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_7",
  "x": "For comparability with the study in <cite>Nilsson et al. (2007)</cite> , and because we used a slightly modified version of their algorithm, we also tested the approach on the versions of the Czech and Slovenian treebanks that they worked on, respectively version 1.0 of the PDT (Hajic et al., 2001 ) and the 2006 version of SDT (Deroski et al., 2006) .",
  "y": "uses differences"
 },
 {
  "id": "d9c0e641f8ceb61e5d6e416bfc6492_8",
  "x": "In this paper, we have attempted to reproduce a study by <cite>Nilsson et al. (2007)</cite> that has shown that making auxiliaries heads in verb groups improves parsing but failed to show that those results port to parsing with Universal Dependencies.",
  "y": "uses background"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_0",
  "x": "Our approach was to build up on the system of the last year's winning approach by NRC Canada 2013 <cite>(Mohammad et al., 2013)</cite> , with some modifications and additions of features, and additional sentiment lexicons. Furthermore, we used a sparse ( 1 -regularized) SVM, instead of the more commonly used 2 -regularization, resulting in a very sparse linear classifier.",
  "y": "extends"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_1",
  "x": "Our approach was to build up on the system of the last year's winning approach by NRC Canada 2013 <cite>(Mohammad et al., 2013)</cite> , with some modifications and additions of features, and additional sentiment lexicons.",
  "y": "extends uses"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_2",
  "x": "Compared to the previous NRC Canada 2013 approach <cite>(Mohammad et al., 2013)</cite> , our main changes are the following three: First we use sparse linear classifiers instead of classical dense ones.",
  "y": "extends"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_3",
  "x": "We tried to reproduce the same classifier as in <cite>(Mohammad et al., 2013)</cite> as a baseline for comparison.",
  "y": "uses"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_4",
  "x": "Unfortunately our replica system of<cite> Mohammad et al. (2013)</cite> only achieved an F1-score of 63.25 on the Twitter-2013 test set, while their score in the 2013 competition on the same test set was 69.02, nearly 6 points higher in F1.",
  "y": "differences"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_5",
  "x": "For each lexicon, the 4 scores were the same as in <cite>(Mohammad et al., 2013)</cite> , i.e. per tweet, we use the number of tokens appearing in the lexicon, the sum and the max of the scores, and the last non-zero score.",
  "y": "similarities"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_6",
  "x": "All text was transformed to lowercase (except for those features in <cite>(Mohammad et al., 2013)</cite> which use case information).",
  "y": "uses"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_7",
  "x": "We used the same set of lexicons as in <cite>(Mohammad et al., 2013)</cite> , with one addition:",
  "y": "extends uses"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_8",
  "x": "To construct the lexicon, we extracted the POS n-grams (as we described in Section 3.1.1 above) from all texts. In comparison,<cite> Mohammad et al. (2013)</cite> used noncontiguous n-grams (unigram-unigram, unigrambigram, and bigram-bigram pairs) . We only used POS n-grams with 2 tokens kept original, and the remaining ones replaced by their POS tag, with n ranging from 3 to 6.",
  "y": "differences"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_9",
  "x": "While in <cite>(Mohammad et al., 2013)</cite> , the score for each n-gram was computed using point-wise mutual information (PMI) with the labels, we trained a linear classifier on the same labels instead.",
  "y": "differences"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_10",
  "x": "We used the same 3 existing sentiment lexicons as in <cite>(Mohammad et al., 2013)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_11",
  "x": "The NRC hashtag sentiment lexicon was generated automatically from a set of 775k tweets containing a hashtag of a small predefined list of positive and negative hashtags <cite>(Mohammad et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "da2429450c8d1f1f3e72383c86ec73_12",
  "x": "Our system is built up on the approach of NRC Canada <cite>(Mohammad et al., 2013)</cite> , with several modifications and extensions (e.g. sparse linear classifiers,",
  "y": "extends uses"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_0",
  "x": "The other attempt of same 6 way PIBOSO classification on the same dataset is presented by <cite>(Verbeke et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_1",
  "x": "The other attempt of same 6 way PIBOSO classification on the same dataset is presented by <cite>(Verbeke et al., 2012)</cite> . Unlike us and Kim et al. (2011) they have used SVM-HMM 2 for learning.",
  "y": "differences"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_2",
  "x": "Please note that the way we categorised an abstract as structured or unstructured might be a bit different from previous approaches by Kim et al. (2011) and<cite> Verbeke et al. 2012</cite> .",
  "y": "differences"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_3",
  "x": "Using sentence ordering labels for unstructured abstracts is the main difference compared to earlier methods (Kim et al., 2011;<cite> Verbeke et al., 2012)</cite> .",
  "y": "differences"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_4",
  "x": "However, we compare our results with (Kim et al., 2011) and <cite>(Verbeke et al., 2012)</cite> using the microaveraged F-scores as in Table 3 .",
  "y": "uses"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_5",
  "x": "However, we compare our results with (Kim et al., 2011) and <cite>(Verbeke et al., 2012)</cite> using the microaveraged F-scores as in Table 3 . Our system outperformed previous works in unstructured abstracts (22% higher than state-of-the-art).",
  "y": "differences"
 },
 {
  "id": "db1fd6f10a3ee22e22093d50395217_6",
  "x": "Our system outperformed earlier existing state-of-art systems (Kim et al., 2011;<cite> Verbeke et al., 2012)</cite> .",
  "y": "differences"
 },
 {
  "id": "db6794da83b12336ab946e5777346d_0",
  "x": "The title of our talk-an implicit reference to the English clich\u00e9 like a spider weaving her webintends to attract one's attention to the metaphor that can be drawn between the dance of a spider weaving her web and a new lexicographic gesture that is gradually emerging from the work on Net-like lexical resources (Fellbaum, 1998; Baker et al., 2003;<cite> Gader et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "db6794da83b12336ab946e5777346d_1",
  "x": "The title of our talk-an implicit reference to the English clich\u00e9 like a spider weaving her webintends to attract one's attention to the metaphor that can be drawn between the dance of a spider weaving her web and a new lexicographic gesture that is gradually emerging from the work on Net-like lexical resources (Fellbaum, 1998; Baker et al., 2003;<cite> Gader et al., 2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "db6794da83b12336ab946e5777346d_2",
  "x": "Work performed on the French Lexical Network <cite>(Gader et al., 2012</cite> ) will serve to demonstrate how the lexicographic process can be made closer to actual navigation through lexical knowledge by the speaker.",
  "y": "future_work"
 },
 {
  "id": "db6794da83b12336ab946e5777346d_3",
  "x": "Computational aspects of the work on the French Lexical Network are dealt with in<cite> (Gader et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_0",
  "x": "Understanding the temporal information in natural language text is an important NLP task (Verhagen et al., 2007 (Verhagen et al., , 2010 UzZaman et al., 2013; Minard et al., 2015; Bethard et al., 2016 Bethard et al., , 2017 . A crucial component is temporal relation (TempRel; e.g., before or after) extraction (Mani et al., 2006; Bethard et al., 2007; Do et al., 2012; Mirza and Tonelli, 2016; <cite>Ning et al., 2017</cite> Ning et al., , 2018a .",
  "y": "background"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_1",
  "x": "Annotators in this setup usually focus only on salient relations but overlook some others. It has been reported that many event pairs in TimeBank should have been annotated with a specific TempRel but the annotators failed to look at them (Chambers, 2013;<cite> Ning et al., 2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_2",
  "x": "It has been reported that many event pairs in TimeBank should have been annotated with a specific TempRel but the annotators failed to look at them (Chambers, 2013;<cite> Ning et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_3",
  "x": "Two recent TempRel extraction systems (Mirza and Tonelli, 2016; <cite>Ning et al., 2017</cite> ) also reported their performances on TB-Dense (F) and on TempEval-3 (P) separately. However, there are no existing systems that jointly train on both.",
  "y": "motivation"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_4",
  "x": "Two recent TempRel extraction systems (Mirza and Tonelli, 2016; <cite>Ning et al., 2017</cite> ) also reported their performances on TB-Dense (F) and on TempEval-3 (P) separately.",
  "y": "background"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_5",
  "x": "Note that Algorithm 1 is only for the learning step of TempRel extraction; as for the inference step of this task, we consistently adopt the standard method by solving Eq. (1), as was done by (Bramsen et al., 2006; Chambers and Jurafsky, 2008; Denis and Muller, 2011; Do et al., 2012;<cite> Ning et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_6",
  "x": "Then the ILP objective is formulated a\u015d where {r m 3 } is selected based on the general transitivity proposed in<cite> (Ning et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_7",
  "x": "A standard way to perform global inference is to formulate it as an Integer Linear Programming (ILP) problem (Roth and Yih, 2004 ) and enforce transitivity rules as constraints. Then the ILP objective is formulated a\u015d where {r m 3 } is selected based on the general transitivity proposed in<cite> (Ning et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_8",
  "x": "We believe that global inference makes better use of the information provided by P; in fact, as we show in Sec. 4, it does perform better than local inference. A standard way to perform global inference is to formulate it as an Integer Linear Programming (ILP) problem (Roth and Yih, 2004 ) and enforce transitivity rules as constraints. Then the ILP objective is formulated a\u015d where {r m 3 } is selected based on the general transitivity proposed in<cite> (Ning et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_9",
  "x": "Results are shown in Table 2 , where all systems were compared in terms of their performances on \"same sentence\" edges (both nodes are from the same sentence), \"nearby sentence\" edges, all edges, and the temporal awareness metric used by the TempEval3 workshop. The first part of Table 2 (Systems 1-5) refers to the baseline method proposed at the beginning of Sec. 3, i.e., simply treating P as F and training on their union. The second part (Systems 6-7) serves as an ablation study showing the effect of bootstrapping only. While System 7 can be regarded as a reproduction of<cite> Ning et al. (2017)</cite> , the original paper of<cite> Ning et al. (2017)</cite> achieved an overall score of P=43.0, R=46.4, F=44.7 and an awareness score of P=42.6, R=44.0, and F=43.3, and the proposed System 9 is also better than<cite> Ning et al. (2017)</cite> on all metrics.",
  "y": "differences"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_10",
  "x": "While incorporating transitivity constraints in inference is widely used,<cite> Ning et al. (2017)</cite> proposed to incorporate these constraints in the learning phase as well.",
  "y": "background"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_11",
  "x": "One of the algorithms proposed in<cite> Ning et al. (2017)</cite> is based on Chang et al. (2012) 's constraint-driven learning (CoDL), which is the same as our intermediate System 7 in Table 2 ; the fact that System 7 is better than System 1 can thus be considered as a reproduction of<cite> Ning et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_12",
  "x": "Despite the technical similarity, this work is motivated differently and is set to achieve a different goal:<cite> Ning et al. (2017)</cite> tried to enforce the transitivity structure, while the current work attempts to use imperfect signals (e.g., partially annotated) taken from additional data, and learn in the incidental supervision framework.",
  "y": "similarities differences"
 },
 {
  "id": "dc6d4eb1870ed5b0bbcbbf6686e5be_13",
  "x": "System 7 can also be considered as a reproduction of<cite> Ning et al. (2017)</cite> (see the discussion in Sec. 5 for details).",
  "y": "uses"
 },
 {
  "id": "dcc866dcfb5f9233170d633d052e8b_0",
  "x": "The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; <cite>Chiang, 2007</cite>; Zhang et al., 2008) .",
  "y": "background"
 },
 {
  "id": "dcc866dcfb5f9233170d633d052e8b_1",
  "x": "For instance, in our investigations for SMT (Section 3.1), the Formally SCFG based hierarchical phrase-based model (hereinafter FSCFG)<cite> (Chiang, 2007)</cite> has a better generalization capability than a Linguistically motivated STSSG based model (hereinafter LSTSSG) (Zhang et al., 2008) , with 5% rules of the former matched by NIST05 test set while only 3.5% rules of the latter matched by the same test set.",
  "y": "uses background"
 },
 {
  "id": "dcc866dcfb5f9233170d633d052e8b_2",
  "x": "The rule extraction in current implementation can be considered as a combination of the ones in<cite> (Chiang, 2007)</cite> and (Zhang et al., 2008) .",
  "y": "uses"
 },
 {
  "id": "dcc866dcfb5f9233170d633d052e8b_3",
  "x": "For example,<cite> (Chiang, 2007)</cite> adopts a CKY style span-based decoding while (Liu et al., 2006 ) applies a linguistically syntax node based bottom-up decoding, which are difficult to integrate.",
  "y": "background"
 },
 {
  "id": "dcc866dcfb5f9233170d633d052e8b_4",
  "x": "FSCFG An in-house implementation of purely formally SCFG based model similar to<cite> (Chiang, 2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_0",
  "x": "Our contributions are summarized as follows: (1) we extend a probablistic model used in the <cite>previous work</cite> which concurrently performs word reordering and dependency parsing; (2) we conducted an evaluation experiment using our semi-automatically constructed evaluation data so that sentences in the data are more likely to be spontaneously written by natives than the automatically constructed evaluation data in the <cite>previous work</cite>.",
  "y": "extends"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_1",
  "x": "To solve the problem, we previously proposed a method for concurrently performing word reordering and dependency parsing and confirmed the effectiveness of their proposed method using evaluation data created by randomly changing the word order in newspaper article sentences <cite>(Yoshida et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_2",
  "x": "This paper proposes a new method on Japanese word reordering based on concurrent execution with dependency parsing by extending the probablistic model proposed by <cite>Yoshida et al. (2014)</cite> , and describes an evaluation experiment using our 1 Bunsetsu is a linguistic unit in Japanese that roughly corresponds to a basic phrase in English.",
  "y": "extends"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_3",
  "x": "We use the same search algorithm as one proposed by <cite>Yoshida et al. (2014)</cite> , which can efficiently find the approximate solution from a huge number of candidates of the pattern by extending CYK algorithm used in conventional dependency parsing.",
  "y": "uses"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_4",
  "x": "In this paper, we refine the probabilistic model proposed by <cite>Yoshida et al. (2014)</cite> to improve the accuracy.",
  "y": "extends"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_5",
  "x": "The structure S is defined as a tuple S = \u27e8O, D\u27e9 where In the probablistic model proposed by <cite>Yoshida et al. (2014)</cite> , P (S|B) was calculated as follows:",
  "y": "uses"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_6",
  "x": "We extend <cite>the above model</cite> and calculate P (S|B) as follows:",
  "y": "extends"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_7",
  "x": "Therefore, we mix Formulas (3) and (4) by adjusting the weight \u03b1 depending on the adequacy of word order in an input sentence, instead of using the constant 0.5 in the previous model proposed by <cite>Yoshida et al. (2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_8",
  "x": "Each factor in Formula (2) is estimated by the maximum entropy method in the same approximation procedure as that of <cite>Yoshida et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_9",
  "x": "Therefore, <cite>our previous work</cite> (<cite>Yoshida et al., 2014</cite>) artificially generated sentences which were not easy to read, by just automatically changing the word order of newspaper article sentences in Kyoto Text Corpus 3 based on the dependency structure.",
  "y": "background"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_10",
  "x": "Therefore, <cite>our previous work</cite> (<cite>Yoshida et al., 2014</cite>) artificially generated sentences which were not easy to read, by just automatically changing the word order of newspaper article sentences in Kyoto Text Corpus 3 based on the dependency structure. However, just automatically changing the word order may create sentences which are unlikely to be written by a native.",
  "y": "motivation"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_11",
  "x": "That is, if a subject judges that a sentence generated by automatically changing the word order in the same way as <cite>the previous work</cite> (<cite>Yoshida et al., 2014</cite> ) may have spontaneously written by a native.",
  "y": "background"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_12",
  "x": "We compared our method to <cite>Yoshida</cite>'s method (<cite>Yoshida et al., 2014</cite>) and two conventional sequential methods.",
  "y": "uses"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_13",
  "x": "All of the methods used the same training features as those described in <cite>Yoshida et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_14",
  "x": "The dependency accuracy of our method was significantly lower than that of the two sequential methods, and was higher than that of <cite>Yoshida's method</cite> although there was no significant difference.",
  "y": "differences"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_15",
  "x": "On the other hand, the sentence accuracy of our method was highest among <cite>all the methods</cite> although there were no significant differences in them.",
  "y": "differences"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_16",
  "x": "As a result of analysis, especially, our method and <cite>Yoshida's method</cite> tended to improve the sentence accuracy very well in case of short sentences.",
  "y": "similarities"
 },
 {
  "id": "ddd23a034c366b62b53d15128edd45_17",
  "x": "Especially, we extended the probablistic model proposed by <cite>Yoshida et al. (2014)</cite> to deal with sentences spontaneously written by a native.",
  "y": "extends"
 },
 {
  "id": "debdaa202ebd856991e09e5e00a12b_0",
  "x": "This architecture has been empirically shown to perform well at Named Entity Recognition (NER) tasks <cite>(Lample et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "debdaa202ebd856991e09e5e00a12b_1",
  "x": "In the Named Entity Recognition task, we utilized a deep learning approach, given the demonstrated effectiveness of such an architecture in this domain <cite>(Lample et al., 2016)</cite> .",
  "y": "uses motivation"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_0",
  "x": "The basic structure of our CKB completion model is similar to that of<cite> Li et al. (2016b)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_1",
  "x": "The basic structure of our CKB completion model is similar to that of<cite> Li et al. (2016b)</cite> . The main difference between ours and theirs is that our method learns the CKB completion and generation tasks jointly.",
  "y": "differences"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_2",
  "x": "Previous model<cite> Li et al. (2016b)</cite> defined a CKB completion model that estimates a confidence score of an arbitrary triple \u27e8t 1 , r, t 2 \u27e9. They used a simple neural network model to formulate score(t 1 , r, t 2 ) \u2208 R.",
  "y": "background"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_3",
  "x": [
   "Our model Our CKB completion model is based on Li et al.'s (2016b) ."
  ],
  "y": "extends"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_4",
  "x": [
   "Li et al. (2016b) formulate the phrase embedding by using attention pooling of LSTM and a bilinear function."
  ],
  "y": "background"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_5",
  "x": "For the experiments with English, we used the ConceptNet 100K data released by<cite> Li et al. (2016b)</cite> 1 .",
  "y": "uses"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_7",
  "x": "CKB completion As baselines, we used the DNN AVG and DNN LSTM models<cite> (Li et al., 2016b</cite> ) that were described in Section 3.1.",
  "y": "uses"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_8",
  "x": "The threshold was determined by using the validation1 data to maximize the accuracy of binary classification for each method, as in<cite> (Li et al., 2016b)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_9",
  "x": "The bottom two lines show the best performances reported in<cite> (Li et al., 2016b)</cite> . The results indicate that our method improved the accuracy of CKB completion compared with the previous method.",
  "y": "differences"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_11",
  "x": "In Wiki gen, we used triples extracted by using the POS tag sequence pattern for each relation according to<cite> Li et al. (2016b)</cite> and scored each triple with CKB completion scores.",
  "y": "uses"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_12",
  "x": "This tendency is similar to the results reported in Li et al.<cite> (Li et al., 2016b)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_13",
  "x": "In particular,<cite> Li et al. (2016b)</cite> and Socher et al. (2013) proposed a simple KBC model for CKB.",
  "y": "background"
 },
 {
  "id": "e0b72115e1905226d22876e72aa304_14",
  "x": "The formulations of CKB completion in the two studies are the same, and we evaluated<cite> Li et al. (2016b)</cite> 's method as a baseline.",
  "y": "uses"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_0",
  "x": "Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and<cite> Sokolov et al. (2013)</cite> .",
  "y": "background"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_1",
  "x": "Our approach extends the work of<cite> Sokolov et al. (2013)</cite> by presenting an alternative learningto-rank approach that can be used for supervised model combination to integrate dense and sparse features, and by evaluating both approaches on cross-lingual retrieval for patents and Wikipedia.",
  "y": "extends differences"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_2",
  "x": "The algorithm of<cite> Sokolov et al. (2013)</cite> combines batch boosting with bagging over a number of independently drawn bootstrap data samples from R. In each step, the single word pair feature is selected that provides the largest decrease of L exp .",
  "y": "background"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_3",
  "x": "The baseline consensus-based voting Borda Count procedure endows each voter with a fixed amount of voting points which he is free to distribute among the scored documents (Aslam and Montague, 2001; <cite>Sokolov et al., 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_4",
  "x": "We use BoostCLIR 1 , a Japanese-English (JP-EN) corpus of patent abstracts from the MAREC and NTCIR data<cite> (Sokolov et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_5",
  "x": "A JP-EN system was trained on data described and preprocessed by<cite> Sokolov et al. (2013)</cite> , consisting of 1.8M parallel sentences from the NTCIR-7 JP-EN PatentMT subtask (Fujii et al., 2008) and 2k parallel sentences for parameter development from the NTCIR-8 test collection.",
  "y": "uses"
 },
 {
  "id": "e0e21b4e473ad6fde28378b2dc4f34_6",
  "x": "PSQ on patents reuses settings found by<cite> Sokolov et al. (2013)</cite> ; settings for Wikipedia were adjusted on its dev set (n=1000, \u03bb=0.4, L=0, C=1).",
  "y": "uses"
 },
 {
  "id": "e177758a227506bbf9de48f8f35715_0",
  "x": "The second step is to perform dictionary induction by learning a linear projection, in the form of a matrix, between language vector spaces <cite>(Mikolov et al., 2013b</cite>; Lazaridou et al., 2015) .",
  "y": "background"
 },
 {
  "id": "e177758a227506bbf9de48f8f35715_1",
  "x": "It is one of the most competitive methods for generating word vector representations, as demonstrated by results on a various semantic tasks (Baroni et al., 2014;<cite> Mikolov et al., 2013b)</cite> .",
  "y": "background"
 },
 {
  "id": "e177758a227506bbf9de48f8f35715_2",
  "x": "To induce a bilingual dictionary for a pair of languages, we use the projection matrix approach <cite>(Mikolov et al., 2013b</cite>; Lazaridou et al., 2015) .",
  "y": "uses"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_0",
  "x": "This paper proposes an extension of Sumida and Torisawa's method of acquiring hyponymy relations from hierachical layouts in Wikipedia<cite> (Sumida and Torisawa, 2008)</cite> .",
  "y": "extends"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_1",
  "x": "We extract hyponymy relation candidates (HRCs) from the hierachical layouts in Wikipedia by regarding all subordinate items of an item x in the hierachical layouts as x's hyponym candidates, while <cite>Sumida and Torisawa (2008)</cite> extracted only direct subordinate items of an item x as x's hyponym candidates.",
  "y": "differences"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_2",
  "x": "Many NLP researchers have attempted to automatically acquire hyponymy relations from texts (Hearst, 1992; Caraballo, 1999; Mann, 2002; Fleischman et al., 2003; Morin and Jacquemin, 2004; Shinzato and Torisawa, 2004; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Sumida et al., 2006;<cite> Sumida and Torisawa, 2008)</cite> .",
  "y": "background"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_3",
  "x": "On the other hand, <cite>Sumida and Torisawa (2008)</cite> have shown that you could easily obtain numerous hyponymy relations from Wikipedia; in particular, they have acquired more than 0.63 million hyponymy relations only from hierarchical layouts in the 2.2GB Japanese version of Wikipedia (e.g., Figure 1 shows a hierarchical structure of a Wikipedia article shown in Figure 2) .",
  "y": "background"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_4",
  "x": "Although the above studies extracted hyponymy relations from the English version of Wikipedia, <cite>Sumida and Torisawa (2008)</cite> extracted hyponymy relations from definition sentences, category labels, and hierarchical structures in Wikipedia articles.",
  "y": "background"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_5",
  "x": "Although the above studies extracted hyponymy relations from the English version of Wikipedia, <cite>Sumida and Torisawa (2008)</cite> extracted hyponymy relations from definition sentences, category labels, and hierarchical structures in Wikipedia articles. We thus focus on the hierarchical structures to acquire more hyponymy relations.",
  "y": "uses"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_6",
  "x": "Our method of acquiring hyponymy relations is an extension of the supervised method proposed by <cite>Sumida and Torisawa (2008)</cite> , but differs in the way of enumerating hyponymy relation candidates (hereafter, HRCs) from the hierarchical layouts, and in the features of machine learning.",
  "y": "extends differences"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_7",
  "x": "We obtain HRCs by considering the title of each marked-up item as a hypernym candidate, and titles of its all subordinate marked-up items as its hyponym candidates; for example, we extract 'England', 'France', 'Wedgwood', 'Lipton', and 'Fauchon' as hyponym candidates of 'Common tea brands' from the hierarchical structure in Figure 1 . Note that <cite>Sumida and Torisawa (2008)</cite> extracted HRCs by regarding the title of each marked-up item as a hypernym candidate and titles of its direct subordinate marked-up items as its hyponyms; for example, they extracted only 'England' and 'France' as hyponym candidates of 'Common tea brands' from the hierarchical structure in Figure 1 .",
  "y": "differences"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_8",
  "x": "In what follows, we briefly review the features proposed by <cite>Sumida and Torisawa (2008)</cite> , and then explain the novel features introduced in this study.",
  "y": "uses"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_9",
  "x": "We expect that the readers will refer to the literature<cite> (Sumida and Torisawa, 2008)</cite> to see the effect of the features proposed by Sumida and Torisawa.",
  "y": "background"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_10",
  "x": "ATTR Using the attribute set created by <cite>Sumida and Torisawa (2008)</cite> , when a hypernym/hyponym is included as an element of the attribute set, we set a feature corresponding to the element to 1.",
  "y": "uses"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_11",
  "x": "This reflects Sumida and Torisawa's observation that HRCs whose hypernym matches the patterns are likely to be correct<cite> (Sumida and Torisawa, 2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_12",
  "x": "The row titled 'S & T (2008) ' shows the performance of the method proposed by <cite>Sumida and Torisawa (2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "e264c45391853fb008c838aa7ccca8_13",
  "x": "We successfully obtained more than 1.73 million hyponymy relations with 85.2% precision, which greatly outperformed the results of <cite>Sumida and Torisawa (2008)</cite> in terms of both the precision and the number of acquired hyponymy relations.",
  "y": "differences"
 },
 {
  "id": "e29c7551ea78cb425054963489e1b9_0",
  "x": "<cite>Salesky et al. (2018)</cite> introduced a set of fluent references 1 for Fisher Spanish-English, enabling a new task: end-to-end training and evaluation against fluent references.",
  "y": "background"
 },
 {
  "id": "e29c7551ea78cb425054963489e1b9_1",
  "x": "Further, corpora can have different translation and annotation schemes: for example for Fisher Spanish-English, translated using Mechanical Turk, <cite>Salesky et al. (2018)</cite> found 268 unique filler words due to spelling and casing.",
  "y": "background"
 },
 {
  "id": "e29c7551ea78cb425054963489e1b9_2",
  "x": "For our experiments, we use Fisher Spanish speech (Graff et al.) and with two sets of English translations<cite> (Salesky et al., 2018</cite>; Post et al., 2013) .",
  "y": "uses"
 },
 {
  "id": "e29c7551ea78cb425054963489e1b9_3",
  "x": "<cite>Salesky et al. (2018)</cite> introduced a new set of fluent reference translations collected on Mechanical Turk.",
  "y": "background"
 },
 {
  "id": "e29c7551ea78cb425054963489e1b9_4",
  "x": "Using clean references for disfluent data collected by <cite>Salesky et al. (2018)</cite> , we extend their text baseline to speech input and provide first results for direct generation of fluent text from noisy disfluent speech.",
  "y": "extends"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_0",
  "x": "Zhiyuan Chen <cite>[2]</cite> ever proposed a approach to determine which domain dose a word have the sentiment orientation to achieve the goal of lifelong learning.",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_1",
  "x": "Zhiyuan Chen <cite>[2]</cite> ever proposed a approach to determine which domain dose a word have the sentiment orientation to achieve the goal of lifelong learning. He made a big progress but the supervised learning still is needed.",
  "y": "motivation"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_2",
  "x": "Zhiyuan and Bing <cite>[2]</cite> improved the sentiment classification by involving knowledge.",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_3",
  "x": "\u2022 Knowledge Base (KB): The knowledge Base <cite>[2]</cite> mainly used to maintain the previous knowledge.",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_4",
  "x": "\u2022 Knowledge-Base Learner (KBL): The Knowledge-Based Learner <cite>[2]</cite> aims to retrieve and transfer previous knowledge to the current task.",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_5",
  "x": "Previous classical paper <cite>[2]</cite> chose the sentiment classification as the learning target because it is could be regarded as a task as well as a group of subtasks in different domain.",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_6",
  "x": "Previous classical paper <cite>[2]</cite> chose the sentiment classification as the learning target because it is could be regarded as a task as well as a group of subtasks in different domain. These sub-tasks related to each other but a model trained on a domain is unable to perform well in rest domains.",
  "y": "motivation"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_7",
  "x": "\"Lifelong Sentiment Classification\" (\"LSC\" for simple below) <cite>[2]</cite> records that which domain does a word have the sentiment orientation.",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_8",
  "x": "Although LSC <cite>[2]</cite> already raised a lifelong approach, it only aims to improve the classification accuracy.",
  "y": "motivation"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_9",
  "x": "Use use the same formula as LSC <cite>[2]</cite> used below.",
  "y": "uses"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_10",
  "x": "LSC <cite>[2]</cite> discussed a possible solution of P(w |c j ).",
  "y": "background"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_11",
  "x": "Although LSC <cite>[2]</cite> considered the difference among domains, it still is a typical supervised learning approach.",
  "y": "motivation"
 },
 {
  "id": "e3ee86bbaca6ae00906e7ec64f0ac0_12",
  "x": "In the experiment, we use the same datasets as LSC <cite>[2]</cite> used.",
  "y": "uses"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_0",
  "x": "However, recently the reverse process, i.e. the generation of texts from AMRs, has started to receive scholarly attention (Flanigan et al., 2016; Song et al., 2016; <cite>Pourdamghani et al., 2016</cite>; Song et al., 2017; Konstas et al., 2017) .",
  "y": "background"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_1",
  "x": "However, recently the reverse process, i.e. the generation of texts from AMRs, has started to receive scholarly attention (Flanigan et al., 2016; Song et al., 2016; <cite>Pourdamghani et al., 2016</cite>; Song et al., 2017; Konstas et al., 2017) . We assume that in practical applications, conceptualisation models or dialogue managers (models which decide \"what to say\") output AMRs. In this paper we study different ways in which these AMRs can be converted into natural language (deciding \"how to say it\").",
  "y": "motivation"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_2",
  "x": "Motivated by this similarity,<cite> Pourdamghani et al. (2016)</cite> proposed an AMR-to-text method that organises some of these concepts and edges in a flat representation, commonly known as Linearisation. Once the linearisation is complete,<cite> Pourdamghani et al. (2016)</cite> map the flat AMR into an English sentence using a Phrase-Based Machine Translation (PBMT) system.",
  "y": "background"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_3",
  "x": "In addition,<cite> Pourdamghani et al. (2016)</cite> use PBMT, which is devised for translation but also utilised in other NLP tasks, e.g. text simplification (Wubben et al., 2012; \u0160tajner et al., 2015) .",
  "y": "background"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_4",
  "x": "To address this,<cite> Pourdamghani et al. (2016)</cite> look for special realisation component for names, dates and numbers in development and test sets and add them on the training set.",
  "y": "background"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_5",
  "x": "Following the aligner of Pourdamghani et al. (2014) ,<cite> Pourdamghani et al. (2016)</cite> clean an AMR by removing some nodes and edges independent of the context.",
  "y": "background"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_6",
  "x": "Following the aligner of Pourdamghani et al. (2014) ,<cite> Pourdamghani et al. (2016)</cite> clean an AMR by removing some nodes and edges independent of the context. Instead, we are using alignments that may relate a given node or edge to an English word according to the context.",
  "y": "differences"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_7",
  "x": "After Compression, we flatten the AMR to serve as input to the translation step, similarly as proposed in<cite> Pourdamghani et al. (2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_8",
  "x": "In a second step, also following<cite> Pourdamghani et al. (2016)</cite>, we implemented a version of the 2-Step Classifier from Lerner and Petrov (2013) to preorder the elements from an AMR according to the target side.",
  "y": "uses"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_9",
  "x": "We compare BLEU scores for some of the AMRto-text systems described in the literature (Flanigan et al., 2016; Song et al., 2016; <cite>Pourdamghani et al., 2016</cite>; Song et al., 2017; Konstas et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_10",
  "x": "Since the models of Flanigan et al. (2016) and<cite> Pourdamghani et al. (2016)</cite> are publicly available, we also use them with the same training data as our models.",
  "y": "uses"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_11",
  "x": "We compare BLEU scores for some of the AMRto-text systems described in the literature (Flanigan et al., 2016; Song et al., 2016; <cite>Pourdamghani et al., 2016</cite>; Song et al., 2017; Konstas et al., 2017) . Since the models of Flanigan et al. (2016) and<cite> Pourdamghani et al. (2016)</cite> are publicly available, we also use them with the same training data as our models. For Flanigan et al. (2016) , we specifically use the version available on GitHub 2 . For<cite> Pourdamghani et al. (2016)</cite> , we use the version available at the first author's website 3 .",
  "y": "uses"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_12",
  "x": "We do not use lexicalised reordering models as<cite> Pourdamghani et al. (2016)</cite> . Moreover, we tune the weights of the feature functions with MERT (Och, 2003) .",
  "y": "differences"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_13",
  "x": "The models of Flanigan et al. (2016) and<cite> Pourdamghani et al. (2016)</cite> were officially trained with 10,313 AMR-sentence pairs from the LDC2014T12 corpus, and with 36,521 AMR-sentence pairs from the LDC2016E25 in our study (as our models).",
  "y": "differences"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_14",
  "x": "All the models with the preordering method in Linearisation Song et al. (2017) and introduce competitive results with<cite> Pourdamghani et al. (2016)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_15",
  "x": "Our best model (PBMT-Delex+Compress+Preorder) presents competitive results to<cite> Pourdamghani et al. (2016)</cite> with the advantage that no technique is necessary to overcome data sparsity.",
  "y": "similarities"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_16",
  "x": "We note that the preordering success was expected, based on previous results<cite> (Pourdamghani et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_17",
  "x": "PBMT models trained on small data sets clearly outperform NMT ones, e.g. Konstas et al. (2017) reported 22.0 BLEU, whereas<cite> Pourdamghani et al. (2016)</cite> 's best model achieved 26.9 BLEU, and our best model performs comparably (26.8 BLEU).",
  "y": "similarities"
 },
 {
  "id": "e4452ce844b74c35f257c916aae120_18",
  "x": "In such situations, our PBMT models, like<cite> Pourdamghani et al. (2016)</cite> , look appear to be a good alternative option.",
  "y": "similarities"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_0",
  "x": "Texts from biomedical publications and electronic medical record have been used to pre-train BERT models for NLP task in this domain and showed considerable improvement in many downstream tasks (Lee et al., 2019;<cite> Alsentzer et al., 2019</cite>; Si et al., 2019) .",
  "y": "motivation background"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_1",
  "x": "Later in the year,<cite> Alsentzer et al. (2019)</cite> and Si et al. (2019) published almost at the same time BERT models pre-trained trained on publicly available clinical notes from MIMIC3 either starting from trained parameters of original BERT or BioBERT model and show improvement of clinical NLP tasks.",
  "y": "background"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_2",
  "x": "We included only discharge summaries in our study as previous studies have shown that performance of a model trained on only discharge summaries in this corpus is only marginally worse than model trained on all notes types<cite> (Alsentzer et al., 2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_3",
  "x": "The prepossessing and tokenization pipeline from<cite> Alsentzer et al. 2019</cite><cite> (Alsentzer et al., 2019</cite> was adapted.",
  "y": "similarities uses"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_4",
  "x": "Centralized fine-tuning of the i2b2 NER tasks plateaued after 4 epochs, with the learning rate set at 2e \u2212 5 and a batch size of 32<cite> (Alsentzer et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_5",
  "x": "Clinical BERT pre-trained on MIMIC corpus has been reported to have superior performance on NER tasks in Inside-Outside-Beginning (IOB) format (Ramshaw and Marcus, 1999) using i2b2 2010 (Uzuner et al., 2011) and 2012 (Sun et al., 2013) data<cite> (Alsentzer et al., 2019)</cite> .Original training/development/test splits in the challenges were used.",
  "y": "background"
 },
 {
  "id": "e48a1eac39987cb2f504b66d135572_6",
  "x": "We also looked at the scenarios where BERTbase model was pre-trained by MIMIC3 discharge summaries in a centralized manner<cite> (Alsentzer et al., 2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_0",
  "x": "In another attempt, <cite>Jana and Goyal (2018b)</cite> proposed various complex network measures which can be used as features to build a supervised classifier model for co-hyponymy detection, and showed improvements over other baseline approaches.",
  "y": "motivation"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_1",
  "x": "Thus, a natural question arises as to whether network embeddings should be more effective than the handcrafted network features used by <cite>Jana and Goyal (2018b)</cite> for cohyponymy detection.",
  "y": "motivation"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_2",
  "x": "In a recent work, <cite>Jana and Goyal (2018b)</cite> used network features extracted from the DT to detect co-hyponyms. In our approach, we attempt to use embeddings obtained through a network representation learning method such as node2vec (Grover and Leskovec, 2016) when applied over the DT network.",
  "y": "extends"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_3",
  "x": "We perform experiments using three benchmark datasets for co-hyponymy detection (Weeds et al., 2014; Santus et al., 2016; <cite>Jana and Goyal, 2018b)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_4",
  "x": "In a recent work, <cite>Jana and Goyal (2018b)</cite> used network features extracted from the DT to detect co-hyponyms.",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_5",
  "x": "Evaluation results: We evaluate the usefulness of DT embeddings against three benchmark datasets for cohyponymy detection (Weeds et al., 2014; Santus et al., 2016; <cite>Jana and Goyal, 2018b)</cite> , following their experimental setup.",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_6",
  "x": "(Ferret, 2017) apply distributional thesaurus embedding for synonym extraction and expansion tasks whereas Jana and Goyal (2018a) use it to improve the state-of-theart performance of word similarity/relatedness tasks, word analogy task etc. Thus, a natural question arises as to whether network embeddings should be more effective than the handcrafted network features used by <cite>Jana and Goyal (2018b)</cite> for cohyponymy detection. Being motivated by this connection, we investigate how the information captured by network representation learning methodologies on distributional thesaurus can be used in discriminating word pairs having co-hyponymy relation from the word pairs having hypernymy, meronymy relation or any random pair of words. Evaluation results: We evaluate the usefulness of DT embeddings against three benchmark datasets for cohyponymy detection (Weeds et al., 2014; Santus et al., 2016; <cite>Jana and Goyal, 2018b)</cite> , following their experimental setup.",
  "y": "extends"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_7",
  "x": "We perform experiments using three benchmark datasets for co-hyponymy detection (Weeds et al., 2014; Santus et al., 2016; <cite>Jana and Goyal, 2018b)</cite> . For <cite>each of these</cite>, we follow the same experimental setup as discussed by the authors and compare our method with the method proposed by the author as well as the state-of-the-art models by <cite>Jana and Goyal (2018b)</cite> . We perform the analysis of three datasets to investigate the extent of overlap present in these publicly available benchmark datasets and find out that 45.7% word pairs of dataset prepared by Weeds et al. (2014) are present in dataset ROOT9 prepared by Santus et al. (2016) . This intersection set comprises 27.8% of the ROOT9 dataset. Similarly 36.7% word pairs of dataset prepared by Weeds et al. (2014) are present in the whole dataset prepared by <cite>Jana and Goyal (2018b)</cite> . This intersection set comprises 44.9% of the dataset prepared by <cite>Jana and Goyal (2018b)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_8",
  "x": "The relation between word pair holds if the lin similarity (Lin, 1998) of the word vectors is greater than some threshold p Table 3 : Accuracy scores on a ten-fold cross validation for cohyponym BLESS dataset of our models along with the top two baseline models (one supervised, one semisupervised) described in (Weeds et al., 2014) and models described in <cite>(Jana and Goyal, 2018b )</cite>",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_9",
  "x": "Table 5 : Accuracy scores on a ten-fold cross validation of models (svmSS, rfALL) proposed by <cite>Jana and Goyal (2018b)</cite> and our models for the dataset prepared by <cite>Jana and Goyal (2018b)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_11",
  "x": "Co-Hyp vs Hyper (Santus et al., 2016) 97.8 95.7 <cite>(Jana and Goyal, 2018b)</cite> 99 Table 4 : Percentage F1 scores on a ten-fold cross validation of our models along with the best models described in (Santus et al., 2016) and <cite>(Jana and Goyal, 2018b)</cite> for ROOT9 dataset a set of baseline methodologies, the descriptions of which are presented in Table 1 .",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_12",
  "x": "Co-Hyp vs Hyper (Santus et al., 2016) 97.8 95.7 <cite>(Jana and Goyal, 2018b)</cite> 99 Table 4 : Percentage F1 scores on a ten-fold cross validation of our models along with the best models described in (Santus et al., 2016) and <cite>(Jana and Goyal, 2018b)</cite> for ROOT9 dataset a set of baseline methodologies, the descriptions of which are presented in Table 1 . Here, the best model proposed by <cite>Jana and Goyal (2018b)</cite> uses SVM classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network.",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_13",
  "x": "Here, the best model proposed by <cite>Jana and Goyal (2018b)</cite> uses SVM classifier which is fed with structural similarity of the words in the given word pair from the distributional thesaurus network. We see that all the 4 proposed methods perform at par or better than the baselines, and using RF CC gives a 15.4% improvement over the best results reported.",
  "y": "differences"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_14",
  "x": "Table 4 represents the performance comparison of our models with the best stateof-the-art models reported in (Santus et al., 2016) and <cite>(Jana and Goyal, 2018b)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_15",
  "x": "Here, the best model proposed by Santus et al. (2016) uses Random Forest classifier which is fed with nine corpus based features like frequency of words, co-occurrence frequency etc., and the best model proposed by <cite>Jana and Goyal (2018b)</cite> use Random Forest classifier which is fed with five complex network features like structural similarity, shortest path etc.",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_16",
  "x": "In the third experiment we use the dataset specifically build for co-hyponymy detection in one of the recent works by <cite>Jana and Goyal (2018b)</cite> . <cite>This dataset</cite> is extracted from BLESS (Baroni and Lenci, 2011) and divided into three small datasets-Co-Hypo vs Hyper, Co-Hypo vs Mero, Co-Hypo Vs Random.",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_17",
  "x": "Following the same setup, we report accuracy scores for ten-fold cross validation for each of these three datasets of our models along with the best models (svmSS, rfALL) reported by <cite>Jana and Goyal (2018b)</cite> in Table 5 .",
  "y": "uses"
 },
 {
  "id": "e5886e138ce8d84a48e44db3f3d6a1_18",
  "x": "<cite>Jana and Goyal (2018b)</cite> use SVM classifier with structural similarity between words in a word pair as feature to obtain svmSS and use Random Forest classifier with five complex network measures computed from distributional thesaurus network as features to obtain rfALL.",
  "y": "background"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_0",
  "x": "Second, although the feature set is fundamentally a combination of those used in previous works <cite>(Zhang and Clark, 2010</cite>; Huang and Sagae, 2010) , to integrate them in a single incremental framework is not straightforward.",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_1",
  "x": "Among the many recent works on joint segmentation and POS tagging for Chinese, the linear-time incremental models by Zhang and Clark (2008) and<cite> Zhang and Clark (2010)</cite> largely inspired our model.",
  "y": "similarities uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_2",
  "x": "More recently,<cite> Zhang and Clark (2010)</cite> proposed an efficient character-based decoder for their word-based model.",
  "y": "background"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_3",
  "x": "Particularly, we change the role of the shift action and additionally use the append action, inspired by the character-based actions used in the joint segmentation and POS tagging model by<cite> Zhang and Clark (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_4",
  "x": "Following<cite> Zhang and Clark (2010)</cite> , the POS tag is assigned to the word when its first character is shifted, and the word-tag pairs observed in the training data and the closed-set tags (Xia, 2000) are used to prune unlikely derivations.",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_5",
  "x": "We can first think of using the number of shifted characters as the step index, as<cite> Zhang and Clark (2010)</cite> does.",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_6",
  "x": "In our framework, because an action increases the step index by 1 (for SH(t) or RL/RR) or 2 (for A), we need to use two beams to store new states at each step. Theoretically, the computational time is greater than that with the character-based joint segmentation and tagging model by<cite> Zhang and Clark (2010)</cite> by a factor of 2.1, when the same beam size is used.",
  "y": "differences"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_7",
  "x": "The feature set of our model is fundamentally a combination of the features used in the state-of-the-art joint segmentation and POS tagging model<cite> (Zhang and Clark, 2010)</cite> and dependency parser (Huang and Sagae, 2010) , both of which are used as baseline models in our experiment.",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_8",
  "x": "The list of the features used in our joint model is presented in Table 1 , where S01-S05, W01-W21, and T01-05 are taken from<cite> Zhang and Clark (2010)</cite> , and P01-P28 are taken from Huang and Sagae (2010) .",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_9",
  "x": "These features will also be used in our reimplementation of the model by<cite> Zhang and Clark (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_10",
  "x": "We use the following baseline and proposed models for evaluation. \u2022 SegTag: our reimplementation of the joint segmentation and POS tagging model by<cite> Zhang and Clark (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_11",
  "x": "We use the following baseline and proposed models for evaluation. tagging (Zhang and Clark, 2008;<cite> Zhang and Clark, 2010)</cite> and dependency parsing (Huang and Sagae, 2010) .",
  "y": "uses"
 },
 {
  "id": "e5ef75cd497dd94b4cf818291707df_12",
  "x": "Table 5 and Table 6 show a comparison of the segmentation and POS tagging accuracies with other state-of-the-art models. \"Zhang '10\" is the incremental model by<cite> Zhang and Clark (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "e608068f472e7045b682f979fd5295_0",
  "x": "Another closely related work is our own previously proposed method for leveraging on resources available for English to construct resources for a second language<cite> (Mihalcea et al., 2007)</cite> . That method assumed the availability of a bridge between languages, such as a bilingual lexicon or a parallel corpus. Instead, in the method proposed here, we rely exclusively on language-specific resources, and do not make use of any such bilingual resources which may not always be available.",
  "y": "motivation background differences"
 },
 {
  "id": "e608068f472e7045b682f979fd5295_1",
  "x": "More details about this data set are available in<cite> (Mihalcea et al., 2007)</cite> .",
  "y": "uses background"
 },
 {
  "id": "e608068f472e7045b682f979fd5295_3",
  "x": "Note that<cite> (Mihalcea et al., 2007</cite> ) also proposed a corpusbased method for subjectivity classification; however that method is supervised and thus not directly comparable with the approach introduced in this paper.",
  "y": "differences"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_0",
  "x": "Two baseNP data sets have been put forward by <cite>(Ramshaw and Marcus, 1995)</cite> .",
  "y": "background"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_1",
  "x": "A standard data set for this task was put forward at the CoNLL-99 workshop. The noun phrases in this data set are the same as in the Treebank and therefore the baseNPs in this data set are slightly different from the ones in the <cite>(Ramshaw and Marcus, 1995)</cite> data sets.",
  "y": "background"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_2",
  "x": "And third, 1This <cite>(Ramshaw and Marcus, 1995)</cite> baseNP data set is available via ftp://ftp.cis.upenn.edu/pub/chunker/ 2Software for generating the data is available from http://lcg-www.uia.ac.be/conl199/npb/ with the FZ=I rate which is equal to (2*precision*recall)/(precision+recall).",
  "y": "background"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_3",
  "x": "An alternative representation for baseNPs has been put forward by <cite>(Ramshaw and Marcus, 1995)</cite> .",
  "y": "background"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_4",
  "x": "(Tjong Kim Sang and Veenstra, 1999) have presented three variants of this tagging representation. They have used the <cite>(Ramshaw and Marcus, 1995)</cite> representation as well (IOB1).",
  "y": "background"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_5",
  "x": "We have applied it to the two data sets mentioned in <cite>(Ramshaw and Marcus, 1995)</cite> .",
  "y": "uses"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_6",
  "x": "For this purpose we performed a 10-fold cross validation experiment on the baseNP training data, sections 15-18 of the WSJ part of the Penn Treebank (211727 tokens). Like the data used by <cite>(Ramshaw and Marcus, 1995)</cite> , this data was retagged by the Brill tagger in order to obtain realistic part-of-speech (POS) tags 3. The data was segmented into baseNP parts and non-baseNP parts in a similar fashion as the data used by <cite>(Ramshaw and Marcus, 1995)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_7",
  "x": "<cite>(Ramshaw and Marcus, 1995)</cite> have build a chunker by applying transformation-based learning to sections of the Penn Treebank.",
  "y": "background"
 },
 {
  "id": "e68d09937d522dc5acac9637eb2a8b_8",
  "x": "They compare two data representations and report that a representation with bracket structures outperforms the IOB tagging representation introduced by <cite>(Ramshaw and Marcus, 1995)</cite> .",
  "y": "differences"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_0",
  "x": "<cite>Bolukbasi et al. (2016b)</cite> show that using word embeddings for simple analogies surfaces many gender stereotypes.",
  "y": "background"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_1",
  "x": "Recently, some work has been done to reduce the gender bias in word embeddings, both as a post-processing step<cite> (Bolukbasi et al., 2016b)</cite> and as part of the training procedure (Zhao et al., 2018) .",
  "y": "background"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_2",
  "x": "<cite>Bolukbasi et al. (2016b)</cite> define the gender bias of a word w by its projection on the \"gender direction\": \u2212 \u2192 w \u00b7 ( \u2212 \u2192 he \u2212 \u2212\u2192 she), assuming all vectors are normalized.",
  "y": "background"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_3",
  "x": "Both <cite>Bolukbasi et al. (2016b)</cite> and Zhao et al. (2018) propose methods for debiasing word embeddings, substantially reducing the bias according to the suggested definition.",
  "y": "background"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_4",
  "x": "2 In a seminal work, <cite>Bolukbasi et al. (2016b)</cite> use a post-processing debiasing method.",
  "y": "background"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_5",
  "x": "These works implicitly define what is good gender debiasing: according to <cite>Bolukbasi et al. (2016b)</cite> , there is no gender bias if each nonexplicitly gendered word in the vocabulary is in equal distance to both elements of all explicitly gendered pairs.",
  "y": "background"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_6",
  "x": "We refer to the word embeddings of the previous works as HARD-DEBIASED<cite> (Bolukbasi et al., 2016b)</cite> and GN-GLOVE (gender-neutral GloVe) counterparts in a predefined set.",
  "y": "similarities"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_7",
  "x": "6 Unless otherwise specified, we follow <cite>Bolukbasi et al. (2016b)</cite> and use a reduced version of the vocabulary for both word embeddings: we take the most frequent 50,000 words and phrases and remove words with upper-case letters, digits, or punctuation, and words longer than 20 characters.",
  "y": "extends differences"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_8",
  "x": "Male-and female-biased words cluster together We take the most biased words in the vocabulary according to the original bias (500 malebiased and 500 female-biased 8 ), and cluster them 6 We use the embeddings provided by <cite>Bolukbasi et al. (2016b)</cite> in https://github.com/tolga-b/ debiaswe and by Zhao et al. (2018) in https:// github.com/uclanlp/gn_glove.",
  "y": "similarities uses"
 },
 {
  "id": "e7c947a02bb0e81d6b6b4b9da74024_9",
  "x": "Professions We consider the list of professions used in <cite>Bolukbasi et al. (2016b)</cite> and Zhao et al. (2018) 10 in light of the neighbours-based bias definition.",
  "y": "uses similarities"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_0",
  "x": "Numerous initiatives such as the Digital Corpus of Sanskrit 1 , GRETIL 2 , The Sanskrit Library 3 and others from the Sanskrit Linguistic and Computational Linguistic community is a fine example of such efforts (Goyal et al., 2012; <cite>Krishna et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_1",
  "x": "Our approach will help to scale the segmentation process in comparison with the challenges posed by knowledge involved processes in the current systems <cite>(Krishna et al., 2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_2",
  "x": "To further catalyse the research in word segmentation for Sanskrit, <cite>Krishna et al. (2017)</cite> has released a dataset for the word segmentation task. <cite>The work</cite> releases a dataset of 119,000 sentences in Sanskrit along with the lexical and morphological analysis from a shallow parser. <cite>The work</cite> emphasises the need for not just predicting the inflected word form but also the prediction of the associated morphological information of the word.",
  "y": "background"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_3",
  "x": "The additional information will be beneficial in further processing of Sanskrit texts, such as Dependency parsing or summarisation <cite>(Krishna et al., 2017)</cite> .So far, no system successfully predicts the morphological information of the words in addition to the final word form.",
  "y": "future_work"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_4",
  "x": "In our case we use 105,000 parallel strings from the Digital Corpus of Sanskrit as released in <cite>Krishna et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_5",
  "x": "We used a dataset of 107,000 sentences from the <cite>Sanskrit Word Segmentation Dataset</cite> <cite>(Krishna et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_6",
  "x": "The systems by Krishna et al. (2016) and <cite>Krishna et al. (2017)</cite> assume that the parser by Goyal et al. (2012) , identifies all the possible candidate chunks.",
  "y": "background"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_7",
  "x": "The systems by Krishna et al. (2016) and <cite>Krishna et al. (2017)</cite> assume that the parser by Goyal et al. (2012) , identifies all the possible candidate chunks. Our proposed model is built with precisely one purpose in mind, which is to predict the final word-forms in a given sequence.",
  "y": "differences"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_8",
  "x": "<cite>Krishna et al. (2017)</cite> states that it is desirable to predict the morphological information of a word from along with the final word-form as the information will be helpful in further processing of Sanskrit.",
  "y": "background"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_9",
  "x": "<cite>Krishna et al. (2017)</cite> states that it is desirable to predict the morphological information of a word from along with the final word-form as the information will be helpful in further processing of Sanskrit. The segmentation task is seen as a means and not an end itself. Here, we overlook this aspect and see the segmentation task as an end in itself.",
  "y": "differences"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_10",
  "x": "Given the importance of morphological segmentation in morphologically rich languages such as Hebrew and Arabic (Seeker and \u00c7 etinoglu, 2015) , the same applies to the morphologically rich Sanskrit as well <cite>(Krishna et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "e7f972baa73e7ababa28eded3adad9_11",
  "x": "Given the importance of morphological segmentation in morphologically rich languages such as Hebrew and Arabic (Seeker and \u00c7 etinoglu, 2015) , the same applies to the morphologically rich Sanskrit as well <cite>(Krishna et al., 2017)</cite> . But, we leave this work for future.",
  "y": "future_work"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_0",
  "x": "These steps result in an improvement of 43.98% percent relative error reduction in F-score over an earlier best result in edited detection when punctuation is included in both training and testing data<cite> [Charniak and Johnson 2001]</cite> , and 20.44% percent relative error reduction in F-score over the latest best result where punctuation is excluded from the training and testing data [Johnson and Charniak 2004] .",
  "y": "differences"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_1",
  "x": "Because of the availability of the Switchboard corpus [Godfrey et al. 1992] and other conversational telephone speech (CTS) corpora, there has been an increasing interest in improving the performance of identifying the edited regions for parsing disfluent sentences<cite> [Charniak and Johnson 2001</cite> , Johnson and Charniak 2004 , Liu et al. 2005 .",
  "y": "background"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_2",
  "x": "These steps result in a significant improvement in F-score over the earlier best result reported in<cite> [Charniak and Johnson 2001]</cite> , where punctuation is included in both the training and testing data of the Switchboard corpus, and a significant error reduction in F-score over the latest best result [Johnson and Charniak 2004] , where punctuation is ignored in both the training and testing data of the Switchboard corpus.",
  "y": "differences"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_3",
  "x": "We include the distributions with punctuation is to match with the baseline system reported in<cite> [Charniak and Johnson 2001]</cite> , where punctuation is included to identify the edited regions.",
  "y": "motivation similarities"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_4",
  "x": "We take as our baseline system the work by<cite> [Charniak and Johnson 2001]</cite> .",
  "y": "uses"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_6",
  "x": "We re-implement the boosting algorithm reported by<cite> [Charniak and Johnson 2001]</cite>",
  "y": "uses"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_7",
  "x": "In<cite> [Charniak and Johnson 2001]</cite> , identifying edited regions is considered as a classification problem, where each word is classified either as edited or normal.",
  "y": "background"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_8",
  "x": "We relax the definition for rough copy, because more than 94% of all edits have both reparandum and repair, while the rough copy defined in<cite> [Charniak and Johnson 2001]</cite> only covers 77.66% of such instances.",
  "y": "differences"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_9",
  "x": "Since the original code from<cite> [Charniak and Johnson 2001]</cite> is not available, we conducted our first experiment to replicate the result of their baseline system described in section 3.",
  "y": "motivation"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_10",
  "x": "We used the exactly same training and testing data from the Switchboard corpus as in<cite> [Charniak and Johnson 2001]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "e831e058f208542af16c1ea236d2c9_11",
  "x": "These results are comparable with the results from <cite>[Charniak & Johnson 2001]</cite> , i.e., 95.2%, 67.8%, and 79.2% for precision, recall, and f-score, correspondingly.",
  "y": "similarities"
 },
 {
  "id": "e834dadbcf08cf14e476b5f5cbf79e_0",
  "x": "In particular, the memory network Chien and Lin, 2018) , neural variational learning (<cite>Serban et al., 2017</cite>; Chung et al., 2015) , neural discrete representation (Jang et al., 2016; Maddison et al., 2016; van den Oord et al., 2017) , recurrent ladder network (Rasmus et al., 2015; Pr\u00e9mont-Schwarz et al., 2017; S\u00f8nderby et al., 2016) , stochastic neural network (Fraccaro et al., 2016; Goyal et al., 2017; Shabanian et al., 2017) , Markov recurrent neural network (Venkatraman et al., 2017; Kuo and Chien, 2018) , sequence GAN (Yu et al., 2017) and reinforcement learning (Tegho et al., 2017) are introduced in various deep models which open a window to more practical tasks, e.g. reading comprehension, sentence generation, dialogue system, question answering and machine translation.",
  "y": "background"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_0",
  "x": "Briefly, our method consists in augmenting a state-of-the-art statistical parser <cite>(Henderson, 2003)</cite> , whose architecture and properties make it particularly adaptive to new tasks.",
  "y": "extends"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_1",
  "x": "Our approach maintains state-of-the-art results in parsing, while also reaching state-of-the-art results in function labelling, by suitably extending a Simple Synchrony Network (SSN) parser <cite>(Henderson, 2003)</cite> into a single integrated system.",
  "y": "extends"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_2",
  "x": "We use a family of statistical parsers, the Simple Synchrony Network (SSN) parsers <cite>(Henderson, 2003)</cite> , which crucially do not make any explicit independence assumptions, and learn to smooth across rare feature combinations.",
  "y": "uses"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_3",
  "x": "SSN parsers, on the other hand, do not state any explicit independence assumptions: they induce a finite history representation of an unbounded sequence of moves, so that the representation of a move i \u2212 1 is included in the inputs to the represention of the next move i, as explained in more detail in <cite>(Henderson, 2003)</cite> .",
  "y": "background"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_4",
  "x": "H03 indicates the model illustrated in <cite>(Henderson, 2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_5",
  "x": "All our models, as well as the parser described in <cite>(Henderson, 2003)</cite> , are run only once.",
  "y": "similarities"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_6",
  "x": "<cite>(Henderson, 2003)</cite> tested the effect of larger input vocabulary on SSN performance by changing the frequency cut-off that selects the input tag-word pairs.",
  "y": "background"
 },
 {
  "id": "e92c6b44f4482ca868221bff551d67_7",
  "x": "Second, this interpretation of the results is confirmed by comparing different ways of enlarging the vocabulary size input to the SSN. <cite>(Henderson, 2003)</cite> tested the effect of larger input vocabulary on SSN performance by changing the frequency cut-off that selects the input tag-word pairs.",
  "y": "uses"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_0",
  "x": "The method is designed for intrinsic evaluation and extends the approach proposed in (<cite>Schnabel et al., 2015</cite>) .",
  "y": "extends"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_1",
  "x": "In (<cite>Schnabel et al., 2015</cite>) , crowdsourcingbased evaluation was proposed for synonyms or a word relatedness task where six word embedding techniques were evaluated.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_2",
  "x": "The <cite>crowdsourcingbased intrinsic evaluation</cite> which tests embeddings for semantic relationship between words focuses on a direct comparison of word embeddings with respect to individual queries.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_3",
  "x": "Although <cite>the method</cite> is promising for evaluating different word embeddings, <cite>it</cite> has some shortcomings.",
  "y": "motivation"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_4",
  "x": "Specifically, <cite>it</cite> does not explicitly consider word context.",
  "y": "motivation"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_5",
  "x": "As <cite>the approach</cite> relies on human interpretation of words, it is important to take into account how humans interpret or understand the meaning of a word.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_6",
  "x": "Thus, if <cite>the approach</cite> is based only on the word without its context, it will be difficult for humans to understand the meaning of a particular word, and it could result in word sense ambiguity (WSA).",
  "y": "motivation"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_7",
  "x": "In this paper, we show what are the consequences of the lack of the word context in (<cite>Schnabel et al., 2015</cite>) , and we discuss how to address the resulting challenge.",
  "y": "uses motivation"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_8",
  "x": "<cite>The method</cite> in (<cite>Schnabel et al., 2015</cite>) started by creating a query inventory which is a pre-selected set of query terms and semantically related target words.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_9",
  "x": "Although the experiments in (<cite>Schnabel et al., 2015</cite>) incorporated participants with adequate knowledge of English, the ambiguity is inherent in the language.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_10",
  "x": "Also, the evaluated word embedding techniques in (<cite>Schnabel et al., 2015</cite>) except TSCCA (Dhillon et al., 2015)-generate one vector for each word, and that makes comparisons between two related words from two embedding techniques difficult.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_11",
  "x": "Before we introduce our extensions in the next section, we investigate how (<cite>Schnabel et al., 2015</cite>) accommodates word sense ambiguity.",
  "y": "uses"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_12",
  "x": "To achieve such an evaluation, we have first extended the work of (<cite>Schnabel et al., 2015</cite>) to include sentential context to avoid word sense ambiguity faced by a human tester.",
  "y": "extends"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_13",
  "x": "We then extended <cite>the method</cite> further so that it is more suitable to evaluate embedding techniques designed for polysemous words with regard to their ability to embed diverse senses.",
  "y": "extends"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_14",
  "x": "Our chief idea is to extend the work of (<cite>Schnabel et al., 2015</cite>) by adding a context sentence for each query term.",
  "y": "extends"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_15",
  "x": "In fact, (<cite>Schnabel et al., 2015</cite>) have already considered 'I don't know the meaning of one (or several) of the words'; however, when the context is in place, there may be a situation when none of the embeddings make a good match for the query term, and in that case 'None of the above' is more appropriate.",
  "y": "motivation background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_16",
  "x": "Note that this is not needed in (<cite>Schnabel et al., 2015</cite>) where query words are not annotated.",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_17",
  "x": "At the end of Sec. 2.2, we explained how word sense ambiguity is accommodated in (<cite>Schnabel et al., 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_18",
  "x": "We argued that <cite>their</cite> evaluation was in expectation with respect to subjective preferences of the Turkers.",
  "y": "uses background"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_19",
  "x": "In this paper, a crowdsourcing-based word embedding evaluation technique of (<cite>Schnabel et al., 2015</cite>) was extended to provide data-driven treatment of word sense ambiguity.",
  "y": "extends"
 },
 {
  "id": "e9404db1fbda5dd8c55a40711d06ec_20",
  "x": "The method of (<cite>Schnabel et al., 2015</cite>) relies on user's subjective and knowledge dependent ability to select 'preferred' meanings whereas our method would deal with this problem selecting explicit contexts for words.",
  "y": "differences"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_0",
  "x": "These corpora, as well as deep learning models, lead to contributions in multilingual language grounding and learning of shared and multimodal representations with neural networks [4, 7, <cite>8,</cite> 9, 10, 11, 12, 13] .",
  "y": "background"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_1",
  "x": "This preliminary result, in line with previous findings of<cite> [8]</cite> , confirms that neural speech-image models can capture a cross-lingual semantic signal, a first step in the perspective of learning speech-to-speech translation systems without text supervision.",
  "y": "similarities"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_2",
  "x": "We have seen in previous section that attention focuses on nouns and Table 2 suggests that these nouns correspond to the main concept of the paired image. To confirm this trend, we experiment on a crosslingual speech-to-speech retrieval task using images as pivots. This possibility was introduced in<cite> [8]</cite> , but required training jointly or alternatively two speech encoders within the same architecture and a parallel bilingual speech dataset while we experiment with separately trained models for both languages.",
  "y": "extends differences"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_3",
  "x": "In<cite> [8]</cite> , a parallel corpus was needed as the loss functions adopted try to minimise either the distance between captions in two languages or the distance between captions in two languages and the associated image as pivot.",
  "y": "background"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_4",
  "x": "We evaluated our approach on 1k captions of our test corpus to be comparable with<cite> [8]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_5",
  "x": "For comparison, we report<cite> [8]</cite> 's results on English to Hindi (HI) and Hindi to English speech-to-speech retrieval.",
  "y": "similarities"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_6",
  "x": "is paired with image I, we assess the ability of our approach to rank the matching spoken caption in language tgt paired with image I in the top 1, 5, and 10 results and give its median rank r. We report our results in Table 4 as well as results from<cite> [8]</cite> who performed speechto-speech retrieval using crowd-sourced spoken captions in English and Hindi.",
  "y": "similarities"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_7",
  "x": "Nevertheless, it is also important to mention that<cite> [8]</cite> experimented on real speech with multiple speakers while we used synthetic speech with only one voice.",
  "y": "differences"
 },
 {
  "id": "e9779b09826d709f8851550d958df7_8",
  "x": "ces so that there would be only one target caption for each query in order to compare our results with<cite> [8]</cite> .",
  "y": "future_work"
 },
 {
  "id": "e99193f62a8f3a9e46dee3cadd786f_0",
  "x": "Our dataset is a gold standard corpus of 1557 single-and multi-word disorder annotations <cite>(Ogren et al., 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_0",
  "x": "Some recent research of image captioning take inspiration from neural machine translation systems (NMT) [15] [16] [17] <cite>[18]</cite> that successfully use sequence-to-sequence learning for translation.",
  "y": "background"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_1",
  "x": "To overcome these limitations both for machine translation and image captioning, some new models were proposed by using the attention mechanism [3, 16,<cite> 18]</cite> .",
  "y": "motivation"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_2",
  "x": "Promising results has been published since attention was introduced in [16] then later refined in <cite>[18]</cite> .",
  "y": "background"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_3",
  "x": "We use the Luong style of attention <cite>[18]</cite> which is a refined version of attention mechanism and that to the best of our knowledge, there has not been any published work reporting the performance of an image captioning model that is built following only the encoder-decoder pipeline with Luong style of attention.",
  "y": "extends differences"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_4",
  "x": "Inspired by the use of attention in sequence-to-sequence learning for machine translation [16,<cite> 18]</cite> , visual attention has been proved to be a very effective way of improving image captioning.",
  "y": "motivation"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_5",
  "x": "In our work, we model the distribution p(w i t |X i , w i 1:t\u22121 ; \u03b8) with a LSTM cell wrapped with Luong-style attention mechanism <cite>[18]</cite> .",
  "y": "similarities"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_6",
  "x": "In our model, we use the general form described in <cite>[18]</cite> :",
  "y": "extends differences"
 },
 {
  "id": "e99baf9c4b8650f29f410501c5165b_7",
  "x": "In this paper, we use a LSTM cell wrapped with the attention mechanism described in <cite>[18]</cite> to form R. LSTM [24] is a powerful form of recurrent neural network that is widely used now because of its ability to deal with issues like vanishing and exploding gradients.",
  "y": "extends differences"
 },
 {
  "id": "e9f7d339ccda101000b53d89da4e49_0",
  "x": "The previous method for AMR parsing takes a Train Dev Test  3504 463 398   Table 1 : Statistics of the extracted NP data two-step approach: first identifying distinct concepts (nodes) in the AMR graph, then defining the dependency relations between those concepts<cite> (Flanigan et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "e9f7d339ccda101000b53d89da4e49_1",
  "x": "We obtain this alignment by using the rule-based alignment tool by <cite>Flanigan et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "e9f7d339ccda101000b53d89da4e49_2",
  "x": "We adopt the method proposed by <cite>Flanigan et al. (2014)</cite> as our baseline, which is a two-step pipeline method of concept identification step and<cite> (Flanigan et al., 2014)</cite> for a retired plant worker.",
  "y": "uses"
 },
 {
  "id": "e9f7d339ccda101000b53d89da4e49_3",
  "x": "We use the implementation 2 of<cite> (Flanigan et al., 2014)</cite> as our baseline.",
  "y": "uses"
 },
 {
  "id": "e9f7d339ccda101000b53d89da4e49_4",
  "x": "The method by <cite>Flanigan et al. (2014)</cite> can only generate the concepts that appear in the training data. On the other hand, our method can generate concepts that do not appear in the training data using the concept generation rules LEMMA, DICT PRED , and DICT NOUN in Table 3 .",
  "y": "differences"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_0",
  "x": "We propose solutions to enhance the Inside-Outside Recursive Neural Network (IORNN) reranker of<cite> Le and Zuidema (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_1",
  "x": "We propose solutions to enhance the Inside-Outside Recursive Neural Network (IORNN) reranker of<cite> Le and Zuidema (2014)</cite> . Replacing the original softmax function with a hierarchical softmax using a binary tree constructed by combining output of the Brown clustering algorithm and frequency-based Huffman codes, we significantly reduce the reranker's computational complexity.",
  "y": "extends"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_2",
  "x": "For dependency parsing, the inside-outside recursive neural net (IORNN) reranker proposed by<cite> Le and Zuidema (2014)</cite> is among the top systems, including the Chen and Manning (2014)'s extremely fast transition-based parser employing a traditional feed-forward neural network.",
  "y": "background"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_3",
  "x": "We focus on how to enhance the IORNN reranker of<cite> Le and Zuidema (2014)</cite> by both reducing its computational complexity and increasing its accuracy.",
  "y": "extends"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_4",
  "x": "Second, by comparing a countbased model with their neural-net-based model on perplexity,<cite> Le and Zuidema (2014)</cite> suggested that predicting with neural nets is an effective solution for the problem of data sparsity.",
  "y": "background"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_5",
  "x": "We focus on how to enhance the IORNN reranker of<cite> Le and Zuidema (2014)</cite> by both reducing its computational complexity and increasing its accuracy.",
  "y": "uses"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_6",
  "x": "We firstly introduce the IORNN reranker <cite>(Le and Zuidema, 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_7",
  "x": "<cite>(Le and Zuidema, 2014)</cite> where r = 0 if y is the first dependent of h; oth- is the set of y's sisters generated before. And,",
  "y": "uses background"
 },
 {
  "id": "eab79e8aa2cbe6f3aeef0018129208_9",
  "x": "Solutions to enhance the IORNN reranker of<cite> Le and Zuidema (2014)</cite> were proposed. We showed that, by replacing the original softmax function with a hierarchical softmax, the reranker's computational complexity significantly decreases.",
  "y": "extends"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_0",
  "x": "One recent notable work (<cite>Ganea and Hofmann 2017</cite>) instead pioneers to rely on pre-trained entity embeddings, learnable context representation and differentiable joint inference stage to learn basic features and their combinations from scratch.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_1",
  "x": "One recent notable work (<cite>Ganea and Hofmann 2017</cite>) instead pioneers to rely on pre-trained entity embeddings, learnable context representation and differentiable joint inference stage to learn basic features and their combinations from scratch. <cite>Such model design</cite> allows to learn useful regularities in an end-to-end fashion and eliminates the need for extensive feature engineering. <cite>It</cite> also substantially outperforms In Milwaukee , Marc Newfield homered off Jose Parra leading off the bottom of the 12th as the Brewers rallied for a 5-4 victory over the Minnesota Twins .",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_2",
  "x": "Local context score Golden Figure 1 : One error case on AIDA-CoNLL development set of the full model of <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_3",
  "x": "Such state-of-the-art entity linking models <cite>(Ganea and Hofmann 2017</cite>; Le and Titov 2018) employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_4",
  "x": "Such state-of-the-art entity linking models <cite>(Ganea and Hofmann 2017</cite>; Le and Titov 2018) employ attention-based bag-of-words context model and pre-trained entity embeddings bootstrapped from word embeddings to assess topic level context compatibility. However, the latent entity type information in the immediate context of the mention is neglected. We suspect this may sometimes cause the models link mentions to incorrect entities with incorrect type. To verify this, we conduct error analysis of the well known <cite>DeepED 1</cite> model <cite>(Ganea and Hofmann 2017)</cite> on the development set of AIDA-CoNLL (Hoffart et al. 2011) , and found that more than half of <cite>their</cite> error cases fall into the category of type errors where the predicted entity's type is different from the golden entity's type, although some predictive contextual cue for them can be found in <cite>their</cite> local context.",
  "y": "motivation"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_5",
  "x": "To verify this, we conduct error analysis of the well known <cite>DeepED 1</cite> model <cite>(Ganea and Hofmann 2017)</cite> on the development set of AIDA-CoNLL (Hoffart et al. 2011) , and found that more than half of <cite>their</cite> error cases fall into the category of type errors where the predicted entity's type is different from the golden entity's type, although some predictive contextual cue for them can be found in <cite>their</cite> local context. As shown in Fig. 1 , the full model of <cite>Ganea and Hofmann (2017)</cite> incorrectly links the mention \"Milwaukee\" to the entity MILWAUKEE BREWERS.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_6",
  "x": "The reason why the local context model of <cite>Ganea and Hofmann (2017)</cite> couldn't capture such apparent cue is two folds.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_7",
  "x": "On the other hand, the pre-trained entity embedding of <cite>Ganea and Hofmann (2017)</cite> is not very sensitive to entity types.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_8",
  "x": "So it is natural for the model of <cite>Ganea and Hofmann (2017)</cite> to make type errors when it is trained to fit such entity embeddings.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_9",
  "x": "What's more, we integrate a BERT-based entity similarity feature into the local model of <cite>Ganea and Hofmann (2017)</cite> to better capture entity type information.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_10",
  "x": "In addition, we conduct detailed experiment analysis on AIDA-CoNLL development set which shows our proposed model can reduce 67.03% type errors of the state-of-the-art model <cite>(Ganea and Hofmann 2017)</cite> and more than 90% of the remaining type error cases are due to over estimation of prior and global modeling problem which we leave as the further work.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_11",
  "x": "\u2022 We integrate a BERT-based entity similarity into the local model of a SOTA model <cite>(Ganea and Hofmann 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_12",
  "x": "Next, we introduce the general formulation of entity linking problem with a focus on the well known <cite>DeepED</cite> model <cite>(Ganea and Hofmann 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_13",
  "x": "Local Model Following <cite>Ganea and Hofmann (2017)</cite> , we instantiate the local model as an attention model based on pre-trained word and entity embeddings.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_14",
  "x": "Besides, <cite>Ganea and Hofmann (2017)</cite> combined this context score with the priorp(e|m) (computed by mixing mention-entity hyperlink count statistics from Wikipedia, a large Web corpus and YAGO.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_15",
  "x": "Previous work (Yamada et al. 2016 ; <cite>Ganea and Hofmann 2017)</cite> on learning entity representation are mostly extensions of the embedding methods proposed by (Mikolov et al. 2013 ).",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_16",
  "x": "Previous work (Yamada et al. 2016 ; <cite>Ganea and Hofmann 2017)</cite> on learning entity representation are mostly extensions of the embedding methods proposed by (Mikolov et al. 2013 ). An entity's context is a bag-ofwords representation which mainly captures topic level entity relatedness rather than entity type relatedness. In contrast, we propose a simple method to build entity embeddings directly from pre-trained BERT (Devlin et al. 2019) which can better capture entity type information.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_17",
  "x": "As will be shown in the analysis section, the entity embeddings from BERT better capture entity type information than those from <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_18",
  "x": "The local context model of <cite>Ganea and Hofmann (2017)</cite> mainly captures the topic level entity relatedness information based on a long range bag-of-words context.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_19",
  "x": "Finally, as for the local disambiguation model, we integrate the BERT-based entity similarity \u03a8 BERT (e, c) with the local context score \u03a8 long (e, c) (defined in Equation 2) and the priorp(e|m i ) with two fully connected layers of 100 hidden units and ReLU non-linearities following the same feature composition methods as <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_20",
  "x": "Then we adopt exactly the same global model as <cite>Ganea and Hofmann (2017)</cite> which is already introduced in the Background section.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_21",
  "x": "Specifically, we adopt <cite>loopy belief propagation (LBP)</cite> to estimate the max-marginal probability\u011d i (e|D) and then combine it with the priorp(e|m i ) using a two-layer neural network to get the final score \u03c1 i (e) for m i .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_22",
  "x": "Following previous work <cite>(Ganea and Hofmann 2017)</cite>, we only consider in-KB mentions.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_23",
  "x": "Besides, our candidate generation strategy follows that of <cite>Ganea and Hofmann (2017)</cite> to make our results comparable.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_24",
  "x": "The main goal of this work is to introduce a BERT-based entity similarity to capture latent entity type information which is supplementary to existing SOTA local context model <cite>(Ganea and Hofmann 2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_25",
  "x": "So we evaluate the performance when integrating the BERT-based entity similarity into the local context model of <cite>Ganea and Hofmann (2017)</cite> . We also evaluate our model with or without global modeling method of <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_26",
  "x": "To verify the contribution of our proposed BERT-based entity embeddings, we also compare with a straightforward baseline which directly replaces the encoder of <cite>Ganea and Hofmann (2017)</cite> utilizing pre-trained BERT. To do so, we introduce a 768 \u00d7 300 dimensional matrix W which projects BERT-based context representation c into <cite>Ganea and Hofmann (2017)</cite>'s entity embeddings space when calculating the similarity score.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_27",
  "x": "The resources (word and entity embeddings) used to train the local context model of <cite>Ganea and Hofmann (2017)</cite> are obtained from <cite>DeepED 7</cite> .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_29",
  "x": "Similar to <cite>Ganea and Hofmann (2017)</cite> , all the entity embeddings are fixed during fine-tuning.",
  "y": "similarities"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_30",
  "x": "Note that all the hyper-parameters used in the local context and global model of <cite>Ganea and Hofmann (2017)</cite> were set to the same values as theirs for direct comparison purpose.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_31",
  "x": "Our local model achieves a 1.31 improvement in terms of F1 over its corresponding baseline <cite>(Ganea and Hofmann 2017)</cite> , yielding a very competitive local model with an average 90.06 F1 score even surpassing the performance of four local & global models.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_32",
  "x": "Equipped with the global modeling method of <cite>Ganea and Hofmann (2017)</cite> , the performance of our model further increase to 93.54 with an average 1.32 improvement in terms of F1 over <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_33",
  "x": "The model of Le and Titov (2018) is a multirelational extension of <cite>Ganea and Hofmann (2017)</cite>'s global modeling method while keeps exactly the same local context model.",
  "y": "extends"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_34",
  "x": "Moreover, BERT+G&Hs embeddings performs significantly worse than the baseline <cite>(Ganea and Hofmann 2017)</cite> and our proposed BERT-Entity-Sim model.",
  "y": "similarities"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_35",
  "x": "Moreover, BERT+G&Hs embeddings performs significantly worse than the baseline <cite>(Ganea and Hofmann 2017)</cite> and our proposed BERT-Entity-Sim model. The reason is that BERT-based context representation space and <cite>Ganea and Hofmanns entity embeddings space</cite> are heterogeneous. <cite>Ganea and Hofmanns entity embeddings</cite> are bootstrapped from word embeddings which mainly capture topic level entity relatedness, while BERT-based context representation is derived from BERT which naturally captures type information.",
  "y": "background"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_36",
  "x": "On average, our proposed model (BERT-Entity-Sim) outperforms the local & global version of <cite>Ganea and Hofmann</cite>; Le and Titov (2017; by an average 0.80 and 0.51 on F1.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_39",
  "x": "Table 5 : Performance of two state-of-the-art fine grained entity typing systems on AIDA-CoNLL development set order to verify our claim that the entity embeddings from BERT better capture entity type information than those from <cite>Ganea and Hofmann (2017)</cite> , we carry out an entity type prediction task based on its entity embedding.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_40",
  "x": "As shown in Table 3 , our proposed entity embedding from BERT significantly outperforms the entity embedding proposed by <cite>Ganea and Hofmann (2017)</cite> on three typing sys-tems FIGER, BBN and OntoNotes fine .",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_41",
  "x": "This demonstrates that our proposed entity embeddings from BERT indeed capture better latent entity type information than <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_42",
  "x": "This indicates that <cite>Ganea and Hofmann (2017)</cite> produces many type errors due to its inability to consider the entity type information in mention context.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_44",
  "x": "Besides, there are 22.95% remaining type errors which are due to global modeling problem which shows the limitation of the global modeling method of <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_45",
  "x": "It is nature to conjecture that we can also correct type errors by incorporating explicit type information into <cite>Ganea and Hofmann (2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_46",
  "x": "DCA is a global entity linking model featuring better efficiency and effectiveness than that of <cite>Ganea and Hofmann (2017)</cite> by breaking the \"all-mention coherence\" assumption.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_48",
  "x": "We follow Papernot and Mc-Daniel (2018) <cite>Ganea and Hofmann (2017)</cite> and BERT based entity representation space neighbour in the context representation space.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_49",
  "x": "We also retrieve nearest entities in the embedding space of <cite>Ganea and Hofmann (2017)</cite> and ours. As we can see, we query STEVE JOBS, the nearest entity in <cite>Ganea and Hofmann (2017)</cite> is APPLE INC.",
  "y": "uses"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_50",
  "x": "Another example is when we query NA-TIONAL BASKETBALL ASSOCIATION, the most similar entities in <cite>Ganea and Hofmann (2017)</cite> are NBA teams which are topically related, while the entities retrieved by our approach are all basketball leagues.",
  "y": "differences"
 },
 {
  "id": "eb5ef34dd9c3845cd27c33242d5316_51",
  "x": "Then we integrate a BERT-based entity similarity into the local model of the state-of-the-art method by (<cite>Ganea and Hofmann 2017</cite>) .",
  "y": "uses"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_0",
  "x": "To our knowledge, <cite>Gildea and Jurafsky (2000)</cite> is the only work that uses FrameNet to build a statistical semantic classifier.",
  "y": "similarities"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_1",
  "x": "<cite>Gildea and Jurafsky (2000)</cite> describe a system that uses completely syntactic features to classify the Frame Elements in a sentence.",
  "y": "background"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_2",
  "x": "Frame: We extend <cite>Gildea and Jurafsky (2000)</cite> 's initial effort in three ways.",
  "y": "extends differences"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_3",
  "x": "Training (32,251 sentences), development (3,491 sentences), and held out test sets (3,398 sentences) were generated from the June 2002 FrameNet release following the divisions used in <cite>Gildea and Jurafsky (2000)</cite> 1 .",
  "y": "uses"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_4",
  "x": "Because human-annotated syntactic information could only be obtained for a subset of their data, the training, development, and test sets used here are approximately 10% smaller than those used in <cite>Gildea and Jurafsky (2000)</cite> .",
  "y": "differences"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_5",
  "x": "Due to data sparsity issues, we do not calculate this model directly, but rather, model various feature combinations as described in <cite>Gildea and Jurafsky (2000)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_6",
  "x": "2 <cite>Gildea and Jurafsky (2000)</cite> use 36995 training, 4000 development, and 3865 test sentences. They do not report results using hand annotated syntactic information.",
  "y": "differences"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_7",
  "x": "As a further analysis, we have examined the performance of our base ME model on the same test set as that used in <cite>Gildea and Jurafsky (2000)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "ebd4488438579946c23904cc0f5932_8",
  "x": "Following <cite>Gildea and Jurafsky (2000)</cite> , automatic extraction of grammatical information here is limited to the governing category of a Noun Phrase.",
  "y": "differences"
 },
 {
  "id": "ec3702a6b30057fcae65ca297656d2_0",
  "x": "Examples of this approach are rarer, and we briefly mention two: Enright and Kondrak (2007) use singleton words (hapax legomena) to represent documents in a bilingual collection for the task of detecting document translation pairs, and <cite>Krstovski and Smith (2011)</cite> construct a vocabulary of overlapping words to represent documents in multilingual collections.",
  "y": "background"
 },
 {
  "id": "ec3702a6b30057fcae65ca297656d2_1",
  "x": "Examples of this approach are rarer, and we briefly mention two: Enright and Kondrak (2007) use singleton words (hapax legomena) to represent documents in a bilingual collection for the task of detecting document translation pairs, and <cite>Krstovski and Smith (2011)</cite> construct a vocabulary of overlapping words to represent documents in multilingual collections. The latter approach demonstrates high precision vs. recall values on various language pairs from different languages and writing systems when detecting translation pairs on a document level such as Europarl sessions. Recently proposed approaches, such as (Klementiev et al., 2012) use monolingual corpora to estimate phrase-based SMT parameters. Unlike our paper, however, they do not demonstrate an end-toend SMT system trained without any parallel data.",
  "y": "differences"
 },
 {
  "id": "ec3702a6b30057fcae65ca297656d2_2",
  "x": "Our bootstrapping approach (Figure 1 ) is a twostage system that used the Overlapping Cosine Distance (OCD) approach of <cite>Krstovski and Smith (2011)</cite> as its first step.",
  "y": "uses"
 },
 {
  "id": "ec3702a6b30057fcae65ca297656d2_3",
  "x": "While the number of overlapping words is dependent on the families of the source and target languages and their orthography, <cite>Krstovski and Smith (2011)</cite> showed that this approach yields good results across language pairs from different families and writing systems such as English-Greek, English-Bulgarian and EnglishArabic where, as one would expect, most shared words are numbers and named entities.",
  "y": "background"
 },
 {
  "id": "ec5897c392b05cb8712feadfc6d2bf_0",
  "x": "<cite>Hatzivassiloglou and McKeown (1993)</cite> duster adjectives into partitions and present an interesting evaluation to compare the generated adjective classes against those provided by an expert.",
  "y": "background"
 },
 {
  "id": "ec5897c392b05cb8712feadfc6d2bf_1",
  "x": "<cite>Hatzivassiloglou and McKeown (1993)</cite> duster adjectives into partitions and present an interesting evaluation to compare the generated adjective classes against those provided by an expert. Their evaluation scheme bases the comparison between two classes on the presence or absence of pairs of words in them. Their approach involves filling in a YES-NO contingency table based on whether a pair of words (adjectives, in their case) is classified in the same class by the human expert and by the system. This method works very well for partitions. However, if it is used to evaluate sets of classes where the classes may be potentiaily overlapping, their technique yields a weaker measure since the same word pair could possibly be present in more than one class. An ideal scheme used to evaluate semantic classes should be able to handle overlapping classes (as o1>. posed to partitions) as well as hierarchies. The technique proposed by Hatzivassiloglou and McKeown does not do a good job of evaluating either of these. In this paper, we present an evaluation methodology which makes it possible to properly evaluate over- In the discussion that follows, the word \"clustering\" is used to refer to the set of classes that may be either provided by an expert or generated by the system, and the word \"class\" is used to refer to a single class in the clustering.",
  "y": "motivation"
 },
 {
  "id": "ec5897c392b05cb8712feadfc6d2bf_2",
  "x": "We have adopted the F-measure<cite> (Hatzivassiloglou and McKeown, 1993</cite>; Chincor, 1992) .",
  "y": "uses"
 },
 {
  "id": "ec5897c392b05cb8712feadfc6d2bf_3",
  "x": "Once all classes in the two clusterings have been accounted for, calculate the precision, recall, and F-measure as explained in<cite> (Hatzivassiloglou and McKeown, 1993)</cite> .",
  "y": "uses"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_0",
  "x": "We focus on the first two tasks. A non-word is a sequence of letters that is not a possible word in the language in any context, e.g., English * thier. Once a sequence of letters has been determined to be a non-word, isolatedword error correction is the process of determining the appropriate word to substitute for the non-word. Given a sequence of letters, there are thus two main subtasks: 1) determine whether this is a nonword, 2) if so, select and rank candidate words as potential corrections to present to the writer. The first subtask can be accomplished by searching for the sequence of letters in a word list. The second subtask can be stated as follows<cite> (Brill and Moore, 2000)</cite> : Given an alphabet \u03a3, a word list D of strings \u2208 \u03a3 * , and a string r / \u2208 D and \u2208 \u03a3 * , find w \u2208 D such that w is the most likely correction.",
  "y": "uses"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_1",
  "x": "The spelling error model proposed by <cite>Brill and Moore (2000)</cite> allows generic string edit operations up to a certain length.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_2",
  "x": "<cite>Brill and Moore (2000)</cite> estimate the probability of each edit from a corpus of spelling errors.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_3",
  "x": "Toutanova and Moore (2002) extend <cite>Brill and Moore (2000)</cite> to consider edits over both letter sequences and sequences of phones in the pronunciations of the word and misspelling.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_4",
  "x": "They show that including pronunciation information improves performance as compared to <cite>Brill and Moore (2000)</cite> .",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_5",
  "x": "The spelling correction models from <cite>Brill and Moore (2000)</cite> and Toutanova and Moore (2002) use the noisy channel model approach to determine the types and weights of edit operations.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_6",
  "x": "1 <cite>Brill and Moore (2000)</cite> allow all edit operations \u03b1 \u2192 \u03b2 where \u03a3 is the alphabet and \u03b1, \u03b2 \u2208 \u03a3 * , with a constraint on the length of \u03b1 and \u03b2.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_7",
  "x": "This error model over letters, called P L , is approximated by <cite>Brill and Moore (2000)</cite> as shown in Figure 1 by considering only the pair of partitions of w and r with the maximum product of the probabilities of individual substitutions.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_8",
  "x": "The method, which is described in detail in <cite>Brill and Moore (2000)</cite> , involves aligning the letters in pairs of words and misspellings, expanding each alignment with up to N neighboring alignments, and calculating the probability of each \u03b1 \u2192 \u03b2 alignment.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_10",
  "x": "Toutanova and Moore (2002) describe an extension to <cite>Brill and Moore (2000)</cite> where the same noisy channel error model is used to model phone sequences instead of letter sequences.",
  "y": "background"
 },
 {
  "id": "ecb6e93a5254b86ef49a5ffd0a52a0_11",
  "x": "7 In order to rank the words as candidate corrections for a misspelling r, P L (r|w) and P P HL (r|w) are calculated for each word in the word list using the algorithm described in <cite>Brill and Moore (2000)</cite> .",
  "y": "uses"
 },
 {
  "id": "ece5f95d3c616ceeb0b3061e606b41_0",
  "x": "In particular, we are interested in the word2vec package available in<cite> (Mikolov et al., 2013a)</cite> .",
  "y": "motivation"
 },
 {
  "id": "ece5f95d3c616ceeb0b3061e606b41_1",
  "x": "The basic architecture that we use to build our models is CBOW<cite> (Mikolov et al., 2013a)</cite> .",
  "y": "uses"
 },
 {
  "id": "ece5f95d3c616ceeb0b3061e606b41_2",
  "x": "We chose these parameters for our system to obtain comparable results to the ones in<cite> (Mikolov et al., 2013a</cite> ) for a CBOW architecture but trained with 783 million words (50.4%).",
  "y": "similarities motivation"
 },
 {
  "id": "ee219d599e0e0c2bbebc1849863005_0",
  "x": "This mismatch of needs has motivated various proposals to reconstruct missing entries, in WALS and other databases, from known entries (Daum\u00e9 III and Campbell, 2007; Daum\u00e9 III, 2009; Coke et al., 2016; <cite>Littell et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "ee219d599e0e0c2bbebc1849863005_1",
  "x": "We calculate these feature vectors using an NMT model trained on 1017 languages, and use them for typlogy prediction both on their own and in composite with feature vectors from previous work based on the genetic and geographic distance between languages<cite> (Littell et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "ee219d599e0e0c2bbebc1849863005_2",
  "x": "Typology Database: To perform our analysis, we use the URIEL language typology database<cite> (Littell et al., 2017)</cite> , which is a collection of binary features extracted from multiple typological, phylogenetic, and geographical databases such as WALS (World Atlas of Language Structures) (Collins and Kayne, 2011) , PHOIBLE (Moran et al., 2014) , Ethnologue (Lewis et al., 2015) , and Glottolog (Hammarstr\u00f6m et al., 2015) .",
  "y": "uses"
 },
 {
  "id": "ee219d599e0e0c2bbebc1849863005_3",
  "x": "As an alternative that does not necessarily require pre-existing knowledge of the typological features in the language at hand,<cite> Littell et al. (2017)</cite> have proposed a method for inferring typological features directly from the language's k nearest neighbors (k-NN) according to geodesic distance (distance on the Earth's surface) and genetic distance (distance according to a phylogenetic family tree).",
  "y": "background"
 },
 {
  "id": "ee219d599e0e0c2bbebc1849863005_4",
  "x": "As an alternative that does not necessarily require pre-existing knowledge of the typological features in the language at hand,<cite> Littell et al. (2017)</cite> have proposed a method for inferring typological features directly from the language's k nearest neighbors (k-NN) according to geodesic distance (distance on the Earth's surface) and genetic distance (distance according to a phylogenetic family tree). In our experiments, our baseline uses this method by taking the 3-NN for each language according to normalized geodesic+genetic distance, and calculating an average feature vector of these three neighbors.",
  "y": "uses"
 },
 {
  "id": "eebf1edb6dbd3e58a904eff309f548_0",
  "x": "Language understanding is modeled as the task of converting natural language questions into queries through intermediate logical forms, with the popular two approaches including: CCG parsing (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011; Krishnamurthy and Mitchell, 2012; Kwiatkowski et al., 2013; Cai and Yates, 2013a) , and dependencybased compositional semantics (Liang et al., 2011; <cite>Berant et al., 2013</cite>; Berant and Liang, 2014) .",
  "y": "background"
 },
 {
  "id": "eebf1edb6dbd3e58a904eff309f548_1",
  "x": "While our conclusions should hold generally for similar KBs, we will focus on Freebase, such as explored by Krishnamurthy and Mitchell (2012) , and then others such as Cai and Yates (2013a) and<cite> Berant et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "eebf1edb6dbd3e58a904eff309f548_2",
  "x": "We compare two open-source, state-ofthe-art systems on the task of Freebase QA: the semantic parsing system SEMPRE<cite> (Berant et al., 2013)</cite> , and the IE system jacana-freebase (Yao and Van Durme, 2014) .",
  "y": "uses"
 },
 {
  "id": "eebf1edb6dbd3e58a904eff309f548_3",
  "x": "A major distinction between the work of<cite> Berant et al. (2013)</cite> and Yao and Van Durme (2014) is the ability of the former to represent, and compose, aggregation operators (such as argmax, or count), as well as integrate disparate pieces of information.",
  "y": "background"
 },
 {
  "id": "eebf1edb6dbd3e58a904eff309f548_4",
  "x": "SEMPRE 3 is an open-source system for training semantic parsers, that has been utilized to train a semantic parser against Freebase by<cite> Berant et al. (2013)</cite> .",
  "y": "background"
 },
 {
  "id": "eebf1edb6dbd3e58a904eff309f548_5",
  "x": "Both<cite> Berant et al. (2013)</cite> and Yao and Van Durme (2014) tested their systems on the WEBQUESTIONS dataset, which contains 3778 training questions and 2032 test questions collected from the Google Suggest API.",
  "y": "background"
 },
 {
  "id": "ef6bd5e57196c013d7d0436e5b0ca5_0",
  "x": "The Fact Extraction and VERification (FEVER) task <cite>(Thorne et al., 2018)</cite> focuses on verification of textual claims against evidence.",
  "y": "background"
 },
 {
  "id": "ef6bd5e57196c013d7d0436e5b0ca5_1",
  "x": "The Fact Extraction and VERification (FEVER) task <cite>(Thorne et al., 2018)</cite> focuses on verification of textual claims against evidence. This paper describes our participating system in the FEVER shared task.",
  "y": "uses background"
 },
 {
  "id": "ef6bd5e57196c013d7d0436e5b0ca5_2",
  "x": "The architecture of our system is designed by following the official baseline system <cite>(Thorne et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "ef6bd5e57196c013d7d0436e5b0ca5_3",
  "x": "To build the model, we utilize the NEARESTP dataset described in<cite> Thorne et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "ef6bd5e57196c013d7d0436e5b0ca5_4",
  "x": "For parameter tuning and performance evaluation, we used a development and test datasets used in <cite>(Thorne et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_0",
  "x": "We show how this approach can be combined with additional features, in particular, the discourse features presented by<cite> Jansen et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_1",
  "x": "Most previous attempts to perform non-factoid answer reranking on CQA data are supervised, feature-based, learning-to-rank approaches<cite> (Jansen et al., 2014</cite>; Fried et al., 2015; Sharp et al., 2015) .",
  "y": "background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_2",
  "x": "These methods represent the candidate answers as meaningful handcrafted features based on syntactic, semantic and discourse parses (Surdeanu et al., 2011; <cite>Jansen et al., 2014)</cite> , web correlation (Surdeanu et al., 2011) , and translation probabilities (Fried et al., 2015; Surdeanu et al., 2011) .",
  "y": "background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_3",
  "x": "First, we present a novel neural approach to answer reranking that achieves competitive results on a public dataset of Yahoo! Answers (YA) that was previously introduced by<cite> Jansen et al. (2014)</cite> and later used in several other studies (Fried et al., 2015; Sharp et al., 2015; Bogdanova and Foster, 2016) .",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_4",
  "x": "The main contributions of this paper are as follows: 1) we propose a novel neural approach for non-factoid answer reranking that achieves state-4 http://askubuntu.com of-the-art performance on a public dataset of Yahoo! Answers; 2) we combine this approach with an approach based on discourse features that was introduced by<cite> Jansen et al. (2014)</cite> , with the hybrid approach outperforming the neural approach and the previous state-of-the-art; 3) we introduce a new dataset of Ask Ubuntu questions and answers.",
  "y": "extends"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_5",
  "x": "Fried et al. (2015) improve on the lexical semantic models of<cite> Jansen et al. (2014)</cite> by exploiting indirect associations between words using higher-order models.",
  "y": "background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_6",
  "x": "Based on the intuition that modelling questionanswer structure both within and across sentences could be useful,<cite> Jansen et al. (2014)</cite> propose an answer reranking model based on discourse features combined with lexical semantics.",
  "y": "background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_7",
  "x": "Based on the intuition that modelling questionanswer structure both within and across sentences could be useful,<cite> Jansen et al. (2014)</cite> propose an answer reranking model based on discourse features combined with lexical semantics. We experimentally evaluate these discourse features -added to our model described in Section 3 (the additional features x ext ) and on their own.",
  "y": "uses background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_8",
  "x": "We illustrate the feature extraction process of<cite> Jansen et al. (2014)</cite> in Figure 2 .",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_9",
  "x": "Further details can be found in<cite> (Jansen et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_10",
  "x": "For comparability, we use the dataset created by<cite> Jansen et al. (2014)</cite> which contains 10K how questions from Yahoo! Answers. 50% of it is used for training, 25% for development and 25% for testing.",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_11",
  "x": "Further details about this dataset can be found in<cite> (Jansen et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_12",
  "x": "For comparability, we use the dataset created by<cite> Jansen et al. (2014)</cite> which contains 10K how questions from Yahoo! Answers. 50% of it is used for training, 25% for development and 25% for testing. Further details about this dataset can be found in<cite> (Jansen et al., 2014)</cite> .",
  "y": "uses background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_13",
  "x": "Following<cite> Jansen et al. (2014)</cite> and Fried et al. (2015) , we implement two baselines: the baseline that selects an answer randomly and the candidate retrieval (CR) baseline.",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_14",
  "x": "The CR baseline uses the same scoring as in<cite> Jansen et al. (2014)</cite> : the questions and the candidate answers are represented using tf-idf over lemmas; the candidate answers are ranked according to their cosine similarity to the respective question.",
  "y": "uses background"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_15",
  "x": "On the YA dataset, we also compare our results to the ones reported by<cite> Jansen et al. (2014)</cite> and by Bogdanova and Foster (2016) .",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_16",
  "x": "We use the software provided by<cite> Jansen et al. (2014)</cite> 7 to extract the discourse features described in Section 4 and referred to as x ext in Section 3.",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_17",
  "x": "Following<cite> Jansen et al. (2014)</cite> , we train them using the skip-gram model (Mikolov et al., 2013) We use the L6 Yahoo dataset 8 to train the skip-gram model for the YA dataset and the Ask Ubuntu September 2015 data dump for the AU dataset.",
  "y": "uses"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_18",
  "x": "They also perform better than the approach of<cite> Jansen et al. (2014)</cite> who used SVMrank with a linear kernel.",
  "y": "differences"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_19",
  "x": "On the YA dataset, the results are better than<cite> Jansen et al. (2014)</cite> and very similar to Bogdanova and Foster (2016) .",
  "y": "differences"
 },
 {
  "id": "ef742defff1c2bdf145f72796cf3af_20",
  "x": "As external features, we evaluate the discourse features that were found useful for this task by<cite> Jansen et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_0",
  "x": "In the domain of text, many modern approaches often begin by embedding the input text data into an embedding space that is used as the first layer in a subsequent deep network [4] , [14] . These word embeddings have been shown to contain the same biases <cite>[3]</cite> , due to the source data from which they are trained. In effect, biases from the source data, such as in the differences in representation for men and women, that have been found in many different large-scale studies [5] , [10] , [12] , carry through to the semantic relations in the word embeddings, which become baked into the learning systems that are built on top of them.",
  "y": "motivation background"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_1",
  "x": "First we propose a new version of the Word Embedding Association Tests (WEATs) studied in <cite>[3]</cite> , designed to demonstrate and quantify bias in word embeddings, which puts them on a firm foundation by using the Linguistic Inquiry and Word Count (LIWC) lexica [17] to systematically detect and measure embedding biases. With this improved experimental setting, we find that European-American names are viewed more positively than African-American names, male names are more associated with work while female names are more associated with family, and that the academic disciplines of science and maths are more associated with male terms than the arts, which are more associated with female terms. Using this new methodology, we then find that there is a gender bias in the way different occupations are represented by the embedding.",
  "y": "motivation background differences"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_2",
  "x": "We first propose a new version of the Word Embedding Association Tests studied in <cite>[3]</cite> by using the LIWC lexica to systematically detect and measure the biases within the embedding, keeping the tests comparable with the same set of target words. We further extend this work using additional sets of target words, and compare sentiment across male and female names. Furthermore, we investigate gender bias in words that represent different occupations, comparing these associations with UK national employment statistics.",
  "y": "extends background"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_3",
  "x": "We begin by using the target words from <cite>[3]</cite> which were originally used in [8] , allowing us to directly compare our findings with the original WEAT. Our approach differs from that of <cite>[3]</cite> in that while we use the same set of target words in each test, we use an expanded set of attribute words, allowing us to perform a more rigorous, systematic study of the associations found within the word embeddings. For this, we use attribute words sourced from the LIWC lexica [17] .",
  "y": "extends"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_4",
  "x": "For each of the original word categories used in <cite>[3]</cite> , we matched them with their closest equivalent within the LIWC categories, for example matching the word lists for 'career' and 'family' with the 'work' and 'family' LIWC categories. We tested the association between each target word and the set of attribute words using the method described in Sec. II-B, focussing on the differences in association between sentimental terms and European-and African-American names, subject disciplines to each of the genders, career and family terms with gendered names, as well as looking at the association between gender and sentiment.",
  "y": "extends"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_5",
  "x": "Taking the list of target European-American and African-American names used in <cite>[3]</cite> , we tested each of them for their associated with the positive and negative emotion concepts found in [17] by using the methodology described by Eq. 3 in Sec. II-B, replacing the short list of words used to originally represent pleasant and unpleasant attribute sets.",
  "y": "uses"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_6",
  "x": "Our test found that while both European-American names and African-American names are more associated with positive emotions than negative emotions, the test showed that European-American names are more associated with positive emotions than their African-American counterparts, as shown in Fig. 1a . This finding supports the association test in <cite>[3]</cite> , where they also found that European-American names were more pleasant than African-American names.",
  "y": "similarities"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_8",
  "x": "3) Association of Gender with Career and Family : Taking the list of target gendered names used in <cite>[3]</cite> , we tested each of them for their associated with the career and family concepts using the categories of 'work' and 'family' found in LIWC [17] .",
  "y": "uses"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_9",
  "x": "As shown in Fig. 1c , we found that the set of male names was more associated with the concept of work, while the female names were more associated with family, mirroring the results found in <cite>[3]</cite> . Extending this test, we generated a much larger set of male and female target names from an online list of baby names 1 . Repeating the same test on this larger set of names, we found that male and female names were much less separated than suggested by previous results, with only minor differences between the two, as shown in Fig. 1d .",
  "y": "extends"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_10",
  "x": "We found that there is a strong, significant correlation (\u03c1 = 0.57, p-value < 10 \u22126 ) between the word embedding association between gender and occupation and the number of people of each gender in the United Kingdom working in those roles. This supports a similar finding for U.S. employment statistics using an independent set of occupations found in <cite>[3]</cite> .",
  "y": "background similarities"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_12",
  "x": "In this paper, we have introduced the LIWC-WEAT, a set of objective tests extending the association tests in <cite>[3]</cite> by using the LIWC lexica to measure bias within word embeddings.",
  "y": "motivation background"
 },
 {
  "id": "f2925513a7cce2e80ade1f948164d0_13",
  "x": "We found bias in both the associations of gender and race, as first described in <cite>[3]</cite> , while additionally finding that male names have a slightly higher positive association than female names. Biases found in the embedding were also shown to reflect biases in the real world and the media, where we found a correlation between the number of men and women in an occupation and its association with each set of male and female names.",
  "y": "differences background"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_1",
  "x": "These constraints can be lexicalized (Collins, 1999; Charniak, 2000) , unlexicalized (Johnson, 1998; Klein and Manning, 2003b) or automatically learned (Matsuzaki et al., 2005; <cite>Petrov et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_4",
  "x": "Computing the joint likelihood of the observed parse trees T and sentences w requires summing over all derivations t over split subcategories: Matsuzaki et al. (2005) derive an EM algorithm for maximizing the joint likelihood, and<cite> Petrov et al. (2006)</cite> extend this algorithm to use a split&merge procedure to adaptively determine the optimal number of subcategories for each observed category.",
  "y": "background"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_5",
  "x": "While the split&merge procedure described above is shown in<cite> Petrov et al. (2006)</cite> to reduce the variance in final performance, we found after closer examination that there are substantial differences in the patterns learned by the grammars.",
  "y": "differences"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_6",
  "x": "In previous work<cite> (Petrov et al., 2006</cite>; Petrov and Klein, 2007 ) the final grammar was chosen based on its performance on a held-out set (section 22), and corresponds to the second best grammar in Figure 3 (because only 8 different grammars were trained).",
  "y": "background"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_7",
  "x": "Using weights learned on a held-out set and rescoring 50-best lists from Charniak (2000) and<cite> Petrov et al. (2006)</cite> , they obtain an F 1 score of 91.0 (which they further improve to 91.4 using a voting scheme).",
  "y": "background"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_8",
  "x": "The parameters of each latent variable grammar are typically smoothed in a linear fashion to prevent excessive overfitting<cite> (Petrov et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "f2db88c0d4e0ec4c34fc295a5d59ba_9",
  "x": "It is also interesting to note that the best results in Zhang et al. (2009) are achieved by combining kbest lists from a latent variable grammar of<cite> Petrov et al. (2006)</cite> with the self-trained reranking parser of McClosky et al. (2006) .",
  "y": "background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_0",
  "x": "In this paper, we followed the line of predicting ICD codes from unstructured text of the MIMIC dataset (Johnson et al. 2016 ), because it is widely studied and publicly available. The state-of-the-art model for this line of work is the combination of the convolutional neural network (CNN) and the attention mechanism<cite> (Mullenbach et al. 2018)</cite> . However, this model only contains one convolutional layer to build document representations for subsequent layers to predict ICD codes.",
  "y": "motivation background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_1",
  "x": "Our Mul-arXiv:1912.00862v1 [cs.CL] 25 Nov 2019 tiResCNN model is composed of five layers: the input layer leverages word embeddings pre-trained by word2vec (Mikolov et al. 2013) ; the multi-filter convolutional layer consists of multiple convolutional filters (Kim 2014); the residual convolutional layer contains multiple residual blocks (He et al. 2016) ; the attention layer keeps the interpretability for the model following<cite> (Mullenbach et al. 2018)</cite> ; the output layer utilizes the sigmoid function to predict the probability of each ICD code.",
  "y": "similarities background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_2",
  "x": "To evaluate our model, we employed the MIMIC dataset (Johnson et al. 2016 ) which has been widely used for automated ICD coding. Compared with 5 existing and stateof-the-art models (Perotte et al. 2013; Prakash et al. 2017; Shi et al. 2017; Baumel et al. 2018;<cite> Mullenbach et al. 2018)</cite> , our model outperformed them in nearly all the evaluation metrics (i.e., macro-and micro-AUC, macro-and micro-F1, precision at K).",
  "y": "background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_3",
  "x": "<cite>Mullenbach et al. (2018)</cite> incorporated the convolutional neural network (CNN) with per-label attention mechanism. Their model achieved the state-of-the-art performance among the work using only unstructured text of the MIMIC dataset.",
  "y": "background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_4",
  "x": "Following <cite>Mullenbach et al. (2018)</cite> , we employed the perlabel attention mechanism to make each ICD code attend to different parts of the document representation H. The attention layer is formalized as: where U \u2208 R (m\u00d7d p )\u00d7l represents the parameter matrix of the attention layer, A \u2208 R n\u00d7l represents the attention weights for each pair of an ICD code and a word, V \u2208 R l\u00d7(m\u00d7d p ) represents the output of the attention layer.",
  "y": "uses"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_5",
  "x": "For training, we treated the ICD coding task as a multi-label classification problem following previous work (McCallum 1999;<cite> Mullenbach et al. 2018)</cite> . The training objective is to minimize the binary cross entropy loss between the prediction\u1ef9 and the target y: where w denotes the input word sequence and \u03b8 denotes all the parameters.",
  "y": "uses"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_6",
  "x": "Following <cite>Mullenbach et al. (2018)</cite> , we used discharge summaries, split them by patient IDs, and conducted experiments using the full codes as well as the top-50 most frequent codes.",
  "y": "uses"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_8",
  "x": "Preprocessing Following previous work<cite> (Mullenbach et al. 2018)</cite> , the text was tokenized, and each token were transformed into its lowercase. The tokens that contain no alphabetic characters were removed such as numbers and punctuations. The maximum length of a token sequence is 2,500 and the one that exceeds this length will be truncated.",
  "y": "uses"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_9",
  "x": "Since our model has a number of hyper-parameters, it is infeasible to search optimal values for all hyper-parameters. Therefore, some hyper-parameter values were chosen empirically or following prior work<cite> (Mullenbach et al. 2018</cite> ).",
  "y": "uses background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_10",
  "x": "\u2022 CNN, which only has one convolutional filter and is equivalent to the CAML model<cite> (Mullenbach et al. 2018</cite> ).",
  "y": "uses"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_11",
  "x": "CAML & DR-CAML The Convolutional Attention network for Multi-Label classification (CAML) was proposed by <cite>Mullenbach et al. (2018)</cite> . It has achieved the state-of-theart results on the MIMIC-III and MIMIC-II datasets among the models using unstructured text. It consists of one convolutional layer and one attention layer to generate label-aware features for multi-label classification (McCallum 1999). The Description Regularized CAML (DR-CAML) is an extension of CAML and incorporates the text description of each code to regularize the model.",
  "y": "background"
 },
 {
  "id": "f2ff155003d139b3677f746baf3807_13",
  "x": "For CAML, we used the optimal hyper-parameter setting reported in their paper<cite> (Mullenbach et al. 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_0",
  "x": "The past work in sarcasm detection involves rule-based and statistical approaches using: (a) unigrams and pragmatic features (such as emoticons, etc.) (Gonzalez-Ibanez et al., 2011; Carvalho et al., 2009; Barbieri et al., 2014) , (b) extraction of common patterns, such as hashtag-based sentiment (Maynard and Greenwood, 2014; Liebrecht et al., 2013) , a positive verb being followed by a negative situation<cite> (Riloff et al., 2013)</cite> , or discriminative n-grams (Tsur et al., 2010a; Davidov et al., 2010) .",
  "y": "background"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_1",
  "x": "\u2022 Our sarcasm detection system outperforms two state-of-art sarcasm detection systems <cite>(Riloff et al., 2013</cite>; Maynard and Greenwood, 2014) .",
  "y": "differences"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_2",
  "x": "Our feature engineering is based on<cite> Riloff et al. (2013)</cite> and Ramteke et al. (2013) .",
  "y": "similarities uses"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_3",
  "x": "For this, we modify the algorithm given in<cite> Riloff et al. (2013)</cite> in two ways: (a) they extract only positive verbs and negative noun situation phrases.",
  "y": "extends differences"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_4",
  "x": "2. Tweet-B (2278 tweets, 506 sarcastic): This dataset was manually labeled for<cite> Riloff et al. (2013</cite> To extract the implicit incongruity features, we run the iterative algorithm described in Section 4.2, on a dataset of 4000 tweets (50% sarcastic) (also created using hashtag-based supervision).",
  "y": "uses similarities"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_5",
  "x": "Table 2 : Comparative results for Tweet-A using rule-based algorithm and statistical classifiers using our feature combinations 6 Evaluation Table 2 shows the performance of our classifiers in terms of Precision (P), Recall (R) and F-score<cite> Riloff et al. (2013)</cite> 's two rule-based algorithms: the ordered version predicts a tweet as sarcastic if it has a positive verb phrase followed by a negative situation/noun phrase, while the unordered does so if the two are present in any order. We see that all statistical classifiers surpass the rule-based algorithms.",
  "y": "differences"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_6",
  "x": "This is an improvement of about 5% over the baseline, and 40% over the algorithm by<cite> Riloff et al. (2013)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_7",
  "x": "Table 4 shows that we achieve a 10% higher F-score than the best reported F-score of<cite> Riloff et al. (2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "f3012301e42a4075ed6d4d2b39b528_8",
  "x": "Our system also outperforms two past works <cite>(Riloff et al., 2013</cite>; Maynard and Greenwood, 2014) with 10-20% improvement in F-score.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_0",
  "x": "Following <cite>Gong et al. (2018)</cite> , we consider two document collections heterogeneous if <cite>their</cite> documents differ systematically with respect to vocabulary and / or level of abstraction. With these defining differences, there often also comes a difference in length, which, however, by itself does not make document collections heterogeneous.",
  "y": "background motivation"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_1",
  "x": "We demonstrate our method with the Concept-Project matching task (<cite>Gong et al. (2018)</cite> ), which is described in the next section.",
  "y": "uses"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_2",
  "x": "The annotation was done by undergrad engineering students. <cite>Gong et al. (2018)</cite> do not provide any specification, or annotation guidelines, of the semantics of the 'matches' relation to be annotated. Instead, <cite>they</cite> create gold standard annotations based on a majority vote of three manual annotations.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_3",
  "x": "The extent to which this information is used by <cite>Gong et al. (2018)</cite> is not entirely clear, so we experiment with several setups (cf. Section 4).",
  "y": "extends motivation"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_4",
  "x": "**<cite>GONG ET AL. (2018)</cite>'S APPROACH** The approach by <cite>Gong et al. (2018)</cite> is based on the idea that the longer document in the pair is reduced to a set of topics which capture the essence of the document in a way that eliminates the effect of a potential length difference.",
  "y": "background"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_5",
  "x": "<cite>Gong et al. (2018)</cite> motivate <cite>their</cite> approach mainly with the length mismatch argument, which <cite>they</cite> claim makes approaches relying on document representations (incl. vector averaging) unsuitable.",
  "y": "background"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_6",
  "x": "Accordingly, <cite>they</cite> use Doc2Vec (Le and Mikolov (2014) ) as one of their baselines, and show that its performance is inferior to <cite>their</cite> method.",
  "y": "background"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_7",
  "x": "<cite>They</cite> do not, however, provide a much simpler averaging-based baseline.",
  "y": "background"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_8",
  "x": "As a second baseline, <cite>they</cite> use Word Mover's Distance (Kusner et al. (2015) ), which is based on word-level distances, rather than distance of global document representations, but which also fails to be competitive with <cite>their</cite> topic-based method.",
  "y": "background"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_9",
  "x": "<cite>Gong et al. (2018)</cite> use two different sets of word embeddings: One (topic wiki) was trained on a full English Wikipedia dump, the other (wiki science) on a smaller subset of the former dump which only contained science articles.",
  "y": "background"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_10",
  "x": "We implement this standard measure (AVG COS SIM) as a baseline for both our method and for the method by <cite>Gong et al. (2018)</cite> .",
  "y": "extends"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_11",
  "x": "Parameter tuning experiments were performed on a random subset of 20% of our data set (54% positive). Note that <cite>Gong et al. (2018)</cite> used only 10% of <cite>their</cite> 537 instances data set as tuning data.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_12",
  "x": "Since the original data split used by <cite>Gong et al. (2018)</cite> is unknown, we cannot exactly replicate <cite>their</cite> settings, but we also perform ten runs using randomly selected 10% of our 408 instances test data set, and report average P, R, F, and standard deviation.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_14",
  "x": "Note that our Both setting is probably the one most similar to the concept input used by <cite>Gong et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_15",
  "x": "This result corroborates our findings on the tuning data, and clearly contradicts the (implicit) claim made by <cite>Gong et al. (2018)</cite> regarding the infeasibility of document-level matching for documents of different lengths.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_16",
  "x": "The second, more important finding is that our proposed TOP n COS SIM AVG measure is also very competitive, as it also outperforms both systems by <cite>Gong et al. (2018)</cite> in two out of three settings.",
  "y": "similarities"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_17",
  "x": "8 This is the more important as we exclusively employ off-the-shelf, general-purpose embeddings, while <cite>Gong et al. (2018)</cite> reach <cite>their</cite> best results with a much more sophisticated system and with embeddings that were custom-trained for the science domain.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_18",
  "x": "Thus, while the performance of our proposed TOP n COS SIM AVG method is superior to the approach by <cite>Gong et al. (2018)</cite> , it is itself outperformed by the 'baseline' AVG COS SIM method with appropriate weighting.",
  "y": "differences"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_19",
  "x": "We presented a simple method for semantic matching of documents from heterogeneous collections as a solution to the Concept-Project matching task by <cite>Gong et al. (2018)</cite> .",
  "y": "motivation"
 },
 {
  "id": "f3282df3adadf78320e99c09d8384f_20",
  "x": "Another result is that, contrary to the claim made by <cite>Gong et al. (2018)</cite> , the standard averaging approach does indeed work very well even for heterogeneous document collections, if appropriate weighting is applied.",
  "y": "differences"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_0",
  "x": "Section 3 then empirically analyzes correlations in two recent argument corpora, one annotated for 15 well-defined quality dimensions taken from theory (Wachsmuth et al., 2017a) and one with 17 reasons for quality differences phrased spontaneously in practice<cite> (Habernal and Gurevych, 2016a)</cite> .",
  "y": "background"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_1",
  "x": "Conv A is more convincing than B. Table 2 : The 17+1 practical reason labels given in the corpus of <cite>Habernal and Gurevych (2016a)</cite> .",
  "y": "background"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_2",
  "x": "Without giving any guidelines, the authors also asked for reasons as to why A is more convincing than B. In a follow-up study<cite> (Habernal and Gurevych, 2016a)</cite> , these reasons were used to derive a hierarchical annotation scheme.",
  "y": "background"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_3",
  "x": "9111 argument pairs were then labeled with one or more of the 17 reason labels in Table 2 Negative Properties of Argument B Positive Properties of Argument A Quality Dimension 5-1 5-2 5-3 6-1 6-2 6-3 7-1 7-2 7-3 7-4 8-1 8-4 8-5 9-1 9-2 9-3 9- Wachsmuth et al. (2017a) given for each of the 17+1 reason labels of <cite>Habernal and Gurevych (2016a)</cite> .",
  "y": "background"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_4",
  "x": "For Hypotheses 1 and 2, we consider all 736 pairs of arguments from <cite>Habernal and Gurevych (2016a)</cite> where both have been annotated by Wachsmuth et al. (2017a) .",
  "y": "similarities uses"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_5",
  "x": "Besides, the descriptions of 6-2 and 6-3 sound like local but cor- Table 4 : The mean rating for each quality dimension of those arguments from Wachsmuth et al. (2017a) given for each reason label<cite> (Habernal and Gurevych, 2016a)</cite> .",
  "y": "background"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_6",
  "x": "For explicitness, we computed the mean rating for each quality dimension of all arguments from Wachsmuth et al. (2017a) with a particular reason label from <cite>Habernal and Gurevych (2016a)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_7",
  "x": "3 Also, Table 4 reveals which reasons predict absolute differences most: The mean ratings of 7-3 (off-topic) are very low, indicating a strong negative impact, while 6-3 (irrelevant reasons) still shows rather 3 While the differences seem not very large, this is expected, as in many argument pairs from <cite>Habernal and Gurevych (2016a)</cite> both arguments are strong or weak respectively.",
  "y": "background"
 },
 {
  "id": "f3f61d50929f862e263e3f658852bc_8",
  "x": "Regarding simplification, the most common practical reasons of <cite>Habernal and Gurevych (2016a)</cite> imply what to focus on.",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_0",
  "x": "Recently, there has been much interest in applying neural network models to solve the problem, where little or no linguistic analysis is performed except for tokenization<cite> (Filippova et al., 2015</cite>; Rush et al., 2015; Chopra et al., 2016) .",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_1",
  "x": "For example,<cite> Filippova et al. (2015)</cite> used close to two Figure 1 : Examples of in-domain and out-ofdomain results by a standard abstractive sequenceto-sequence model trained on the Gigaword corpus.",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_2",
  "x": "Although neural network-based models have achieved good performance on this task recently, they tend to suffer from two problems: (1) They require a large amount of data for training. For example,<cite> Filippova et al. (2015)</cite> used close to two Figure 1 : Examples of in-domain and out-ofdomain results by a standard abstractive sequenceto-sequence model trained on the Gigaword corpus.",
  "y": "background motivation"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_3",
  "x": "To this end, we extend the deletionbased LSTM model for sentence compression by<cite> Filippova et al. (2015)</cite> .",
  "y": "extends"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_4",
  "x": "Specifically, we propose two major changes to the model by<cite> Filippova et al. (2015)</cite> : (1) We explicitly introduce POS embeddings and dependency relation embeddings into the neural network model.",
  "y": "extends"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_5",
  "x": "We evaluate our method using around 10,000 sentence pairs released by<cite> Filippova et al. (2015)</cite> and two other data sets representing out-ofdomain data.",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_6",
  "x": "Our problem setup is the same as that by<cite> Filippova et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_7",
  "x": "This base model is largely based on the model by<cite> Filippova et al. (2015)</cite> with some differences, which will be explained below.",
  "y": "uses differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_8",
  "x": "Following<cite> Filippova et al. (2015)</cite> , our bi-LSTM has three layers, as shown in Figure 2 .",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_9",
  "x": "There are some differences between our base model and the LSTM model by<cite> Filippova et al. (2015)</cite> .",
  "y": "differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_10",
  "x": "(1)<cite> Filippova et al. (2015)</cite> first encoded the input sentence in its reverse order using the same LSTM before processing the sentence for sequence labeling.",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_11",
  "x": "There are some differences between our base model and the LSTM model by<cite> Filippova et al. (2015)</cite> . (1)<cite> Filippova et al. (2015)</cite> first encoded the input sentence in its reverse order using the same LSTM before processing the sentence for sequence labeling.",
  "y": "differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_12",
  "x": "(2)<cite> Filippova et al. (2015)</cite> used only a single-directional LSTM while we use bi-LSTM to capture contextual information from both directions.",
  "y": "differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_13",
  "x": "(3) Although<cite> Filippova et al. (2015)</cite> did not use any syntactic information in their basic model, they introduced some features based on dependency parse trees in their advanced models.",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_14",
  "x": "There are some differences between our base model and the LSTM model by<cite> Filippova et al. (2015)</cite> . (3) Although<cite> Filippova et al. (2015)</cite> did not use any syntactic information in their basic model, they introduced some features based on dependency parse trees in their advanced models.",
  "y": "differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_15",
  "x": "(4)<cite> Filippova et al. (2015)</cite> combined the predicted y i\u22121 with w i to help predict y i .",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_16",
  "x": "(4)<cite> Filippova et al. (2015)</cite> combined the predicted y i\u22121 with w i to help predict y i . This adds some dependency between consecutive labels. We do not do this because later we will introduce an ILP layer to introduce dependencies among labels.",
  "y": "differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_17",
  "x": "For example, the method above as well as the original method by<cite> Filippova et al. (2015)</cite> cannot impose any length constraint on the compressed sentences.",
  "y": "motivation"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_18",
  "x": "Google News: The first dataset contains 10,000 sentence pairs collected and released by<cite> Filippova et al. (2015)</cite> 2 .",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_19",
  "x": "We compare our methods with a few baselines: LSTM: This is the basic LSTM-based deletion method proposed by<cite> (Filippova et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_20",
  "x": "LSTM+: This is advanced version of the model proposed by<cite> Filippova et al. (2015)</cite> , where the authors incorporated some dependency parse tree information into the LSTM model and used the prediction on the previous word to help the prediction on the current word.",
  "y": "background"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_21",
  "x": "We compare our methods with a few baselines: LSTM: This is the basic LSTM-based deletion method proposed by<cite> (Filippova et al., 2015)</cite> . LSTM+: This is advanced version of the model proposed by<cite> Filippova et al. (2015)</cite> , where the authors incorporated some dependency parse tree information into the LSTM model and used the prediction on the previous word to help the prediction on the current word.",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_22",
  "x": "We took the first 1,000 sentence pairs from Google News as the test set, following the same practice as<cite> Filippova et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_23",
  "x": "(2) In the in-domain setting, with the same amount of training data (8,000), our BiLSTM method with syntactic features (BiLSTM+SynFeat and BiLSTM+SynFeat+ILP) performs similarly to or better than the LSTM+ method proposed by<cite> Filippova et al. (2015)</cite> , in terms of both F1 and accuracy.",
  "y": "differences"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_24",
  "x": "In order to evaluate whether sentences generated by our method are readable, we adopt the manual evaluation procedure by<cite> Filippova et al. (2015)</cite> to compare our method with LSTM+ and Traditional ILP in terms of readability and informativeness.",
  "y": "uses"
 },
 {
  "id": "f4becae9cd7eeaa7fd3085ff904aaa_25",
  "x": "Our work is based on the deletion-based LSTM model for sentence compression by<cite> Filippova et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "f58555aa8fc78903df83af8309a3d7_0",
  "x": "Our representation model is built on the functionalities of Annotation Graph <cite>[7]</cite> and the underlying storage scheme is conceptually similar to Standoff XML format [9] , but we opted for a relational database structure built with an object-oriented design for efficiency, reusability and versatility.",
  "y": "uses differences"
 },
 {
  "id": "f58555aa8fc78903df83af8309a3d7_1",
  "x": "The tagger is built on a generic, multifunctional relational database similar to the annotation graph model <cite>[7]</cite> that has been demonstrated to be capable of representing virtually all sorts of common linguistic annotations.",
  "y": "similarities"
 },
 {
  "id": "f59a8c650583343fe372db42fc109a_0",
  "x": "We trained Transformer models <cite>(Vaswani et al., 2017)</cite> using Sockeye 1 (Hieber et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "f59a8c650583343fe372db42fc109a_1",
  "x": "Figure 1 (a) shows the structure of the standard Transformer translation model <cite>(Vaswani et al., 2017)</cite> and we removed the encoder and the attention layer in the decoder from the Transformer translation model to create our Transformer language model as shown in Figure 1 (b) .",
  "y": "extends"
 },
 {
  "id": "f59a8c650583343fe372db42fc109a_2",
  "x": "Then we randomly selected 10M sentences which contain difficult words for back-translation. The mod- els used for back-translating monolingual data are baseline Transformers <cite>(Vaswani et al., 2017)</cite> trained on the bilingual data after data selection as described before.",
  "y": "uses"
 },
 {
  "id": "f59a8c650583343fe372db42fc109a_3",
  "x": "The settings of Transformerbase is the same as the baseline Transformer in<cite> Vaswani et al. (2017)</cite> 's work.",
  "y": "similarities uses"
 },
 {
  "id": "f60796ff05156e81c4b183cdcb05ae_0",
  "x": "Similar experiments on using shared feature extraction layers for slot-filling across several domains have demonstrated significant performance improvements relative to single-domain baselines, especially in low data regimes<cite> [9]</cite> .",
  "y": "background"
 },
 {
  "id": "f60796ff05156e81c4b183cdcb05ae_1",
  "x": "All digits were replaced with special \"#\" tokens following<cite> [9]</cite> .",
  "y": "uses"
 },
 {
  "id": "f60796ff05156e81c4b183cdcb05ae_3",
  "x": "Both LSTM layers are shared across all domains, fol- lowed by domain specific softmax layers, following<cite> [9]</cite> .",
  "y": "uses"
 },
 {
  "id": "f6a35ed1ec0c01d3e9faa1ec3d8478_0",
  "x": "We build on previous work in our lab on disagreement detection, classifying stance, identifying high quality arguments, measuring the properties and the persuasive effects of factual vs. emotional arguments, and clustering arguments into their facets or frames related to a particular topic [9, 1, 13, 18, <cite>16,</cite> 12, 15] .",
  "y": "uses"
 },
 {
  "id": "f6a35ed1ec0c01d3e9faa1ec3d8478_1",
  "x": "Swanson et al.(2015) created a large corpus consisting of 109,074 posts on the topics gay marriage (GM, 22425 posts), gun control (GC, 38102 posts), death penalty (DP, 5283 posts) by combining the Internet Argument Corpus(IAC) [17] , with dialogues from online debate forums 1<cite> [16]</cite> .",
  "y": "background"
 },
 {
  "id": "f6a35ed1ec0c01d3e9faa1ec3d8478_2",
  "x": "We started with the Argument Quality (AQ) regressor from<cite> [16]</cite> , which predicts a quality score for each sentence.",
  "y": "uses"
 },
 {
  "id": "f6a35ed1ec0c01d3e9faa1ec3d8478_3",
  "x": "had improved upon the AQ predictor from<cite> [16]</cite> , giving a much larger and diverse corpus [12] .",
  "y": "extends"
 },
 {
  "id": "f7255360eacc4e2a4e8bea2f6ab1b0_0",
  "x": "<cite>Hearst (1997)</cite> and Nomoto and Nitta (1994) detect this coherence through patterns of lexical cooccurrence.",
  "y": "background"
 },
 {
  "id": "f7255360eacc4e2a4e8bea2f6ab1b0_1",
  "x": "A first qualitative evaluation of the method has been done with about 20 texts but without a formal protocol as in<cite> (Hearst, 1997)</cite> .",
  "y": "differences"
 },
 {
  "id": "f7255360eacc4e2a4e8bea2f6ab1b0_2",
  "x": "As in<cite> (Hearst, 1997)</cite> , boundaries found by the method are weighted and sorted in decreasing order.",
  "y": "uses"
 },
 {
  "id": "f7255360eacc4e2a4e8bea2f6ab1b0_3",
  "x": "Each boundary, which is a minimum of the cohesion graph, was weighted by the sum of the differences between its value and the values of the two maxima around it, as in<cite> (Hearst, 1997)</cite> .",
  "y": "uses"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_0",
  "x": "In <cite>Martschat and Strube (2014)</cite> , we propose a framework for error analysis for coreference resolution.",
  "y": "motivation"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_1",
  "x": "The idea underlying the analysis framework of <cite>Martschat and Strube (2014)</cite> is to employ spanning trees in a graph-based entity representation.",
  "y": "background"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_2",
  "x": "In <cite>Martschat and Strube (2014)</cite> , we propose an algorithm based on Ariel's accessibility theory (Ariel, 1990) for reference entities.",
  "y": "similarities uses"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_3",
  "x": "First, it includes multigraph, which is a deterministic approach using a few strong features<cite> (Martschat and Strube, 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_4",
  "x": "We already implemented the algorithms discussed in <cite>Martschat and Strube (2014)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_5",
  "x": "Our system also supports other use cases, such as the cross-system analysis described in <cite>Martschat and Strube (2014)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_6",
  "x": "Hence, following <cite>Martschat and Strube (2014)</cite> , we categorize all errors by coarse mention type of anaphor and antecedent (proper name, noun, pronoun, demonstrative pronoun or verb) 4 .",
  "y": "similarities uses"
 },
 {
  "id": "f797e7439bd78af2ef86271214f991_7",
  "x": "Compared to our original implementation of the error analysis framework<cite> (Martschat and Strube, 2014)</cite> , we made the analysis interface more userfriendly and provide more analysis functionality.",
  "y": "differences"
 },
 {
  "id": "f861e6590ff57225395e7d480c66e8_0",
  "x": "We start from a baseline joint model that performs the tasks of named entity recognition (NER) and relation extraction at once. Previously proposed models (summarized in Section 2) exhibit several issues that the neural network-based baseline approach (detailed in Section 3.1) overcomes: (i) our model uses automatically extracted features without the need of external parsers nor manually extracted features (see <cite>Gupta et al. (2016)</cite> ; Miwa and Bansal (2016) ; Li et al. (2017) ), (ii) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time (see Adel and Sch\u00fctze (2017) ), and (iii) we model relation extraction in a multi-label setting, allowing multiple relations per entity (see Katiyar and Cardie (2017) ; Bekoulis et al. (2018a) ).",
  "y": "motivation background"
 },
 {
  "id": "f861e6590ff57225395e7d480c66e8_1",
  "x": "Joint entity and relation extraction: Joint models (Li and Ji, 2014; Miwa and Sasaki, 2014) that are based on manually extracted features have been proposed for performing both the named entity recognition (NER) and relation extraction subtasks at once. These methods rely on the availability of NLP tools (e.g., POS taggers) or manually designed features leading to additional complexity. <cite>Gupta et al. (2016)</cite> propose the use of various manually extracted features along with RNNs.",
  "y": "motivation background"
 },
 {
  "id": "f861e6590ff57225395e7d480c66e8_2",
  "x": "For the CoNLL04 (Roth and Yih, 2004 ) EC task (assuming boundaries are given), we use the same splits as in <cite>Gupta et al. (2016)</cite> ; Adel and Sch\u00fctze (2017) .",
  "y": "uses"
 },
 {
  "id": "f861e6590ff57225395e7d480c66e8_3",
  "x": "For the CoNLL04 dataset, we use two evaluation settings. We use the relaxed evaluation similar to <cite>Gupta et al. (2016)</cite> ; Adel and Sch\u00fctze (2017) on the EC task. The baseline model outperforms the state-of-the-art models that do not rely on manually extracted features (>4% improvement for both tasks), since we directly model the whole sentence, instead of just considering pairs of entities.",
  "y": "uses differences"
 },
 {
  "id": "f881f6c65301fdfe2fffe7a18e05c4_0",
  "x": "Words and phrases that may directly mark the structure of a discourse have been termed CUE PttR.ASES, CLUE WORDS, DISCOURSE MAI:tKERS~ arid DISCOURSE PARTICLES [3,<cite> 4,</cite> 14, 17, 19] .",
  "y": "background"
 },
 {
  "id": "f881f6c65301fdfe2fffe7a18e05c4_1",
  "x": "For example, by indicating the presence of a structural boundary or a relationship between parts of a discourse, cue phrases caa assist in the resolution of anaphora [5,<cite> 4,</cite> 17] and in the identification of rhetorical relations [10, 12, 17] .",
  "y": "background"
 },
 {
  "id": "f881f6c65301fdfe2fffe7a18e05c4_2",
  "x": "Grosz and Sidner<cite> [4]</cite> classify cue phrases based on changes to the attentional stack and intentional structure found in their theory of discourse.",
  "y": "background"
 },
 {
  "id": "f881f6c65301fdfe2fffe7a18e05c4_3",
  "x": "Once a cue phrase has been identified, however, it is not always clear whether to interpret it as a discourse marker or not [6,<cite> 4,</cite> 8, 18] .",
  "y": "background"
 },
 {
  "id": "f881f6c65301fdfe2fffe7a18e05c4_4",
  "x": "8Our set of cue phrases was derived from extensional definitions provided by ourselves and othel~ [3,<cite> 4,</cite> 17, 18, 21] .",
  "y": "extends differences"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_0",
  "x": "For example, systems have learned to commentate simulated robot soccer games by learning from sample sportscasts (Chen and Mooney, 2008; Liang et al., 2009; <cite>B\u00f6rschinger et al., 2011)</cite> , or understand navigation instructions by learning from action traces produced when following the directions (Chen and Mooney, 2011; Tellex et al., 2011) .",
  "y": "background"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_1",
  "x": "Our approach extends that of<cite> B\u00f6rschinger et al. (2011)</cite> , which in turn was inspired by a series of previous techniques (Lu et al., 2008; Liang et al., 2009; following the idea of constructing correspondences between NL and MR in a single probabilistic generative framework.",
  "y": "extends"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_2",
  "x": "2 Like<cite> B\u00f6rschinger et al. (2011)</cite> , our approach learns a semantic parser directly from ambiguous supervision, specifically NL instructions paired with their complete landmarks plans as context.",
  "y": "similarities uses"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_3",
  "x": "We basically follow the scheme of<cite> B\u00f6rschinger et al. (2011)</cite> , but instead of generating NL words from each atomic MR, words are generated from each lexeme MR, Figure 6 : Summary of the rule generation process.",
  "y": "extends differences"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_4",
  "x": "Lexeme rules come from the schemata of<cite> B\u00f6rschinger et al. (2011)</cite> , and allow every lexeme MR to generate one or more NL words.",
  "y": "uses"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_5",
  "x": "After traversing all of its children, 5 We used the implementation available at http://web. science.mq.edu.au/\u02dcmjohnson/Software.htm which was also used by<cite> B\u00f6rschinger et al. (2011)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_6",
  "x": "Our approach improves on<cite> B\u00f6rschinger et al. (2011)</cite> 's method in the following ways:",
  "y": "extends"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_7",
  "x": "A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; <cite>B\u00f6rschinger et al., 2011)</cite> assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence.",
  "y": "background"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_8",
  "x": "As previously discussed,<cite> B\u00f6rschinger et al. (2011)</cite> use a PCFG generative model and also train it on ambiguous data using EM.",
  "y": "background"
 },
 {
  "id": "f8fc3634684ff37ab3d29cee910443_9",
  "x": "Our model enhances<cite> B\u00f6rschinger et al. (2011)</cite> 's approach to reducing the problem of grounded learning of semantic parsers to PCFG induction.",
  "y": "extends"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_0",
  "x": "Large pre-trained language models (Peters et al., 2018; Radford et al., 2018; Devlin et al., 2019;<cite> Yang et al., 2019</cite>; improved the state-of-the-art of various natural language understanding (NLU) tasks such as question answering (e.g., SQuAD; Rajpurkar et al. 2016) , natural language inference (e.g., MNLI; Bowman et al. 2015) as well as text classification (Zhang et al., 2015) .",
  "y": "background"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_2",
  "x": "As mentioned earlier, we can take advantage of recent pre-trained Transformer encoders for the document encoding part as in<cite> Liu and Lapata (2019)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_3",
  "x": "As mentioned earlier, we can take advantage of recent pre-trained Transformer encoders for the document encoding part as in<cite> Liu and Lapata (2019)</cite> . However,<cite> Liu and Lapata (2019)</cite> leave the decoder randomly initialized.",
  "y": "differences"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_4",
  "x": "Very recently, the feature learning part was replaced again with pretrained transformers (Zhang et al., 2019;<cite> Liu and Lapata, 2019</cite> ) that lead to another huge improvement of summarization performance.",
  "y": "background"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_5",
  "x": "Following previous work (See et al., 2017; Zhang et al., 2019;<cite> Liu and Lapata, 2019)</cite> , we use the non-anonymized version of CNNDM.",
  "y": "uses"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_6",
  "x": "We closely follow the preprocessing procedures described in Durrett et al. (2016) and<cite> Liu and Lapata (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_9",
  "x": "BERTExt<cite> (Liu and Lapata, 2019</cite> ) is an extractive model fine-tuning on BERT (Devlin et al., 2019) that outperforms other extractive systems.",
  "y": "background"
 },
 {
  "id": "fa00b8bac394b48bf950f154c65216_10",
  "x": "BERTAbs<cite> (Liu and Lapata, 2019)</cite> and UniLM (Dong et al., 2019) are both pre-training based SEQ2SEQ summarization models.",
  "y": "background"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_0",
  "x": "Even with recent progress (Gehrmann et al., 2018;<cite> Chen and Bansal, 2018)</cite> , there is still some work to be done in the field.",
  "y": "motivation"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_1",
  "x": "Nonetheless remarkable progress have been achieved with the use of seq2seq models (Gehrmann et al., 2018; See et al., 2017; Chopra et al., 2016; Rush et al., 2015) and a reward instead of loss function via deep-reinforcement learning<cite> (Chen and Bansal, 2018</cite>; Paulus et al., 2017; Ranzato et al., 2015) .",
  "y": "background"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_2",
  "x": "We see abstractive summarization in same light as several other authors<cite> (Chen and Bansal, 2018</cite>; Hsu et al., 2018; Liu et al., 2018 ) -extract salient sentences and then abstract; thus sharing similar advantages as the popular divide-and-conquer algorithm.",
  "y": "uses"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_3",
  "x": "Hence it is customary to create one from the abstractive ground-truth summaries<cite> (Chen and Bansal, 2018</cite>; Nallapati et al., 2017) .",
  "y": "uses"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_4",
  "x": "Different from Nallapati et al. (2017) 's approach to greedily add sentences to the summary that maximizes the ROUGE score, our approach is more similar to <cite>Chen and Bansal (2018)</cite>'s model that calculates the individual reference sentence-level score as per its similarity with each sentence in the corresponding document.",
  "y": "similarities"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_5",
  "x": "for each t th sentence in the reference summary, R j , per i th sentence in document D j , in contrast to <cite>Chen and Bansal (2018)</cite> 's that uses ROUGE-L recall score.",
  "y": "differences"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_6",
  "x": "<cite>Chen and Bansal (2018)</cite> introduced a stop criterion in their reinforcement learning process.",
  "y": "background"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_9",
  "x": "Following previous works (See et al., 2017; Nallapati et al., 2017;<cite> Chen and Bansal, 2018)</cite> , we evaluate both datasets on standard ROUGE-1, ROUGE-2 and ROUGE-L (Lin, 2004) .",
  "y": "uses"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_10",
  "x": "Some authors have employed integer linear programming (Martins and Smith, 2009; Gillick and Favre, 2009; Boudin et al., 2015) , graph concepts (Erkan and Radev, 2004; , ranking with reinforcement learning (Narayan et al., 2018) and mostly related to our work -binary classification (Shen et al., 2007; Nallapati et al., 2017;<cite> Chen and Bansal, 2018)</cite> Our binary classification architecture differs significantly from existing models because it uses a transformer as the building block instead of a bidirectional GRU-RNN (Nallapati et al., 2017) , or bidirectional LSTM-RNN<cite> (Chen and Bansal, 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "fa3d20d5975ec59454abfca68f8935_11",
  "x": "Similar to Rush et al. (2015) ; <cite>Chen and Bansal (2018)</cite> we abstract by simplifying our extracted sentences.",
  "y": "similarities"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_0",
  "x": "Recent studies on KD<cite> [33,</cite> 15] even leverage more sophisticated model-specific distillation loss functions for better performance.",
  "y": "background"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_1",
  "x": "Recent studies on KD<cite> [33,</cite> 15] even leverage more sophisticated model-specific distillation loss functions for better performance. Different from previous KD studies which explicitly exploit a distillation loss to minimize the distance between the teacher model and the student model, we propose a new genre of model compression.",
  "y": "differences"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_2",
  "x": "Also, selecting various loss functions and balancing the weights of each loss for different tasks and datasets are always laborious<cite> [33,</cite> 28] .",
  "y": "background"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_3",
  "x": "The use of only one loss function throughout the whole compression process allows us to unify the different phases and keep the compression in a total end-to-end fashion. Also, selecting various loss functions and balancing the weights of each loss for different tasks and datasets are always laborious<cite> [33,</cite> 28] .",
  "y": "differences"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_4",
  "x": "Patient Knowledge Distillation (PKD)<cite> [33]</cite> designs multiple distillation losses between the module hidden states of the teacher and student models.",
  "y": "background"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_5",
  "x": "However, the performance greatly relies on the design of the loss function [14,<cite> 33,</cite> 15] .",
  "y": "background"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_6",
  "x": "This loss function needs to be combined with taskspecific loss<cite> [33,</cite> 17] .",
  "y": "background"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_7",
  "x": "We test our approach under a task-specific compression setting<cite> [33,</cite> 37] instead of a pretraining compression setting [28, 34] .",
  "y": "uses"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_8",
  "x": "Formally, we define the task of compression as trying to retain as much performance as possible when compressing the officially released BERT-base (uncased) 5 to a 6-layer compact model with the same hidden size, following the settings in [28,<cite> 33,</cite> 37] .",
  "y": "uses"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_9",
  "x": "As a result, we are able to obtain a predecessor model with comparable performance with that reported in previous studies [28,<cite> 33,</cite> 15] .",
  "y": "similarities"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_10",
  "x": "Afterward, for training successor models, following [28, <cite>33]</cite> , we use the first 6 layers of BERT-base to initialize the successor model since the over-parameterized nature of Transformer [38] could cause the model unable to converge while training on small datasets.",
  "y": "uses"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_11",
  "x": "We set up a baseline of vanilla Knowledge Distillation [14] as in<cite> [33]</cite> .",
  "y": "uses"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_12",
  "x": "Under the setting of compressing 12-layer BERT-base to a 6-layer compact model, we choose BERT-PKD<cite> [33]</cite> , PD-BERT [37] , and DistillBERT [28] as strong baselines.",
  "y": "uses"
 },
 {
  "id": "fa7475b6025d010dd6814dfb3905ef_13",
  "x": "Also, our model obviously outperforms the vanilla KD [14] and Patient Knowledge Distillation (PKD)<cite> [33]</cite> , showing its supremacy over the KD-based compression approaches.",
  "y": "differences"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_0",
  "x": "Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001;<cite> Koeling et al., 2005)</cite> .",
  "y": "background"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_1",
  "x": "<cite>Koeling et al. (2005)</cite> present a corpus were the examples are drawn from the balanced BNC corpus (Leech, 1992) and the SPORTS and FINANCES sections of the newswire Reuters corpus (Rose et al., 2002) , comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns.",
  "y": "background"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_2",
  "x": "In (Agirre and Lopez de Lacalle, 2008) , the authors also show that state-of-the-art WSD systems are not able to adapt to the domains in the context of the <cite>Koeling et al. (2005)</cite> dataset.",
  "y": "background"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_3",
  "x": "In contrast, ) reimplemented this method and showed that the improvement on WSD in the<cite> (Koeling et al., 2005)</cite> data was marginal.",
  "y": "background"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_4",
  "x": "In ) the authors report successful adaptation on the<cite> (Koeling et al., 2005</cite> ) dataset on supervised setting.",
  "y": "background"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_5",
  "x": "The predominant sense acquisition method was succesfully applied to specific domains in<cite> (Koeling et al., 2005)</cite> .",
  "y": "uses"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_6",
  "x": "When a general corpus is used, the most predominant sense in general is obtained, and when a domain-specific corpus is used, the most predominant sense for that corpus is obtained<cite> (Koeling et al., 2005)</cite> .",
  "y": "background"
 },
 {
  "id": "fb75198b7c9e569932dfd486ba6c0a_7",
  "x": "When a general corpus is used, the most predominant sense in general is obtained, and when a domain-specific corpus is used, the most predominant sense for that corpus is obtained<cite> (Koeling et al., 2005)</cite> . The main motivation of the authors is that the most frequent sense is a very powerful baseline, but it is one which requires hand-tagging text, while their method yields similar information automatically.",
  "y": "similarities"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_0",
  "x": "Lexical Simplification (LS) aims at replacing complex words with simpler alternatives, which can help various groups of people, including children [De Belder and Moens, 2010] , non-native speakers<cite> [Paetzold and Specia, 2016]</cite> , people with cognitive disabilities [Feng, 2009; Saggion, 2017] , to understand text better.",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_1",
  "x": "For avoiding the need for resources such as databases or parallel corpora, recent work utilizes word embedding models to extract simplification candidates for complex words [Glava\u0161 and\u0160tajner, 2015;<cite> Paetzold and Specia, 2016</cite>; <cite>Paetzold and Specia, 2017a]</cite> .",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_2",
  "x": "Given one sentence \"John composed these verses.\" and complex words 'composed' and 'verses', the top three simplification candidates for each complex word are generated by our method BERT-LS and the state-of-the-art two baselines based word embeddings (Glava\u0161[Glava\u0161 and\u0160tajner, 2015] and Paetzold-NE<cite> [Paetzold and Specia, 2017a]</cite> ).",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_3",
  "x": "original word embeddings trained on text, and<cite> Paetzold et al. (2017)</cite> used a retrofitted context-aware word embedding model trained on text with the POS tag.",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_4",
  "x": "For complex words 'composed' and 'verses' in the sentence \"John composed these verses.\", the top three substitution candidates of the two complex words generated by the LS systems based on word embeddings [Glava\u0161 and\u0160tajner, 2015; <cite>Paetzold and Specia, 2017a]</cite> are only related with the complex words itself without without paying attention to the original sentence.",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_5",
  "x": "For complex words 'composed' and 'verses' in the sentence \"John composed these verses.\", the top three substitution candidates of the two complex words generated by the LS systems based on word embeddings [Glava\u0161 and\u0160tajner, 2015; <cite>Paetzold and Specia, 2017a]</cite> are only related with the complex words itself without without paying attention to the original sentence. The top three substitution candidates generated by BERT-LS are not only related with the complex words, but also can fit for the original sentence very well.",
  "y": "differences background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_6",
  "x": "Lexical simplification (LS) contains identifying complex words and finding the best candidate substitution for these complex words [Shardlow, 2014;<cite> Paetzold and Specia, 2017b]</cite> .",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_7",
  "x": "The popular lexical simplification (LS) approaches are rule-based, which each rule contain a complex word and its simple synonyms<cite> [Lesk, 1986</cite>; Pavlick and Callison-Burch, 2016;<cite> Maddela and Xu, 2018]</cite> .",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_8",
  "x": "Afterward, they further extracted candidates for complex word by combining word embeddings with WordNet and parallel corpora<cite> [Paetzold and Specia, 2017a]</cite> .",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_9",
  "x": "Afterward, they further extracted candidates for complex word by combining word embeddings with WordNet and parallel corpora<cite> [Paetzold and Specia, 2017a]</cite> . After examining existing LS methods ranging from rulesbased to embedding-based, the major challenge is that they generated simplification candidates for the complex word regardless of the context of the complex word, which will inevitably produce a large number of spurious candidates that can confuse the systems employed in the subsequent steps.",
  "y": "motivation background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_10",
  "x": "Afterward, they further extracted candidates for complex word by combining word embeddings with WordNet and parallel corpora<cite> [Paetzold and Specia, 2017a]</cite> . After examining existing LS methods ranging from rulesbased to embedding-based, the major challenge is that they generated simplification candidates for the complex word regardless of the context of the complex word, which will inevitably produce a large number of spurious candidates that can confuse the systems employed in the subsequent steps. In this paper, we will first present a BERT-based LS approach that requires only a sufficiently large corpus of regular text without any manual efforts.",
  "y": "motivation background differences"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_11",
  "x": "The substitution ranking of the lexical simplification pipeline is to decide which of the candidate substitutions that fit the context of a complex word is the simplest<cite> [Paetzold and Specia, 2017b]</cite>.",
  "y": "background"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_12",
  "x": "In this paper, we are not focused on identifying complex words<cite> [Paetzold and Specia, 2017b]</cite> , which is a separate task.",
  "y": "differences"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_14",
  "x": "We use three widely used lexical simplification datasets to do experiments. (2) BenchLS 6<cite> [Paetzold and Specia, 2016]</cite> .",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_15",
  "x": "We choose the following eight baselines to evaluation: Devlin [Devlin and Tait, 1998 ], Biran [Biran et al., 2011 ], Yamamoto [Kajiwara et al., 2013 , Horn [Horn et al., 2014] , Glava\u0161 [Glava\u0161 and\u0160tajner, 2015] , SimplePPDB [Pavlick and Callison-Burch, 2016] , Paetzold-CA<cite> [Paetzold and Specia, 2016]</cite> , and Paetzold-NE<cite> [Paetzold and Specia, 2017a]</cite> .",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_16",
  "x": "The following three widely used metrics are used for evaluation<cite> [Paetzold and Specia, 2015</cite>;<cite> Paetzold and Specia, 2016</cite>;<cite> Paetzold and Specia, 2017b]</cite> .",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_17",
  "x": "The results of the baselines on LexMTurk are from<cite> [Paetzold and Specia, 2017b]</cite> and the results on BenchLS and NNSeval are from<cite> [Paetzold and Specia, 2017a]</cite> .",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_18",
  "x": "The results of the baselines on LexMTurk are from<cite> [Paetzold and Specia, 2017b]</cite> and the results on BenchLS and NNSeval are from<cite> [Paetzold and Specia, 2017a]</cite> . As can be seen, despite being entirely unsupervised, our model BERT-LS obtains F1 scores on three 7 http://ghpaetzold.github.io/data/NNSeval.zip datasets, largely outperforming the previous best baselines.",
  "y": "differences"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_19",
  "x": "We chooses the state-of-the-art two baselines based word embeddings (Glava\u0161[Glava\u0161 and\u0160tajner, 2015] and Paetzold-NE<cite> [Paetzold and Specia, 2017a]</cite>) as comparison.",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_20",
  "x": "We chooses the state-of-the-art two baselines based word embeddings (Glava\u0161[Glava\u0161 and\u0160tajner, 2015] and Paetzold-NE<cite> [Paetzold and Specia, 2017a]</cite>) as comparison. From Table 2 , we observe that BERT-LS achieves the best simplification candidates for complex words compared with the two baselines based word embeddings.",
  "y": "differences"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_21",
  "x": "We adopt the following two well-known metrics used by these work [Horn et al., 2014;<cite> Paetzold and Specia, 2017b]</cite> .",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_22",
  "x": "The results of the baselines on LexMTurk are from<cite> [Paetzold and Specia, 2017b]</cite> and the results on BenchLS and NNSeval are from<cite> [Paetzold and Specia, 2017a]</cite> .",
  "y": "uses"
 },
 {
  "id": "fb87be2081ce1515dd8dbda46b4f3f_23",
  "x": "The results of the baselines on LexMTurk are from<cite> [Paetzold and Specia, 2017b]</cite> and the results on BenchLS and NNSeval are from<cite> [Paetzold and Specia, 2017a]</cite> . We can see that our method BERT-LS attains the highest Accuracy on three datasets, which has an average increase of 11.6% over the former state-of-theart baseline (Paetzold-NE).",
  "y": "differences"
 },
 {
  "id": "fbd028e073459b1b4c2d8d99173e15_0",
  "x": "On the FrameNet 1.5 data, presented additional semi-supervised experiments using gold targets, which was recently outperformed by an approach presented by <cite>Hermann et al. (2014)</cite> that made use of distributed word representations.",
  "y": "differences background"
 },
 {
  "id": "fbd028e073459b1b4c2d8d99173e15_1",
  "x": "On the FrameNet 1.5 data, presented additional semi-supervised experiments using gold targets, which was recently outperformed by an approach presented by <cite>Hermann et al. (2014)</cite> that made use of distributed word representations.",
  "y": "background differences"
 },
 {
  "id": "fbd028e073459b1b4c2d8d99173e15_2",
  "x": "Subsequently, <cite>Hermann et al. (2014)</cite> used a very similar framework but presented a novel method using distributed word representations for better frame identification, outperforming the aforementioned update to SEMAFOR.",
  "y": "differences"
 },
 {
  "id": "fbd028e073459b1b4c2d8d99173e15_3",
  "x": "For example, the training dataset used for the state-ofthe-art system of <cite>Hermann et al. (2014)</cite> contains only 4,458 labeled targets, which is approximately 40 times less than the number of annotated targets in Ontonotes 4.0 (Hovy et al., 2006) , a standard NLP dataset, containing PropBank-style verb annotations.",
  "y": "background"
 },
 {
  "id": "fbd028e073459b1b4c2d8d99173e15_4",
  "x": "Given the wide body of work in frame-semantic analysis of text, and recent interest in using framesemantic parsers in NLP applications, the future directions of research look exciting. First and foremost, to improve the quality of automatic frame-semantic parsers, the coverage of the FrameNet lexicon on free English text, and the number of annotated targets needs to increase. For example, the training dataset used for the state-ofthe-art system of <cite>Hermann et al. (2014)</cite> contains only 4,458 labeled targets, which is approximately 40 times less than the number of annotated targets in Ontonotes 4.0 (Hovy et al., 2006) , a standard NLP dataset, containing PropBank-style verb annotations.",
  "y": "background future_work"
 },
 {
  "id": "fc3775c0d23292160f5c5eb86861be_0",
  "x": "The dataset we used is a Romanian language resource containing a total of 480,722 inflected forms of Romanian nouns and adjectives. It was extracted from the text form of the morphological dictionary RoMorphoDict<cite> (Barbu, 2008)</cite> , which was also used by Nastase and Popescu (2009) for their Romanian classifier, where every entry has the following structure:",
  "y": "uses"
 },
 {
  "id": "fc4b56c865c8a9d0f6a7f5ae37ba96_0",
  "x": "Table 1 presents the statistics of the available training and LM corpora for the constrained (C) systems in WMT15 <cite>(Bojar et al., 2015)</cite> as well as the statistics of the ParFDA selected training and LM data.",
  "y": "uses"
 },
 {
  "id": "fc4b56c865c8a9d0f6a7f5ae37ba96_1",
  "x": "We run ParFDA SMT experiments using Moses (Koehn et al., 2007) in all language pairs in WMT15 <cite>(Bojar et al., 2015)</cite> and obtain SMT performance close to the top constrained Moses systems.",
  "y": "uses similarities"
 },
 {
  "id": "fc4b56c865c8a9d0f6a7f5ae37ba96_2",
  "x": "We run ParFDA SMT experiments for all language pairs in both directions in the WMT15 translation task <cite>(Bojar et al., 2015)</cite> , which include English-Czech (en-cs), English-German (en-de), English-Finnish (en-fi), English-French (en-fr), and English-Russian (en-ru).",
  "y": "uses"
 },
 {
  "id": "fc4b56c865c8a9d0f6a7f5ae37ba96_3",
  "x": "Table 1 presents the statistics of the available training and LM corpora for the constrained (C) systems in WMT15 <cite>(Bojar et al., 2015)</cite> as well as the statistics of the ParFDA selected training and LM data.",
  "y": "uses"
 },
 {
  "id": "fc4b56c865c8a9d0f6a7f5ae37ba96_4",
  "x": "We run ParFDA SMT experiments using Moses (Koehn et al., 2007) in all language pairs in WMT15 <cite>(Bojar et al., 2015)</cite> and obtain SMT performance close to the top constrained Moses systems.",
  "y": "uses"
 },
 {
  "id": "fc4b56c865c8a9d0f6a7f5ae37ba96_5",
  "x": "We run ParFDA SMT experiments for all language pairs in both directions in the WMT15 translation task <cite>(Bojar et al., 2015)</cite> , which include English-Czech (en-cs), English-German (en-de), English-Finnish (en-fi), English-French (en-fr), and English-Russian (en-ru).",
  "y": "uses"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_0",
  "x": "An end-to-end approach [1] [2] [3] [4] <cite>[5]</cite> [6] [7] is particularly appealing for source languages with no written form, or for endangered languages where translations into a high-resource language may be easier to collect than transcriptions [8] .",
  "y": "background"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_1",
  "x": "An end-to-end approach [1] [2] [3] [4] <cite>[5]</cite> [6] [7] is particularly appealing for source languages with no written form, or for endangered languages where translations into a high-resource language may be easier to collect than transcriptions [8] . However, building high-quality endto-end AST with little parallel data is challenging, and has led researchers to explore how other sources of data could be used to help.",
  "y": "background motivation"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_2",
  "x": "For example, Bansal et al. <cite>[5]</cite> showed that pre-training on either English or French ASR improved their Spanish-English AST system (trained on 20 hours of parallel data) and Tian [10] got improvements on an 8-hour Swahili-English AST dataset using English ASR pretraining.",
  "y": "background"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_3",
  "x": "To answer these questions, we use the same AST architecture and Spanish-English parallel data as Bansal et al. <cite>[5]</cite> , but pretrain the encoder using a number of different ASR datasets: the 150hour AISHELL corpus of Chinese as well as seven GlobalPhone languages, each with about 20 hours of data.",
  "y": "extends uses"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_4",
  "x": "For both ASR and AST tasks we use the same end-to-end system architecture shown in Figure 1 : the encoder-decoder model from <cite>[5]</cite> , which itself is adapted from [2] , [4] and [3] .",
  "y": "uses"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_5",
  "x": "Previous experiments <cite>[5]</cite> showed that the encoder accounts for most of the benefits of transferring the parameters.",
  "y": "background"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_6",
  "x": "Finally, to reproduce one of the experiments from <cite>[5]</cite> , we pretrained one model using 300 hours of Switchboard English [18] .",
  "y": "uses"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_7",
  "x": "However, as noted by <cite>[5]</cite> , the Fisher Spanish speech contains many words that are actually in English (code-switching), so pretraining on English may provide an unfair advantage relative to other languages.",
  "y": "background motivation"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_8",
  "x": "Following the architecture and training procedure described in <cite>[5]</cite> , input speech features are fed into a stack of two CNN layers.",
  "y": "uses"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_9",
  "x": "We use code and hyperparameter settings from <cite>[5]</cite> 4 : the Adam optimizer [25] with an initial learning rate of 0.001 and decay it by a factor of 0.5 based on the dev set BLEU score.",
  "y": "uses"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_10",
  "x": "Our baseline 20-hour AST system obtains a BLEU score of 10.3 ( Table 1 , first row), 0.5 BLEU point lower than that reported by <cite>[5]</cite> .",
  "y": "differences"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_11",
  "x": "Moreover, pretraining on the large Chinese dataset yields a bigger improvement than either of these-4.3 BLEU points. This is nearly as much as the 6 point improvement reported by <cite>[5]</cite> when pretraining on 100 hours of English data, which is especially surprising given not only that Chinese is very different from Spanish, but also that the Spanish data contains some English words.",
  "y": "similarities"
 },
 {
  "id": "fc5de471ba4cc82a2156ed25d2c78b_12",
  "x": "This is nearly as much as the 6 point improvement reported by <cite>[5]</cite> when pretraining on 100 hours of English data, which is especially surprising given not only that Chinese is very different from Spanish, but also that the Spanish data contains some English words.",
  "y": "similarities"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_0",
  "x": "Litman et al. <cite>(2016)</cite> found significant group-level differences in pitch, jitter and shimmer between first and second halves of conversation.",
  "y": "background"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_1",
  "x": "Finally, to support our studies, we have developed an innovative representation of multi-party entrainment by extending the measurement from Litman et al. <cite>(2016)</cite> and adapting it to study the feature of linguistic style from Pennebaker and King (1999) .",
  "y": "extends"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_2",
  "x": "The freely available Teams Corpus<cite> (Litman et al. 2016)</cite> The corpus also includes survey data.",
  "y": "uses"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_3",
  "x": "Recently, Litman et al. <cite>(2016)</cite> proposed a method to compute multi-party entrainment on acoustic-prosodic features based on the same Teams Corpus as used here.",
  "y": "similarities"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_4",
  "x": "More specifically, T Dif f unw (unweighted team difference) converts the team difference of Litman et al. <cite>(2016)</cite> to deal with multiple feature categories.",
  "y": "uses"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_5",
  "x": "Litman et al. <cite>(2016)</cite> then define convergence, a type of entrainment measuring increase in feature similarity, by comparing the T Dif f of two non-overlapping temporal intervals of a game as in Equation 4.",
  "y": "similarities"
 },
 {
  "id": "fca75d394e9f7007e1f674c7b99794_6",
  "x": "Since Litman et al. <cite>(2016)</cite> previously found that in the Teams corpus the highest acoustic-prosodic convergence occurred within the first and last three minutes, we used this finding to define our n. We evenly divided each game, which was limited to 30 minutes, into ten intervals, so each interval is less than three minutes.",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_0",
  "x": "In this paper, we compare <cite>CFG filtering techniques for LTAG</cite> (Harbusch, 1990; <cite>Poller and Becker, 1998</cite>) and HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000) , following an approach to parsing comparison among different grammar formalisms ).",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_1",
  "x": "An empirical comparison of <cite>CFG filtering techniques for LTAG</cite> and HPSG is presented.",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_2",
  "x": "We performed a comparison between the existing <cite>CFG filtering techniques for LTAG</cite> (<cite>Poller and Becker, 1998</cite>) and HPSG (Torisawa et al., 2000) , using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al., 1993) into HPSG-style.",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_3",
  "x": "Investigating the difference between the ways of context-free (CF) approximation of LTAG and HPSG will thereby enlighten a way of further optimization for both techniques. We performed a comparison between the existing <cite>CFG filtering techniques for LTAG</cite> (<cite>Poller and Becker, 1998</cite>) and HPSG (Torisawa et al., 2000) , using strongly equivalent grammars obtained by converting LTAGs extracted from the Penn Treebank (Marcus et al., 1993) into HPSG-style.",
  "y": "motivation"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_4",
  "x": "In this section, we introduce a grammar conversion ) and <cite>CFG filtering</cite> (Harbusch, 1990; <cite>Poller and Becker, 1998</cite>; Torisawa et al., 2000; Kiefer and Krieger, 2000) .",
  "y": "uses background"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_5",
  "x": "**<cite>CFG FILTERING</cite> TECHNIQUES**",
  "y": "background"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_6",
  "x": "An initial offline step of <cite>CFG filtering</cite> is performed to approximate a given grammar with a CFG.",
  "y": "background"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_7",
  "x": "The <cite>CFG filtering</cite> generally consists of two steps.",
  "y": "background"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_8",
  "x": "The parsers with <cite>CFG filtering</cite> used in our experiments follow the above parsing strategy, but are different in the way the CF approximation and the elimination of impossible parse trees in phase 2 are performed.",
  "y": "extends uses differences"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_9",
  "x": "In <cite>CFG filtering techniques for LTAG</cite> (Harbusch, 1990; <cite>Poller and Becker, 1998</cite>) , every branching of elementary trees in a given grammar is extracted as a CFG rule as shown in Figure 1 .",
  "y": "uses background"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_10",
  "x": "In this section, we compare a pair of <cite>CFG filtering techniques for LTAG</cite> (<cite>Poller and Becker, 1998</cite>) and HPSG (Torisawa et al., 2000) described in Section 2.2.1 and 2.2.2.",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_11",
  "x": "We can thereby construct another <cite>CFG filtering for LTAG</cite> by combining this CFG filter with an existing LTAG parsing algorithm (van Noord, 1994) .",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_12",
  "x": "Because the processed portions of generated tree structures are no longer used later, we regard the unprocessed portions of the tree structures as nonterminals of CFG. We can thereby construct another <cite>CFG filtering for LTAG</cite> by combining this CFG filter with an existing LTAG parsing algorithm (van Noord, 1994) .",
  "y": "uses"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_13",
  "x": "Experimental results showed that the existing CF approximation of HPSG (Torisawa et al., 2000) produced a more effective filter than that of LTAG (<cite>Poller and Becker, 1998</cite>) .",
  "y": "differences"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_14",
  "x": "**CONCLUSION AND FUTURE DIRECTION** We are going to integrate the advantage of the CF approximation of HPSG into that of LTAG in order to establish another <cite>CFG filtering for LTAG</cite>.",
  "y": "future_work"
 },
 {
  "id": "fdfb8fbdb8544dca17b1aeba768124_15",
  "x": "We are going to integrate the advantage of the CF approximation of HPSG into that of LTAG in order to establish another <cite>CFG filtering for LTAG</cite>.",
  "y": "uses future_work"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_0",
  "x": "We bring together two strands of research: one strand uses Reinforcement Learning to automatically optimise dialogue strategies, e.g. (Singh et al., 2002) , (Henderson et al., 2008) , (Rieser and Lemon, 2008a;<cite> Rieser and Lemon, 2008b)</cite> ; the other other focuses on automatic evaluation of dialogue strategies, e.g. the PARADISE framework (Walker et al., 1997) , and meta-evaluation of dialogue metrics, e.g. (Engelbrecht and M\u00f6ller, 2007; Paek, 2007) .",
  "y": "uses"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_1",
  "x": "In the following we evaluate different aspects of an objective function obtained from Wizard-of-Oz (WOZ) data<cite> (Rieser and Lemon, 2008b)</cite> .",
  "y": "uses"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_2",
  "x": "We therefore formulate dialogue learning as a hierarchical optimisation problem<cite> (Rieser and Lemon, 2008b)</cite> .",
  "y": "uses"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_3",
  "x": "In the following the overall method is shortly summarised. Please see <cite>(Rieser and Lemon, 2008b</cite>; Rieser, 2008) for details.",
  "y": "background"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_4",
  "x": "The PARADISE regression model is constructed from 3 different corpora: the SAMMIE WOZ experiment (Rieser et al., 2005) , and the iTalk system used for the user tests<cite> (Rieser and Lemon, 2008b)</cite> running the supervised baseline policy and the RL-based policy.",
  "y": "uses"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_5",
  "x": "In previous work we showed that the RL-based policy significantly outperforms the supervised policy in terms of improved user ratings and dialogue performance measures<cite> (Rieser and Lemon, 2008b)</cite> .",
  "y": "background"
 },
 {
  "id": "fe3e71020dfb32927f5c348a6fdcfc_6",
  "x": "The SL policy, in contrast, did not learn an upper boundary for when to show items on the screen (since the wizards did not follow a specific pattern,<cite> (Rieser and Lemon, 2008b)</cite> ).",
  "y": "differences"
 },
 {
  "id": "fe443d5e13b525cbdfa58dafb83162_0",
  "x": "Recently, empty-element recovery for Chinese has begun to receive attention: <cite>Yang and Xue (2010)</cite> treat it as classification problem, while Chung and Gildea (2010) pursue several approaches for both Korean and Chinese, and explore applications to machine translation.",
  "y": "background"
 },
 {
  "id": "fe443d5e13b525cbdfa58dafb83162_1",
  "x": "The method is language-independent and performs very well on both languages we tested it on: for English, it outperforms the best published method we are aware of (Schmid, 2006) , and for Chinese, it outperforms the method of <cite>Yang and Xue (2010)</cite> .",
  "y": "differences"
 },
 {
  "id": "fe443d5e13b525cbdfa58dafb83162_2",
  "x": "<cite>Yang and Xue (2010)</cite> simply count unlabeled empty elements: items are (i, i) for each empty element, where i is its position.",
  "y": "background"
 },
 {
  "id": "fe443d5e13b525cbdfa58dafb83162_4",
  "x": "The unlabeled empty elements column shows that our system outperforms the baseline system of <cite>Yang and Xue (2010)</cite> .",
  "y": "differences"
 },
 {
  "id": "fe443d5e13b525cbdfa58dafb83162_5",
  "x": "Our system outperformed that of <cite>Yang and Xue (2010)</cite> especially on *pro*, used for dropped arguments, and *T*, used for relative clauses and topicalization.",
  "y": "differences"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_0",
  "x": "It is in general to normalize the model score by translation length (say length normalization) to eliminate this system bias<cite> (Wu et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_1",
  "x": "Alternatively, one can rerank the n-best outputs by coverage-sensitive models, but this method just affects the final output list which has a very limited scope<cite> (Wu et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_2",
  "x": "Given a source position i, we define its coverage as the sum of the past attention probabilities c i = |y| j a ij <cite>(Wu et al., 2016</cite>; Tu et al., 2016) .",
  "y": "similarities"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_3",
  "x": "Note that our way of truncation is different from<cite> Wu et al. (2016)</cite> 's, where they clip the coverage into [0, 1] and ignore the fact that a source word may be translated into multiple target words and its coverage should be of a value larger than 1.",
  "y": "differences"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_4",
  "x": "For comparison, we re-implemented the length normalization (LN) and coverage penalty (CP) methods<cite> (Wu et al., 2016)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_5",
  "x": "We used grid search to tune all hyperparameters on the development set as<cite> Wu et al. (2016)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_6",
  "x": "The simplest of these is length normalization which penalizes short translations in decoding<cite> (Wu et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_7",
  "x": "Perhaps the most related work to this paper is<cite> Wu et al. (2016)</cite> .",
  "y": "background"
 },
 {
  "id": "fe8d369d4a6f940a1eb25aa7c9b4fe_8",
  "x": "Another difference lies in that our coverage model is applied to every beam search step, while<cite> Wu et al. (2016)</cite> 's model affects only a small number of translation outputs.",
  "y": "differences"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_0",
  "x": "We applied the monolingual sentence alignment algorithm of <cite>Barzilay and Elhadad (2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_1",
  "x": "<cite>Barzilay and Elhadad (2003)</cite> additionally considered every word starting with a capital letter inside a sentence to be a proper name. In German, all nouns (i.e., regular nouns as well as proper names) are capitalized; thus, this approach does not work. We used a list of 61,228 first names to remove at least part of the proper names.",
  "y": "extends background"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_2",
  "x": "We adapted the hierarchical completelink clustering method of <cite>Barzilay and Elhadad (2003)</cite> : While the authors claimed to have set a specific number of clusters, we believe this is not generally possible in hierarchical agglomerative clustering. Therefore, we used the largest number of clusters in which all paragraph pairs had a cosine similarity strictly greater than zero. Following the formation of the clusters, lexical similarity between all paragraphs of corresponding AS and LS texts was computed to establish probable mappings between the two sets of clusters.",
  "y": "extends background"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_3",
  "x": "<cite>Barzilay and Elhadad (2003)</cite> used the boosting tool Boostexter (Schapire and Singer, 2000) . All possible cross-combinations of paragraphs from the parallel training data served as training instances. An instance consisted of the cosine similarity of the two paragraphs and a string combining the two cluster IDs. The classification result was extracted from the manual alignments. In order for an AS and an LS paragraph to be aligned, at least one sentence from the LS paragraph had to be aligned to one sentence in the AS paragraph.",
  "y": "background"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_4",
  "x": "Like <cite>Barzilay and Elhadad (2003)</cite> , we performed 200 iterations in Boostexter.",
  "y": "similarities uses"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_5",
  "x": "We set the skip penalty to 0.001 conforming to the value of <cite>Barzilay and Elhadad (2003)</cite> .",
  "y": "similarities"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_6",
  "x": "Adapted algorithm of <cite>Barzilay and Elhadad (2003)</cite> 27.7% 5.0% 8.5% Baseline I: First sentence 88.1% 4.8% 9.3% Baseline II: Word in common 2.2% 8.2% 3.5% Table 2 : Alignment results on test set 1. Aligning only the first sentence of each text (\"First sentence\") 2.",
  "y": "extends"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_7",
  "x": "As can be seen from Table 2 , by applying the sentence alignment algorithm of <cite>Barzilay and Elhadad (2003)</cite> we were able to extract only 5% of all reference alignments, while precision was below 30%.",
  "y": "uses"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_8",
  "x": "In conclusion, none of the three approaches (adapted algorithm of <cite>Barzilay and Elhadad (2003)</cite> , two baselines \"First sentence\" and \"Word in common\") performed well on our test set.",
  "y": "differences background"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_9",
  "x": "Compared with the results of <cite>Barzilay and Elhadad (2003)</cite> , who achieved 77% precision at 55.8% recall for their data, our alignment scores were considerably lower (27.7% precision, 5% recall).",
  "y": "differences"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_10",
  "x": "While <cite>Barzilay and Elhadad (2003)</cite> aligned English/Simple English texts, we dealt with German/Simple German data.",
  "y": "differences"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_11",
  "x": "In terms of domain, <cite>Barzilay and Elhadad (2003)</cite> used city descriptions from an encyclopedia for their experiments. For these descriptions clustering worked well because all articles had the same structure (paragraphs about culture, sports, etc.). The domain of our corpus was broader: It included information about housing, work, and events for people with disabilities as well as information about the organizations behind the respective websites. Apart from language and domain challenges we observed heavy transformations from AS to LS in our data (Figure 1 shows a sample article in AS and LS). As a result, LS paragraphs were typically very short and the clustering process returned many singleton clusters.",
  "y": "differences background"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_12",
  "x": "Since all of our data was from the same language, we applied the monolingual sentence alignment approach of <cite>Barzilay and Elhadad (2003)</cite> .",
  "y": "similarities"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_13",
  "x": "For example, named entity recognition, a preprocessing step to clustering, is harder for German than for English, the language <cite>Barzilay and Elhadad (2003)</cite> worked with. Moreover, German features richer morphology than English, which leads to less lexical overlap when working on the word form level.",
  "y": "background"
 },
 {
  "id": "febb64368c09d03932742fc557f3d3_14",
  "x": "The domain of our corpus was also broader than that of <cite>Barzilay and Elhadad (2003)</cite> , who used city descriptions from an encyclopedia for their experiments. This made it harder to identify common article structures that could be exploited in clustering.",
  "y": "background differences"
 }
]