[
 {
  "id": "02521fd9721c264ee05315dec9b31d_0",
  "x": "Moreover, compared to previous work that uses two models in tandem <cite>(Baevski et al., 2019b)</cite> , by using one model for both BERT pre-trainining and fine-tuning, our model provides an average relative WER reduction of 9%.",
  "y": "differences"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_1",
  "x": "Recently impressive results have been reported for representation learning, that generalizes to different downstream tasks, through self-supervised learning for text and speech (Devlin et al., 2018; Baevski et al., 2019a; van den Oord et al., 2018;<cite> Baevski et al., 2019b)</cite> .",
  "y": "background"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_2",
  "x": "Different from <cite>(Baevski et al., 2019b)</cite> where the a BERT-like model is trained with the masked language model loss, frozen, and then used as a feature extractor in tandem with a final fully supervised convolutional ASR model (Collobert et al., 2016) , in this work, our \"Discrete BERT\" approach achieves an average relative Word Error Rate (WER) reduction of 9% by pre-training and fine-tuning the same BERT model using a Connectionist Temporal Classification (Graves et al.) loss.",
  "y": "differences"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_3",
  "x": "vq-wav2vec <cite>(Baevski et al., 2019b)</cite> learns vector quantized (VQ) representations of audio data using a future time-step prediction task.",
  "y": "background"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_4",
  "x": "Our work builds on the recently proposed work in <cite>(Baevski et al., 2019b)</cite> where audio is quantized using a contrastive loss, then features learned on top by a BERT model (Devlin et al., 2018) .",
  "y": "extends"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_5",
  "x": "For the vq-wav2vec quantization, we use the gumbelsoftmax vq-wav2vec model with the same setup as described in <cite>(Baevski et al., 2019b)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_6",
  "x": "We train a standard BERT model (Devlin et al., 2018; with only the masked language modeling task on each set of inputs in the same way as described in <cite>(Baevski et al., 2019b)</cite> , namely by choosing tokens for masking with probability of 0.05, expanding each chosen token to a span of 10 masked tokens (spans may overlap) and then computing a cross-entropy loss which attempts to maximize the likelihood of predicting the true token for each one that was masked ( Figure  1a ).",
  "y": "similarities uses"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_7",
  "x": "We first train the vq-wav2vec quantization model following the gumbel-softmax recipe described in <cite>(Baevski et al., 2019b)</cite> .",
  "y": "uses"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_8",
  "x": "To mask the input sequence, we follow <cite>(Baevski et al., 2019b)</cite> and randomly sample p = 0.05 of all tokens to be a starting index, without replacement, and mask M = 10 consecutive tokens from every sampled index; spans may overlap.",
  "y": "uses"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_9",
  "x": "We expect that increasing the size of the fixed positional embeddings, or switching to relative positional embeddings will improve performance on longer examples, but in this work we wanted to stay consistent with the setup in<cite> Baevski et al. (2019b)</cite> .",
  "y": "uses"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_10",
  "x": "Compared to the two-model tandem system proposed in <cite>(Baevski et al., 2019b)</cite> , which uses a the discrete BERT features to train another ASR system from scratch, our discrete BERT model provides an average of 13% and 6% of WER reduction on clean and other subsets respectively, by pre-training and fine-tuning the same BERT model on the 10h labeled set.",
  "y": "differences"
 },
 {
  "id": "02521fd9721c264ee05315dec9b31d_11",
  "x": "The the success of BERT (Devlin et al., 2018) and Word2Vec (Mikolov et al., 2013) for NLP tasks motivated more research on self-supervised approaches for acoustic word embedding and unsupervised acoustic feature representation (Bengio and Heigold; Levin et al.; Chung et al., b; He et al.; van den Oord et al., 2018;<cite> Baevski et al., 2019b)</cite> , either by predicting masked discrete or continuous input, or by contrastive prediction of neighboring or similarly sounding segments using distant supervision or proximity in the audio signal as an indication of similarity.",
  "y": "background"
 },
 {
  "id": "0593fb7ee345cf632e6a61f1f21e6c_0",
  "x": "Next we present some of our computed results over the three architectures: vanilla VQA model [1] , Stacked Attention Network (SAN) [12] and Teney et al. model <cite>[14]</cite> .",
  "y": "uses"
 },
 {
  "id": "0593fb7ee345cf632e6a61f1f21e6c_1",
  "x": "1 . The architecture is similar to Teney et al. <cite>[14]</cite> with reduced computations with elementwise multiplication, use of GloVe vectors [23] , and ensemble of 30 models.",
  "y": "similarities"
 },
 {
  "id": "0593fb7ee345cf632e6a61f1f21e6c_2",
  "x": "We considered the following three models for our experiments, 1) the baseline Vanilla VQA model [1] which uses the VGG16 CNN architecture [3] and LSTMs [7] , 2) the Stacked Attention Networks [12] architecture, and 3) the 2017 VQA challenge winner Teney et al. model <cite>[14]</cite> .",
  "y": "uses"
 },
 {
  "id": "0593fb7ee345cf632e6a61f1f21e6c_3",
  "x": "In the experiments, we found that the Teney et al. <cite>[14]</cite> is the best performing model on both VQA and Visual7W Dataset.",
  "y": "uses"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_0",
  "x": "Many recent discourse relation classification approaches have focused on cross-lingual data augmentation , training models to better represent the relational arguments by using various neural network models, including feed-forward network (Rutherford et al., 2017) , convolutional neural networks (Zhang et al., 2015) , recurrent neural network (Ji et al., 2016;<cite> Bai and Zhao, 2018)</cite> , character-based (Qin et al., 2016) or formulating relation classification as an adversarial task (Qin et al., 2017) .",
  "y": "background"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_1",
  "x": "Many recent discourse relation classification approaches have focused on cross-lingual data augmentation , training models to better represent the relational arguments by using various neural network models, including feed-forward network (Rutherford et al., 2017) , convolutional neural networks (Zhang et al., 2015) , recurrent neural network (Ji et al., 2016;<cite> Bai and Zhao, 2018)</cite> , character-based (Qin et al., 2016) or formulating relation classification as an adversarial task (Qin et al., 2017) . However, previously proposed neural models still crucially lack a representation of the typical relations between sentences: to solve the task properly, a model should ideally be able to form discourse expectations, i.e., to represent the typical causes, consequences, next events or contrasts to a given event described in one relational argument, and then assess the content of the second relational argument with respect to these expectations (see Example 1).",
  "y": "motivation"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_2",
  "x": "Following the experimental settings and evaluation metrics in<cite> Bai and Zhao (2018)</cite> , we use two most-used splitting methods of PDTB data, denoted as PDTB-Lin (Lin et al., 2009) , which uses sections 2-21, 22, 23 as training, validation and test sets, and PDTB-Ji (Ji and Eisenstein, 2015) , which uses 2-20, 0-1, 21-22 as training, validation and test sets and report the overall accuracy score.",
  "y": "uses"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_3",
  "x": "The current best performance was achieved by<cite> Bai and Zhao (2018)</cite> , who combined representations from different grained em-beddings including contextualized word vectors from ELMo (Peters et al., 2018) , which has been proved very helpful.",
  "y": "background"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_4",
  "x": "It obtained improvements of 7.3% points on PDTB-Lin, 5.5% points on PDTB-Ji, compared with the ELMobased method proposed in <cite>(Bai and Zhao, 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_5",
  "x": "We also tested the state of the art model of implicit discourse relation classification proposed by<cite> Bai and Zhao (2018)</cite> on BioDRB.",
  "y": "uses"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_6",
  "x": "From Table 2 , we can see that the BERT base model achieved almost 12% points improvement over the Bi-LSTM baseline and 15% points over<cite> Bai and Zhao (2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "0753a2be70f9844d353ec54c04fd53_8",
  "x": "From Table 2 , we can see that the BERT base model achieved almost 12% points improvement over the Bi-LSTM baseline and 15% points over<cite> Bai and Zhao (2018)</cite> . When fine-tuned on in-domain data in the crossvalidation setting, the improvement increases to around 17% points. Cross-Domain In-Domain Bi-LSTM + w2v 300 32.97 46.49<cite> Bai and Zhao (2018)</cite> 29.52 55.90",
  "y": "differences"
 },
 {
  "id": "07a2b256766020450c85eae2839db8_0",
  "x": "Most importantly, it is clear from some recent studies <cite>[8,</cite> 9 ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "background"
 },
 {
  "id": "07a2b256766020450c85eae2839db8_1",
  "x": "Therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. Most importantly, it is clear from some recent studies <cite>[8,</cite> 9 ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "motivation future_work"
 },
 {
  "id": "07a2b256766020450c85eae2839db8_2",
  "x": "Unfortunately, a major problem arising from the analyses performed with co-occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success of the model. Therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. Most importantly, it is clear from some recent studies <cite>[8,</cite> 9 ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "motivation future_work"
 },
 {
  "id": "07a2b256766020450c85eae2839db8_3",
  "x": "Furthermore, such representation has also been useful in the analysis of the complexity [15] and quality of texts [16] . Unfortunately, a major problem arising from the analyses performed with co-occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success of the model. Therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. Most importantly, it is clear from some recent studies <cite>[8,</cite> 9 ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "motivation"
 },
 {
  "id": "07a2b256766020450c85eae2839db8_4",
  "x": "More specifically, in (i), I propose 1 E-mail:diego.raphael@gmail.com, diego@icmc.usp.br December 4, 2014 the conception of measurements that are able to capture semantic aspects, since the topological measurements of co-occurrence networks capture mostly syntactic factors <cite>[8]</cite> .",
  "y": "uses"
 },
 {
  "id": "07cee5aa02b518d48e41b1d6010c2f_0",
  "x": "The discriminative re-scoring models (Collins, 2000; Collins and Duffy, 2002; Charniak and Johnson, 2005; <cite>Huang, 2008)</cite> can be viewed as previous attempts to higher-order constituent parsing, using some parts containing more than one grammar rule as non-local features.",
  "y": "background"
 },
 {
  "id": "07cee5aa02b518d48e41b1d6010c2f_1",
  "x": "Following<cite> Huang (2008)</cite> , this algorithm traverses a parse forest in a bottom-up manner.",
  "y": "uses background"
 },
 {
  "id": "07cee5aa02b518d48e41b1d6010c2f_2",
  "x": "The factorization of the parsing model allows us to develop an exact decoding algorithm for it. Following<cite> Huang (2008)</cite> , this algorithm traverses a parse forest in a bottom-up manner.",
  "y": "uses"
 },
 {
  "id": "07cee5aa02b518d48e41b1d6010c2f_3",
  "x": "The factorization of the parsing model allows us to develop an exact decoding algorithm for it. This algorithm is more complex than the approximate decoding algorithm of<cite> Huang (2008)</cite> .",
  "y": "differences"
 },
 {
  "id": "07cee5aa02b518d48e41b1d6010c2f_5",
  "x": "The parameters \u03b8 of each parsing model are estimated from a training set using an averaged perceptron algorithm, following Collins (2002) and<cite> Huang (2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "086619bef9b4e7851bf42bf36eb14a_0",
  "x": "Recent methods applied to study texts at sentence level include probability distributions [24, 25, 26, 27] and correlations [26, 27, 17, <cite>28]</cite> .",
  "y": "background"
 },
 {
  "id": "086619bef9b4e7851bf42bf36eb14a_1",
  "x": "In general, sentence lengths have been quantified by the number of words [24, 29, 25, <cite>28]</cite> or characters [30, 31, 26, 27] .",
  "y": "background"
 },
 {
  "id": "086619bef9b4e7851bf42bf36eb14a_2",
  "x": "However, an issue about this relationship was addressed in [37] : \"Somewhat more problematic is the relation of sentence length to the word length.\" This comment is consistent with the one in<cite> [28]</cite> asserting that the Menzerath-Altmann law does not hold if the sentence length is measured in terms of characters instead of the number of words.",
  "y": "background"
 },
 {
  "id": "086619bef9b4e7851bf42bf36eb14a_3",
  "x": "This result is consistent with the multifractal analysis performed in<cite> [28]</cite> .",
  "y": "similarities"
 },
 {
  "id": "0888b30ae5dcc880761a92ffbdcd1b_0",
  "x": "This principle has already been used to explain the origins of other linguistic laws: Zipf's law of abbreviation, namely, the frequency of more frequent words to be shorter [3,<cite> 4]</cite> , and Menzerath's law, the tendency of a larger linguistic construct to be made of smaller components [5] .",
  "y": "background"
 },
 {
  "id": "0888b30ae5dcc880761a92ffbdcd1b_2",
  "x": "First, a relationship between the length of a word and its probability<cite> [4]</cite> l = a log p + b,",
  "y": "background"
 },
 {
  "id": "0888b30ae5dcc880761a92ffbdcd1b_3",
  "x": "Third, its assumptions are far reaching: compression allows one to shed light on the origins of three linguistic laws at the same time: Zipf's law for word frequencies, Zipf's law of abbreviation and Menzerath's law with the unifying principle of compression [3, <cite>4,</cite> 5] .",
  "y": "background"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_0",
  "x": "A significant limitation of F-Score is that it does not evaluate the make up of clusters beyond the majority class <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_1",
  "x": "These two limitations define the matching problem of F-Score <cite>(Rosenberg and Hirschberg, 2007)</cite> which can lead to: (1) identical scores between different clustering solutions, and (2) inaccurate assessment of the clustering quality.",
  "y": "background"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_2",
  "x": "Subsequently, we present the use of V-measure <cite>(Rosenberg and Hirschberg, 2007)</cite> as an evaluation measure that can overcome the current limitations of F-Score.",
  "y": "extends differences"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_3",
  "x": "As it can be observed, F-Score assesses the quality of a clustering solution by considering two different angles, i.e. homogeneity and completeness <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_4",
  "x": "However, F-Score suffers from the matching problem, which manifests itself either by not evaluating the entire membership of a cluster, or by not evaluating every cluster <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_5",
  "x": "The former situation is present, due to the fact that F-Score does not consider the make-up of the clusters beyond the majority class <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "differences"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_6",
  "x": "V-measure assesses the quality of a clustering solution by explicitly measuring its homogeneity and its completeness <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_7",
  "x": "Overall, in accordance with the convention of 1 being desirable and 0 undesirable, the homogeneity (h) of a clustering solution is 1 if there is only a single class, and 1\u2212 H(GS|C) H(GS) in any other case <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_8",
  "x": "This happens when each GS class is included in all clusters with a distribution equal to the distribution of sizes <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "09dad2fd96cd1d48936cd5b99a38e7_9",
  "x": "This is due to the fact that V-measure considers as the worst solution in terms of completeness the one, in which each class is represented by every cluster, and specifically with a distribution equal to the distribution of cluster sizes <cite>(Rosenberg and Hirschberg, 2007)</cite> .",
  "y": "similarities"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_0",
  "x": "In addition, several works have demonstrated how combining robot affordance learning with language grounding can provide cognitive robots with new and useful skills, such as learning the association of spoken words with sensorimotor experience<cite> [10,</cite> 11] or sensorimotor representations [12] , learning tool use capabilities [13, 14] , and carrying out complex manipulation tasks expressed in natural language instructions which require planning and reasoning [15] .",
  "y": "background"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_1",
  "x": "In <cite>[10]</cite> , a joint model is proposed to learn robot affordances (i. e., relationships between actions, objects and resulting effects) together with word meanings.",
  "y": "background"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_2",
  "x": "In this paper, we combine (1) the robot affordance model of <cite>[10]</cite> , which associates verbal descriptions to the physical interactions of an agent with the environment, with (2) the gesture recognition system of [4] , which infers the type of action from human user movements.",
  "y": "extends differences"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_3",
  "x": "Our main contribution is that of extending <cite>[10]</cite> by relaxing the assumption that the action is known during the learning phase.",
  "y": "extends differences"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_4",
  "x": "Following the method adopted in <cite>[10]</cite> , we use a Bayesian probabilistic framework to allow a robot to ground the basic world behavior and verbal descriptions associated to it.",
  "y": "similarities uses"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_5",
  "x": "This joint probability distribution, that is illustrated by the part of Fig. 2 enclosed in the dashed box, is estimated by the robot in an ego-centric way through interaction with the environment, as in <cite>[10]</cite> .",
  "y": "background"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_6",
  "x": "In this study we wish to generalize the model of <cite>[10]</cite> by observing external (human) agents, as shown in Fig. 1 .",
  "y": "extends"
 },
 {
  "id": "09dfa2f17283fe6b3fc28383f36732_7",
  "x": "In the experimental section, we will show that what the robot has learned subjectively or alone (by self-exploration, knowing the action identity as a prior <cite>[10]</cite> ), can subsequently be used when observing a new agent (human), provided that the actions can be estimated with Gesture HMMs as in [4] .",
  "y": "background"
 },
 {
  "id": "0ab60c5c9ace058a5fbe3bc2643cba_0",
  "x": "Apart from its application to machine translation, the encoder-decoder or sequence-to-sequence (seq2seq) paradigm has been successfully applied to monolingual text-to-text tasks including simplification <cite>(Nisioi et al., 2017)</cite> , paraphrasing (Mallinson et al., 2017) , style transfer (Jhamtani et al., 2017) , sarcasm interpretation (Peled and Reichart, 2017) , automated lyric annotation (Sterckx et al., 2017) and dialogue systems (Serban et al., 2016) .",
  "y": "background"
 },
 {
  "id": "0ab60c5c9ace058a5fbe3bc2643cba_1",
  "x": "Wikilarge is a collection of 296,402 automatically aligned complex and simple sentences from the ordinary and simple English Wikipedia corpora, used extensively in previous work (Wubben et al., 2012; Woodsend and Lapata, 2011; Zhang and Lapata, 2017;<cite> Nisioi et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "0ab60c5c9ace058a5fbe3bc2643cba_2",
  "x": "We use a similar archi- Table 2 : Quantitative evaluation of existing baselines from previous work and seq2seq with prior attention from the CVAE when choosing an optimal z sample for BLEU scores. tecture as Zhu et al. (2010) and<cite> Nisioi et al. (2017)</cite> : 2 layers of stacked unidirectional LSTMs with bi-linear global attention as proposed by Luong et al. (2015) , with hidden states of 512 dimensions.",
  "y": "uses"
 },
 {
  "id": "0ab60c5c9ace058a5fbe3bc2643cba_3",
  "x": "Our standard seq2seq model with attention, without prior attention, obtains a score of 89.92 BLEU points, which is close to scores obtained by similar models used in existing 1 Fleish-Kincaid Grade Level index. work on neural text simplification (Zhang and Lapata, 2017;<cite> Nisioi et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "0ab60c5c9ace058a5fbe3bc2643cba_4",
  "x": "For comparison, we include the SMT-based model by (Wubben et al., 2012) , the NTS model by <cite>(Nisioi et al., 2017)</cite> and the EncDecA by (Zhang and Lapata, 2017) .",
  "y": "uses"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_0",
  "x": "Our work is based on the recently released <cite>Multimodal Dialogue</cite> (<cite>MMD</cite>) dataset <cite>(Saha et al., 2017)</cite> in the fashion domain. We introduce a multimodal extension to the Hierarchical Recurrent Encoder-Decoder (HRED) model and show that this extension outperforms strong baselines in terms of text-based similarity metrics.",
  "y": "extends"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_1",
  "x": "This research makes use of a recently released <cite>Multimodal Dialogue</cite> (<cite>MMD</cite>) dataset <cite>(Saha et al., 2017)</cite> , which contains multiple dialogue sessions in the fashion domain.",
  "y": "uses"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_2",
  "x": "The <cite>MMD</cite> dataset provides an interesting new challenge, combining recent efforts on task-oriented dialogue systems, as well as visually grounded dialogue.",
  "y": "background"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_3",
  "x": "In contrast to simple QA tasks in visually grounded dialogue, e.g. (Antol et al., 2015) , <cite>it contains</cite> conversations with a clear end-goal.",
  "y": "background"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_4",
  "x": "However, in contrast to previous slot-filling dialogue systems, e.g. (Rieser and Lemon, 2011; Young et al., 2013) , <cite>it heavily relies on</cite> the extra visual modality to drive the conversation forward (see Figure 1) .",
  "y": "background"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_5",
  "x": "<cite>Saha et al. (2017)</cite> propose a similar baseline model for the <cite>MMD</cite> dataset, extending HREDs to include the visual modality.",
  "y": "similarities"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_6",
  "x": "Example contexts for a given system utterance; note the difference in our approach from <cite>Saha et al. (2017)</cite> when extracting the training data from the original chat logs.",
  "y": "differences"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_7",
  "x": "Note that we started with the raw transcripts of dialogue sessions to create our own version of <cite>the dataset</cite> for the model.",
  "y": "extends"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_8",
  "x": "This is done since <cite>the authors</cite> originally consider each image as a different context, while we consider all the images in a single turn as one concatenated context (cf. Figure 3 ).",
  "y": "differences motivation"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_9",
  "x": "4 Note that the results reported in <cite>their paper</cite> are on a different version of the corpus, hence not directly comparable.",
  "y": "differences"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_10",
  "x": "To summarize, our best performing model (M-HRED-attn) outperforms the model of <cite>Saha et al.</cite> by 7 BLEU points.",
  "y": "differences"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_11",
  "x": "In this research, we address the novel task of response generation in search-based multimodal dialogue by learning from the recently released <cite>Multimodal Dialogue</cite> (<cite>MMD</cite>) dataset <cite>(Saha et al., 2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_12",
  "x": "We introduce a novel extension to the Hierarchical Recurrent Encoder-Decoder (HRED) model (Serban et al., 2016) and show that our implementation significantly outperforms the model of <cite>Saha et al. (2017)</cite> by modelling the full multimodal context.",
  "y": "differences"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_13",
  "x": "Contrary to <cite>their results</cite>, our generation outputs improved by adding attention and increasing context size.",
  "y": "differences"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_14",
  "x": "We compare our results against <cite>Saha et al. (2017)</cite> by using <cite>their code</cite> and data-generation scripts.",
  "y": "uses"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_15",
  "x": "The <cite>MMD</cite> dataset <cite>(Saha et al., 2017)</cite> consists of 100/11/11k train/validation/test chat sessions comprising 3.5M context-response pairs for the model.",
  "y": "background"
 },
 {
  "id": "0bb68718667b8850dc0110d10d1d3a_16",
  "x": "The <cite>MMD</cite> dataset <cite>(Saha et al., 2017)</cite> consists of 100/11/11k train/validation/test chat sessions comprising 3.5M context-response pairs for the model. Each session contains an average of 40 dialogue turns (average of 8 words per textual response, 4 images per image response). <cite>The data</cite> contains complex user queries, which pose new challenges for multimodal, task-based dialogue, such as quantitative inference (sorting, counting and filtering): \"Show me more images of the 3rd product in some different directions\", inference using domain knowledge and long term context: \"Will the 5th result go well with a large sized messenger bag?\", inference over aggregate of images: \"List more in the upper material of the 5th image and style as the 3rd and the 5th\", co-reference resolution.",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_0",
  "x": "It is usually de ned as a classi cation problem where for a text and target pair, the stance of the author of the text for that target is expected as a classi cation output from the set: {Favor, Against, Neither} <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_1",
  "x": "Like sentiment analysis, stance detection systems can be valuable components of information retrieval and other text analysis systems <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_2",
  "x": "e authors state that their approach achieves stateof-the art performance rates [1] on SemEval 2016 Twi er Stance Detection corpus <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_3",
  "x": "Lastly, in <cite>[12]</cite> , SemEval 2016's aforementioned shared task on Twi er Stance Detection is described.",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_4",
  "x": "Lastly, in <cite>[12]</cite> , SemEval 2016's aforementioned shared task on Twi er Stance Detection is described. Also provided are the results of the evaluations of 19 systems participating in two subtasks (one with training data set provided and the other without an annotated data set) of the shared task <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_5",
  "x": "It is emphasized in the related literature that unigram-based methods are reliable for the stance detection task [16] and similarly unigram-based models have been used as baseline models in studies such as <cite>[12]</cite> .",
  "y": "background"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_6",
  "x": "e 10-fold cross-validation results of the two classi ers are provided in Table 1 using the metrics of precision, recall, and F-Measure. e performance of the classi ers is be er for the Favor class for both targets when compared with the performance results for the Against class. e same percentage of common terms may not have been observed in tweets during the expression of negative stances towards the targets. Yet, completely the opposite pa ern is observed in stance detection results of baseline systems given in <cite>[12]</cite> , i.e., be er FMeasure rates have been obtained for the Against class when compared with the Favor class <cite>[12]</cite> .",
  "y": "differences"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_7",
  "x": "Some of the baseline systems reported in <cite>[12]</cite> are SVM-based systems using unigrams and ngrams as features similar to our study, but their data sets include all three stance classes of Favor, Against, and Neither, while our data set comprises only tweets classi ed as belonging to Favor or Against classes.",
  "y": "differences"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_8",
  "x": "Another di erence is that the data sets in <cite>[12]</cite> have been divided into training and test sets, while in our study we provide 10-fold cross-validation results on the whole data set.",
  "y": "differences"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_9",
  "x": "We have also evaluated SVM classi ers which use only bigrams as features, as ngram-based classi ers have been reported to perform be er for the stance detection problem <cite>[12]</cite> .",
  "y": "uses"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_10",
  "x": "We have also evaluated SVM classi ers which use only bigrams as features, as ngram-based classi ers have been reported to perform be er for the stance detection problem <cite>[12]</cite> . However, we have observed that using bigrams as the sole features of the SVM classi ers leads to quite poor results.",
  "y": "differences"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_11",
  "x": "Particularly, related methods presented in recent studies such as <cite>[12]</cite> can be tested on our data set.",
  "y": "uses future_work"
 },
 {
  "id": "0bd3236100730487986ade49af24b9_12",
  "x": "Other classi cation approaches could also be implemented and tested against our baseline classi ers. Particularly, related methods presented in recent studies such as <cite>[12]</cite> can be tested on our data set.",
  "y": "future_work"
 },
 {
  "id": "0bfea881773f504206bef9c1394f20_0",
  "x": "We evaluated the learning informativess of such sets in terms of semantic word-sense classification accuracy (with WORD2VEC <cite>[4]</cite>), and of n-gram perplexity.",
  "y": "uses"
 },
 {
  "id": "0bfea881773f504206bef9c1394f20_1",
  "x": "We evaluated the learning informativess of such sets in terms of semantic word-sense classification accuracy (with WORD2VEC <cite>[4]</cite> ), and of n-gram perplexity.",
  "y": "uses"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_0",
  "x": "Such an issue is particularly prevalent when employing VAE-RNN architectures for text modelling <cite>(Bowman et al., 2016)</cite> . In this paper, we present a simple architecture called holistic regularisation VAE (HR-VAE), which can effectively avoid latent variable collapse.",
  "y": "motivation"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_1",
  "x": "When applying VAEs for text modelling, recurrent neural networks (RNNs) 1 are commonly used as the architecture for both encoder and decoder <cite>(Bowman et al., 2016</cite>; Xu and Durrett, 2018; Dieng et al., 2019) .",
  "y": "background"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_2",
  "x": "<cite>Bowman et al. (2016)</cite> uses KL annealing, where a variable weight is added to the KL term in the cost function at training time.",
  "y": "background"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_3",
  "x": "Although the aforementioned works show effectiveness in addressing the latent variable collapse issue to some extent, they either require carefully engineering to balance the weight between the reconstruction loss and KL loss <cite>(Bowman et al., 2016</cite>; , or resort to designing more sophisticated model structures (Yang et al., 2017; Xu and Durrett, 2018; Dieng et al., 2019) .",
  "y": "motivation"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_4",
  "x": "We evaluate our model against several strong baselines which apply VAE for text modelling <cite>(Bowman et al., 2016</cite>; Yang et al., 2017; Xu and Durrett, 2018) . We conducted experiments based on two public benchmark datasets, namely, the Penn Treebank dataset (Marcus and Marcinkiewicz, 1993) and the end-to-end (E2E) text generation dataset (Novikova et al., 2017) . Experimental results show that our HR-VAE model not only can effectively mitigate the latent variable collapse issue with a stable training process, but also can give better predictive performance than the baselines, as evidenced by both quantitative (e.g., negative log likelihood and perplexity) and qualitative evaluation.",
  "y": "differences"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_5",
  "x": "Our model design is motivated by one noticeable defect shared by the VAE-RNN based models in previous works <cite>(Bowman et al., 2016</cite>; Yang et al., 2017; Xu and Durrett, 2018; Dieng et al., 2019) .",
  "y": "motivation"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_6",
  "x": "( 3) As can be seen in Eq. 3, our solution to the KL collapse issue does not require any engineering for balancing the weight between the reconstruction term and KL loss as commonly the case in existing works <cite>(Bowman et al., 2016</cite>; .",
  "y": "differences"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_7",
  "x": "We evaluate our model on two public datasets, namely, Penn Treebank (PTB) (Marcus and Marcinkiewicz, 1993) and the end-to-end (E2E) text generation corpus (Novikova et al., 2017) , which have been used in a number of previous works for text generation <cite>(Bowman et al., 2016</cite>; Xu and Durrett, 2018; Wiseman et al., 2018; Su et al., 2018) .",
  "y": "uses background"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_8",
  "x": "For the PTB dataset, we used the train-test split following <cite>(Bowman et al., 2016</cite>; Xu and Durrett, 2018) .",
  "y": "uses"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_9",
  "x": "KL annealing is used to tackled the latent variable collapse issue <cite>(Bowman et al., 2016)</cite> ; VAE-CNN 4 : A variational autoencoder model with a LSTM encoder and a dilated CNN decoder (Yang et al., 2017) ; vMF-VAE 5 : A variational autoencoder model using LSTM for both encoder and decoder where the prior distribution is the von Mises-Fisher (vMF) distribution rather than a Gaussian distribution (Xu and Durrett, 2018) .",
  "y": "uses"
 },
 {
  "id": "0da20f60adaff9637ebdbe2a27f2a4_10",
  "x": "We can see that the KL loss of VAE-LSTMbase, which uses Sigmoid annealing <cite>(Bowman et al., 2016)</cite> , collapses to zero, leading to a poor generative performance as indicated by the high reconstruction loss.",
  "y": "uses"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_0",
  "x": "While common sentence representation methods are unsupervised in nature, recently, an approach for learning universal sentence representation in a supervised setting was presented in <cite>(Conneau et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_1",
  "x": "While previous methods train sentence embeddings in an unsupervised manner, a recent work <cite>(Conneau et al., 2017)</cite> argued that better representations can be achieved via supervised training on a general sentence inference dataset (Bowman et al., 2015) .",
  "y": "background"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_2",
  "x": "BiLSTM refers to the original BiLSTM followed by MaxPooling implementation of <cite>(Conneau et al., 2017)</cite> which is the baseline for our work.",
  "y": "uses"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_3",
  "x": "To this end, we incorporate unsupervised regularization terms motivated by language modeling and auto-encoders in the training framework proposed by <cite>(Conneau et al., 2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_4",
  "x": "We test our proposed model on a set of NLP tasks and show improved results over the baseline framework of <cite>(Conneau et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_5",
  "x": "Our approach builds upon the previous work of <cite>(Conneau et al., 2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_6",
  "x": "The original model of <cite>(Conneau et al., 2017)</cite> was trained on the SNLI dataset in a supervised fashion -given pairs of sentences s 1 and s 2 , denote their representation bys 1 and s 2 .",
  "y": "uses"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_7",
  "x": "Following <cite>(Conneau et al., 2017)</cite> we have tested our approach on a wide array of classification tasks, including sentiment analysis (MR -Pang and Lee (2005) , SST -Socher et al. (2013) ), question-type (TREC -Li and Roth (2002) ), product reviews (CR - Hu and Liu (2004) ), subjectivity/objectivity (SUBJ - Pang and Lee (2005) ) and opinion polarity (MPQA -Wiebe et al. (2005) ).",
  "y": "uses"
 },
 {
  "id": "0f66e9a5c51cff004d97e4aaddf4d0_10",
  "x": "Leveraging supervision given by some general task aided in obtaining state-of-the-art sentence representations <cite>(Conneau et al., 2017)</cite> . However, every supervised learning tasks is prone to overfit.",
  "y": "motivation"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_0",
  "x": "In contrast, using multi-step relation paths (e.g., husband(barack, michelle) \u2227 mother(michelle, sasha) to train KB embeddings has been proposed very recently <cite>(Guu et al., 2015</cite>; Garcia-Duran et al., 2015; Lin et al., 2015; Neelakantan et al., 2015) .",
  "y": "background"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_1",
  "x": "In contrast, using multi-step relation paths (e.g., husband(barack, michelle) \u2227 mother(michelle, sasha) to train KB embeddings has been proposed very recently <cite>(Guu et al., 2015</cite>; Garcia-Duran et al., 2015; Lin et al., 2015; Neelakantan et al., 2015) . While using relation paths improves model performance, it also poses a critical technical challenge.",
  "y": "motivation background"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_2",
  "x": "The two approaches we consider here are: using relation paths to generate new auxiliary triples for training<cite> (Guu et al., 2015)</cite> and using relation paths as features for scoring (Lin et al., 2015) .",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_3",
  "x": "The natural composition function of a BILINEAR model is matrix multiplication<cite> (Guu et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_4",
  "x": "This can be done in time O T where Triples is the same quantity used in the analysis of<cite> Guu et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_5",
  "x": "The memory requirements of this method are the same as these of<cite> (Guu et al., 2015)</cite> , up to a constant to store random-walk probabilities for paths.",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_6",
  "x": "The memory requirements of this method are the same as these of<cite> (Guu et al., 2015)</cite> , up to a constant to store random-walk probabilities for paths. The time requirements are different, however.",
  "y": "uses differences"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_7",
  "x": "We should note that whether this method or the one of<cite> Guu et al. (2015)</cite> will be faster in training depends on whether the average number of paths per node pair multiplied by E kb is bigger or smaller than the total number of triples T .",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_8",
  "x": "Unlike the method of<cite> Guu et al. (2015)</cite> , the evaluation-time memory requirements of this approach are the same as its training memory requirements, or they could be reduced slightly to match the evaluation-time memory requirements of ALL-PATHS, if these are lower as determined by the specific problem instance.",
  "y": "differences"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_9",
  "x": "Given the values of the quantities from our knowledge graph and d = 50, \u03b7 = 50, and maximum path length of 5, the estimated memory for<cite> (Guu et al., 2015)</cite> and PRUNED-PATHS is 4.0 \u00d7 10 18 and for ALL-PATHS the memory is 1.9\u00d710 9 .",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_10",
  "x": "The time estimates are 2.4\u00d710 21 , 2.6 \u00d7 10 25 , and 7.3 \u00d7 10 15 for<cite> (Guu et al., 2015)</cite> , PRUNED-PATHS, and ALL-PATHS, respectively.",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_11",
  "x": "Our experiments are designed to study three research questions: (i) What is the impact of using path representations as a source of compositional regularization as in<cite> (Guu et al., 2015)</cite> versus using them as features for scoring as in PRUNED-PATHS and ALL-PATHS? (ii) What is the impact of using textual mentions for KB completion in different models?",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_12",
  "x": "As a second dataset, we used a WordNet KB with the same train, dev, and test splits as<cite> Guu et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_13",
  "x": "The most relevant prior approach is<cite> Guu et al. (2015)</cite> .",
  "y": "background"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_14",
  "x": "The most relevant prior approach is<cite> Guu et al. (2015)</cite> . We ran experiments using both their publicly available code and our re-implementation.",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_15",
  "x": "For our implementation of<cite> (Guu et al., 2015)</cite> , we run 5 random walks of each length starting from each node and we found that adding a weight \u03b2 to the multi-step path triples improves the results.",
  "y": "extends"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_16",
  "x": "The implementation of<cite> Guu et al. (2015)</cite> with default parameters performed significantly worse than our re-implementation.",
  "y": "differences"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_17",
  "x": "Model MAP HITS@10 BILINEAR-DIAG<cite> (Guu et al., 2015)</cite> N/A 12.9 BILINEAR-DIAG 8.0 12.2 +Guu et al. (2015) N/A 14.4 PRUNED-PATHS l = 3 c=10 9.5 14.8 PRUNED-PATHS l = 3 c=1 9.5 14.9 PRUNED-PATHS l = 5 c=10 8.9 14.4 ALL-PATHS l = 3 9.4 14.7 ALL-PATHS+NODES l=3 9.4 15.2 ALL-PATHS l = 5 9.6 16.6 ALL-PATHS+NODES l=5 9.8 16.7 Table 2 : KB completion results on the WordNet test set: comparison of our compositional learning approach (ALL-PATHS) with baseline systems.",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_18",
  "x": "The MAP results were not reported in<cite> Guu et al. (2015)</cite> ; hence the NA value for MAP in row one.",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_19",
  "x": "12 On this dataset, our implementation of the baseline model does not have substantially different results than<cite> Guu et al. (2015)</cite> and we use their reported results for the baseline and compositionally trained model.",
  "y": "uses"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_20",
  "x": "Compositional training improved performance in Hits@10 from 12.9 to 14.4 in<cite> Guu et al. (2015)</cite> , and we find that using PRUNED-PATHS as features gives similar, but a bit higher performance gains.",
  "y": "similarities"
 },
 {
  "id": "10b9ec42ac06344cd575a66161ad91_21",
  "x": "This performance degradation could be avoided with 12 We ran the trained model distributed by<cite> Guu et al. (2015)</cite> and obtained a much lower Hits@10 value of 6.4 and MAP of of 3.5.",
  "y": "uses"
 },
 {
  "id": "117d30ddacd28478c6cce1e6d39c12_0",
  "x": "Word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of NLP tasks [7, <cite>8,</cite> 9 ].",
  "y": "motivation"
 },
 {
  "id": "117d30ddacd28478c6cce1e6d39c12_1",
  "x": "Word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of NLP tasks [7, <cite>8</cite>, 9] .",
  "y": "motivation"
 },
 {
  "id": "117d30ddacd28478c6cce1e6d39c12_2",
  "x": "Bansal et al. [<cite>8</cite>] and Melamud et al. [11] show the benefits of such modified-context embeddings in dependency parsing task.",
  "y": "background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_0",
  "x": "Systems that are trained on clean data generally perform poorly when faced with such errors at test time (Heigold et al., 2017; <cite>Belinkov and Bisk, 2018</cite>) .",
  "y": "background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_1",
  "x": "Systems that are trained on clean data generally perform poorly when faced with such errors at test time (Heigold et al., 2017; <cite>Belinkov and Bisk, 2018</cite>) . One potential solution is to introduce noise at training time, an approach that is similar in spirit to the use of adversarial examples in other areas of machine learning (Goodfellow et al., 2014) and natural language processing (Ebrahimi et al., 2018) . So far, using synthetic noise at training time has been found to only improve performance on test data with exactly the same kind of synthetic noise, while at the same time impairing performance on clean test data (Heigold et al., 2017; <cite>Belinkov and Bisk, 2018</cite>) . We desire methods that yield good performance on both clean text as well as naturally-occurring noise, but this is beyond the reach of current techniques.",
  "y": "background motivation"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_2",
  "x": "<cite>Belinkov and Bisk (2018)</cite> report significant degradations in performance after applying noise to only a small fraction of input tokens.",
  "y": "background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_3",
  "x": "Substitutions and swaps were experimented with extensively in previous work (Heigold et al., 2017; <cite>Belinkov and Bisk, 2018</cite>) , but deletion and insertion were not. Deletion and insertion pose a different challenge to character encoders, since they alter the distances between character sequences in the word, as well as its overall length.",
  "y": "motivation background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_4",
  "x": "Table 2 shows the performance of the model on data with varying amounts of natural orthographical errors (see Section 2.2). As observed in prior art (Heigold et al., 2017; <cite>Belinkov and Bisk, 2018</cite>) , when there are significant amounts of natural noise, the model's performance drops significantly.",
  "y": "background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_5",
  "x": "As observed in prior art (Heigold et al., 2017; <cite>Belinkov and Bisk, 2018</cite>) , when there are significant amounts of natural noise, the model's performance drops significantly. However, training on our synthetic noise cocktail greatly improves performance, regaining between 20% (Czech) and 50% (German) of the BLEU score that was lost to natural noise.",
  "y": "differences"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_6",
  "x": "The fact that we use deletion and insertion also explains why our model was able to regain a significant portion of its original performance when confronted with natural noise at test time, while <cite>previous work</cite> that trained only on substitutions and swaps was not able to do so <cite>(Belinkov and Bisk, 2018)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_7",
  "x": "Most relevant for us is the work of <cite>Belinkov and Bisk (2018)</cite> , who evaluated on natural noise obtained from Wikipedia edit histories (e.g., Max and Wisniewski, 2010) . <cite>They</cite> find that robustness to natural noise can be obtained by training on the same noise model, but that (a) training on synthetic noise does not yield robustness to natural noise at test time, and (b) training on natural noise significantly impairs performance on clean text.",
  "y": "background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_8",
  "x": "Most relevant for us is the work of <cite>Belinkov and Bisk (2018)</cite> , who evaluated on natural noise obtained from Wikipedia edit histories (e.g., Max and Wisniewski, 2010) . <cite>They</cite> find that robustness to natural noise can be obtained by training on the same noise model, but that (a) training on synthetic noise does not yield robustness to natural noise at test time, and (b) training on natural noise significantly impairs performance on clean text. In contrast, we show that training on the right kind and the right amount of synthetic noise can yield substantial improvements on natural noise at test time, without significantly impairing performance on clean data. Our ablation results suggest that deletion and insertion noise -which were not included by <cite>Belinkov and Bisk</cite> -are essential to achieving robustness to natural noise.",
  "y": "extends differences"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_9",
  "x": "<cite>Belinkov and Bisk (2018)</cite> experiment with a bag of characters, while Sakaguchi et al. (2017) use character RNNs combined with special representations for the first and last characters of each token.",
  "y": "background"
 },
 {
  "id": "13091dd4d06e11957a5cb7785b92d4_10",
  "x": "<cite>Belinkov and Bisk (2018)</cite> experiment with a bag of characters, while Sakaguchi et al. (2017) use character RNNs combined with special representations for the first and last characters of each token. <cite>These models</cite> are particularly suited for specific types of swapping and scrambling noises, but are not robust to natural noise.",
  "y": "background motivation"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_0",
  "x": "In this paper, we use a compound noun compositionality dataset (<cite>Reddy et al., 2011</cite>) to investigate the extent to which the underlying definition of context has an effect on a model's ability to support composition.",
  "y": "uses"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_1",
  "x": "Compositionality detection (<cite>Reddy et al., 2011</cite>) involves deciding whether a given multiword expression is compositional or not i.e., whether the meaning can be understood from the literal meaning of its parts. <cite>Reddy et al. (2011)</cite> introduced a dataset consisting of 90 compound nouns along with human judgments of their literality or compositionally at both the constituent and the phrase level.",
  "y": "background"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_2",
  "x": "Accordingly, as observed elsewhere (<cite>Reddy et al., 2011</cite>; Salehi et al., 2015; Yazdani et al., 2015) , compositional methods can be evaluated by correlating the similarity of composed and observed phrase representations with the human judgments of compositionality.",
  "y": "background"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_3",
  "x": "<cite>Reddy et al. (2011)</cite> carried out experiments with a vector space model built from ukWaC (Ferraresi et al., 2008) using untyped co-occurrences (window size=100). Used 3-fold cross-validation, <cite>they</cite> found that using weighted addition outperformed multiplication as a compositionality function. With <cite>their</cite> optimal settings, <cite>they</cite> achieved a Spearman's rank correlation coefficient of 0.714 with the human judgments, which remains the state-of-the-art on this dataset 1 .",
  "y": "background"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_4",
  "x": "For consistency with the experiments of <cite>Reddy et al. (2011)</cite> , the corpus used in this experiment is the same fullyannotated version of the web-derived ukWaC corpus (Ferraresi et al., 2008) .",
  "y": "background"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_5",
  "x": "For consistency with the experiments of <cite>Reddy et al. (2011)</cite> , the corpus used in this experiment is the same fullyannotated version of the web-derived ukWaC corpus (Ferraresi et al., 2008) . This corpus has been tokenised, POS-tagged and lemmatised with TreeTagger (Schmid, 1994) and dependency-parsed with the Malt Parser (Nivre, 2004) . In order to create a corpus which contains compound nouns, we further preprocessed the corpus by identifying occurrences of the 90 target compound nouns and recombining them into a single lexical item.",
  "y": "motivation"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_6",
  "x": "1 Hermann et al. (2012) proposed using generative models for modeling the compositionality of noun-noun compounds. Using interpolation to mitigate the sparse data problem, their model beat the baseline of weighted addition on the <cite>Reddy et al. (2011)</cite> evaluation task when trained on the BNC. However, these results were still significantly lower than those reported by <cite>Reddy et al. (2011)</cite> using the larger ukWaC corpus.",
  "y": "background"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_7",
  "x": "Following <cite>Reddy et al. (2011)</cite> , when using the UNI operation, we experiment with weighting the contributions of each constituent to the composed APT representation using the parameter, h. For example, if A 2 is the APT associated with the head of the phrase and A \u03b4 1 is the properly aligned APT associated with the modifier where \u03b4 is the dependency path from the head to the modifier (e.g. NMOD or AMOD), the composition operations can be defined as:",
  "y": "uses"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_8",
  "x": "Using the cbow model with 100 dimensions and a subsampling threshold of t = 10 \u22123 gives a performance of 0.74 which is significantly higher than the previous state-ofthe-art reported in <cite>Reddy et al. (2011)</cite> .",
  "y": "differences"
 },
 {
  "id": "14529822630fb469f5fc8f37aaf473_9",
  "x": "We see that the results using standard PPMI (\u03b1 = 1) significantly outperform the result reported in <cite>Reddy et al. (2011)</cite> , which demonstrates the superiority of a typed dependency space over an untyped dependency space.",
  "y": "differences"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_0",
  "x": "Good examples of the later are character-based models like Flair (Akbik et al., 2018) and masked language models like BERT<cite> (Devlin et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_1",
  "x": "In that case, only multilingual versions are available, where each language shares the quota of substrings and parameters with the rest of the languages, leading to a decrease in performance<cite> (Devlin et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_2",
  "x": "Alternatively, multilingual versions have been tested in transfer learning scenarios for other languages, where they have not been compared to monolingual versions<cite> (Devlin et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_3",
  "x": "More recently,<cite> Devlin et al. (2019)</cite> introduced BERT, a model based on the transformer architecture trained as a masked language model, which has obtained very good results on a variety of NLP tasks.",
  "y": "motivation"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_4",
  "x": "Flair (embeddings and system) have been successfully applied to sequence labeling tasks obtaining state-of-the-art results for a number of English Named Entity Recognition (NER) and Part-of-Speech tagging benchmarks (Akbik et al., 2018) , outperforming other well-known approaches such as BERT and ELMO <cite>(Devlin et al., 2019</cite>; Peters et al., 2018) .",
  "y": "background"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_5",
  "x": "We have trained a BERT<cite> (Devlin et al., 2019)</cite> model for Basque Language using the BMC corpus motivated by the rather low representation this language has in the original multilingual BERT model.",
  "y": "uses"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_6",
  "x": "Model Architecture In the same way as the original BERT architecture proposed by<cite> Devlin et al. (2019)</cite> our model is composed by stacked layers of Transformer encoders (Vaswani et al., 2017) .",
  "y": "extends differences"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_7",
  "x": "Pre-training procedure Similar to<cite> (Devlin et al., 2019)</cite> we use Adam with learning rate of 1e \u2212 4, \u03b2 1 = 0.9, \u03b2 2 = 0.999, L2 weight decay of 0.01, learning rate warmup over the first 10, 0000 steps, and linear decay of the learning rate.",
  "y": "similarities"
 },
 {
  "id": "14fcaa3645771e9ca183558eb2e9a1_8",
  "x": "For comparison between BERT models we fine-tune on the training data provided for each of the four tasks with both the official multilingual BERT<cite> (Devlin et al., 2019)</cite> model and with our BERTeus model (trained as described in Section 3.3.).",
  "y": "similarities uses"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_0",
  "x": "Hybrid self-attention/LSTM encoders were studied in the context of listenattend-spell (LAS) <cite>[27]</cite> , and the Transformer was directly adapted to speech in [19, 28, 29] ; both are encoder-decoder systems.",
  "y": "background"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_1",
  "x": "Unlike past works, we do not require convolutional frontends [19] or interleaved recurrences <cite>[27]</cite> to train self-attention for ASR.",
  "y": "differences"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_2",
  "x": "In this work, we propose and evaluate fully self-attentional networks for CTC (SAN-CTC). Unlike past works, we do not require convolutional frontends [19] or interleaved recurrences <cite>[27]</cite> to train self-attention for ASR.",
  "y": "motivation"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_3",
  "x": "While in theory, a relatively local context could suffices for ASR, this is complicated by alphabets L which violate the conditional independence assumption of CTC (e.g., English characters [36] ). Wide contexts also enable incorporation of noise/speaker contexts, as <cite>[27]</cite> suggest regarding the broad-context attention heads in the first layer of their self-attentional LAS model.",
  "y": "motivation"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_4",
  "x": "Our proposed framework ( Figure 1a ) is built around self-attention layers, as used in the Transformer encoder [22] , previous explorations of self-attention in ASR [19,<cite> 27]</cite> , and defined in Section 2.3.",
  "y": "similarities"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_5",
  "x": "One can also assign interpretations; for example, <cite>[27]</cite> argue their LAS self-attention heads are differentiated phoneme detectors.",
  "y": "background"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_6",
  "x": "Instead, we consider three fixed approaches, from least-to most-preserving of the input data: subsampling, which only takes every k-th frame; pooling, which aggregates every k consecutive frames via a statistic (average, maximum); reshaping, where one concatenates k consecutive frames into one <cite>[27]</cite> .",
  "y": "uses"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_7",
  "x": "The latter was found necessary for self-attentional LAS <cite>[27]</cite> , as additive encodings did not give convergence.",
  "y": "motivation"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_8",
  "x": "We see that unlike self-attentional LAS <cite>[27]</cite> , SAN-CTC works respectably even with no position en- coding; in fact, the contribution of position is relatively minor (compare with [21] , where location in an encoder-decoder system improved CER by 3% absolute).",
  "y": "differences"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_9",
  "x": "Inspired by <cite>[27]</cite> , we plot the standard deviation of attention weights for each head as training progresses; see Figure 2 for details.",
  "y": "similarities"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_10",
  "x": "In the first layers, we similarly observe a differentiation of variances, along with wide-context heads; in later layers, unlike <cite>[27]</cite> we still see mild differentiation of variances.",
  "y": "differences"
 },
 {
  "id": "154fd8e6b625eb93da21c09906ee90_11",
  "x": "Inspired by <cite>[27]</cite> , we plot the standard deviation of attention weights for each head as training progresses; see Figure 2 for details. In the first layers, we similarly observe a differentiation of variances, along with wide-context heads; in later layers, unlike <cite>[27]</cite> we still see mild differentiation of variances.",
  "y": "similarities differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_0",
  "x": "Although traditional AES methods typically rely on handcrafted features (Larkey, 1998; Foltz et al., 1999; Attali and Burstein, 2006; Dikli, 2006; Wang and Brown, 2008; Chen and He, 2013; Somasundaran et al., 2014; Yannakoudakis et al., 2014; Phandi et al., 2015) , recent results indicate that state-of-the-art deep learning methods reach better performance (Alikaniotis et al., 2016; <cite>Dong and Zhang, 2016</cite>; Taghipour and Ng, 2016; Song et al., 2017; Tay et al., 2018) , perhaps because these methods are able to capture subtle and complex information that is relevant to the task <cite>(Dong and Zhang, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_1",
  "x": "The empirical results indicate that our approach yields a better performance than state-of-the-art approaches (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>; Tay et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_2",
  "x": "Since the official test data of the ASAP competition is not released to the public, we, as well as others before us (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>;  1 https://www.kaggle.com/c/asap-aes/data Tay et al., 2018) , use only the training data in our experiments.",
  "y": "uses similarities"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_3",
  "x": "As <cite>Dong and Zhang (2016)</cite>, we scaled the essay scores into the range 0-1.",
  "y": "uses similarities"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_4",
  "x": "We closely followed the same settings for data preparation as (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) .",
  "y": "similarities uses"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_5",
  "x": "For the cross-domain experiments, we use the same source\u2192target domain pairs as (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) , namely, 1\u21922, 3\u21924, 5\u21926 and 7\u21928.",
  "y": "uses similarities"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_6",
  "x": "The sub-sample sizes are n t = {10, 25, 50, 100}. The sub-sampling is repeated for 5 times as in (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) to reduce bias.",
  "y": "uses"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_7",
  "x": "We compare our approach with stateof-the-art methods based on handcrafted features (Phandi et al., 2015) , as well as deep features (<cite>Dong and Zhang, 2016</cite>; Tay et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_8",
  "x": "We note that results for the cross-domain setting are reported only in some of these recent works (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) .",
  "y": "background"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_9",
  "x": "We used functions from the VLFeat li- Table 2 : In-domain automatic essay scoring results of our approach versus several state-of-the-art methods (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>; Tay et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_10",
  "x": "We first note that the histogram intersection string kernel alone reaches better overall performance (0.780) than all previous works (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>; Tay et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_11",
  "x": "Although the BOSWE model can be regarded as a shallow approach, its overall results are comparable to those of deep learning approaches (<cite>Dong and Zhang, 2016</cite>; Tay et al., 2018) .",
  "y": "similarities"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_12",
  "x": "For each and every source\u2192target pair, we report better results than both state-of-theart methods (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) .",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_13",
  "x": "Our score in this case (0.728) is even higher than both scores of Phandi et al. (2015) and <cite>Dong and Zhang (2016)</cite> when they use n t = 50.",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_14",
  "x": "We concluded that this simple apSource\u2192Target Method n t = 0 n t = 10 n t = 25 n t = 50 n t = 100 1\u21922 (Phandi et al., 2015) Table 3 : Corss-domain automatic essay scoring results of our approach versus two state-of-the-art methods (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) .",
  "y": "differences"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_15",
  "x": "Results are reported in terms of the quadratic weighted kappa (QWK) measure, using the same evaluation procedure as (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>) .",
  "y": "similarities uses"
 },
 {
  "id": "15dd59368074f3473b57d86568807f_16",
  "x": "We compared our approach on the Automated Student Assessment Prize data set, in both in-domain and crossdomain settings, with several state-of-the-art approaches (Phandi et al., 2015; <cite>Dong and Zhang, 2016</cite>; Tay et al., 2018) . Overall, the in-domain and the cross-domain comparative studies indicate that string kernels, both alone and in combination with word embeddings, attain the best performance on the automatic essay scoring task. Using a shallow approach, we report better results compared to recent deep learning approaches <cite>(Dong and Zhang, 2016</cite>; Tay et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_0",
  "x": "We make use of the RefCOCO and RefCOCO+ datasets in our work along with another recently collected referring expression dataset, released by Google, denoted in our paper as RefCOCOg <cite>[26]</cite> .",
  "y": "uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_1",
  "x": "The most relevant work to ours is Mao et al <cite>[26]</cite> which introduced the first deep learning approach to REG.",
  "y": "background"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_2",
  "x": "Three recent approaches for referring expression generation <cite>[26]</cite> and comprehension [14, 33] also take a deep learning approach. However, we add visual object comparisons and tie together language generation for multiple objects.",
  "y": "differences"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_3",
  "x": "Since then, another three REG datasets based on the object labels in MSCOCO have been collected [19,<cite> 26]</cite> .",
  "y": "background"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_4",
  "x": "The first set of models are recent state of the art deep learning approaches from Mao et al <cite>[26]</cite> . We use these as our baselines (Sec 3.1).",
  "y": "uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_5",
  "x": "For comparison, we implement both the baseline and strong model of Mao et al <cite>[26]</cite> .",
  "y": "motivation uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_6",
  "x": "In Mao et al's baseline <cite>[26]</cite> , the model uses maximum likelihood training and outputs the most likely referring expression given the target object, context, and location/size features.",
  "y": "background"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_7",
  "x": "For the referring expression generation task, rather than generating sentences for each object in an image separately [15] <cite>[26]</cite>, we consider tying the generation process together into a single task to jointly generate expressions for all objects of the same object category depicted in an image.",
  "y": "differences"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_8",
  "x": "We make use of 3 referring expression datasets in our work, all collected on top of the Microsoft COCO image collection [24] . One dataset, RefCOCOg <cite>[26]</cite> is collected in a non-interactive setting, while the other two datasets, RefCOCO and RefCOCO+, are collected interactively in a two-player game [19] .",
  "y": "uses background"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_9",
  "x": "We use this split for RefCOCOg since same division was used in the previous state-of-the-art approach <cite>[26]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_10",
  "x": "In experiments for the referring expression comprehension task, we use the same evaluation as Mao et al <cite>[26]</cite> , namely we first predict the region referred by the given expression, then we compute the intersection over union (IOU) ratio between the true and predicted bounding box.",
  "y": "similarities uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_12",
  "x": "Context Representation As previously discussed, we suggest that the approaches proposed in recent referring expression works<cite> [26,</cite> 14] make use of relatively weak contextual information, by only considering a single global image context for all objects.",
  "y": "background"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_13",
  "x": "To verify this intuition, we implemented both the baseline and strong MMI models from Mao et al <cite>[26]</cite> , and compare the results for referring expression comprehension task with and without global context on RefCOCO and Refcoco+ in Table 1 .",
  "y": "uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_14",
  "x": "For RefCOCOg, we evaluate on the per-object split as previous work <cite>[26]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_15",
  "x": "We observe that our implementation of Mao et al <cite>[26]</cite> achieves comparable performance to the numbers reported in their paper.",
  "y": "similarities uses"
 },
 {
  "id": "163770df02c1110edc60e7cac90ad2_16",
  "x": "For RefCOCOg, we use the detection results provided by <cite>[26]</cite> , which were trained uisng Multibox [4] .",
  "y": "uses"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_0",
  "x": "Previous works<cite> (Rubin et al., 2016</cite>; Rashkin et al., 2017) rely on various linguistic and handcrafted semantic features for differentiating between news articles.",
  "y": "background"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_1",
  "x": "We present a series of experiments on News Corpus with Varying Reliability dataset (Rashkin et al., 2017) and Satirical Legitimate News dataset<cite> (Rubin et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_2",
  "x": "<cite>Rubin et al. (2016)</cite> defines news satire as a genre of satire that mimics the format and style of journalistic reporting.",
  "y": "background"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_3",
  "x": "Datasets created for the task of identifying satirical news articles from the trusted ones are often constructed by collecting documents from different online sources<cite> (Rubin et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_4",
  "x": "<cite>Rubin et al. (2016)</cite> 's work by offering a quantitative study of linguistic differences found in articles of different types of fake news such as hoax, propaganda and satire. They also proposed predictive models for graded deception across multiple domains. We show that our proposed neural network based on graph convolutional layers can outperform this model.",
  "y": "differences"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_5",
  "x": "We use SLN: Satirical and Legitimate News Database<cite> (Rubin et al., 2016)</cite> , RPN: Random Political News Dataset (Horne and Adali, 2017) and LUN: Labeled Unreliable News Dataset Rashkin et al. (2017) for our experiments.",
  "y": "uses"
 },
 {
  "id": "18ef4e4fafdf62839d6797d62eb76b_6",
  "x": "Given that we use SLN as an out of domain test set (just one overlapping source, no overlap in articles), whereas the SoTA paper<cite> (Rubin et al., 2016)</cite> reports a 10fold cross validation number on SLN.",
  "y": "differences"
 },
 {
  "id": "19a62878f72c84d1c5c83a9a8cdeff_0",
  "x": "For sociological reasons, these arguments started appearing in print many years later [20, 5, <cite>21]</cite> .",
  "y": "background"
 },
 {
  "id": "19a62878f72c84d1c5c83a9a8cdeff_1",
  "x": "For the case of a single head and its dependents, the minimization of dependency lengths yields that the head should be placed at the center of the sequence whereas the principle of predictability maximization (or uncertainty minimization) yields that the head should be placed at one of the ends of the sequence (last if the head is the target of the prediction; first otherwise)<cite> [21,</cite> 20] .",
  "y": "background"
 },
 {
  "id": "19a62878f72c84d1c5c83a9a8cdeff_2",
  "x": "The real challenge for psycholinguistic research is not the extent to which the theoretical framework above is supported by current results in the lab but rather to increase the precision of dependency length measurements and investigate the experimental conditions in which the following theoretical predictions are observed [20, <cite>21]</cite> : one principle beating the other, coexistence, collaboration between principles or the very same trade-off causing the delusion that word order constraints have relaxed dramatically or even disappeared.",
  "y": "uses background"
 },
 {
  "id": "19a62878f72c84d1c5c83a9a8cdeff_3",
  "x": "For sociological reasons, these arguments started appearing in print many years later [20, 5, <cite>21]</cite> .",
  "y": "background"
 },
 {
  "id": "19a62878f72c84d1c5c83a9a8cdeff_4",
  "x": "For the case of a single head and its dependents, the minimization of dependency lengths yields that the head should be placed at the center of the sequence whereas the principle of predictability maximization (or uncertainty minimization) yields that the head should be placed at one of the ends of the sequence (last if the head is the target of the prediction; first otherwise)<cite> [21,</cite> 20] .",
  "y": "background"
 },
 {
  "id": "19a62878f72c84d1c5c83a9a8cdeff_5",
  "x": "The real challenge for psycholinguistic research is not the extent to which the theoretical framework above is supported by current results in the lab but rather to increase the precision of dependency length measurements and investigate the experimental conditions in which the following theoretical predictions are observed [20, <cite>21]</cite> : one principle beating the other, coexistence, collaboration between principles or the very same trade-off causing the delusion that word order constraints have relaxed dramatically or even disappeared.",
  "y": "uses background"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_0",
  "x": "Recent work that incorporated Dirichlet process (DP) nonparametric models into TSGs has provided an efficient solution to the problem of segmenting training data trees into elementary parse tree fragments to form the grammar (Cohn et al., 2009;<cite> Cohn and Blunsom, 2010</cite>; Post and Gildea, 2009) .",
  "y": "background"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_1",
  "x": "The canonical P 0 uses a probabilistic CFGP that is fixed a priori to sample CFG rules top-down and Bernoulli variables for determining where substitutions should occur (Cohn et al., 2009;<cite> Cohn and Blunsom, 2010)</cite> .",
  "y": "background"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_2",
  "x": "The canonical P 0 uses a probabilistic CFGP that is fixed a priori to sample CFG rules top-down and Bernoulli variables for determining where substitutions should occur (Cohn et al., 2009;<cite> Cohn and Blunsom, 2010)</cite> . We extend this model by adding specialized DPs for left and right auxiliary trees.",
  "y": "extends"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_3",
  "x": "Following previous work, we design a blocked Metropolis-Hastings sampler that samples derivations per entire parse trees all at once in a joint fashion<cite> (Cohn and Blunsom, 2010</cite>; Shindo et al., 2011) .",
  "y": "uses"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_4",
  "x": "It is then straightforward to represent this TSG as a CFG using the Goodman transform (Goodman, 2002;<cite> Cohn and Blunsom, 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_5",
  "x": "We compare our system (referred to as TIG) to our implementation of the TSG system of<cite> (Cohn and Blunsom, 2010</cite> ) (referred to as TSG) and the constrained TIG variant of (Shindo et al., 2011 ) (referred to as TIG 0 ).",
  "y": "uses"
 },
 {
  "id": "1a17ae4e5c8ea9e605f129aa96a6ee_6",
  "x": "We compare our system (referred to as TIG) to our implementation of the TSG system of<cite> (Cohn and Blunsom, 2010</cite> ) (referred to as TSG) and the constrained TIG variant of (Shindo et al., 2011 ) (referred to as TIG 0 ). The upshot of our experiments is that, while on the large training set all models have similar performance (85.6, 85.3, 85 .4 for TSG, TIG 0 and TIG respectively), on the small dataset insertion helps nonparametric model to find more compact and generalizable representations for the data, which affects parsing performance (Figure 4 ).",
  "y": "uses similarities"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_0",
  "x": "The second factor is the formulation of standard machine comprehension benchmarks based on Cloze-style queries<cite> (Hill et al., 2015</cite>; Hermann et al., 2015) , which permit fast integration loops between model conception and experimental evaluation.",
  "y": "background"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_1",
  "x": "In a pragmatic approach, recent work<cite> (Hill et al., 2015)</cite> formed such questions by extracting a sentence from a larger document.",
  "y": "background"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_2",
  "x": "We present a novel iterative, alternating attention mechanism that, unlike existing models<cite> (Hill et al., 2015</cite>; Kadlec et al., 2016) , does not compress the query to a single representation, but instead alternates its attention between the query and the document to obtain a fine-grained query representation within a fixed computation time.",
  "y": "differences"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_4",
  "x": "One of the advantages of using Cloze-style questions to evaluate machine comprehension systems is that a sufficient amount of training and test data can be obtained without human intervention. The CBT<cite> (Hill et al., 2015)</cite> and CNN (Hermann et al., 2015) corpora are two such datasets.",
  "y": "background"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_5",
  "x": "We will focus our evaluation solely on the first two subsets, i.e. CBT-NE (named entity) and CBT-CN (common nouns), since the latter two are relatively simple as demonstrated by<cite> (Hill et al., 2015)</cite> .",
  "y": "motivation"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_6",
  "x": "The attention we use here is similar to the formulation used in<cite> (Hill et al., 2015</cite>; Sukhbaatar et al., 2015) , but with two differences. First, we use a bilinear term instead of a simple dot product in order to compute the importance of each query term in the current time step. This simple bilinear attention has been successfully used in (Luong et al., 2015) . Second, we add a term a q that allows to bias the attention mechanism towards words which tend to be important across the questions independently of the search key s t\u22121 .",
  "y": "similarities differences"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_8",
  "x": "The Humans, LSTMs and Memory Networks (MemNNs) results are taken from<cite> (Hill et al., 2015)</cite> and the Attention-Sum Reader (AS Reader) is a state-of-the-art result recently obtained by (Kadlec et al., 2016) .",
  "y": "uses"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_10",
  "x": "Our model is closely related to (Sukhbaatar et al., 2015; Kumar et al., 2015; Hermann et al., 2015; Kadlec et al., 2016;<cite> Hill et al., 2015)</cite> , which were also applied to question answering.",
  "y": "similarities"
 },
 {
  "id": "1cd671c60486a137377096cae435ec_11",
  "x": "Finally, our iterative inference process shares similarities to the iterative hops in Memory Networks (Sukhbaatar et al., 2015;<cite> Hill et al., 2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "1f463f2f87bc2d572299d96481084f_0",
  "x": "Bootstrap resampling was one of the early randomized methods proposed for statistical significance testing of MT (Germann, 2003; Och, 2003; Kumar and Byrne, 2004;<cite> Koehn, 2004)</cite> , to assess for a pair of systems how likely a difference in BLEU scores occurred by chance.",
  "y": "background"
 },
 {
  "id": "1f463f2f87bc2d572299d96481084f_1",
  "x": "Empirical tests detailed in<cite> Koehn (2004)</cite> show that even for test sets as small as 300 translations, BLEU confidence intervals can be computed as accurately as if they had been computed on a test set 100 times as large.",
  "y": "background"
 },
 {
  "id": "1f463f2f87bc2d572299d96481084f_2",
  "x": "We also note that the pseudo-code contains an unconventional computation of mean pseudo-statistics, \u03c4 B , for shiftto-zero. Rather than speculate over whether these issues with the original paper were simply presentational glitches or the actual basis of the experiments reported on in the paper, we present a normalized version of the two-sided bootstrap algorithm in Figure 1 , and report on the results of our own experiments in Section 4. We compare this method with approximate randomization and also paired bootstrap resampling<cite> (Koehn, 2004)</cite> , which is widely used in MT evaluation.",
  "y": "motivation differences"
 },
 {
  "id": "1f463f2f87bc2d572299d96481084f_3",
  "x": "A bootstrap pseudo-sample consists of the translations by the two systems (X b , Y b ) of a bootstrapped test set<cite> (Koehn, 2004)</cite> , constructed by sampling with replacement from the original test set translations.",
  "y": "uses background"
 },
 {
  "id": "1f72d18331beaef7adf4a78d1619c6_0",
  "x": "Our method is a modification of QVEC-an evaluation based on alignment of embeddings to a matrix of features extracted from a linguistic resource <cite>(Tsvetkov et al., 2015)</cite> .",
  "y": "extends"
 },
 {
  "id": "1f72d18331beaef7adf4a78d1619c6_1",
  "x": "To evaluate the semantic content of word vectors,<cite> Tsvetkov et al. (2015)</cite> exploit supersense annotations in a WordNetannotated corpus-SemCor (Miller et al., 1993 Table 2 : Linguistic dimension word vector matrix with syntactic vectors, constructed using PTB.",
  "y": "background"
 },
 {
  "id": "1f72d18331beaef7adf4a78d1619c6_2",
  "x": "We extend the setup of<cite> Tsvetkov et al. (2015)</cite> with two syntactic benchmarks, and evaluate QVEC-CCA with the syntactic matrix.",
  "y": "extends"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_0",
  "x": "Furthermore, there is good evidence that detecting communities at risk using computational models trained on social media data is possible<cite> (Fried et al., 2014</cite>; Culotta, 2014) .",
  "y": "background"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_1",
  "x": "Furthermore, there is good evidence that detecting communities at risk using computational models trained on social media data is possible<cite> (Fried et al., 2014</cite>; Culotta, 2014) . However, in all cases, classification is made on aggregated data from cities, counties, or states, so these models are not immediately applicable to the task of classifying individuals. Our work takes the first steps towards transferring a classification model that identifies communities that are more overweight than average to classifying overweight (and thus at-risk for T2DM) individuals.",
  "y": "extends"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_2",
  "x": "Despite the model's simplicity, it outperforms<cite> Fried et al. (2014)</cite> 's best model by 2% accuracy.",
  "y": "differences"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_3",
  "x": "In the last couple of years, several variants of this problem have been considered<cite> (Fried et al., 2014</cite>; Abbar et al., 2015; Culotta, 2014; Ardehaly and Culotta, 2015) .",
  "y": "background"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_4",
  "x": "Importantly,<cite> Fried et al. (2014)</cite> train and test their models on communities rather than individuals, which limits the applicability of their approach to individualized public health.",
  "y": "motivation"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_5",
  "x": "Even though performing classification at state or county granularity tends to be robust and accurate<cite> (Fried et al., 2014)</cite> , characteristics that are specific to individuals are more meaningful and practical.",
  "y": "differences"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_6",
  "x": "To this end, we started with the same settings as<cite> Fried et al. (2014)</cite> : we used the 887,310 tweets they collected which were localizable to a specific state and contained at least one relevant hashtag, such as #breakfast or #dinner.",
  "y": "uses"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_7",
  "x": "To mitigate sparsity, we also included topics generated using Latent Dirichlet Allocation (LDA) (Blei et al., 2003) and all tweets collected by Fried et al. For example, one of the generated topics contains words that approximate the standard American diet (e.g., chicken, potatoes, cheese, baked, beans, fried, mac), which has already been shown to correlate with higher overweight and T2DM rates<cite> (Fried et al., 2014</cite> Figure 2 : A decision tree from the random forest classifier trained using state-level Twitter data.",
  "y": "uses"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_8",
  "x": "Majority baseline 50.89 SVM<cite> (Fried et al., 2014)</cite> 80.39 RF (food + hashtags) 82.35 Discretized RF (food + hashtags) 78.43 Table 2 : Random forest (RF) classifier performance on state-level data relative to majority baseline and<cite> Fried et al. (2014)</cite> 's best classifier.",
  "y": "uses"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_9",
  "x": "identical experimental settings as<cite> (Fried et al., 2014)</cite> , i.e., leave-one-out-cross-validation on the 50 states plus the District of Columbia.",
  "y": "uses"
 },
 {
  "id": "1f77b780c98093cd85966243471a1d_10",
  "x": "The table shows that our best model performs 2% better than the best model of<cite> (Fried et al., 2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_0",
  "x": "Therefore, in conjunction with this task, we present the Offensive Language Identification Dataset (OLID)<cite> (Zampieri et al., 2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_1",
  "x": "In OffensEval 1 we use OLID<cite> (Zampieri et al., 2019)</cite> and propose one sub-task for each layer of annotation as presented in Section 3.",
  "y": "extends differences"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_2",
  "x": "The remainder of this paper is organized as follows: Section 3 presents the shared task description and the sub-tasks included in OffensEval and Section 4 includes a brief description of OLID based on <cite>Zampieri et al. (2019)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_3",
  "x": "While each of these sub-tasks tackle a particular type of abuse or offense, they share similar properties and the hierarchical annotation model pro-posed proposed in OLID<cite> (Zampieri et al., 2019)</cite> and used in OffensEval aims to capture this.",
  "y": "similarities uses"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_4",
  "x": "OLID was annotated using a hierarchical three-level annotation model introduced in <cite>Zampieri et al. (2019)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_5",
  "x": "A detailed description of the data collection process and annotation is presented in <cite>Zampieri et al. (2019)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "1ffadfc2d4961beeb1621502298a70_6",
  "x": "In OffensEval we used OLID<cite> (Zampieri et al., 2019)</cite> , a dataset containing English tweets annotated with a hierarchical three-layer annotation model which considers 1) whether a message is offensive or not (sub-task A); 2) what is the type of the offensive 7 In the camera-ready version of this report we will be including a Table with references to all system descriptions papers.",
  "y": "similarities uses"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_0",
  "x": "One method for addressing this difficulty is the reordering-as-preprocessing approach, exemplified by <cite>Collins et al. (2005)</cite> and Xia and McCord (2004) , where PSMT is coupled with a preprocessing step that reorders input sentences to more closely parallel the target language word order.",
  "y": "background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_1",
  "x": "Although this leads to improved performance overall, <cite>Collins et al. (2005)</cite> show that the reordering-as-preprocessing system does not consistently provide better translations than the PSMT baseline on a sentence-by-sentence basis.",
  "y": "motivation background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_2",
  "x": "We reimplement the <cite>Collins et al. (2005)</cite> reordering preprocessing step and conduct some preliminary experiments in German-toEnglish translation ( \u00a74).",
  "y": "uses"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_3",
  "x": "Our results ( \u00a75) do not replicate the finding of <cite>Collins et al. (2005)</cite> that the preprocessing step produces better translation results overall.",
  "y": "differences"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_4",
  "x": "Our work builds on the reordering-aspreprocessing approach of <cite>Collins et al. (2005)</cite> .",
  "y": "extends"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_5",
  "x": "Working with German-to-English translation, <cite>Collins et al. (2005)</cite> parse input sentences with a constituent-structure parser and apply six hand-crafted rules to reorder the German text toward English word order.",
  "y": "background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_6",
  "x": "Despite the success of the reordering-aspreprocessing approach overall, <cite>Collins et al. (2005)</cite> found that in a human evaluation on 100 sentences, there were still several cases in which the baseline system translation was preferred over that produced with the reordering.",
  "y": "background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_7",
  "x": "Zwarts and Dras (2008) explore the <cite>Collins et al. (2005)</cite> finding by examining whether machine learning techniques can be used to predict, on a sentence-by-sentence basis, whether the translation of the reordered sentence is to be preferred over the alternative.",
  "y": "background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_8",
  "x": "Zwarts and Dras (2008) explore the <cite>Collins et al. (2005)</cite> finding by examining whether machine learning techniques can be used to predict, on a sentence-by-sentence basis, whether the translation of the reordered sentence is to be preferred over the alternative. Our work has some similarities to that of Zwarts and Dras (2008) but uses the log-linear model of the translation system itself to include features, rather than a separate classifier that does not permit interaction between the confidence features and features used during translation.",
  "y": "differences background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_9",
  "x": "For reordering, we use the Berkeley parser (Petrov et al., 2006 ) and the rules given by <cite>Collins et al. (2005)</cite> , but any reordering preprocessing step could equally be used.",
  "y": "uses"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_10",
  "x": "5 For the reordering preprocessing step we reimplement the <cite>Collins et al. (2005)</cite> rules and use this to recreate the <cite>Collins et al. (2005)</cite> reordering-aspreprocessing system as our second baseline.",
  "y": "uses"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_11",
  "x": "Since the German parsing model provided on the parser website does not include the function labels needed by the <cite>Collins et al. (2005)</cite> rules, we trained a new parsing model on the Tiger corpus (version 1).",
  "y": "differences"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_12",
  "x": "We compare four systems on German-toEnglish translation: the Moses baseline (MOSES), the <cite>Collins et al. (2005)</cite> baseline (REORDER), the lattice system with just the reordering indicator feature (LATTICE), and the lattice system with all 3 It is possible that in practice the imbalance in number of non-zero features between the two paths could cause the system some difficulty in assigning the weights for each feature.",
  "y": "uses"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_13",
  "x": "We note that these numbers are lower than those reported by <cite>Collins et al. (2005)</cite> .",
  "y": "differences"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_14",
  "x": "8 Interestingly, our reimplementation of the <cite>Collins et al. (2005)</cite> baseline does not outperform the plain PSMT baseline.",
  "y": "uses"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_15",
  "x": "It may also be that the inconsistency of improvement noted by <cite>Collins et al. (2005)</cite> is the cause; sometimes the reordering produces better results and sometimes the baseline, with the effect just by chance favouring the baseline here.",
  "y": "uses background"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_16",
  "x": "The BLEU score for the oracle is higher than that of both baselines; from this and the distribution of the oracle's choices, we conclude that the difference between our findings and those of <cite>Collins et al. (2005)</cite> is at least partly due to the inconsistency that they identified.",
  "y": "differences"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_17",
  "x": "For future systems, we would like to replace the <cite>Collins et al. (2005)</cite> reordering rules with a set of automatically-extracted reordering rules (as in Xia and McCord (2004) ) so that we may more easily explore the usefulness of our system and confidence features in new language pairs with a variety of reordering requirements.",
  "y": "future_work"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_18",
  "x": "In addition, we wish to explore more fully our negative result with the reimplementation of the <cite>Collins et al. (2005)</cite> system, to investigate the effect of balancing features in the lattice, and to examine the variability of the BLEU scores for each system.",
  "y": "future_work"
 },
 {
  "id": "20b605ec3596ccd204b60cf893b738_19",
  "x": "While our reordering step is a reimplementation of the <cite>Collins et al. (2005)</cite> system, contrary to their findings we do not see an improvement using the reordering step alone.",
  "y": "uses differences"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_0",
  "x": "The most widely used technique is the use of beam search with n-gram LMs proposed by<cite> Nuhn et al. (2013)</cite> .",
  "y": "background"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_1",
  "x": "Previous work using pretrained language models (LMs) for decipherment use n-gram LMs (Ravi and Knight, 2011;<cite> Nuhn et al., 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_2",
  "x": "We use the notation from<cite> Nuhn et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_3",
  "x": "Finding this argmax is solved using a beam search algorithm<cite> (Nuhn et al., 2013)</cite> which incrementally finds the most likely substitutions using the language model scores as the ranking.",
  "y": "background"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_4",
  "x": "Algorithm 1 is the beam search algorithm<cite> (Nuhn et al., 2013</cite> (Nuhn et al., , 2014 Hs.",
  "y": "background"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_5",
  "x": "In this experiment we use a synthetic 1:1 letter substitution cipher dataset following Ravi and Knight (2008) ,<cite> Nuhn et al. (2013)</cite> and Hauer et al. (2014) .",
  "y": "similarities uses"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_6",
  "x": "Our neural LM model with global rest cost estimation and frequency matching heuristic with a beam size of 1M has SER of 1.2% compared to the beam search algorithm<cite> (Nuhn et al., 2013)</cite> with beam size of 10M with a 6-gram LM which gives an SER of 2%.",
  "y": "background"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_7",
  "x": "Nuhn et al. (2014) present various improvements to the beam search algorithm in<cite> Nuhn et al. (2013)</cite> including improved rest cost estimation and an optimized strategy for ordering decipherment of the cipher symbols.",
  "y": "background"
 },
 {
  "id": "2357152e66ad3ae1c23738ac95f971_8",
  "x": "We modify the beam search algorithm for decipherment from<cite> Nuhn et al. (2013</cite>; and extend it to use global scoring of the plaintext message using neural LMs.",
  "y": "extends differences"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_0",
  "x": "We provide several popular schedulers, e.g., the inverse square-root scheduler from <cite>Vaswani et al. (2017)</cite> and cyclical schedulers based on warm restarts (Loshchilov and Hutter, 2016) .",
  "y": "similarities uses"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_1",
  "x": "FAIRSEQ provides fast inference for non-recurrent models (Gehring et al., 2017;<cite> Vaswani et al., 2017</cite>; Fan et al., 2018b; Wu et al., 2019) through incremental decoding, where the model states of previously generated tokens are cached in each active beam and re-used.",
  "y": "background"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_2",
  "x": "We provide reference implementations of several popular sequence-to-sequence models which can be used for machine translation, including LSTM (Luong et al., 2015) , convolutional models (Gehring et al., 2017; Wu et al., 2019) and Transformer<cite> (Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_3",
  "x": "For En-De we replicate the setup of <cite>Vaswani et al. (2017)</cite> which relies on WMT'16 for training with 4.5M sentence pairs, we validate on newstest13 and test on newstest14.",
  "y": "similarities uses"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_4",
  "x": "All results use beam search with a beam width of 4 and length penalty of 0.6, following<cite> Vaswani et al. 2017</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_5",
  "x": "We reported improved BLEU scores over <cite>Vaswani et al. (2017)</cite> by training with a bigger batch size and an increased learning rate .",
  "y": "differences"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_6",
  "x": "FAIRSEQ supports language modeling with gated convolutional models and Transformer models<cite> (Vaswani et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "242aacd35fb92d836fea9eb33961a3_7",
  "x": "Models can be trained using a variety of input and output representations, such as standard token embeddings, convolutional character embeddings (Kim 1 En-De En-Fr a. Gehring et al. (2017) 25.2 40.5 b. <cite>Vaswani et al. (2017)</cite> 28.4 41.0 c. Ahmed et al. (2017) 28.9 41.4 d. Shaw et al. (2018) 29 et al., 2016), adaptive softmax (Grave et al., 2017) , and adaptive inputs .",
  "y": "background"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_0",
  "x": "Neural sequence-to-sequence models define the state of the art for paradigm completion (Cotterell et al., 2016 <cite>(Cotterell et al., , 2017</cite> Kann and Sch\u00fctze, 2016) , the task of generating inflected forms of a lemma's paradigm, e.g., filling the empty fields in Table 1 using one of the non-empty fields.",
  "y": "background"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_1",
  "x": "Neural sequence-to-sequence models define the state of the art for paradigm completion (Cotterell et al., 2016 <cite>(Cotterell et al., , 2017</cite> Kann and Sch\u00fctze, 2016) , the task of generating inflected forms of a lemma's paradigm, e.g., filling the empty fields in Table 1 using one of the non-empty fields. However, those models are in general very datahungry, and do not reach good performances in low-resource settings.",
  "y": "background motivation"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_2",
  "x": "Neural sequence-to-sequence models define the state of the art for paradigm completion (Cotterell et al., 2016 <cite>(Cotterell et al., , 2017</cite> Kann and Sch\u00fctze, 2016) , the task of generating inflected forms of a lemma's paradigm, e.g., filling the empty fields in Table 1 using one of the non-empty fields. However, those models are in general very datahungry, and do not reach good performances in low-resource settings. While closer related languages seem to help more than distant ones, the mechanisms how this transfer works still remain largely obscure.",
  "y": "motivation"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_3",
  "x": "Therefore,<cite> Kann et al. (2017)</cite> propose to leverage morphological knowledge from a high-resource language (source language) to improve paradigm completion in a closely related language with insufficient resources (target language). However,<cite> Kann et al. (2017)</cite> show that transferring morphological knowledge from Spanish to Portuguese, two languages with similar morphology and 89% lexical similarity, works well and, more surprisingly, even supposedly very different languages like Arabic and Spanish can benefit from each other.",
  "y": "background"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_4",
  "x": "Therefore,<cite> Kann et al. (2017)</cite> propose to leverage morphological knowledge from a high-resource language (source language) to improve paradigm completion in a closely related language with insufficient resources (target language). While closer related languages seem to help more than distant ones, the mechanisms how this transfer works still remain largely obscure.",
  "y": "motivation"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_5",
  "x": "However,<cite> Kann et al. (2017)</cite> show that transferring morphological knowledge from Spanish to Portuguese, two languages with similar morphology and 89% lexical similarity, works well and, more surprisingly, even supposedly very different languages like Arabic and Spanish can benefit from each other.",
  "y": "background"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_6",
  "x": "The model<cite> Kann et al. (2017)</cite> use and we explore in more detail here is an encoder-decoder recurrent neural network (RNN) with attention (Bahdanau et al., 2015) .",
  "y": "background"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_7",
  "x": "We use the Romance and Arabic language data from<cite> Kann et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_8",
  "x": "This explains the unexpected result that l-emb performs best for Arabic (200) and Portuguese (200): both source languages potentially confuse the language model; in Portuguese we contribute this to a big overlap of lemmata in the two languages with Portuguese often inflecting in a different way<cite> (Kann et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "28900a293048fdb0c40dc540985cf1_9",
  "x": "SIGMORPHON hosted two shared tasks on paradigm completion (Cotterell et al., 2016 <cite>(Cotterell et al., , 2017</cite> , in order to encourage the development of systems for the task.",
  "y": "background"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_0",
  "x": "On the other hand, recent studies for abstractive summarization<cite> (Chen and Bansal, 2018</cite>; Hsu et al., 2018; Gehrmann et al., 2018) have attempted to exploit extractive models.",
  "y": "background"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_1",
  "x": "Among these, a notable one is<cite> Chen and Bansal (2018)</cite> , in which a sophisticated model called Reinforce-Selected Sentence Rewriting is proposed.",
  "y": "background"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_2",
  "x": "In this paper, we improve the model of<cite> Chen and Bansal (2018)</cite> , addressing two primary issues.",
  "y": "extends"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_3",
  "x": "In this paper, we focus on single-document multisentence summarization and propose a neural abstractive model based on the Sentence Rewriting framework<cite> (Chen and Bansal, 2018</cite>; Xu and Dur-rett, 2019) which consists of two parts: a neural network for the extractor and another network for the abstractor.",
  "y": "extends"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_4",
  "x": "As the decoder structure is almost the same with the previous work, we convey the equations of<cite> Chen and Bansal (2018)</cite> to avoid confusion, with minor modifications to agree with our notations.",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_5",
  "x": "Our abstractor is practically identical to the one proposed in<cite> Chen and Bansal (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_6",
  "x": "Thus, we pre-train the network using cross entropy (CE) loss like previous work (Bahdanau et al., 2017;<cite> Chen and Bansal, 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_7",
  "x": "Following<cite> Chen and Bansal (2018)</cite> , we use the Advantage Actor Critic (Mnih et al., 2016) method to train.",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_8",
  "x": "On the CNN/Daily Mail and DUC-2002 dataset, we use standard ROUGE-1, ROUGE-2, and ROUGE- L (Lin, 2004) on full length F 1 with stemming as previous work did (Nallapati et al., 2017; See et al., 2017;<cite> Chen and Bansal, 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_9",
  "x": "However, as Table 2 shows, ROUGE scores of lead baselines and extractors from previous work in Sentence Rewrite framework<cite> (Chen and Bansal, 2018</cite>; Xu and Durrett, 2019) are almost tie.",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_10",
  "x": "The combined model (BERT-ext + abs) without additional RL training outperforms the Sentence Rewrite model<cite> (Chen and Bansal, 2018)</cite> without reranking, showing the effectiveness of our extractor network.",
  "y": "differences"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_11",
  "x": "With the proposed RL training procedure (BERT-ext + abs + RL), our model exceeds the best model of<cite> Chen and Bansal (2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_12",
  "x": "In addition, the result is better than those of all the other abstractive methods exploiting extractive approaches in them (Hsu et al., 2018; <cite>Chen and Bansal, 2018</cite>; Gehrmann et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_13",
  "x": "We tried Trigram Blocking (Liu, 2019) for extractor and Reranking<cite> (Chen and Bansal, 2018)</cite> for abstractor, and we empirically found that the reranking only improves the performance.",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_14",
  "x": "This search method matches with the best reward from<cite> Chen and Bansal (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_15",
  "x": "Relevance Readability Total Sentence Rewrite<cite> (Chen and Bansal, 2018)</cite> 56 59 115 BERTSUM (Liu, 2019) 58 60 118 BERT-ext + abs + RL + rerank (ours) 66 61 127 which has the highest summary-level ROUGE-L score, from all the possible combinations of sentences.",
  "y": "differences"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_16",
  "x": "We train the same model with different training signals; Sentencelevel reward from<cite> Chen and Bansal (2018)</cite> and combinatorial reward from ours.",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_17",
  "x": "We randomly select 20 samples from the CNN/Daily Mail test set and ask the human testers (3 for each sample) to rank summaries (for relevance and readability) produced by 3 different models: our final model, that of<cite> Chen and Bansal (2018)</cite> and that of Liu (2019) .",
  "y": "uses"
 },
 {
  "id": "2a01240f628d7deb74e6e9fe750378_18",
  "x": "Some notable examples include the use of inconsistency loss (Hsu et al., 2018) , key phrase extraction (Li et al., 2018; Gehrmann et al., 2018) , and sentence extraction with rewriting<cite> (Chen and Bansal, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_0",
  "x": "Following Poon and Domingos (2009), we consider a semantic parsing setting where the goal is to (1) decompose the syntactic dependency tree of a sentence into fragments, (2) assign each of these fragments to a cluster of semantically equivalent syntactic structures, and (3) predict predicate-argument relations between the fragments. While a similar direction has been previously explored in (Swier and Stevenson, 2004; Abend et al., 2009; Lang and Lapata, 2010) , the recent work of <cite>(Poon and Domingos, 2009</cite> ) takes it one step further by not only predicting predicate-argument structure of a sentence but also assigning sentence fragments to clusters of semantically similar expressions.",
  "y": "background"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_1",
  "x": "Statistical approaches to semantic parsing have recently received considerable attention. However, most of this research has concentrated on supervised methods requiring large amounts of labeled data. These approaches cluster semantically equivalent verbalizations of relations, often relying on syntactic fragments as features for relation extraction and clustering (Lin and Pantel, 2001; Banko et al., 2007) . The success of these methods suggests that semantic parsing can also be tackled as clustering of syntactic realizations of predicate-argument relations. While a similar direction has been previously explored in (Swier and Stevenson, 2004; Abend et al., 2009; Lang and Lapata, 2010) , the recent work of <cite>(Poon and Domingos, 2009</cite> ) takes it one step further by not only predicting predicate-argument structure of a sentence but also assigning sentence fragments to clusters of semantically similar expressions.",
  "y": "background"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_2",
  "x": "Our non-parametric model automatically discovers granularity of clustering appropriate for the dataset, unlike the parametric method of<cite> (Poon and Domingos, 2009)</cite> which have to perform model selection and use heuristics to penalize more complex models of semantics.",
  "y": "differences"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_3",
  "x": "More detailed discussion of relation between the Markov Logic Network (MLN) approach of <cite>(Poon and Domingos, 2009</cite> ) and our non-parametric method is presented in Section 3.",
  "y": "background"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_4",
  "x": "In our case, the state space size equals the total number of distinct semantic clusters, and, thus, is expected to be exceedingly large even for moderate datasets: for example, the MLN model induces 18,543 distinct clusters from 18,471 sentences of the GENIA corpus <cite>(Poon and Domingos, 2009</cite> ).",
  "y": "background"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_5",
  "x": "We evaluate our model both qualitatively, examining the revealed clustering of syntactic structures, and quantitatively, on a question answering task. In both cases, we follow <cite>(Poon and Domingos, 2009</cite> ) in using the corpus of biomedical abstracts.",
  "y": "uses"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_6",
  "x": "Unlike <cite>(Poon and Domingos, 2009</cite> ), we do not use the lambda calculus formalism to define our task but rather treat it as an instance of frame-semantic parsing, or a specific type of semantic role labeling (Gildea and Jurafsky, 2002) . The reason for this is two-fold: first, the frame semantics view is more standard in computational linguistics, sufficient to describe induced semantic representation and convenient to relate our method to the previous work. Second, lambda calculus is a considerably more powerful formalism than the predicate-argument structure used in frame semantics, normally supporting quantification and logical connectors (for example, negation and disjunction), neither of which is modeled by our model or in<cite> (Poon and Domingos, 2009)</cite> .",
  "y": "background differences"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_7",
  "x": "Third, as in <cite>(Poon and Domingos, 2009</cite> ), we do not model polysemy as we assume that each syntactic fragment corresponds to a single semantic class.",
  "y": "similarities"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_8",
  "x": "As in some of the recent work on learning semantic representations (Eisenstein et al., 2009;<cite> Poon and Domingos, 2009</cite> ), we assume that dependency structures are provided for every sentence.",
  "y": "similarities"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_9",
  "x": "The work of <cite>(Poon and Domingos, 2009</cite> ) models joint probability of the dependency tree and its latent semantic representation using Markov Logic Networks (MLNs) (Richardson and Domingos, 2006) , selecting parameters (weights of first-order clauses) to maximize the probability of the observed dependency structures. For each sentence, the MLN induces a Markov network, an undirected graphical model with nodes corresponding to ground atoms and cliques corresponding to ground clauses. The MLN is a powerful formalism and allows for modeling complex interaction between features of the input (syntactic trees) and latent output (semantic representation), however, unsupervised learning of semantics with general MLNs can be prohibitively expensive. The reason for this is that MLNs are undirected models and when learned to maximize likelihood of syntactically annotated sentences, they would require marginalization over semantic representation but also over the entire space of syntactic structures and lexical units. Given the complexity of the semantic parsing task and the need to tackle large datasets, even approximate methods are likely to be infeasible.",
  "y": "motivation background"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_10",
  "x": "In order to overcome this problem, <cite>(Poon and Domingos, 2009</cite> ) group parameters and impose local normalization constraints within each group. Given these normalization constraints, and additional structural constraints satisfied by the model, namely that the clauses should be engineered in such a way that they induce treestructured graphs for every sentence, the parameters can be estimated by a variant of the EM algorithm. The class of such restricted MLNs is equivalent to the class of directed graphical models over the same set of random variables corresponding to fragments of syntactic and semantic structure. Given that the above constraints do not directly fit into the MLN methodology, we believe that it is more natural to regard their model as a directed model with an underlying generative story specifying how the semantic structure is generated and how the syntactic parse is drawn for this semantic structure. This view would facilitate understanding what kind of features can easily be integrated into the model, simplify application of non-parametric Bayesian techniques and expedite the use of inference techniques designed specifically for directed models. Our approach makes one step in this direction by proposing a non-parametric version of such generative model.",
  "y": "motivation background differences"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_11",
  "x": "We used the GENIA corpus (Kim et al., 2003) , a dataset of 1999 biomedical abstracts, and a set of questions produced by<cite> (Poon and Domingos, 2009)</cite> .",
  "y": "uses"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_12",
  "x": "We now turn to the QA task and compare our model (USP-BAYES) with the results of baselines considered in <cite>(Poon and Domingos, 2009</cite> ).",
  "y": "uses"
 },
 {
  "id": "2b836473cf682ed474b7cda1800f84_13",
  "x": "In addition to the MLN model <cite>(Poon and Domingos, 2009</cite> ), another unsupervised method has been proposed in (Goldwasser et al., 2011) .",
  "y": "background"
 },
 {
  "id": "2db9f6c8540d8d2b7a5946c3c132e9_0",
  "x": "As SVD PPMI performs very similar to word2vec on evaluation tasks while avoiding reliability problems we deem it the best currently available word embedding method for applying distributional semantics in the Digital Humanities<cite> (Hamilton et al., 2016</cite>; Hellrich and Hahn, 2016a) .",
  "y": "background"
 },
 {
  "id": "2db9f6c8540d8d2b7a5946c3c132e9_1",
  "x": "Most work is centered around word2vec (e.g., Kim et al. (2014) ; Kulkarni et al. (2015) ; Hellrich and Hahn (2016b) ), whereas alternative approaches are rare, e.g., Jo (2016) using GloVe (Pennington et al., 2014) and<cite> Hamilton et al. (2016)</cite> using SVD PPMI .",
  "y": "background"
 },
 {
  "id": "2db9f6c8540d8d2b7a5946c3c132e9_2",
  "x": "Embeddings trained on corpora specific for multiple time spans can be used for two research purposes, namely, screening the semantic evolution of lexical items over time (Kim et al., 2014; Kulkarni et al., 2015;<cite> Hamilton et al., 2016)</cite> and exploring the meaning of lexical items during a specific time span by finding their closest neighbors in embedding space.",
  "y": "background"
 },
 {
  "id": "2db9f6c8540d8d2b7a5946c3c132e9_3",
  "x": "In accordance with this limit, we also discarded slices with less than 10k (5k for RSC) 7 Parameters were chosen in accordance with Levy et al. (2015) and <cite>Hamilton et al. (2016</cite> words above the minimum frequency threshold used during PPMI and \u03c7 2 calculation, e.g., the 1810s and 1820s COHA slices.",
  "y": "uses similarities"
 },
 {
  "id": "2db9f6c8540d8d2b7a5946c3c132e9_4",
  "x": "We follow Kim et al. (2014) in choosing such a visualization, while we refrain from using the two-dimensional projection used in other studies (Kulkarni et al., 2015;<cite> Hamilton et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "2db9f6c8540d8d2b7a5946c3c132e9_6",
  "x": "Future technical work will add functionality to compare words across corpora which might require a mapping between embeddings (Kulkarni et al., 2015;<cite> Hamilton et al., 2016)</cite> and provide optional stemming routines.",
  "y": "future_work"
 },
 {
  "id": "2dc830dd598102ee82f1b982b88be9_0",
  "x": "Singular value decomposition (SVD) is a common factorization technique and has been explored in feedforward networks [9, 10, 21, 22] and recurrent neural networks (RNN) <cite>[11]</cite> .",
  "y": "background"
 },
 {
  "id": "2dc830dd598102ee82f1b982b88be9_1",
  "x": "We focus on two widely used and effective methods for deep models: low-rank matrix factorization and and quantization. Singular value decomposition (SVD) is a common factorization technique and has been explored in feedforward networks [9, 10, 21, 22] and recurrent neural networks (RNN) <cite>[11]</cite> .",
  "y": "uses background"
 },
 {
  "id": "2dc830dd598102ee82f1b982b88be9_2",
  "x": "Low-rank matrix factorization The factorization of weight matrices is based on the SVD compression of LSTM <cite>[11]</cite> .",
  "y": "background"
 },
 {
  "id": "2dc830dd598102ee82f1b982b88be9_3",
  "x": "We start by formulating the multi-class audio event detection problem. Low-rank matrix factorization The factorization of weight matrices is based on the SVD compression of LSTM <cite>[11]</cite> .",
  "y": "uses background"
 },
 {
  "id": "2dc830dd598102ee82f1b982b88be9_4",
  "x": "As the distribution of weight matrices' eigenvalues can be different across different LSTM layers, we follow the practice of <cite>[11]</cite> to set the same threshold \u03c4 across layers as the fraction of retained singular values, defined as \u03c4 = Table 1 summarizes the results of low-rank matrix factorization compared to our baseline 3-layer LSTM.",
  "y": "uses"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_0",
  "x": "Since 2014, lipreading systems have systematically begun to use neural networks at part of the processing pipeline [5, 6] or for end-to-end-training<cite> [7,</cite> 8, 9] .",
  "y": "background"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_1",
  "x": "In our previous work <cite>[7]</cite> , we proposed a fully neural network based system, using a stack of fully connected and recurrent (LSTM, Long ShortTerm Memory) [10, 11] neural network layers.",
  "y": "similarities"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_2",
  "x": "We evaluate our established system <cite>[7]</cite> in a crossspeaker setting, observing a drastic performance drop on unknown speakers.",
  "y": "similarities"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_3",
  "x": "Since then, several end-to-end trainable systems were presented<cite> [7,</cite> 8, 9] .",
  "y": "similarities"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_4",
  "x": "We follow the data preprocessing protocol from <cite>[7]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_5",
  "x": "We converted the \"normal\" quality videos (360 \u00d7 288 pixels) to greyscale and extracted 40\u00d740 pixel windows containing the mouth area, as described in <cite>[7]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_6",
  "x": "The system is based on the lipreading setup from <cite>[7]</cite> , reimplemented in Tensorflow [36] .",
  "y": "extends differences"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_7",
  "x": "* marks the (reimplemented and recomputed) best system from <cite>[7]</cite> .",
  "y": "background"
 },
 {
  "id": "2e7df0912d9aac8bf97f4061de613f_8",
  "x": "The first experiment deals with establishing a baseline for our experiments, building on prior work <cite>[7]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "2e95d98d5f9d4d6fc90e3d8453f945_0",
  "x": "1 <cite>(Tetreault and Chodorow, 2008b)</cite> challenged the view that using one rater is adequate by showing that preposition usage errors actually do not have high inter-annotator reliability.",
  "y": "background"
 },
 {
  "id": "2e95d98d5f9d4d6fc90e3d8453f945_1",
  "x": "<cite>(Tetreault and Chodorow, 2008b)</cite> showed that trained human raters can achieve very high agreement (78%) on this task.",
  "y": "background"
 },
 {
  "id": "2e95d98d5f9d4d6fc90e3d8453f945_2",
  "x": "<cite>(Tetreault and Chodorow, 2008b)</cite> showed that trained human raters can achieve very high agreement (78%) on this task. We replicate this experiment not with trained raters but with the AMT to answer two research questions: 1. Can untrained raters be as effective as trained 46 raters? 2. If so, how many raters does it take to match trained raters?",
  "y": "extends background"
 },
 {
  "id": "2e95d98d5f9d4d6fc90e3d8453f945_3",
  "x": "For example, <cite>(Tetreault and Chodorow, 2008b)</cite> found kappa between two raters averaged 0.630.",
  "y": "background"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_0",
  "x": "For German readability assessment, however, little progress has been made in recent years, despite a series of promising results published around the turn of the decade (Vor der Br\u00fcck et al., 2008;<cite> Hancke et al., 2012)</cite> .",
  "y": "background"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_1",
  "x": "To address these issues, we first present two new data sets for German readability assessment in Section 3: a set of German news broadcast subtitles based on the primary German TV news outlet Tagesschau and the children's counterpart Logo!, and a GEO/GEOlino corpus crawled from the educational GEO magazine's web site, a source first identified by <cite>Hancke et al. (2012)</cite> , but double in size.",
  "y": "extends"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_2",
  "x": "There was a series of articles on this issue from the late 2000s to the early 2010s that demonstrated the benefits of broad linguistic modeling, in particular the use of morphological complexity measures for languages with rich morphological systems like German (Vor der Br\u00fcck et al., 2008;<cite> Hancke et al., 2012)</cite> , but also Russian (Reynolds, 2016) or French (Fran\u00e7ois and Fairon, 2012) .",
  "y": "background"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_3",
  "x": "Later work by <cite>Hancke et al. (2012)</cite> also combines traditional readability formula measures, such as text or word length, with more sophisticated lexical, syntactic, and language model, and morphological features to assess German readability, but they employ an overall broader and more diverse feature set than DeLite.",
  "y": "background"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_4",
  "x": "<cite>Hancke et al. (2012)</cite> first compiled and analyzed a data set from this web resource.",
  "y": "background"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_5",
  "x": "<cite>Hancke et al. (2012)</cite> first compiled and analyzed a data set from this web resource. We followed their lead and crawled 8,263 articles from the GEO/GEOlino online archive, almost doubling the size of the original corpus.",
  "y": "uses"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_6",
  "x": "On GEO/GEOlino S , the performance is comparable to the performance observed by <cite>Hancke et al. (2012)</cite> on the original GEO/GEOlino data.",
  "y": "similarities"
 },
 {
  "id": "2e967f8560ffdb216135ae387776eb_7",
  "x": "The approach presented thus extends the state-of-the-art in <cite>Hancke et al. (2012)</cite> in terms of the breadth of features integrated and the accuracy and generalizability of the model -and provides two new data sources for this line of research.",
  "y": "extends"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_0",
  "x": "First, many bug reports have many spelling, grammatical and sentence structure errors. To address this we extend a suitable stateof-the-art technique that is robust to such corpora, i.e. (<cite>Barzilay and McKeown, 2001</cite>) .",
  "y": "motivation"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_1",
  "x": "To address this we extend a suitable stateof-the-art technique that is robust to such corpora, i.e. (<cite>Barzilay and McKeown, 2001</cite>) .",
  "y": "motivation"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_2",
  "x": "Paraphrases can be extracted from non-parallel corpora using contextual similarity (Lin, 1998) . They can also be obtained from parallel corpora if such data is available (<cite>Barzilay and McKeown, 2001</cite>; Ibrahim et al., 2003) .",
  "y": "background"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_3",
  "x": "The approach in (<cite>Barzilay and McKeown, 2001</cite>) does not use deep linguistic analysis and therefore is suitable to noisy corpora like ours.",
  "y": "background"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_4",
  "x": "The approach in (<cite>Barzilay and McKeown, 2001</cite>) does not use deep linguistic analysis and therefore is suitable to noisy corpora like ours. Due to this reason, we build our technique on top of <cite>theirs</cite>.",
  "y": "motivation"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_5",
  "x": "The approach in (<cite>Barzilay and McKeown, 2001</cite>) does not use deep linguistic analysis and therefore is suitable to noisy corpora like ours. The following provides a summary of <cite>their technique</cite>.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_6",
  "x": "The approach in (<cite>Barzilay and McKeown, 2001</cite>) does not use deep linguistic analysis and therefore is suitable to noisy corpora like ours. <cite>The authors</cite> first used identical words and phrases as seeds to find and score contextual patterns.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_7",
  "x": "Global Context-Based Scoring Our contextbased paraphrase scoring method is an extension of (<cite>Barzilay and McKeown, 2001</cite> ) described in Sec. 2.",
  "y": "extends"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_8",
  "x": "In (<cite>Barzilay and McKeown, 2001</cite> ), a paraphrase is reported as long as there is a single good supporting pair of sentences.",
  "y": "background"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_9",
  "x": "In (<cite>Barzilay and McKeown, 2001</cite> ), a paraphrase is reported as long as there is a single good supporting pair of sentences. Although <cite>this</cite> works well for a relatively clean parallel corpus considered in their work, i.e., novels, <cite>this</cite> does not work well for bug reports.",
  "y": "motivation"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_10",
  "x": "We compute the set of patterns with affixed pattern scores based on (<cite>Barzilay and McKeown, 2001</cite> ).",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_11",
  "x": "This set of chunk pairs are later fed to the method in (<cite>Barzilay and McKeown, 2001</cite> ) to produce a set of patterns with affixed scores.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_12",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_13",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. We call <cite>it</cite> BL.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_14",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. We call <cite>it</cite> BL. As described in Sec. 2, <cite>BL</cite> utilizes a threshold to control the number of patterns mined.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_15",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. We call <cite>it</cite> BL. As described in Sec. 2, <cite>BL</cite> utilizes a threshold to control the number of patterns mined. In the experiment, we find that running <cite>BL</cite> using <cite>their</cite> default threshold of 0.95 on the 5,935 parallel bug reports only gives us 18 paraphrases.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_16",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. In our approach, we first form chunk pairs from the 5,935 pairs of parallel sentences and then use the <cite>baseline approach</cite> at a low threshold to ob-tain patterns.",
  "y": "uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_17",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. We call <cite>it</cite> BL. As described in Sec. 2, <cite>BL</cite> utilizes a threshold to control the number of patterns mined. In the experiment, we find that running <cite>BL</cite> using <cite>their</cite> default threshold of 0.95 on the 5,935 parallel bug reports only gives us 18 paraphrases. This number is too small for practical purposes. Therefore, we reduce the threshold to get more paraphrases.",
  "y": "extends motivation"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_18",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. We call <cite>it</cite> BL. As described in Sec. 2, <cite>BL</cite> utilizes a threshold to control the number of patterns mined. In the experiment, we find that running <cite>BL</cite> using <cite>their</cite> default threshold of 0.95 on the 5,935 parallel bug reports only gives us 18 paraphrases. This number is too small for practical purposes.",
  "y": "motivation"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_19",
  "x": "In our approach, we first form chunk pairs from the 5,935 pairs of parallel sentences and then use the <cite>baseline approach</cite> at a low threshold to ob-tain patterns.",
  "y": "extends uses"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_20",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. From the figure we can see that our holistic approach using global-context score to rank and co-occurrence score to filter (i.e., Rk-S g +Ft-S c ) has higher precision than the <cite>baseline approach</cite> (i.e., <cite>BL</cite>) in all ks.",
  "y": "differences"
 },
 {
  "id": "2f3e2c81bed66fd020731b2475bb98_21",
  "x": "Experimental Setup The baseline method we consider is the one in (<cite>Barzilay and McKeown, 2001</cite> ) without sentence alignment -as the bug reports are usually of one sentence long. Interestingly, the graph shows that using only one of the scores alone (i.e., Rk-S g and Rk-S c ) does not result in a significantly higher precision than the <cite>baseline approach</cite>.",
  "y": "similarities differences"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_0",
  "x": "This supervision takes form of sentence-aligned parallel data [5] , pre-built word translation pairs [11,<cite> 19]</cite> or document-aligned comparable data [21] .",
  "y": "similarities uses"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_1",
  "x": "For our proposed CLIR models, we investigate cross-lingual embedding spaces produced with state-of-the-art representative methods requiring different amount and type of bilingual supervision: 1) document-aligned comparable data [21] , 2) word translation pairs <cite>[19]</cite> ; and 3) no bilingual data at all [3] .",
  "y": "similarities uses"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_2",
  "x": "This class of models [1, 11,<cite> 19]</cite> focuses on learning the projections (i.e., mappings) between independently trained monolingual embedding spaces.",
  "y": "background"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_3",
  "x": "We therefore opt for the recent model of Smith et al. <cite>[19]</cite> to serve as a baseline, due to its competitive performance, large coverage, and readily available implementation.",
  "y": "similarities uses"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_4",
  "x": "2 Technically, the method of Smith et al. <cite>[19]</cite> learns two projection functions f S ( S |\u03b8 S ) and f S ( T |\u03b8 T ), projecting the source and target monolingual embedding spaces, respectively, to the new shared space.",
  "y": "background"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_5",
  "x": "Most recently, Conneau et al. [3] have proposed an adversarial learning-based model in order to automatically, in a fully unsupervised fashion, create word translation pairs that can then be used to learn the same projection functions f S and f T as in the model of Smith et al. <cite>[19]</cite> . Let X be the set of all monolingual word embeddings from the source language, and Y the set of all target language embeddings.",
  "y": "similarities uses"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_6",
  "x": "In the second step, the projection matrix W trained with adversarial objective is used to find the mutual nearest neighbors between the two vocabularies -this set of automatically obtained word translation pairs becomes a synthetic training set for the refined projection functions f S and f T computed via the SVD-based method similar to the previously described model of Smith et al. <cite>[19]</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_7",
  "x": "The CL-WT embeddings of Smith et al. <cite>[19]</cite> use 10K translation pairs obtained from Google Translate to learn the linear mapping functions.",
  "y": "differences"
 },
 {
  "id": "320a5c79d9884e652c42f85847172b_8",
  "x": "The reported performance on bilingual lexicon extraction (BLE) using cross-lingual embedding spaces is also lower for EN-NL compared to EN-IT (see, e.g., <cite>[19]</cite> ).",
  "y": "similarities"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_0",
  "x": "Recently, <cite>Glockner et al. (2018)</cite> have shown that state-of-the-art NLI systems break considerably easily when instead of tested on the original SNLI test set, they are tested on a test set which Preprint.",
  "y": "motivation"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_1",
  "x": "The results we get are in line with <cite>Glockner et al. (2018)</cite> , showing that the generalization capability of the individual NLI systems is very limited, but, what is more, they further show the only system that was less prone to breaking in <cite>Glockner et al. (2018)</cite> , breaks in the experiments we have conducted as well.",
  "y": "extends similarities differences"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_2",
  "x": "The ability of NLI systems to generalize and related skepticism has been raised in a recent paper by <cite>Glockner et al. (2018)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_3",
  "x": "KIM is particularly interesting in this context as it performed significantly better than other models in the Breaking NLI experiment conducted by <cite>Glockner et al. (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_4",
  "x": "In contrast to the findings of <cite>Glockner et al. (2018)</cite> , utilizing external knowledge did not improve the model's generalization capability, as KIM performed equally poorly across all dataset combinations.",
  "y": "differences"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_5",
  "x": "Our findings, together with the previous negative findings e.g. by <cite>Glockner et al. (2018)</cite> and Gururangan et al. (2018) , indicate that the current state-of-the-art neural network models fail to capture the semantics of NLI in a way that will enable them to generalize across different NLI situations.",
  "y": "similarities"
 },
 {
  "id": "35ef3eba487c3cd97d32210670678a_6",
  "x": "Our findings, together with the previous negative findings e.g. by <cite>Glockner et al. (2018)</cite> and Gururangan et al. (2018) , indicate that the current state-of-the-art neural network models fail to capture the semantics of NLI in a way that will enable them to generalize across different NLI situations. The results indicate two issues to be taken into consideration: a) using datasets involving a fraction of what NLI is, will fail when tested in datasets that are testing for a slightly different definition.",
  "y": "future_work"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_0",
  "x": "At the same time, previous research on PCFG parsing using treebank training data present PAR-SEVAL measures in comparing the parsing performance for different languages and annotation schemes, reporting a number of striking differences. For example, Levy and Manning (2003) , K\u00fcbler (2005) , and <cite>K\u00fcbler et al. (2006)</cite> highlight the significant effect of language properties and annotation schemes for German and Chinese treebanks.",
  "y": "background"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_1",
  "x": "In related work, parser enhancements that provide a significant performance boost for English, such as head lexicalization, are reported not to provide the same kind of improvement, if any, for German (Dubey and Keller, 2003; Dubey, 2004;<cite> K\u00fcbler et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_2",
  "x": "<cite>K\u00fcbler et al. (2006)</cite> compares the Negra and T\u00fcBa-D/Z corpora of German using a PARSEVAL evaluation and an evaluation on core grammatical function labels that is included to address concerns about the PARSEVAL measure.",
  "y": "background"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_3",
  "x": "Dubey (2004) also includes an evaluation on grammatical function for statistical models trained on Negra, but obtains very different results from <cite>K\u00fcbler et al. (2006)</cite> .",
  "y": "background"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_4",
  "x": "2 While the focus of <cite>K\u00fcbler et al. (2006)</cite> is on comparing parsing results across corpora, Dubey (2004) focuses on improving parsing for Negra, including corpus-specific enhancements leading to better results.",
  "y": "background"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_5",
  "x": "2 While the focus of <cite>K\u00fcbler et al. (2006)</cite> is on comparing parsing results across corpora, Dubey (2004) focuses on improving parsing for Negra, including corpus-specific enhancements leading to better results. This difference in focus and additional differences in experimental setup mean that a finegrained comparison of the results is inappropriate -the relevant point here is that the gap between the results (23% for subjects, 35% for accusative objects) warrants further attention in the context of comparing parsing results across corpora. corpora of German that PARSEVAL is inappropriate for comparisons of the output of PCFG parsers trained on different treebank annotation schemes because PARSEVAL scores are affected by the ratio of terminal to non-terminal nodes. A dependencybased evaluation on triples of the form word-POShead shows better results for the parser trained on Tiger even though the much lower PARSEVAL scores, if meaningful, would predict that the output for Tiger is of lower quality. However, their dependency-based evaluation does not make use of the grammatical function labels, which are provided in the corpora and closely correspond to the representations used in recent work on formalismindependent evaluation of parsers (e.g., Clark and Curran, 2007) . 3 Addressing these issues, we resolve the apparent discrepancy between <cite>K\u00fcbler et al. (2006)</cite> and Dubey (2004) and establish a firm grammatical function comparison of Negra and T\u00fcBa-D/Z. We also extend the evaluation to a labeled dependency evaluation based on grammatical relations for both corpora.",
  "y": "motivation"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_6",
  "x": "3 Addressing these issues, we resolve the apparent discrepancy between <cite>K\u00fcbler et al. (2006)</cite> and Dubey (2004) and establish a firm grammatical function comparison of Negra and T\u00fcBa-D/Z. We also extend the evaluation to a labeled dependency evaluation based on grammatical relations for both corpora.",
  "y": "extends"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_7",
  "x": "Such an evaluation, which abstracts away from the specifics of the annotation schemes, shows that, in contrast to the claims made in <cite>K\u00fcbler et al. (2006)</cite> , the parsing results for PCFG parsers trained on these heterogeneous corpora are very similar.",
  "y": "differences"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_8",
  "x": "Following <cite>K\u00fcbler et al. (2006)</cite> , only sentences with fewer than 35 words were used, which results in 20,002 sentences for Negra and 21,365 sentences for T\u00fcBa-D/Z. Because punctuation is not attached within the sentence in the corpus annotation, punctuation was removed.",
  "y": "uses"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_9",
  "x": "To remove discontinuities, we used the conversion program included with the Negra corpus annotation tools (Brants and Plaehn, 2000) , the same tool used in <cite>K\u00fcbler et al. (2006)</cite> , which raises non-head elements to a higher tree until there are no more discontinuities.",
  "y": "uses"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_10",
  "x": "Unlike <cite>K\u00fcbler et al. (2006)</cite> , which ignored edge labels on words, we incorporate all edge labels present in both corpora.",
  "y": "differences"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_11",
  "x": "Thus, it is useful to per-7 Our experimental setup is designed to support a comparison between Negra and T\u00fcBa-D/Z for the three evaluation metrics and is intended to be comparable to the setup of <cite>K\u00fcbler et al. (2006)</cite> .",
  "y": "similarities"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_12",
  "x": "<cite>K\u00fcbler et al. (2006)</cite> present the results shown in Table 3 for the parsing performance of the unlexicalized model of the Stanford Parser (Klein and Manning, 2002) .",
  "y": "uses"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_14",
  "x": "In effect, single-word arguments in Negra -mainly pronouns and bare nouns -are not considered in the evaluation from <cite>K\u00fcbler et al. (2006)</cite> .",
  "y": "background"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_15",
  "x": "The results are shown in Table 4 In contrast to the results for NP grammatical functions of <cite>K\u00fcbler et al. (2006)</cite> we saw in Table 3 , Negra and T\u00fcBa-D/Z perform quite similarly overall, with Negra slightly outperforming T\u00fcBa-D/Z for all types of arguments.",
  "y": "uses"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_16",
  "x": "Contrary to the finding in <cite>K\u00fcbler et al. (2006)</cite> , the PAR-SEVAL evaluation does not echo the grammatical function label evaluation.",
  "y": "differences"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_17",
  "x": "Shifting the focus to the grammatical function evaluation, we showed that a grammatical function evaluation based on phrasal arguments as provided by <cite>K\u00fcbler et al. (2006)</cite> is inadequate for comparing parsers trained on the Negra and T\u00fcBa-D/Z corpora.",
  "y": "differences"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_18",
  "x": "The models trained on both corpora perform very similarly in the grammatical function evaluation, in contrast to the claims in <cite>K\u00fcbler et al. (2006)</cite> .",
  "y": "differences"
 },
 {
  "id": "366231b855f226f63d637e6b2e1667_19",
  "x": "In contrast to <cite>K\u00fcbler et al. (2006)</cite> a grammatical function evaluation on subjects, accusative objects, and dative objects establishes that Negra and T\u00fcBa-D/Z perform similarly when all types of words and phrases appearing as arguments are taken into consideration.",
  "y": "differences"
 },
 {
  "id": "3816a122d7f0847c01415fadef2d3d_0",
  "x": "In this paper, we compare CFG filtering techniques for LTAG<cite> (Harbusch, 1990</cite>; Poller and Becker, 1998) and HPSG (Torisawa et al., 2000; Kiefer and Krieger, 2000) , following an approach to parsing comparison among different grammar formalisms ).",
  "y": "uses"
 },
 {
  "id": "3816a122d7f0847c01415fadef2d3d_1",
  "x": "In this section, we introduce a grammar conversion ) and CFG filtering<cite> (Harbusch, 1990</cite>; Poller and Becker, 1998; Torisawa et al., 2000; Kiefer and Krieger, 2000) .",
  "y": "uses"
 },
 {
  "id": "3816a122d7f0847c01415fadef2d3d_2",
  "x": "In CFG filtering techniques for LTAG<cite> (Harbusch, 1990</cite>; Poller and Becker, 1998) , every branching of elementary trees in a given grammar is extracted as a CFG rule as shown in Figure 1 .",
  "y": "uses"
 },
 {
  "id": "3816a122d7f0847c01415fadef2d3d_3",
  "x": "However, CFG PB (also a CFG produced by the other work<cite> (Harbusch, 1990)</cite> ) cannot avoid generating invalid parse trees that connect two lo-cal structures where adjunction takes place between them.",
  "y": "motivation uses"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_0",
  "x": "Despite the steadily increasing body of research on text-adventure games (Bordes et al., 2010; He et al., 2016; Narasimhan et al., 2015; Fulda et al., 2017; Haroush et al., 2018; Tao et al., 2018;<cite> Ammanabrolu and Riedl, 2019)</cite> , and in addition to the ubiquity of deep reinforcement learning applications (Parisotto et al., 2016; Zambaldi et al., 2019) , teaching an agent to play text-adventure games remains a challenging task.",
  "y": "background"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_1",
  "x": "Learning a control policy for a text-adventure game requires a significant amount of exploration, resulting in training runs that take hundreds of thousands of simulations (Narasimhan et al., 2015;<cite> Ammanabrolu and Riedl, 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_2",
  "x": "Text-adventure games, in which an agent must interact with the world entirely through natural language, provide us with two challenges that have proven difficult for deep reinforcement learning to solve (Narasimhan et al., 2015; Haroush et al., 2018;<cite> Ammanabrolu and Riedl, 2019)</cite> : (1) The agent must act based only on potentially incomplete textual descriptions of the world around it.",
  "y": "background"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_3",
  "x": "Multiple recent works have explored the challenges associated with these games (Bordes et al., 2010; He et al., 2016; Narasimhan et al., 2015; Fulda et al., 2017; Haroush et al., 2018; Tao et al., 2018;<cite> Ammanabrolu and Riedl, 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_4",
  "x": "Previous work <cite>(Ammanabrolu and Riedl, 2019)</cite> introduced the use of knowledge graphs and questionanswering pre-training to aid in the problems of partial observability and a combinatorial action space.",
  "y": "background"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_5",
  "x": "We make minor modifications to the rules used in<cite> Ammanabrolu and Riedl (2019)</cite> to better achieve such a graph in general interactive fiction environments.",
  "y": "extends"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_6",
  "x": "As this is too large a space for a RL agent to effectively explore, the knowledge graph is used to prune this space by ranking actions based on their presence in the current knowledge graph and the relations between the objects in the graph as in <cite>(Ammanabrolu and Riedl, 2019)</cite> The architecture for the deep Q-network consists of two separate neural networks-encoding state and action separately-with the final Q-value for a state-action pair being the result of a pairwise interaction function between the two (Figure 1 ).",
  "y": "uses similarities"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_7",
  "x": "The portions that are pre-trained are the same parts of the architecture as in<cite> Ammanabrolu and Riedl (2019)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_8",
  "x": "For the metrics tested after convergence, we set = 0.1 following both Narasimhan et al. (2015) and<cite> Ammanabrolu and Riedl (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_9",
  "x": "We use similar hyperparameters to those reported in <cite>(Ammanabrolu and Riedl, 2019)</cite> for training the KG-DQN with action pruning, with the main difference being that we use 100 dimensional word embeddings instead of 50 dimensions for the horror genre.",
  "y": "similarities differences"
 },
 {
  "id": "385ce03aee1e3d3de193de09fa1278_10",
  "x": "Following<cite> Ammanabrolu and Riedl (2019)</cite>, we use TextWorld's \"home\" theme to generate the games for the question-answering system.",
  "y": "uses"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_0",
  "x": "Starting from word embeddings, researchers proposed various ways of aggregating word embedding vectors to obtain efficient sentence-level or documentlevel representations Cheng et al., 2018; Clinchant and Perronnin, 2013; Conneau et al., 2017; Cozma et al., 2018; Fu et al., 2018; <cite>Hill et al., 2016</cite>; Kiros et al., 2015; Kusner et al., 2015; Le and Mikolov, 2014; Shen et al., 2018; Torki, 2018; Zhao et al., 2015; Zhou et al., 2016 Zhou et al., , 2018 .",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_1",
  "x": "Although the mean (or sum) of word vectors is commonly adopted because of its simplicity (Mitchell and Lapata, 2010) , it seems that more complex approaches usually yield better performance (Cheng et al., 2018; Conneau et al., 2017; Cozma et al., 2018; Fu et al., 2018; <cite>Hill et al., 2016</cite>; Kiros et al., 2015; Torki, 2018; Zhao et al., 2015; Zhou et al., 2016 Zhou et al., , 2018 .",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_2",
  "x": "We compare VLAWE with recent stateof-the-art methods Cheng et al., 2018; Fu et al., 2018; <cite>Hill et al., 2016</cite>; Iyyer et al., 2015; Kim, 2014; Kiros et al., 2015; Le and Mikolov, 2014; Liu et al., 2017; Shen et al., 2018; Torki, 2018; Xue and Zhou, 2009; Zhao et al., 2015; Zhou et al., 2016 Zhou et al., , 2018 , demonstrating the effectiveness of our approach.",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_3",
  "x": "There are various works Cheng et al., 2018; Conneau et al., 2017; Fu et al., 2018; <cite>Hill et al., 2016</cite>; Iyyer et al., 2015; Kim, 2014; Kiros et al., 2015; Kusner et al., 2015; Le and Mikolov, 2014; Clinchant and Perronnin, 2013; Shen et al., 2018; Torki, 2018; Zhao et al., 2015; Zhou et al., 2018 ) that propose to build effective sentence-level or document-level representations based on word embeddings.",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_4",
  "x": "While most of these approaches are based on deep learning (Cheng et al., 2018; Conneau et al., 2017; <cite>Hill et al., 2016</cite>; Iyyer et al., 2015; Kim, 2014; Kiros et al., 2015; Le and Mikolov, 2014; Zhao et al., 2015; Zhou et al., 2018) , there have been some approaches that are inspired by computer vision research, namely by the bag-of-visual-words and by Fisher Vectors (Clinchant and Perronnin, 2013) .",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_5",
  "x": "In the learning stage, we employ the Support Vector Machines (SVM) implementation provided by LibSVM (Chang and Lin, 2011 Table 1 : Performance results (in %) of our approach (VLAWE) versus several state-of-the-art methods Cheng et al., 2018; Fu et al., 2018; <cite>Hill et al., 2016</cite>; Iyyer et al., 2015; Kim, 2014; Kiros et al., 2015; Le and Mikolov, 2014; Liu et al., 2017; Shen et al., 2018; Torki, 2018; Xue and Zhou, 2009; Zhao et al., 2015; Zhou et al., 2016 Zhou et al., , 2018 on the Reuters-21578, RT-2k, MR, TREC and Subj data sets.",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_6",
  "x": "We follow the same evaluation procedure as Kiros et al. (2015) and<cite> Hill et al. (2016)</cite> , using 10-fold cross-validation when a train and test split is not pre-defined for a given data set.",
  "y": "similarities uses"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_7",
  "x": "We compare VLAWE with several state-of-theart methods Cheng et al., 2018; Fu et al., 2018; <cite>Hill et al., 2016</cite>; Iyyer et al., 2015; Kim, 2014; Kiros et al., 2015; Le and Mikolov, 2014; Liu et al., 2017; Shen et al., 2018; Torki, 2018; Xue and Zhou, 2009; Zhao et al., 2015; Zhou et al., 2016 Zhou et al., , 2018 as well as two baseline methods, namely the average of word embeddings and the standard bag-of-words (BOW).",
  "y": "background"
 },
 {
  "id": "3bb6243de9f77fc6ebf2dc24de7faa_8",
  "x": "First, we notice that our approach outperforms both baselines on all data sets, unlike other related methods (Le and Mikolov, 2014;<cite> Hill et al., 2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "3ebfa05038431571701a7199163832_0",
  "x": "Previous work has explored learnable alternatives to speech features that rely on a similar computation to spectral representations [19, 20, 21, <cite>22,</cite> 5] .",
  "y": "background"
 },
 {
  "id": "3ebfa05038431571701a7199163832_1",
  "x": "Our experiments show that by training a PCEN block on top of mel-filterbanks or replacing them by learnable time-domain filterbanks from<cite> [22]</cite> , we get a gain in accuracy around 10% in absolute when training an identical neural network for dysarthria detection.",
  "y": "uses"
 },
 {
  "id": "3ebfa05038431571701a7199163832_2",
  "x": "As the first step of our computational pipeline, we use TimeDomain filterbanks from<cite> [22]</cite> .",
  "y": "uses"
 },
 {
  "id": "3ebfa05038431571701a7199163832_3",
  "x": "where (\u03d5 n ) n=1...N are Gabor wavelets defined in<cite> [22]</cite> such that |\u03c6 n | 2 \u2248 |\u03c8 n | 2 .<cite> [22]</cite> shows that this computation can be implemented as neural network layers, referred as TimeDomain filterbanks (TD-filterbanks).",
  "y": "uses background"
 },
 {
  "id": "3ebfa05038431571701a7199163832_4",
  "x": "Following<cite> [22]</cite> , the first 1D convolution filters are initialized with Gabor wavelets, to replicate mel-filterbanks, and are then learnt at the same time as the rest of the model.",
  "y": "uses"
 },
 {
  "id": "3fe979e570992b79c8656ab6cb34fb_0",
  "x": "We base these regular extensions on intersective Levin classes, a fine-grained variation on Levin classes, as a source of semantic components associated with specific adjuncts <cite>(Dang et al., 1998)</cite> .",
  "y": "uses background"
 },
 {
  "id": "3fe979e570992b79c8656ab6cb34fb_1",
  "x": "Push/Pull verbs can appear in the conative construction, which emphasizes their forceful semantic component and ability to express an attempted action where any result that might be associated with the verb is not necessarily achieved; Carry verbs (used with a goal or directional phrase) cannot take the conative alternation because this would conflict with the causation of motion which is the intrinsic meaning of the class <cite>(Dang et al., 1998)</cite> .",
  "y": "background"
 },
 {
  "id": "40d73d5fc22686c13a14946946dd18_0",
  "x": "More recently, <cite>Tan et al. (2018)</cite> replaced the common recurrent architecture with a self-attention network, directly capturing relationships between tokens regardless of their distance, resulting in better results and faster training.",
  "y": "background"
 },
 {
  "id": "40d73d5fc22686c13a14946946dd18_1",
  "x": "Beyond the existing state-of-the-art models (Zhou and Xu, 2015; He et al., 2017; <cite>Tan et al., 2018</cite> ), we exploit character-level modeling, beneficial when considering multiple languages.",
  "y": "background"
 },
 {
  "id": "40d73d5fc22686c13a14946946dd18_2",
  "x": "Despite the foreseen importance, character-level embeddings have not been used in previous work (Zhou and Xu, 2015; He et al., 2017; <cite>Tan et al., 2018</cite>) .",
  "y": "background"
 },
 {
  "id": "40d73d5fc22686c13a14946946dd18_3",
  "x": "Phase II: As core sequence representation component, users can choose between a self-attention encoding (<cite>Tan et al., 2018</cite>) , a regular Bi-LSTM (Hochreiter and Schmidhuber, 1997) or a highway Bi-LSTM (Zhang et al., 2016; He et al., 2017) .",
  "y": "background"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_0",
  "x": "Our system is based on <cite>Marton et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_1",
  "x": "In this section, we summarize <cite>Marton et al. (2013)</cite> .",
  "y": "background"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_2",
  "x": "In contrast to these negative results, <cite>Marton et al. (2013)</cite> showed positive results for using agreement morphology for Arabic.",
  "y": "background"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_3",
  "x": "However, it had been more difficult showing that agreement morphology helps parsing, with negative results for dependency parsing in several languages Eryigit et al., 2008; Nivre, 2009) . In contrast to these negative results, <cite>Marton et al. (2013)</cite> showed positive results for using agreement morphology for Arabic.",
  "y": "motivation"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_5",
  "x": "In <cite>Marton et al. (2013)</cite> , we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA).",
  "y": "background"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_6",
  "x": "In <cite>Marton et al. (2013)</cite> , we investigated morphological features for dependency parsing of Modern Standard Arabic (MSA). <cite>We</cite> used both the MaltParser (Nivre, 2008) and the Easy-First Parser (Goldberg and Elhadad, 2010) . Since the Easy-First Parser performed better, we use it in all experiments reported in this paper.",
  "y": "uses"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_7",
  "x": "In <cite>Marton et al. (2013)</cite> , we showed that by modeling the functional morphology rather than the form-based morphology, we obtain a further increase in parsing performance (2013) test (old split) 81.0 84.0 92.7 Table 2 : Results of our system on Shared Task test data, Gold Tokenization, Predicted Morphological Tags; and for reference also on the data splits used in our previous work <cite>(Marton et al., 2013)</cite> ; \"\u2264 70\" refers to the test sentences with 70 or fewer words.",
  "y": "background"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_8",
  "x": "The best performing set of features on non-gold input, obtained in <cite>Marton et al. (2013)</cite> , are shown in Table 1 .",
  "y": "uses"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_9",
  "x": "The data split used in the shared task is different from the data split we used in <cite>(Marton et al., 2013)</cite> , so we retrained our models on the new splits (Diab et al., 2013) .",
  "y": "differences"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_10",
  "x": "For gold tokenization and predicted morphology (Table 2) , we also give the performance reported in our previous work <cite>(Marton et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "4176674f83dec5389a23d9d45654c7_11",
  "x": "The increase over <cite>the previously reported work</cite> may simply be due to the different split for training and test, but it may also be due to improvements to the functional feature prediction (Alkuhlani and Habash, 2012) , and the predicted features provided by the Shared Task organizers.",
  "y": "differences"
 },
 {
  "id": "41bd8c692ac513b8a9cabbd5aafbda_0",
  "x": "The word2vec <cite>[10]</cite> is among the most widely used word embedding models today.",
  "y": "background"
 },
 {
  "id": "41bd8c692ac513b8a9cabbd5aafbda_1",
  "x": "The word2vec <cite>[10]</cite> is among the most widely used word embedding models today.",
  "y": "background"
 },
 {
  "id": "4235dbd05a848d934f17f35894c051_0",
  "x": "PredPatt 1 <cite>(White et al., 2016</cite> ) is a pattern-based framework for predicate-argument extraction.",
  "y": "background"
 },
 {
  "id": "4235dbd05a848d934f17f35894c051_1",
  "x": "However, the evaluation of PredPatt has been restricted to manually-checked extractions over a small set of sentences<cite> (White et al., 2016)</cite> , which lacks gold annotations to conduct an objective and reproducible evaluation, and inhibits the updates of patterns in PredPatt.",
  "y": "motivation background"
 },
 {
  "id": "4235dbd05a848d934f17f35894c051_2",
  "x": "However, the evaluation of PredPatt has been restricted to manually-checked extractions over a small set of sentences<cite> (White et al., 2016)</cite> , which lacks gold annotations to conduct an objective and reproducible evaluation, and inhibits the updates of patterns in PredPatt. In this work, we aim to conduct a large-scale and reproducible evaluation of PredPatt by introducing a large set of gold annotations gathered from PropBank (Palmer et al., 2005) .",
  "y": "extends motivation"
 },
 {
  "id": "4235dbd05a848d934f17f35894c051_3",
  "x": "PredPatt extracts predicates and arguments in four stages<cite> (White et al., 2016)</cite> : (1) predicate and argument root identification, (2) argument resolution, (3) predicate and argument phrase extraction, and (4) optional post-processing.",
  "y": "background"
 },
 {
  "id": "4235dbd05a848d934f17f35894c051_4",
  "x": "PredPatt extracts predicates and arguments in four stages<cite> (White et al., 2016)</cite> : (1) predicate and argument root identification, (2) argument resolution, (3) predicate and argument phrase extraction, and (4) optional post-processing. We analyze PredPatt extraction in each of these stages on the held-out set, and make 19 improvements to PredPatt patterns.",
  "y": "extends background"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_0",
  "x": "Self-attention networks (SANs) (Parikh et al., 2016; Lin et al., 2017) have shown promising empirical results in various natural language processing (NLP) tasks, such as machine translation <cite>(Vaswani et al., 2017)</cite> , natural language inference (Shen et al., 2018a) , and acoustic modeling (Sperber et al., 2018) .",
  "y": "background"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_1",
  "x": "In addition, the performance of SANs can be improved by multi-head attention <cite>(Vaswani et al., 2017)</cite> , which projects the input sequence into multiple subspaces and applies attention to the representation in each subspace.",
  "y": "background"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_2",
  "x": "Experimental results demonstrate that our approach consistently improves performance over the strong TRANSFORMER model <cite>(Vaswani et al., 2017)</cite> across language pairs.",
  "y": "differences"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_3",
  "x": "where ATT(\u00b7) is an attention model (Bahdanau et al., 2015;<cite> Vaswani et al., 2017)</cite> that retrieves the keys K h with the query q h i .",
  "y": "background"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_4",
  "x": "Multi-Head Attention Multi-head attention mechanism <cite>(Vaswani et al., 2017)</cite> employs different attention heads to capture distinct features (Raganato and Tiedemann, 2018) .",
  "y": "background"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_5",
  "x": "We conducted experiments with the Transformer model <cite>(Vaswani et al., 2017)</cite> on English\u21d2German (En\u21d2De), Chinese\u21d2English (Zh\u21d2En) and Japanese\u21d2English (Ja\u21d2En) translation tasks.",
  "y": "uses"
 },
 {
  "id": "43622e43d6ef5291b64320d2d68b95_6",
  "x": "About configurations of NMT models, we used the Base and Big settings same as<cite> Vaswani et al. (2017)</cite> , and all models were trained on 8 NVIDIA P40 GPUs with a batch of 4096 tokens.",
  "y": "similarities"
 },
 {
  "id": "4590b1a4a0566915a6f2d6439a4e8a_0",
  "x": "Our interest here is the ability of capturing hierarchical structure without being equipped with explicit structural representations <cite>(Bowman et al., 2015b</cite>; Tran et al., 2016; Linzen et al., 2016) .",
  "y": "uses"
 },
 {
  "id": "4590b1a4a0566915a6f2d6439a4e8a_1",
  "x": "The second task was introduced by<cite> Bowman et al. (2015b)</cite> to compare tree-based recursive neural networks against sequence-based recurrent networks with respect to their ability to exploit hierarchical structures to make accurate inferences.",
  "y": "uses"
 },
 {
  "id": "4590b1a4a0566915a6f2d6439a4e8a_2",
  "x": "In this task, we choose the artificial language introduced by<cite> Bowman et al. (2015b)</cite> .",
  "y": "uses"
 },
 {
  "id": "4590b1a4a0566915a6f2d6439a4e8a_3",
  "x": "We follow the general architecture proposed in<cite> (Bowman et al., 2015b)</cite> : Premise and hypothesis sentences are encoded by fixed-size vectors.",
  "y": "uses"
 },
 {
  "id": "4590b1a4a0566915a6f2d6439a4e8a_4",
  "x": "The LSTM architecture used in this experiment is similar to that of<cite> Bowman et al. (2015b)</cite> .",
  "y": "similarities"
 },
 {
  "id": "4590b1a4a0566915a6f2d6439a4e8a_5",
  "x": "Following the experimental protocol of<cite> Bowman et al. (2015b)</cite> , the data is divided into 13 bins based on the number of logical operators.",
  "y": "uses"
 },
 {
  "id": "45d804ec30d20bd7e484c3bbd8399f_0",
  "x": "We use two dependency relation extraction methods to extract dependency relations from each self-attention heads of BERT and RoBERTa. The first method-maximum attention weight (MAX)-designates the word with the highest incoming attention weight as the parent, and is meant to identify specialist heads that track specific dependencies like obj (in the style of <cite>Clark et al., 2019)</cite> .",
  "y": "uses background"
 },
 {
  "id": "45d804ec30d20bd7e484c3bbd8399f_1",
  "x": "In prior work,<cite> Clark et al. (2019)</cite> find that some heads of BERT exhibit the behavior of some dependency relation types, though they do not perform well at all types of relations in general. We are able to replicate their results on BERT using our MAX method.",
  "y": "extends motivation background"
 },
 {
  "id": "45d804ec30d20bd7e484c3bbd8399f_2",
  "x": "Additionally, researchers have investigated the syntactic knowledge that BERT learns by analyzing the contextualized embeddings (Warstadt et al., 2019a) and attention heads of BERT<cite> (Clark et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "45d804ec30d20bd7e484c3bbd8399f_3",
  "x": "Method 1: Maximum Attention Weights (MAX) Given a token A in a sentence, a selfattention mechanism is designed to assign high attention weights on tokens that have some kind of relationship with token A (Vaswani et al., 2017) . Therefore, for a given token A, a token B that has the highest attention weight with respect to the token A should be related to token A. Our aim is to investigate whether this relation maps to a universal dependency relation. We assign a relation (w i , w j ) between word w i and w j if j = argmax W [i] for each row (that corresponds to a word in attention matrix) i in attention matrix W . Based on this simple strategy, we extract relations for all sentences in our evaluation datasets. This method is similar to<cite> Clark et al. (2019)</cite> , and attempts to recover individual arcs between words; the relations extracted using this method need not form a valid tree, or even be fully connected, and the resulting edge directions may or may not match the canonical directions. Hence, we evaluate the resulting arcs individually and ignore their direction. After extracting dependency relations from all heads at all layers, we take the maximum UUAS over all relations types.",
  "y": "extends similarities"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_0",
  "x": "<cite>Goldberg (2019)</cite> adapted the experimental setup of Linzen et al. (2016) , Gulordava et al. (2018) and Marvin and Linzen (2018) to use the cloze test to assess BERT's sensitivity to number agreement in English subject-verb agreement relations.",
  "y": "background"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_1",
  "x": "To what extent does<cite> Goldberg's (2019)</cite> result hold for subject-verb agreement in other languages, including more morphologically rich ones, as well as for other types of agreement relations?",
  "y": "motivation"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_2",
  "x": "Building on<cite> Goldberg's (2019)</cite> work, we expand the experiment to 26 languages and four types of agreement relations, which include more challenging examples.",
  "y": "extends"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_3",
  "x": "' Previous work using agreement relations to assess knowledge of syntactic structure in modern neural networks has focussed on subject-verb agreement in number<cite> (Goldberg, 2019</cite>; Gulordava et al., 2018; Linzen et al., 2016) .",
  "y": "background"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_4",
  "x": "' Previous work using agreement relations to assess knowledge of syntactic structure in modern neural networks has focussed on subject-verb agreement in number<cite> (Goldberg, 2019</cite>; Gulordava et al., 2018; Linzen et al., 2016) . In our work, we study all four types of agreement relations and all four features discussed above.",
  "y": "uses"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_5",
  "x": "Moreover, previous work using any method to assess BERT's knowledge of syntactic structure has focussed exclusively on the single-language English model (Hewitt and Manning, 2019;<cite> Goldberg, 2019</cite>; Tenney et al., 2019; Lin et al., 2019; Jawahar et al., 2019; Clark et al., 2019) .",
  "y": "background"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_6",
  "x": "Moreover, previous work using any method to assess BERT's knowledge of syntactic structure has focussed exclusively on the single-language English model (Hewitt and Manning, 2019;<cite> Goldberg, 2019</cite>; Tenney et al., 2019; Lin et al., 2019; Jawahar et al., 2019; Clark et al., 2019) . We expand this line of work to 26 languages.",
  "y": "extends"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_7",
  "x": "Our experimental set up is an adaptation of that of <cite>Goldberg (2019)</cite> .",
  "y": "extends"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_8",
  "x": "<cite>Goldberg (2019)</cite> , following Linzen et al. (2016) , considered a correct prediction to be one in which the masked word receives a higher probability than other inflected forms of the lemma.",
  "y": "background"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_9",
  "x": "<cite>Goldberg (2019)</cite> , following Linzen et al. (2016) , considered a correct prediction to be one in which the masked word receives a higher probability than other inflected forms of the lemma. This evaluation leaves open the possibility that selectional restrictions or frequency are responsible for the results rather than sensitivity to syntactic structure (Gulordava et al., 2018) . To remove this possibility, we take into account all words of the same part-of-speech as the masked word.",
  "y": "differences"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_10",
  "x": "The average example in our cloze data is evaluated using 1,468 words, compared with 2 in <cite>Goldberg (2019)</cite> .",
  "y": "differences"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_11",
  "x": "Following <cite>Goldberg (2019)</cite>, we use the pretrained BERT models from the original authors 2 , but through the PyTorch implementation.",
  "y": "uses"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_12",
  "x": "3 <cite>Goldberg (2019)</cite> showed that in his experiments the base BERT model performed better than the larger model, so we restrict our attention to the base model.",
  "y": "uses"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_13",
  "x": "Previous work by <cite>Goldberg (2019)</cite> showed that BERT captures English subject-verb number agreement well despite this lack of explicit structural representation.",
  "y": "background"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_14",
  "x": "Previous work by <cite>Goldberg (2019)</cite> showed that BERT captures English subject-verb number agreement well despite this lack of explicit structural representation. We replicated this result using a different evaluation methodology that addresses shortcomings in the original methodology and expanded the study to 26 languages.",
  "y": "extends"
 },
 {
  "id": "46050691971ea46ce7e18fef5f6d2d_15",
  "x": "Second, we used a different evaluation scheme than previous work<cite> (Goldberg, 2019)</cite> by averaging BERT's predictions over many word types and plan to compare both schemes in future work.",
  "y": "differences"
 },
 {
  "id": "46cc0df5c6ed25f735cc0afd301ec8_0",
  "x": "Recent research has started to investigate models with self-explaining capability, i.e. extracting evidence to support their final predictions (Li et al., 2015; Lei et al., 2016;<cite> Lin et al., 2017</cite>; Mullenbach et al., 2018) .",
  "y": "background"
 },
 {
  "id": "46cc0df5c6ed25f735cc0afd301ec8_1",
  "x": "Two methods have been proposed on how to jointly provide highlights along with classification. (1) an extraction-based method (Lei et al., 2016) , which first extracts evidences from the original text and then makes a prediction solely based on the extracted evidences; (2) an attentionbased method <cite>(Lin et al., 2017</cite>; Mullenbach et al., 2018) , which leverages the self-attention mechaMedical Report: The patient was admitted to the Neurological Intensive Care Unit for close observation.",
  "y": "background"
 },
 {
  "id": "46cc0df5c6ed25f735cc0afd301ec8_2",
  "x": [
   "However, previous work has several limitations. Lin et al. (2017) , for example, take single words as basic units, while meaningful information is usually carried by multi-word phrases."
  ],
  "y": "motivation background"
 },
 {
  "id": "46cc0df5c6ed25f735cc0afd301ec8_3",
  "x": "Another issue of<cite> Lin et al. (2017)</cite> is that their attention model is applied on the representation vectors produced by an LSTM. Each LSTM output contains more than just the information of that position, thus the real range for the highlighted position is unclear.",
  "y": "motivation background"
 },
 {
  "id": "46cc0df5c6ed25f735cc0afd301ec8_4",
  "x": "Our work leverages the attention-based selfexplaining method<cite> (Lin et al., 2017)</cite> , as shown in Figure 1 . First, our text encoder ( \u00a73) formulates an input text into a list of basic units, learning a vector representation for each, where the basic units can be words, phrases, or arbitrary ngrams. Then, the attention mechanism is leveraged over all basic units, and sums up all unit representations based on the attention weights {\u03b1 1 , ..., \u03b1 n }. Eventually, the attention weight \u03b1 i will be used to reveal how important a basic unit h i is. The last prediction layer takes the fixed-length text representation t as input, and makes the final prediction.",
  "y": "uses"
 },
 {
  "id": "46cc0df5c6ed25f735cc0afd301ec8_5",
  "x": "We compare two types of baseline text encoders in Figure 1 . (1)<cite> Lin et al. (2017)</cite> (BiLSTM), which formulates single word positions as basic units, and computes the vector h i for the i-th word position with a BiLSTM; (2) Extension of Mullenbach et al. (2018) (CNN) .",
  "y": "uses"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_0",
  "x": "The learning algorithms applied including: decision tree, decisionlist [15] , neural networks [7] , na\u00efve Bayesian learning ( [5] , <cite>[11]</cite> ) and maximum entropy [10] .",
  "y": "uses"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_1",
  "x": "Another similar study for Chinese <cite>[11]</cite> is based on the Naive Bayes classifier model which has taken into consideration PoS with position information and bi-gram templates in the local context.",
  "y": "background"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_2",
  "x": "Another similar study for Chinese <cite>[11]</cite> is based on the Naive Bayes classifier model which has taken into consideration PoS with position information and bi-gram templates in the local context. Even though in both approaches, statistically significant bi-gram co-occurrence information is used, they are not necessarily true collocations. In our system, we do not rely on co-occurrence information.",
  "y": "background differences"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_3",
  "x": "Niu <cite>[11]</cite> proved in his experiments that Na\u00efve Bayes classifier achieved best disambiguation accuracy with small topical context window size (< 10 words).",
  "y": "background"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_4",
  "x": "Niu <cite>[11]</cite> proved in his experiments that Na\u00efve Bayes classifier achieved best disambiguation accuracy with small topical context window size (< 10 words). We follow their method and set the contextual window size as 10 in our system.",
  "y": "uses background"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_5",
  "x": "In both Niu <cite>[11]</cite> and Dang's [10] work, topical features as well as the so called collocational features were used.",
  "y": "background"
 },
 {
  "id": "4705e8c0bac7bf29d8ef3193cf729b_6",
  "x": "In both Niu <cite>[11]</cite> and Dang's [10] work, topical features as well as the so called collocational features were used. Thus instead of using co-occurrences of bigrams, we take the true bi-gram collocations extracted from our system and use this data to compare with bi-gram co-occurrences to test the usefulness of collocation for WSD.",
  "y": "differences background"
 },
 {
  "id": "473cf4603dea14ff89ca12d6e0cb50_0",
  "x": "We evaluate the performance of our SGNNs on Dialogue Act classification, because (1) it is an important step towards dialog interpretation and conversational analysis aiming to understand the intent of the speaker at every utterance of the conversation and (2) deep learning methods reached state-of-the-art (Lee and Dernoncourt, 2016; Khanpour et al., 2016; Tran et al., 2017;<cite> Ortega and Vu, 2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "473cf4603dea14ff89ca12d6e0cb50_1",
  "x": "We use the train, validation and test splits as defined in (Lee and Dernoncourt, 2016;<cite> Ortega and Vu, 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "473cf4603dea14ff89ca12d6e0cb50_2",
  "x": "According to <cite>(Ortega and Vu, 2017)</cite> , prior work by (Ji and Bilmes, 2006) achieved promising results on the MRDA dataset, but since the evaluation was conducted on a different data split, it is hard to compare them directly.",
  "y": "background"
 },
 {
  "id": "473cf4603dea14ff89ca12d6e0cb50_3",
  "x": "Our study also shows that the proposed method is very effective for such natural language tasks compared to more complex neural network architectures such as deep CNN (Lee and Dernoncourt, 2016) and RNN variants (Khanpour et al., 2016;<cite> Ortega and Vu, 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "473cf4603dea14ff89ca12d6e0cb50_5",
  "x": "Experiments on multiple dialog act datasets showed that our model outperforms state-of-the-art deep leaning methods (Lee and Dernoncourt, 2016; Khanpour et al., 2016;<cite> Ortega and Vu, 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_0",
  "x": "We experiment in two different tasks with promising results: First, we repeat the disambiguation experiment of <cite>Grefenstette and Sadrzadeh (2011a)</cite> for transitive verbs.",
  "y": "similarities uses"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_1",
  "x": "The work of <cite>Grefenstette and Sadrzadeh (2011a)</cite> was the first large-scale practical implementation of this framework for intransitive and transitive sentences, and thus a first step towards providing some concrete answers to these questions.",
  "y": "background"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_2",
  "x": "An important consequence of our design decision is that it enables us to reduce the space complexity of the implementation from \u0398(d n )<cite> (Grefenstette and Sadrzadeh, 2011a)</cite> to \u0398(d), making the problem much more tractable.",
  "y": "extends differences"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_3",
  "x": "We also remind to the reader that the relational method for constructing a tensor for the meaning of a verb<cite> (Grefenstette and Sadrzadeh, 2011a)</cite> provides us with a matrix in N 2 .",
  "y": "similarities"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_4",
  "x": "Furthermore, note that the nesting problem of <cite>Grefenstette and Sadrzadeh (2011a)</cite> does not arise here, since the linguistic and concrete types are the same.",
  "y": "differences"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_5",
  "x": "We train our vectors from a lemmatised version of the British National Corpus (BNC), following closely the parameters of the setting described in Mitchell and Lapata (2008) , later used by <cite>Grefenstette and Sadrzadeh (2011a)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_6",
  "x": "We first test our models against the disambiguation task for transitive sentences described in <cite>Grefenstette and Sadrzadeh (2011a)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_7",
  "x": "The most successful S = N model for this task is the copyobject model, which is performing really close to the original relational model of <cite>Grefenstette and Sadrzadeh (2011a)</cite> , with the difference to be statistically insignificant.",
  "y": "extends differences"
 },
 {
  "id": "48e3715c55fcc188367dcfdc26c05f_8",
  "x": "1 The original relational model of <cite>Grefenstette and Sadrzadeh (2011a)</cite> with S = N 2 , provided a \u03c1 of 0.21. When computed with our program with the exact same parameters (without embedding them in the S = N model), we obtained a \u03c1 of 0.195.",
  "y": "extends differences"
 },
 {
  "id": "493f353942929c1a015d5e0acbf564_0",
  "x": "Although the aforementioned works show effectiveness in addressing the latent variable collapse issue to some extent, they either require carefully engineering to balance the weight between the reconstruction loss and KL loss (Bowman et al., 2016; , or resort to designing more sophisticated model structures<cite> (Yang et al., 2017</cite>; Xu and Durrett, 2018; Dieng et al., 2019) .",
  "y": "background"
 },
 {
  "id": "493f353942929c1a015d5e0acbf564_1",
  "x": "We evaluate our model against several strong baselines which apply VAE for text modelling (Bowman et al., 2016; <cite>Yang et al., 2017</cite>; Xu and Durrett, 2018) .",
  "y": "uses"
 },
 {
  "id": "493f353942929c1a015d5e0acbf564_2",
  "x": "We evaluate our model against several strong baselines which apply VAE for text modelling (Bowman et al., 2016; <cite>Yang et al., 2017</cite>; Xu and Durrett, 2018) . Experimental results show that our HR-VAE model not only can effectively mitigate the latent variable collapse issue with a stable training process, but also can give better predictive performance than the baselines, as evidenced by both quantitative (e.g., negative log likelihood and perplexity) and qualitative evaluation.",
  "y": "uses differences"
 },
 {
  "id": "493f353942929c1a015d5e0acbf564_3",
  "x": "Our model design is motivated by one noticeable defect shared by the VAE-RNN based models in previous works (Bowman et al., 2016; <cite>Yang et al., 2017</cite>; Xu and Durrett, 2018; Dieng et al., 2019) .",
  "y": "motivation"
 },
 {
  "id": "493f353942929c1a015d5e0acbf564_4",
  "x": "KL annealing is used to tackled the latent variable collapse issue (Bowman et al., 2016) ; VAE-CNN 4 : A variational autoencoder model with a LSTM encoder and a dilated CNN decoder<cite> (Yang et al., 2017)</cite> ; vMF-VAE 5 : A variational autoencoder model using LSTM for both encoder and decoder where the prior distribution is the von Mises-Fisher (vMF) distribution rather than a Gaussian distribution (Xu and Durrett, 2018) .",
  "y": "background"
 },
 {
  "id": "493f353942929c1a015d5e0acbf564_5",
  "x": "We compare our HR-VAE model with three strong baselines using VAE for text modelling: VAE-LSTM-base 3 : A variational autoencoder model which uses LSTM for both encoder and decoder. KL annealing is used to tackled the latent variable collapse issue (Bowman et al., 2016) ; VAE-CNN 4 : A variational autoencoder model with a LSTM encoder and a dilated CNN decoder<cite> (Yang et al., 2017)</cite> ; vMF-VAE 5 : A variational autoencoder model using LSTM for both encoder and decoder where the prior distribution is the von Mises-Fisher (vMF) distribution rather than a Gaussian distribution (Xu and Durrett, 2018) .",
  "y": "uses background"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_0",
  "x": "This model was further improved by<cite> (Makarov et al., 2017)</cite> , whose system was the winner of Sigmorphon 2017 evaluation campaign (Cotterell et al., 2017) .",
  "y": "background"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_1",
  "x": "However, this decomposition is already realised in model of<cite> (Makarov et al., 2017)</cite> since the grammatical features are treated as a list of atomic elements, not as entire label.",
  "y": "background"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_2",
  "x": "Summarizing, our approach was to enrich the model of<cite> (Makarov et al., 2017</cite> ) with the language model component.",
  "y": "extends"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_3",
  "x": "We expected to improve performance especially in low and medium resource setting, however, our approach does not have clear advantages: our joint system is only slightly ahead the baseline system of<cite> (Makarov et al., 2017)</cite> for most of the languages.",
  "y": "differences"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_4",
  "x": "As the state-of-the-art baseline we choose the model of Makarov et al.<cite> (Makarov et al., 2017)</cite> , the winner of previous Sigmorphon Shared Task.",
  "y": "uses"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_5",
  "x": "We also use the copy gate from<cite> (Makarov et al., 2017)</cite> : since the neural network copies the vast majority of its symbols, the output distribution p i is obtained as a weighted sum of singleton distribution which outputs current input symbol and the preliminary distribution p i specified above.",
  "y": "uses"
 },
 {
  "id": "49b42346795d541dbcac9e2b9ad00a_6",
  "x": "We submitted three systems, one replicating the algorithm of<cite> (Makarov et al., 2017)</cite> , the second equipped with language models.",
  "y": "uses"
 },
 {
  "id": "4ad830d8377d2584798a30bed65254_0",
  "x": "This is shown when training word embeddings, a vector representation of words, in news sets with crowd-sourcing evaluation to quantify the presence of biases, such as gender bias, in those representation<cite> (Bolukbasi et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "4ad830d8377d2584798a30bed65254_1",
  "x": "More specifically, gender stereotypes are learned from human generated corpora as shown by<cite> (Bolukbasi et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "4ad830d8377d2584798a30bed65254_2",
  "x": "Debiaswe is a postprocess method for debiasing previously generated embeddings<cite> (Bolukbasi et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "4ad830d8377d2584798a30bed65254_3",
  "x": "Debiaswe<cite> (Bolukbasi et al., 2016</cite> ) is a postprocess method for debiasing word embeddings.",
  "y": "background"
 },
 {
  "id": "4ad830d8377d2584798a30bed65254_4",
  "x": "Debiaswe<cite> (Bolukbasi et al., 2016</cite> ) is a debiasing post-process performed on trained embeddings.",
  "y": "background"
 },
 {
  "id": "4ad830d8377d2584798a30bed65254_5",
  "x": "Then, we debiased the embeddings using Debiaswe<cite> (Bolukbasi et al., 2016)</cite> and also trained its gender neutral version with GN-GloVe (Zhao et al., 2018b) .",
  "y": "uses"
 },
 {
  "id": "4bc5fc3bccb704b9978b294ffb07de_0",
  "x": "This tutorial introduces the advances in deep Bayesian learning with abundant applications for natural language understanding ranging from speech recognition (Saon and Chien, 2012; Chan et al., 2016) to document summarization (Chang and Chien, 2009 ), text classification (Blei et al., 2003; Zhang et al., 2015) , text segmentation (Chien and Chueh, 2012) , information extraction (Narasimhan et al., 2016) , image caption generation (Vinyals et al., 2015; Xu et al., 2015) , sentence generation (Li et al., 2016b) , dialogue control (Zhao and Eskenazi, 2016; <cite>Li et al., 2016a</cite>) , sentiment classification, recommendation system, question answering (Sukhbaatar et al., 2015) and machine translation , to name a few.",
  "y": "uses background"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_0",
  "x": "For example,<cite> Bohnet and Nivre (2012)</cite> had to carefully discretize the real-valued POS tag score in order to combine it with the other discrete binary features in their system.",
  "y": "background"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_1",
  "x": "Additionally, we also experiment with different transition systems, most notably the integrated parsing and part-of-speech (POS) tagging system of<cite> Bohnet and Nivre (2012)</cite> and also the swap system of Nivre (2009) .",
  "y": "similarities uses"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_2",
  "x": "Inspired by the work of<cite> Bohnet and Nivre (2012)</cite> , we embed the set of top tags according to a first-stage tagger.",
  "y": "similarities uses"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_3",
  "x": "The integrated arc-standard transition system of<cite> Bohnet and Nivre (2012)</cite> allows the parser to participate in tagging decisions, rather than being forced to treat the tagger's tags as given, as in the arc-standard system.",
  "y": "uses"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_4",
  "x": "For ease of experimentation, we deviate from<cite> Bohnet and Nivre (2012)</cite> and use a single unstructured beam, rather than separate beams for POS tag and parse differences.",
  "y": "differences"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_5",
  "x": "Additionally, our pipelined neural network parser always outperforms its linear counterpart, an in-house reimplementation of the system of Zhang and Nivre (2011) , as well as the more recent and highly accurate parsers of Zhang and McDonald (2014) and Lei et al. (2014 again outperforms its linear counterpart<cite> (Bohnet and Nivre, 2012)</cite> , however, in some cases the addition of graph-based and cluster features<cite> (Bohnet and Nivre, 2012</cite> )+G+C can lead to even better results.",
  "y": "differences"
 },
 {
  "id": "4cf805818bed233fabb81f5f64f4cc_6",
  "x": "The results shown in Table 4 , we find that our full model surpasses, to our knowledge, all previously reported supervised parsing models for the Stanford dependency conversions. It surpasses its linear analog, the work of<cite> Bohnet and Nivre (2012)</cite> on Stanford Dependencies UAS by 0.9% UAS and by 1.14% LAS.",
  "y": "differences"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_0",
  "x": "<cite>Zhang et al. (2017)</cite> utilize adversarial training to obtain cross-lingual word embeddings without any parallel data. However, their performance is still significantly worse than supervised methods. <cite>Zhang et al. (2017)</cite> apply adversarial training to align monolingual word vector spaces with no supervision.",
  "y": "background"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_1",
  "x": "In the first part, we conduct experiments on smallscale datasets and our main baseline is <cite>Zhang et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_2",
  "x": "In this section, our experiments focus on smallscale datasets and our main baseline model is adversarial autoencoder<cite> (Zhang et al., 2017)</cite> . For justice, we use the same model selection strategy with <cite>Zhang et al. (2017)</cite> , i.e. we choose the model whose sum of reconstruction loss and classification accuracy is the least.",
  "y": "similarities"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_3",
  "x": "For this set of experiments, we use the same data as <cite>Zhang et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_4",
  "x": "The baseline models are MonoGiza system (Dou et al., 2015) , translation matrix (TM) (Mikolov et al., 2013) , isometric alignment (IA) (Zhang et al., 2016b) and adversarial training approach<cite> (Zhang et al., 2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_5",
  "x": "The results of baseline models are cited from <cite>Zhang et al. (2017)</cite> . As we can see from the table, our model could achieve superior performance compared with other baseline models.",
  "y": "uses differences"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_6",
  "x": "Again, we use the same dataset with <cite>Zhang et al. (2017)</cite> . and the statistics are shown in The experimental results are shown in Table 4 .",
  "y": "similarities uses"
 },
 {
  "id": "4d528117dd7751d0cd6413430e1ec1_7",
  "x": "In this section, we integrate our method with Conneau et al. (2018) , whose method improves <cite>Zhang et al. (2017)</cite> by more sophiscated refinement procedure and validation criterion.",
  "y": "extends differences"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_0",
  "x": "Previous work<cite> (MacCartney et al., 2008)</cite> has presented a phrase-based monolingual aligner for NLI (MANLI) that has been shown to significantly outperform a token-based NLI aligner (Chambers et al., 2007) as well as popular alignment techniques borrowed from machine translation (Och and Ney, 2003; Liang et al., 2006) .",
  "y": "background"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_1",
  "x": "Previous work<cite> (MacCartney et al., 2008)</cite> has presented a phrase-based monolingual aligner for NLI (MANLI) that has been shown to significantly outperform a token-based NLI aligner (Chambers et al., 2007) as well as popular alignment techniques borrowed from machine translation (Och and Ney, 2003; Liang et al., 2006) . However, MANLI's use of a phrase-based alignment representation appears to pose a challenge to the decoding task, i.e. the task of recovering the highest-scoring alignment under some parameters.",
  "y": "motivation"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_2",
  "x": "Consequently, <cite>MacCartney et al. (2008)</cite> employ a stochastic search algorithm to decode alignments approximately while remaining consistent with regard to phrase segmentation.",
  "y": "background"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_3",
  "x": "However, MANLI's use of a phrase-based alignment representation appears to pose a challenge to the decoding task, i.e. the task of recovering the highest-scoring alignment under some parameters. Consequently, <cite>MacCartney et al. (2008)</cite> employ a stochastic search algorithm to decode alignments approximately while remaining consistent with regard to phrase segmentation.",
  "y": "motivation"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_4",
  "x": "Alignment is an integral part of statistical MT (Vogel et al., 1996; Och and Ney, 2003; Liang et al., 2006) but the task is often substantively different from monolingual alignment, which poses unique challenges depending on the application<cite> (MacCartney et al., 2008)</cite> .",
  "y": "background motivation"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_5",
  "x": "In our experiments, we merge the annotations using majority rule in the same manner as <cite>MacCartney et al. (2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_6",
  "x": "Our alignment system is structured identically to MANLI<cite> (MacCartney et al., 2008)</cite> and uses the same phrase-based alignment representation.",
  "y": "uses"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_7",
  "x": "Our implementation uses the same set of features as <cite>MacCartney et al. (2008)</cite> with some minor changes: we use a shallow parser (Daum\u00e9 and Marcu, 2005) for detecting constituents and employ only string similarity and WordNet for determining semantic relatedness, forgoing NomBank and the distributional similarity resources used in the original MANLI implementation.",
  "y": "extends uses"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_8",
  "x": "We deviate from <cite>MacCartney et al. (2008)</cite> and do not introduce L2 normalization of weights during learning as this could have an unpredictable effect on the averaged parameters.",
  "y": "extends differences"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_9",
  "x": "All models are trained on the development section of the Microsoft Research RTE2 alignment corpus (cf. \u00a73.1) using the training parameters specified in <cite>MacCartney et al. (2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_10",
  "x": "We first observe that our reimplemented version of MANLI improves over the results reported in <cite>MacCartney et al. (2008)</cite> , gaining 2% in precision, 1% in recall and 2-3% in the fraction of alignments that exactly matched human annotations.",
  "y": "differences"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_11",
  "x": "Our final system improves over the results reported in <cite>MacCartney et al. (2008)</cite> by about 4.5% in precision and 1% in recall, with a large gain in the number of perfect alignments over the test corpus.",
  "y": "differences"
 },
 {
  "id": "4f111ff06afd5523d65fc1d1a9ff83_12",
  "x": "An examination of the alignments produced by our system reveals that many remaining errors can be tackled by the use of named-entity recognition and better paraphrase corpora; this was also noted by <cite>MacCartney et al. (2008)</cite> with regard to the original MANLI system.",
  "y": "similarities future_work"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_0",
  "x": "To provide the awareness of errors in mt originating from src, the transformer architecture <cite>(Vaswani et al., 2017)</cite> , which is built solely upon attention mechanisms (Bahdanau et al., 2015) , makes it possible to model dependencies without regard to their distance in the input or output sequences and also captures global dependencies between input and output (for our case src, mt, and pe).",
  "y": "background"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_1",
  "x": "Our APE system extends this transformer-based NMT architecture <cite>(Vaswani et al., 2017)</cite> by using two encoders, a joint encoder, and a single decoder.",
  "y": "extends differences"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_2",
  "x": "Finally, this joint encoder is fed to the decoder which follows a similar architecture as described in<cite> Vaswani et al. (2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_3",
  "x": "Our single-source model (SS) is based on an encoder-decoder-based transformer architecture <cite>(Vaswani et al., 2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_4",
  "x": "Apart from enc src and enc mt , each of which is equivalent to the original transformer's encoder <cite>(Vaswani et al., 2017)</cite> , we use a joint encoder with an equivalent architecture, to maintain the homogeneity of the transformer model.",
  "y": "extends differences"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_5",
  "x": "For this, we extend<cite> Vaswani et al. (2017)</cite> by introducing an additional identical encoding block by which both the enc src and the enc mt encoders communicate with the decoder.",
  "y": "extends differences"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_6",
  "x": "This is a similar setting to<cite> Vaswani et al. (2017)</cite> 's C \u2212 model 1 .",
  "y": "similarities"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_7",
  "x": "The learning rate is varied throughout the training process, first increasing linearly for the first training steps warmup steps = 4000 and then adjusted as described in <cite>(Vaswani et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_8",
  "x": "For encoding the word order, our model uses learned positional embeddings (Gehring et al., 2017) , since<cite> Vaswani et al. (2017)</cite> reported nearly identical results to sinusoidal encodings.",
  "y": "similarities"
 },
 {
  "id": "4f75f73b4eac8aecdde9312a846a1d_9",
  "x": "Unfortunately, we could not test either the 'big' or the 'base' hyper-parameter configuration in<cite> Vaswani et al. (2017)</cite> due to unavailable computing resources at the time of submission.",
  "y": "differences"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_0",
  "x": "Recently, an attention based system<cite> (Zhong et al., 2019)</cite> utilizing both documentlevel and entity-level information achieved stateof-the-art results on WIKIHOP data set, proving that techniques like co-attention and self-attention widely employed in single-document RC tasks are also useful in multi-document RC tasks.",
  "y": "background"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_1",
  "x": "In addition, following the success of Coarse-grain Fine-grain Coattention (CFC) network<cite> (Zhong et al., 2019)</cite> , we apply both co-attention and self-attention to learn queryaware node representations of candidates, documents and entities;",
  "y": "uses"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_2",
  "x": "Evaluated on the blind test set of WIKIHOP, our proposed end-to-end trained single neural model beats the current stateof-the-art results in<cite> (Zhong et al., 2019)</cite> 1 , without using pretrained contextual ELMo embedding (Peters et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_3",
  "x": "The study presented in this paper is directly related to existing research on multi-hop reading comprehension across multiple documents (Dhingra et al., 2018; Song et al., 2018; De Cao et al., 2018;<cite> Zhong et al., 2019</cite>; Kundu et al., 2018) . The method presented in this paper is similar to previous studies using GNN for multi-hop reasoning (Song et al., 2018; De Cao et al., 2018) .",
  "y": "uses"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_4",
  "x": "The co-attention and self-attention based encoding of multi-level information presented in each input is also inspired by the CFC model<cite> (Zhong et al., 2019)</cite> because they show the effectiveness of attention mechanisms.",
  "y": "uses"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_5",
  "x": "We use simple exact match strategy (De Cao et al., 2018;<cite> Zhong et al., 2019)</cite> to find the locations of mentions of query subject and candidates, i.e. we need the start and end positions of each mention.",
  "y": "uses"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_6",
  "x": "Co-attention: Co-attention has achieved great success for single document reading comprehension tasks (Seo et al., 2016; Xiong et al., 2016) , and recently was applied to multiple-hop reading comprehension<cite> (Zhong et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_7",
  "x": "We follow the implementation of coattention in<cite> (Zhong et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_8",
  "x": "We expect S ca carries query-aware contextual information of supporting documents as shown by <cite>Zhong et al. (2019)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_9",
  "x": "Self-attentive pooling: while co-attention yields a query-aware contextual representation of documents, self-attentive pooling is designed to convert the sequential contextual representation to a fixed dimensional non-sequential feature vector by selecting important query-aware information<cite> (Zhong et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_10",
  "x": "Our context encoding module is different from the one used in <cite>Zhong et al. (2019)</cite> in following aspects: 1) we compute the co-attention between query and candidates which is not presented in the CFC model.",
  "y": "differences"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_11",
  "x": "2) For entity word sequences, we first calculate co-attention with query and then use selfattention to summarize each entity word sequence while <cite>Zhong et al. (2019)</cite> first do self-attention on entity word sequences to get a sequence of entity vectors in each documents.",
  "y": "differences"
 },
 {
  "id": "5095f2af3f0c51283c8fbee08a17ac_13",
  "x": "We show that our proposed HDE graph based model improves the state-of-the-art accuracy on development set from 67.1% (Kundu et al., 2018) to 68.1%, on the blind test set from 70.6%<cite> (Zhong et al., 2019)</cite> to 70.9%.",
  "y": "differences"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_0",
  "x": "The starting point of our study is the goal oriented dialogue task of <cite>Kottur et al. (2017)</cite> , summarized in Fig. 2 .",
  "y": "uses"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_1",
  "x": "Existing work has investigated conditions under which compositional languages emerge between neural agents in simple environments (Mordatch & Abbeel, 2018;<cite> Kottur et al., 2017)</cite> , but it only investigates how language changes within a generation.",
  "y": "motivation background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_2",
  "x": "This desire for structure motivates the previously mentioned work on compositional language emergence in neural agents<cite> (Kottur et al., 2017</cite>; Mordatch & Abbeel, 2018; Choi et al., 2018) .",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_3",
  "x": "The starting point for our investigation is the recent work of <cite>Kottur et al. (2017)</cite> , which investigates compositionality using a cooperative reference game between two agents.",
  "y": "uses"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_4",
  "x": "As in <cite>Kottur et al. (2017)</cite> , we implement Q, A, and U as neural networks.",
  "y": "similarities"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_5",
  "x": "In <cite>Kottur et al. (2017)</cite> it was used to generate a somewhat compositional language given Algorithm 1: Training with Replacement and Multiple Agents",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_6",
  "x": "This approach-summarized in the black lines (4-9) of Algorithm 1-is our starting point. In <cite>Kottur et al. (2017)</cite> it was used to generate a somewhat compositional language given Algorithm 1: Training with Replacement and Multiple Agents",
  "y": "uses background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_7",
  "x": "In <cite>Kottur et al. (2017)</cite> there is only one pair of agents (N Q = N A = 1) so we cannot replace both agents at the same round because all existing language would be lost.",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_8",
  "x": "As in <cite>Kottur et al. (2017)</cite> , our world contains objects with 3 attributes (shape, size, color) such that each attribute has 4 possible values.",
  "y": "similarities"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_9",
  "x": "Previous work also measures generalization to held out compositions of attributes to measure compositionality<cite> (Kottur et al., 2017</cite>; Kirby et al., 2015) .",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_10",
  "x": "Unlike <cite>Kottur et al. (2017)</cite> , we use a slightly harder version of their dataset which aligns better with the goal of compositional language.",
  "y": "differences"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_11",
  "x": "Our A-bots and Q-bots have the same architecture and hyperparameter variations as in <cite>Kottur et al. (2017)</cite> , but with our cultural transmission training procedure and some other differences identified below.",
  "y": "similarities differences"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_12",
  "x": "Like <cite>Kottur et al. (2017)</cite> , our hyperparameter variations consider the number of vocab words Q-bot (V Q ) and A-bot (V A ) may utter and whether or not A-bot has memory between dialog rounds.",
  "y": "similarities"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_13",
  "x": "7 This differs from <cite>Kottur et al. (2017)</cite> , which stopped once train accuracy reached 100%.",
  "y": "differences"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_14",
  "x": "Thus we compare to the Replace All baseline, which has the greatest chance of seeing a lucky initialization and thereby ensures that gains over the No Replacement baseline 6 This is slightly different from Small Vocab in<cite> (Kottur et al., 2017)</cite> .",
  "y": "differences"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_15",
  "x": "Test set accuracies (with standard deviations) are reported against our new harder dataset using models similar to those in<cite> (Kottur et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_16",
  "x": "The models considered in <cite>Kottur et al. (2017)</cite> were ordered, from best to worse, as: Memoryless + Small Vocab > Small Vocab > Overcomplete.",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_17",
  "x": "The models considered in <cite>Kottur et al. (2017)</cite> were ordered, from best to worse, as: Memoryless + Small Vocab > Small Vocab > Overcomplete. Our trends tend to agree with that conclusion though the differences are smaller-mainly comparing the Memoryless + Small Vocab model to others in cultural transmission settings.",
  "y": "similarities"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_18",
  "x": "This agrees with factors noted elsewhere<cite> (Kottur et al., 2017</cite>; Mordatch & Abbeel, 2018; Nowak et al., 2000) .",
  "y": "similarities"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_19",
  "x": "Even though cultural transmission may aid the emergence of compositionality, recent results in evolutionary linguistics (Raviv et al., 2018) and deep learning<cite> (Kottur et al., 2017</cite>; Mordatch & Abbeel, 2018) show cultural transmission may not be necessary for compositionality to emerge.",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_20",
  "x": "Most relevant is similar work which focuses on conditions under which compositional language emerges as deep agents learn to cooperate (Mordatch & Abbeel, 2018;<cite> Kottur et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "50cdfe539f84d793ec50873b5ab066_21",
  "x": "Both Mordatch & Abbeel (2018) and <cite>Kottur et al. (2017)</cite> find that limiting the vocabulary size so that there aren't too many more words than there are objects to refer to encourages compositionality, which follows earlier results in evolutionary linguistics (Nowak et al., 2000) .",
  "y": "background"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_0",
  "x": "Recently, translation scholars have made some general claims about translation properties. Some of these are source language independent while others are not. <cite>Koppel and Ordan (2011)</cite> performed empirical studies to validate both types of properties using English source texts and other texts translated into English. Obviously, corpora of this sort, which focus on a single language, are not adequate for claiming universality of translation properties.",
  "y": "background motivation"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_1",
  "x": "Recently, scholars in this area identified several properties of the translation process with the aid of corpora (Baker, 1993; Baker, 1996; Olohan, 2001; Laviosa, 2002; Hansen, 2003; Pym, 2005) . These properties are subsumed under four keywords: explicitation, simplification, normalization and levelling out. They focus on the general effects of the translation process. Toury (1995) has a different theory from these. That is, a translated text will carry some fingerprints of its source language. Recently, Pastor et al. (2008) and Ilisei et al. (2009; have provided empirical evidence of simplification translation properties using a comparable corpus of Spanish. <cite>Koppel and Ordan (2011)</cite> perform empirical studies to validate both theories, using a subcorpus extracted from the Europarl (Koehn, 2005) and IHT corpora<cite> (Koppel and Ordan, 2011)</cite> . They used a comparable corpus of original English and English translated from five other European languages. In addition, original English and English translated from Greek and Korean was also used in their experiment. They have found that a translated text contains both source language dependent and independent features. Obviously, corpora of this sort, which focus on a single language (e.g., English), are not adequate for claiming the universal validity of translation properties. Different languages (and language families) have different linguistic properties.",
  "y": "motivation background"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_2",
  "x": "<cite>Koppel and Ordan (2011)</cite> have built a classifier that can identify the correct source of the translated text (given different possible source languages). They have built another classifier which can identify source text and translated text. Furthermore, they have shown that the degree of difference between two translated texts, translated from two different languages into the same target language reflects, the degree of difference of the source languages. They have gained impressive results for both of the tasks. However, the limitation of this study is that they only used a corpus of English original text and English text translated from various European languages.",
  "y": "motivation background"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_3",
  "x": "We can not compare our findings directly with <cite>Koppel and Ordan (2011)</cite> even though we use text from the same corpus and similar techniques.",
  "y": "similarities"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_4",
  "x": "Furthermore, instead of the list of 300 function words used by <cite>Koppel and Ordan (2011)</cite> , we used the 100 most frequent words for each candidate language.",
  "y": "differences"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_5",
  "x": "We extract a suitable corpus from the Europarl corpus in a way similar to Lembersky et al. (2011) and <cite>Koppel and Ordan (2011)</cite> . Our target is to extract texts that are translated from and to the languages considered here.",
  "y": "uses"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_6",
  "x": "We trust the source language marker that has been put by the respective translator, as did Lembersky et al.(2011) and <cite>Koppel and Ordan (2011)</cite> .",
  "y": "similarities"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_7",
  "x": "In this experiment, our goal is to validate the translation properties postulated by Toury (1995) . He stated that a translated text inherits some fingerprints from the source language. The experimental result of <cite>Koppel and Ordan (2011)</cite> shows that text translated into English holds this property.",
  "y": "background"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_8",
  "x": "Our hypothesis is again similar to <cite>Koppel and Ordan (2011)</cite> , that is, if the classifier's accuracy is close to 20%, then we cannot say that there is an interference effect in translated text. If the classifier's accuracy is close to 100% then our conclusion will be that interference effects exist in translated text.",
  "y": "similarities"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_9",
  "x": "In the past, researchers have used comparable corpora to validate these translation properties (Baroni and Bernardini, 2006; Pastor et al., 2008; Ilisei et al., 2009; Ilisei et al., 2010;<cite> Koppel and Ordan, 2011)</cite> . Most of them used comparable corpora for two-class classification, distinguishing translated texts from the original texts. Only<cite> Koppel and Ordan (Koppel and Ordan, 2011)</cite> used English texts translated from multiple source languages. We perform similar experiments only for six European languages as shown in Table 1 .",
  "y": "background"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_10",
  "x": "<cite>Koppel and Ordan (2011)</cite> received the highest accuracy (96.7%) among all works noted above.",
  "y": "background"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_11",
  "x": "Even though the classifier for German achieves around 99% accuracy, we cannot compare the result with<cite> Koppel and Ordan (Koppel and Ordan, 2011)</cite> as the amount of chunks for the classes are different.",
  "y": "differences"
 },
 {
  "id": "50d065b6b187f361f8e456df0a0bbe_12",
  "x": "The results show that training a classifier based on the 100 most frequent words of a language is sufficient to obtain interpretable results. We find our results to be compatible with <cite>Koppel and Ordan (2011)</cite> who used 300 function words.",
  "y": "similarities"
 },
 {
  "id": "511c17a6cb6bd74e0216c3d50eb9c0_0",
  "x": "As opposed to the situation for Irish Gaelic (Lynn et al., 2012a;<cite> Lynn et al., 2012b</cite>; Lynn et al., 2013; Lynn et al., 2014) there are no treebanks or tagging schemes for Scottish Gaelic, although there are machine-readable dictionaries and databases available from Sabhal M\u00f2r Ostaig.",
  "y": "background"
 },
 {
  "id": "511c17a6cb6bd74e0216c3d50eb9c0_1",
  "x": "A very important scheme is the Dublin scheme for Irish (Lynn et al., 2012a;<cite> Lynn et al., 2012b</cite>; Lynn et al., 2013) , which is of a similar size to the Stanford scheme, but the reason for its size relative to GR is that it includes a large number of dependencies intended to handle grammatical features found in Irish but not in English.",
  "y": "background"
 },
 {
  "id": "511c17a6cb6bd74e0216c3d50eb9c0_2",
  "x": "Fig. 1 shows our dependency tree for this. Note that this is different from the scheme in <cite>Lynn et al. (2012b)</cite> because of a difference between the two languages.",
  "y": "differences"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_0",
  "x": "On the other hand, <cite>Noraset et al. (2017)</cite> attempted to generate a definition of a word from an embedding induced from massive text (which can be seen as global context).",
  "y": "background"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_1",
  "x": "Considering various applications where we need definitions of expressions, we evaluated our method with four datasets including WordNet<cite> (Noraset et al., 2017)</cite> for general words, the Oxford dictionary (Gadetsky et al., 2018) for polysemous words, Urban Dictionary (Ni and Wang, 2017) for rare idioms or slang, and a newlycreated Wikipedia dataset for entities.",
  "y": "uses"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_2",
  "x": "To incorporate the different types of contexts, we propose to use a gate function similar to <cite>Noraset et al. (2017)</cite> to dynamically control how the global and local contexts influence the description.",
  "y": "similarities"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_3",
  "x": "In order to capture the surface information of X trg , we construct character-level CNNs (Eq. (6)) following<cite> (Noraset et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_4",
  "x": "Note that the input to the CNNs is a sequence of words in X trg , which are concatenated with special character \" ,\" such as \"sonic boom.\" Following <cite>Noraset et al. (2017)</cite>, we set the CNN kernels of length 2-6 and size 10, 30, 40, 40, 40 respectively with a stride of 1 to obtain a 160-dimensional vector c trg .",
  "y": "uses"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_5",
  "x": "In order to capture the interaction between the local and global contexts, we adopt a GATE(\u00b7) function (Eq. (7)) which is similar to <cite>Noraset et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_6",
  "x": "Datasets To evaluate our model on the word description task on WordNet, we followed <cite>Noraset et al. (2017)</cite> and extracted data from WordNet using the dict-definition 9 toolkit.",
  "y": "uses"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_7",
  "x": "Since not all entries in WordNet have usage examples, our dataset is a small subset of <cite>Noraset et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_8",
  "x": "Global<cite> (Noraset et al., 2017)</cite> , (2) Local (Ni and Wang, 2017) with CNN, (3) I-Attention (Gadetsky et al., 2018) , and our proposed model, (4) LOGCaD. The Global model is our reimplementation of the best model (S + G + CH) in <cite>Noraset et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "5203c1037fe57bd1b813c0bf1ff5c4_9",
  "x": "Recently, <cite>Noraset et al. (2017)</cite> introduced a task of generating a definition sentence of a word from its pre-trained embedding.",
  "y": "background"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_0",
  "x": "Recent researches on sequence-to-sequence attention-based models try to remove this dependency on the pronunciation lexicon [8,<cite> 9,</cite> 10] .",
  "y": "background"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_1",
  "x": "Our previous work <cite>[9]</cite> demonstrates that the lexicon independent models can outperform lexicon dependent models on Mandarin Chinese ASR tasks by the ASR Transformer and the character based model establishes a new state-of-the-art character error rate (CER) on HKUST datasets.",
  "y": "background"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_2",
  "x": "Building on our work <cite>[9]</cite> , we employ sub-words generated by byte pair encoding (BPE) [11] as the multilingual modeling unit, which do not need any pronunciation lexicon.",
  "y": "extends differences"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_3",
  "x": "The ASR Transformer is chosen to be the basic architecture of sequence-to-sequence attention-based model<cite> [9,</cite> 12] .",
  "y": "extends differences"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_4",
  "x": "The ASR Transformer architecture used in this work is the same as our work<cite> [9,</cite> 12] which is shown in Figure 1 .",
  "y": "similarities uses"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_5",
  "x": "We generate more training data by linearly scaling the audio lengths by factors of 0.9 and 1.1 [22] , since it is always beneficial for training the ASR Transformer <cite>[9]</cite> .",
  "y": "background"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_6",
  "x": "We perform our experiments on the big model (D1024-H16)<cite> [9,</cite> 17] of the ASR Transformer.",
  "y": "background"
 },
 {
  "id": "520588fbf0643725153b07a09430d1_7",
  "x": "To compensate the lack of training data on low-resource languages, a well-trained ASR Transformer with a CER of 26.64% on HKUST dataset, a corpus of Mandarin Chinese conversational telephone speech, is adopted from our work <cite>[9]</cite> .",
  "y": "uses"
 },
 {
  "id": "52af1f5378194ccdb7c8f755a6ae34_0",
  "x": "Previously proposed models (summarized in Section 2) exhibit several issues that the neural network-based baseline approach (detailed in Section 3.1) overcomes: (i) our model uses automatically extracted features without the need of external parsers nor manually extracted features (see Gupta et al. (2016) ; Miwa and Bansal (2016) ; Li et al. (2017) ), (ii) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time (see <cite>Adel and Sch\u00fctze (2017)</cite> ), and (iii) we model relation extraction in a multi-label setting, allowing multiple relations per entity (see Katiyar and Cardie (2017) ; Bekoulis et al. (2018a) ).",
  "y": "differences"
 },
 {
  "id": "52af1f5378194ccdb7c8f755a6ae34_1",
  "x": "<cite>Adel and Sch\u00fctze (2017)</cite> solve the simpler problem of entity classification (EC, assuming entity boundaries are given), instead of NER, and they replicate the context around the entities, feeding entity pairs to the relation extraction layer.",
  "y": "background"
 },
 {
  "id": "52af1f5378194ccdb7c8f755a6ae34_2",
  "x": "For the CoNLL04 (Roth and Yih, 2004 ) EC task (assuming boundaries are given), we use the same splits as in Gupta et al. (2016) ; <cite>Adel and Sch\u00fctze (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "52af1f5378194ccdb7c8f755a6ae34_3",
  "x": "We use the relaxed evaluation similar to Gupta et al. (2016) ; <cite>Adel and Sch\u00fctze (2017)</cite> on the EC task.",
  "y": "similarities"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_0",
  "x": "A promising approach to cross-lingual transfer of syntactic dependency parsers is to use multiple source languages and to tie model parameters across related languages. This idea was first explored for weakly supervised learning (Cohen and Smith, 2009; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010) and recently by <cite>Naseem et al. (2012)</cite> for multisource cross-lingual transfer.",
  "y": "background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_1",
  "x": "In particular, <cite>Naseem et al.</cite> showed that by selectively sharing parameters based on typological features of each language, substantial improvements can be achieved, compared to using a single set of parameters for all languages.",
  "y": "background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_2",
  "x": "The resulting parser outperforms the method of <cite>Naseem et al. (2012)</cite> on 12 out of 16 evaluated languages.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_3",
  "x": "The resulting parser provides significant improvements over a strong baseline parser and achieves a 13% relative error reduction on average with respect to the best model of <cite>Naseem et al. (2012)</cite> , outperforming it on 15 out of the 16 evaluated languages.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_4",
  "x": "To account for this issue, <cite>Naseem et al. (2012)</cite> recently introduced a novel generative model of dependency parsing, in which the generative process is factored into separate steps for the selection of dependents and their ordering.",
  "y": "background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_5",
  "x": "In the ordering step, however, parameters are selectively shared between subsets of <cite>Naseem et al. (2012)</cite> restricts its potential performance.",
  "y": "motivation"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_6",
  "x": "To account for this issue, <cite>Naseem et al. (2012)</cite> recently introduced a novel generative model of dependency parsing, in which the generative process is factored into separate steps for the selection of dependents and their ordering. In the ordering step, however, parameters are selectively shared between subsets of <cite>Naseem et al. (2012)</cite> restricts its potential performance.",
  "y": "motivation"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_7",
  "x": "Inspired by the superiority of discriminative graphbased parsing in the supervised scenario, we investigate whether the insights of <cite>Naseem et al. (2012)</cite> on selective parameter sharing can be incorporated into such models in the transfer scenario.",
  "y": "uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_8",
  "x": "To facilitate comparison with the state of the art, we use the same treebanks and experimental setup as <cite>Naseem et al. (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_9",
  "x": "We refer the reader to <cite>Naseem et al. (2012)</cite> for detailed information on the different treebanks.",
  "y": "background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_10",
  "x": "In line with <cite>Naseem et al. (2012)</cite>, we use gold part-of-speech tags and evaluate only on sentences of length 50 or less excluding punctuation.",
  "y": "similarities uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_11",
  "x": "The first baseline, <cite>NBG</cite>, is the generative model with selective parameter sharing from <cite>Naseem et al. (2012)</cite> .",
  "y": "uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_12",
  "x": "The first baseline, <cite>NBG</cite>, is the generative model with selective parameter sharing from <cite>Naseem et al. (2012)</cite> . 3 <cite>This model</cite> is trained without target language data, but we investigate the use of such data in \u00a75.4.",
  "y": "extends differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_13",
  "x": "We see that Delex performs well on target languages that are related to the majority of the source languages. However, for languages 3 Model \"D-,To\" in Table 2 from <cite>Naseem et al. (2012)</cite> . that diverge from the Indo-European majority family, the selective sharing model, <cite>NBG</cite>, achieves substantially higher accuracies.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_14",
  "x": "The feature templates of the resulting Bare model are shown in the center of Figure 2 . These features only model selectional preferences and dependency length, analogously to the selection component of <cite>NBG</cite>.",
  "y": "similarities"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_15",
  "x": "Inspired by <cite>Naseem et al.</cite> Table 2 from <cite>Naseem et al. (2012)</cite> . (2012), we make use of the typological features from WALS (Dryer and Haspelmath, 2011), listed in Table 1, to selectively share directional parameters between languages.",
  "y": "uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_16",
  "x": "This problem applies to any method for parameter mixing that treats all the parameters as equal. Like <cite>Naseem et al. (2012)</cite> , we instead share parameters more selectively.",
  "y": "similarities uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_17",
  "x": "Although this model still performs worse than <cite>NBG</cite>, it is an improvement over the Delex baseline and actually outperforms the former on 5 out of the 16 languages.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_18",
  "x": "Furthermore, Family achieves a 7% relative error reduction over the <cite>NBG</cite> baseline and outperforms it on 12 of the 16 languages.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_19",
  "x": "Cohen et al. (2011) and <cite>Naseem et al. (2012)</cite> have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains.",
  "y": "background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_20",
  "x": "While some higher-level linguistic properties of the target language have been incorporated through selective sharing, so far no features specific to the target language have been employed. Cohen et al. (2011) and <cite>Naseem et al. (2012)</cite> have shown that using expectation-maximization (EM) to this end can in some cases bring substantial accuracy gains. However, as discussed in \u00a75.2, standard self-training is not optimal for target language adaptation.",
  "y": "motivation"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_21",
  "x": "In this study, we combine the arc sets of two base parsers: first, the arc-marginal ambiguity set of the base parser ( \u00a75.2); and second, the Viterbi arc set from the <cite>NBG</cite> parser of <cite>Naseem et al. (2012)</cite> in Table 2 .",
  "y": "uses background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_22",
  "x": "As in <cite>Naseem et al. (2012)</cite> , we use the CoNLL training sets, stripped of all dependency information, as the unlabeled target language data in our experiments.",
  "y": "uses similarities"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_23",
  "x": "The ambiguity-aware training methods, that is ambiguity-aware self-training (AAST) and ambiguityaware ensemble-training (AAET), are compared to three baseline systems. First, <cite>NBG+EM</cite> is the generative model of <cite>Naseem et al. (2012)</cite> trained with expectation-maximization on additional unlabeled target language text.",
  "y": "uses"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_24",
  "x": "First, <cite>NBG+EM</cite> is the generative model of <cite>Naseem et al. (2012)</cite> trained with expectation-maximization on additional unlabeled target language text.",
  "y": "extends"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_25",
  "x": "Comparing this model to the <cite>NBG+EM</cite> baseline, we observe an improvement by 3.6% absolute, outperforming it on 14 of the 16 languages.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_26",
  "x": "<cite>Naseem et al.</cite> observed an increase from 59.3% to 60.4% on average by adding unlabeled target language data and the gains were not consistent across languages.",
  "y": "background"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_27",
  "x": "<cite>Naseem et al.</cite> observed an increase from 59.3% to 60.4% on average by adding unlabeled target language data and the gains were not consistent across languages. AAST, on the other hand, achieves consistent gains, rising from 62.0% to 64.0% on average.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_28",
  "x": "The relative error reduction with respect to the base Family model is 9% on average, while the average reduction with respect to <cite>NBG+EM</cite> is 13%.",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_29",
  "x": "While the best generative transfer model of <cite>Naseem et al. (2012)</cite> approaches its upper-bounding supervised accuracy (60.4% vs. 67.1%), our relaxed selftraining model is still far below its supervised counterpart (64.0% vs. 84.1%).",
  "y": "differences"
 },
 {
  "id": "52c52f6ce3663de49d5784630af1e7_30",
  "x": "On average, our best model provides a relative error reduction of 13% over the state-ofthe-art model of <cite>Naseem et al. (2012)</cite> , outperforming it on 15 out of 16 evaluated languages.",
  "y": "differences"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_0",
  "x": "Knowledge Base Population (KBP, e.g.: Riedel et al., 2013; Sterckx et al., 2016) attempts to identify facts within raw text and convert them into triples consisting of a subject, object and the relation between them. One common form of this task is slot filling (Surdeanu and Heng, 2014) , in which a knowledge base (KB) query, such as place of birth(Obama, ?) is applied to a set of documents and a set of slot fillers is returned. By converting such KB queries to natural language questions, <cite>Levy et al. (2017)</cite> showed that a question answering (QA) system could be effectively applied to this task.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_1",
  "x": "By converting such KB queries to natural language questions, <cite>Levy et al. (2017)</cite> showed that a question answering (QA) system could be effectively applied to this task. However, <cite>their approach</cite> relied on a modified QA model architecture and a dedicated slot-filling training corpus.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_2",
  "x": "Within this framework, we consider different models and training and test datasets, but we keep the translation of KB queries into natural language questions fixed, based on the crowd-sourced templates used by <cite>Levy et al. (2017)</cite> .",
  "y": "extends"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_3",
  "x": "In our first experiment, we examine the utility of a standard QA dataset as training data for the slotfilling model of <cite>Levy et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_4",
  "x": "In our first experiment, we examine the utility of a standard QA dataset as training data for the slotfilling model of <cite>Levy et al. (2017)</cite> . <cite>Their</cite> zeroshot model generalised from seen relations to unseen relations by translating all relations into natural language question templates, such as Where was XXX born? for the relation place of birth.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_5",
  "x": "In our first experiment, we examine the utility of a standard QA dataset as training data for the slotfilling model of <cite>Levy et al. (2017)</cite> . However, such a model also needs to be able to identify when no answer is found in the text, and to achieve this <cite>they</cite> trained a slightly modified version of BiDAF (Seo et al., 2016) both positive examples, containing answers, and negative examples, without answers.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_6",
  "x": "In our first experiment, we examine the utility of a standard QA dataset as training data for the slotfilling model of <cite>Levy et al. (2017)</cite> . <cite>These examples</cite> were derived from a pre-existing relation extraction resource, as <cite>their</cite> intention was to show the utility of the QA model.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_7",
  "x": "Data We compare two sources of training data: The <cite>University of Washington relation extraction</cite> (<cite>UWRE</cite>) dataset created by <cite>Levy et al. (2017</cite>) and the Stanford Question Answering Dataset (SQuAD) created by Rajpurkar et al. (2016) .",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_8",
  "x": "The <cite>UWRE</cite> data is derived from WikiReading (Hewlett et al., 2016) , which is itself derived from WikiData (Vrande\u010di\u0107, 2012) , and consists of a set of positive and negative examples for relation extraction from Wikipedia sentences.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_9",
  "x": "<cite>Levy et al. (2017)</cite> provide a number of train/dev/test splits, to allow <cite>them</cite> to evaluate a variety of modes of generalisation.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_10",
  "x": "We also construct a series of datasets that combine increasing quantities of the <cite>UWRE</cite> entity split training set into the SQuAD training set, to evaluate the benefits of SQuAD when dedicated relation extraction data is limited.",
  "y": "extends"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_11",
  "x": "Random samples of 10 3 , 10 4 , 10 5 and 10 6 <cite>UWRE</cite> instances are added to our SQuAD training set, while leaving the SQuAD dev dataset untouched.",
  "y": "extends"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_12",
  "x": "Models We employ the same modified BiDAF (Seo et al., 2016 ) model as <cite>Levy et al. (2017)</cite> , which uses an additional bias term to allow the model to signal when no answer is predicted within the text.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_13",
  "x": "Evaluation Following the approach of <cite>Levy et al. (2017)</cite> , we report F1 scores on the answers returned by the model.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_14",
  "x": "Results Table 1 reports the F1 scores for zeroshot relation extraction on the relation split test set, using models trained on the original <cite>UWRE</cite> and SQuAD datasets.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_15",
  "x": "As can be seen, BIDAF is actually more effective at answering the questions for the unseen relation types in the <cite>UWRE</cite> test set when it is trained on a standard QA dataset, rather than a dedicated relation extraction dataset.",
  "y": "extends"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_16",
  "x": "We compare training purely on <cite>UWRE</cite> instances to those same instances combined with the whole SQuAD dataset.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_17",
  "x": "In this second experiment, we want to test the ability of the models decribed above to generalise to data beyond the <cite>UWRE</cite> test set.",
  "y": "extends"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_18",
  "x": "Data We construct a challenge test set of negative examples based on sentences which are about the wrong entity but which do contain potential answers that are valid for the question and relation type. Thus, each positive example from the original <cite>UWRE</cite> entity split test set is turned into a negative example by pairing the sentence with an equivalent question about another entity.",
  "y": "extends"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_19",
  "x": "Models We re-use the <cite>UWRE</cite> and SQuAD trained models in addition to training on the UWRE+ datasets described in the previous section.",
  "y": "extends uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_20",
  "x": "Table 3 : Zero-shot Precision, Recall and F1 on the <cite>UWRE</cite> relation split test set.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_21",
  "x": "Although the original <cite>UWRE</cite> model achieved an F1 of around 90% on the unmodified entity split test set, here it only manages to get 2% of its predictions correct.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_22",
  "x": "Looking first at the effect of adding the original <cite>UWRE</cite> training instances, performance drops dramatically as the size of this expansion increases.",
  "y": "uses"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_23",
  "x": "4 Using an unmodified QA model for slot filling <cite>Levy et al. (2017)</cite> modify the BiDAF architecture to produce an additional output representing the probability that no answer is present in the text.",
  "y": "background"
 },
 {
  "id": "5428f8c196308c90618abfdbdf856a_24",
  "x": "Results Table 3 reveals that the unmodified BiDAF model is almost as effective as the <cite>Levy et al. (2017)</cite> model in terms of zero-shot F1 on the original <cite>UWRE</cite> test set.",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_0",
  "x": "State-of-the-art semantic parsers are neural encoder-decoder models, where decoding is guided by the grammar of the target programming language (Yin and Neubig, 2017; Rabinovich et al., 2017; <cite>Iyer et al., 2018</cite>) to ensure syntactically valid programs.",
  "y": "background"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_1",
  "x": "We evaluate our approach on a context dependent semantic parsing task (<cite>Iyer et al., 2018</cite>) using the CONCODE dataset, where we improve the state of the art by 2.2% of BLEU score.",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_2",
  "x": "Neural encoder-decoder models have proved effective in mapping NL to logical forms (Dong and Lapata, 2016) and also for directly producing general purpose programs (Iyer et al., 2017 (<cite>Iyer et al., , 2018</cite> .",
  "y": "background"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_3",
  "x": "Iy<cite>er et al. (2018</cite>) use a similar decoding approach but use a specialized context encoder for the task of context-dependent code generation.",
  "y": "background"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_4",
  "x": "The decoder is then trained similar to previous approaches (Yin and Neubig, 2017; <cite>Iyer et al., 2018</cite>) using the compressed set of rules.",
  "y": "similarities"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_5",
  "x": "We apply our approach to the context dependent encoder-decoder model of <cite>Iyer et al. (2018</cite>) on the CONCODE dataset, and compare performance to a better tuned instance of their best model.",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_6",
  "x": "We follow the approach of <cite>Iyer et al. (2018</cite>) with three major modifications in their encoder, which yields improvements in speed and accuracy (IyerSimp) .",
  "y": "extends"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_7",
  "x": "Then, h 1 , . . . , h z , andt i ,v i ,r i ,m i are passed on to the attention mechanism in the decoder, exactly as in <cite>Iyer et al. (2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_8",
  "x": "The decoder of <cite>Iyer et al. (2018)</cite> is left unchanged.",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_9",
  "x": "We use a BPE vocabulary of 10K tokens for embedding matrix B and get the best validation set results using the original hyperparameters used by <cite>Iyer et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_10",
  "x": "Since idiom aware training is significantly faster than without idioms, we are also able to train on an additional 400K training examples that <cite>Iyer et al. (2018)</cite> released as part of CONCODE.",
  "y": "uses"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_12",
  "x": "We report exact match accuracy, corpus level BLEU score (which serves as a measure of partial credit) (Papineni et al., 2002) , and training time for all these configurations. <cite>Iyer et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "55160a7ab2df9a86e677bcc72d9842_13",
  "x": "Compared to the model of <cite>Iyer et al. (2018)</cite> , our significantly reduced training time enables us to train on their extended training set.",
  "y": "differences"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_0",
  "x": "Seminal work from <cite>[5]</cite> presents a comparative style analysis of hyperpartisan news, evaluating features such as characters n-grams, stop words, part-of-speech, readability scores, and ratios of quoted words and external links.",
  "y": "background"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_2",
  "x": "We build upon <cite>previous work</cite> and use the dataset from <cite>[5]</cite> : this way we can investigate hyperpartisan-biased news (i.e., extremely one-sided) that have been manually fact-checked by professional journalists from BuzzFeed.",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_3",
  "x": "However, perhaps surprisingly, we are able to achieve the overall best performance by simply using higher-length n-grams than those used in the original work from <cite>[5]</cite> : this seems to indicate a strong lexical overlap between different sources with the same orientation, which, in turn, calls for more challenging datasets and task formulations to encourage the development of models covering more subtle, i.e., implicit, forms of bias.",
  "y": "extends"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_4",
  "x": "We used the <cite>BuzzedFeed-Webis Fake News Corpus 2016</cite> collected by <cite>[5]</cite> whose articles were labeled with respect to three political orientations: mainstream, left-wing, and right-wing (see Table 2 ).",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_5",
  "x": "We used the <cite>BuzzedFeed-Webis Fake News Corpus 2016</cite> collected by <cite>[5]</cite> whose articles were labeled with respect to three political orientations: mainstream, left-wing, and right-wing (see Table 2 ). During initial data analysis and prototyping we identified a variety of issues with the <cite>original dataset:</cite> we cleaned the data excluding articles with empty or bogus texts, e.g. 'The document has moved here' (23 and 14 articles respectively).",
  "y": "extends"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_6",
  "x": "4 Following the settings of <cite>[5]</cite> , we balance the training set using random duplicate oversampling.",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_7",
  "x": "4 Following the settings of <cite>[5]</cite> , we balance the training set using random duplicate oversampling. 4 <cite>The dataset</cite> is available at <cite>https://github.com/jjsjunquera/ UnmaskingBiasInNews</cite>.",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_8",
  "x": "Evaluation: We performed 3-fold cross-validation with the same configuration used in <cite>[5]</cite> .",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_9",
  "x": "In order to compare our results with those reported in <cite>[5]</cite> , we also used accuracy, precision, and recall.",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_10",
  "x": "We compare with <cite>[5]</cite> against their topic and style-based methods.",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_11",
  "x": "In order to compare our results with those reported in <cite>[5]</cite> , we report the same measures the <cite>authors</cite> used.",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_12",
  "x": "The last two rows show the results obtained by applying the system from <cite>[5]</cite> 6 to our cleaned dataset (Section 3).",
  "y": "uses"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_13",
  "x": "Similar to <cite>[5]</cite> , the topic-based model achieves better results than the style-related model.",
  "y": "similarities"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_14",
  "x": "However, the differences between the results of the two evaluated approaches are much higher (0.66 vs. 0.57 according to Macro F 1 ) than those shown in <cite>[5]</cite> .",
  "y": "differences"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_15",
  "x": "In line with what was already pointed out in <cite>[5]</cite> , the left-wing orientation is harder to predict, possibly because this class is represented with fewer examples in the dataset.",
  "y": "similarities"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_16",
  "x": "In fact, comparing the results of <cite>[5]</cite> against our baseline model, it is possible to note that even without masking any word, the classifier obtains better results.",
  "y": "differences"
 },
 {
  "id": "55bcdca5052745160dc861e22e7401_17",
  "x": "These results confirm that perhaps the performance of our approach overcomes the models proposed in <cite>[5]</cite> because of the length of the n-grams 7 .",
  "y": "differences"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_0",
  "x": "Figure 1: An English sentence re-ordered into Japanese order using the rule-based method of<cite> Isozaki et al. (2010b)</cite> , and its reference Japanese translation.",
  "y": "uses"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_1",
  "x": "Importantly, even simple heuristic reordering methods with a few handcreated rules have been shown to be highly effective in closing syntactic gaps (Collins et al. (2005) ;<cite> Isozaki et al. (2010b)</cite> ; Fig. 1 ).",
  "y": "background"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_2",
  "x": "Experiments demonstrate the effectiveness of our approach on translation from Japanese and Uyghur to English, with a simple, linguistically motivated method of head finalization (HF;<cite> Isozaki et al. (2010b)</cite> ) as our reordering method.",
  "y": "uses"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_3",
  "x": "Reordering can be done either using rules based on linguistic knowledge<cite> (Isozaki et al., 2010b</cite>; Collins et al., 2005) or learning from aligned parallel data (Xia and McCord, 2004; Habash, 2007) , and in principle our pseudo-corpus creation paradigm is compatible with any of these methods.",
  "y": "uses"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_4",
  "x": "Examples of rule-based methods include those to reorder English into German (Navratil et al., 2012) , Arabic (Badr et al., 2009 ), or Japanese<cite> (Isozaki et al., 2010b)</cite> .",
  "y": "background"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_5",
  "x": "In experiments we use<cite> Isozaki et al. (2010b)</cite> 's method of reordering SVO languages (e.g. English) into the order of SOV languages (e.g. Japanese) by simply (1) applying a syntactic parser to English (Tsuruoka et al., 2004) , (2) identifying the head constituent of each phrase and moving it to the end of the phrase, and (3) inserting special tokens after subjects and objects of predicates to mimic Japanese case markers.",
  "y": "uses"
 },
 {
  "id": "56d1812bec8abbdb31a2346d96e5ca_6",
  "x": "As noted above, we use HF<cite> (Isozaki et al., 2010b)</cite> as our re-ordering rule.",
  "y": "uses"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_0",
  "x": "We show that the proposed method outperforms the baseline of <cite>Richardson et al. (2013)</cite> , and despite its relative simplicity, is comparable to recent work using machine learning.",
  "y": "differences"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_1",
  "x": "To this end, <cite>Richardson et al. (2013)</cite> proposed the Machine Comprehension Test (MCTest), a new challenge that aims at evaluating machine comprehension.",
  "y": "background"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_2",
  "x": "<cite>Richardson et al. (2013)</cite> also showed how the creation of stories and questions can be crowdsourced efficiently, constructing two datasets for the task, namely MC160 and MC500.",
  "y": "background"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_3",
  "x": "When combined with BIUTEE, we achieved 74.27% accuracy on MC160 and 65.96% on MC500, which are significantly better than those reported by <cite>Richardson et al. (2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_4",
  "x": "3 Scoring function <cite>Richardson et al. (2013)</cite> proposed a sliding window algorithm that ranks the answers by forming the bag-of-words vector of each answer paired with the question text and then scoring them according to their overlap with the story text.",
  "y": "background"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_5",
  "x": "More concretely, the algorithm of <cite>Richardson et al. (2013)</cite> passes a sliding window over the story, size of which is equal to the number of words in the question-answer pair.",
  "y": "background"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_6",
  "x": "Similar to <cite>Richardson et al. (2013)</cite> , we use a linear combination of this score with their distancebased scoring function, and we weigh tokens with their inverse document frequencies in each individual story.",
  "y": "similarities uses"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_7",
  "x": "Our proposed baseline outperforms the baseline of <cite>Richardson et al. (2013)</cite> by 4 and 3 points in accuracy on MC160 and MC500 respectively.",
  "y": "differences"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_8",
  "x": "If we linearly combine the RTE scores used in the MSR baseline with our method, we achieve 5 and 2.5 accuracy points higher than the best results achieved by <cite>Richardson et al. (2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "5a000efaa052588f6cfbb69f8ced2d_9",
  "x": "<cite>Richardson et al. (2013)</cite> demonstrate that the MC160 and MC500 have similar ratings for clarity and grammar, and that humans perform equally well on both.",
  "y": "background"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_0",
  "x": "Current statistical machine translation systems suffer from a major drawback: they only extract rules from 1-best alignments, which adversely affects the rule sets quality due to alignment mistakes. To alleviate this problem, we extract hierarchical rules from weighted alignment matrix<cite> (Liu et al., 2009)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_1",
  "x": "Since<cite> Liu et al. (2009)</cite> show that weighted alignment matrix provides an elegant solution to these two drawbacks, we apply it to the hierarchical phrase-based model (Chiang, 2005) and the tree-to-string model Huang et al., 2006) . While such an idea seems intuitive, it is non-trivial to extract hierarchical rules from weighted alignment matrices.",
  "y": "uses"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_2",
  "x": "Another challenge is how to achieve a balance between performance and rule table size. Note that given a source phrase, there would be plenty of \"potential\" candidate target phrases in weighted matrices<cite> (Liu et al., 2009</cite> ). If we retain all of them, these phrase pairs would produce even more hierarchical rules. For computational tractability, we need to design a measure to score the phrase pairs and wipe out the low-quality ones. We propose a new algorithm to calculate the relative frequencies of rules, and construct a measure that incorporates both frequency and lexical weight to score target phrases.",
  "y": "motivation background differences"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_3",
  "x": "A weighted alignment matrix<cite> (Liu et al., 2009)</cite> m is a J \u00d7 I matrix to encode the probabilities of n-best alignments of the same sentence pair. Each element in the matrix stores a link probability p m (j, i), which is estimated from an n-best list by calculating relative frequencies: where Here N is an n-best list, p(a) is the probability of an alignment a in the n-best list.",
  "y": "background"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_4",
  "x": [
   "Liu et al. (2009) use the product of inside and outside probabilities as the fractional count of a phrase pair. Liu et al. (2009) define that inside probability indicates the probability that at least one word in source phrase is aligned to a word in target phrase, and outside probability indicates the chance that no words in one phrase are aligned to a word outside the other phrase. The fractional count is calculated: where \u03b1(\u00b7) and \u03b2(\u00b7) denote the inside and outside probabilities respectively, which can be calculated as Here in(\u00b7) denotes the inside area, which includes elements that fall inside the phrase pair, while out(\u00b7) denotes the outside area including elements that fall outside the phrase pair while fall in the same row or the same column."
  ],
  "y": "background"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_5",
  "x": "To calculate the lexical weights,<cite> Liu et al. (2009)</cite> adapt p m (j, i) as the fractional count count(f j , e i ).",
  "y": "background"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_6",
  "x": "Since we can calculate relative frequencies and lexical weights of phrase pairs as in<cite> Liu et al. (2009)</cite> , we only focus on the calculation of variable rules.",
  "y": "uses background"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_7",
  "x": "We follow<cite> Liu et al. (2009)</cite> to calculate relative frequencies using the product of inside and outside probabilities.",
  "y": "uses"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_8",
  "x": "We follow<cite> Liu et al. (2009)</cite> to prune rule table using a threshold of frequency.",
  "y": "uses"
 },
 {
  "id": "5a6684d978c0dbcfaabb4bc2314aeb_9",
  "x": "We follow<cite> Liu et al. (2009)</cite> to use p s2t \u00d7 p t2s as the probabilities of an alignment pair. Analogously, we abandon duplicate alignments that are produced from different alignment pairs.",
  "y": "uses"
 },
 {
  "id": "5b98a80237182b2d506ea4c9d71aa1_0",
  "x": "Most empirical approaches currently employed in NER task make decision only on local context for extract inference, which is based on the data independent assumption<cite> (Krishnan and Manning, 2006)</cite> . But often this assumption does not hold because non-local dependencies are prevalent in natural language (including the NER task).",
  "y": "motivation background"
 },
 {
  "id": "5b98a80237182b2d506ea4c9d71aa1_1",
  "x": "In order to establish the long dependencies easily and overcome the disadvantage of the approximate inference,<cite> Krishnan and Manning (2006)</cite> propose a two-stage approach using Conditional Random Fields (CRFs) with extract inference. They represent the non-locality with non-local features, and extract the nonlocal features from the output of the first stage CRF using local context alone; then they incorporate the non-local features into the second CRF. But the features in this approach are only used to improve label consistency. To our best knowledge, up to now, non-local information has not been explored to improve NER recall in previous researches; on the other hand, NER is always impaired by its lower recall due to the imbalanced distribution where the NONE class dominates the entity classes.",
  "y": "motivation background"
 },
 {
  "id": "5b98a80237182b2d506ea4c9d71aa1_2",
  "x": "Similar to<cite> Krishnan and Manning (2006)</cite> , we also encode non-local information with features and apply the simple two-stage architecture. Different from their work for improve label consistency, their features are activated on the recognized entities coming from the first CRF, the non-local features we design are used to recall more missed entities which are seen in the training data or unseen entities but some of their occurrences being recognized correctly in the first stage, our features are fired on the raw token sequence directly with forward maximum match. Compared to their non-local information extracted from training data with 10-fold cross-validation, our non-local information is extracted from the training date directly; our approach obtaining the non-local features is simpler. Moreover, we design different non-local features encoding different useful information for NER two subtasks: entity boundary detection and entity semantic classification.",
  "y": "similarities differences"
 },
 {
  "id": "5b98a80237182b2d506ea4c9d71aa1_3",
  "x": "Similar to<cite> (Krishnan and Manning, 2006)</cite> , we employ two-stage architecture under conditional random fields (CRFs) framework.",
  "y": "similarities"
 },
 {
  "id": "5b98a80237182b2d506ea4c9d71aa1_4",
  "x": "Token-position & entity-majority features (F4): These features capture non-local information from F2 and F3 simultaneously. They take into account the entity boundary and semantic class information at the same time. These non-local features are applied in English NER in one-step approach<cite> (Krishnan and Manning, 2006</cite>; Wong and Ng, 2007) , they employ these features to improve entity consistence among their different occurrences.",
  "y": "background"
 },
 {
  "id": "5ed24e18f892d7092c183acab4b175_0",
  "x": "Recently, high quality and easy to train Skip-gram shallow architectures were presented in <cite>[10]</cite> and considerably improved in [11] with the introduction of negative sampling and subsampling of frequent words.",
  "y": "background"
 },
 {
  "id": "5ed24e18f892d7092c183acab4b175_1",
  "x": "Google News is one of the biggest and richest text sets with 100 billion tokens and a vocabulary of 3 million words and phrases <cite>[10]</cite> .",
  "y": "background"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_0",
  "x": "In this paper we describe the Semantic Entity Retrieval Toolkit (SERT) that provides implementations of <cite>our previously published entity representation models</cite>.",
  "y": "extends motivation"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_1",
  "x": "e unsupervised learning of low-dimensional, semantic representations of words and entities has recently gained a ention for the entity-oriented tasks of expert nding [9] and product search [<cite>8</cite>] .",
  "y": "background motivation"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_2",
  "x": "In the case of product search, an associated document is a product description or review [<cite>8</cite>] .",
  "y": "background"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_3",
  "x": "In this paper we describe the Semantic Entity Retrieval Toolkit (SERT) that provides implementations of our previously published entity representation models [<cite>8</cite>, 9] .",
  "y": "extends"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_4",
  "x": "An alternative option that exists within the toolkit is to resample word sequence/entity pairs such that every entity is associated with the same number of word sequences, as used for product search [<cite>8</cite>] .",
  "y": "extends similarities"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_5",
  "x": "e toolkit includes implementations of state-of-the-art representation learning models that were applied to expert nding [9] and product search [<cite>8</cite>] . Users of the toolkit can use these implementations to learn representations out-of-the-box or adapt the algorithms to their needs.",
  "y": "extends background"
 },
 {
  "id": "5f62958d0cdd32b15067c1afe458a5_7",
  "x": "e toolkit contains implementations of state-of-the-art entity representations algorithms [<cite>8</cite>, 9] and consists of three components: text processing, representation learning and inference.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_0",
  "x": "The recent advances in image captioning as well as the release of large-scale movie description datasets such as <cite>MPII-MD</cite> <cite>[28]</cite> allow to study this task in more depth.",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_2",
  "x": "In the meanwhile, two large-scale <cite>movie description datasets</cite> have been proposed, namely <cite>MPII Movie Description (MPII-MD)</cite> <cite>[28]</cite> and Montreal Video Annotation Dataset (M-VAD) [31] .",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_3",
  "x": "In the meanwhile, two large-scale <cite>movie description datasets</cite> have been proposed, namely <cite>MPII Movie Description (MPII-MD)</cite> <cite>[28]</cite> and Montreal Video Annotation Dataset (M-VAD) [31] . <cite>Both</cite> are based on movies with associated textual descriptions and allow studying the problem how to generate movie description for visually disabled people.",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_4",
  "x": "Works addressing these datasets <cite>[28,</cite> 33, 39] show that <cite>they</cite> are indeed challenging in terms of visual recognition and automatic description.",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_5",
  "x": "This work contributes a) an approach to build robust visual classifiers which distinguish verbs, objects, and places extracted from weak sentence annotations; b) based on the visual classifiers we evaluate different design choices to train an LSTM for generating descriptions. This outperforms <cite>related work</cite> on the <cite>MPII-MD dataset</cite>, both using automatic and human evaluation; c) we perform a detailed analysis of prior work and our approach to understand the challenges of the movie description task.",
  "y": "differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_6",
  "x": "Recently two large-scale movie description datasets have been proposed, <cite>MPII Movie Description (MPII-MD)</cite> <cite>[28]</cite> and Montreal Video Annotation Dataset (M-VAD) [31] .",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_7",
  "x": "Recently two large-scale movie description datasets have been proposed, <cite>MPII Movie Description (MPII-MD)</cite> <cite>[28]</cite> and Montreal Video Annotation Dataset (M-VAD) [31] . Given that <cite>they</cite> are based on movies, <cite>they</cite> cover a much broader domain then previous video description datasets.",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_8",
  "x": "Recently two large-scale movie description datasets have been proposed, <cite>MPII Movie Description (MPII-MD)</cite> <cite>[28]</cite> and Montreal Video Annotation Dataset (M-VAD) [31] . Given that <cite>they</cite> are based on movies, <cite>they</cite> cover a much broader domain then previous video description datasets. Consequently <cite>they</cite> are much more varied and challenging with respect to the visual content and the associated description.",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_9",
  "x": "Recently two large-scale movie description datasets have been proposed, <cite>MPII Movie Description (MPII-MD)</cite> <cite>[28]</cite> and Montreal Video Annotation Dataset (M-VAD) [31] . Given that <cite>they</cite> are based on movies, <cite>they</cite> cover a much broader domain then previous video description datasets. Consequently <cite>they</cite> are much more varied and challenging with respect to the visual content and the associated description. <cite>They</cite> also do not have any additional annotations, as e.g. TACoS Multi-Level [27] , thus one has to rely on the weak annotations of the sentence descriptions.",
  "y": "background"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_10",
  "x": "To extract labels from sentences we rely on the semantic parser of <cite>[28]</cite> , however we treat the labels differently to handle the weak supervision (see Section 3.1).",
  "y": "uses differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_11",
  "x": "To extract labels from sentences we rely on the semantic parser of <cite>[28]</cite> , however we treat the labels differently to handle the weak supervision (see Section 3.1). We show that this improves over <cite>[28]</cite> and [33] .",
  "y": "uses differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_12",
  "x": "As in <cite>[28]</cite> we parse the sentences to obtain a set of labels (single words or short phrases, e.g. look up) to train our visual classifiers.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_13",
  "x": "However, in contrast to <cite>[28]</cite> we do not want to keep all of these initial labels as they are noisy, but select only visual ones which actually can be robustly recognized.",
  "y": "differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_14",
  "x": "In order to find the verbs among the labels we rely on the semantic parser of <cite>[28]</cite> .",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_15",
  "x": "In this section we first analyze our approach on the <cite>MPII-MD</cite> <cite>[28]</cite> dataset and explore different design choices.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_17",
  "x": "We build on the labels discovered by our semantic parser <cite>[28]</cite> and additionally match these labels to sentences which <cite>the parser</cite> failed to process.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_18",
  "x": "We build on the labels discovered by our semantic parser <cite>[28]</cite> and additionally match these labels to sentences which <cite>the parser</cite> failed to process. To be able to learn classifiers we select the labels that appear at least 30 times, resulting in 1,263 labels. <cite>The parser</cite> additionally tells us whether the label is a verb.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_19",
  "x": "We use the visual features (DT, LSDA, PLACES) provided with the <cite>MPII-MD dataset</cite> <cite>[28]</cite> .",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_21",
  "x": "In the following section we evaluate our best ensemble (last line of Table 4 ) on the test set of <cite>MPII-MD</cite>.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_22",
  "x": "We compare the best method of <cite>[28]</cite> , the recently proposed method S2VT [33] and our proposed \"Visual Labels\"-LSTM on the test set of the <cite>MPII-MD dataset</cite> (6,578 clips).",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_23",
  "x": "We also perform a human evaluation, by randomly selecting 1300 video snippets and asking AMT turkers to rank <cite>three systems</cite> (the best SMT of <cite>[28]</cite> , S2VT [33] and ours) with respect to Correctness, Grammar and Relevance, similar to <cite>[28]</cite> .",
  "y": "similarities"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_24",
  "x": "Exploring different strategies to label selection and classifier training, as well as various LSTM configurations allows to obtain best result to date on the <cite>MPII-MD dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_25",
  "x": "We also perform a human evaluation, by randomly selecting 1300 video snippets and asking AMT turkers to rank <cite>three systems</cite> (the best SMT of <cite>[28]</cite> , S2VT [33] and ours) with respect to Correctness, Grammar and Relevance, similar to <cite>[28]</cite> . Results. Moreover, we improve over the recent approach of [33] , which also uses LSTM to generate video descriptions. Exploring different strategies to label selection and classifier training, as well as various LSTM configurations allows to obtain best result to date on the <cite>MPII-MD dataset</cite>. Human evaluation mainly agrees with the automatic measures. We outperform <cite>both prior works</cite> in terms of Correctness and Relevance, however we lose to S2VT in terms of Grammar.",
  "y": "differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_26",
  "x": "A closer look at the sentences produced by <cite>all three methods</cite> gives us additional insights. An interesting characteristic is the output vocabulary size, which is 94 for <cite>[28] ,</cite> 86 for [33] and 605 for our method, while the test set contains 6422 unique words.",
  "y": "differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_27",
  "x": "An interesting characteristic is the output vocabulary size, which is 94 for <cite>[28] ,</cite> 86 for [33] and 605 for our method, while the test set contains 6422 unique words.",
  "y": "differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_28",
  "x": "Despite the recent advances in the video description domain, including our proposed approach, the video description performance on the movie description datasets (<cite>MPII-MD</cite> <cite>[28]</cite> and M-VAD [31] ) remains relatively low.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_30",
  "x": "In the following we evaluate <cite>all three methods</cite> on the <cite>MPII-MD</cite> test set.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_35",
  "x": "We obtain the sense information from the semantic parser of <cite>[28]</cite> , thus senses might be noisy.",
  "y": "uses"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_36",
  "x": "We find that our method is best for all topics except \"communication\", where <cite>[28]</cite> wins.",
  "y": "differences"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_37",
  "x": "The most frequent verbs in this topic are \"look up\" and \"nod\", which are also frequent in the dataset and in the sentences produced by <cite>[28]</cite> .",
  "y": "similarities"
 },
 {
  "id": "5fa570cf5f37c7aae3b428a17de3e3_38",
  "x": "As the result we obtain the highest performance on the <cite>MPII-MD</cite> dataset as shown by all automatic evaluation measures and extensive human evaluation.",
  "y": "uses"
 },
 {
  "id": "600317fc3ce88ea730993d3cc94f19_0",
  "x": "Since the first approach [Wright and Wrigley 1991] of combining a probabilistic method into the GLR technique was published, Some probabilistic GLR parsers also have been implemented in which probabilities are assigned to actions of LR parsing tables by using lookaheads or LR states as simple context information of <cite>[Briscoe and Carroll 1993]</cite> , [Kentaro et al. 1998 ], and [Ruland, 2000] which does not use the stack information of the GLR parser effectively, because of highly complex internal GLR stack.",
  "y": "background"
 },
 {
  "id": "600317fc3ce88ea730993d3cc94f19_1",
  "x": "Since the first approach [Wright and Wrigley 1991] of combining a probabilistic method into the GLR technique was published, Some probabilistic GLR parsers also have been implemented in which probabilities are assigned to actions of LR parsing tables by using lookaheads or LR states as simple context information of <cite>[Briscoe and Carroll 1993]</cite> , [Kentaro et al. 1998 ], and [Ruland, 2000] which does not use the stack information of the GLR parser effectively, because of highly complex internal GLR stack. As a result, they have used relatively limited contextual information for disambiguation. [Kwak et al., 2001] have proposed a conditional action model that uses the partially constructed parse represented by the graph-structured stack as the additional context. However, this method inappropriately defined sub-tree structure. Our proposed model uses Surface Phrasal Types representing the structural characteristics of the sub-trees for its additional contextual information.",
  "y": "motivation"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_0",
  "x": "Our study focuses on racial bias in hate speech and abusive language detection datasets (Waseem, 2016;<cite> Waseem and Hovy, 2016</cite>; Golbeck et al., 2017; Founta et al., 2018) , all of which use data collected from Twitter.",
  "y": "background motivation"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_1",
  "x": "<cite>Waseem and Hovy (2016)</cite> collected 130k tweets containing one of seventeen different terms or phrases they considered to be hateful.",
  "y": "background"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_2",
  "x": "In all but one of the comparisons, there are statistically significant (p < 0.001) differences and in all but one of these we see that tweets in the black-aligned corpus are assigned negative labels more frequently than those by whites. The only case where blackaligned tweets are classified into a negative class less frequently than white-aligned tweets is the racism class in the <cite>Waseem and Hovy (2016)</cite> classifier.",
  "y": "differences"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_3",
  "x": "Table 3 shows that for tweets containing the word \"n*gga\", classifiers trained on <cite>Waseem and Hovy (2016)</cite> and Waseem (2016) are both predict black-aligned tweets to be instances of sexism approximately 1.5 times as often as white-aligned tweets.",
  "y": "similarities uses"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_4",
  "x": "We see similar results for <cite>Waseem and Hovy (2016)</cite> and Waseem (2016) .",
  "y": "similarities"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_5",
  "x": "The <cite>Waseem and Hovy (2016)</cite> classifier is particularly sensitive to the word \"b*tch\" with 96% of black-aligned and 94% of white-aligned tweets predicted to belong to this class.",
  "y": "background"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_6",
  "x": "Classifiers trained on data from <cite>Waseem and Hovy (2016)</cite> and Waseem (2016) only predicted a small fraction of the tweets to be racism.",
  "y": "differences"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_7",
  "x": "Some studies sampled tweets using small, ad hoc sets of keywords created by the authors<cite> (Waseem and Hovy, 2016</cite>; Waseem, 2016; Golbeck et al., 2017) , an approach demonstrated to produce poor results (King et al., 2017) .",
  "y": "background"
 },
 {
  "id": "60c1245eff625441383913f947a8b1_8",
  "x": "The datasets considered here relied upon a range of different annotators, from the authors (Golbeck et al., 2017;<cite> Waseem and Hovy, 2016)</cite> and crowdworkers Founta et al., 2018) to activists (Waseem, 2016) .",
  "y": "background"
 },
 {
  "id": "61f88b86c451fb6a5e5893c8c42a24_0",
  "x": "Suggestions can either be expressed explicitly (Brun, 2013) , or by expressing wishes regarding new features and improvements<cite> (Ramanand et al., 2010)</cite> (Table 1) .",
  "y": "background"
 },
 {
  "id": "61f88b86c451fb6a5e5893c8c42a24_1",
  "x": "Table 1 presents some examples of occurrence of subjunctive mood collected from different forums on English grammar 1 . There seems to be a high probability of the occurrence of subjunctive mood in wish and suggestion expressing sentences. This observation can be exploited for the tasks of wish detection<cite> (Ramanand et al., 2010)</cite> , and suggestion extraction (Brun, 2013) . To the best of our knowledge, subjunctive mood has never been analysed in the context of wish and suggestion detection.",
  "y": "motivation background"
 },
 {
  "id": "61f88b86c451fb6a5e5893c8c42a24_2",
  "x": "Suggestion Detection: <cite>Ramanand et al. (2010)</cite> pointed out that wish is a broader category, which might not bear suggestions every time. They performed suggestion detection, where they focussed only on suggestion bearing wishes, and used manually formulated syntactic patterns for their detection.",
  "y": "background"
 },
 {
  "id": "61f88b86c451fb6a5e5893c8c42a24_3",
  "x": "<cite>Ramanand et al. (2010)</cite> worked on product review dataset of the wish corpus, with an objective to extract suggestions for improvements. They considered suggestions as a subset of wishes, and thus retained the labels of only suggestion bearing wishes. They also annotated additional product reviews, but their data is not available for open research.",
  "y": "background"
 },
 {
  "id": "61f88b86c451fb6a5e5893c8c42a24_4",
  "x": "Annotation Details: We had 2 annotators annotate each sentence with a suggestion or non-suggestion tag. We support the observation of <cite>Ramanand et al. (2010)</cite> that wishes for improvements and new features are implicit expression of suggestions. Therefore, annotators were also asked to annotate suggestions which were expressed as wishes.",
  "y": "motivation similarities"
 },
 {
  "id": "61f88b86c451fb6a5e5893c8c42a24_5",
  "x": "We collect all members of the VerbNet verb classes advice, wish, want, urge, require; 28 different verbs were obtained. <cite>Ramanand et al. (2010)</cite> also used a similar but much smaller subset {love, like, prefer and suggest} in their rules.",
  "y": "similarities"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_0",
  "x": "Recently, <cite>Bicknell and Levy (2010)</cite> presented a model of eye movement control in reading that directly models the process of identifying the text from visual input, and makes eye movements to maximize the efficiency of the identification process.",
  "y": "background"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_1",
  "x": "Because<cite> Bicknell and Levy's (2010)</cite> model implements the main proposal for why word length effects should arise, i.e., visual acuity limitations, the fact that the model does not reproduce humanlike word length effects suggests that our understanding of the causes of word length effects may be incomplete.",
  "y": "background"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_2",
  "x": "We present an extension of<cite> Bicknell and Levy's (2010)</cite> model which does not make this simplifying assumption, and show in two sets of simulations that effects of word length produced by the extended model look more like those of humans.",
  "y": "extends differences"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_3",
  "x": "The model presented by <cite>Bicknell and Levy (2010)</cite> fits this description, and includes visual acuity limitations (in fact, identical to the visual acuity function in SWIFT).",
  "y": "similarities"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_4",
  "x": "In the remainder of this paper, we describe an extension of<cite> Bicknell and Levy's (2010)</cite> model in which visual input provides stochastic -rather than veridical -information about the length of words, yielding uncertainty about word length, and in which the amount of uncertainty grows with length.",
  "y": "extends differences"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_5",
  "x": "In this section, we describe our extension of<cite> Bicknell and Levy's (2010)</cite> rational model of eye movement control in reading.",
  "y": "extends"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_6",
  "x": "Following <cite>Bicknell and Levy (2010)</cite>, we use very simple probabilistic models of language knowledge: word n-gram models (Jurafsky & Martin, 2009) , which encode the probability of each word conditional on the n \u2212 1 previous words.",
  "y": "similarities uses"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_7",
  "x": "We compare three levels of length uncertainty: \u03b4 \u2208 {0, .05, .1}. The first of these (\u03b4 = 0) corresponds to<cite> Bicknell and Levy's (2010)</cite> model, which has no uncertainty about word length.",
  "y": "similarities"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_8",
  "x": "We test the model on a corpus of 33 sentences from the Schilling corpus slightly modified by <cite>Bicknell and Levy (2010)</cite> so that every bigram occurred in the BNC, ensuring that the results do not depend on smoothing.",
  "y": "extends differences"
 },
 {
  "id": "6388fd7167389982be2f01fbe594cd_9",
  "x": "We described the failure of the rational model presented in <cite>Bicknell and Levy (2010)</cite> to obtain humanlike effects of word length, despite including all of these factors, suggesting that our understanding of word length effects in reading is incomplete.",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_0",
  "x": "By converting such KB queries to natural language questions, <cite>Levy et al. (2017)</cite> showed that a question answering (QA) system could be effectively applied to this task.",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_1",
  "x": "By converting such KB queries to natural language questions, <cite>Levy et al. (2017)</cite> showed that a question answering (QA) system could be effectively applied to this task. However, <cite>their</cite> approach relied on a modified QA model architecture and a dedicated slot-filling training corpus.",
  "y": "motivation"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_2",
  "x": "Within this framework, we consider different models and training and test datasets, but we keep the translation of KB queries into natural language questions fixed, based on the crowd-sourced templates used by <cite>Levy et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_3",
  "x": "In our first experiment, we examine the utility of a QA dataset in relation to the slot-filling task of <cite>Levy et al. (2017)</cite> .",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_4",
  "x": "In our first experiment, we examine the utility of a QA dataset in relation to the slot-filling task of <cite>Levy et al. (2017)</cite> . <cite>Their</cite> zero-shot model generalised from seen relations to unseen relations by translating all relations into natural language question templates, such as Where was XXX born? for the relation place of birth.",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_5",
  "x": "In our first experiment, we examine the utility of a QA dataset in relation to the slot-filling task of <cite>Levy et al. (2017)</cite> . <cite>Their</cite> zero-shot model generalised from seen relations to unseen relations by translating all relations into natural language question templates, such as Where was XXX born? for the relation place of birth. Identifying an instance of such a relation in text is then equivalent to finding an answer to the relevant question template, instantiated with the appropriate entity. However, such a model also needs to be able to identify when no answer is found in the text, and to achieve this <cite>they</cite> trained a slightly modified version of BiDAF (Seo et al., 2016) (Rajpurkar et al., 2016) , can be applied to the relation extraction task.",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_6",
  "x": "Data We compare two sources of training data: The University of Washington relation extraction (UWRE) dataset created by <cite>Levy et al. (2017)</cite> and the Stanford Question Answering Dataset (SQuAD) created by Rajpurkar et al. (2016) .",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_7",
  "x": "<cite>Levy et al. (2017)</cite> provide a number of train/dev/test splits, to allow <cite>them</cite> to evaluate a variety of modes of generalisation.",
  "y": "background"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_8",
  "x": "Models We employ the same modified BiDAF (Seo et al., 2016) model as <cite>Levy et al. (2017)</cite> , which uses an additional bias term to allow the model to signal when no answer is predicted within the text.",
  "y": "uses similarities"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_9",
  "x": "Evaluation Following the approach of <cite>Levy et al. (2017)</cite> , we report F1 scores on the answers returned by the model.",
  "y": "uses"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_10",
  "x": "4 Using an unmodified QA model for slot filling <cite>Levy et al. (2017)</cite> modify the BiDAF architecture to produce an additional output representing the probability that no answer is present in the text. In this experiment, we investigate whether it is possible to adapt a QA model to the slot filling task without having to understand and modify its internal structure and implementation.",
  "y": "motivation"
 },
 {
  "id": "64d11e9efeaa735f74585d6998bab7_11",
  "x": "Results Table 3 reveals that the unmodified BiDAF model is almost as effective as the <cite>Levy et al. (2017)</cite> model in terms of zero-shot F1 on the original UWRE test set.",
  "y": "differences"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_0",
  "x": "Recent work by <cite>Nerbonne and Wiersma (2006)</cite> has provided a foundation for measuring syntactic differences between corpora.",
  "y": "background"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_1",
  "x": "Heeringa and others have also done related work on phonological distance in Nerbonne and Heeringa (1997) and Gooskens and Heeringa (2004) . A measure of syntactic distance is the obvious next step: <cite>Nerbonne and Wiersma (2006)</cite> provide one such method.",
  "y": "motivation background"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_2",
  "x": "Fortunately, the permutation test used by <cite>Nerbonne and Wiersma (2006)</cite> is already designed to normalize the effects of differing sentence length when combining POS trigrams into a single vector per region.",
  "y": "motivation"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_3",
  "x": "The primary source is the syntactic comparison of <cite>Nerbonne and Wiersma (2006)</cite> , which uses a permutation test, explained in Good (1995) and in particular for linguistic purposes in Kessler (2001) .",
  "y": "similarities uses"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_4",
  "x": "The principal difference between the work of <cite>Nerbonne and Wiersma (2006)</cite> and ours is the use of leaf-ancestor paths.",
  "y": "differences"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_5",
  "x": "The permutation test used by <cite>Nerbonne and Wiersma (2006)</cite> is independent of the type of item whose frequency is measured, treating the items as atomic symbols.",
  "y": "background"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_6",
  "x": "Fortunately, this is not the case; <cite>Nerbonne and Wiersma (2006)</cite> generate N \u2212 2 POS trigrams from each sentence of length N ; we generate N leaf-ancestor paths from each parsed sentence in the corpus.",
  "y": "differences"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_7",
  "x": "However, to find out if the value of R is significant, we must use a permutation test with a Monte Carlo technique described by Good (1995) , following closely the same usage by <cite>Nerbonne and Wiersma (2006)</cite> . The intuition behind the technique is to compare the R of the two corpora with the R of two random subsets of the combined corpora. For comparison to the experiment conducted by <cite>Nerbonne and Wiersma (2006)</cite> , the experiment was also run with POS trigrams.",
  "y": "similarities uses"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_8",
  "x": "The average corpus was smaller than the Norwegian L2 English corpora of <cite>Nerbonne and Wiersma (2006)</cite> , which had two groups, one with 221,000 words and the other with 84,000.",
  "y": "differences"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_9",
  "x": "Our work extends that of <cite>Nerbonne and Wiersma (2006)</cite> in a number of ways.",
  "y": "extends"
 },
 {
  "id": "6597d733f13b06f61cb653f86c4460_10",
  "x": "In fact, even though leaf-ancestor paths should provide finer distinctions than trigrams and thus require more data for detectable significance, the regional corpora presented here were smaller than the Norwegian speakers' corpora in <cite>Nerbonne and Wiersma (2006)</cite> by up to a factor of 10.",
  "y": "differences"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_0",
  "x": "Our submission to the W-NUT Named Entity Recognition in Twitter task closely follows the approach detailed by <cite>Cherry and Guo (2015)</cite> , who use a discriminative, semi-Markov tagger, augmented with multiple word representations.",
  "y": "similarities uses"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_1",
  "x": "Our submission to this competition closely follows <cite>Cherry and Guo (2015)</cite> , who advocate the use of a semi-Markov tagger trained online with standard discriminative tagging features, gazetteer matches, Brown clusters, and word embeddings.",
  "y": "similarities uses"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_2",
  "x": "The same corpus is used by <cite>Cherry and Guo (2015)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_3",
  "x": "We first summarize the approach of <cite>Cherry and Guo (2015)</cite> , which we build upon for our system.",
  "y": "similarities uses"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_4",
  "x": "Note that we do not include part-of-speech tags as features, as they were not found to be useful by <cite>Cherry and Guo (2015)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_5",
  "x": "In recent years, two sources of information have been found to be valuable to boost the performance for NER: distributed representation learned from a large corpus and domain-specific lexicons (Turian et al., 2010;<cite> Cherry and Guo, 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_6",
  "x": "C&G 2015 adds Brown clusters and word embeddings to create a complete re-implementation of <cite>Cherry and Guo (2015)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_7",
  "x": "The hyper-parameters suggested by <cite>Cherry and Guo (2015)</cite> (E=10, C=0.01, P=10) were selected to work well with and without representations.",
  "y": "similarities uses"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_8",
  "x": "Our entry extends the work of <cite>Cherry and Guo (2015)</cite> with updated lexicons, phrase embeddings, and gazetteer-infused phrase embeddings.",
  "y": "extends differences"
 },
 {
  "id": "65f6a6fce98c511473a3ab144a73e4_9",
  "x": "Taken together with improved hyper-parameters, these extensions improve the approach of <cite>Cherry and Guo (2015)</cite> by 2.6 Fmeasure on a completely blind test.",
  "y": "extends differences"
 },
 {
  "id": "65fbdd0397473763bca35376d581be_0",
  "x": "The performance of the state-of-the-art systems has improved significantly<cite> (Horn et al., 2014</cite>; Siddharthan and Angrosh, 2014) .",
  "y": "background"
 },
 {
  "id": "65fbdd0397473763bca35376d581be_1",
  "x": "Following <cite>Horn et al. (2014)</cite> , our system simplifies neither proper nouns, as identified by the Natural Language Toolkit (Bird et al., 2009) , nor words in our stoplist, which are already simple.",
  "y": "uses"
 },
 {
  "id": "65fbdd0397473763bca35376d581be_2",
  "x": "We evaluated the performance of our algorithm on the Mechanical Turk Lexical Simplification Data Set<cite> (Horn et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "65fbdd0397473763bca35376d581be_3",
  "x": "We evaluated the quality of syntactic simplification on the first 300 sentences in the Mechanical Turk Lexical Simplification Data Set<cite> (Horn et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_0",
  "x": "In previous work <cite>(Lucena & Paraboni, 2008)</cite> we presented a frequency-based greedy attribute selection strategy submitted to the TUNA Challenge 2008.",
  "y": "background"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_1",
  "x": "In previous work <cite>(Lucena & Paraboni, 2008)</cite> we presented a frequency-based greedy attribute selection strategy submitted to the TUNA Challenge 2008. Presently we further the issue by taking additional information into accountnamely, the trial condition information available from the TUNA data -and report improved results for string-edit distance as required for the 2009 competition.",
  "y": "extends background"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_2",
  "x": "In<cite> Lucena & Paraboni (2008)</cite> we presented a combined strategy based on attribute frequency and certain aspects of a greedy attribute selection strategy for referring expressions generation.",
  "y": "background"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_3",
  "x": "The above approach performed fairly well (at least considering its simplicity) as reported in<cite> Lucena & Paraboni (2008)</cite> .",
  "y": "background"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_4",
  "x": "The above approach performed fairly well (at least considering its simplicity) as reported in<cite> Lucena & Paraboni (2008)</cite> . However, there is one major source of information available from the TUNA data that was not taken into account in the above strategy: the trial condition represented by the +/-LOC feature. This clear gap in our previous work represents an opportunity for improvement discussed in the next section.",
  "y": "motivation"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_5",
  "x": "The present work is a refined version of the original frequency-based greedy attribute selection strategy submitted to the TUNA Challenge 2008 <cite>(Lucena & Paraboni, 2008)</cite> , now taking also the trial condition (+/-LOC) into account.",
  "y": "extends"
 },
 {
  "id": "6781a5d131e68f7a7ac2fe239cc3d0_6",
  "x": "The most relevant comparison with our previous work is observed in the overall string-edit distance values in Figure 1 : considering that in<cite> Lucena & Paraboni (2008)</cite> we reported 6.12 editdistance for Furniture and 7.38 for People, the overall improvement (driven by the descriptions in the Furniture domain) may be explained by the fact that the current version makes more accurate decisions as to when to use these attributes according to the instructions given to the participants of the TUNA trials (the trial condition +/-LOC. )",
  "y": "differences"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_0",
  "x": "Recently, <cite>Wang et al. (2019)</cite> introduced an embedding alignment approach to enable continual learning for relation extraction models.",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_1",
  "x": "Recently, <cite>Wang et al. (2019)</cite> introduced an embedding alignment approach to enable continual learning for relation extraction models. <cite>They</cite> consider a setting with streaming tasks, where each task consists of a number of distinct relations, and proposed to align the representation of relation instances in the embedding space to enable continual learning of new relations without forgetting knowledge from past relations.",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_2",
  "x": "Recently, <cite>Wang et al. (2019)</cite> introduced an embedding alignment approach to enable continual learning for relation extraction models. While <cite>they</cite> obtained promising results, a key weakness of the approach is that the use of an alignment model introduces additional parameters to already overparameterized relation extraction models, which may in turn lead to an increase in the quantity of supervision required for training.",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_3",
  "x": "In this work, we extend the work of <cite>Wang et al. (2019)</cite> by exploiting ideas from both lifelong learning and meta-learning.",
  "y": "extends"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_4",
  "x": "Unlike the use of a separate alignment model as proposed in <cite>Wang et al. (2019)</cite> , the proposed approach does not introduce additional parameters.",
  "y": "extends"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_5",
  "x": "In order to use the same number of parameters and ensure fair comparison to <cite>Wang et al. (2019)</cite> , we adopt as the relation extraction model f \u03b8 the Hier- arachical Residual BiLSTM (HR-BiLSTM) model of Yu et al. (2017) , which is the same model used by <cite>Wang et al. (2019)</cite> for their experiments.",
  "y": "uses"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_6",
  "x": "Hyperparameters Apart from the hyperparameters specific to meta-learning (such as the step size ), all other hyperparameters we use for the learner model are the same as used by <cite>Wang et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_7",
  "x": "We conduct experiments on <cite>Lifelong FewRel</cite> and Lifelong <cite>SimpleQuestions</cite> datasets, both introduced in <cite>Wang et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_8",
  "x": "We conduct experiments on <cite>Lifelong FewRel</cite> and Lifelong <cite>SimpleQuestions</cite> datasets, both introduced in <cite>Wang et al. (2019)</cite> . <cite>Lifelong FewRel</cite> is derived from the FewRel (Han et al., 2018) dataset, by partitioning its 80 relations into 10 distinct clusters made up of 8 relations each, with each cluster serving as a task where a sentence must be labeled with the correct relation.",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_10",
  "x": "We report two measures, <cite>ACC whole</cite> and <cite>ACC avg</cite> , both introduced in <cite>Wang et al. (2019)</cite> .",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_11",
  "x": "We report two measures, <cite>ACC whole</cite> and <cite>ACC avg</cite> , both introduced in <cite>Wang et al. (2019)</cite> . <cite>ACC whole</cite> measures accuracy on the test set of all tasks and gives a balanced measure of model performance on both observed (seen) and unobserved (unseen) tasks, and is the primary metric we report for all experiments.",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_12",
  "x": "We report two measures, <cite>ACC whole</cite> and <cite>ACC avg</cite> , both introduced in <cite>Wang et al. (2019)</cite> . We also report <cite>ACC avg</cite> , which measures the average accuracy on the test set of only observed (seen) tasks.",
  "y": "background"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_13",
  "x": "Full Supervision Results Table 1 gives both the <cite>ACC whole</cite> and <cite>ACC avg</cite> results of our approach compared to other approaches including Episodic Memory Replay (EMR) and its various embedding-aligned variants EA-EMR as proposed in <cite>Wang et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_14",
  "x": "The aim of our limited supervision experiments is to compare the use of an alignment module as proposed by <cite>Wang et al. (2019)</cite> to using our approach when only limited supervision is available for all tasks.",
  "y": "uses"
 },
 {
  "id": "681c3e59adbfc09a28d267a4885598_15",
  "x": "We conduct experiments on <cite>Lifelong FewRel</cite> and Lifelong <cite>SimpleQuestions</cite> datasets, both introduced in <cite>Wang et al. (2019)</cite> . Figures 1(a) and 1(b) show results obtained using 100 supervision instances for each task on <cite>Lifelong FewRel</cite> and <cite>Lifelong SimpleQuestions</cite>.",
  "y": "uses"
 },
 {
  "id": "684349c06be7ff51c0944b25be10ce_0",
  "x": "Characters form the core of many computational analyses, from inferring prototypical character types (Bamman et al., 2014) to identifying the structure of social networks in literature <cite>(Elson et al., 2010</cite>; Lee and Yeung, 2012; Agarwal et al., 2013; Ardanuy and Sporleder, 2014; Jayannavar et al., 2015) .",
  "y": "background"
 },
 {
  "id": "684349c06be7ff51c0944b25be10ce_1",
  "x": "Third, as practical applications, we analyze literary trends in character density over 20 decades and revisit the character-based literary hypothesis tested by<cite> Elson et al. (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "684349c06be7ff51c0944b25be10ce_2",
  "x": "Two approaches mined social interaction net-works without relying on dialogue, unlike the methods of<cite> Elson et al. (2010)</cite> and He et al. (2013) .",
  "y": "background"
 },
 {
  "id": "684349c06be7ff51c0944b25be10ce_3",
  "x": "Therefore, three state-of-the-art systems for social network extraction were selected: the method described in<cite> Elson et al. (2010)</cite> , BookNLP (Bamman et al., 2014) , and the method described in Ardanuy and Sporleder (2014) .",
  "y": "uses"
 },
 {
  "id": "684349c06be7ff51c0944b25be10ce_4",
  "x": "(For comparison, BookNLP, the next best system, extracted 69 and 72 characters for Pride and Prejudice and The Moonstone, respectively, and within 1.2, on average, on the Sherlock Holmes set.) Experiment 2: Literary Theories<cite> Elson et al. (2010)</cite> analyze 60 novels to computationally test literary theories for novels in urban and rural settings (Williams, 1975; Moretti, 1999) .",
  "y": "uses"
 },
 {
  "id": "684349c06be7ff51c0944b25be10ce_5",
  "x": "Character detection was run on the same novels from<cite> Elson et al. (2010)</cite> and we found no statistically-significant difference in the mean number of characters in urban and rural settings, even when accounting for text size.",
  "y": "uses"
 },
 {
  "id": "685b0b0da37b81765bb78f0f87505b_0",
  "x": "Neural sequence-to-sequence models have led to substantial improvements on this task of abstractive summarization, via machine translation inspired encoder-aligner-decoder approaches, further enhanced via convolutional encoders, pointer-copy mechanisms, and hierarchical attention (Rush et al., 2015;<cite> Nallapati et al., 2016</cite>; See et al., 2017) .",
  "y": "background"
 },
 {
  "id": "685b0b0da37b81765bb78f0f87505b_1",
  "x": "Neural sequence-to-sequence models have led to substantial improvements on this task of abstractive summarization, via machine translation inspired encoder-aligner-decoder approaches, further enhanced via convolutional encoders, pointer-copy mechanisms, and hierarchical attention (Rush et al., 2015;<cite> Nallapati et al., 2016</cite>; See et al., 2017) . Despite these promising recent improvements, Input Document: may is a pivotal month for moving and storage companies . Ground-truth Summary: moving companies hit bumps in economic road Baseline Summary: a month to move storage companies Multi-task Summary: pivotal month for storage firms there is still scope in better teaching summarization models about the general natural language inference skill of logical entailment generation.",
  "y": "motivation"
 },
 {
  "id": "685b0b0da37b81765bb78f0f87505b_2",
  "x": "Several advances have been made in this direction using machine translation inspired encoder-aligner-decoder models, convolution-based encoders, switching pointer and copy mechanisms, and hierarchical attention models (Rush et al., 2015;<cite> Nallapati et al., 2016</cite>; See et al., 2017) .",
  "y": "background"
 },
 {
  "id": "685b0b0da37b81765bb78f0f87505b_3",
  "x": "Following previous work<cite> (Nallapati et al., 2016</cite>; Chopra et al., 2016; Rush et al., 2015) , we use the full-length F1 variant of Rouge (Lin, 2004) for the Gigaword results, and the 75-bytes length limited Recall variant of Rouge for DUC.",
  "y": "uses"
 },
 {
  "id": "685b0b0da37b81765bb78f0f87505b_5",
  "x": "In Table 2 , we again see that et al. (2015) 28.18 8.49 23.81 Chopra et al. (2016) 28.97 8.26 24.06<cite> Nallapati et al. (2016)</cite> our Luong et al. (2015) baseline model achieves competitive performance with previous work, esp. on Rouge-2 and Rouge-L. Next, we show promising multi-task improvements over this baseline of around 0.4% across all metrics, despite being a test-only setting and also with the mismatch between the summarization and entailment domains.",
  "y": "differences"
 },
 {
  "id": "685b0b0da37b81765bb78f0f87505b_6",
  "x": "Our next steps to this workshop paper include: (1) stronger summarization baselines, e.g., using pointer copy mechanism (See et al., 2017;<cite> Nallapati et al., 2016)</cite> , and also adding this capability to the entailment generation model; (2) results on CNN/Daily Mail corpora<cite> (Nallapati et al., 2016)</cite> ; (3) incorporating entailment knowledge from other news-style domains such as the new Multi-NLI corpus (Williams et al., 2017) , and (4) demonstrating mutual improvements on the entailment generation task.",
  "y": "future_work"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_0",
  "x": "Our approach to the annotation projection builds upon the approach recently introduced by <cite>(Grishina and Stede, 2017)</cite> , who experimented with projecting manually annotated coreference chains from two source languages to the target language.",
  "y": "similarities uses"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_1",
  "x": "Therefore, in contrast to <cite>(Grishina and Stede, 2017)</cite> , we use automatic source annotations produced by two state-of-the-art coreference systems, and we combine the output of our projection method for two source languages (English and German) to obtain target annotations for a third language (Russian).",
  "y": "extends differences"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_2",
  "x": "Thereafter, <cite>(Grishina and Stede, 2017)</cite> proposed a multi-source method for annotation projection: They used a manually annotated trilingual coreference corpus and two source languages (English-German, English-Russian) to transfer annotations to the target language (Russian and German, respectively).",
  "y": "background"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_3",
  "x": "We use the English-German-Russian unannotated corpus of <cite>(Grishina and Stede, 2017)</cite> as the basis for our experiment, which contains texts in two genres -newswire texts (229 sentences per language) and short stories (184 sentences per language).",
  "y": "similarities uses"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_4",
  "x": "Thereafter, we re-implement the multi-source approach as described in <cite>(Grishina and Stede, 2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_5",
  "x": "In our experiment, we apply the following strategies from <cite>(Grishina and Stede, 2017)</cite>:",
  "y": "uses similarities"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_6",
  "x": "As for the multi-source settings, we were able to achieve the highest F1 of 36.2 by combining disjoint chains (Setting 1), which is 1.9 point higher than the best single-source projection scores and constitutes almost 62% of the quality of the projection of gold standard annotations reported in <cite>(Grishina and Stede, 2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_7",
  "x": "Following the work of <cite>(Grishina and Stede, 2017)</cite> , we analyse the projection accuracy for common nouns ('Nc'), named entities ('Np') and pronouns ('P') separately 4 : Table 5 shows the percentage of correctly projected markables of each type out of all the projected markables of this type.",
  "y": "similarities uses"
 },
 {
  "id": "6891aebc7bb1152884d2236a893b55_8",
  "x": "Our results conform to the results of <cite>(Grishina and Stede, 2017)</cite> : For both languages, pronouns exhibit the highest projection quality, while common and proper nouns are projected slightly less accurately, which is probably due to the fact that pronouns typically consist of single tokens and are better aligned than multi-token common and proper names.",
  "y": "differences"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_0",
  "x": "Deep learning's recent success in speech recognition is based on learning feature hierarchies atop these representations [1,<cite> 2]</cite> .",
  "y": "background"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_1",
  "x": "The experimental design of this study is modelled after our previous work on end-to-end speech recognition [12,<cite> 2]</cite> .",
  "y": "uses"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_2",
  "x": "Batch normalization [13] , is employed between each layer, but not between individual timesteps <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_3",
  "x": "The training data is drawn from a diverse collection of sources including read, conversational, accented, and noisy speech <cite>[2]</cite> .",
  "y": "uses"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_4",
  "x": "Following <cite>[2]</cite> , we sort the first epoch by utterance length (SortaGrad), to promote stability of training on long utterances.",
  "y": "uses"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_5",
  "x": "As previously observed <cite>[2]</cite> , deep neural networks trained on sufficient data perform better as the model size grows.",
  "y": "uses similarities"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_6",
  "x": "As previously observed <cite>[2]</cite> , deep neural networks trained on sufficient data perform better as the model size grows. In order to make fair comparisons, the number of parameters of the models used in our experiments is held constant at 35M.",
  "y": "uses"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_7",
  "x": "While learned features outperformed spectrograms feeding into temporal convolution in this study, many state of the art systems apply two-dimensional convolutions to their inputs<cite> [2,</cite> 16] .",
  "y": "similarities"
 },
 {
  "id": "68d41bee7361b6680103c9951a6570_8",
  "x": "While learned features outperformed spectrograms feeding into temporal convolution in this study, many state of the art systems apply two-dimensional convolutions to their inputs<cite> [2,</cite> 16] . Our learned features underperform in this context, which is understandable as they are not spectrally ordered, and lack spatial structure.",
  "y": "differences"
 },
 {
  "id": "692f7edc151a9a833c7dd7943bb608_0",
  "x": "Several research work have been reported since 2010 in this research field of hate speech detection (Kwok and Wang, 2013; Burnap and Williams, 2015; Djuric et al., 2015; <cite>Davidson et al., 2017</cite>; Malmasi and Zampieri, 2018; Schmidt and Wiegand, 2017; Fortuna and Nunes, 2018; ElSherief et al., 2018; Gamb\u00e4ck and Sikdar, 2017; Zhang et al., 2018; Mathur et al., 2018) .",
  "y": "background"
 },
 {
  "id": "692f7edc151a9a833c7dd7943bb608_1",
  "x": "The performance may be improved further by incorporating external datasets (Kumar et al., 2018a;<cite> Davidson et al., 2017)</cite>",
  "y": "future_work"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_0",
  "x": "Previous work has used Bayesian HMMs to learn taggers for both POS tagging and supertagging<cite> (Baldridge, 2008)</cite> separately.",
  "y": "background"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_1",
  "x": "In this experiment, we use the training and test sets used by <cite>Baldridge (2008)</cite> from CCGbank.",
  "y": "uses similarities"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_2",
  "x": "The accuracy of our HMM is lower than the performance of <cite>Baldridge (2008)</cite> for supertags.",
  "y": "differences"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_3",
  "x": "We draw the initial sample of CCG tag sequences corresponding to the observation sequence, using probabilities based on grammar informed initialization<cite> (Baldridge, 2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_4",
  "x": "The performance of the HMM model (31%) in Table 5 (a) without any frequency cut-off on the CCG categories, is comparable to the bitag HMM of <cite>Baldridge (2008)</cite> that uses variational Bayes EM (33%).",
  "y": "similarities"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_5",
  "x": "Our complexity based initialization is not directly comparable to the results in <cite>Baldridge (2008)</cite> because the values there are based on a weighted combination of complexity based initialization and modified transition priors based on the CCG formalism.",
  "y": "differences"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_6",
  "x": "However, it is encouraging to see that when there is no cut-off based filtering of the categories, FHMMB (47.98%) greatly outperforms the HMM-EM model of <cite>Baldridge (2008)</cite> .",
  "y": "differences"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_7",
  "x": "It is however, quite short of the 56.1% accuracy achieved by the model of <cite>Baldridge (2008)</cite> that uses grammar informed initialization (combination of category based initialization along with category transition rules).",
  "y": "background"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_8",
  "x": "We expect that CCG transition rules<cite> (Baldridge, 2008)</cite> when encoded as category specific transition priors, will lead to better performance with the FHMMs.",
  "y": "future_work"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_9",
  "x": "This paper follows the work of Duh (2005) , <cite>Baldridge (2008)</cite> and Goldwater and Griffiths (2007) .",
  "y": "extends"
 },
 {
  "id": "6a90ecc147618b3909609fc6c2e2b3_10",
  "x": "Despite this, the FHMMs are suited for estimating models with less supervision, such as from tag dictionaries alone and incorporating more informative prior distributions such as those in <cite>Baldridge (2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_0",
  "x": "The most prominent approaches include: (1) temporal ordering in terms of publication date (Barzilay, 2003) , (2) temporal ordering in terms of textual cues in sentences (Bollegala et al., 2006) , (3) the topic of the sentences (Barzilay, 2003) , (4) coherence theories (<cite>Barzilay and Lapata, 2008</cite>) , e.g., Centering Theory, (5) content models (Barzilay and Lee, 2004) , and (6) ordering(s) in the underlying documents in the case of summarisation (Bollegala et al., 2006; Barzilay, 2003) .",
  "y": "background"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_1",
  "x": "Hence, paralleling <cite>Barzilay and Lapata (2008)</cite> , our model has the following structure.",
  "y": "similarities"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_2",
  "x": "Yet, in contrast to <cite>Barzilay and Lapata (2008)</cite> , <cite>who</cite> employ the syntactic properties of the respective occurrences, we reduce the accounts to whether or not the entities occur in subsequent sentences (similar to Karamanis (2004) 's NOCB metric).",
  "y": "differences"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_3",
  "x": "However, the coherence of a text is clearly not only defined by direct relations, but also requires longer range relations between sentences (e.g., <cite>Barzilay and Lapata (2008)</cite> ).",
  "y": "motivation"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_4",
  "x": "The first two are the earthquake and accident datasets used by <cite>Barzilay and Lapata (2008)</cite> .",
  "y": "uses"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_5",
  "x": "The source furthermore differs from <cite>Barzilay and Lapata (2008)</cite> 's datasets in that the content of each text is not based on one individual event (an earthquake or accident), but on more complex topics followed over a period of time (e.g., the espionage case between GM and VW along with the various actions taken to resolve it).",
  "y": "differences"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_6",
  "x": "(<cite>Barzilay and Lapata (2008)</cite> only perform well when using <cite>their</cite> coreference module, which determines antecedents based on the identified coreferences in the original sentence ordering, thereby biasing <cite>their</cite> orderings towards the correct ordering.) Longer range and WordNet relations together (Chunk+Temp-WN+LongRange+) achieve the best performance.",
  "y": "differences"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_7",
  "x": "The results for Coreference+Syntax+Salience+ and HMM-Based Content Models are reproduced from <cite>Barzilay and Lapata (2008)</cite>.",
  "y": "similarities"
 },
 {
  "id": "6b147afca676882878e67bc10abd58_8",
  "x": "When compared to the results obtained by <cite>Barzilay and Lapata (2008)</cite> and Barzilay and Lee (2004) , it would appear that direct sentenceto-sentence similarity (as suggested by the <cite>Barzilay and Lapata</cite> baseline score) or capturing topic sequences are essential for acquiring the correct sequence of sentences in the earthquake dataset.",
  "y": "similarities"
 },
 {
  "id": "6bf17a793eaee0593596df0c2249b5_0",
  "x": "Multi-hop QA requires finding multiple supporting evidence, and reasoning over them in order to answer a question (Welbl et al., 2018; Talmor and Berant, 2018; <cite>Yang et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "6bf17a793eaee0593596df0c2249b5_1",
  "x": "To summarize, this paper presents an entitycentric IR approach that jointly performs entity linking and effectively finds relevant evidence required for questions that need multi-hop reasoning from a large corpus containing millions of paragraphs. When the retrieved paragraphs are supplied to the baseline QA model introduced in<cite> Yang et al. (2018)</cite> , it improved the QA performance on the hidden test set by 10.59 F1 points.",
  "y": "uses"
 },
 {
  "id": "6bf17a793eaee0593596df0c2249b5_2",
  "x": "For all our experiment, unless specified otherwise, we use the open domain corpus 4 released by<cite> Yang et al. (2018)</cite> which contains over 5.23 million Wikipedia abstracts (introductory paragraphs).",
  "y": "uses"
 },
 {
  "id": "6bf17a793eaee0593596df0c2249b5_4",
  "x": "Baseline Reader<cite> (Yang et al., 2018)</cite> Table 2 shows the performance on the QA task.",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_0",
  "x": "One way to remedy this fundamental problem is to refine model output iteratively (Lee et al., 2018;<cite> Ghazvininejad et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_1",
  "x": "Parallel decoding results in conditional independence and prevents the model from properly capturing highly multimodal distribution of target translations (Gu et al., 2018) . One way to remedy this fundamental problem is to refine model output iteratively (Lee et al., 2018;<cite> Ghazvininejad et al., 2019)</cite> .",
  "y": "background motivation"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_2",
  "x": "Unlike the masked language models (Devlin et al., 2019;<cite> Ghazvininejad et al., 2019)</cite> where the model only predicts the masked words, the DisCo transformer can predict all words simultaneously, leading to faster inference as well as a substantial performance gain when training data are relatively large.",
  "y": "differences background"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_3",
  "x": "Specifically, our DisCo transformer predicts every word in a sentence conditioned on an arbitrary subset of the rest of the words. Unlike the masked language models (Devlin et al., 2019;<cite> Ghazvininejad et al., 2019)</cite> where the model only predicts the masked words, the DisCo transformer can predict all words simultaneously, leading to faster inference as well as a substantial performance gain when training data are relatively large.",
  "y": "differences"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_4",
  "x": "We also introduce a new inference algorithm for iterative parallel decoding, parallel easy-first, where each word is predicted by attending to the words that the model is more confident about. This decoding algorithm allows for predicting all tokens with different context in each iteration and terminates when the output prediction converges, contrasting with the constant number of iterations<cite> (Ghazvininejad et al., 2019)</cite> .",
  "y": "differences"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_5",
  "x": "This decoding algorithm allows for predicting all tokens with different context in each iteration and terminates when the output prediction converges, contrasting with the constant number of iterations<cite> (Ghazvininejad et al., 2019)</cite> .",
  "y": "background differences"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_6",
  "x": "Similar to masked language models for contextual word representations (Devlin et al., 2019; Liu et al., 2019 ), a con- ditional masked language model (CMLM, <cite>Ghazvininejad et al. (2019)</cite> ) predicts randomly masked target tokens Y mask given a source text X and the rest of the target tokens Y obs .",
  "y": "background"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_7",
  "x": "2 CMLMs have proven successful in parallel decoding for machine translation<cite> (Ghazvininejad et al., 2019)</cite> , video captioning (Yang et al., 2019a) , and speech recognition (Nakayama et al., 2019) .",
  "y": "background"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_8",
  "x": "We introduce the 2 BERT (Devlin et al., 2019 ) masks a token with probability 0.15 while CMLMs<cite> (Ghazvininejad et al., 2019)</cite> sample the number of masked tokens uniformly from [1, N ].",
  "y": "differences"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_9",
  "x": "For each Y n in Y where |Y | = N , we uniformly sample the number of visible tokens from [0, N \u2212 1], and then we randomly choose that number of tokens from Y \\ Y n as Y n obs , similarly to CMLMs<cite> (Ghazvininejad et al., 2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_10",
  "x": "Mask-predict is an iterative inference algorithm introduced in <cite>Ghazvininejad et al. (2019)</cite> to decode a conditional masked language model (CMLM).",
  "y": "background"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_11",
  "x": "Following <cite>Ghazvininejad et al. (2019)</cite> , we apply length beam.",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_12",
  "x": "Notice that all for-loops are parallelizable except the one over iterations t. In the subsequent experiments, we use length beam size of 5<cite> (Ghazvininejad et al., 2019)</cite> unless otherwise noted.",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_13",
  "x": "We evaluate performance with BLEU scores (Papineni et al., 2002) for all directions except that we use SacreBLEU (Post, 2018) 5 in en\u2192zh again for fair comparison with prior work<cite> (Ghazvininejad et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_14",
  "x": "CMLM As discussed earlier, we can generate a translation with mask-predict from a CMLM<cite> (Ghazvininejad et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_15",
  "x": "Hyperparameters We generally follow the hyperparameters for a transformer base (Vaswani et al., 2017;<cite> Ghazvininejad et al., 2019)</cite> : 6 layers for both the encoder and decoder, 8 attention heads, 512 model dimensions, and 2048 hidden dimensions.",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_16",
  "x": "Seen in Table 1 are the results in the four directions from the WMT'14 EN-DE and WMT'16 EN-RO datasets. First, our re-implementations of CMLM + Mask-Predict outperform <cite>Ghazvininejad et al. (2019)</cite> (e.g. 31.24 vs. 30.53 in de\u2192en with 10 steps).",
  "y": "uses"
 },
 {
  "id": "6d5a52c29e4f91bc17502e250c9187_17",
  "x": "As in this work, several prior work proposed methods to iteratively refine output predictions (Lee et al., 2018;<cite> Ghazvininejad et al., 2019</cite>; Gu et al., 2019; Mansimov et al., 2019) .",
  "y": "similarities"
 },
 {
  "id": "6e5ee9176bcc54c3c9c32965765990_0",
  "x": "The models were trained with multi-domain data and we improved performance following a domainmixing approach <cite>(Britz et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "6e5ee9176bcc54c3c9c32965765990_1",
  "x": "The models were trained with multi-domain data and we improved performance following a domainmixing approach <cite>(Britz et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_0",
  "x": "A breakthrough has come in the form of research by McClosky et al. (2006a;<cite> 2006b</cite> ) who show that self-training can be used to improve parser performance when combined with a two-stage reranking parser model (Charniak and Johnson, 2005) .",
  "y": "background"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_2",
  "x": "McClosky et al. (2006a;<cite> 2006b</cite> ) proceed as follows: sentences * Now affiliated to Lalic, Universit\u00e9 Paris 4 La Sorbonne. from the LA Times newspaper are parsed by a firststage generative statistical parser trained on some seed training data (WSJ Sections 2-21) and the nbest parse trees produced by this parser are reranked by a discriminative reranker.",
  "y": "background"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_3",
  "x": "In the experiments of McClosky et al. (2006a;<cite> 2006b)</cite> , the parse trees used for self-training come from the same domain (American newspaper text) as the parser's original seed training material.",
  "y": "background"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_4",
  "x": "However, McCloskey et al. (<cite>2006b)</cite> report a drop in performance for their reranking parser when the experiment is repeated in the opposite direction, i.e. with Brown data for self-training and testing, and WSJ data for seed training.",
  "y": "background"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_5",
  "x": "In contrast, we report successful in-domain 1 self-training experiments with the BNC data as self-training and test material, and with the WSJ-trained reranking parser used by McCloskey et al. (2006a;<cite> 2006b)</cite> .",
  "y": "uses"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_6",
  "x": "However, McCloskey et al. (<cite>2006b)</cite> report a drop in performance for their reranking parser when the experiment is repeated in the opposite direction, i.e. with Brown data for self-training and testing, and WSJ data for seed training. In contrast, we report successful in-domain 1 self-training experiments with the BNC data as self-training and test material, and with the WSJ-trained reranking parser used by McCloskey et al. (2006a;<cite> 2006b)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "6f3d6ad1f09c55a1a006abbeddb4ab_7",
  "x": "The f-score of 83.7% is lower than the f-score of 85.2% reported by<cite> McClosky et al. (2006b)</cite> for the same parser on Brown corpus data.",
  "y": "differences"
 },
 {
  "id": "6fbfc9f887e736472510bce30c9228_0",
  "x": "In previous work, we collected a small corpus of task-oriented dialogues between customers and support representatives from the MSN Shopping online support service <cite>(Ivanovic, 2005b)</cite> .",
  "y": "uses background"
 },
 {
  "id": "6fbfc9f887e736472510bce30c9228_1",
  "x": "In <cite>Ivanovic (2005b)</cite> , the MSN Shopping corpus was collected and a gold standard produced by labelling the utterances with dialogue acts.",
  "y": "background"
 },
 {
  "id": "6fbfc9f887e736472510bce30c9228_2",
  "x": "Our dialogue act tag set contains 12 dialogue acts, which are intended to represent the illocutionary force of an utterance. The tags were derived in <cite>Ivanovic (2005b)</cite> by manually labelling the MSN Shopping corpus using the tags that seemed appropriate from a list of 42 tags in Stolcke et al. (2000) .",
  "y": "uses"
 },
 {
  "id": "6fbfc9f887e736472510bce30c9228_3",
  "x": "<cite>Ivanovic (2005b)</cite> describes the manual process of segmenting the messages into utterances and labelling the utterances with dialogue act tags to produce a gold standard version of the data.",
  "y": "background"
 },
 {
  "id": "6fd0c2fbbe0c7fb669f2618f4d01f7_0",
  "x": "About 74% of Wikipedia articles fall under the category of named entity classes <cite>[4]</cite> , therefore, we consider Wikipedia links among articles to construct the Hi-En-WP NER annotated corpus.",
  "y": "uses background"
 },
 {
  "id": "6fd0c2fbbe0c7fb669f2618f4d01f7_1",
  "x": "Wikipedia is an abundant resource for generation of different types of multilingual, cross lingual, cross script and language independent corpus, etc., its markup has been used extensively to automatically generate NER annotated corpus for training machine learning models <cite>[4]</cite> [5] [6] [11] [12] [13] [14] 19] .",
  "y": "background"
 },
 {
  "id": "6fd0c2fbbe0c7fb669f2618f4d01f7_2",
  "x": "This approach is similar to Nothman et al (2008) <cite>[4]</cite> to generate the NER data from wikilinks.",
  "y": "similarities"
 },
 {
  "id": "6fd0c2fbbe0c7fb669f2618f4d01f7_3",
  "x": "The MISC F-score is expectedly low, in agreement with the results of Nothman et al (2008) <cite>[4]</cite> .",
  "y": "similarities"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_0",
  "x": "They have been used for both rule-based (Taboada et al., 2011) and unsupervised (Turney, 2002; Hu and Liu, 2004; or supervised<cite> (Mohammad et al., 2013</cite>; Tang et al., 2014b; Vo and Zhang, 2015) machine-learning-based sentiment analysis.",
  "y": "background"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_1",
  "x": "Recently, statistical methods have been exploited to learn sentiment lexicons automatically (Esuli and Sebastiani, 2006; Baccianella et al., 2010;<cite> Mohammad et al., 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_2",
  "x": "Among the automatic methods,<cite> Mohammad et al. (2013)</cite> proposed to use tweets with emoticons or hashtags as training data.",
  "y": "background"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_3",
  "x": [
   "Mohammad et al. (2013) collect sentiment lexicons by calculating pointwise mutual information (PMI) between words and emoticons."
  ],
  "y": "background"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_4",
  "x": "The correlation between our method and the method of<cite> Mohammad et al. (2013)</cite> is analogous to the \"predicting\" vs \"counting\" correlation between distributional and distributed word representations (Baroni et al., 2014) .",
  "y": "differences"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_5",
  "x": "The method can leverage the same data as<cite> Mohammad et al. (2013)</cite> and therefore benefits from both scale and annotation independence.",
  "y": "uses"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_6",
  "x": "We use the same data source as<cite> Mohammad et al. (2013)</cite> to train lexicons.",
  "y": "uses"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_7",
  "x": "We compare our lexicon with the lexicons of NRC 4<cite> (Mohammad et al., 2013)</cite> , HIT 5 (Tang et al., 2014a) and WEKA 6 (Bravo-Marquez et al., 2015) .",
  "y": "uses"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_8",
  "x": "Table 6 shows examples of our predicting-based lexicon and the counting-based lexicon of<cite> Mohammad et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_9",
  "x": "Second, we find many cases where our lexicon gives the correct polarity (e.g. suitable, lazy) but the lexicon of<cite> Mohammad et al. (2013)</cite> does not.",
  "y": "differences"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_10",
  "x": "Table 6 shows examples of our predicting-based lexicon and the counting-based lexicon of<cite> Mohammad et al. (2013)</cite> . First, both lexicons can correctly reflect the strength of emotional words (e.g. bad, worse, worst), which demonstrates that our method can learn statistical relevance as effectively as PMI. Second, we find many cases where our lexicon gives the correct polarity (e.g. suitable, lazy) but the lexicon of<cite> Mohammad et al. (2013)</cite> does not.",
  "y": "differences"
 },
 {
  "id": "710ec6f6d6d4c7c8c148833c0adfef_11",
  "x": "The polarity accuracy of our lexicon is 78.2%, in contrast to 76.9% by the lexicon of<cite> Mohammad et al. (2013)</cite> , demonstrating the relative strength of our method.",
  "y": "differences"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_0",
  "x": "To improve the precision of retrieval output, especially within the very few (e.g, 5 or 10) highest-ranked documents that are returned, a number of researchers [36, 13, 16, 7, 22, 34, 25, 1, <cite>18,</cite> 9] have considered a structural re-ranking strategy.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_1",
  "x": "In particular, in our prior work<cite> [18]</cite> we adapted PageRank [3] -which, due to the success of Google, is surely the most well-established algorithm for defining and computing centrality within a directed graph -to the task of re-ranking non-hyperlinked document sets.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_2",
  "x": "Our previous study<cite> [18]</cite> applied HITS to non-Web documents.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_3",
  "x": "We found that its performance was comparable to or better than that of algorithms that do not involve structural re-ranking; however, HITS was not as effective as PageRank<cite> [18]</cite> .",
  "y": "motivation background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_4",
  "x": "Specifically, our experimental results show that the centralityinduction methods that we previously studied solely in the context of document-only graphs<cite> [18]</cite> result in much better re-ranking performance if implemented over bipartite graphs of documents (on one side) and clusters (on the other side).",
  "y": "extends"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_5",
  "x": "This is a natural comparison because PageRank is the most well-known centrality-induction algorithm utilized for ranking documents, and because in earlier work<cite> [18]</cite> , PageRank performed quite well as a tool for structural re-ranking of non-Web documents, at least when applied to document-to-document graphs.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_6",
  "x": "We will compare the results of using the HITS algorithm against those derived using PageRank instead. This is a natural comparison because PageRank is the most well-known centrality-induction algorithm utilized for ranking documents, and because in earlier work<cite> [18]</cite> , PageRank performed quite well as a tool for structural re-ranking of non-Web documents, at least when applied to document-to-document graphs.",
  "y": "uses background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_7",
  "x": "Earlier work<cite> [18]</cite> also considered scoring a node v by its influx, P u\u2208V w t(u \u2192 v).",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_8",
  "x": "Examples include document (re-)ranking [7, 24, 9, <cite>18,</cite> 39 ], text summarization [11, 26] , sentence retrieval [28] , and document representation [10] .",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_9",
  "x": "Most aspects of the evaluation framework described below are adopted from our previous experiments with noncluster-based structural re-ranking<cite> [18]</cite> so as to facilitate direct comparison.",
  "y": "uses"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_10",
  "x": "Section 4.1 of<cite> [18]</cite> provides a more detailed justification of the experimental design.",
  "y": "uses background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_11",
  "x": "The main conceptual changes 6 here are: a slightly larger parameter search-space for the \"out-degree\" parameter \u03b4 (called the \"ancestry\" parameter \u03b1 in<cite> [18]</cite> ); and, of course, the incorporation of clusters.",
  "y": "differences"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_12",
  "x": "To estimate the degree to which one item, if considered relevant, can vouch for the relevance of another, we follow our previous work on document-based graphs<cite> [18]</cite> and utilize p [\u00b5] d (\u00b7), the unigram Dirichlet-smoothed language model induced from a given document d (\u00b5 is the smoothing parameter) [38] .",
  "y": "uses"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_13",
  "x": "The asymmetry of this measure corresponds nicely to the intuition that relevance flow is not symmetric<cite> [18]</cite> .",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_14",
  "x": "Moreover, this function 6 Some of the PageRank results appearing in our previous paper<cite> [18]</cite> accidentally reflect experiments utilizing a suboptimal choice of Dinit.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_15",
  "x": "is somewhat insensitive to large length differences between the items in question<cite> [18]</cite> , which is advantageous when both documents and clusters (which we treat as very long documents) are considered.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_16",
  "x": "Previous work<cite> [18,</cite> 33] makes heavy use of the idea of nearest neighbors in language-model space.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_17",
  "x": "Note that the neighborhood of x corresponds to what we previously termed the \"top generators\" of x<cite> [18]</cite> .",
  "y": "background similarities"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_18",
  "x": "There are two motivations underlying our approach to choosing values for our algorithms' parameters<cite> [18]</cite> .",
  "y": "motivation"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_19",
  "x": "We first consider our main question: can we substantially boost the effectiveness of HITS by applying it to cluster-to-document graphs, which we have argued are more suitable for it than the document-to-document graphs we constructed in our previous work<cite> [18]</cite> ?",
  "y": "motivation"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_20",
  "x": "We now turn to Figure 2 , which gives the results for the re-ranking algorithms docInflux, doc-PageRank and doc-Auth as applied to either the document-based graph d\u2194d (as in<cite> [18]</cite> ) or the clusterdocument graph c\u2192d.",
  "y": "uses"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_21",
  "x": "As the notation suggests, this corresponds to running HITS and PageRank on the same graph, d\u2194d. But an alternative interpretation<cite> [18]</cite> is that non-smoothed (or no-random-jump) PageRank, as expressed by Equation (3), is applied to a different version of d\u2194d wherein the original edge weights w t(u \u2192 v) have been smoothed as follows:",
  "y": "differences"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_22",
  "x": "In previous work, we showed that PageRank centrality scores induced over documentbased graphs can be used as a multiplicative weight on document query-likelihood terms, the intent being to cope with cases in which centrality in Dinit and relevance are not strongly correlated<cite> [18]</cite> .",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_23",
  "x": "While PageRank scores correspond to a stationary distribution that could be loosely interpreted as a prior<cite> [18]</cite> , in which case multiplicative combination with query likelihood is sensible, it is not usual to assign a probabilistic interpretation to hub or authority scores.",
  "y": "background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_24",
  "x": "While PageRank scores correspond to a stationary distribution that could be loosely interpreted as a prior<cite> [18]</cite> , in which case multiplicative combination with query likelihood is sensible, it is not usual to assign a probabilistic interpretation to hub or authority scores. Nonetheless, for the sake of comparison completeness, we applied this idea to the doc-Auth[c\u2192d] algorithm, yielding the following performance changes: from .541, .544, and .564 to .537, .572 and .572 respectively.",
  "y": "uses background"
 },
 {
  "id": "72323bc821355923b8c4444ee37ef9_25",
  "x": "Thus, it may be the case that centrality scores induced over a document-based graph are more effective as a multiplicative bias on query-likelihood than as direct representations of relevance in Dinit (see also<cite> [18]</cite> ); but, modulo the caveat above, it seems that when centrality is induced over cluster-based one-way bipartite graphs, the correlation with relevance is much stronger, and hence this kind of centrality serves as a better \"bias\" on query-likelihood.",
  "y": "background"
 },
 {
  "id": "74471d4e333ce76fd62b968045eba5_0",
  "x": "This tutorial introduces the advances in deep Bayesian learning with abundant applications for natural language understanding ranging from speech recognition (Saon and Chien, 2012; Chan et al., 2016) to document summarization (Chang and Chien, 2009 ), text classification (Blei et al., 2003; <cite>Zhang et al., 2015</cite>) , text segmentation (Chien and Chueh, 2012) , information extraction (Narasimhan et al., 2016) , image caption generation (Vinyals et al., 2015; Xu et al., 2015) , sentence generation (Li et al., 2016b) , dialogue control (Zhao and Eskenazi, 2016; Li et al., 2016a) , sentiment classification, recommendation system, question answering (Sukhbaatar et al., 2015) and machine translation , to name a few.",
  "y": "uses background"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_0",
  "x": "Our model significantly outperforms the previously mentioned hypergraph model of<cite> Lu and Roth (2015)</cite> and Muis and Lu (2017) on entity mention recognition for the ACE2004 and ACE2005 corpora.",
  "y": "differences"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_1",
  "x": "As a result, we do not adopt their parse tree-based representation of nested entities and propose instead a linear time directed hypergraph-based model similar to that of<cite> Lu and Roth (2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_2",
  "x": "While most previous efforts for nested entity recognition were limited to named entities,<cite> Lu and Roth (2015)</cite> addressed the problem of nested entity mention detection where mentions can either be named, nominal or pronominal.",
  "y": "background"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_3",
  "x": "In contrast to the hypergraph representation that we and<cite> Lu and Roth (2015)</cite> adopt, they learn a multigraph representation and are able to perform exact inference on their structure.",
  "y": "uses"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_4",
  "x": "Note that the hypergraph representation of our model is similar to<cite> Lu and Roth (2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_5",
  "x": "Also, the expressiveness of our model is exactly the same as<cite> Lu and Roth (2015)</cite> ; Muis and Lu (2017) .",
  "y": "similarities"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_6",
  "x": "We use a strict evaluation metric similar to<cite> Lu and Roth (2015)</cite> : an entity mention is considered correct if both the mention span and the mention type are exactly correct.",
  "y": "similarities"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_9",
  "x": "We find that our LSTM-flat baseline that ignores embedded entity mentions during training performs worse than<cite> Lu and Roth (2015)</cite> ; however, our other neural network-based approaches all outperform the previous feature-based approach.",
  "y": "differences"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_10",
  "x": "We follow the same dataset split as Finkel and Manning (2009);<cite> Lu and Roth (2015)</cite> ; Muis and Lu (2017) .",
  "y": "similarities uses"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_12",
  "x": "We suspect that it is because we use pretrained word embeddings 5 trained on PubMed data (Pyysalo et al., 2013) whereas<cite> Lu and Roth (2015)</cite> did not have access to them.",
  "y": "differences"
 },
 {
  "id": "74b8684eaabda30a2d8705adcb19a2_13",
  "x": "We show that our model significantly outperforms a feature based mention hypergraph model<cite> (Lu and Roth, 2015)</cite> and a recent multigraph model (Muis and Lu, 2017) on the ACE dataset.",
  "y": "differences"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_0",
  "x": "However, it is not flexible with regards to (C3), or the sense granularity problem, as it requires the users to specify the number of senses: Current systems (<cite>Wang et al. 2015</cite>; Chang, Pei, and Chen 2014) required to set the number of senses to a small number (set to 3 or 5 in the literature) to get a good accuracy, however many words may have a large number of senses, e.g. play in Figure 1 .",
  "y": "motivation"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_1",
  "x": "More recent models introduced a latent variable for the sense of a word, with the assumption that a sense has multiple concepts (HC, HC+Zipf) (Chang, Pei, and Chen 2014) and that topics and senses should be inferred jointly (STM) (<cite>Wang et al. 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_2",
  "x": "STM also used word embeddings (Mikolov et al. 2013) to assign similarity weights during inference (STM+w2v) (<cite>Wang et al. 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_3",
  "x": "LDA extensions (<cite>Wang et al. 2015</cite>; Chang, Pei, and Chen 2014) mitigated this problem by setting S to a small number (e.g. 3 or 5).",
  "y": "background"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_4",
  "x": "LDA extensions (<cite>Wang et al. 2015</cite>; Chang, Pei, and Chen 2014) mitigated this problem by setting S to a small number (e.g. 3 or 5). However, this is not a good solution because there are many words with more than five senses.",
  "y": "motivation"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_5",
  "x": "Previous works also attempted to introduce a separate sense latent variable to generate all the words (Chang, Pei, and Chen 2014) , or to generate only the neighboring words within a local context, decided by a strict user-specified window (<cite>Wang et al. 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_6",
  "x": "Following (<cite>Wang et al. 2015</cite>), we set the local context window to 10, with a maximum number of words of 21 (i.e. 10 words before and 10 words after).",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_7",
  "x": "We arbitrarily set the number of senses to S = 15, and the number of topics T = 2S = 30, following (<cite>Wang et al. 2015</cite>) .",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_8",
  "x": "Following the convention of previous works (Lau et al. 2012; Goyal and Hovy 2014; <cite>Wang et al. 2015</cite>) , we assume convergence when the number of iterations is high.",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_9",
  "x": "In order to get a common ground for comparison, we do a geometric average AVG of both metrics, following (<cite>Wang et al. 2015</cite>) .",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_10",
  "x": "Therefore, computing the AVG of both metrics is also necessary in this experiment, for ease of comparison, as also suggested in (<cite>Wang et al. 2015</cite>) .",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_11",
  "x": "We use seven baselines: a) lexical substitution method (AI-KU) and b) nonparametric HDP model (Unimelb) as reported in (Jurgens and Klapaftis 2013) , c) Sense-Topic Model STM, d) STM with word2vec weights (STM+w2v) as reported in (<cite>Wang et al. 2015</cite>) , e) Word Graph embeddings (WG), f) Distributional Inclusion Vector Embedding (DIVE) as reported in (Chang et al. 2018) , and g) Multi Context Continuous model MCC as reported in (Komninos and Manandhar 2016) .",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_12",
  "x": "For completeness, we also report STM with additional contexts, STM+actual and STM+ukWac (<cite>Wang et al. 2015</cite>) , where they used the actual additional contexts from the original data and semantically similar contexts from ukWac, respectively, as additional global context.",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_13",
  "x": "Recent models such as HC (Chang, Pei, and Chen 2014) and STM (<cite>Wang et al. 2015</cite>) mitigated this problem by tuning the number of senses hyperparameter S to minimize the error.",
  "y": "background"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_14",
  "x": "However, such tuning, often empirically set to a small number such as S = 3 (<cite>Wang et al. 2015</cite>) , fails to infer varying number of senses of words, especially for words with a higher number of senses.",
  "y": "motivation"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_15",
  "x": "We compare the cluster errors of LDA (Blei, Ng, and Jordan 2003) , STM (<cite>Wang et al. 2015</cite>) , HC (Chang, Pei, and Chen 2014) , and a nonparametric model HDP (Teh et al. 2004 ), with AutoSense.",
  "y": "uses"
 },
 {
  "id": "75b2aa54c363151130ca2146044922_16",
  "x": "We use LDA (Blei, Ng, and Jordan 2003) , HC (Chang, Pei, and Chen 2014) and STM (<cite>Wang et al. 2015</cite>) as baselines.",
  "y": "uses"
 },
 {
  "id": "782517ae7688cf18b4bca37a8087dd_0",
  "x": "<cite>Rao et al. (2018)</cite> identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling, and proposed a model specifically designed to handle these characteristics.",
  "y": "background"
 },
 {
  "id": "782517ae7688cf18b4bca37a8087dd_1",
  "x": "<cite>Rao et al. (2018)</cite> identified short document length, informality of language, and heterogeneous relevance signals as main challenges in relevance modeling, and proposed a model specifically designed to handle these characteristics. In this paper, we also examine the problem of modeling relevance for ranking short social media posts, but from a complementary perspective.",
  "y": "similarities background"
 },
 {
  "id": "782517ae7688cf18b4bca37a8087dd_2",
  "x": "Following <cite>Rao et al. (2018)</cite> , we evaluate our models in a reranking task, where the inputs are up to the top 1000 tweets retrieved from the classical query likelihood (QL) language model (Ponte and Croft, 1998) .",
  "y": "uses"
 },
 {
  "id": "782517ae7688cf18b4bca37a8087dd_3",
  "x": "MP-HCNN<cite> (Rao et al., 2018)</cite> is the first neural model that captures the characteristics of social media domain.",
  "y": "uses"
 },
 {
  "id": "782517ae7688cf18b4bca37a8087dd_4",
  "x": "Results from 5 -8 are adopted from <cite>Rao et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "782517ae7688cf18b4bca37a8087dd_5",
  "x": "To the best of our knowledge, <cite>Rao et al. (2018)</cite> is the best neural model to date, and there are no neural models from TREC evaluations for further comparison.",
  "y": "background"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_0",
  "x": "Compared to meta-learning baselines and recent approaches which use language supervision as a more fundamental bottleneck in a model <cite>[1]</cite> , we find this simple auxiliary training objective results in learned representations that generalize better to new concepts.",
  "y": "differences"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_3",
  "x": "[13] use METEOR scores between captions as a similarity metric for specializing embeddings for image retrieval, but do not directly Figure<cite> 1</cite> : Building on prototype networks [26] , we propose few-shot classification models whose learned representations are constrained to predict natural language descriptions of the task during training, in contrast to models <cite>[1]</cite> which explicitly use language as a bottleneck for classification.",
  "y": "differences"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_5",
  "x": "Our work is most similar to <cite>[1]</cite> , which we describe and compare to later.",
  "y": "similarities"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_9",
  "x": "With this component, we call our approach language-shaped learning (LSL) (Figure<cite> 1</cite> ). Relation to L3. LSL is similar to another recent model for this setting: Learning with Latent Language (L3) <cite>[1]</cite> , which proposes to use language not only as a supervision source, but as a bottleneck for classification ( Figure<cite> 1</cite> ).",
  "y": "similarities"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_10",
  "x": "First, we use the ShapeWorld [20] dataset devised by <cite>[1]</cite> , which consists of 9000 training,<cite> 1</cite>000 validation, and 4000 test tasks ( Figure 2 ).",
  "y": "uses"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_11",
  "x": "Model details are identical to <cite>[1]</cite> for easy comparison.",
  "y": "uses"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_17",
  "x": "A.1 ShapeWorld f \u03b8 . Like <cite>[1]</cite> , f \u03b8 starts with features extracted from the last convolutional layer of a fixed ImageNetpretrained VGG-19 network [25] .",
  "y": "similarities"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_19",
  "x": "Like <cite>[1]</cite> , a total of<cite> 1</cite>0 descriptions per task are sampled at test time.",
  "y": "similarities"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_21",
  "x": "This differs slightly from <cite>[1]</cite> , who use different numbers of epochs per model and did not specify how they were chosen; otherwise, the training and evaluation process is the same.",
  "y": "differences"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_22",
  "x": "We recreated the ShapeWorld dataset using the same code as <cite>[1]</cite> , except generating 4x as many test tasks (4000 vs<cite> 1</cite>000) for more stable confidence intervals.",
  "y": "uses differences similarities"
 },
 {
  "id": "79ac70221fa28e577876425cad627f_23",
  "x": "Note that results for both L3 and Baseline (Meta) are 3-4 points lower than the scores of the corresponding implementations in <cite>[1]</cite> .",
  "y": "differences"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_0",
  "x": "Following <cite>Webber et al. (2003)</cite> , the paper argues that in contrast crucially involves discourse anaphora and, thus, resembles other discourse adverbials such as then, otherwise, and nevertheless.",
  "y": "differences"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_1",
  "x": "The third generalization is further elaborated by <cite>Webber et al. (2003)</cite> who distinguish between coordinating conjunctions such as and, or, so, and but and subordinating conjunctions such as although, whereas, and when on the one hand, and discourse adverbials such as then, otherwise, nevertheless, and instead on the other hand.",
  "y": "background"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_2",
  "x": "It is the latter group, namely discourse adverbials, that, according to <cite>Webber et al. (2003)</cite> , should be considered as anaphors in very much the same way as other anaphoric expressions such as definite descriptions and pronouns.",
  "y": "similarities"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_3",
  "x": "Following <cite>Webber et al. (2003)</cite>, we will argue that it resembles other discourse adverbials such as then, otherwise, and nevertheless in that it crucially involves the notion of discourse anaphora.",
  "y": "similarities"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_4",
  "x": "(8) Sue grabbed one phone, as Tom darted to the other phone.<cite> (Webber et al. (2003)</cite>, p. 555) Here the referent of the other phone can be inferred from the antecedent one phone.",
  "y": "background"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_5",
  "x": "<cite>Webber et al. (2003)</cite> observe that identification of the correct antecedent of a definite description such as the tower or this tower in (12a) or a discourse adverbial such as otherwise in (12b) may require reference to abstract discourse objects such as the result of stacking blocks (to form a tower) or the state of not wanting an apple as the logical antecedent of a definite description or of a discourse adverbial.",
  "y": "background"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_6",
  "x": "Now close your eyes and try knocking the tower, this tower\u00a1 over with your nose.<cite> (Webber et al. (2003)</cite> , p. 552) b. Do you want an apple? Otherwise you can have a pear.",
  "y": "background"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_7",
  "x": "B0H (0476) Another property that distinguishes anaphoric discourse adverbials from structural connectives in the sense of <cite>Webber et al. (2003)</cite> , i.e. coordinating and subordinating conjunctions, concerns the type of dependencies that the arguments of the types of connectives can enter into.",
  "y": "background"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_8",
  "x": "Following earlier proposals by Hinrichs (1986) and Kamp and Reyle (1993) , <cite>Webber et al. (2003)</cite> assume that the semantics of discourse adverbials such as then involves an anaphoric relation between two events.",
  "y": "background"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_9",
  "x": "The semantics proposed for in-contrast, thus, provides further evidence for the distinction between coordinating and subordinating conjunctions and discourse adverbials that has been put forth by <cite>Webber et al. (2003)</cite> .",
  "y": "differences"
 },
 {
  "id": "79ff6e23cc951aa18ae53763e9c982_10",
  "x": "Following <cite>Webber et al. (2003)</cite> , the paper argues that in contrast crucially involves discourse anaphora and, thus, resembles other discourse adverbials such as then, otherwise, and nevertheless.",
  "y": "differences"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_0",
  "x": "<cite>Artetxe et al. (2017)</cite> use a very small, automatically-generated seed lexicon of identical numerals as the initialization in an iterative self-learning framework to learn a linear mapping between monolingual embedding spaces; Zhang et al. (2017) use an adversarial training method to learn a similar mapping.",
  "y": "background"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_1",
  "x": "<cite>Artetxe et al. (2017)</cite> use a very small, automatically-generated seed lexicon of identical numerals as the initialization in an iterative self-learning framework to learn a linear mapping between monolingual embedding spaces; Zhang et al. (2017) use an adversarial training method to learn a similar mapping. These recent advances in unsupervised bilingual lexicon induction show promise for use in low-resource contexts. However, none of them make use of linguistic features of the languages themselves (with the arguable exception of syntactic/semantic information encoded in the word embeddings).",
  "y": "motivation"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_2",
  "x": "In this work, we extend the modern embeddingbased approach of <cite>Artetxe et al. (2017)</cite> with orthographic information in order to leverage similarities between related languages for increased accuracy in bilingual lexicon induction.",
  "y": "extends"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_3",
  "x": "This work is directly based on the work of <cite>Artetxe et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_4",
  "x": "This work is directly based on the work of <cite>Artetxe et al. (2017)</cite> . Following their work, let X \u2208 R |Vs|\u00d7d and Z \u2208 R |Vt|\u00d7d be the word embedding matrices of two distinct languages, referred to respectively as the source and target, such that each row corresponds to the d-dimensional embedding of a single word.",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_5",
  "x": "<cite>Artetxe et al. (2017)</cite> define the optimal mapping matrix W * with the following equation, which minimizes the sum of the squared Euclidean distances between mapped source embeddings and their aligned target embeddings.",
  "y": "background"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_6",
  "x": "This work is directly based on the work of <cite>Artetxe et al. (2017)</cite> . <cite>Artetxe et al. (2017)</cite> define the optimal mapping matrix W * with the following equation, which minimizes the sum of the squared Euclidean distances between mapped source embeddings and their aligned target embeddings.",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_7",
  "x": "To reduce the need for a large seed dictionary, <cite>Artetxe et al. (2017)</cite> propose an iterative, self-learning framework that determines W as above, uses it to calculate a new dictionary D, and then iterates until convergence. We propose two methods for extending this system using orthographic information, described in the following two sections.",
  "y": "extends"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_8",
  "x": "To reduce the need for a large seed dictionary, <cite>Artetxe et al. (2017)</cite> propose an iterative, self-learning framework that determines W as above, uses it to calculate a new dictionary D, and then iterates until convergence.",
  "y": "background"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_9",
  "x": "This work is directly based on the work of <cite>Artetxe et al. (2017)</cite> . To reduce the need for a large seed dictionary, <cite>Artetxe et al. (2017)</cite> propose an iterative, self-learning framework that determines W as above, uses it to calculate a new dictionary D, and then iterates until convergence.",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_10",
  "x": "This method augments the embeddings for all words in both languages before using them in the self-learning framework of <cite>Artetxe et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_11",
  "x": "This method modifies the similarity score for each word pair during the dictionary induction phase of the self-learning framework of <cite>Artetxe et al. (2017)</cite> , which uses the dot product of two words' embeddings to quantify similarity.",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_12",
  "x": "This method modifies the similarity score for each word pair during the dictionary induction phase of the self-learning framework of <cite>Artetxe et al. (2017)</cite> , which uses the dot product of two words' embeddings to quantify similarity. We modify this similarity score by adding a measure of orthographic similarity, which is a function of the normalized string edit distance of the two words.",
  "y": "extends"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_13",
  "x": "We use the datasets used by <cite>Artetxe et al. (2017)</cite> , consisting of three language pairs: EnglishItalian, English-German, and English-Finnish.",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_14",
  "x": "We use the datasets used by <cite>Artetxe et al. (2017)</cite> , consisting of three language pairs: EnglishItalian, English-German, and English-Finnish. The English-Italian dataset was introduced in Dinu and Baroni (2014) ; the other datasets were created by <cite>Artetxe et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_15",
  "x": "We do not use the training set as the input dictionary to the system, instead using an automatically-generated dictionary consisting only of numeral identity translations (such as 2-2, 3-3, et cetera) as in <cite>Artetxe et al. (2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_16",
  "x": "Table 1 compares our methods against the system of <cite>Artetxe et al. (2017)</cite> , using scaling factors selected based on development data results. Because approximately 20% of source-target pairs in the dictionary were identical, we also extended all systems to guess the identity translation if the source word appeared in the target vocabulary. This improved accuracy in most cases, with some exceptions for English-Italian.",
  "y": "differences"
 },
 {
  "id": "7b9fc52e4479dc5ff9b8796a558981_17",
  "x": "Table 1 compares our methods against the system of <cite>Artetxe et al. (2017)</cite> , using scaling factors selected based on development data results.",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_0",
  "x": "Answering detailed questions about an image is a type of task which requires more sophisticated patterns of reasoning, and there has been a rapid recent proliferation of computer vision approaches for tackling the visual question answering (Visual QA) task [6,<cite> 7]</cite> .",
  "y": "background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_1",
  "x": "to handle many objects and their complex relations while also integrating rich background knowledge, and attention has emerged as a promising strategy for achieving good performance<cite> [7,</cite> 8, 9, 10, 11, 12, 13, 14] .",
  "y": "background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_2",
  "x": "Existing attention models<cite> [7,</cite> 8, 9, 10] are predominantly based on soft attention, in which all information is adaptively re-weighted before being aggregated.",
  "y": "background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_3",
  "x": "We rely on a canonical Visual QA pipeline<cite> [7,</cite> 9, 22, 23, 24, 25] augmented with a hard attention mechanism that uses the L2-norms of the feature vectors to select subsets of the information for further processing.",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_4",
  "x": "Creating a good Visual QA dataset has proved non-trivial: biases in the early datasets [6, 22, 23, 33] rewarded algorithms for exploiting spurious correlations, rather than tackling the reasoning problem head-on<cite> [7,</cite> 34, 35] .",
  "y": "background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_5",
  "x": "Thus, we focus on the recently-introduced VQA-CP <cite>[7]</cite> and CLEVR [34] datasets, which aim to reduce the dataset biases, providing a more difficult challenge for rich visual reasoning.",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_6",
  "x": "However, only soft attention is used in the majority of Visual QA works<cite> [7,</cite> 8, 9, 10, 11, 12, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52] .",
  "y": "motivation background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_7",
  "x": "As is common in question answering<cite> [7,</cite> 9, 22, 23, 24] , the question is a sequence of words q = [q 1 , ..., q n ], while the output is reduced to a classification problem between a set of common answers (this is limited compared to approaches that generate answers [41] , but works better in practice).",
  "y": "background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_8",
  "x": "We compute a combined representation by copying the question representation to every spatial location in the CNN, and concatenating it with (or simply adding it to) the visual features, like previous Otherwise, we follow the canonical Visual QA pipeline<cite> [7,</cite> 9, 22, 23, 24, 25] .",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_10",
  "x": "After a few layers of combined processing, we apply attention over spatial locations, following previous works which often apply soft attention mechanisms<cite> [7,</cite> 8, 9, 10] at this point in the architecture.",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_11",
  "x": "This dataset <cite>[7]</cite> consists of about 121K (98K) images, 438K (220K) questions, and 4.4M (2.2M) answers in the train (test) set; and it is created so that the distribution of the answers between train and test splits differ, and hence the models cannot excessively rely on the language prior <cite>[7]</cite> . As expected, <cite>[7]</cite> show that performance of all Visual QA approaches they tested drops significantly between train to test sets.",
  "y": "background"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_12",
  "x": "This dataset <cite>[7]</cite> consists of about 121K (98K) images, 438K (220K) questions, and 4.4M (2.2M) answers in the train (test) set; and it is created so that the distribution of the answers between train and test splits differ, and hence the models cannot excessively rely on the language prior <cite>[7]</cite> . As expected, <cite>[7]</cite> show that performance of all Visual QA approaches they tested drops significantly between train to test sets. The dataset provides a standard traintest split, and also breaks questions into different question types: those where the answer is yes/no, those where the answer is a number, and those where the answer is something else. Thus, we report accuracy on each question type as well as the overall accuracy for each network architecture.",
  "y": "motivation"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_13",
  "x": "In particular, we include previous results using a basic soft attention network<cite> [7,</cite> 9] , as well as our own re-implementation of the soft attention pooling algorithm presented in<cite> [7,</cite> 9] with the same features used in other experiments.",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_14",
  "x": "Our results overall are somewhat worse than the state-of-the-art <cite>[7]</cite> , but this is likely due to several architectural decisions not included here, such as a split pathway for different kinds of questions, special question embeddings, and the use of the question extractor.",
  "y": "differences"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_15",
  "x": "Table 1 shows SAN's [9] results reported by <cite>[7]</cite> together with our in-house implementation (denoted as \"ours\").",
  "y": "uses"
 },
 {
  "id": "7bdb51a3ca6c322ef6e04d18ba8483_16",
  "x": "In our experiments, simple-SAN achieves about 21% performance on the test set. Surprisingly, simple-HAN+sum achieves about 24% performance on the same split, on-par with the performance of normal SAN that uses more complex and deeper visual architecture [67] ; the results are reported by <cite>[7]</cite> .",
  "y": "similarities"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_0",
  "x": "Whereas early approaches to unsupervised text segmentation measured the coherence of segments via raw term overlaps between sentences (Hearst, 1997; Choi, 2000) , more recent methods (Misra et al., 2009;<cite> Riedl and Biemann, 2012)</cite> addressed the issue of sparsity of term-based representations by replacing term-vectors with vectors of latent topics.",
  "y": "background"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_1",
  "x": "Like the majority of TS methods (Hearst, 1994; Brants et al., 2002; Misra et al., 2009;<cite> Riedl and Biemann, 2012)</cite> , in this work we focus on linear segmentation of text, but there is also a solid body of work on hierarchical TS, where each toplevel segment is further broken down (Yaari, 1997; Eisenstein, 2009 ).",
  "y": "similarities"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_2",
  "x": "More recent models (Misra et al., 2009;<cite> Riedl and Biemann, 2012)</cite> employed the latent Dirichlet allocation (LDA) (Blei et al., 2003) to compute the latent topics and displayed superior performance to previous models on standard synthetic datasets (Choi, 2000; Galley et al., 2003) .",
  "y": "background"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_3",
  "x": "Misra et al. (2009) used dynamic programming to find globally optimal segmentation over the set of LDA-based segment representations, whereas <cite>Riedl and Biemann (2012)</cite> introduced TopicTiling, an LDA-driven extension of Hearst's TextTiling algorithm where segments are, represented as dense vectors of dominant topics of terms they contain (instead of as sparse term vectors).",
  "y": "background"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_4",
  "x": "<cite>Riedl and Biemann (2012)</cite> show that TopicTiling outperforms at-that-time state-of-the-art methods for unsupervised linear segmentation (Choi, 2000; Utiyama and Isahara, 2001; Galley et al., 2003; Fragkou et al., 2004; Misra et al., 2009 ) and that it is also faster than other LDA-based methods (Misra et al., 2009 ).",
  "y": "background"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_5",
  "x": "4 Both LDA-based models (Misra et al., 2009;<cite> Riedl and Biemann, 2012)</cite> and GRAPHSEG rely on corpus-derived word representations.",
  "y": "background"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_6",
  "x": "Thus, we evaluated on the Manifesto dataset both the domainadapted and domain-unadapted variants of these methods. This means that we obtain (1) in-domain topics for the LDAbased TopicTiling model of <cite>Riedl and Biemann (2012)</cite> and (2) domain-specific embeddings for the GRAPHSEG algorithm.",
  "y": "uses"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_7",
  "x": "This means that we obtain (1) in-domain topics for the LDAbased TopicTiling model of <cite>Riedl and Biemann (2012)</cite> and (2) domain-specific embeddings for the GRAPHSEG algorithm.",
  "y": "uses"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_8",
  "x": "Following <cite>Riedl and Biemann (2012)</cite> , we set k to half of the document length divided by the number of gold segments.",
  "y": "uses"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_9",
  "x": "In view of comparison with other models, the parameter optimization is justified be-3-5 6-8 9-11 3-11 Brants et al. (2002) 7. cause other models, e.g., TopicTiling<cite> (Riedl and Biemann, 2012)</cite> , also have parameters (e.g., number of topics for the topic model) which are optimized using cross-validation.",
  "y": "similarities"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_10",
  "x": "GRAPHSEG performs competitively, outperforming all methods but (Fragkou et al., 2004) and domain-adapted versions of LDA-based models (Misra et al., 2009;<cite> Riedl and Biemann, 2012)</cite> .",
  "y": "differences"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_11",
  "x": "Despite the fact that they use different documents for training the topic models from those used for evaluating segmentation quality, the evaluation is still tainted because snippets from the original documents appear in multiple artificial documents -some of which belong to the the training set and others to the test set, as admitted by <cite>Riedl and Biemann (2012)</cite> and this is why their reported performance on this dataset is overestimated.",
  "y": "background"
 },
 {
  "id": "7be8bcb17980dee5e94df9faec8183_12",
  "x": "This result contrasts previous findings (Misra et al., 2009;<cite> Riedl and Biemann, 2012)</cite> in which the performance boost was credited to the indomain trained topics and supports our hypothesis that the performance boost of the LDA-based methods' with in-domain trained topics originates from information leakage between different portions of the synthetic Choi dataset.",
  "y": "differences"
 },
 {
  "id": "7c2586a172dc6f061817c3a8b3ebf0_0",
  "x": "Pidgin English is one of the the most widely spoken languages in West Africa with roughly 75 million speakers estimated in Nigeria; and over 5 million speakers estimated in Ghana<cite> (Ogueji & Ahia, 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "7c2586a172dc6f061817c3a8b3ebf0_1",
  "x": "Previous works on unsupervised neural machine translation for Pidgin English constructed a monolingual corpus<cite> (Ogueji & Ahia, 2019)</cite> , and achieved a BLEU score of 5.18 from English to Pidgin.",
  "y": "background"
 },
 {
  "id": "7c2586a172dc6f061817c3a8b3ebf0_2",
  "x": "Previous works on unsupervised neural machine translation for Pidgin English constructed a monolingual corpus<cite> (Ogueji & Ahia, 2019)</cite> , and achieved a BLEU score of 5.18 from English to Pidgin. However, there is an issue of domain mismatch between down-stream NLG tasks and the trained machine translation system.",
  "y": "background motivation"
 },
 {
  "id": "7c2586a172dc6f061817c3a8b3ebf0_3",
  "x": "First phase of the approach requires training of an unsupervised NMT system similar to <cite>Ogueji & Ahia (2019)</cite> (PidginUNMT).",
  "y": "similarities"
 },
 {
  "id": "7c2586a172dc6f061817c3a8b3ebf0_4",
  "x": "Similar to <cite>Ogueji & Ahia (2019)</cite> , we train the cross-lingual model using FastText Bojanowski et al. (2017) on the combined Pidgin-English corpus.",
  "y": "similarities"
 },
 {
  "id": "7c2586a172dc6f061817c3a8b3ebf0_5",
  "x": "Next, we train an unsupervised NMT similar to Lample et al. (2017) ; Artetxe et al. (2017) ; <cite>Ogueji & Ahia (2019)</cite> between them to obtain model unsup .",
  "y": "similarities"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_0",
  "x": "The unsupervised approaches for keyphrase extraction proposed so far have involved a number of techniques, including language modeling (e.g., Tomokiyo and Hurst (2003) ), graph-based ranking (e.g., Zha (2002) ,<cite> Mihalcea and Tarau (2004)</cite> , Wan et al. (2007) , Wan and Xiao (2008) , Liu et al. (2009a) ), and clustering (e.g., Matsuo and Ishizuka (2004) , Liu et al. (2009b) ).",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_1",
  "x": "The unsupervised approaches for keyphrase extraction proposed so far have involved a number of techniques, including language modeling (e.g., Tomokiyo and Hurst (2003) ), graph-based ranking (e.g., Zha (2002) ,<cite> Mihalcea and Tarau (2004)</cite> , Wan et al. (2007) , Wan and Xiao (2008) , Liu et al. (2009a) ), and clustering (e.g., Matsuo and Ishizuka (2004) , Liu et al. (2009b) ). While these methods have been shown to work well on a particular domain of text such as short paper abstracts and news articles, their effectiveness and portability across different domains have remained an unexplored issue.",
  "y": "motivation"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_2",
  "x": "These algorithms represent the ma-jor directions in this research area, including TfIdf and four recently proposed systems, namely, TextRank <cite>(Mihalcea and Tarau, 2004)</cite> , SingleRank (Wan and Xiao, 2008) , ExpandRank (Wan and Xiao, 2008) , and a clustering-based approach (Liu et al., 2009b) .",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_3",
  "x": "More specifically, we compare five unsupervised keyphrase extraction algorithms on four corpora with varying domains and statistical characteristics. These algorithms represent the ma-jor directions in this research area, including TfIdf and four recently proposed systems, namely, TextRank <cite>(Mihalcea and Tarau, 2004)</cite> , SingleRank (Wan and Xiao, 2008) , ExpandRank (Wan and Xiao, 2008) , and a clustering-based approach (Liu et al., 2009b) .",
  "y": "uses"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_4",
  "x": "These algorithms represent the ma-jor directions in this research area, including TfIdf and four recently proposed systems, namely, TextRank <cite>(Mihalcea and Tarau, 2004)</cite> , SingleRank (Wan and Xiao, 2008) , ExpandRank (Wan and Xiao, 2008) , and a clustering-based approach (Liu et al., 2009b) . Since none of these systems (except TextRank) are publicly available, we reimplement all of them and make them freely available for research purposes.",
  "y": "uses"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_5",
  "x": "This is a relatively popular dataset for automatic keyphrase extraction, as it was first used by Hulth (2003) and later by<cite> Mihalcea and Tarau (2004)</cite> and Liu et al. (2009b) .",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_6",
  "x": "Commonly used heuristics include (1) using a stop word list to remove non-keywords (e.g., Liu et al. (2009b) ) and (2) allowing words with certain partof-speech tags (e.g., nouns, adjectives, verbs) to be considered candidate keywords<cite> (Mihalcea and Tarau (2004)</cite> , Liu et al. (2009a) , Wan and Xiao (2008) ).",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_7",
  "x": "A candidate phrase, typically a sequence of nouns and adjectives, is selected as a keyphrase if (1) it includes one or more of the top-ranked candidate words<cite> (Mihalcea and Tarau (2004)</cite> , Liu et al. (2009b) ), or (2) the sum of the ranking scores of its constituent words makes it a top scoring phrase (Wan and Xiao, 2008) .",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_8",
  "x": "In the TextRank algorithm <cite>(Mihalcea and Tarau, 2004)</cite> , a text is represented by a graph.",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_9",
  "x": "According to<cite> Mihalcea and Tarau (2004)</cite> , TextRank's best score on the Inspec dataset is achieved when only nouns and adjectives are used to create a uniformly weighted graph for the text under consideration, where an edge connects two word types only if they co-occur within a window of two words.",
  "y": "background"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_10",
  "x": "TextRank and SingleRank setup Following<cite> Mihalcea and Tarau (2004)</cite> and Wan and Xiao (2008) , we set the co-occurrence window size for TextRank and SingleRank to 2 and 10, respectively, as these parameter values have yielded the best results for their evaluation datasets.",
  "y": "uses"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_11",
  "x": "We generate the curves for each system as follows. For Tf-Idf, SingleRank, and ExpandRank, we vary the number of keyphrases, N , predicted by each system. On average, TextRank performs much worse compared to Tf-Idf. This certainly gives more insight into TextRank since it was evaluated on Inspec only for T=33% by<cite> Mihalcea and Tarau (2004)</cite> .",
  "y": "differences"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_12",
  "x": "While<cite> Mihalcea and Tarau (2004)</cite> and our reimplementations use all of these gold-standard keyphrases in our evaluation, Hulth (2003) and Liu et al. address Table 3 : Original vs. re-implementation scores of TextRank 3 , and are confident that our implementation is correct.",
  "y": "similarities"
 },
 {
  "id": "7d5c01ec5d744747413e42dcbc1a3c_13",
  "x": "It is also worth mentioning that using our re-implementation of SingleRank, we are able to match the best scores reported by<cite> Mihalcea and Tarau (2004)</cite> on Inspec.",
  "y": "similarities"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_0",
  "x": "Universal schema, in particular, has found impressive accuracy gains by (1) treating the distant-supervision as a knowledge-base (KB) containing both structured relations such as bornIn * First two authors contributed equally to the paper. and surface form relations such as \"was born in\" extracted from text, and (2) by completing the entries in such a KB using joint and compact encoding of the dependencies between the relations <cite>(Riedel et al., 2013</cite>; Fan et al., 2014; .",
  "y": "background"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_1",
  "x": "Matrix factorization is at the core of this completion:<cite> Riedel et al. (2013)</cite> convert the KB into a binary matrix with entity-pairs forming the rows and relations forming the columns.",
  "y": "background"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_2",
  "x": "Universal schema, in particular, has found impressive accuracy gains by (1) treating the distant-supervision as a knowledge-base (KB) containing both structured relations such as bornIn * First two authors contributed equally to the paper. and surface form relations such as \"was born in\" extracted from text, and (2) by completing the entries in such a KB using joint and compact encoding of the dependencies between the relations <cite>(Riedel et al., 2013</cite>; Fan et al., 2014; . Matrix factorization is at the core of this completion:<cite> Riedel et al. (2013)</cite> convert the KB into a binary matrix with entity-pairs forming the rows and relations forming the columns.",
  "y": "background"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_3",
  "x": "A universal schema is defined as the union of all OpenIE-like surface form patterns found in text and fixed canonical relations that exist in a knowledge base<cite> (Riedel et al., 2013)</cite> .",
  "y": "background"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_4",
  "x": "In matrix factorization for universal schema,<cite> Riedel et al. (2013)</cite> construct a sparse binary matrix of size |P| \u00d7 |R| whose rows are indexed by entity-pairs (a, b) \u2208 P and columns by surface form and Freebase relations s \u2208 R. Subsequently, generalized PCA (Collins et al., 2001 ) is used to find a rank-k factorization, i.e., with relation factors r \u2208 R |R|\u00d7k and entity-pair factors p \u2208 R |P|\u00d7k , the probability of a relation s and two entities a and b is:",
  "y": "background"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_5",
  "x": "Furthermore, we isolate the entity factorization in<cite> Riedel et al. (2013)</cite> by viewing it as tensor factorization.",
  "y": "extends"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_6",
  "x": "Although not explored in isolation by<cite> Riedel et al. (2013)</cite> , model E can be used on its own to predict relations between entities, even if they have not been observed to be in a relation.",
  "y": "extends"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_7",
  "x": "Although matrix factorization performs well for universal schema<cite> (Riedel et al., 2013)</cite> , it is not robust to sparse data and does not capture latent entity types that can be crucial for accurate relation extraction.",
  "y": "motivation"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_8",
  "x": "As the direct combination of a pairwise model (Eq. 1) with an entity model (Eq. 5), we consider the FE model from<cite> Riedel et al. (2013)</cite> , i.e., the additive combination of the two: P (s(a, b)) = \u03c3(r s \u00b7 e ab + r s,1 \u00b7 e a + r s,2 \u00b7 e b ) (6) Both the matrix factorization model F and entity model E can de defined as special cases of this model, by setting r s,1/2 or r s to zero, respectively.",
  "y": "uses"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_9",
  "x": "As the direct combination of a pairwise model (Eq. 1) with an entity model (Eq. 5), we consider the FE model from<cite> Riedel et al. (2013)</cite> , i.e., the additive combination of the two: P (s(a, b)) = \u03c3(r s \u00b7 e ab + r s,1 \u00b7 e a + r s,2 \u00b7 e b ) (6) Both the matrix factorization model F and entity model E can de defined as special cases of this model, by setting r s,1/2 or r s to zero, respectively. A problem with combining the two models additively, as in FE, is that one model can easily override the other.",
  "y": "motivation"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_10",
  "x": "As the direct combination of a pairwise model (Eq. 1) with an entity model (Eq. 5), we consider the FE model from<cite> Riedel et al. (2013)</cite> , i.e., the additive combination of the two: P (s(a, b)) = \u03c3(r s \u00b7 e ab + r s,1 \u00b7 e a + r s,2 \u00b7 e b ) (6) Both the matrix factorization model F and entity model E can de defined as special cases of this model, by setting r s,1/2 or r s to zero, respectively. A problem with combining the two models additively, as in FE, is that one model can easily override the other. To alleviate this shortcoming, we experimented with rectifier units (Nair and Hinton, 2010) so that a score of model F or model E first needs to reach a certain threshold to influence the overall prediction for a triplet.",
  "y": "extends"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_11",
  "x": "As by<cite> Riedel et al. (2013)</cite> , we use a Bayesian personalized ranking objective (Rendle et al., 2009 ) to estimate parameters, i.e., for each observed training fact, we sample an unobserved fact for the same relation, and maximize their relative ranking using AdaGrad.",
  "y": "uses"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_12",
  "x": "Following the experiment setup of<cite> Riedel et al. (2013)</cite> , we instantiate the universal schema matrix over entity pairs and text/Freebase relations for New York Times data, and compare the performance using average precision of the presented models.",
  "y": "uses"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_13",
  "x": "Table 1 summarizes the performance of our models, as compared to existing approaches (see<cite> Riedel et al. (2013)</cite> for an overview).",
  "y": "uses"
 },
 {
  "id": "7d80c3cc15453ddeaea72dcb9c04f9_14",
  "x": [
   "In particular, TR-R13 takes the output predictions of matrix factorization, and combines it with an entity-type aware RESCAL model . 3 Tensor factorization approaches perform poorly on this data. We present results for Model E, but other formulations such as PARAFAC, TransE, RESCAL, and Tucker2 achieved even lower accuracy; this is consistent with the results in ."
  ],
  "y": "differences"
 },
 {
  "id": "7ddd5b18d774575ae7acb97ae9eb33_0",
  "x": "It is a popular tool in semantic parsing, and treebank creation efforts have been made for Turkish (\u00c7 ak\u0131c\u0131, 2005) , German (Hockenmaier, 2006) , English <cite>(Hockenmaier and Steedman, 2007)</cite> , Italian (Bos et al., 2009) , Chinese (Tse and Curran, 2010) , Arabic (Boxwell and Brew, 2010) , Japanese (Uematsu et al., 2013) , and Hindi (Ambati et al., 2018) .",
  "y": "background"
 },
 {
  "id": "7ddd5b18d774575ae7acb97ae9eb33_1",
  "x": "It is a popular tool in semantic parsing, and treebank creation efforts have been made for Turkish (\u00c7 ak\u0131c\u0131, 2005) , German (Hockenmaier, 2006) , English <cite>(Hockenmaier and Steedman, 2007)</cite> , Italian (Bos et al., 2009) , Chinese (Tse and Curran, 2010) , Arabic (Boxwell and Brew, 2010) , Japanese (Uematsu et al., 2013) , and Hindi (Ambati et al., 2018) . However, all of these treebanks were not directly annotated according to the CCG formalism, but automatically converted from phrase structure or dependency treebanks, which is an error-prone process. Direct annotation in CCG has so far mostly been limited to small datasets for seeding or testing semantic parsers (e.g., Artzi et al., 2015) , and no graphical annotation interface is available to support such efforts, making the annotation process difficult to scale. The only exceptions we are aware of are the Groningen Meaning Bank and the Parallel Meaning Bank (Abzianidze et al., 2017) , two annotation efforts which use a graphical user interface for annotating sentences with CCG derivations and other annotation layers, and which have produced CCG treebanks for English, German, Italian, and Dutch. However, these efforts are focused on semantics and have not released explicit guidelines for syntactic annotation. Their annotation tool is limited in that annotators only have control over lexical categories, not larger constituents. Even though CCG is a lexicalized formalism, where most decisions can be made on the lexical level, there is no full control over attachment phenomena in the lexicon. Moreover, these annotation tools are not open-source and cannot easily be deployed to support other annotation efforts. In this paper, we present an open-source, lightweight, easy-to-use graphical annotation tool that employs a statistical parser to create initial CCG derivations for sentences, and allows annotators to correct these annotations via lexical category constraints and span constraints.",
  "y": "motivation"
 },
 {
  "id": "7ddd5b18d774575ae7acb97ae9eb33_2",
  "x": "The main annotation guideline was to copy the annotation style of CCGrebank (Honnibal et al., 2010), a CCG treebank adapted from CCGbank <cite>(Hockenmaier and Steedman, 2007)</cite> , which is in turn based on the Penn Treebank (Marcus et al., 1993) .",
  "y": "uses"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_0",
  "x": "We extend the tests made in <cite>Agirre et al. (2008)</cite> , who used different types of semantic information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing.",
  "y": "extends differences"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_1",
  "x": "We will evaluate the parser on both the full PTB (Marcus et al. 1993 ) and on a senseannotated subset of the Brown Corpus portion of PTB, in order to investigate the upper bound performance of the models given gold-standard sense information, as in <cite>Agirre et al. (2008)</cite> .",
  "y": "similarities"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_2",
  "x": "<cite>Agirre et al. (2008)</cite> trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004 ) on semantically-enriched input, where content words had been substituted with their semantic classes.",
  "y": "background"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_3",
  "x": "We extend the tests made in <cite>Agirre et al. (2008)</cite> , who used different types of semantic information, obtaining significant improvements in two constituency parsers, showing how semantic information helps in constituency parsing.",
  "y": "extends differences"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_4",
  "x": "We will evaluate the parser on both the full PTB (Marcus et al. 1993 ) and on a senseannotated subset of the Brown Corpus portion of PTB, in order to investigate the upper bound performance of the models given gold-standard sense information, as in <cite>Agirre et al. (2008)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_5",
  "x": "<cite>Agirre et al. (2008)</cite> trained two state-of-the-art statistical parsers (Charniak, 2000; Bikel, 2004) on semantically-enriched input, where content words had been substituted with their semantic classes.",
  "y": "background"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_6",
  "x": "We used two different datasets: the full PTB and the Semcor/PTB intersection<cite> (Agirre et al. 2008</cite> ).",
  "y": "uses"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_7",
  "x": "We use the same train-test split of <cite>Agirre et al. (2008)</cite> , with a total of 8,669 sentences containing 151,928 words partitioned into 3 sets: 80% training, 10% development and 10% test data.",
  "y": "similarities uses"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_8",
  "x": "We will experiment with the range of semantic representations used in <cite>Agirre et al. (2008)</cite> , all of which are based on WordNet 2.1.",
  "y": "similarities uses"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_9",
  "x": "<cite>Agirre et al. (2008)</cite> used a simple method of substituting wordforms with semantic information, which only allowed using a single semantic feature.",
  "y": "background"
 },
 {
  "id": "805935a672f5d706bd878a73fa8171_10",
  "x": "Our results extend those of <cite>Agirre et al. (2008)</cite> , which showed improvements on a subset of the PTB.",
  "y": "extends differences"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_0",
  "x": "BERT <cite>(Devlin et al., 2019)</cite> improved over previous transformer models and recurrent networks by allowing the system to learn from input text in a bidirectional way, rather than only from left-to-right or the other way around.",
  "y": "background"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_1",
  "x": "For example, Multilingual-BERT is trained on a collection of corpora in 104 different languages <cite>(Devlin et al., 2019)</cite> , and generalizes language components well across languages (Pires et al., 2019) .",
  "y": "background"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_2",
  "x": "This cornerstone was used for BERT, a transformer model that obtained stateof-the-art results for eleven natural language processing tasks, such as question answering and natural language inference <cite>(Devlin et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_3",
  "x": "This architecture has been shown to be a general language model that could be fine-tuned with little data in a relatively efficient way for a very distinct range of tasks and still outperform previous architectures <cite>(Devlin et al., 2019)</cite> .",
  "y": "background"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_4",
  "x": "That<cite> Devlin et al. (2019)</cite> trained a better model when using NSP than without NSP is likely due to the model learning long-range dependencies in text from its inputs, which are longer than just the single sentence on itself.",
  "y": "background"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_5",
  "x": "The architecture of our language model is thus equal to the original BERT model with 12 self-attention layers with 12 heads <cite>(Devlin et al., 2019)</cite> .",
  "y": "similarities"
 },
 {
  "id": "817576dbe36f79ac3e0031211f400d_6",
  "x": "ZeroR (majority class) 66.70 mBERT <cite>(Devlin et al., 2019)</cite> 90.21 BERTje (de Vries et al., 2019) 94.94 RobBERT (ours) 98.03 RobBERT outperforms previous models as well as other BERT models both with as well as without fine-tuning (see Table 1 and Table 2 ).",
  "y": "background"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_0",
  "x": "To deal with phonological variability alternate pronunciations are included in the lexicon, and optional phonological rules are applied during training and recognition. A trigram LM is used in a second acoustic decoding pass which makes use of the word graph generated using the bigram LM [6] . Experimental results are reported on the ARPA Wall Street Journal (WSJ) <cite>[19]</cite> and BREF [14] corpora, using for both corpora over 37k utterances for acoustic training and more than 37 million words of newspaper text for language model training. It is shown that for both corpora increasing the amount of training utterances by an order of magnitude reduces the word error by about 30%. The use of a trigram LM in a second pass also gives an error reduction of 20% to 30%.",
  "y": "background"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_1",
  "x": "This property can be used in the first bigram decod1While we have built n-gram-backoff LMs directly from the 37M-word standardized WSJ training text material, in these experiments all results are reported using the 5k or 20k, bigram and tfigram backoff LMs provided by Lincoln Labs<cite> [ 19]</cite> as required by ARPA so as to be compatible with the other sites participating in the tests.",
  "y": "uses"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_2",
  "x": "In order to be able to constnact LMs for BREF, it was necessary to normalize the text material of Le Monde newpaper, which entailed a pre-treatment rather different from that used to normalize the WSJ texts <cite>[19]</cite> .",
  "y": "uses differences"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_3",
  "x": "The ARPA WSJ corpus <cite>[19]</cite> was designed to provide general-purpose speech data with large vocabularies.",
  "y": "background"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_4",
  "x": "The 20k open test is also referred to as a 64k test since all of the words in these sentences occur in the 63,495 most frequent words in the normalized WSJ text material<cite> [ 19]</cite> .",
  "y": "uses"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_5",
  "x": "Except when explicitly stated otherwise, all of the results reported for WSJ use the standard language models <cite>[19]</cite> .",
  "y": "uses"
 },
 {
  "id": "84ae490de92cb9d064993be751b3e0_6",
  "x": "The recognizer has been evaluated on 5k and 20k test data for the English and French languages using similar style corpora. For WSJ, paragraphs were selected ensuring not more than one word was out of the 5.6k most frequent words<cite> [ 19]</cite> , and these additional words were then included as part of the vocabulary.",
  "y": "uses"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_0",
  "x": "Fukui et al.<cite> [6]</cite> propose multimodal compact bilinear pooling (MCB) to efficiently implement an outer product operator that combines visual and textual representations.",
  "y": "background"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_1",
  "x": "These coefficients are then used to weight the embedding of the image regions to obtain a suitable descriptor [19, 21,<cite> 6,</cite> 25, 26] .",
  "y": "background"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_2",
  "x": "We mostly build upon the MCB model in<cite> [6]</cite> , which exemplifies current state-of-the-art techniques for this problem.",
  "y": "extends differences"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_3",
  "x": "Afterwards, the fusion module models the joint relationship J attn \u2208 R O\u00d7H\u00d7W between questions and images, mapping them to a common space of dimension O. In the simplest case, one can implement the fusion module using either concatenation or Hadamard product [1] , but more effective pooling schemes can be applied <cite>[6,</cite> 11, 25, 26] .",
  "y": "background"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_4",
  "x": "Following previous work<cite> [6]</cite> , we use as candidate outputs the top 3000 most frequent answers in the VQA dataset.",
  "y": "similarities uses"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_5",
  "x": "It is mostly based on the model presented in<cite> [6]</cite> .",
  "y": "extends"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_6",
  "x": "We build the attention supervision on top of the opensourced implementation of MCB<cite> [6]</cite> and MFB [25] .",
  "y": "extends differences"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_7",
  "x": "We follow the processing scheme from<cite> [6]</cite> , where non-informative words in the questions and answers such as \"a\" and \"is\" are removed.",
  "y": "similarities uses"
 },
 {
  "id": "866ae880aa0de1e60d306eac2e66fc_8",
  "x": "Accuracy/% VQA-HAT VQA-X VQA-2.0 Human [5] 0.623 -80.62 PJ-X [17] 0.396 0.342 -MCB<cite> [6]</cite> 0 authors also collect 1374 \u00d7 3 = 4122 HAT maps for VQA-1.0 validation sets, where each of the 1374 (I, Q, A) were labeled by three different annotators, so one can compare the level of agreement among labels.",
  "y": "similarities"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_0",
  "x": "Recent work has shown benefits of combining conventional lexical information into neural cross-lingual part-ofspeech (PoS) tagging <cite>(Plank and Agi\u0107, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_1",
  "x": "Recent work has shown benefits of combining conventional lexical information into neural cross-lingual part-ofspeech (PoS) tagging <cite>(Plank and Agi\u0107, 2018)</cite> . However, little is known on how complementary such additional information is, and to what extent improvements depend on the coverage and quality of these external resources.",
  "y": "motivation"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_2",
  "x": "The tagger we analyze in this paper is an extension of the base tagger, called distant supervision from disparate sources (DSDS) tagger <cite>(Plank and Agi\u0107, 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_3",
  "x": "The tagger we analyze in this paper is an extension of the base tagger, called distant supervision from disparate sources (DSDS) tagger <cite>(Plank and Agi\u0107, 2018)</cite> . It is trained on projected data and further differs from the base tagger by the integration of lexicon information.",
  "y": "extends"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_4",
  "x": "We here focus on 21 dev sets of the Universal Dependencies 2.1 (Nivre and et al., 2017) , test set results are reported by<cite> Plank and Agi\u0107 (2018)</cite> showing that DSDS provides a viable alternative.",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_5",
  "x": "Annotation projection To build the taggers for new languages, we resort to annotation projection following<cite> Plank and Agi\u0107 (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_6",
  "x": "The wide-coverage Watchtower corpus (WTC) by Agi\u0107 et al. (2016) is used, where 5k instances are selected via data selection by alignment coverage following<cite> Plank and Agi\u0107 (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_7",
  "x": "Hyperparameters We use the same setup as<cite> Plank and Agi\u0107 (2018)</cite> , i.e., 10 epochs, word dropout rate (p=.25) and l=40-dimensional lexicon embeddings for DSDS, except for downscaling the hidden dimensionality of the character representations from 100 to 32 dimensions.",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_8",
  "x": "We use the off-the-shelf Polyglot word embeddings (Al-Rfou et al., 2013) . Word embedding initialization provides a consistent and considerable boost in this cross-lingual setup, up to 10% absolute improvements across 21 languages when only 500 projected training instances are available <cite>(Plank and Agi\u0107, 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_9",
  "x": "Word embedding initialization provides a consistent and considerable boost in this cross-lingual setup, up to 10% absolute improvements across 21 languages when only 500 projected training instances are available <cite>(Plank and Agi\u0107, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_10",
  "x": "Combining the best of two worlds results in the overall best tagging accuracy, confirming<cite> Plank and Agi\u0107 (2018)</cite> : Embedding lexical information into a neural tagger improves tagging accuracy from 83.4 to 84.1 (means over 21 languages).",
  "y": "similarities"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_11",
  "x": "The lexicons we use so far are of different sizes (shown in Table 1 of<cite> Plank and Agi\u0107 (2018)</cite> ), spanning from 1,000 entries to considerable dictionaries of several hundred thousands entries.",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_12",
  "x": "Our study contributes to the increasing literature to show the utility of linguistic resources for deep learning models by providing a deep analysis of a recently proposed model <cite>(Plank and Agi\u0107, 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "8853d810b364ae47a2da71c2502b3e_13",
  "x": "We replicated the results of<cite> Plank and Agi\u0107 (2018)</cite> , showing that the more implicit use of embedding user-generated dictionaries turns out to be more beneficial than approaches that rely more explicitly on symbolic knowledge, such a type constraints or retrofitting.",
  "y": "extends uses"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_0",
  "x": "In this paper, we present a model for improved discriminative semantic parsing. The model addresses an important limitation associated with our previous stateof-the-art discriminative semantic parsing model -the <cite>relaxed hybrid tree</cite> model by introducing our constrained semantic forests.",
  "y": "differences motivation"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_1",
  "x": "One state-of-the-art model for semantic parsing is our recently introduced <cite>relaxed hybrid tree</cite> model <cite>(Lu, 2014)</cite> , which performs integrated lexicon acquisition and semantic parsing within a single framework utilizing efficient algorithms for training and inference. <cite>The model</cite> allows natural language phrases to be recursively mapped to semantic units, where certain long-distance dependencies can be captured. <cite>It</cite> relies on representations called <cite>relaxed hybrid trees</cite> that can jointly represent both the sentences and semantics. <cite>The model</cite> is essentially discriminative, and allows rich features to be incorporated.",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_2",
  "x": "One state-of-the-art model for semantic parsing is our recently introduced <cite>relaxed hybrid tree</cite> model <cite>(Lu, 2014)</cite> , which performs integrated lexicon acquisition and semantic parsing within a single framework utilizing efficient algorithms for training and inference. Unfortunately, the <cite>relaxed hybrid tree</cite> model has an important limitation: <cite>it</cite> essentially does not allow certain sentence-semantics pairs to be jointly encoded using the proposed <cite>relaxed hybrid tree</cite> representations. Thus, <cite>the model</cite> is unable to identify joint representations for certain sentence-semantics pairs during the training process, and is unable to produce desired outputs for certain inputs during the evaluation process. In this work, we propose a solution addressing the above limitation, which makes our model more robust.",
  "y": "motivation"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_3",
  "x": "Examples of such models include the WASP system (Wong and Mooney, 2006) which regards the semantic parsing problem as a statistical machine translation problem, the UBL system (Kwiatkowski et al., 2010) which performs CCG-based semantic parsing using a log-linear model, as well as the <cite>relaxed hybrid tree</cite> model <cite>(Lu, 2014)</cite> which extends the generative hybrid tree model.",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_4",
  "x": "The <cite>relaxed hybrid tree</cite> model has achieved the state-of-the-art results on standard benchmark datasets across different languages.",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_6",
  "x": "We briefly discuss our previously proposed <cite>relaxed hybrid tree</cite> model <cite>(Lu, 2014)</cite> in this section. <cite>The model</cite> is a discriminative semantic parsing model which extends the generative hybrid tree model (Lu et al., 2008) . Let us use m to denote a complete semantic representation, n to denote a complete natural language sentence, and h to denote a complete latent structure that jointly represents both m and n. <cite>The model</cite> defines the conditional probability for observing a (m, h) pair for a given natural language sentence n using a log-linear approach:",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_7",
  "x": "Typically, to limit the space of latent structures, certain assumptions have to be made to h. In our work, we assume that h must be from a space consisting of <cite>relaxed hybrid tree</cite> structures <cite>(Lu, 2014)</cite> . The <cite>relaxed hybrid trees</cite> are analogous to the hybrid trees, which was earlier introduced as a generative framework. One major distinction between these two types of representations is that the <cite>relaxed hybrid tree</cite> representations are able to capture unbounded long-distance dependencies in a principled way.",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_8",
  "x": "Figure 1 gives an example of a hybrid tree and a <cite>relaxed hybrid tree</cite> representation encoding the sentence w 1 w 2 w 3 w 4 w 5 w 6 w 7 w 8 w 9 w 10 and the se-",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_9",
  "x": "In the <cite>relaxed hybrid tree</cite>, however, each word is not only directly associated with exactly one semantic unit m, but also indirectly associated with all other semantic units that are predecessors of m. For example, the word w 3 now is directly associated with m b , but is also indirectly associated with m a . Both the hybrid tree and <cite>relaxed hybrid tree</cite> models define patterns at each level of their latent structure which specify how the words and child semantic units are organized at each level.",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_10",
  "x": "One important difference between the hybrid tree representations and the <cite>relaxed hybrid tree</cite> representations is the exclusion of the pattern X in the latter. This ensured <cite>relaxed hybrid trees</cite> with an infinite number of nodes were not considered <cite>(Lu, 2014)</cite> when computing the denominator term of Equation 1.",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_11",
  "x": "In <cite>relaxed hybrid tree</cite>, H(n, m) was implemented as a packed forest representation for exponentially many possible <cite>relaxed hybrid trees</cite> where pattern X was excluded. By allowing pattern X, we allow certain semantic units with no natural language word counter- part to exist in the joint <cite>relaxed hybrid tree</cite> representation.",
  "y": "motivation differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_13",
  "x": "When pattern X is allowed, both m a and m b are not directly associated with any natural language word, so we are able to further insert arbitrarily many (compatible) semantic units between the two units m a and m b while the resulting <cite>relaxed hybrid tree</cite> remains valid. Therefore we can construct a <cite>relaxed hybrid tree</cite> representation that contains the given natural language sentence w 1 w 2 with an infinite number of nodes.",
  "y": "motivation"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_14",
  "x": "This issue essentially prevents us from computing the denominator term of Equation 1 since it involves an infinite number of possible m and h . To eliminate <cite>relaxed hybrid trees</cite> consisting of an infinite number of nodes, pattern X is disallowed in the <cite>relaxed hybrid trees</cite> model <cite>(Lu, 2014)</cite> .",
  "y": "motivation"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_17",
  "x": "To address this limitation, we allow pattern X to be included when building our new discriminative semantic parsing model. However, as mentioned above, doing so will lead to latent structures (<cite>relaxed hybrid tree</cite> representations) of infinite heights.",
  "y": "motivation"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_18",
  "x": "Our new objective function is as follows: where M refers to the set of all possible semantic trees whose heights are less than or equal to c, and H (n, m ) refers to the set of possible <cite>relaxed hybrid tree</cite> representations where the pattern X is allowed.",
  "y": "uses motivation"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_19",
  "x": "Such a constrained semantic forest is a packed forest representation of exponentially many possible unique semantic trees, where we set the height of the forest to c. By contrast, it was not possible in our previous <cite>relaxed hybrid tree</cite> model to introduce such a compact representation over all possible semantic trees.",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_20",
  "x": "Such a constrained semantic forest is a packed forest representation of exponentially many possible unique semantic trees, where we set the height of the forest to c. By contrast, it was not possible in our previous <cite>relaxed hybrid tree</cite> model to introduce such a compact representation over all possible semantic trees. In our previous model's implementation, we directly constructed for each sentence n a different compact representation over all possible <cite>relaxed hybrid trees</cite> containing n.",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_21",
  "x": "Setting the maximum height to c effectively guarantees that all semantic trees contained in the constrained semantic forest have a height no greater than c. We then constructed the (exponentially many) <cite>relaxed hybrid tree</cite> representations based on the constrained semantic forest M and each input sentence n. We used a single packed forest representation to represent all such <cite>relaxed hybrid tree</cite> representations. This allows the computation of the denominator to be performed efficiently using similar dynamic programming algorithms described in <cite>(Lu, 2014)</cite> .",
  "y": "similarities"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_22",
  "x": "To make our system directly comparable to previous works, we used the same train/test split used in those works (Jones et al., 2012; <cite>Lu, 2014</cite>) for evaluation.",
  "y": "uses"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_23",
  "x": "Following previous works, we regarded an output semantic representation as correct if and only if it returned the same answers as the gold standard (Jones et al., 2012; <cite>Lu, 2014</cite>) .",
  "y": "uses"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_24",
  "x": "<cite>RHT</cite> <cite>(Lu, 2014)</cite> is the discriminative semantic parsing system based on <cite>relaxed hybrid trees</cite>.",
  "y": "background"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_25",
  "x": "Results showed that our system consistently yielded higher results than all the previous systems, including our state-of-the-art <cite>relaxed hybrid tree</cite> system (<cite>the full model</cite>, when all the features are used), in terms of both accuracy score and F 1 -measure.",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_26",
  "x": "We would like to highlight two potential advantages of our new model over the old <cite>RHT</cite> model. First, our model is able to handle certain sentence-semantics pairs which could not be handled by <cite>RHT</cite> during both training and evaluation as discussed in Section 3.1.",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_27",
  "x": "We note that in our experiments we used a small subset of the features used by our <cite>relaxed hybrid tree</cite> work.",
  "y": "uses"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_28",
  "x": "As we have mentioned in <cite>(Lu, 2014)</cite> , although the <cite>RHT</cite> model is able to capture unbounded long-distance dependencies, for certain languages such as German such longdistance features appeared to be detrimental to the performance of the system (<cite>Lu, 2014</cite>, Table  4 ). Here in this work, we only used simple unigram features (concatenation of a semantic unit and an individual word that appears directly below that unit in the joint representation), pattern features (concatenation of a semantic unit and the pattern below that unit) as well as transition features (concatenation of two semantic units that form a parent-child relationship) described in <cite>(Lu, 2014)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_29",
  "x": "We summarized in Table 3 the number of features used in both the previous <cite>RHT</cite> system and our system across four different languages. It can be seen that our system only required about 2-3% of the Table 3 : Number of features involved for both the <cite>RHT</cite> system and our new system using constrained semantic forests, across four different languages.",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_30",
  "x": "We also note that the training time for our model is longer than that of the <cite>relaxed hybrid tree</cite> model since the space for H (n, m ) is now much larger than the space for H(n, m ).",
  "y": "differences"
 },
 {
  "id": "88aca1aa7ab73cde8492adc0e7a059_31",
  "x": "In practice, to make the overall training process faster, we implemented a parallel version of the original <cite>RHT</cite> algorithm.",
  "y": "uses"
 },
 {
  "id": "8905d5936a5b2a839bfd56783ff55d_0",
  "x": "In subsequent work, we showed that we could augment the E2E training data with synthetically generated stylistic variants and train a neural generator to reproduce these variants, however the models can still only generate what they have seen in training<cite> [5]</cite> .",
  "y": "background"
 },
 {
  "id": "8905d5936a5b2a839bfd56783ff55d_1",
  "x": "The PERSONAGE corpus<cite> [5]</cite> provides a controlled environment for testing different models of neural generation and style generation.",
  "y": "uses"
 },
 {
  "id": "8905d5936a5b2a839bfd56783ff55d_2",
  "x": "Previous work shows that a simple model trained on the whole corpus of 88,855 utterances produces semantically correct outputs, but with reduced stylistic variation<cite> [5]</cite> , while a model that allocates a variable corresponding to a label for each style learns to reproduce the stylistic variation.",
  "y": "differences background"
 },
 {
  "id": "8905d5936a5b2a839bfd56783ff55d_3",
  "x": "Our NNLG model uses a single token to represent personality encoding, following the use of single language labels used in machine translation and other work on neural generation [10, <cite>5]</cite> .",
  "y": "uses"
 },
 {
  "id": "8905d5936a5b2a839bfd56783ff55d_4",
  "x": "Our model differs from the TO-KEN model used in our previous work<cite> [5]</cite> because it is trained on unsorted inputs to allow us to add multiple CONVERT tags to the MR at generation time.",
  "y": "differences"
 },
 {
  "id": "8905d5936a5b2a839bfd56783ff55d_5",
  "x": "Natural language generators for task-oriented dialog should be able to vary the style of the output while still effectively realizing the system dialog actions and their associated semantics. The use of neural natural language generation (NNLG) for training the response generation component of conversational agents promises to simplify the process of producing high quality responses in new domains by relying on the neural architecture to automatically learn how to map an input meaning representation to an output utterance. However, there has been little investigation of NNLGs for dialog that can vary their response style, and we know of no experiments on models that can generate responses that are different in style from those seen during training, while still maintaining semantic fidelity to the input meaning representation. Instead, work on stylistic transfer has focused on tasks where only coarse-grained semantic fidelity is needed, such as controlling the sentiment of the utterance (positive or negative), or the topic or entity under discussion [1, 2, 3] . Consider for example a training instance for the restaurant domain consisting of a meaning representation (MR) from the End-to-End (E2E) Generation Challenge 1 and a sample output from one of our neural generation models in Figure 1 [4, <cite>5]</cite> .",
  "y": "background"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_0",
  "x": "One interesting aspect of using a global model with beam-search is that it narrows down the contrast between \"local, greedy, transition-based parsing\" and \"global, exhaustive, graph-based parsing\" as exemplified by<cite> McDonald and Nivre (2007)</cite> .",
  "y": "background"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_1",
  "x": "We follow<cite> McDonald and Nivre (2007)</cite> and perform a comparative error analysis of ZPar, MSTParser and MaltParser using the CoNLL-X shared task data.",
  "y": "uses"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_2",
  "x": "We characterize the errors of ZPar and add it to the error comparison between MaltParser and MSTParser <cite>(McDonald and Nivre, 2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_3",
  "x": "Following<cite> McDonald and Nivre (2007)</cite> we evaluate the parsers on the CoNLL-X Shared Task data (Buchholz and Marsi, 2006) , which include training and test sentences for 13 different languages.",
  "y": "uses"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_4",
  "x": "For each parser, we conjoin the outputs for all 13 languages in the same way as<cite> McDonald and Nivre (2007)</cite> , and calculate error distributions over the aggregated output.",
  "y": "uses"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_5",
  "x": "Another important reason, as pointed out by<cite> McDonald and Nivre (2007)</cite> , is the default single-root mechanism by MaltParser: all words that have not been attached as a modifier when the shift-reduce process finishes are attached as modifiers to the pseudo-root.",
  "y": "background"
 },
 {
  "id": "89b2b492b4319636ff2f28a4ba0d95_6",
  "x": "Here the precision of MaltParser and MSTParser is very different, with MaltParser being more precise for arcs nearer to the leaves, but less precise for those nearer to the root. One possible reason is that arcs near the bottom of the tree require comparatively fewer shift-reduce actions to build, and are therefore less prone to the propagation of search errors. Another important reason, as pointed out by<cite> McDonald and Nivre (2007)</cite> , is the default single-root mechanism by MaltParser: all words that have not been attached as a modifier when the shift-reduce process finishes are attached as modifiers to the pseudo-root.",
  "y": "similarities background"
 },
 {
  "id": "8a8670fd7cfb8db9ddd3f546ce4534_0",
  "x": "However, many agreement studies have restricted annotators to using a single sense, which can significantly lower inter-annotator agreement (IAA) in the presence of ambiguous or polysemous usages; indeed, multiple studies have shown that when allowed, annotators readily assign multiple senses to a single usage (V\u00e9ronis, 1998; Murray and Green, 2004; <cite>Erk et al., 2009</cite>; Passonneau et al., 2012b) .",
  "y": "background motivation"
 },
 {
  "id": "8a8670fd7cfb8db9ddd3f546ce4534_1",
  "x": "Furthermore, we adopt the goal of<cite> Erk et al. (2009)</cite> , which enabled annotators to weight each sense by its applicability to the given context, thereby quantifying the ambiguity.",
  "y": "similarities"
 },
 {
  "id": "8a8670fd7cfb8db9ddd3f546ce4534_3",
  "x": "We adopt the annotation guidelines of<cite> Erk et al. (2009)</cite> which used a five-point scale, ranging from 1 to 5, indicating the sense does not apply or that it matches the contextual usage exactly, respectively.",
  "y": "uses"
 },
 {
  "id": "8a8670fd7cfb8db9ddd3f546ce4534_4",
  "x": "MaxDiff MaxDiff is an alternative to scale-based ratings in which Turkers are presented with a only subset of all of a word's senses and then asked to select (1) the sense option that best matches the mean-add.v ask.v win.v argument.n interest.n paper.n different.a important.a<cite> Erk et al. (2009)</cite> ing in the example context and (2) the sense option that least matches (Louviere, 1991) .",
  "y": "uses"
 },
 {
  "id": "8a8670fd7cfb8db9ddd3f546ce4534_5",
  "x": "For the reference sense labeling, we use a subset of the GWS dataset of<cite> Erk et al. (2009)</cite> , where three annotators rated 50 instances each for eight words.",
  "y": "uses"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_0",
  "x": "Most rely on convolutional neural nets (Zeng et al., 2014 (Zeng et al., , 2015 Grishman, 2015, 2016;<cite> Fu et al., 2017)</cite> or recurrent neural nets (Zhang et al., 2015; Zhou et al., 2016; Miwa and Bansal, 2016) to learn the representation of relations.",
  "y": "background"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_1",
  "x": "Our initial experiments did not use syntactic features (Nguyen and Grishman, 2016;<cite> Fu et al., 2017</cite> ) that require additional parsers.",
  "y": "differences"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_2",
  "x": "The supervised neural model on a single dataset was introduced by Zeng et al. (2014) and followed by many others (Nguyen and Grishman, 2015; Zhou et al., 2016; Miwa and Bansal, 2016; Nguyen and Grishman, 2016;<cite> Fu et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_3",
  "x": "Some work (Nguyen and Grishman, 2016;<cite> Fu et al., 2017)</cite> used extra syntax features as input.",
  "y": "background"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_4",
  "x": "The entity embedding (Nguyen and Grishman, 2016;<cite> Fu et al., 2017</cite> ) is included for arguments that are entities rather than common nouns.",
  "y": "similarities"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_5",
  "x": "It usually contains one hidden layer (Zeng et al., 2014; Nguyen and Grishman, 2016;<cite> Fu et al., 2017</cite> ) and a softmax output layer.",
  "y": "background"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_6",
  "x": "Previous work (Gormley et al., 2015; Nguyen and Grishman, 2016;<cite> Fu et al., 2017)</cite> set, and the other half of bc, cts and wl as the test sets.",
  "y": "background"
 },
 {
  "id": "8ca479895b028ea6dedb0e99cacae6_7",
  "x": "With syntactic features as (Nguyen and Grishman, 2016;<cite> Fu et al., 2017)</cite> did, it could be further improved.",
  "y": "future_work"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_0",
  "x": "Evaluated on a recent large scale dataset<cite> (Hermann et al., 2015)</cite> , our model exhibits better results than previous research, and we find that max-pooling is suited for modeling the accumulation of information on entities.",
  "y": "uses"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_1",
  "x": "Recently, large scale datasets of document-queryanswer triples have been constructed from online newspaper articles and their summaries<cite> (Hermann et al., 2015)</cite> , by replacing named entities in the summaries with placeholders to form Cloze (Taylor, 1953 ) style questions ( Figure 1 ).",
  "y": "background"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_2",
  "x": "These datasets have enabled training and testing of complicated neural network models of hypothesized machine readers<cite> (Hermann et al., 2015</cite>; Hill et al., 2015) .",
  "y": "background"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_3",
  "x": "This insight has been reflected by the anonymization process in construction of the dataset, in which coreferent entities (e.g. \"Robert Downey Jr.\" and \"Downey\") are replaced by randomly permuted abstract entity markers (e.g. \"@en-tity0\"), in order to prevent additional world knowledge from being attached to the surface form of the entities<cite> (Hermann et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_4",
  "x": "This insight has been reflected by the anonymization process in construction of the dataset, in which coreferent entities (e.g. \"Robert Downey Jr.\" and \"Downey\") are replaced by randomly permuted abstract entity markers (e.g. \"@en-tity0\"), in order to prevent additional world knowledge from being attached to the surface form of the entities<cite> (Hermann et al., 2015)</cite> . We, however, take it as a strong motivation to implement a reader that dynamically builds meaning representations for each entity, by gathering and accumulating information on that entity as it reads a document (Section 2).",
  "y": "motivation"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_5",
  "x": "Following<cite> Hermann et al. (2015)</cite> , our model estimates the conditional probability p(e|D, q), where q is a query and D is a document.",
  "y": "uses"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_6",
  "x": "in which u(q) is the learned meaning for the query and v(e; D, q) the dynamically constructed meaning for an entity, depending on the document D and the query q. We note that (1) is in contrast to the factorization used by<cite> Hermann et al. (2015)</cite>:",
  "y": "differences"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_7",
  "x": "We use the CNN-QA dataset<cite> (Hermann et al., 2015)</cite> for evaluating our model's ability to answer questions about named entities.",
  "y": "uses"
 },
 {
  "id": "91723cf7f22ba6405c85a929ac2d8e_8",
  "x": "Finally, we note that our model, full DER Network, shows the best results compared to several previous reader models<cite> (Hermann et al., 2015</cite>; Hill et al., 2015) , endorsing our approach as promising.",
  "y": "differences"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_0",
  "x": "To effectively incorporate KB information and perform knowledge- * Corresponding Author based reasoning, memory augmented models have been proposed (Bordes et al., 2017; Seo et al., 2017; Eric and Manning, 2017b; <cite>Madotto et al., 2018</cite>; Raghu et al., 2018; Reddy et al., 2019; Wu et al., 2019) .",
  "y": "background"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_1",
  "x": "We omit the subscript E or S 2 , following <cite>Madotto et al. (2018)</cite> to define each pointer index set:",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_2",
  "x": "Symbol Definition xi or yi a token in the dialog history or system response $ a special token used as a sentinel <cite>(Madotto et al., 2018 )</cite> X X = {x1, . . . , xn, $}, the dialog history Y Y = {y1, \u00b7 \u00b7 \u00b7 , ym}, the expected response bi one KB tuple, actually the corresponding entity B B = {b1, \u00b7 \u00b7 \u00b7 , b l , $}, the KB tuples P T RE = {ptrE,1, \u00b7 \u00b7 \u00b7 , ptrE,m}, dialog pointer index set.",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_3",
  "x": "We also incorporate additional temporal information and speaker information into dialog utterances as <cite>(Madotto et al., 2018)</cite> and adopt a (subject, relation, object) representation of KB information as (Eric and Manning, 2017b) .",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_4",
  "x": "We here use a rule-based word selection strategy by extending the sentinel idea in <cite>(Madotto et al., 2018)</cite> , which is shown in Figure 1 .",
  "y": "extends"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_5",
  "x": "We use Per-response/dialog Accuracy (Bordes et al., 2017) , BLEU (Papineni et al., 2002) and Entity F1 <cite>(Madotto et al., 2018)</cite> to compare the performance of different models.",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_6",
  "x": "And the baseline models are Seq2Seq+Attn (Luong et al., 2015) , Pointer to Unknown (Ptr-Unk, Gulcehre et al. (2016) ), <cite>Mem2Seq</cite> <cite>(Madotto et al., 2018)</cite> , Hierarchical Pointer Generator Memory Network (HyP-MN, Raghu et al. (2018) ) and Global-to-Local Memory Pointer (GLMP, Wu et al. (2019) ).",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_7",
  "x": "Second, we find that WMM2Seq outperforms <cite>Mem2Seq</cite>, which uses a unified memory to store dialog history and KB information.",
  "y": "differences"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_8",
  "x": "We can safely conclude that the separation of context memory and KB memory benefits the performance, as WMM2Seq performs well with less parameters than <cite>Mem2Seq</cite> on task 5.",
  "y": "extends differences"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_9",
  "x": "Though multi-hop attention strengthens the reasoning ability and improves the results, we find that the performance difference between the hops K = 1 and K = 3 is not so obvious as shown in <cite>(Madotto et al., 2018</cite>; Wu et al., 2019) .",
  "y": "differences"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_10",
  "x": "We adopt <cite>Mem2Seq</cite> as the baseline for human evaluation considering its good performance and code release 3 .",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_11",
  "x": "First we randomly select 100 samples from the DSTC2 test set, then generate the corresponding responses using WMM2Seq and <cite>Mem2Seq</cite>, and finally ask two human subjects to judge the quality of the generated responses according to the appropriateness and humanlikeness on a scale from 1 to 5.",
  "y": "uses"
 },
 {
  "id": "91c82c4a49815fb2de300d99312754_12",
  "x": "As shown in Table 4 , WMM2Seq outperforms <cite>Mem2Seq</cite> in both measures, which is coherent to the automatic evaluation.",
  "y": "differences"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_0",
  "x": "BLEU has also been applied to monolingual translation tasks, such as grammatical error correction (Park and Levy, 2011) , summarization (Graham, 2015) and text simplification (Narayan and Gardent, 2014; Stajner et al., 2015;<cite> Xu et al., 2016)</cite> , i.e. the rewriting of a sentence as one or more simpler sentences.",
  "y": "background"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_1",
  "x": "Indeed, focusing on lexical simplification,<cite> Xu et al. (2016)</cite> argued that BLEU gives high scores to sentences that are close or even identical to the input, especially when multiple references are used.",
  "y": "background"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_2",
  "x": "First, we experiment with the most common set, proposed by<cite> Xu et al. (2016)</cite> , evaluating a variety of system outputs, as well as HSplit.",
  "y": "uses"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_3",
  "x": "While BLEU is standardly used for TS evaluation (e.g.,<cite> Xu et al., 2016</cite>; Nisioi et al., 2017; Zhang and Lapata, 2017; Ma and Sun, 2017 ), only few works tested its correlation with human judgments.",
  "y": "motivation"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_4",
  "x": "We use the complex side of the test corpus of<cite> Xu et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_5",
  "x": "3 While Narayan et al. (2017) recently proposed the semi-automatically compiled WEB-SPLIT dataset for training automatic sentence splitting systems, here we generate a completely manual corpus, without a-priori splitting points nor do we pre-suppose that all sentences should be split. This corpus enriches the set of references focused on lexical operations that were collected by<cite> Xu et al. (2016)</cite> for the same source sentences and can also be used as an out-of-domain test set for Split-and-Rephrase (Narayan et al., 2017) .",
  "y": "extends"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_6",
  "x": "In addition to BLEU, 7 we also experiment with (1) iBLEU (Sun and Zhou, 2012) which was recently used for TS <cite>(Xu et al., 2016</cite>; and which takes into account the BLEU scores of the output against the input and against the references; (2) the Flesch-Kincaid Grade Level (FK; Kincaid et al., 1975 ), computed at the system level, which estimates the readability of the text with a lower value indicating higher 4 Examples are taken from Siddharthan (2006) .",
  "y": "background"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_7",
  "x": "Metrics. 7 System-level BLEU scores are computed using the multi-bleu Moses support tool. Sentence-level BLEU scores are computed using NLTK (Loper and Bird, 2002). readability; 8 (3) SARI<cite> (Xu et al., 2016)</cite> , which compares the n-grams of the system output with those of the input and the human references, separately evaluating the quality of words that are added, deleted and kept by the systems.",
  "y": "uses"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_8",
  "x": "10 We further include Moses (Koehn et al., 2007) and SBMT-SARI<cite> (Xu et al., 2016)</cite> , a syntax-based MT system tuned against SARI, and the identity function (outputs are same as inputs).",
  "y": "uses"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_9",
  "x": "In one (\"Standard Reference Setting\", \u00a74.2), we use two sets of references: the Simple Wikipedia reference (yielding BLEU-1ref and iBLEU-1ref), and 8 references obtained by crowdsourcing by<cite> Xu et al. (2016)</cite> (yielding BLEU-8ref, iBLEU-8ref and SARI-8ref).",
  "y": "uses"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_10",
  "x": "We use the evaluation benchmark provided by Sulem et al. (2018b) , 11 including system outputs and human evaluation scores corresponding to the first 70 sentences of the test corpus of<cite> Xu et al. (2016)</cite> , and extend it to apply to HSplit as well.",
  "y": "uses"
 },
 {
  "id": "91e869971f139d90e36f73b1089877_11",
  "x": "12 The high scores obtained for Identity, also observed by<cite> Xu et al. (2016)</cite> , indicate that BLEU is a not a good predictor for relative simplicity to the input.",
  "y": "similarities"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_0",
  "x": "Social media are under pressure to combat abusive content, but so far rely mostly on user reports and tools that detect frequent words and phrases of reported posts. 2<cite> Wulczyn et al. (2017)</cite> estimated that only 17.9% of personal attacks in Wikipedia discussions were followed by moderator actions.",
  "y": "background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_1",
  "x": "Furthermore, we experiment on the 'attacks' dataset of<cite> Wulczyn et al. (2017)</cite> , approx. 115K English Wikipedia talk page comments labeled as containing personal attacks or not.",
  "y": "uses"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_3",
  "x": "Krippendorff's (2004) alpha was 0.4762, close to the value (0.45) reported by<cite> Wulczyn et al. (2017)</cite> for the Wikipedia 'attacks' dataset.",
  "y": "background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_4",
  "x": "The Wikipedia 'attacks' dataset <cite>(Wulczyn et al., 2017)</cite> contains approx. 115K English Wikipedia talk page comments, which were labeled as containing personal attacks or not. Each comment was labeled by at least 10 annotators. Inter-annotator agreement, measured on a random sample of 1K comments using Krippendorff's (2004) alpha, was 0.45. The gold label of each comment is determined by the majority of annotators, leading to binary labels (accept, reject). Alternatively, the gold label is the percentage of annotators that labeled the comment as 'accept' (or 'reject'), leading to probabilistic labels. 7 The dataset is split in three parts (Table 1) : training (W-ATT-TRAIN, 69,526 comments), development (W-ATT-DEV, 23,160), and test (W-ATT-TEST, 23,178). In all three parts, the rejected comments are 12%, but this is an artificial ratio (Wulczyn et al. oversampled comments posted by banned users). By contrast, the ratio of rejected comments in all the Gazzetta subsets is the truly observed one. The Wikipedia comments are also longer (median length 38 tokens) compared to Gazzetta's (median length 25 tokens).",
  "y": "background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_5",
  "x": [
   "Wulczyn et al. (2017) also provide two additional datasets of English Wikipedia talk page comments, which are not used in this paper. The first one, called 'aggression' dataset, contains the same comments as the 'attacks' dataset, now labeled as 'aggressive' or not. The (probabilistic) labels of the 'attacks' and 'aggression' datasets are very highly correlated (0.8992 Spearman, 0.9718 Pearson) and we did not consider the aggression dataset any further. The second additional dataset, called 'toxicity' dataset, contains approx. 160K comments labeled as being toxic or not."
  ],
  "y": "background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_6",
  "x": "We experimented with an RNN operating on word embeddings, the same RNN enhanced with our attention mechanism (a-RNN), a vanilla convolutional neural network (CNN) also operating on word embeddings, the DETOX system of<cite> Wulczyn et al. (2017)</cite> , and a baseline that uses word lists.",
  "y": "uses"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_7",
  "x": "DETOX <cite>(Wulczyn et al., 2017)</cite> was the previous state of the art in comment moderation, in the sense that it had the best reported results on the Wikipedia datasets (Section 2.2), which were in turn the largest previous publicly available dataset of moderated user comments. 8 DETOX represents each comment as a bag of word n-grams (n \u2264 2, each comment becomes a bag containing its 1-grams and 2-grams) or a bag of character n-grams (n \u2264 5, each comment becomes a bag containing character 1-grams, . . . , 5-grams). DETOX can rely on a logistic regression (LR) or MLP classifier, and it can use binary or probabilistic gold labels (Section 2.2) during training.",
  "y": "background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_8",
  "x": [
   "We used the DETOX implementation provided by Wulczyn et al. and the same grid search (and code) to tune the hyper-parameters of DETOX that select word or character n-grams, classifier (LR or MLP), and gold labels (binary or probabilistic)."
  ],
  "y": "uses"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_9",
  "x": [
   "Unlike Wulczyn et al., we tuned the hyper-parameters by evaluating (computing AUC and Spearman, Section 4) on a random 2% of held-out comments of W-ATT-TRAIN or G-TRAIN-S, instead of the development subsets, to be able to obtain more realistic results from the development sets while developing the methods."
  ],
  "y": "differences"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_12",
  "x": "Scores reported by<cite> Wulczyn et al. (2017)</cite> are shown in brackets.",
  "y": "background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_13",
  "x": "We also repeated the annotator ensemble experiment of<cite> Wulczyn et al. (2017)</cite> on 8K randomly chosen comments of W-ATT-TEST (4K comments from random users, 4K comments from banned users). 19 The decisions of 10 randomly chosen annotators (possibly different per comment) were used to construct the gold label of each comment. The gold labels were then compared to the decisions of the systems and the decisions of an ensemble of k other annotators, k ranging from 1 to 10.",
  "y": "uses background"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_14",
  "x": "We conclude that RNN and a-RNN are as good as an ensemble of 7 human annotators; CNN is as good as 4 annotators; DETOX is as good as 4 in AUC and 3 annotators in Spearman correlation, which is consistent with the results of<cite> Wulczyn et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "920f2b94270c0711fcc19ad23dbb0d_15",
  "x": [
   "Wulczyn et al. (2017) experimented with character and word n-grams. We included their dataset and moderation system (DETOX) in our experiments."
  ],
  "y": "similarities uses"
 },
 {
  "id": "929020618e8e1daa6a769f552a4655_0",
  "x": "Models proposed by Vajjala and Meurers [17] , Xia et al. <cite>[18]</cite> , and Mohammadi and Khasteh [19] are examples of state-of-the-art models for their target languages and target audience.",
  "y": "background"
 },
 {
  "id": "929020618e8e1daa6a769f552a4655_1",
  "x": "Xia et al. <cite>[18]</cite> has published a thorough study on second language text readability assessment.",
  "y": "background"
 },
 {
  "id": "929020618e8e1daa6a769f552a4655_2",
  "x": "To examine the proposed DRL model regarding this ability, it is applied to the Cambridge Exams dataset <cite>[18]</cite> .",
  "y": "uses"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_0",
  "x": "While incorporating existing knowledge (from curated knowledge bases) for the purpose of question-answering [12, 9, 16] is an important area of research, we consider the simpler setting where all the information is contained within the text itself -which is the approach taken by many recent memory based neural network models [17, <cite>18</cite>, 19, 20] .",
  "y": "background motivation"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_1",
  "x": "Recently, Henaff et. al. <cite>[18]</cite> proposed a dynamic memory based neural network for implicitly modeling the state of entities present in the text for question answering. However, <cite>this model</cite> lacks any module for relational reasoning.",
  "y": "motivation"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_2",
  "x": "However, <cite>this model</cite> lacks any module for relational reasoning. In response, we propose RelNet, which extends memoryaugmented neural networks with a relational memory to reason about relationships between multiple entities present within the text.",
  "y": "motivation"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_3",
  "x": "We demonstrate the utility of the model through experiments on the bAbI tasks [19] and find that the model achieves smaller mean error across the tasks than the best previously published result [<cite>18</cite>] in the 10k examples regime and achieves 0% error on 11 of the 20 tasks.",
  "y": "differences"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_4",
  "x": "We model the dynamic memory in a fashion similar to <cite>Recurrent Entity Networks</cite> [<cite>18</cite>] and then equip it with an additional relational memory.",
  "y": "extends similarities"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_5",
  "x": "The input encoder and output module implementations are similar to the <cite>Entity Network</cite> [<cite>18</cite>] and main novelty lies in the dynamic memory.",
  "y": "extends similarities"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_6",
  "x": "We use a simple encoder with a learned multiplicative mask [<cite>18</cite>, 17] :",
  "y": "uses"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_7",
  "x": "Indeed, Henaff et. al. <cite>[18]</cite> found that if <cite>they</cite> tie the key vectors to entities in the text then the memories contain information about the state of those entities.",
  "y": "background"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_8",
  "x": "Note that there can be multiple entites in a sentence hence a sigmoid operation is more suitable, and it is also more scalable <cite>[18]</cite> .",
  "y": "background"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_9",
  "x": "Similar to [<cite>18</cite>] , we normalize the memories after each update step (that is after reading each sentence).",
  "y": "similarities"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_10",
  "x": "Output Module This is a standard attention module used in memory networks [17, <cite>18</cite>] .",
  "y": "similarities"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_11",
  "x": "Recent successful approaches use memory based neural networks for question answering [24, 19, 25, 20, <cite>18</cite>] .",
  "y": "background"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_12",
  "x": "As described previously, the model is closely related to the <cite>Recurrent Entity Networks</cite> model [<cite>18</cite>] which describes an end-to-end approach to model entities in text but does not directly model relations.",
  "y": "background"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_14",
  "x": "We keep all other details similar to <cite>[18]</cite> for a fair comparison.",
  "y": "similarities"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_15",
  "x": "The baseline <cite>EntNet</cite> model was run for 10 times for each task <cite>[18]</cite> .",
  "y": "similarities"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_16",
  "x": "The RelNet model achieves a mean error of 0.285% across tasks which is better than the results of the <cite>EntNet</cite> model <cite>[18]</cite> .",
  "y": "differences"
 },
 {
  "id": "92f4cc0d6516a19a860d5b9af80f59_17",
  "x": "The RelNet model is able to achieve 0% test error on 11 of the tasks, whereas the <cite>EntNet</cite> model achieves 0% error on 7 of the tasks.",
  "y": "differences"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_0",
  "x": "While relatively new, the seq2seq approach has achieved state-of-the-art results in not only its original application -machine translation - (Luong et al., 2015b; Jean et al., 2015a; Luong et al., 2015a; Jean et al., 2015b; Luong & Manning, 2015) , but also image caption generation , and constituency parsing<cite> (Vinyals et al., 2015a)</cite> .",
  "y": "background"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_1",
  "x": "While relatively new, the seq2seq approach has achieved state-of-the-art results in not only its original application -machine translation - (Luong et al., 2015b; Jean et al., 2015a; Luong et al., 2015a; Jean et al., 2015b; Luong & Manning, 2015) , but also image caption generation , and constituency parsing<cite> (Vinyals et al., 2015a)</cite> . Despite the popularity of multi-task learning and sequence to sequence learning, there has been little work in combining MTL with seq2seq learning.",
  "y": "motivation"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_2",
  "x": "We show that syntactic parsing and image caption generation improves the translation quality between English (Sutskever et al., 2014) and (right) constituent parsing<cite> (Vinyals et al., 2015a)</cite> .",
  "y": "differences"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_3",
  "x": "Recent work such as Jean et al., 2015a; Luong et al., 2015a; <cite>Vinyals et al., 2015a)</cite> has found that it is crucial to empower seq2seq models with the attention mechanism.",
  "y": "background"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_5",
  "x": "For constituency parsing, we experiment with two types of corpora: 1. a small corpus -the widely used Penn Tree Bank (PTB) dataset (Marcus et al., 1993) and, 2. a large corpus -the high-confidence (HC) parse trees provided by<cite> Vinyals et al. (2015a)</cite> .",
  "y": "uses"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_6",
  "x": "Note also that the parse trees have been linearized following<cite> Vinyals et al. (2015a)</cite> .",
  "y": "uses"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_7",
  "x": "Since the parsing task maps from a sequence of English words to a sequence of parsing tags<cite> (Vinyals et al., 2015a)</cite> , only the encoder can be shared with an English\u2192German translation task.",
  "y": "background"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_8",
  "x": "For parsing, as<cite> Vinyals et al. (2015a)</cite> have shown that attention is crucial to achieve good parsing performance when training on the small PTB corpus, we do not set a high bar for our attention-free systems in this setup (better performances are reported in Section 4.3.3). Nevertheless, the parsing results in Table 2 indicate that MTL is also beneficial for parsing, yielding an improvement of up to +8.9 F 1 points over the baseline.",
  "y": "similarities"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_9",
  "x": "Instead of using the small Penn Tree Bank corpus, we consider a large parsing resource, the high-confidence (HC) corpus, which is provided by<cite> Vinyals et al. (2015a)</cite> .",
  "y": "uses"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_10",
  "x": "Our models are compared against the best attention-based systems in<cite> (Vinyals et al., 2015a)</cite> , including the state-of-the-art result of 92.8 F 1 .",
  "y": "uses"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_11",
  "x": "7 Second, our baseline system can obtain a very competitive F 1 score of 92.2, rivaling<cite> Vinyals et al. (2015a)</cite> 's systems.",
  "y": "similarities"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_12",
  "x": "This is rather surprising since our models do not use any attention mechanism. A closer look into these models reveal that there seems to be an architectural difference:<cite> Vinyals et al. (2015a)</cite> use 3-layer LSTM with 256 cells and 512-dimensional embeddings; whereas our models use 4-layer LSTM with 1000 cells and 1000-dimensional embeddings.",
  "y": "differences"
 },
 {
  "id": "9426b2faf2ba633033c7dfcee4118b_13",
  "x": "At the mixing ratio of 0.05, we obtain a non-negligible boost of 0.2 F 1 over the baseline and with 92.4 F 1 , our multi-task system is on par with the best single system reported in<cite> (Vinyals et al., 2015a)</cite> .",
  "y": "similarities"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_0",
  "x": "In recent work, <cite>we</cite> showed (<cite>Zapirain et al., 2009</cite> ) how automatically generated selectional preferences (SP) for verbs were able to perform better than pure lexical features in a role classification experiment, disconnected from a full-fledged SRL system.",
  "y": "background"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_1",
  "x": "In this paper we advance (<cite>Zapirain et al., 2009</cite>) in two directions: (1) We learn separate SPs for prepositions and verbs, showing improvement over using SPs for verbs alone.",
  "y": "extends"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_2",
  "x": "In recent work, <cite>we</cite> showed (<cite>Zapirain et al., 2009</cite> ) how automatically generated selectional preferences (SP) for verbs were able to perform better than pure lexical features in a role classification experiment, disconnected from a full-fledged SRL system. SPs introduce semantic generalizations on the type of arguments preferred by the predicates and, thus, they are expected to improve results on infrequent and unknown words. The positive effect was especially relevant for out-of-domain data.",
  "y": "motivation"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_3",
  "x": "More recently, <cite>we</cite> showed (<cite>Zapirain et al., 2009</cite> ) that several methods to automatically generate SPs generalize well and outperform lexical match in a large dataset for semantic role classification, but the impact on a full system was not explored.",
  "y": "motivation background"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_4",
  "x": "In this work we apply a subset of the SP methods proposed in (<cite>Zapirain et al., 2009</cite> ).",
  "y": "extends"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_5",
  "x": "WordNet-based similarity: One of the models that we used is based on Resnik's similarity measure (1993), referring to it as res. The other model is an in-house method (<cite>Zapirain et al., 2009</cite> ), referred as <cite>wn</cite>, which only takes into account the depth of the most common ancestor, and returns SPs that are as specific as possible. Distributional similarity: Following (<cite>Zapirain et al., 2009</cite>) we considered both first order and second order similarity.",
  "y": "uses"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_6",
  "x": "In <cite>our previous work</cite> (<cite>Zapirain et al., 2009</cite> ), we modelled SPs for pairs of predicates (verbs) and arguments, independently of the fact that the argument is a core argument (typically a noun) or an adjunct argument (typically a prepositional phrase).",
  "y": "background"
 },
 {
  "id": "9567cb276162a6e9d445f13f06f5a2_7",
  "x": "In <cite>our previous work</cite> (<cite>Zapirain et al., 2009</cite> ), we modelled SPs for pairs of predicates (verbs) and arguments, independently of the fact that the argument is a core argument (typically a noun) or an adjunct argument (typically a prepositional phrase). In contrast, (Litkowski and Hargraves, 2005) show that prepositions have SPs of their own, especially when functioning as adjuncts. We therefore decided to split SPs according to whether the potential argument is a Prepositional Phrase (PP) or a Noun Phrase (NP).",
  "y": "extends differences"
 },
 {
  "id": "9666fd26c7e9a02505ff26a687076d_0",
  "x": "<cite>Dyer et al. (2013)</cite> present a simple reparameterization of IBM Model 2 that is very fast to train, and achieves results similar to IBM Model 4.",
  "y": "background"
 },
 {
  "id": "9666fd26c7e9a02505ff26a687076d_1",
  "x": "However, using the reparameterization in<cite> (Dyer et al., 2013)</cite> would leave the model simple enough even with a relatively large amount of word classes.",
  "y": "background"
 },
 {
  "id": "9666fd26c7e9a02505ff26a687076d_2",
  "x": "We make use of a modified version of Model 2, from <cite>Dyer et al. (2013)</cite> , which has an alignment model that is parameterised in its original form solely on the variable \u03bb.",
  "y": "extends"
 },
 {
  "id": "9666fd26c7e9a02505ff26a687076d_3",
  "x": "As the partition function (Z(\u00b7)) used in<cite> (Dyer et al., 2013)</cite> consists of 2 calculations for each target position i, one for above and one for below the diagonal, we can simply substitute \u03b3 for the geometric series calculations in order to use different parameters for each:",
  "y": "background"
 },
 {
  "id": "9666fd26c7e9a02505ff26a687076d_4",
  "x": "This is not done in the current work however, so timing results will not be directly comparable to those found in<cite> (Dyer et al., 2013)</cite> .",
  "y": "differences"
 },
 {
  "id": "9666fd26c7e9a02505ff26a687076d_5",
  "x": "We use similar corpora as used in<cite> (Dyer et al., 2013)</cite> : a French-English corpus made up of Europarl version 7 and news-commentary corpora, the ArabicEnglish parallel data consisting of the non-UN portions of the NIST training corpora, and the FBIS Chinese-English corpora.",
  "y": "similarities"
 },
 {
  "id": "9770f647c0b406462f4b941f136748_0",
  "x": "The main limitation of their algorithm is that it was developed specifically for adjectives and that the question of its application to other grammatical categories has not been solved <cite>(Turney & Littman, 2003)</cite> .",
  "y": "motivation"
 },
 {
  "id": "9770f647c0b406462f4b941f136748_1",
  "x": "The technique proposed by<cite> Turney and Littman (2003)</cite> tries to infer semantic orientation from semantic association in a corpus.",
  "y": "background"
 },
 {
  "id": "9770f647c0b406462f4b941f136748_3",
  "x": "The two techniques described above were used in this experiment. The fourteen SO-LSA benchmarks chosen by<cite> Turney and Littman (2003)</cite> were translated into 2 Each sentence was automatically modified so as to replace the name and the description of the function of every individual by a generic first name of adequate sex (Mary, John, etc.) in order to prevent the judges being influenced by their prior positive or negative opinion about these people.",
  "y": "similarities"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_0",
  "x": "In particular, the technique proposed by <cite>Yuan et al. (2016)</cite> returned state-of-the-art performance in several benchmarks, but neither the training data nor the source code was released.",
  "y": "background"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_1",
  "x": "In particular, the technique proposed by <cite>Yuan et al. (2016)</cite> returned state-of-the-art performance in several benchmarks, but neither the training data nor the source code was released. This paper presents the results of a reproduction study and analysis of this technique using only openly available datasets (GigaWord, SemCor, OMSTI) and software (TensorFlow).",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_2",
  "x": "Our study showed that similar results can be obtained with much less data than hinted at by <cite>Yuan et al. (2016)</cite> .",
  "y": "differences"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_3",
  "x": "Among the best-performing ones is the approach by <cite>Yuan et al. (2016)</cite> , in which an LSTM language model trained on a corpus with 100 billion tokens was coupled with small sense-annotated datasets to achieve state-of-the-art performance in all-words WSD.",
  "y": "background"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_4",
  "x": "Even though the results obtained by <cite>Yuan et al. (2016)</cite> outperform the previous state-of-the-art, neither the used datasets nor the constructed models are available to the community. This is unfortunate because this makes the re-application of this technique a non-trivial process, and it hinders further studies for understanding which limitations prevent even higher accuracies. These could be, for instance, of algorithmic nature or relate to the input (either size or quality), and a deeper understanding is crucial for enabling further improvements. In addition, some details are not reported, and this could prevent other attempts from replicating the results. To address these issues, we reimplemented <cite>Yuan et al. (2016)</cite> 's method with the goal of: 1) reproducing and making available the code, trained models, and results and 2) understanding which are the main factors that constitute the strengths and weaknesses of this method.",
  "y": "motivation"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_5",
  "x": "To address these issues, we reimplemented <cite>Yuan et al. (2016)</cite> 's method with the goal of: 1) reproducing and making available the code, trained models, and results and 2) understanding which are the main factors that constitute the strengths and weaknesses of this method.",
  "y": "extends"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_6",
  "x": "First, a positive result is that we were able to reproduce the method from <cite>Yuan et al. (2016)</cite> and obtain similar results to the ones originally published.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_7",
  "x": "First, a positive result is that we were able to reproduce the method from <cite>Yuan et al. (2016)</cite> and obtain similar results to the ones originally published. However, to our surprise, these results were obtained using a much smaller corpus of 1.8 billion tokens (Gigaword), which is less than 2% of the data used in the original study.",
  "y": "differences"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_8",
  "x": "The work by <cite>Yuan et al. (2016)</cite> , which we consider in this paper, belongs to this last category.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_9",
  "x": "The method proposed by <cite>Yuan et al. (2016)</cite> performs WSD by annotating each lemma in a text with one WordNet synset that is associated with its meaning.",
  "y": "background"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_10",
  "x": "In <cite>Yuan et al. (2016)</cite> , the first operation consists of constructing an LSTM language model to capture the meaning of words in context.",
  "y": "background"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_11",
  "x": "<cite>Yuan et al. (2016)</cite> argue that the averaging procedure is suboptimal because of two reasons.",
  "y": "background"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_12",
  "x": "For the training of the sense embeddings, we use the same two corpora used by <cite>Yuan et al. (2016)</cite>: 1. SemCor (Miller et al., 1993 ) is a corpus containing approximately 240,000 sense annotated words.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_13",
  "x": "Three scorers are used: \"framework\" refers to the WSD evaluation framework from Raganato et al. (2017a) ; \"mapping to WN3.0\" refers to the evaluation used by <cite>Yuan et al. (2016)</cite> while \"competition\" refers to the scorer provided by the competition itself (e.g., semeval2013).",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_14",
  "x": "In this section, we report our reproduction of the results of <cite>Yuan et al. (2016)</cite> and additional experiments to gain a deeper insight into the strengths and weaknesses of the approach.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_15",
  "x": "We trained the LSTM model with the best reported settings in <cite>Yuan et al. (2016)</cite> (hidden layer size h = 2048, embedding dimensionality p = 512) using a machine equipped with an Intel Xeon E5-2650, 256GB of RAM, 8TB of disk space, and two nVIDIA GeForce GTX 1080 Ti GPUs.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_16",
  "x": "The top part of the table presents our reproduction results, the middle part reports the results from <cite>Yuan et al. (2016)</cite> , while the bottom part reports a representative sample of the other state-of-the-art approaches.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_17",
  "x": "The top part of the table presents our reproduction results, the middle part reports the results from <cite>Yuan et al. (2016)</cite> , while the bottom part reports a representative sample of the other state-of-the-art approaches. It should be noted that with the test set semeval2013, all scorers use WordNet 3.0, therefore the performance of the various methods can be directly compared.",
  "y": "similarities"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_19",
  "x": "Different from <cite>Yuan et al. (2016)</cite>, we did not observe improvement by using label propagation (comparing T: SemCor, U: OMSTI against T:SemCor without propagation).",
  "y": "differences"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_20",
  "x": "Different from <cite>Yuan et al. (2016)</cite>, we did not observe improvement by using label propagation (comparing T: SemCor, U: OMSTI against T:SemCor without propagation). However, the performance of the label propagation strategy is still competitive on both test sets.",
  "y": "similarities"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_21",
  "x": "Table 2 shows that the method by <cite>Yuan et al. (2016)</cite> does not overfit towards the MFS to the same extent as other supervised systems since the recall on LFS instances is still quite high 0.41 (a lower recall on LFS instances than on MFS ones is expected due to the reduced training data for them).",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_23",
  "x": "The data points at 100 billion (10 11 ) tokens correspond to <cite>Yuan et al. (2016)</cite> 's reported results.",
  "y": "uses similarities"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_24",
  "x": "This paper reports the results of a reproduction study of the model proposed by <cite>Yuan et al. (2016)</cite> and an additional analysis to gain a deeper understanding of the impact of various factors on its performance.",
  "y": "uses"
 },
 {
  "id": "97f8d0af85eda3e453fc4fb00819f0_25",
  "x": "First, we observed that we do not need a very large unannotated dataset to achieve state-of-the-art all-words WSD performance since we used the Gigaword corpus, which is two orders of magnitude smaller than <cite>Yuan et al. (2016)</cite> 's proprietary corpus, and got similar performance on senseval2 and semeval2013.",
  "y": "differences"
 },
 {
  "id": "98d8ea63896cc80f0989130e7cbbf1_0",
  "x": "Akiva and Koppel (2013) followed that work with an expanded method, and<cite> Aldebei et al. (2015)</cite> have since presented an improved technique in the 'multi-author document' context by exploiting posterior probabilities of a Naive-Bayesian Model.",
  "y": "background"
 },
 {
  "id": "98d8ea63896cc80f0989130e7cbbf1_1",
  "x": "In this paper, we argue that the biblical clustering done by Koppel et al. (2011) and by<cite> Aldebei et al. (2015)</cite> do not represent a grouping around true authorship within the Bible, but rather around common topics or shared style.",
  "y": "differences"
 },
 {
  "id": "98d8ea63896cc80f0989130e7cbbf1_2",
  "x": "Additionally, in cases where authors are rhetorically similar, our framework outperforms techniques outlined by Akiva (2013) and <cite>Aldebei (2015)</cite> , which both rely on word occurrences as features.",
  "y": "differences"
 },
 {
  "id": "98d8ea63896cc80f0989130e7cbbf1_3",
  "x": "The NYT cor- pus is used both because the author of each document is known with certainty and because it is a canonical dataset that has served as a benchmark for both Akiva and Koppel (2013) and<cite> Aldebei et al. (2015)</cite> .",
  "y": "similarities"
 },
 {
  "id": "98d8ea63896cc80f0989130e7cbbf1_4",
  "x": "Indeed, we were further surprised to discover that by adjusting our framework to be similar to that presented in Akiva and Koppel (2013) and<cite> Aldebei et al. (2015)</cite> -by replacing POS n-grams with ordinary word occurrences in step one -our framework performed very well, clustering at 95.3%.",
  "y": "similarities"
 },
 {
  "id": "9a8b29b10539be9e6c65172a97b16f_0",
  "x": "<cite>[9]</cite> in <cite>their work</cite> pointed out that hate speech is different from offensive language and released a data set of 25k tweets with the goal of distinguishing hate speech from offensive language.",
  "y": "background"
 },
 {
  "id": "9a8b29b10539be9e6c65172a97b16f_1",
  "x": "<cite>[9]</cite> use a similar handcrafted feature engineered model to identify offensive language and distinguish it from hate speech.",
  "y": "background"
 },
 {
  "id": "9a8b29b10539be9e6c65172a97b16f_3",
  "x": "We have used the 3 benchmark data sets for abusive content detection on Twitter. At the time of the experiment, the [10] data set had a total of 15,844 tweets out of which 1,924 were labelled as belonging to racism, 3,058 as sexism and 10,862 as none. The <cite>[9]</cite> data set had a total of 25,112 tweets out of which 1498 were labelled as hate speech, 19,326 as offensive language and 4,288 as neither.",
  "y": "uses"
 },
 {
  "id": "9a8b29b10539be9e6c65172a97b16f_4",
  "x": "We have used the 3 benchmark data sets for abusive content detection on Twitter. At the time of the experiment, the [10] data set had a total of 15,844 tweets out of which 1,924 were labelled as belonging to racism, 3,058 as sexism and 10,862 as none. The <cite>[9]</cite> data set had a total of 25,112 tweets out of which 1498 were labelled as hate speech, 19,326 as offensive language and 4,288 as neither. For the [4] data set, there were 20,362 tweets out of which 5,235 were positive harassment examples and 15,127 were negative. We call [10] data set as D1 , <cite>[9]</cite> data set as <cite>D2</cite> and [4] as D3 For tweet tokenization, we use Ekphrasis which is a text processing tool built specially from social platforms such as Twitter.",
  "y": "uses"
 },
 {
  "id": "9a8b29b10539be9e6c65172a97b16f_5",
  "x": "The results are averaged over 10-fold cross-validations for D1 and D3 and 5 fold cross-validations for <cite>D2</cite> because <cite>[9]</cite> reported results using 5 fold CV.",
  "y": "motivation"
 },
 {
  "id": "9a8b29b10539be9e6c65172a97b16f_6",
  "x": "On closer investigation we find that most cases where our model fails are instances where annotation is either noisy or the difference between classes are very blurred and subtle. The first tweet is a tweet from [10] , the second tweet is a tweet from from <cite>[9]</cite> data set and the third from the [4]",
  "y": "differences"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_0",
  "x": "The paper presents an application of Structural Correspondence Learning (SCL)<cite> (Blitzer et al., 2006)</cite> for domain adaptation of a stochastic attribute-value grammar (SAVG).",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_1",
  "x": "So far, SCL has been applied successfully in NLP for Part-of-Speech tagging and Sentiment Analysis<cite> (Blitzer et al., 2006</cite>; ).",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_2",
  "x": "The problem itself has started to get attention only recently (Roark and Bacchiani, 2003; Hara et al., 2005; Daum\u00e9 III and Marcu, 2006; Daum\u00e9 III, 2007;<cite> Blitzer et al., 2006</cite>; McClosky et al., 2006; .",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_3",
  "x": "In contrast, semi-supervised domain adaptation<cite> (Blitzer et al., 2006</cite>; McClosky et al., 2006; is the scenario in which, in addition to the labeled source data, we only have unlabeled and no labeled target domain data.",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_5",
  "x": "While several authors have looked at the supervised adaptation case, there are less (and especially less successful) studies on semi-supervised domain adaptation (McClosky et al., 2006;<cite> Blitzer et al., 2006</cite>; .",
  "y": "background motivation"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_6",
  "x": "Similarly, Structural Correspondence Learning<cite> (Blitzer et al., 2006</cite>; Blitzer, 2008) has proven to be successful for the two tasks examined, PoS tagging and Sentiment Classification.",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_7",
  "x": "We examine the effectiveness of Structural Correspondence Learning (SCL)<cite> (Blitzer et al., 2006)</cite> for this task, a recently proposed adaptation technique shown to be effective for PoS tagging and Sentiment Analysis.",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_8",
  "x": "(Structural Correspondence Learning)<cite> (Blitzer et al., 2006</cite>; Blitzer, 2008 ) is a recently proposed domain adaptation technique which uses unlabeled data from both source and target domain to learn correspondences between features from different domains.",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_9",
  "x": "Pivots are features occurring frequently and behaving similarly in both domains<cite> (Blitzer et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_10",
  "x": "Intuitively, if we are able to find good correspondences among features, then the augmented labeled source domain data should transfer better to a target domain (where no labeled data is available)<cite> (Blitzer et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_11",
  "x": "Applying the projection W T x (where x is a training instance) would give us m new features, however, for \"both computational and statistical reasons\"<cite> (Blitzer et al., 2006</cite>; Ando and Zhang, 2005 ) a low-dimensional approximation of the original feature space is computed by applying Singular Value Decomposition (SVD) on W (step 4).",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_12",
  "x": "So far, pivot features on the word level were used<cite> (Blitzer et al., 2006</cite>; Blitzer, 2008) , e.g. \"Does the bigram not buy occur in this document?\" (Blitzer, 2008) .",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_13",
  "x": "Predictive features As pointed out by<cite> Blitzer et al. (2006)</cite> , each instance will actually contain features which are totally predictive of the pivot features (i.e. the pivot itself).",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_14",
  "x": "Following<cite> Blitzer et al. (2006)</cite> (which follow Ando and Zhang (2005)), we only use positive entries in the pivot predictors weight vectors to compute the SVD.",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_15",
  "x": "In practice, there are more free parameters and model choices (Ando and Zhang, 2005; Ando, 2006;<cite> Blitzer et al., 2006</cite>; Blitzer, 2008) besides the ones discussed above.",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_16",
  "x": "When training the supervised model on the augmented feature space x, \u03b8x ,<cite> Blitzer et al. (2006)</cite> only regularize the weight vector of the original features, but not the one for the new low-dimensional features.",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_17",
  "x": "Due to the positive results in Ando (2006),<cite> Blitzer et al. (2006)</cite> include this in their standard setting of SCL and report results using block SVDs only.",
  "y": "background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_18",
  "x": "In our empirical setup, we followed<cite> Blitzer et al. (2006)</cite> and tried to balance the size of source and target data.",
  "y": "uses"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_19",
  "x": "We can confirm that changing the dimensionality parameter h has rather little effect (Table 4) , which is in line with previous findings (Ando and Zhang, 2005;<cite> Blitzer et al., 2006)</cite> .",
  "y": "similarities"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_20",
  "x": "While<cite> Blitzer et al. (2006)</cite> found it necessary to normalize (and scale) the projection features, we did not observe any improvement by normalizing them (actually, it slightly degraded performance in our case).",
  "y": "differences"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_21",
  "x": "While SCL has been successfully applied to PoS tagging and Sentiment Analysis<cite> (Blitzer et al., 2006</cite>; , its effectiveness for parsing was rather unexplored.",
  "y": "motivation background"
 },
 {
  "id": "9bd974b0fa4732f361f1c397e6b4c7_22",
  "x": "The empirical results show that our instantiation of SCL to parse disambiguation gives promising initial results, even without the many additional extensions on the feature level as done in<cite> Blitzer et al. (2006)</cite> .",
  "y": "differences"
 },
 {
  "id": "9c8c5da4cdd13efb187690e7d3aa20_0",
  "x": "Previous work on paraphrase generation that used these datasets (Wang et al., 2019;<cite> Gupta et al., 2018</cite>; Li et al., 1 https://data.quora.com/ First-Quora-Dataset-Release-Question-Pairs 2018; Prakash et al., 2016) chose BLEU (Papineni et al., 2002) , METEOR (Lavie and Agarwal, 2007) and TER (Snover et al., 2006) as evaluation metrics.",
  "y": "background"
 },
 {
  "id": "9c8c5da4cdd13efb187690e7d3aa20_1",
  "x": "<cite>Gupta et al. (2018)</cite> sampled 4K sentences as their test set, but did not specify which sentences they used.",
  "y": "background"
 },
 {
  "id": "9c8c5da4cdd13efb187690e7d3aa20_2",
  "x": "There have been multiple works which use it as a paraphrase generation dataset by treating captions of the same image as paraphrases (Wang et al., 2019;<cite> Gupta et al., 2018</cite>; Prakash et al., 2016) .",
  "y": "background"
 },
 {
  "id": "9c8c5da4cdd13efb187690e7d3aa20_3",
  "x": "However, relevance scores for captions of the same image score only 3.38 out of 5 under human evaluation (in contrast, the score is 4.82 for QUORA)<cite> (Gupta et al., 2018)</cite> , due to the fact that different captions for the same image often vary in the semantic information conveyed.",
  "y": "background"
 },
 {
  "id": "9c8c5da4cdd13efb187690e7d3aa20_4",
  "x": "Consequently, although the exact test sets used by<cite> (Gupta et al., 2018)</cite> and (Li et al., 2018) are not available, it is logical to assume that parroting performance would still exceed or be on par with the state-of-the-art on those test sets.",
  "y": "future_work"
 },
 {
  "id": "9d1699d4ca3b4026ed5aab125a737d_0",
  "x": "In proposing bigrams as concepts for their system,<cite> Gillick and Favre (2009)</cite> explain that:",
  "y": "background"
 },
 {
  "id": "9d1699d4ca3b4026ed5aab125a737d_1",
  "x": "(Gillick and Favre, 2009) Several authors, e.g., Woodsend and Lapata (2012) , and Li et al. (2013) , have followed<cite> Gillick and Favre (2009)</cite> in assuming that bigrams would lead to better practical performance than more syntactic or semantic concepts, even though bigrams serve as only an approximation of these.",
  "y": "background"
 },
 {
  "id": "9d1699d4ca3b4026ed5aab125a737d_2",
  "x": "Bigrams.<cite> Gillick and Favre (2009)</cite> proposed to use bigrams as concepts, and to weight their contribution to the objective function in Equation (1) by the frequency with which they occur in the document.",
  "y": "background"
 },
 {
  "id": "9d1699d4ca3b4026ed5aab125a737d_4",
  "x": "Our baseline is the bigram-based extraction summarization system of<cite> Gillick and Favre (2009)</cite> , icsisumm 7 .",
  "y": "uses"
 },
 {
  "id": "9d1699d4ca3b4026ed5aab125a737d_5",
  "x": "For 'A' type documents,<cite> Gillick and Favre (2009)</cite> set this threshold to 3 and for 'B' type documents, they set this to 4.",
  "y": "background"
 },
 {
  "id": "9d1699d4ca3b4026ed5aab125a737d_6",
  "x": "We first note that our runs of the current distribution of icsisumm yield significantly worse ROUGE-2 results than reported in<cite> (Gillick and Favre, 2009</cite> ) (see Table 1 , BIGRAMS): 0.081 compared to 0.110 respectively.",
  "y": "differences"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_0",
  "x": "As we expected, both the macroaverage F1-score and class-wise F1 scores are lower compared with the results in Table 2 where in-genre data were used for model training as well. But the performance drop on the paragraph-level models is little, which clearly outperform the previous system<cite> (Friedrich et al., 2016)</cite> and the baseline model by a large margin.",
  "y": "differences"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_1",
  "x": "We aim to categorize a clause based on its aspectual property and more specifically, based on the type of Situation Entity (SE) 1 (e.g., events, states, generalizing statements and generic statements) the clause introduces to the discourse, following the recent work by<cite> (Friedrich et al., 2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_2",
  "x": "Recently, <cite>Friedrich et al. (2016)</cite> used insightful syntactic-semantic features extracted from the target clause itself for SE type classification, which has achieved good performance across several genres when evaluated on the newly created large dataset MASC+Wiki.",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_3",
  "x": "In addition, <cite>Friedrich et al. (2016)</cite> implemented a sequence labeling model with conditional random fields (CRF) (Lafferty et al., 2001 ) for finetuning a sequence of predicted SE types.",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_4",
  "x": "Recently, <cite>Friedrich et al. (2016)</cite> used insightful syntactic-semantic features extracted from the target clause itself for SE type classification, which has achieved good performance across several genres when evaluated on the newly created large dataset MASC+Wiki. In addition, <cite>Friedrich et al. (2016)</cite> implemented a sequence labeling model with conditional random fields (CRF) (Lafferty et al., 2001 ) for finetuning a sequence of predicted SE types. However, other than leveraging common SE label patterns (e.g., GENERIC clauses tend to cluster together.), this approach largely ignored the wider contexts a clause appears in when predicting its SE type.",
  "y": "background motivation"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_5",
  "x": "Experimental results show that our paragraphlevel neural network model greatly improves the performance of SE type classification on the same MASC+Wiki<cite> (Friedrich et al., 2016)</cite> corpus and achieves robust performance close to human level.",
  "y": "differences"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_6",
  "x": "In order to further improve SE type classification performance, we also add an extra CRF layer at the top of our paragraph-level model to fine-tune a sequence of SE type predictions over clauses<cite> (Friedrich et al., 2016)</cite> , which however is not our contribution.",
  "y": "extends"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_7",
  "x": "The situation entity types annotated in the MASC+Wiki corpus<cite> (Friedrich et al., 2016)</cite> were initially introduced by Smith (2003) , which were then extended by (Palmer et al., 2007; Friedrich and Palmer, 2014b) .",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_8",
  "x": "To bridge the gap, <cite>Friedrich et al. (2016)</cite> created a much larger dataset MASC+Wiki (more than 40,000 clauses) and achieved better SE type classification performance (around 75% accuracy) by using rich features extracted from the target clause.",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_9",
  "x": "<cite>Friedrich et al. (2016)</cite> further improved the performance by implementing a sequence labeling (CRF) model to fine-tune a sequence of SE type predictions and noted that much of the performance gain came from modeling the label pattern that GENERIC clauses often occur together.",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_10",
  "x": "<cite>Friedrich et al. (2016)</cite> further improved the performance by implementing a sequence labeling (CRF) model to fine-tune a sequence of SE type predictions and noted that much of the performance gain came from modeling the label pattern that GENERIC clauses often occur together. In contrast, we focus on deriving dynamic clause representations informed by paragraph-level contexts and model context influences more extensively.",
  "y": "background differences"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_11",
  "x": "For example, <cite>Friedrich et al. (2016)</cite> reported the fact that GENERIC sentences usually occur together in a paragraph.",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_12",
  "x": "Following<cite> (Friedrich et al., 2016)</cite> , in order to capture SE label patterns in our hierarchical recurrent neural network model, we add a CRF layer at the top of the softmax prediction layer (shown in figure 2 ) to fine-tune predicted situation entity types.",
  "y": "uses"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_13",
  "x": "The MASC+Wiki Corpus: We evaluated our neural network model on the MASC+Wiki corpus 7<cite> (Friedrich et al., 2016)</cite> (Friedrich et al., 2016; Becker et al., 2017) , we used the same 80:20 traintest split with balanced genre distributions.",
  "y": "uses"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_14",
  "x": "Preprocessing: As described in<cite> (Friedrich et al., 2016)</cite> , texts were split into clauses using SPADE (Soricut and Marcu, 2003) .",
  "y": "uses"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_17",
  "x": "Following the previous work<cite> (Friedrich et al., 2016)</cite> on the same task and dataset, we report accuracy and macro-average F1-score across SE types on the test set of MASC+Wiki.",
  "y": "uses"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_18",
  "x": "We noticed that the previous work<cite> (Friedrich et al., 2016)</cite> did not publish the class-wise performance of their model on the test set, instead, they reported the detailed performance on the training set using 10-fold cross-validation.",
  "y": "background"
 },
 {
  "id": "9e7f3943d8f8aff2eb91c291cd020e_19",
  "x": "We noticed that the previous work<cite> (Friedrich et al., 2016)</cite> did not publish the class-wise performance of their model on the test set, instead, they reported the detailed performance on the training set using 10-fold cross-validation. For direct comparisons, we also report our 10-fold cross-validation results 8 on the training set of MASC+Wiki.",
  "y": "uses"
 },
 {
  "id": "a01a6ab7cf13c7916b1b3823a4b4de_0",
  "x": "In order to effectively incorporate the otherlanguage data, we apply SVM re-ranking in a manner that has previously been shown to provide significant improvement for grapheme-to-phoneme conversion (Bhargava and Kondrak, 2011) . This method is flexible enough to incorporate multiple languages; it employs features based on character alignments between potential outputs and existing transliterations from other languages, as well as scores of these alignments, which serve as a measure of similarity. We apply this approach on top of the same DIRECTL+ system as submitted last year <cite>(Jiampojamarn et al., 2010b)</cite> for English-to-Hindi machine transliteration. Compared to the base DI-RECTL+ performance, we are able to achieve significantly better results, with a relative performance increase of over 10%.",
  "y": "background"
 },
 {
  "id": "a01a6ab7cf13c7916b1b3823a4b4de_1",
  "x": "Our principal base system that generates the n-best output lists is DIRECTL+, which has produced excellent results in the NEWS 2010 Shared Task on Transliteration <cite>(Jiampojamarn et al., 2010b)</cite> .",
  "y": "uses background"
 },
 {
  "id": "a01a6ab7cf13c7916b1b3823a4b4de_2",
  "x": "We tune the SVM's hyperparameter based on performance on the provided development data, and use the best DIRECTL+ settings established in the NEWS 2010 Shared Task <cite>(Jiampojamarn et al., 2010b)</cite> . Armed with optimal parameter settings, we combine the training and development data into a single set used to train our final DIRECTL+ system.",
  "y": "extends"
 },
 {
  "id": "a01a6ab7cf13c7916b1b3823a4b4de_4",
  "x": "For the NEWS 2009 and 2010 Shared Tasks, the discriminative DIRECTL+ system that incorporates many-to-many alignments, online maxmargin training and a phrasal decoder was shown to function well as a general string transduction tool; while originally designed for grapheme-tophoneme conversion, it produced excellent results for machine transliteration (Jiampojamarn et al., 2009;<cite> Jiampojamarn et al., 2010b)</cite> , leading us to re-use it here.",
  "y": "uses background"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_0",
  "x": "Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013) , or the prediction of the compositionality of MWE types (Reddy et al., 2011;<cite> Salehi and Cook, 2013</cite>; Salehi et al., 2014) .",
  "y": "background"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_1",
  "x": "The prediction of the compositionality of MWE types has traditionally been couched as a binary classification task (compositional or non-compositional: Baldwin et al. (2003) , Bannard (2006) ), but more recent work has moved towards a regression setup, where the degree of the compositionality is predicted on a continuous scale (Reddy et al., 2011;<cite> Salehi and Cook, 2013</cite>; Salehi et al., 2014) .",
  "y": "background"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_2",
  "x": "In either case, the modelling has been done either over the whole MWE (Reddy et al., 2011;<cite> Salehi and Cook, 2013)</cite> , or relative to each component within the MWE (Baldwin et al., 2003; Bannard, 2006) .",
  "y": "background"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_3",
  "x": "The work that is perhaps most closely related to this paper is that of<cite> Salehi and Cook (2013)</cite> and Salehi et al. (2014) , who use translation data to predict the compositionality of a given MWE relative to each of its components, and then combine those scores to derive an overall compositionality score.",
  "y": "similarities"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_4",
  "x": "The basis of the similarity calculation is unsupervised, using either string similarity<cite> (Salehi and Cook, 2013)</cite> or distributional similarity (Salehi et al., 2014) .",
  "y": "uses"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_5",
  "x": "To benchmark our method, we use two of the same datasets as these two papers, and repurpose the best-performing methods of<cite> Salehi and Cook (2013)</cite> and Salehi et al. (2014) for classification of the compositionality of each MWE component.",
  "y": "uses"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_6",
  "x": "Our approach is to take whatever translations happen to exist in Wiktionary for a given MWE, and where there are translations in that language for the component of interest, use the LCSbased method of<cite> Salehi and Cook (2013)</cite> to measure the string similarity between the translation of the MWE and the translation of the components.",
  "y": "uses"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_7",
  "x": "Unlike<cite> Salehi and Cook (2013)</cite> , however, we do not use development data to select the optimal set of languages in a supervised manner, and instead simply take the average of the string similarity scores across the available languages.",
  "y": "differences"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_8",
  "x": "As mentioned above, we evaluate our method over the same two datasets as<cite> Salehi and Cook (2013)</cite> (which were later used, in addition to a third dataset of German noun compounds, in Salehi et al. (2014) ): (1) 90 binary English noun compounds (ENCs, e.g. spelling bee or swimming pool); and (2) 160 English verb particle constructions (EVPCs, e.g. stand up and give away).",
  "y": "similarities"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_9",
  "x": "Our results are not directly comparable with those of<cite> Salehi and Cook (2013)</cite> and Salehi et al. (2014) , however, who evaluated in terms of a regression task, modelling the overall compositionality of the MWE.",
  "y": "similarities differences"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_10",
  "x": "We also compare our method with: (1) \"LCS\", the string similarity-based method of<cite> Salehi and Cook (2013)</cite> , in which 54 languages are used; (2) \"DS\", the monolingual distributional similarity method of Salehi et al. (2014) ; (3) \"DS+DSL2\", the multilingual distributional similarity method of Salehi et al. (2014) , including supervised language selection for a given dataset, based on crossvalidation; and (4) \"LCS+DS+DSL2\", whereby the first three methods are combined using a supervised support vector regression model.",
  "y": "uses"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_11",
  "x": "Overall, the simple unsupervised methods proposed in this paper are comparable with the unsupervised and supervised state-of-the-art methods of<cite> Salehi and Cook (2013)</cite> and Salehi et al. (2014) , with ITAG achieving the highest F-score for the ENC dataset and for the verb components of the EVPC dataset.",
  "y": "uses differences"
 },
 {
  "id": "a0730efd9575800ba779516af1f440_12",
  "x": "When we combine each of our proposed methods with the string and distributional similarity methods of<cite> Salehi and Cook (2013)</cite> and Salehi et al. (2014) , we see substantial improvements over the comparable combined method of \"LCS+DS+DSL2\" in most cases, demonstrating both the robustness of the proposed methods and their complementarity with the earlier methods.",
  "y": "uses"
 },
 {
  "id": "a229630a81020951ec0be27f54885a_0",
  "x": "Following<cite> (Androutsopoulos et al., 2000)</cite> , we have assigned 9 and 999 (9 and 999 times more important) penalties to the missclassification of legitimate messages as UCE.",
  "y": "uses"
 },
 {
  "id": "a229630a81020951ec0be27f54885a_1",
  "x": "Recall and precision for the UCE class show how effective the filter is blocking UCE, and what is its effectiveness letting legitimate messages pass the filter, respectively<cite> (Androutsopoulos et al., 2000)</cite> .",
  "y": "background"
 },
 {
  "id": "a229630a81020951ec0be27f54885a_2",
  "x": "In (Sahami et al., 1998; <cite>Androutsopoulos et al., 2000)</cite> , the method followed is the variation of the probability threshold, which leads to a high variation of results.",
  "y": "background"
 },
 {
  "id": "a229630a81020951ec0be27f54885a_3",
  "x": "For future experiments, we will use the collection from<cite> (Androutsopoulos et al., 2000)</cite> , which is in raw form.",
  "y": "future_work"
 },
 {
  "id": "a5d7f5c5fed218149818463427d6a1_0",
  "x": "Distributed representations of words in the form of word embeddings Pennington et al., 2014) and contextualized word embeddings (Peters et al., 2018; Devlin et al., 2018; Radford et al., 2018; McCann et al., 2017; Radford et al., 2019) have led to huge performance improvement on many NLP tasks. However, several recent studies show that training word embeddings in large corpora could lead to encoding societal biases present in these human-produced data<cite> (Bolukbasi et al., 2016</cite>; Caliskan et al., 2017) . In this work, we extend these analyses to the ELMo contextualized word embeddings. Our work provides a new intrinsic analysis of how ELMo represents gender in biased ways.",
  "y": "motivation background"
 },
 {
  "id": "a5d7f5c5fed218149818463427d6a1_1",
  "x": "For word representations,<cite> Bolukbasi et al. (2016)</cite> and Caliskan et al. (2017) show that word embeddings encode societal biases about gender roles and occupations, e.g. engineers are stereotypically men, and nurses are stereotypically women. As a consequence, downstream applications that use these pretrained word embeddings also reflect this bias.",
  "y": "motivation background"
 },
 {
  "id": "a5d7f5c5fed218149818463427d6a1_2",
  "x": "To mitigate bias from word embeddings,<cite> Bolukbasi et al. (2016)</cite> propose a post-processing method to project out the bias subspace from the pre-trained embeddings. Their method is shown to reduce the gender information from the embeddings of gender-neutral words, and, remarkably, maintains the same level of performance on different downstream NLP tasks.",
  "y": "background"
 },
 {
  "id": "a5d7f5c5fed218149818463427d6a1_3",
  "x": "Figure 1 shows there are two principal components for gender in ELMo, in contrast to GloVe which only has one<cite> (Bolukbasi et al., 2016)</cite> . The two principal components in ELMo seem to represent the gender from the contextual information (Contextual Gender) as well as the gender embedded in the word itself (Occupational Gender).",
  "y": "differences"
 },
 {
  "id": "a5d7f5c5fed218149818463427d6a1_4",
  "x": "Data augmentation is performed by replacing gender revealing entities in the OntoNotes dataset with words indicating the opposite gender and then training on the union of the original data and this swapped data. In addition, they find it useful to also mitigate bias in supporting resources and therefore replace standard GloVe embeddings with bias mitigated word embeddings from<cite> Bolukbasi et al. (2016)</cite> .",
  "y": "uses"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_0",
  "x": "We therefore explore an alternative approach to Arabic SA on social media, using off-the-shelf Machine Translation systems to translate Arabic tweets into English and then use a state-of-the-art sentiment classifier <cite>(Socher et al., 2013)</cite> to assign sentiment labels.",
  "y": "uses"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_1",
  "x": "Our approach differs from the ones described, in that we use automatic MT to translate Arabic tweets into English and then perform SA using a stateof-the-art SA classifier for English <cite>(Socher et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_2",
  "x": "We then use the Stanford Sentiment Classifier (SSC) developed by<cite> Socher et al. (2013)</cite> to automatically assign sentiment labels (positive, negative) to translated tweets.",
  "y": "uses"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_3",
  "x": "Using<cite> Socher et al. (2013)</cite> 's approach for directly training a sentiment classifier will require a larger training data-set, which is not available yet for Ara-bic 3 .",
  "y": "uses"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_4",
  "x": "Note that our ML baseline systems as well as the English SA classifier by<cite> Socher et al. (2013)</cite> are trained on balanced data sets, i.e. we can assume no prior bias towards one class.",
  "y": "similarities"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_5",
  "x": "Note that the Stanford SA system pays particular attention to sentence structure due to its \"deep\" architecture that adds to the model the feature of being sensitive to word ordering <cite>(Socher et al., 2013)</cite> . In future work, we will verify this by comparing these results to other high performing English SA tools (see for example Abbasi et al. (2014) In sum, one of the major challenges of this approach seems to be the use of Arabic dialects in social media, such as Twitter.",
  "y": "future_work"
 },
 {
  "id": "a5f00f524fdf18e62a4e98a92a2d82_6",
  "x": "We then use the Stanford Sentiment Classifier <cite>(Socher et al., 2013)</cite> to automatically assign sentiment labels (positive, negative) to translated tweets.",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_0",
  "x": "On the other hand, <cite>Noraset et al. (2017)</cite> attempted to generate a definition of a word from its word embedding induced from massive text, followed by Gadetsky et al. (2018) that refers to a local context to define a polysemous word with a local context by choosing relevant dimensions of their embeddings.",
  "y": "background"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_1",
  "x": "On the other hand, <cite>Noraset et al. (2017)</cite> attempted to generate a definition of a word from its word embedding induced from massive text, followed by Gadetsky et al. (2018) that refers to a local context to define a polysemous word with a local context by choosing relevant dimensions of their embeddings. Although these research efforts revealed that both local and global contexts of words are useful in generating their definitions, none of these studies exploited both local and global contexts directly. In this study, we tackle a task of describing (defining) a phrase when given its local context as (Ni and Wang, 2017) , while allowing access to other usage examples via word embeddings trained from massive text (global contexts) (Noraset et al., 2017; Gadetsky et al., 2018) .",
  "y": "motivation"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_2",
  "x": "Considering various contexts where we need definitions of phrases, we evaluated our method with four datasets including WordNet<cite> (Noraset et al., 2017)</cite> for general words, the Oxford dictionary (Gadetsky et al., 2018) for polysemous words, Urban Dictionary (Ni and Wang, 2017) for rare idioms or slangs, and a newlycreated Wikipedia dataset for entities.",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_3",
  "x": "Considering various contexts where we need definitions of phrases, we evaluated our method with four datasets including WordNet<cite> (Noraset et al., 2017)</cite> for general words, the Oxford dictionary (Gadetsky et al., 2018) for polysemous words, Urban Dictionary (Ni and Wang, 2017) for rare idioms or slangs, and a newlycreated Wikipedia dataset for entities. Experimental results demonstrate the effectiveness of our method against the three baselines stated above (Noraset et al., 2017; Ni and Wang, 2017; Gadetsky et al., 2018) .",
  "y": "differences"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_4",
  "x": "\" Previous work on the definition generation task<cite> (Noraset et al., 2017)</cite> has shown that global contexts can be useful clues when generating definitions of unknown words.",
  "y": "background"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_5",
  "x": "To incorporate the different types of contexts, we propose to use a GATE function<cite> (Noraset et al., 2017)</cite> to dynamically control how the global and local contexts influence the generation of the description.",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_6",
  "x": "In order to capture prefixes and suffixes in X trg , we construct character-level CNNs (Eq. (5)) following<cite> (Noraset et al., 2017)</cite> . Note that the input to the CNNs is a sequence of words in X trg , which are concatenated with special character \" ,\" such as \"sonic boom.\" Following <cite>Noraset et al. (2017)</cite> , we set the kernels of length 2-6 and size 10, 30, 40, 40, 40 respectively with a stride of 1 to obtain a 160-dimensional vector c trg .",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_7",
  "x": "We achieve this by two different strategies proposed by <cite>Noraset et al. (2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_8",
  "x": "Datasets To evaluate our model on the word description task on WordNet, we followed <cite>Noraset et al. (2017)</cite> and extracted data from WordNet 7 using the dict-definition 8 toolkit.",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_9",
  "x": "We implemented four methods including three baselines: (1) Global, (2) Local, (3) I-Attention, and our proposed model, (4) LOGCaD. The Global model is our reimplementation of the strongest model (S + G + CH) in<cite> (Noraset et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_10",
  "x": "Recently, <cite>Noraset et al. (2017)</cite> introduced a task of generating a definition sentence of a word from its pre-trained embedding.",
  "y": "background"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_11",
  "x": "Their model does not take advantage of global contexts (word embeddings induced from massive text) as was used in <cite>Noraset et al. (2017)</cite> .",
  "y": "background"
 },
 {
  "id": "a5f33403d23cdc0532547266f1841a_12",
  "x": "Their model does not take advantage of global contexts (word embeddings induced from massive text) as was used in <cite>Noraset et al. (2017)</cite> . Our task of describing phrases with its given context is a generalization of these three tasks (Noraset et al., 2017; Ni and Wang, 2017; Gadetsky et al., 2018) , and the proposed method naturally utilizes both local and global contexts of a word in question.",
  "y": "uses"
 },
 {
  "id": "a6296d02f21ca5887c7686a2cbe56c_0",
  "x": "The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts <cite>(Rosti et al., 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "a6296d02f21ca5887c7686a2cbe56c_1",
  "x": "The recent approaches used pair-wise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts <cite>(Rosti et al., 2007)</cite> . The alignment method described in this paper extends the latter by incrementally aligning the hypotheses as in MSA but also allowing shifts as in the TER alignment.",
  "y": "extends"
 },
 {
  "id": "a6296d02f21ca5887c7686a2cbe56c_2",
  "x": "As in <cite>(Rosti et al., 2007)</cite> , confusion networks built around all skeletons are joined into a lattice which is expanded and rescored with language models.",
  "y": "similarities uses"
 },
 {
  "id": "a6296d02f21ca5887c7686a2cbe56c_3",
  "x": "Other scores for the word arc are set as in <cite>(Rosti et al., 2007)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "a6b450d1113e0e6d3d2813c09d12a8_0",
  "x": "<cite>Gurevych (2005)</cite> conducted experiments with a German translation of an English dataset (Rubenstein and Goodenough, 1965) , but argued that the dataset (Gur65) is too small (it contains only 65 noun pairs), and does not model SR.",
  "y": "background"
 },
 {
  "id": "a6b450d1113e0e6d3d2813c09d12a8_1",
  "x": "<cite>Gurevych (2005)</cite> proposed an alternative algorithm (PG) generating surrogate glosses by using a concept's relations within the hierarchy.",
  "y": "background"
 },
 {
  "id": "a6b450d1113e0e6d3d2813c09d12a8_2",
  "x": "We use the P G measure in optimal configuration as reported by <cite>Gurevych (2005)</cite> .",
  "y": "uses"
 },
 {
  "id": "a6b450d1113e0e6d3d2813c09d12a8_3",
  "x": "Our results on Gur65 using GermaNet are very close to those published by <cite>Gurevych (2005)</cite> , ranging from 0.69-0.75.",
  "y": "similarities"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_0",
  "x": "Neural machine translation (NMT) (Bahdanau et al., 2015; Wu et al., 2016;<cite> Vaswani et al., 2017)</cite> trains an encoder-decoder network on sentence pairs to maximize the likelihood of predicting a target-language sentence given the corresponding source-language sentence, without considering the document context.",
  "y": "background"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_1",
  "x": "Furthermore, we extend the original HAN with a multi-head attention<cite> (Vaswani et al., 2017)</cite> to capture different types of discourse phenomena.",
  "y": "uses"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_2",
  "x": "(ii) We integrate the HAN in a very competitive NMT ar-chitecture<cite> (Vaswani et al., 2017)</cite> and show significant improvement over two strong baselines on multiple data sets.",
  "y": "uses"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_3",
  "x": "We used the MultiHead attention function proposed by<cite> (Vaswani et al., 2017)</cite> to capture different types of relations among words.",
  "y": "uses"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_4",
  "x": "where f s is a linear transformation, q s is the query for the attention function, FFN is a position-wise feed-forward layer<cite> (Vaswani et al., 2017</cite> ).",
  "y": "background"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_5",
  "x": "The configuration is the same as the model called \"base model\" in the original paper<cite> (Vaswani et al., 2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "a6f32017135e984fbe59f2171c50f4_6",
  "x": "The optimization and regularization methods were the same as proposed by<cite> Vaswani et al. (2017)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "a7e49bec53a2bfd7795b9c770f5d0c_0",
  "x": "There is an accumulation of evidence that the use of dense distributional lexical representations, known as word embeddings, often supports better performance on a range of NLP tasks (Bengio et al., 2003; Turian et al., 2010; Collobert et al., 2011; <cite>Mikolov et al., 2013a</cite>; Mikolov et al., 2013b; Levy et al., 2015) . Consequently, word embeddings have been commonly used in the last few years for lexical similarity tasks and as features in multiple, syntactic and semantic, NLP applications.",
  "y": "background"
 },
 {
  "id": "a7e49bec53a2bfd7795b9c770f5d0c_1",
  "x": "Moreover, we provide two ways to train existing algorithms<cite> (Mikolov et al., 2013a</cite>; Mikolov et al., 2013b ) when the memory is limited during training and show that, here, too, an order of magnitude saving in memory is possible without degrading performance.",
  "y": "extends"
 },
 {
  "id": "a7e49bec53a2bfd7795b9c770f5d0c_2",
  "x": "If we consider traditional cluster encoded word representation, e.g., Brown clusters (Brown et al., 1992) , it only uses a small number of bits to track the path on a hierarchical tree of word clusters to represent each word. In fact, word embedding generalized the idea of discrete clustering representation to continuous vector representation in language models, with the goal of improving the continuous word analogy prediction and generalization ability (Bengio et al., 2003; <cite>Mikolov et al., 2013a</cite>; Mikolov et al., 2013b) .",
  "y": "motivation background"
 },
 {
  "id": "a7e49bec53a2bfd7795b9c770f5d0c_4",
  "x": "We train the word embedding algorithms, word2vec<cite> (Mikolov et al., 2013a</cite>; Mikolov et al., 2013b) , based on the Oct. 2013 Wikipedia dump.",
  "y": "uses"
 },
 {
  "id": "a7e49bec53a2bfd7795b9c770f5d0c_5",
  "x": "We ran both CBOW and skipgram with negative sampling<cite> (Mikolov et al., 2013a</cite>; Mikolov et al., 2013b) on the Wikipedia dump data, and set the window size of context to be five.",
  "y": "uses"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_0",
  "x": "We combine these networks with a sparse linear model to achieve state-of-the-art performance on multiple entity linking datasets, outperforming the prior systems of<cite> Durrett and Klein (2014)</cite> and Nguyen et al. (2014) .",
  "y": "motivation"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_1",
  "x": "Past approaches to such cases have often focused on collective entity linking: nearby mentions in a document might be expected to link to topically-similar entities, which can give us clues about the identity of the mention currently being resolved (Ratinov et al., 2011; Hoffart et al., 2011; He et al., 2013; Cheng and Roth, 2013;<cite> Durrett and Klein, 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_2",
  "x": "We show that convolutions over multiple granularities of the input document are useful for providing different notions of semantic context. Finally, we show how to integrate these networks with a preexisting entity linking system <cite>(Durrett and Klein, 2014)</cite> .",
  "y": "motivation"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_3",
  "x": "Following<cite> Durrett and Klein (2014)</cite> , we introduce a latent variable q to capture which subset of a mention (known as a query) we resolve.",
  "y": "extends differences"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_4",
  "x": "f Q and f E are both sparse features vectors and are taken from previous work <cite>(Durrett and Klein, 2014)</cite> .",
  "y": "extends similarities"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_5",
  "x": "The indicator features f Q and f E are described in more detail in<cite> Durrett and Klein (2014)</cite> .",
  "y": "background"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_6",
  "x": "Adding tf-idf indicators is the only modification we made to the features of<cite> Durrett and Klein (2014)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_7",
  "x": "This corpus was used in Fahrni and Strube (2014) and<cite> Durrett and Klein (2014)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_8",
  "x": "Our results outperform those of<cite> Durrett and Klein (2014)</cite> and Nguyen et al. (2014) . We see that this system outperforms the results of<cite> Durrett and Klein (2014)</cite> and the AIDA-LIGHT system of Nguyen et al. (2014) .",
  "y": "differences"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_9",
  "x": "We can also compare to two ablations: using just the sparse features (a system which is a direct extension of<cite> Durrett and Klein (2014)</cite> ) or using just the CNNderived features. 5 Our CNN features generally outperform the sparse features and improve even further when stacked with them.",
  "y": "extends differences"
 },
 {
  "id": "a7f4154081f4045390e662c6e6f3ac_10",
  "x": "In the sparse feature system, the highest weighted features are typically those indicating the frequency that a page was linked to and those indicating specific lexical items in the choice of the latent query variable q. This suggests that the system of<cite> Durrett and Klein (2014)</cite> has the power to pick the right span of a mention to resolve, but then is left to generally pick the most common link target in Wikipedia, which is not always correct. By contrast, the full system has a greater ability to pick less common link targets if the topic indicators distilled from the CNNs indicate that it should do so.",
  "y": "background motivation"
 },
 {
  "id": "a8743bb89abd16f75bec9e72e446b3_0",
  "x": "<cite>Bartlett et al. (2008)</cite> observe that some of the errors made by their otherwise highly-accurate system, such as hol-dov-er and coad-ju-tors, can be attributed to the lack of awareness of morphological boundaries, which influence syllabification.",
  "y": "background"
 },
 {
  "id": "a8743bb89abd16f75bec9e72e446b3_1",
  "x": "We augment the syllabification approach of <cite>Bartlett et al. (2008)</cite> , with features encoding morphological segmentation of words.",
  "y": "extends"
 },
 {
  "id": "a8743bb89abd16f75bec9e72e446b3_2",
  "x": "In this section, we describe the original syllabification method of <cite>Bartlett et al. (2008)</cite> , which serves as our baseline system, and discuss various approaches to incorporating morphological information.",
  "y": "uses"
 },
 {
  "id": "a8743bb89abd16f75bec9e72e446b3_3",
  "x": "<cite>Bartlett et al. (2008)</cite> present a discriminative approach to automatic syllabification.",
  "y": "background"
 },
 {
  "id": "a8743bb89abd16f75bec9e72e446b3_5",
  "x": "As a baseline, we replicate the experiments of <cite>Bartlett et al. (2008)</cite> , and extend them to lowresource settings.",
  "y": "extends uses"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_0",
  "x": "Machine Translation systems have been adapted to translate complex sentences into simple ones <cite>(Zhu et al., 2010</cite>; Wubben et al., 2012; Coster and Kauchak, 2011) .",
  "y": "background"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_1",
  "x": "When compared against current state of the art methods <cite>(Zhu et al., 2010</cite>; Woodsend and Lapata, 2011; Wubben et al., 2012) , our model yields significantly simpler output that is both grammatical and meaning preserving.",
  "y": "differences"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_2",
  "x": "Machine Translation systems have been adapted to translate complex sentences into simple ones <cite>(Zhu et al., 2010</cite>; Wubben et al., 2012; Coster and Kauchak, 2011) . And handcrafted rules have been proposed to model the syntactic transformations involved in simplifications (Siddharthan et al., 2004; Siddharthan, 2011; Chandrasekar et al., 1996) . In this paper, we present a hybrid approach to sentence simplification which departs from this previous work in two main ways.",
  "y": "extends"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_3",
  "x": "Using both the PWKP corpus developed by<cite> Zhu et al. (2010)</cite> and the edit history of Simple Wikipedia, Woodsend and Lapata (2011) learn a quasi synchronous grammar (Smith and Eisner, 2006) describing a loose alignment between parse trees of complex and of simple sentences.",
  "y": "background"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_4",
  "x": "They evaluate their model on the same dataset used by<cite> Zhu et al. (2010)</cite> namely, an aligned corpus of 100/131 EWKP/SWKP sentences and show that they achieve better BLEU score.",
  "y": "uses background"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_5",
  "x": "A human evaluation on 20 sentences randomly selected from the test data indicates that, in terms of fluency and adequacy, their system is judged to outperform both<cite> Zhu et al. (2010)</cite> and Woodsend and Lapata (2011) systems.",
  "y": "background"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_6",
  "x": "While our semantic based approach naturally accounts for this by copying the phrase corresponding to the shared entity in both phrases, syntax based approach such as<cite> Zhu et al. (2010)</cite> and Woodsend and Lapata (2011) will often fail to appropriately reconstruct the shared phrase and introduce agreement mismatches because the alignment or rules they learn are based on syntax alone. For instance, in example (2),<cite> Zhu et al. (2010)</cite> fails to copy the shared argument \"The judge\" to the second clause whereas Woodsend and Lapata (2011) learns a synchronous rule matching (VP and VP) to (VP.",
  "y": "differences"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_7",
  "x": "By contrast, syntax based approaches <cite>(Zhu et al., 2010</cite>; Woodsend and Lapata, 2011) do not distinguish between optional and obligatory arguments.",
  "y": "differences"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_8",
  "x": "By contrast, syntax based approaches <cite>(Zhu et al., 2010</cite>; Woodsend and Lapata, 2011) do not distinguish between optional and obligatory arguments. For instance<cite> Zhu et al. (2010)</cite> simplifies (3C) to (3S) thereby incorrectly deleting the obligatory theme (gifts) of the complex sentence and modifying its meaning to giving knights and warriors (instead of giving gifts to knights and warriors).",
  "y": "differences"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_9",
  "x": "For an efficient implementation of EM algorithm, we follow the work of Yamada and Knight (2001) and<cite> Zhu et al. (2010)</cite> ; and build training graphs (Figure 2 ) from the pair of complex and simple sentence pairs in the training data.",
  "y": "uses"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_10",
  "x": "To evaluate performance, we compare our approach with three other state of the art systems using the test set provided by<cite> Zhu et al. (2010)</cite> and relying both on automatic metrics and on human judgments.",
  "y": "uses"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_11",
  "x": "The DRS-Based simplification model is trained on PWKP, a bi-text of complex and simple sentences provided by<cite> Zhu et al. (2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_12",
  "x": "To construct this bi-text,<cite> Zhu et al. (2010)</cite> extracted complex and simple sentences from EWKP and SWKP respectively and automatically aligned them using TF*IDF as a similarity measure.",
  "y": "background"
 },
 {
  "id": "a8ba807b94f6f7ff4f7e77a9fcde35_13",
  "x": "We evaluate our model on the test set used by<cite> Zhu et al. (2010)</cite> namely, an aligned corpus of 100/131 EWKP/SWKP sentences.",
  "y": "uses"
 },
 {
  "id": "a9897f66e05a0354c36daba0db9afe_0",
  "x": "A breakthrough has come in the form of research by <cite>McClosky et al. (2006a</cite>; 2006b ) who show that self-training can be used to improve parser performance when combined with a two-stage reranking parser model (Charniak and Johnson, 2005) .",
  "y": "background"
 },
 {
  "id": "a9897f66e05a0354c36daba0db9afe_2",
  "x": "In the experiments of <cite>McClosky et al. (2006a</cite>; 2006b) , the parse trees used for self-training come from the same domain (American newspaper text) as the parser's original seed training material.",
  "y": "background"
 },
 {
  "id": "abe561b75389e026a9f140280f211c_0",
  "x": "Sentiment analysis is a type of opinion mining where affective states are represented categorically or by multi-dimensional continuous values<cite> (Yu et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "abe561b75389e026a9f140280f211c_1",
  "x": "According to the twodimensional representation, any affective state can be represented as a point in the valence-arousal space by determining the degrees of valence and arousal of given words (Wei et al., 2011; <cite>Yu et al., 2015)</cite> or texts (Kim et al., 2010) .",
  "y": "background"
 },
 {
  "id": "abe561b75389e026a9f140280f211c_2",
  "x": "Moreover, previous research suggested that it is possible to improve the performance by aggregating the results of a number of valence-arousal methods<cite> (Yu et al., 2015)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_0",
  "x": "We replicate the syntactic experiments of <cite>Mikolov et al. (2013b)</cite> on English, and expand them to include morphologically complex languages.",
  "y": "extends uses"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_1",
  "x": "1 Introduction <cite>Mikolov et al. (2013b)</cite> demonstrate that vector representations of words obtained from a neural network language model provide a way of capturing both semantic and syntactic regularities in language.",
  "y": "background"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_2",
  "x": "In order to to validate our methodology, we first replicate the results of <cite>Mikolov et al. (2013b)</cite> on English syntactic analogies.",
  "y": "uses"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_3",
  "x": "The vectors of <cite>Mikolov et al. (2013b)</cite> were trained on 320M tokens of broadcast news data, as described by Mikolov et al. (2011) .",
  "y": "background"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_4",
  "x": "For comparison with the results of <cite>Mikolov et al. (2013b)</cite> , we limit the data to the first 320M lowercased tokens of the corpus.",
  "y": "motivation"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_5",
  "x": "<cite>Mikolov et al. (2013b)</cite> obtain their best results with vectors of size 1600 that combine several models, but do not elaborate how this composite model was constructed. Instead, we take as a point of reference their second-best model, which employs 640-dimensional vectors produced by a single recursive neural network (RNN) language model.",
  "y": "differences"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_7",
  "x": "The first, labeled as M13, is the result of applying the vectors of <cite>Mikolov et al. (2013b)</cite> to their test set.",
  "y": "uses"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_8",
  "x": "Our verbal and adjectival vectors obtain slightly lower accuracies than the RNN trained vectors of <cite>Mikolov et al. (2013b)</cite> , but they are not far off.",
  "y": "similarities differences"
 },
 {
  "id": "af6c68ef5f80eac2274bf33a894d1f_9",
  "x": "We follow the methodology of <cite>Mikolov et al. (2013b)</cite> in limiting analogy questions to the 100 most frequent verbs or nouns.",
  "y": "uses"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_0",
  "x": "N-gram-based models are Markov models over sequences of tuples or operations encapsulating tuples<cite> (Durrani et al., 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_1",
  "x": "In order to deal with these problems, search is carried out only on a graph of pre-calculated orderings, and ad-hoc reordering limits are imposed to constrain the search space (Crego et al., 2005; , or a higher beam size is used in decoding<cite> (Durrani et al., 2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_2",
  "x": "In this work, we extend the N-gram model, based on operation sequences<cite> (Durrani et al., 2011)</cite> , to use phrases during decoding.",
  "y": "extends"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_3",
  "x": "<cite>Durrani et al. (2011)</cite> recently addressed these problems by proposing an operation sequence Ngram model which strongly couples translation and reordering, hypothesizes all possible reorderings and does not require POS-based rules.",
  "y": "background"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_4",
  "x": "Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework<cite> (Durrani et al., 2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_5",
  "x": "(Refer to Algorithm 1 in <cite>Durrani et al. (2011)</cite> ).",
  "y": "background"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_6",
  "x": "The reordering operations (gaps and jumps) are generated by looking at the position of the translator, the last foreign word generated etc. (Refer to Algorithm 1 in <cite>Durrani et al. (2011)</cite> ).",
  "y": "uses"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_7",
  "x": "We extended the training steps in <cite>Durrani et al. (2011)</cite> to extract a phrase lexicon from the parallel data.",
  "y": "extends"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_8",
  "x": "We extended the decoder developed by <cite>Durrani et al. (2011)</cite> and tried three ideas.",
  "y": "extends"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_9",
  "x": "We follow the training steps described in <cite>Durrani et al. (2011)</cite> , consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models.",
  "y": "uses"
 },
 {
  "id": "b0a50145121eb797cf8e6ebc2f49e0_10",
  "x": "We mark a result as sig-8 Discontinuous source-side units did not lead to any improvements in<cite> (Durrani et al., 2011)</cite> and increased the decoding times by multiple folds.",
  "y": "differences"
 },
 {
  "id": "b21dfcb9854b0b48af47f4f13899b0_0",
  "x": "In our previous work (Zhang and Litman, 2014; <cite>Zhang and Litman, 2015)</cite> , we focused on 1) and 2), the automatic extraction and classification of revisions for argumentative writings.",
  "y": "background"
 },
 {
  "id": "b21dfcb9854b0b48af47f4f13899b0_1",
  "x": "In our previous work (Zhang and Litman, 2014; <cite>Zhang and Litman, 2015)</cite> , we focused on 1) and 2), the automatic extraction and classification of revisions for argumentative writings. In this work, we extend our framework to integrate the automatic analyzer with a web-based interface to support student argumentative writings.",
  "y": "extends background"
 },
 {
  "id": "b21dfcb9854b0b48af47f4f13899b0_2",
  "x": "Following the argumentative revision definition in our prior work<cite> (Zhang and Litman, 2015)</cite> , revisions are first categorized to Content (Text-based) and Surface 3 according to whether the revision changed the meaning of the essay or not.",
  "y": "uses"
 },
 {
  "id": "b21dfcb9854b0b48af47f4f13899b0_3",
  "x": "Our prior work<cite> (Zhang and Litman, 2015)</cite> demonstrates that only Text-based revisions are significantly correlated with the writing improvement.",
  "y": "background"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_0",
  "x": "From a synchronic perspective, <cite>Reddy et al. (2011</cite> ), Schulte im Walde et al. (2013 and Schulte im Walde et al. (2016a) are closest to our approach, since they predict the compositionality of compounds using vector space representations.",
  "y": "background similarities"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_1",
  "x": "Several studies have been conducted in order to measure compositionality for compounds in different languages (von der Heide and Borgwaldt, 2009;<cite> Reddy et al., 2011</cite>; Schulte im Walde et al., 2016b) .",
  "y": "background"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_2",
  "x": "However, as it is not possible to survey compositionality rating for diachronic data, we instead use the synchronic data provided by<cite> Reddy et al. (2011)</cite> (henceforth referred to as REDDY) for evaluating the quality of the Google Books Ngram data as a source for investigating the compositionality of compounds in general.",
  "y": "uses"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_3",
  "x": "Like<cite> Reddy et al. (2011)</cite> and Schulte im Walde et al. (2013), we opt for Spearman's \u03c1.",
  "y": "similarities"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_4",
  "x": "As can also be seen from Table 2 , our correlation values are considerably lower than that of<cite> Reddy et al. (2011)</cite> , but on par with a replication study by Schulte im Walde et al. (2016a) for compound-mean.",
  "y": "differences"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_5",
  "x": "We speculate that these differences are potentially due to the use of different data sets, the fact that we use a considerably smaller context window for constructing the word vectors (5 due to the restrictions of Google Ngram corpus vs. 100 in<cite> Reddy et al. (2011)</cite> and 40 in Schulte im Walde et al. (2016b) ) and the use of a compound-centric setting (as described in 4.1).",
  "y": "differences"
 },
 {
  "id": "b49e6f8181d51a998c6c27a830b98e_6",
  "x": "Our current work was limited to English compounds from<cite> Reddy et al. (2011)</cite> .",
  "y": "uses"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_0",
  "x": "While Ratnaparkhi's tag dictionary makes tagging faster but less accurate, an alternative tag dictionary that we recently proposed<cite> (Moore, 2014)</cite> makes tagging as fast as with Ratnaparkhi's tag dictionary, but with no decrease in accuracy.",
  "y": "motivation background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_1",
  "x": "We recently presented<cite> (Moore, 2014)</cite> a new method of constructing a tag dictionary that produces a tagging speed-up comparable to Ratnaparkhi's, but with no decrease in tagging accuracy.",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_2",
  "x": "While Ratnaparkhi's tag dictionary makes tagging faster but less accurate, an alternative tag dictionary that we recently proposed <cite>(Moore, 2014</cite> ) makes tagging as fast as with Ratnaparkhi's tag dictionary, but with no decrease in accuracy.",
  "y": "differences motivation"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_3",
  "x": "We recently presented<cite> (Moore, 2014)</cite> a new method of constructing a tag dictionary that produces a tagging speed-up comparable to Ratnaparkhi's, but with no decrease in tagging accuracy.",
  "y": "differences motivation"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_4",
  "x": "With a more accurate model, however, we found <cite>(Moore, 2014</cite> ) that while Ratnaparkhi's tag dictionary decreased the average number of tags per token from 45 to 3.7 on the current standard WSJ development set, it also decreased per-tag accuracy from 97.31% to 97.19%.",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_5",
  "x": "We previously presented<cite> (Moore, 2014)</cite> a tag dictionary constructed by using the annotated training set to compute a smoothed probability estimate for any possible tag given any possible word, and for each word in the training set, including in the dictionary the tags having an estimated probability greater than a fixed threshold T .",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_6",
  "x": "For full details of the feature set, see our previous paper<cite> (Moore, 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_7",
  "x": "The tagger we used is based on the fastest of the methods described in our previous work <cite>(Moore, 2014</cite>, Section 3.1) .",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_8",
  "x": "The last column shows the tagging speed in tokens per second for each of the three tag dictionaries, using the fast tagging method we previously described<cite> (Moore, 2014)</cite> , in a singlethreaded implementation in Perl on a Linux workstation equipped with Intel Xeon X5550 2.67 GHz processors.",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_9",
  "x": "For comparison, we tested our previous tagger and the fast version (english-left3words-distsim) of the Stanford tagger (Toutanova et al., 2003; Manning, 2011) recommended for practical use on the Stanford tagger website, which we found to be by far the fastest of the six publicly available taggers tested in our previous work<cite> (Moore, 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "b5149b6136c8baaed8356b562d3f96_10",
  "x": "It reduces the mean number of possible tags per token by 57% and increases the number of unambiguous tokens by by 47%, compared to the previous state of the art<cite> (Moore, 2014)</cite> for a tag dictionary that does not degrade tagging accuracy.",
  "y": "differences"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_0",
  "x": "There is a limited amount of work on incorporating graph structures into neural sequence models. Though, unlike semantics in NMT, syntactically-aware NMT has been a relatively hot topic recently, with a number of approaches claiming improvements from using treebank syntax Eriguchi et al., 2016; Nadejde et al., 2017;<cite> Bastings et al., 2017</cite>; Aharoni and Goldberg, 2017) , our graphs are different from syntactic structures.",
  "y": "differences background"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_1",
  "x": "Luckily, the modeling approach of <cite>Bastings et al. (2017)</cite> does not make any assumptions about the graph structure, and thus we build on their method.",
  "y": "background similarities"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_2",
  "x": "<cite>Bastings et al. (2017)</cite> used Graph Convolutional Networks (GCNs) to encode syntactic structure. GCNs were originally proposed by Kipf and Welling (2016) and modified to handle labeled and automatically predicted (hence noisy) syntactic dependency graphs by . Representations of nodes (i.e. words in a sentence) in GCNs are directly influenced by representations of their neighbors in the graph. The form of influence (e.g., transition matrices and parameters of gates) are learned in such a way as to benefit the end task (i.e. translation). These linguistically-aware word representations are used within a neural encoder.",
  "y": "background"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_3",
  "x": "As we use exactly the same modeling approach as in the syntactic method of <cite>Bastings et al. (2017)</cite> , we can easily compare the influence of the types of linguistic structures (i.e., syntax vs. semantics). We observe that when using full WMT data we obtain better results with semantics than with syntax (23.9 BLEU for syntactic GCN). Using syntactic and semantic GCN together, we obtain a further gain (24.9 BLEU) that suggests the complementarity of syntax and semantics.",
  "y": "uses similarities motivation"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_4",
  "x": "Graph neural networks are a family of neural architectures (Scarselli et al., 2009; Gilmer et al., 2017) specifically devised to induce representation of nodes in a graph relying on its graph structure. Graph convolutional networks (GCNs) belong to this family. While GCNs were introduced BiRNN CNN Baseline<cite> (Bastings et al., 2017)</cite> 14.9 12.6 +Sem 15.6 13.4 +Syn<cite> (Bastings et al., 2017)</cite> 16.1 13.7 +Syn + Sem 15.8 14.3 for modeling undirected unlabeled graphs (Kipf and Welling, 2016) , in this paper we use a formulation of GCNs for labeled directed graphs, where the direction and the label of an edge are incorporated.",
  "y": "differences background"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_5",
  "x": "In particular, we follow the formulation of and <cite>Bastings et al. (2017)</cite> for syntactic graphs and apply it to dependency-based semantic-role structures (Hajic et al., 2009 ) (as in Figure 1 ).",
  "y": "uses"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_6",
  "x": "The functions g u,v are scalar gates which weight the importance of each edge. Gates are particularly useful when the graph is predicted BiRNN Baseline<cite> (Bastings et al., 2017)</cite> 23.3 +Sem 24.5 +Syn<cite> (Bastings et al., 2017)</cite> 23.9 +Syn + Sem 24.9 and thus may contain errors, i.e., wrong edges.",
  "y": "background"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_7",
  "x": "The settings and the framework (Neural Monkey (Helcl and Libovick\u00fd, 2017) ) used for experiments are the ones used in <cite>Bastings et al. (2017)</cite> , which we use as baselines.",
  "y": "uses"
 },
 {
  "id": "b71321a9252376308d627c439e85b7_8",
  "x": "As in <cite>Bastings et al. (2017)</cite> , we used the standard attention-based encoder-decoder model as a baseline. We tested the impact of semantic GCNs when used on top of CNN and BiRNN encoders.",
  "y": "uses"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_0",
  "x": "In some cases, the code was initially made available, then removed, and is now back online <cite>(Tang et al., 2016a)</cite> . Similarly, when others (Tay et al., 2017; Chen et al., 2017) attempt to replicate the experiments of<cite> Tang et al. (2016a)</cite> they also produce different results to the original authors.",
  "y": "background"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_1",
  "x": "In this paper, we therefore reproduce three papers chosen as they employ widely differing methods: Neural Pooling (NP) , NP with dependency parsing (Wang et al., 2017) , and RNN <cite>(Tang et al., 2016a)</cite> , as well as having been applied largely to different datasets.",
  "y": "motivation"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_2",
  "x": "Since its inception, papers have applied different methods such as feature based (Kiritchenko et al., 2014) , Recursive Neural Networks (RecNN) (Dong et al., 2014) , Recurrent Neural Networks (RNN) <cite>(Tang et al., 2016a)</cite> , attention applied to RNN (Wang et al., 2016; Chen et al., 2017; Tay et al., 2017) , Neural Pooling (NP) Wang et al., 2017) , RNN combined with NP (Zhang et al., 2016) , and attention based neural networks (Tang et al., 2016b) .",
  "y": "background"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_3",
  "x": "They did perform a comparison across different languages, domains, corpora types, and different methods; SVM with features (Kiritchenko et al., 2014) , Rec-NN (Dong et al., 2014) , TDLSTM <cite>(Tang et al., 2016a)</cite> , Memory Neural Network (MNet) (Tang et al., 2016b) and their own attention method.",
  "y": "background"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_4",
  "x": "For the LSTMs we initialised the weights using uniform distribution U(0.003, 0.003), used Stochastic Gradient Descent (SGD) a learning rate of 0.01, cross entropy loss, padded and truncated sequence to the length of the maximum sequence in the training dataset as stated in the original paper, and we did not \"set the clipping threshold of softmax layer as 200\" <cite>(Tang et al., 2016a)</cite> as we were unsure what this meant.",
  "y": "extends differences"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_5",
  "x": "However for the neural network/deep learning approach of<cite> Tang et al. (2016a)</cite> we agree with Reimers and Gurevych (2017) that reporting multiple runs of the system over different seed values is required as the single performance scores can be misleading, which could explain why previous papers obtained different results to the original for the TDLSTM method (Chen et al., 2017; Tay et al., 2017) .",
  "y": "extends differences"
 },
 {
  "id": "b7a718664f395f048abb3655fb1d8d_6",
  "x": "We chose these word vectors as they have very different sizes (50 and 300), also they have been shown to perform well in different text types; SSWE for social media <cite>(Tang et al., 2016a)</cite> and Glove for reviews (Chen et al., 2017) .",
  "y": "similarities uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_0",
  "x": "Such paths are not only useful for link prediction (Lao et al., 2011; <cite>Gardner et al., 2014)</cite> , but also for finding explanations for direct links and help with targeted information extraction to fill in incomplete knowledge repositories (Yin et al., 2018; Zhou and Nastase, 2018) .",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_1",
  "x": "We test the extracted paths through the link prediction task on Freebase (Bollacker et al., 2008) and NELL (Carlson et al., 2010a) , using<cite> Gardner et al. (2014)</cite> 's experimental set-up: pairs of nodes are represented using their connected paths as fea-tures, and a model for predicting the direct relations is learned and tested on training and test sets for 24 relations in Freebase and 10 relations in NELL.",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_2",
  "x": "The idea of using paths in the graph has then been applied to the task of link prediction (Lao et al., 2011) , and extended to incorporate textual information<cite> (Gardner et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_3",
  "x": "The paths themselves can be incorporated in different ways in a model -as features (Lao et al., 2011; <cite>Gardner et al., 2014)</cite> , as Horn clauses to provide rules for inference in KGs whether directly or through scores that represent the strength of the path as a direct relation (Neelakantan et al., 2015; Guu et al., 2015) , also taking into account information about intermediary nodes (Das et al., 2017; Yin et al., 2018) .",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_4",
  "x": "To test the quality of these paths we ground them using the original KG and use these grounded paths in a learning framework similar to<cite> (Gardner et al., 2014)</cite> .",
  "y": "similarities"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_5",
  "x": "Figure 1: Knowledge graphs statistics on a logarithmic scale: relation and nodes frequencies for Freebase and NELL (the version used by<cite> (Gardner et al., 2014)</cite> and in this paper).",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_6",
  "x": "The Path Ranking Algorithm formalism originally proposed by (Lao and Cohen, 2010) performs two main steps to represent of a pair of nodes in a graph: (i) feature selection -adding paths that connect the node pair; (ii) feature computation - Table 1 : Graph statistics on the datasets used by<cite> (Gardner et al., 2014)</cite> , and their abstract versions associating a value for each added path.",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_7",
  "x": "Algorithms that harness path information often mine paths either by performing costly random walks (Guu et al., 2015) , traversals<cite> (Gardner et al., 2014</cite>; Neelakantan et al., 2015; Das et al., 2016) or by constructing paths through generative models (Das et al., 2017; Ding et al., 2018) .",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_8",
  "x": "Algorithms that harness path information often mine paths either by performing costly random walks (Guu et al., 2015) , traversals<cite> (Gardner et al., 2014</cite>; Neelakantan et al., 2015; Das et al., 2016) or by constructing paths through generative models (Das et al., 2017; Ding et al., 2018) . Here, we adopt a different approach, by abstracting the graph first, then finding paths in this graph through traversal algorithms.",
  "y": "background differences"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_9",
  "x": "They can be used in different ways, e.g. (i) as features in a link prediction system (e.g.<cite> (Gardner et al., 2014)</cite> ), (ii) to fill in larger portions of the graph by producing, rather than finding, groundings of the path for specific instances.",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_10",
  "x": "They can be used in different ways, e.g. (i) as features in a link prediction system (e.g.<cite> (Gardner et al., 2014)</cite> ), (ii) to fill in larger portions of the graph by producing, rather than finding, groundings of the path for specific instances. In the work presented here we test the abstract paths through the link prediction task, so we will try to ground abstract paths for relation instances in the training and test data.",
  "y": "uses background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_11",
  "x": "Because we want to compare the abstract paths found using the abstract graph with paths found using PRA, we use the experimental set-up of<cite> (Gardner et al., 2014)</cite> , where we replace the feature selection and feature computation steps with the approach presented here.",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_12",
  "x": "The data thus obtained is used for training a linear regression model (similarly to<cite> (Gardner et al., 2014)</cite> ), and tested on the provided test sets and evaluated using mean average precision (MAP).",
  "y": "similarities"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_13",
  "x": "We build abstract graphs and paths from the Freebase and NELL data described in<cite> (Gardner et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_14",
  "x": "The graphs built by<cite> Gardner et al. (2014)</cite> cover several variations, where the KGs were enhanced with < subject, verb, object > triples extracted from dependency parses of ClueWeb documents.",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_15",
  "x": "We build abstract graphs and paths from the Freebase and NELL data described in<cite> (Gardner et al., 2014)</cite> . The graphs built by<cite> Gardner et al. (2014)</cite> cover several variations, where the KGs were enhanced with < subject, verb, object > triples extracted from dependency parses of ClueWeb documents.",
  "y": "uses background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_16",
  "x": "The results presented by<cite> Gardner et al. (2014)</cite> show that this configuration very rarely (and never overall) leads to better results than the other graph variations.",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_17",
  "x": "Negative sampling The number of negative instances used in<cite> (Gardner et al., 2014)</cite> is not clearly stated.",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_18",
  "x": "The overall results of the experiments are presented in Table 3, and the relation-level results are  in Tables 4 for NELL, and 5 Table 3 : Results on the three graph variations of Freebase and NELL as reported by<cite> (Gardner et al., 2014)</cite> (G) and using abstract graphs (KG A ).",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_19",
  "x": "Overall, the results indicate that enhancing Freebase and NELL with additional facts from textual sources leads to better results, particularly when these additional facts (< subject, verb, object > triples) are processed and clustered using low dimensional dense representations<cite> Gardner et al. (2014</cite>; use embeddings obtained by running PCA on the matrix of SVO triples).",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_20",
  "x": "The second column is the best result for each relation reported by<cite> (Gardner et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_21",
  "x": "For all Freebase KG configurations,<cite> Gardner et al. (2014)</cite> have 1000 paths for most relations (approx. 6 of the relations have between 230 and 973).",
  "y": "background"
 },
 {
  "id": "b7a7b7d9a6594dadb5853c49cddddf_22",
  "x": "We include the best result on PRA (on any variation of the graph), as reported by<cite> (Gardner et al., 2014)</cite> , although since we used different negative instances the results are not directly comparable.",
  "y": "uses differences"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_0",
  "x": "More recently researchers have begun to employ deeper syntactic analysis, such as dependency parsing (Yangarber et al., 2000; Sudo et al., 2001;<cite> Sudo et al., 2003</cite>; Yangarber, 2003) .",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_1",
  "x": "For example the patterns used by Yangarber et al. (2000) are the subject-verb-object tuples from the dependency tree (the remainder of the dependency parse is discarded) while <cite>Sudo et al. (2003)</cite> allow any subtree within the dependency parse to act as an extraction pattern.",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_2",
  "x": "Predicate-Argument Model (SVO): A simple approach, used by Yangarber et al. (2000) , Yangarber (2003) and , is to use subject-verb-object tuples from the dependency parse as extraction patterns. This model can identify information which is expressed using simple predicate-argument constructions such as the relation between Acme and Smith 1 The formalism used for representing dependency patterns is similar to the one introduced by <cite>Sudo et al. (2003)</cite> .",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_3",
  "x": "This model can identify information which is expressed using simple predicate-argument constructions such as the relation between Acme and Smith 1 The formalism used for representing dependency patterns is similar to the one introduced by <cite>Sudo et al. (2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_4",
  "x": "Subtrees: The final model to be considered is the subtree model<cite> (Sudo et al., 2003)</cite> .",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_5",
  "x": "<cite>Sudo et al. (2003)</cite> compared three models (SVO, chains and subtrees) on two IE scenarios using a entity extraction task.",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_6",
  "x": "However, Stevenson and Greenwood (2006) also found that the coverage of the chain model was significantly worse than the subtree model, although <cite>Sudo et al. (2003)</cite> found that in some cases their performance could not be distinguished.",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_7",
  "x": "We compared each of the patterns models described in Section 2 using an unsupervised IE experiment similar to one described by <cite>Sudo et al. (2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_8",
  "x": "Patterns which occur frequently in relevant documents without being too prevalent in the corpus are preferred. <cite>Sudo et al. (2003)</cite> found that it was important to find the appropriate balance between these two factors.",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_9",
  "x": "For these experiments relevant documents were identified using annotations in the corpus. However, this is not necessary since <cite>Sudo et al. (2003)</cite> showed that adequate knowledge about document relevance could be obtained automatically using an IR system.",
  "y": "differences"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_10",
  "x": "In addition, <cite>Sudo et al. (2003)</cite> only generated subtrees which appeared in at least three documents.",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_11",
  "x": "Kudo et al. (2005) and <cite>Sudo et al. (2003)</cite> both used the rightmost extension algorithm to generate subtrees.",
  "y": "background"
 },
 {
  "id": "b8244f9337456f1f90a576b2398680_12",
  "x": "The value of \u03b2 in equation 1 was set using a separate corpus from which the patterns were generated, a methodology suggested by <cite>Sudo et al. (2003)</cite> .",
  "y": "uses"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_0",
  "x": "Neural machine translation has achieved great success in the last few years (Bahdanau et al., 2014; Gehring et al., 2017;<cite> Vaswani et al., 2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_1",
  "x": "The Transformer <cite>(Vaswani et al., 2017)</cite> , which has outperformed previous RNN/CNN based translation models (Bahdanau et al., 2014; Gehring et al., 2017) , is based on multi-layer self-attention networks and can be trained very efficiently.",
  "y": "motivation"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_2",
  "x": "However, even with residual connections and layer normalization, deep Transformers are still hard to train: the original Transformer <cite>(Vaswani et al., 2017)</cite> only contains 6 encoder/decoder layers.",
  "y": "background"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_3",
  "x": "The official implementation of the Transformer uses a different computation sequence (Figure 1 b) compared to the published version <cite>(Vaswani et al., 2017)</cite> (Figure 1 a), since it seems better for harder-to-learn models 1 .",
  "y": "background"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_4",
  "x": "We used the same setting as the Transformer base <cite>(Vaswani et al., 2017)</cite> except the number of warm-up steps was set to 8k.",
  "y": "extends differences"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_5",
  "x": "We used a beam size of 4 for decoding, and evaluated tokenized case-sensitive BLEU with the averaged model of the last 5 checkpoints saved with an interval of 1,500 training steps <cite>(Vaswani et al., 2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_6",
  "x": "v1 and v2 stand for the computation order of the proposed Transformer <cite>(Vaswani et al., 2017)</cite> and that of the official implementation respectively. \"\u00ac\" means fail to converge, \"None\" means not reported in original works, \"*\" indicates our implementation of their approach.",
  "y": "background"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_7",
  "x": "In contrast to all previous works Wu et al., 2019) which show that deep Transformers with the computation order as in<cite> Vaswani et al. (2017)</cite> have difficulty in convergence.",
  "y": "background"
 },
 {
  "id": "bb133ba3dfe483412672b44b777c4a_8",
  "x": "In this paper, we first investigate convergence differences between the published Transformer <cite>(Vaswani et al., 2017)</cite> and the official implementation of the Transformer , and compare the differences of computation orders between them.",
  "y": "differences"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_0",
  "x": "In order to compare the performance with the state-of-the-art, we have also evaluated ROOT9 in subsets of the<cite> Weeds et al. (2014)</cite> datasets, proving that it is in fact competitive.",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_1",
  "x": "Co-hyponymy (or coordination) is instead the relation held by words sharing a close hypernym, which are therefore attributionally similar<cite> (Weeds et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_2",
  "x": "The ability of discriminating hypernymy, co-hyponymy and random words has potentially infinite applications, including Automatic Thesauri Creation, Paraphrasing, Textual Entailment, Sentiment Analysis and so on<cite> (Weeds et al., 2014</cite>; Tungthamthiti et al. 2015) .",
  "y": "background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_3",
  "x": "For this reason, in the last decades, numerous methods, datasets and shared tasks have been proposed to improve computers' ability in such discrimination, generally achieving promising results (Santus et al., 2016b; Roller et al., 2014<cite> , Weeds et al., 2014</cite> Santus et al. 2014a; Rimmel, 2014; Lenci and Benotto, 2012; Kotlerman et al., 2010; Geffet and Dagan, 2005; Weeds and Weir, 2003) .",
  "y": "background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_4",
  "x": "The former have been shown to outperform the latter in<cite> Weeds et al. (2014)</cite> , even though Levy et al. (2015) have claimed that these methods may learn whether a term y is a prototypical hypernym, regardless of its actual relation with a term x. In this paper we further investigate and revise ROOT13 (Santus et al., 2016b) , a supervised method based on a Random Forest algorithm and thirteen corpus-based features.",
  "y": "extends background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_5",
  "x": "In order to compare ROOT9 with the state-of-the-art, we have also evaluated it in the<cite> Weeds et al. (2014)</cite> datasets.",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_6",
  "x": "Also in 1 The 9,600 pairs are available at https://github.com/esantus/ROOT9 relation to the state of the art, ROOT9 is proved to be competitive, being slightly outperformed in all the datasets only by the svmCAT model<cite> (Weeds et al., 2014)</cite> , which is a Support Vector Machine (SVM) classifier run on the concatenation of the distributional vectors of the words in the pairs.",
  "y": "differences"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_7",
  "x": "Roller et al. (2014) used the vectors' difference, while<cite> Weeds et al. (2014)</cite> implemented numerous combinations (difference, multiplication, sum, concatenation, etc.), comparing them against the most common unsupervised methods.",
  "y": "background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_8",
  "x": "We have performed three tasks: i) an ablation test to evaluate the contribution of the features on our dataset (henceforth, ROOT9 Dataset; see Section 4.2); ii) an evaluation against the state of the art, and -in particularagainst the best performant models in<cite> Weeds et al. (2014)</cite> ; iii) an evaluation on switched pairs to verify whether the actual semantic relations or the prototypical hypernyms (Levy et al., 2015) were learnt.",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_9",
  "x": "The second task, which is described in Section 6, consisted in binary classification tasks on the four datasets proposed by<cite> Weeds et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_10",
  "x": "The task allowed us to compare ROOT9 against the state of the art models reported in<cite> Weeds et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_11",
  "x": "In order to compare ROOT9 to the state-of-the-art, we have evaluated it with the datasets created by<cite> Weeds et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_12",
  "x": "The WN dataset<cite> (Weeds et al., 2014</cite> ) -meaning both WN Hyper and WN Co-Hyp -in particular, was built after noticing that supervised systems tended to perform well also on random vectors.",
  "y": "background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_13",
  "x": "In order to compare ROOT9 to the state-of-the-art, we have evaluated it with the datasets created by<cite> Weeds et al. (2014)</cite> . The WN dataset<cite> (Weeds et al., 2014</cite> ) -meaning both WN Hyper and WN Co-Hyp -in particular, was built after noticing that supervised systems tended to perform well also on random vectors.",
  "y": "uses background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_15",
  "x": "The discrepancy with what found by<cite> Weeds et al. (2014)</cite> namely that random vectors perform particularly well when words are re-used in the dataset -may depend on the small number of features, which does not allow the system to identify discriminative random dimensions.",
  "y": "background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_16",
  "x": "In the second task (see Section 6), we have used as baselines the most competitive models reported in<cite> Weeds et al. (2014)</cite> , namely the SVM classifiers trained on the PPMI vector of the second word (svmSINGLE), or on the concatenated (svmCAT), summed (svmADD), multiplied (svmMULT) and subtracted (svmDIFF) PPMI vectors of the words in the pair.",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_17",
  "x": "However, it is worth noticing here that such difference disappears with the WN datasets proposed by<cite> Weeds et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_18",
  "x": "In Table 4 , we show ROOT9's performance compared to the best systems reported by<cite> Weeds et al. (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_19",
  "x": "The scores are all calculated on subsets of<cite> Weeds et al. (2014)</cite> 's datasets, as reported in Section 4.3.",
  "y": "uses"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_20",
  "x": "Considering all the datasets, ROOT9 is the second best performing system, after svmCAT<cite> (Weeds et al., 2014)</cite> , which uses the SVM classifier on the concatenation of PPMI vectors, containing as features all major grammatical dependency relations involving open class Parts Of Speech.",
  "y": "differences background"
 },
 {
  "id": "bbb91e450b3503166bcfae60e9ba72_21",
  "x": "The impressive results in our dataset, developed by randomly extracting 9,600 pairs from EVALution , Lenci/Benotto (Benotto, 2015) and BLESS (Baroni and Lenci, 2011) , were further tested against the state-of-the-art models presented in<cite> Weeds et al. (2014</cite> In future experiment, we plan to increase the number of features, investigating new distributional properties that may help in the classification without incurring in memorization effects such as those described by Levy et al. (2015) .",
  "y": "uses future_work"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_0",
  "x": "Section 3 then empirically analyzes correlations in two recent argument corpora, one annotated for 15 well-defined quality dimensions taken from theory<cite> (Wachsmuth et al., 2017a)</cite> and one with 17 reasons for quality differences phrased spontaneously in practice (Habernal and Gurevych, 2016a) .",
  "y": "uses"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_2",
  "x": "<cite>Wachsmuth et al. (2017a)</cite> point out that dialectical builds on rhetorical, and rhetorical builds on logical quality.",
  "y": "background"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_3",
  "x": "9111 argument pairs were then labeled with one or more of the 17 reason labels in Table 2 Negative Properties of Argument B Positive Properties of Argument A Quality Dimension 5-1 5-2 5-3 6-1 6-2 6-3 7-1 7-2 7-3 7-4 8-1 8-4 8-5 9-1 9-2 9-3 9- <cite>Wachsmuth et al. (2017a)</cite> given for each of the 17+1 reason labels of Habernal and Gurevych (2016a) .",
  "y": "background"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_4",
  "x": "9111 argument pairs were then labeled with one or more of the 17 reason labels in Table 2 Negative Properties of Argument B Positive Properties of Argument A Quality Dimension 5-1 5-2 5-3 6-1 6-2 6-3 7-1 7-2 7-3 7-4 8-1 8-4 8-5 9-1 9-2 9-3 9- <cite>Wachsmuth et al. (2017a)</cite> given for each of the 17+1 reason labels of Habernal and Gurevych (2016a) . These pairs represent the practical view in our experiments.",
  "y": "uses"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_5",
  "x": "For Hypotheses 1 and 2, we consider all 736 pairs of arguments from Habernal and Gurevych (2016a) where both have been annotated by <cite>Wachsmuth et al. (2017a)</cite> .",
  "y": "uses"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_6",
  "x": "Besides, the descriptions of 6-2 and 6-3 sound like local but cor- Table 4 : The mean rating for each quality dimension of those arguments from <cite>Wachsmuth et al. (2017a)</cite> given for each reason label (Habernal and Gurevych, 2016a) .",
  "y": "uses"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_7",
  "x": "For explicitness, we computed the mean rating for each quality dimension of all arguments from <cite>Wachsmuth et al. (2017a)</cite> with a particular reason label from Habernal and Gurevych (2016a) .",
  "y": "uses"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_8",
  "x": "We emulated the expert annotation process carried out by <cite>Wachsmuth et al. (2017a)</cite> on CrowdFlower in order to evaluate whether lay annotators suffice for a theory-based quality assessment.",
  "y": "uses"
 },
 {
  "id": "bd2a718f75d206ef3f2cb5648585d5_9",
  "x": "On one hand, we compared the mean of all 10 crowd ratings to the mean of the three ratings of <cite>Wachsmuth et al. (2017a)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdcd8b0f3a56606427ee298d454b52_0",
  "x": "Because SLMs can be trained from only unlabeled text, they can be applied for ADS even when the relations of interest are not specified in advance <cite>(Downey et al., 2007)</cite> . In this paper, we show that an ADS technique based on SLMs is improved substantially when the language model it employs becomes more accurate.",
  "y": "differences"
 },
 {
  "id": "bdcd8b0f3a56606427ee298d454b52_1",
  "x": "For relations of arity greater than one, we consider the typechecking task, an important sub-task of extraction <cite>(Downey et al., 2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdcd8b0f3a56606427ee298d454b52_2",
  "x": "We experiment with choices of n from 2 to 4, and two popular smoothing approaches, Modified Kneser-Ney (Chen and Goodman, 1996) and Witten-Bell (Bell et al., 1990) . Unsupervised Hidden Markov Models (HMMs) are an alternative SLM approach previously shown to offer accuracy and scalability advantages over ngram models in ADS <cite>(Downey et al., 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "bdcd8b0f3a56606427ee298d454b52_3",
  "x": "In our experiments, we utilize an ADS approach previously proposed for HMMs <cite>(Downey et al., 2007)</cite> and adapt it to also apply to n-gram models, as detailed below.",
  "y": "extends"
 },
 {
  "id": "bdcd8b0f3a56606427ee298d454b52_4",
  "x": "The first two data sets evaluate ADS for unsupervised information extraction, and were taken from <cite>(Downey et al., 2007)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdcd8b0f3a56606427ee298d454b52_5",
  "x": "A model selection technique that picks the HMM model with lowest perplexity (HMM 1-100) results in better ADS performance than previous results. As shown in Table 2, HMM 1-100 reduces error over the HMM-T model in <cite>(Downey et al., 2007)</cite> by 26%, on average.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_0",
  "x": "This reduces feature sparsity and has been shown to improve PRA inference (Gardner et al., 2013) , <cite>(Gardner et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_1",
  "x": "This is different from the scheme in (Gardner et al., 2013) and <cite>(Gardner et al., 2014)</cite> , which adds edges between KB nodes by mining surface relations from an external corpus.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_2",
  "x": "In contrast, the previous approaches of adding edges or embeddings to the KB (Gardner et al., 2013) , and <cite>vector space random walk PRA</cite> <cite>(Gardner et al., 2014)</cite> are batch procedures.",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_3",
  "x": "We term this procedure as On-Demand Augmentation (ODA), because the search can be performed during test time in an on-demand manner. In contrast, the previous approaches of adding edges or embeddings to the KB (Gardner et al., 2013) , and <cite>vector space random walk PRA</cite> <cite>(Gardner et al., 2014)</cite> are batch procedures.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_4",
  "x": "As we shall see in Section 4, due to a limited search space, on-demand augmentation is much faster compared to algorithms in (Gardner et al., 2013; <cite>Gardner et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_5",
  "x": "We term this procedure as On-Demand Augmentation (ODA), because the search can be performed during test time in an on-demand manner. As we shall see in Section 4, due to a limited search space, on-demand augmentation is much faster compared to algorithms in (Gardner et al., 2013; <cite>Gardner et al., 2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_6",
  "x": "Our experiments suggest that ODA provides better performance than (Gardner et al., 2013) and nearly the same prediction performance as provided by <cite>(Gardner et al., 2014)</cite> , but in both cases with the added advantage of faster running time and greater flexibility due to its online and on-demand nature.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_7",
  "x": "Instead of hard mapping of surface relations to latent embeddings, <cite>(Gardner et al., 2014 )</cite> perform a 'soft' mapping using <cite>vector space random walks</cite>.",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_8",
  "x": "Instead of hard mapping of surface relations to latent embeddings, <cite>(Gardner et al., 2014 )</cite> perform a 'soft' mapping using <cite>vector space random walks</cite>. Although, like others, we too use an external corpus to augment the KB, the crucial difference in our approach is that apart from adding surface relations, we also add bridging entities that enable us to create new paths in the KB.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_10",
  "x": "PRA-SVO and <cite>PRA-VS</cite> are the systems proposed in (Gardner et al., 2013) and <cite>(Gardner et al., 2014)</cite> respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus.",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_11",
  "x": "**PRA-SVO AND <cite>PRA-VS</cite>** PRA-SVO and <cite>PRA-VS</cite> are the systems proposed in (Gardner et al., 2013) and <cite>(Gardner et al., 2014)</cite> respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus.",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_12",
  "x": "**PRA-SVO AND <cite>PRA-VS</cite>** PRA-SVO and <cite>PRA-VS</cite> are the systems proposed in (Gardner et al., 2013) and <cite>(Gardner et al., 2014)</cite> respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus. In contrast, PRA-ODA, the method proposed in the paper, also expands the set of nodes through bridging entities, and performs the augmentation in an on-demand manner.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_13",
  "x": "PRA-SVO, <cite>PRA-VS</cite> are the systems proposed in (Gardner et al., 2013; <cite>Gardner et al., 2014)</cite> .",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_14",
  "x": "We used the implementation of PRA provided by the authors of <cite>(Gardner et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_15",
  "x": "For our experiments, we used the same 10 NELL relation data as used in <cite>(Gardner et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_16",
  "x": "Values for d max , and K, the most frequent paths, were obtained by tuning on a development set for 4 relations (athleteplaysforsport,actorstarredinmovie,citylocatedincountry (Gardner et al., 2013; <cite>Gardner et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_17",
  "x": "Between the two top performing systems, i.e., PRA-ODA and <cite>PRA-VS</cite>, PRA-ODA is faster by a factor of 1.8.",
  "y": "differences"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_18",
  "x": "For the L 1 and L 2 regularization parameters in the logistic regression classifier, we used the same values as used in (Gardner et al., 2013; <cite>Gardner et al., 2014)</cite> , viz., L 1 = 0.005, and L 2 = 1.0.",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_19",
  "x": "We compare the results (PRA-ODA) with the PRA algorithm executed on the NELL KB, NELL KB augmented with surface relations (PRA-SVO) (Gardner et al., 2013) and <cite>vector space random walk PRA</cite> (<cite>PRA-VS</cite>) <cite>(Gardner et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_20",
  "x": "The run times, i.e, the time taken to perform an entire experiment for PRA-SVO and <cite>PRA-VS</cite> includes the time taken to augment NELL KB with SVO edges.",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_21",
  "x": "The <cite>PRA-VS</cite> runtime also includes the time taken for generating embeddings to perform the <cite>vector space random walk</cite>.",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_22",
  "x": "The <cite>PRA-VS</cite> runtime also includes the time taken for generating embeddings to perform the <cite>vector space random walk</cite>. As can be seen from Table 2 and Table 3 , our scheme, PRA-ODA, provides performance equivalent to PRA-VS with faster running time (speed up of 1.8).",
  "y": "similarities"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_23",
  "x": "In addition to the time taken for the full SVO augmentation, <cite>PRA-VS</cite> takes additional time to generate embeddings (13 minutes) from the added verbs.",
  "y": "background"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_24",
  "x": "We note that the batch augmentation in case of PRA-SVO and <cite>PRA-VS</cite>, and embedding computation in case of <cite>PRA-VS</cite> are all specific to the relations in the evaluation set, and hence can't be ignored as a one-time offline cost.",
  "y": "uses"
 },
 {
  "id": "bdd7a4dabf8a8d7c0a2b638eb6eb72_25",
  "x": "An additional advantage of the proposed algorithm is that it can also be run on the top of any PRA based algorithm such as the PRA-SVO and <cite>PRA-VS</cite>.",
  "y": "uses"
 },
 {
  "id": "be26538a785f9ec9edc1ea031194cf_0",
  "x": "Although there are many previous works which deal with Hindi and English hate speech (the top two languages in India), but very few on the code-switched version (Hinglish) of the two (<cite>Mathur et al. 2018</cite>) .",
  "y": "motivation"
 },
 {
  "id": "be26538a785f9ec9edc1ea031194cf_1",
  "x": "Thus, with this in mind, we build a transfer learning based model for the code-switched language Hinglish, which outperforms the baseline model of (<cite>Mathur et al. 2018</cite>) .",
  "y": "differences"
 },
 {
  "id": "be26538a785f9ec9edc1ea031194cf_2",
  "x": "In this work, we use the datasets released by (Davidson et al. 2017 ) and HEOT dataset provided by (<cite>Mathur et al. 2018</cite>) .",
  "y": "uses"
 },
 {
  "id": "be26538a785f9ec9edc1ea031194cf_3",
  "x": "Results Table 3 shows the performance of our model (after getting trained on (Davidson et al. 2017) ) with two types of embeddings in comparison to the models by (<cite>Mathur et al. 2018</cite>) and (Davidson et al. 2017 ) on the HEOT dataset averaged over three runs. We also compare results on pre-trained embeddings. As shown in the table, our model when given Glove embeddings performs better than all other models.",
  "y": "differences"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_0",
  "x": "Since sentiment lexicons helped in improving the accuracy of sentiment classification models (Liu and Zhang, 2012; Al-Sallab et al., 2017; Badaro et al., 2014a Badaro et al., ,b, 2015 , several researchers are working on developing emotion lexicons for different languages such as English, French, Polish and Chinese (Mohammad, 2017; Bandhakavi et al., 2017; Yang et al., 2007; Mohammad and Turney, 2013; Abdaoui et al., 2017;<cite> Staiano and Guerini, 2014</cite>; Maziarz et al., 2016; Janz et al., 2017) .",
  "y": "background"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_1",
  "x": "For example, DepecheMood<cite> (Staiano and Guerini, 2014)</cite> , one of the largest publicly available emotion lexicon for English, includes around 37K terms while SentiWordNet (SWN) (Esuli and Sebastiani, 2007; Baccianella et al., 2010) , a large scale English sentiment lexicon semi-automatically generated using English WordNet (EWN) (Fellbaum, 1998) , includes around 150K terms annotated with three sentiment scores: positive, negative and objective.",
  "y": "background"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_2",
  "x": "While WordNet Affect, EmoLex and AffectNet include terms with emotion labels, Affect database (Neviarouskaya et al., 2007) and DepecheMood<cite> (Staiano and Guerini, 2014)</cite> include words that have emotion scores instead, which can be useful for compositional computations of emotion scores.",
  "y": "background"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_3",
  "x": "<cite>Staiano and Guerini (2014)</cite> utilized news articles from rappler.com.",
  "y": "background"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_4",
  "x": "We select to expand the DepecheMood variation with normalized scores since this variation performed best according to the presented results in<cite> (Staiano and Guerini, 2014)</cite> .",
  "y": "extends differences"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_5",
  "x": "We considered the same emotion mapping assumptions presented in the work of<cite> (Staiano and Guerini, 2014)</cite> : Fear \u2192 Afraid, Anger \u2192 Angry, Joy \u2192 Happy, Sadness \u2192 Sad and Surprise \u2192 Inspired.",
  "y": "similarities"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_6",
  "x": "Disgust was not aligned with any emotion in EmoWordNet and hence was discarded as also assumed in<cite> (Staiano and Guerini, 2014)</cite> .",
  "y": "similarities"
 },
 {
  "id": "c0cac496ec0abdfd3f6bd9914f4cc4_7",
  "x": "As stated in<cite> (Staiano and Guerini, 2014)</cite> paper, 'Disgust' emotion was excluded since there was no corresponding mapping in EmoWordNet/DepecheMood.",
  "y": "similarities"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_0",
  "x": "An interesting approach to the problem of parsing efficiency was using supertagging (Clark and Cur-ran, 2004b; Clark and Curran, 2004a; Wang, 2003; Wang and Harper, 2004; Nasr and Rambow, 2004; <cite>Ninomiya et al., 2006</cite>; , which was originally developed for lexicalized tree adjoining grammars (LTAG) (Bangalore and Joshi, 1999) .",
  "y": "background"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_1",
  "x": "<cite>Ninomiya et al. (2006)</cite> showed the parsing model using only supertagging probabilities could achieve accuracy as high as the probabilistic model for phrase structures.",
  "y": "background"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_2",
  "x": "They filter out unlikely lexical entries just to help parsing (Clark and Curran, 2004a) , or the probabilistic models for phrase structures were trained independently of the supertagger's probabilistic models (Wang and Harper, 2004; <cite>Ninomiya et al., 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_4",
  "x": "We also compared with a probabilistic model in <cite>(Ninomiya et al., 2006)</cite> . The probabilities of <cite>their model</cite> are defined as the product of probabilities of supertagging and probabilities of the probabilistic model for phrase structures, but <cite>their model</cite> was trained independently of supertagging probabilities, i.e., the supertagging probabilities are not used for reference distributions.",
  "y": "background"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_8",
  "x": "In our model, <cite>Ninomiya et al. (2006)</cite> <cite>'s model 1</cite> is used as a reference distribution.",
  "y": "uses"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_9",
  "x": "The probabilistic model of lexical entry selection and its feature templates are the same as defined in <cite>Ninomiya et al. (2006)</cite> <cite>'s model 1</cite>.",
  "y": "similarities"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_10",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution.",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_11",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution. Both our model and <cite>their model</cite> consist of the probabilities for lexical entries (= p model1 (T |w)) and the probabilities for phrase structures (= the rest of each formula).",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_12",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution. Both our model and <cite>their model</cite> consist of the probabilities for lexical entries (= p model1 (T |w)) and the probabilities for phrase structures (= the rest of each formula). The only difference between our model and <cite>their model</cite> is the way of how to train model parameters for phrase structures.",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_13",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution. Both our model and <cite>their model</cite> consist of the probabilities for lexical entries (= p model1 (T |w)) and the probabilities for phrase structures (= the rest of each formula). The only difference between our model and <cite>their model</cite> is the way of how to train model parameters for phrase structures. In both our model and <cite>their model</cite>, the parameters for lexical entries (= the parameters of p model1 (T |w)) are first estimated from the word and POS sequences independently of the parameters for phrase structures.",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_14",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution. Both our model and <cite>their model</cite> consist of the probabilities for lexical entries (= p model1 (T |w)) and the probabilities for phrase structures (= the rest of each formula). The only difference between our model and <cite>their model</cite> is the way of how to train model parameters for phrase structures. In both our model and <cite>their model</cite>, the parameters for lexical entries (= the parameters of p model1 (T |w)) are first estimated from the word and POS sequences independently of the parameters for phrase structures. That is, the estimated parameters for lexical entries are the same in both models, and hence the probabilities of p model1 (T |w) of both models are the same. Note that the parameters for lexical entries will never be updated after this estimation stage; i.e., the parameters for lexical entries are not estimated in the same time with the parameters for phrase structures. The difference of our model and <cite>their model</cite> is the estimation of parameters for phrase structures.",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_15",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution. Both our model and <cite>their model</cite> consist of the probabilities for lexical entries (= p model1 (T |w)) and the probabilities for phrase structures (= the rest of each formula). The only difference between our model and <cite>their model</cite> is the way of how to train model parameters for phrase structures. In both our model and <cite>their model</cite>, the parameters for lexical entries (= the parameters of p model1 (T |w)) are first estimated from the word and POS sequences independently of the parameters for phrase structures. That is, the estimated parameters for lexical entries are the same in both models, and hence the probabilities of p model1 (T |w) of both models are the same. Note that the parameters for lexical entries will never be updated after this estimation stage; i.e., the parameters for lexical entries are not estimated in the same time with the parameters for phrase structures. The difference of our model and <cite>their model</cite> is the estimation of parameters for phrase structures. In our model, given the probabilities for lexical entries, the parameters for phrase structures are estimated so as to maximize the entire probabilistic model (= the product of the probabilities for lexical entries and the probabilities for phrase structures) in the training corpus. In <cite>their model</cite>, the parameters for phrase structures are trained without using the probabilities for lexical entries, i.e., the parameters for phrase structures are estimated so as to maximize the probabilities for phrase structures only.",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_16",
  "x": "The formula of our model is the same as <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite>. But, <cite>their model</cite> is not a probabilistic model with a reference distribution. Both our model and <cite>their model</cite> consist of the probabilities for lexical entries (= p model1 (T |w)) and the probabilities for phrase structures (= the rest of each formula). The only difference between our model and <cite>their model</cite> is the way of how to train model parameters for phrase structures. In both our model and <cite>their model</cite>, the parameters for lexical entries (= the parameters of p model1 (T |w)) are first estimated from the word and POS sequences independently of the parameters for phrase structures. That is, the estimated parameters for lexical entries are the same in both models, and hence the probabilities of p model1 (T |w) of both models are the same. Note that the parameters for lexical entries will never be updated after this estimation stage; i.e., the parameters for lexical entries are not estimated in the same time with the parameters for phrase structures. The difference of our model and <cite>their model</cite> is the estimation of parameters for phrase structures. In our model, given the probabilities for lexical entries, the parameters for phrase structures are estimated so as to maximize the entire probabilistic model (= the product of the probabilities for lexical entries and the probabilities for phrase structures) in the training corpus. In <cite>their model</cite>, the parameters for phrase structures are trained without using the probabilities for lexical entries, i.e., the parameters for phrase structures are estimated so as to maximize the probabilities for phrase structures only. That is, the parameters for lexical entries and the parameters for phrase structures are trained independently in <cite>their model</cite>.",
  "y": "similarities differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_17",
  "x": "We must admit that the difference between our models and <cite>Ninomiya et al. (2006)</cite> <cite>'s model 3</cite> was not as great as the difference from 's model, but 'our model 1' achieved 0.56 points higher F-score, and 'our model 2' achieved 0.8 points higher F-score.",
  "y": "differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_18",
  "x": "Their parser ran around 6 times faster than <cite>Ninomiya et al. (2006)</cite> <cite>'s model 3</cite>, 9 times faster than 'our model 1' and 60 times faster than 'our model 2.' Instead, our models achieved better accuracy.",
  "y": "background"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_19",
  "x": "On the other hand, <cite>Ninomiya et al. (2006)</cite><cite>'s model 3</cite> uses the supertagger as an external module.",
  "y": "background"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_23",
  "x": "Though our model was not as fast as <cite>Ninomiya et al. (2006)</cite> <cite>'s models</cite>, it achieved the highest accuracy among them.",
  "y": "differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_24",
  "x": "Our model had around 2.65 points higher F-score than 's model and around 0.56 points higher F-score than the <cite>Ninomiya et al. (2006)</cite> <cite>'s model 3</cite>.",
  "y": "differences"
 },
 {
  "id": "c14d918f3b1b1248dc1d25a7e0b2e4_25",
  "x": "When we sacrifice parsing speed, our model achieved around 2.9 points higher F-score than 's model and around 0.8 points higher F-score than <cite>Ninomiya et al. (2006)</cite> <cite>'s model 3</cite>.",
  "y": "differences"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_0",
  "x": "(ii) The local approach might suffer from the data sparseness issue of unseen words/features, the difficulty of calibrating, and the failure to induce the underlying similarity structures at high levels of abstraction for EL (due to the extensive reliance on the hand-designed coarse features) (Sun et al., 2015;<cite> Francis-Landau et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_1",
  "x": "In practice, the features automatically induced by NN are combined with the discrete features in the local approach to extend their coverage for EL (Sun et al., 2015;<cite> Francis-Landau et al., 2016)</cite> . However, as the previous NN models for EL are local, they cannot capture the global interdependence among the target entities in the same document (the first limitation of the local approach). Guided by these analyses, in this paper, we propose to use neural networks to model both the local mention-to-entity similarities and the global relatedness among target entities in an unified architecture. This allows us to inherit all the benefits from the previous systems as well as overcome their inherent issues.",
  "y": "motivation background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_2",
  "x": "Our work is an extension of<cite> (Francis-Landau et al., 2016)</cite> which only considers the local similarities. Given a document, we simultaneously perform linking for every entity mention from the beginning to the end of the document. For each entity mention, we utilize convolutional neural networks (CNN) to obtain the distributed representations for the entity mention as well as its target candidates. These distributed representations are then used for two purposes: (i) computing the local similarities for the entity mention and target candidates, and (ii) functioning as the input for the recurrent neural networks (RNN) that runs over the entity mentions in the documents.",
  "y": "similarities background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_3",
  "x": "In the next step, we apply the convolution operation over w to generate the hidden vector sequence, that is then transformed by a non-linear function G and pooled by the sum function<cite> (Francis-Landau et al., 2016)</cite> .",
  "y": "uses background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_4",
  "x": "We employ the local similarities \u03c6 local (m i , p ij ) from<cite> (Francis-Landau et al., 2016)</cite> , the state-of-the-art neural network model for EL.",
  "y": "uses background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_5",
  "x": "The representative features include the anchor text counts from Wikipedia, the string match indications with the title of the Wikipedia candidate pages, or the information about the shape of the queries for candidate generations<cite> (Francis-Landau et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_6",
  "x": "The intuition for this computation is that the similarities at different levels of contexts might help to enforce the potential topic compatibility between the contexts of the entity mentions and target candidates for EL<cite> (Francis-Landau et al., 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_7",
  "x": "Following<cite> (Francis-Landau et al., 2016)</cite>, we evaluate the models on 4 different entity linking datasets: i) ACE (Bentivogli et al., 2010 ): This corpus is from the 2005 evaluation of NIST.",
  "y": "uses"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_8",
  "x": "For all the datasets, we use the standard data splits (for training data, test data and development data) as the previous works for comparable comparison<cite> (Francis-Landau et al., 2016)</cite>.",
  "y": "uses"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_9",
  "x": "Note that every parameter and resource in this work is either taken from the previous work (Nguyen and Grishman, 2016b;<cite> Francis-Landau et al., 2016)</cite> or selected by the development data.",
  "y": "background similarities"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_10",
  "x": "This section compares the proposed system (called Global-RNN) with the state-of-the-art models on our four datasets. These systems include the neural network model in<cite> (Francis-Landau et al., 2016)</cite> , the joint model for entity analysis in (Durrett and Klein, 2014) and the AIDA-light system with two-stage mapping in (Nguyen et al., 2014b) 6 . Table 2 shows the performance of the systems on the test sets with the reference knowledge base of the June 2016 Wikipedia dump.",
  "y": "background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_11",
  "x": "We also include the performance of the systems on the December 2014 Wikipedia dump that was used and provided by<cite> (Francis-Landau et al., 2016)</cite> for further and compatible comparison.",
  "y": "background similarities"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_12",
  "x": "The intuition is that the entities mentioned in a document of any domains should be related to each other. Eventually, we expect that the proposed model with global coherence features would be more robust to domain shifts than the local approach<cite> (Francis-Landau et al., 2016)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_13",
  "x": "Table 3 compares Global-RNN with the neural network EL model in<cite> (Francis-Landau et al., 2016)</cite> , the best reported model on the ACE dataset in the literature 8 .",
  "y": "background"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_14",
  "x": "Second and most importantly, Global-RNN is consistently better than the model with only local features in<cite> (Francis-Landau et al., 2016)</cite> over all the target domains (although it is less pronounced in the cts domain). This demonstrates the cross-domain robustness of the proposed model and confirms our hypothesis about the domain-independence of the global coherence features for EL.",
  "y": "background differences"
 },
 {
  "id": "c2a956a6ae0fb1ab338da01e5a5645_15",
  "x": "Sun et al. (2015) employ convolutional neural networks and neural tensor networks to model mentions, entities and contexts while <cite>Francis-Landau et al. (2016)</cite> combine CNN-based representations with sparse features to improve the performance. However, none of these work utilize recurrent neural networks to capture the coherence features as we do in this work.",
  "y": "differences background"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_0",
  "x": "Therefore, mapping documents in different languages into a common latent topic space can be of great benefit when detecting document translation pairs (Mimno et al., 2009;<cite> Platt et al., 2010)</cite> .",
  "y": "motivation"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_1",
  "x": "Aside from their widespread use on monolingual text, topic models have also been used to model multilingual data (Boyd-Graber and Blei, 2009;<cite> Platt et al., 2010</cite>; Jagarlamudi and Daum\u00e9, 2010; Fukumasu et al., 2012) , to name a few.",
  "y": "background"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_2",
  "x": "Mimno et al. (2009) introduced polylingual topic models (PLTM), an extension of latent Dirichlet allocation (LDA), and, more recently,<cite> Platt et al. (2010)</cite> proposed extensions of principal component analysis (PCA) and probabilistic latent semantic indexing (PLSI).",
  "y": "background"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_3",
  "x": "In addition, we show how the results as reported by<cite> Platt et al. (2010)</cite> can be obtained using the PLTM representation with a significant speed improvement.",
  "y": "differences"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_4",
  "x": "As in <cite>(Platt et al., 2010)</cite> and (Mimno et al., 2009 ) the task is to find document translation pairs in a multilingual collection of documents by representing documents in the probability simplex and computing similarity between their probability distribution representation across all document pairs.",
  "y": "similarities"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_5",
  "x": "We use Mallet's (McCallum, 2002) implementation of the PLTM to train and infer topics on the same data set used in<cite> Platt et al. (2010)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_6",
  "x": "This same approach was used by <cite>(Platt et al., 2010)</cite> to show the absolute performance comparison.",
  "y": "uses similarities"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_7",
  "x": "Since in <cite>(Platt et al., 2010)</cite> numbers were reported on the test speeches whose word length is greater or equal to 100, we used the same subset (total of 14150 speeches) of the original test collection.",
  "y": "similarities uses"
 },
 {
  "id": "c2bfe3534597a8f192ec846619f6b1_8",
  "x": "On the same data set, <cite>(Platt et al., 2010)</cite> report accuracy of 98.9% using 50 topics, a slightly different prior distribution, and MAP instead of posterior inference.",
  "y": "extends differences"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_0",
  "x": "It was observed by<cite> [Zeng et al., 2015]</cite> that 50% of the sentences in the Riedel2010 Distant Supervision dataset [Riedel et al., 2010] , a popular DS benchmark dataset, had 40 or more words in them.",
  "y": "background"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_1",
  "x": "Given a set of sentences S = {s i }; i \u2208 [1 . . . N ], where each sentence s i contains both the entities, the task of relation extraction with distantly supervised dataset is to learn a function F r : F r (S, (e 1 , e 2 )) = 1 if relation r is true for pair(e 1 , e 2 ) 0 Otherwise PCNN:<cite> [Zeng et al., 2015]</cite> proposed the Piecewise Convolution Neural Network (PCNN), a successful model for distantly supervised relation extraction.",
  "y": "background"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_2",
  "x": "For a given bag of sentences, learning is done using the setting proposed by<cite> [Zeng et al., 2015]</cite> , wherein the sentence with the highest probability of expressing a relation in a bag is selected to train the model in each iteration.",
  "y": "uses"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_3",
  "x": "The PCNN layer is applied on the words in the sentence<cite> [Zeng et al., 2015]</cite> .",
  "y": "uses"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_4",
  "x": "It uses PCNN<cite> [Zeng et al., 2015]</cite> assumption to select the sentence with highest probability of any relation.",
  "y": "uses"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_5",
  "x": "Baselines: We compare proposed models with (a) Piecewise Convolution Neural Network (PCNN)<cite> [Zeng et al., 2015]</cite> and (b) Neural Relation Extraction with Selective Attention over Instances (NRE) [Lin et al., 2016] .",
  "y": "uses"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_6",
  "x": "We implemented PCNN model baseline following<cite> [Zeng et al., 2015]</cite> and used author provided results and implementation for NRE baseline.",
  "y": "uses"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_7",
  "x": "[ <cite>Zheng et al., 2016]</cite> aimed to leverage inter-sentence information for relation extraction in a ranking model.",
  "y": "background"
 },
 {
  "id": "c3c09df34cf9f81c1cc4fc63a18bf0_8",
  "x": "Attention mechanisms in neural networks have been successfully applied to a variety of problems, like machine translation [Bahdanau et al., 2014] , image captioning [Xu et al., 2015] , supervised relation extraction [Shen and Huang, 2016] , distantly-supervised relation extraction<cite> [Zheng et al., 2016]</cite> etc.",
  "y": "background"
 },
 {
  "id": "c42e9d10ca8876af80eee021c969d7_0",
  "x": "Dialogue structure information is of particular importance when the interaction is centered around a learning task, such as in natural language tutoring, because techniques that support empirical identification of dialogue strategies can inform not only the design of intelligent tutoring systems <cite>(Forbes-Riley et al., 2007)</cite> , but also contribute to our understanding of the cognitive and affective processes involved in learning through tutoring (VanLehn et al., 2007) .",
  "y": "background"
 },
 {
  "id": "c42e9d10ca8876af80eee021c969d7_1",
  "x": "Although traditional top-down approaches (e.g., Cade et al., 2008) and some empirical work on analyzing the structure of tutorial dialogue <cite>(Forbes-Riley et al., 2007)</cite> have yielded significant results, the field is limited by the lack of an automatic, data-driven approach to identifying dialogue structure.",
  "y": "motivation background"
 },
 {
  "id": "c42e9d10ca8876af80eee021c969d7_2",
  "x": "The importance of adjacency pairs is wellestablished in natural language dialogue (e.g., Schlegoff & Sacks, 1973) , and adjacency pair analysis has illuminated important phenomena in tutoring as well <cite>(Forbes-Riley et al., 2007)</cite> .",
  "y": "background"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_0",
  "x": "We evaluate and compare our proposed system both on our new multi-target UK election dataset, as well as on the benchmarking dataset for single-target dependent sentiment<cite> (Dong et al., 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_1",
  "x": "Recent work<cite> (Dong et al., 2014)</cite> used recursive neural networks and adaptively chose composition functions to combine child feature vectors according to their dependency type, to reflect sentiment signal propagation to the target.",
  "y": "background"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_2",
  "x": "Vo and Zhang (2015) exploit the left and right context around a target in a tweet and combine low-dimensional embedding features from both contexts and the full tweet using a number of different pooling functions. Despite not fully capturing semantic and syntactic information given the target entity, they show a much better performance than<cite> Dong et al. (2014)</cite> , indicating useful signals in relation to the target can be drawn from such context representation.",
  "y": "background"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_3",
  "x": "The resulting dataset contains 4,077 tweets, with an average of 3.09 entity mentions (targets) per tweet. As many as 3,713 tweets have more than a single entity mention (target) per tweet, which makes the task different from 2015 Semeval 10 subtask C (Rosenthal et al., 2015) and a target-dependent benchmarking dataset of<cite> Dong et al. (2014)</cite> where each tweet has only one target annotated and thus one sentiment label assigned.",
  "y": "differences"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_4",
  "x": "Data set: We evaluate and compare our proposed system to the state-of-the-art baselines on a benchmarking corpus<cite> (Dong et al., 2014</cite> ) that has been used by several previous studies (Vo and Zhang, 2015; Tang et al., 2016a; Zhang et al., 2016) .",
  "y": "uses"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_6",
  "x": "We report our experimental results in Table 2 on the single-target benchmarking corpus<cite> (Dong et al., 2014)</cite> , with three model categories: 1) tweet-level target-independent models, 2) targetdependent models without considering the 'sametarget-multi-appearance' scenario and 3) targetdependent models incorporating the 'same-targetmulti-appearance' scenario.",
  "y": "uses"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_7",
  "x": "Among the target-independent baseline models Target-ind (Vo and Zhang, 2015) and Semevalbest have shown strong performance compared with SSWE and SVM-ind (Jiang et al., 2011) as they use more features, especially rich automatic features using the embeddings of Mikolov et al. (2013) . Interestingly they also perform better than some of the targetdependent baseline systems, namely SVM-dep (Jiang et al., 2011) , Recursive NN and AdaRNN<cite> (Dong et al., 2014)</cite> , showing the difficulty of fully extracting and incorporating target information in tweets.",
  "y": "background"
 },
 {
  "id": "c4e2a9322471fb5988a5bd737fa51e_8",
  "x": "The adaptive recursive neural network, namely AdaRNN<cite> (Dong et al., 2014)</cite> , adaptively selects composition functions based on the input data and thus performs better than a standard recursive neural network model (Recursive NN<cite> (Dong et al., 2014)</cite> ).",
  "y": "background"
 },
 {
  "id": "c57e98c9c07dd5d8653e172136c901_0",
  "x": "This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process , Chinese restaurant process (Blei et al., 2010) , hierarchical Pitman-Yor process (Teh, 2006) , Indian buffet process (Ghahramani and Griffiths, 2005) , recurrent neural network (Mikolov et al., 2010; Van Den Oord et al., 2016) , long short-term memory (Hochreiter and Schmidhuber, 1997; , sequence-to-sequence model (Sutskever et al., 2014), variational auto-encoder (Kingma and Welling, 2014) , generative adversarial network (Goodfellow et al., 2014) , attention mechanism (Chorowski et al., 2015; <cite>Seo et al., 2016)</cite> , memory-augmented neural network (Graves et al., 2014; Graves et al., 2014) , stochastic neural network Miao et al., 2016) , predictive state neural network (Downey et al., 2017) , policy gradient (Yu et al., 2017) and reinforcement learning (Mnih et al., 2015) .",
  "y": "background"
 },
 {
  "id": "c594df62c01bef2ffb1a7ee9c5ea28_0",
  "x": "This approach has achieved promising initial results [6] <cite>[7]</cite> [8] [9] 14] , but many questions remain. Two outstanding questions are the best method of learning verb tensors from a corpus, and the best sentence space for a variety of different tasks.",
  "y": "motivation"
 },
 {
  "id": "c594df62c01bef2ffb1a7ee9c5ea28_2",
  "x": "The correct sentence space to use is less obvious; previous approaches have either mapped sentence meaning to the same topic-based noun space [6,<cite> 7]</cite> or defined a new space for sentence meaning, particularly plausibility space [11, 14] .",
  "y": "background"
 },
 {
  "id": "c594df62c01bef2ffb1a7ee9c5ea28_3",
  "x": "However, tensor training can be expensive and in practice, for some tasks, the verb can be approximated as a matrix<cite> [7,</cite> 14] .",
  "y": "background"
 },
 {
  "id": "c594df62c01bef2ffb1a7ee9c5ea28_4",
  "x": "Following <cite>[7]</cite> , we generate a K \u00d7 K matrix for each verb as the average of outer products of subject and verb vectors from the positively labelled subset of the training data:",
  "y": "uses"
 },
 {
  "id": "c594df62c01bef2ffb1a7ee9c5ea28_6",
  "x": "For the verb disambiguation task we use the GS2011 dataset <cite>[7]</cite> .",
  "y": "uses"
 },
 {
  "id": "c5ec401f42f79c4707770dac4f5013_0",
  "x": "Despite the success of the above research on single-turn conversational response generation, human conversations are usually coherent (Li et al., 2016c) and context-sensitive (Tian et al., 2017;<cite> Xing et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "c5ec401f42f79c4707770dac4f5013_1",
  "x": "\u2022 First, existing studies of utterance modeling mainly focus on representing utterances by using bidirectional GRU<cite> (Xing et al., 2017)</cite> or unidirectional GRU (Tian et al., 2017 ). One is the attention-based approach<cite> (Xing et al., 2017)</cite> , the other is the sequential integration approach (Tian et al., 2017) . \u2022 Utterance Representations: Bidirectional GRU vs. Unidirectional GRU<cite> Xing et al. (2017)</cite> utilized a bidirectional GRU and a word-level attention mechanism to transfer word representations to utterance representations. \u2022 Inter-utterance Representations: Attention vs. Sequential Integration<cite> Xing et al. (2017)</cite> proposed a hierarchical attention mechanism to feed the utterance representations to a backward RNN to obtain contextual representation.",
  "y": "background"
 },
 {
  "id": "c5ec401f42f79c4707770dac4f5013_2",
  "x": "For utterance representation, we consider the advantages of the two state-of-the-art approaches to encoding contextual information for context-sensitive response generation <cite>(Xing et al., 2017</cite>; Tian et al., 2017) . weighing the importance of utterances for generating open-domain conversational responses<cite> (Xing et al., 2017)</cite> , we thus model the inter-utterance representation to obtain the context vector in two measures, namely static and dynamic attention, as shown in Figure 2 .",
  "y": "similarities uses"
 },
 {
  "id": "c5ec401f42f79c4707770dac4f5013_3",
  "x": "Rather than use a hierarchical attention neural network<cite> (Xing et al., 2017)</cite> to obtain the contextual representation of a conversation, we propose two utterance-level attentions for weighting the importance of each utterance in the context, which is more simple in structure and has less number of parameters than the hierarchical attention approach.",
  "y": "extends differences"
 },
 {
  "id": "c5ec401f42f79c4707770dac4f5013_4",
  "x": "\u2022 WSI and HRAN are proposed by Tian et al. (2017) and<cite> Xing et al. (2017)</cite> respectively.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_0",
  "x": "Furthermore, we reproduce <cite>multisource projection</cite> <cite>(Tyers et al., 2018)</cite> , in which dependency trees of multiple sources are combined.",
  "y": "uses"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_1",
  "x": "We build on recent work by <cite>Tyers et al. (2018)</cite> who show that in the absence of annotated training data for the target language, a lexicalized treebank can be created by translating a target language corpus into a number of related source languages and parsing the translations using models trained on the source language treebanks.",
  "y": "extends"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_2",
  "x": "1 These annotations are then projected to the target language using separate word alignments for each source language, combined into a single graph for each sentence and decoded (Sagae and Lavie, 2006) , resulting in a treebank for the target language, Faroese in the case of <cite>Tyers et al.'s</cite> and our experiments.",
  "y": "similarities"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_3",
  "x": "The former differs from the approach of <cite>Tyers et al. (2018)</cite> , who use multiple discrete, monolingual models to parse the translated sentences, whereas in this work we use a single model trained on multiple source treebanks.",
  "y": "differences"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_4",
  "x": "Our best result of 71.5 -an absolute improvement of 7.2 points over the result reported by <cite>Tyers et al. (2018)</cite> -was achieved with multi-treebank target learning over the monolingual projections.",
  "y": "differences"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_5",
  "x": "<cite>Tyers et al. (2018)</cite> describe a method for creating synthetic treebanks for Faroese based on previous work which uses machine translation and word alignments to transfer trees from source language(s) to the target language.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_6",
  "x": "The parser output is evaluated using the gold-standard Faroese test treebank developed by <cite>Tyers et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_7",
  "x": "In contrast to <cite>Tyers et al. (2018)</cite> , they translate a target sentence and project the source parse tree back to the target during test time instead of using this approach to obtain training data for the target language.",
  "y": "differences"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_8",
  "x": "We use the same raw corpus, alignments and tokenized and segmented versions of the source translations 4 as <cite>Tyers et al. (2018)</cite> who release all of <cite>their data</cite>.",
  "y": "similarities uses"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_9",
  "x": "We use the same raw corpus, alignments and tokenized and segmented versions of the source translations 4 as <cite>Tyers et al. (2018)</cite> who release all of <cite>their data</cite>. 5 In this way, the experimental pipeline is the same as <cite>theirs</cite> but we predict POS tags and dependency annotations using our own models.",
  "y": "similarities differences"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_10",
  "x": "We use the target corpus built by <cite>Tyers et al. (2018)</cite> which comprises 28,862 sentences which were extracted from Faroese Wikipedia dumps 6 using the WikiExtractor script 7 and further pre-processed to remove any non-Faroese texts and other forms of unsuitable sentences.",
  "y": "uses"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_11",
  "x": "Machine Translation As noted by <cite>Tyers et al. (2018)</cite> , popular repositories for developing machine translation systems such as OPUS (Tiedemann, 2016) contain an inadequate amount of sentences to train a data-driven machine translation system for Faroese.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_12",
  "x": "Consequently, to create parallel source sentences, <cite>Tyers et al. (2018)</cite> use a rule-based machine translation system available in Apertium 8 to translate from Faroese to Norwegian Bokm\u00e5l.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_13",
  "x": "For a more thorough description of the machine translation process and for resource creation in general, see the work of <cite>Tyers et al. (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_14",
  "x": "We use word alignments between the Faroese text and the source translations generated by <cite>Tyers et al. (2018)</cite> using fast align (Dyer et al., 2013) , a word alignment tool based on IBM Model 2.",
  "y": "uses"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_15",
  "x": "Synthetic Source Treebanks Source translations are tokenized with UDPipe (Straka and Strakov\u00e1, 2017) by <cite>Tyers et al. (2018)</cite> .",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_16",
  "x": "Annotation Projection Once the synthetic source treebanks are compiled, i. e. the translations are parsed, the annotations are then projected from the source translations to the target language using the word alignments and <cite>Tyers et al.'s projection tool</cite>, resulting in a Faroese treebank.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_17",
  "x": "In some cases, not all tokens are aligned and <cite>Tyers et al. (2018)</cite> work around this by falling back to a 1:1 mapping between the target index and the source index.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_18",
  "x": "<cite>Tyers et al.'s projection setup</cite> removes unsuitable projected trees containing e. g. more than one root token, a token that is its own head or a token with a head outside the range of the sentence.",
  "y": "background"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_19",
  "x": "In this section, we describe our experiments, which include a replication of the main findings of <cite>Tyers et al. (2018)</cite> , using AllenNLP for POS tagging and parsing instead of UDPipe (Straka and Strakov\u00e1, 2017 Figure 3 : Multi-source projection.",
  "y": "uses"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_20",
  "x": "Comparing the results in Tables 4 and 5, we see that LAS scores tend to be slightly lower than on the version which included all target sen-WORK RESULT Rosa and Mare\u010dek (2018) 49.4 <cite>Tyers et al. (2018)</cite> 64.4 Our implementation 68.0 of <cite>Tyers et al. (2018)</cite> Our Best Model 71.5 tences, indicating that we did lose some information by filtering out a large number of sentences.",
  "y": "uses differences"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_21",
  "x": "Another reason why the multi-source model does not work as well in our experiments as it does in those of <cite>Tyers et al. (2018)</cite> might be that we use pre-trained embeddings whereas <cite>Tyers et al. (2018)</cite> do not.",
  "y": "differences"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_22",
  "x": "Note that they use predicted tokenization and segmentation whereas our experiments and <cite>Tyers et al.'s</cite> use gold tokenization and segmentation, which provides a small artificial boost.",
  "y": "similarities"
 },
 {
  "id": "c684a2be8ca8ed8db25be6e080f921_23",
  "x": "<cite>Tyers et al. (2018)</cite> report an LAS of 64.43 with a monolingual multi-source approach.",
  "y": "background"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_0",
  "x": "Recent state-of-the-art models (Wang et al., 2018; Fried et al., 2018b;<cite> Ma et al., 2019)</cite> have demonstrated large gains in accuracy on the VLN task.",
  "y": "background"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_1",
  "x": "Most recently,<cite> Ma et al. (2019)</cite> introduce a visual and textual co-attention mechanism and a route progress predictor.",
  "y": "background"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_2",
  "x": "Most recently,<cite> Ma et al. (2019)</cite> introduce a visual and textual co-attention mechanism and a route progress predictor. These approaches have significantly improved performance on the VLN task, when evaluated by metrics such as success rate. However, it is unclear where the high performance comes from.",
  "y": "motivation"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_3",
  "x": "In this paper, we show that the same trends hold for two recent state-of-the-art architectures <cite>(Ma et al., 2019</cite>; Fried et al., 2018b) for the VLN task; we also analyze to what extent object-based representations and mixture-ofexperts methods can address these issues.",
  "y": "uses"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_4",
  "x": "In this paper, we find that agents without any visual input can achieve competitive performance, matching or even outperforming their vision-based counterparts under two state-of-theart model models (Fried et al., 2018b;<cite> Ma et al., 2019)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_5",
  "x": "In this work, we analyze two recent VLN models, which typify the visual grounding approaches of VLN work: the panoramic \"follower\" model from the Speaker-Follower (SF) system of Fried et al. (2018b) and the Self-Monitoring (SM) model of<cite> Ma et al. (2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_6",
  "x": "For SM, we use a reimplementation without the progress monitor, which was shown to be most important for search in inference<cite> (Ma et al., 2019)</cite> .",
  "y": "uses"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_7",
  "x": "We compare performance on the validation sets of the R2R dataset: the val-seen split, consisting of the same environments as in training, and the val- Table 1 : Success rate (SR) of the vision-based full agent (\"RN\", using ResNet) and the non-visual agent (\"no vis.\", setting all visual features to zero) on the R2R dataset under different model architectures (SpeakerFollower (SF) (Fried et al., 2018b) and Self-Monitoring (SM)<cite> (Ma et al., 2019)</cite> ) and training schemes.",
  "y": "uses"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_8",
  "x": "We then use the same visual attention mechanism as in Fried et al. (2018b) and<cite> Ma et al. (2019)</cite> to obtain an attended object representation x obj,att over these {x obj,j } vectors.",
  "y": "uses"
 },
 {
  "id": "c705c0533600b9b93d2c89bcbc292b_11",
  "x": "The Speaker-Follower (SF) model (Fried et al., 2018b ) and the Self-Monitoring (SM) model<cite> (Ma et al., 2019)</cite> which we analyze both use sequenceto-sequence model (Cho et al., 2014) with attention (Bahdanau et al., 2015) as their base instruction-following agent.",
  "y": "uses"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_0",
  "x": "Question generation (QG) task, which takes a context and an answer as input and generates a question that targets the given answer, have received tremendous interests in recent years from both industrial and academic communities (Zhao et al., 2018) (Zhou et al., 2017) <cite>(Du et al., 2017)</cite> .",
  "y": "motivation"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_1",
  "x": "However, the inherent sequential nature of the RNN models suffers from the problem of handling long sequences. As a result, the existing QG models <cite>(Du et al., 2017)</cite> (Zhou et al., 2017 ) mainly use only sentence-level information as context.",
  "y": "background"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_2",
  "x": "When applied to a paragraphlevel context, the existing models show significant performance degradation. However, as indicated by <cite>(Du et al., 2017)</cite> , providing paragraph-level information can improve QG performance.",
  "y": "motivation"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_3",
  "x": "We follow the same data split settings as previous work on the QG tasks <cite>(Du et al., 2017)</cite> (Zhao et al., 2018) to directly compare the state-of-theart results on QG tasks.",
  "y": "uses similarities"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_4",
  "x": "\u2022 SQuAD 73K In this set, we follow the same setting as <cite>(Du et al., 2017)</cite> ; the accessible parts of the SQuAD training data are randomly divided into a training set (80%), a development set (10%), and a test set (10%).",
  "y": "similarities uses"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_5",
  "x": "The <cite>(Du et al., 2017)</cite> , and SQuAD 81K is the setting of (Zhao et al., 2018) .",
  "y": "background"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_6",
  "x": "In this paper, we compare our models with the best performing models <cite>(Du et al., 2017)</cite> (Zhao et al., 2018) in the literature.",
  "y": "similarities"
 },
 {
  "id": "c7821d22613ad91f77ea454d50a5ce_7",
  "x": "The compared models in the experiment are: \u2022 NQG-RC <cite>(Du et al., 2017)</cite> : A seq2seq question generation model based on bidirectional LSTM.",
  "y": "uses similarities"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_0",
  "x": "RNNs and their variants such as LSTM (Hochreiter and Schmidhuber, 1997) have shown success in several natural language processing (NLP) tasks, such as entity extraction (Lample et al., 2016; Ma and Hovy, 2016) , relation extraction <cite>(Vu et al., 2016a</cite>; Miwa and Bansal, 2016; Gupta et al., 2016 Gupta et al., , 2018c , language modeling (Mikolov et al., 2010; Peters et al., 2018) , slot filling (Mesnil et al., 2015; Vu et al., 2016b) , machine translation (Bahdanau et al., 2014) , sentiment analysis (Wang et al., 2016; Tang et al., 2015) , semantic textual similarity (Mueller and Thyagarajan, 2016; Gupta et al., 2018a) and dynamic topic modeling (Gupta et al., 2018d) .",
  "y": "background"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_2",
  "x": "We adopt the bi-directional recurrent neural network architecture with ranking loss, proposed by<cite> Vu et al. (2016a)</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_3",
  "x": "Ranking Objective: Similar to Santos et al. (2015) and<cite> Vu et al. (2016a)</cite> , we applied the ranking loss function to train C-BRNN.",
  "y": "similarities uses"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_4",
  "x": "The parameter \u03b3 controls the penalization of the prediction errors and m + and m are margins for the correct and incorrect classes. Following<cite> Vu et al. (2016a)</cite> , we set \u03b3 = 2, m + = 2.5 and m \u2212 = 0.5.",
  "y": "similarities uses"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_5",
  "x": "In our analysis and interpretation of recurrent neural networks, we use the trained C-BRNN ( Figure 1 )<cite> (Vu et al., 2016a)</cite> model.",
  "y": "uses similarities"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_6",
  "x": "Following<cite> Vu et al. (2016a)</cite> , we use N-grams (e.g., tri-grams) representation for each word in each subsequence S \u2264k that is input to C-BRNN to compute P (R|S \u2264k ), where the N-gram (N=3) subsequence S \u2264k is given by,",
  "y": "similarities uses"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_7",
  "x": "However,<cite> Vu et al. (2016a)</cite> has shown that the extended context helps.",
  "y": "background"
 },
 {
  "id": "c82c31a3e7b229b5aed8faeff21efa_8",
  "x": "We use the similar experimental setup as<cite> Vu et al. (2016a)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "c86271049ebbcf8eafe781a0af6a98_0",
  "x": "While some work focused on the representation of relations on the basis of triplets belonging to the KB [3] , other work proposed to enhance the distributed representation of words for representing their underlying concepts by taking into consideration the structure of the KB graph (e.g., concepts in the same category or their relationships with other concepts) <cite>[6,</cite> 18, 19] .",
  "y": "background"
 },
 {
  "id": "c86271049ebbcf8eafe781a0af6a98_1",
  "x": "A first work<cite> [6]</cite> proposes a \"retrofitting\" technique consisting in a leveraging of lexicon-derived relational information, namely adjacent words of concepts, to refine their associated word embeddings.",
  "y": "background"
 },
 {
  "id": "c86271049ebbcf8eafe781a0af6a98_2",
  "x": "In contrast to<cite> [6]</cite> , other work [18, 19] proposes an endto-end oriented approach that rather adjusts the objective function of the neural language model.",
  "y": "background"
 },
 {
  "id": "c86271049ebbcf8eafe781a0af6a98_3",
  "x": "While a naive approach would be to exploit the concept embeddings learned from the KB distributed representation <cite>[6,</cite> 18] as input of the deep neural network, we believe that a hybrid representation of the distributional semantic (namely, word embeddings) and the symbolic semantics (namely, concept embeddings taking into account the graph structure) would allow enhancing the document-query matching.",
  "y": "differences"
 },
 {
  "id": "c86271049ebbcf8eafe781a0af6a98_4",
  "x": "On the other hand, the semantic layer could be built by the representation of concepts (and their relationships) extracted from the plain text through a concept embedding<cite> [6]</cite> or a richer embedding representation of a KB sub-graph, as suggested in [2] .",
  "y": "background"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_0",
  "x": "Currently, most of the state-of-the-art VQA models (<cite>Antol et al. 2015</cite>; Chen et al. 2016; Lu et al. 2016; Ben-younes et al. 2017; Fukui et al. 2016; Kim et al. 2017) only focus on how to improve accuracy.",
  "y": "motivation"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_1",
  "x": "In Module 1, we encode all of the questions, also by Skip-Thought Vectors, from the training and validation sets of <cite>VQA</cite> (<cite>Antol et al. 2015</cite>) dataset as a 4800 by 186027 dimension basic question (BQ) matrix, and then solve the LASSO optimization problem (Huang, Alfadly, and Ghanem 2017) , with MQ, to find the top 3 similar BQ of MQ.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_2",
  "x": "Then, we verify the above claim by the detailed experiments and use the VQABQ method to analyze the robustness of 6 available pretrained stateof-the-art VQA models, provided by papers' authors, (<cite>Antol et al. 2015</cite>; Lu et al. 2016; Ben-younes et al. 2017; Fukui et al. 2016; Kim et al. 2017) .",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_3",
  "x": "Recently, there are many papers (<cite>Antol et al. 2015</cite>; Shih, Singh, and Hoiem 2016; Chen et al. 2016; Kafle and Kanan 2016; Ma, Lu, and Li 2016; Ren, Kiros, and Zemel 2015; Zhu et al. 2016; Wu et al. 2016; Lu et al. 2016; Ben-younes et al. 2017; Fukui et al. 2016; Kim et al. 2017) have proposed methods to solve the challenging VQA task.",
  "y": "background"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_4",
  "x": "We take the most popular <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) to develop our BQD.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_5",
  "x": "At the beginning, we take all of the training and validation questions from the <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) to be our basic question candidates.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_6",
  "x": "Then, we take all of the testing questions from the <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) to be our main question candidates.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_7",
  "x": "That is to say, our main question candidates and the number of main question candidates are exactly the same as the testing question set of <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite> ).",
  "y": "similarities uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_8",
  "x": "Our idea is the BQ generation for MQ and, at the same time, we only want the minimum number of BQ to represent the MQ, so modeling our problem as LASSO optimization problem is an appropriate way: (<cite>Antol et al. 2015</cite>) . \"-\" indicates the results are not available, \"-std\" means the accuracy of VQA model evaluated on the complete testing set of BQD and <cite>VQA dataset</cite> and \"-dev\" means the accuracy of VQA model evaluated on the partial testing set of BQD and <cite>VQA dataset</cite>.",
  "y": "background"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_9",
  "x": "According to the above subsections, Question Encoding and Problem Formulation, we can encode all basic question candidates from the training and validation question sets of <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) by Skip-Thought Vectors, and then we have a matrix of basic question candidates.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_10",
  "x": "Finally, we find the ranked BQ of all 244302 testing questions from the testing question set of <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) and collect them together, with the format {Image, M Q, 21 (BQ + corresponding similarity score)}, as our Basic Question Dataset (BQD).",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_11",
  "x": "We propose a novel large scale dataset, called Basic (<cite>Antol et al. 2015</cite>) . \"-\" indicates the results are not available, \"-std\" means the accuracy of VQA model evaluated on the complete testing set of BQD and <cite>VQA dataset</cite> and \"-dev\" means the accuracy of VQA model evaluated on the partial testing set of BQD and <cite>VQA dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_12",
  "x": "(<cite>Antol et al. 2015</cite>) , and the corresponding similarity scores of BQ are generated by our basic question generation method, referring to Section 3. Note that we preprocess the training and validation question datasets from the <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) , so the total number of basic question candidates is less than the total number of training and validation question datasets in <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) .",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_13",
  "x": "Furthermore, we exploit the BQD to do robustness analysis of the 6 available pretrained state-of-the-art VQA models (<cite>Antol et al. 2015</cite>; Lu et al. 2016; Ben-younes et al. 2017; Fukui et al. 2016; Kim et al. 2017) in the next subsection.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_14",
  "x": "For the image part, there is already a rapidly growing research on evaluating the robustness of deep learning models (Fawzi, Moosavi Dezfooli, and Frossard 2017;  Table 3 : MUTAN without Attention model evaluation results on BQD and <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) . \"-\" indicates the results are not available, \"-std\" means the accuracy of VQA model evaluated on the complete testing set of BQD and <cite>VQA dataset</cite> and \"-dev\" means the accuracy of VQA model evaluated on the partial testing set of BQD and <cite>VQA dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_15",
  "x": "First, we measure the accuracy of the model on the clean <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) and we call it Acc vqa .",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_16",
  "x": "We conduct our experiments on BQD and <cite>VQA</cite> (<cite>Antol et al. 2015</cite>) dataset.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_17",
  "x": "<cite>VQA dataset</cite> is based on the MS COCO Table 4 : MUTAN with Attention model evaluation results on BQD and <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) .",
  "y": "uses background"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_18",
  "x": "\"-\" indicates the results are not available, \"-std\" means the accuracy of VQA model evaluated on the complete testing set of BQD and <cite>VQA dataset</cite> and \"-dev\" means the accuracy of VQA model evaluated on the partial testing set of BQD and <cite>VQA dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_19",
  "x": "In the <cite>VQA dataset</cite>, each question is associated with 10 answers annotated by different people from Amazon Mechanical Turk (AMT).",
  "y": "background"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_20",
  "x": "Note that we only develop our work on the open-ended case in <cite>VQA dataset</cite> because it is the most popular task and we also think the open-ended task is closer to the real situation than multiple-choice one.",
  "y": "motivation uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_21",
  "x": "<cite>VQA dataset</cite> provides multiple-choice and open-ended task for evaluation.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_22",
  "x": "The accuracy is given by the following: Table 5 : MLB with Attention model evaluation results on BQD and <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) . \"-\" indicates the results are not available, \"-std\" means the accuracy of VQA model evaluated on the complete testing set of BQD and <cite>VQA dataset</cite> and \"-dev\" means the accuracy of VQA model evaluated on the partial testing set of BQD and <cite>VQA dataset</cite>.",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_23",
  "x": "Note that Figure 2 : The accuracy of state-of-the-art VQA models evaluated on BQD and <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) .",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_24",
  "x": "We want to do more advanced analysis on this model, so we claim that if the quality of Figure 3 : The accuracy decrement of state-of-the-art VQA models evaluated on BQD and <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) .",
  "y": "uses"
 },
 {
  "id": "c8cf2d615cc47395a55bc8737cd9fd_26",
  "x": "Furthermore, we can use the proposed BQD, R score and <cite>VQA dataset</cite> (<cite>Antol et al. 2015</cite>) to measure the robustness of VQA models.",
  "y": "uses"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_0",
  "x": "With the advances of deep learning, neural sequence labeling models have achieved state-ofthe-art for many tasks (Ling et al., 2015;<cite> Ma and Hovy, 2016</cite>; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_1",
  "x": "Although many authors released their code along with their sequence labeling papers (Lample et al., 2016;<cite> Ma and Hovy, 2016</cite>; Liu et al., 2018) , the implementations are mostly focused on specific model structures and specific tasks.",
  "y": "background"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_2",
  "x": "It builds a LSTM-CRF framework with CNN to encode character sequence (the same structure as <cite>Ma and Hovy (2016)</cite> ), plus POS and Cap features, within 10 lines.",
  "y": "background"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_3",
  "x": "In addition, NCRF++ integrates several state-of-the-art automatic feature extractors, such as CNN and LSTM for character sequences, leading easy reproduction of many recent work (Lample et al., 2016; Chiu and Nichols, 2016;<cite> Ma and Hovy, 2016)</cite> .",
  "y": "background"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_4",
  "x": "\u2022 Effective and efficient: we reimplement several state-of-the-art neural models (Lample et al., 2016;<cite> Ma and Hovy, 2016)</cite> using NCRF++.",
  "y": "similarities uses"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_5",
  "x": "\u2022 Word RNN together with GRU and LSTM are available in NCRF++, which are popular structures in the recent literature (Huang et al., 2015; Lample et al., 2016;<cite> Ma and Hovy, 2016</cite>; Yang et al., 2017) .",
  "y": "background"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_6",
  "x": "For POS tagging, we use the same data and split with <cite>Ma and Hovy (2016)</cite> .",
  "y": "similarities uses"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_7",
  "x": "Hyperparameters are mostly following <cite>Ma and Hovy (2016)</cite> and almost keep the same in all these experiments 5 .",
  "y": "similarities uses"
 },
 {
  "id": "c91781e76a8d7d6de7d7bc4407e799_8",
  "x": "Most of state-of-the-art models utilize the framework of word LSTM-CRF with character LSTM or CNN features (correspond to \"CLSTM+WLSTM+CRF\" and \"CCNN+WLSTM+CRF\" of our models) (Lample et al., 2016;<cite> Ma and Hovy, 2016</cite>; Yang et al., 2017; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "c9d9997b61974a537915a2c90af3cf_0",
  "x": "Multimodal sentiment analysis research focuses on understanding how an individual modality conveys sentiment information (intra-modal dynamics), and how they interact with each other (intermodal dynamics). It is a challenging research area and state-of-the-art performance of automatic sentiment prediction has room for improvement compared to human performance<cite> (Zadeh et al., 2018a)</cite> .",
  "y": "background"
 },
 {
  "id": "c9d9997b61974a537915a2c90af3cf_1",
  "x": "We use the CMU Multimodal Data Software Development Kit (SDK)<cite> (Zadeh et al., 2018a)</cite> to load and pre-process the CMU-MOSI database, which splits the 2199 opinion segments into training (1283 segments), validation (229 segments), and test (686 segments) sets.",
  "y": "uses"
 },
 {
  "id": "c9d9997b61974a537915a2c90af3cf_2",
  "x": "We use the vocal modality at the bottom of the hierarchy while using the verbal modality at the top in HF fusion. This is because in previous studies (e.g., <cite>Zadeh et al. (2018a)</cite> ) the verbal modality was shown to be the most effective for unimodal sentiment analysis, while the vocal modality was shown to be the least effective.",
  "y": "background similarities"
 },
 {
  "id": "c9d9997b61974a537915a2c90af3cf_3",
  "x": "To evaluate the performance of sentiment score prediction, following previous work<cite> (Zadeh et al., 2018a)</cite> , we Tables 2 and 3 , the numbers in bold are the best performance for each modality or fusion strategy.",
  "y": "uses"
 },
 {
  "id": "c9d9997b61974a537915a2c90af3cf_4",
  "x": "3 The verbal models have the best performance here, which is consistent with previous sentiment analysis studies on multiple databases (e.g., <cite>Zadeh et al. (2018a)</cite> ). This suggests that lexical information remains the most effective for sentiment analysis.",
  "y": "similarities"
 },
 {
  "id": "cc5927700475b7abc0482a28ab209a_0",
  "x": "Subsequently, there has been emphasis on post-processing the embeddings to improve their performance on downstream tasks <cite>(Mu and Viswanath, 2018)</cite> or to induce linguistic properties (Mrk\u0161ic et al.; Faruqui et al., 2015) .",
  "y": "background"
 },
 {
  "id": "cc5927700475b7abc0482a28ab209a_1",
  "x": "In particular, the Principal Component Analysis (PCA) based post-processing algorithm proposed by <cite>(Mu and Viswanath, 2018)</cite> has led to significant gains in word and sentence similarity tasks, and has also proved useful in dimensionality reduction (Raunak, 2017) .",
  "y": "background"
 },
 {
  "id": "cc5927700475b7abc0482a28ab209a_2",
  "x": "4. We point out the limitations of applying variance based post-processing <cite>(Mu and Viswanath, 2018)</cite> and demonstrate that it leads to a decrease in performance in sentence classification and machine translation arXiv:1910.02211v1 [cs.CL] 5 Oct 2019 In Section 1, we provide an introduction to the problem statement.",
  "y": "motivation"
 },
 {
  "id": "cc5927700475b7abc0482a28ab209a_3",
  "x": "In this section, we first describe and then evaluate the post-processing algorithm (PPA) proposed in <cite>(Mu and Viswanath, 2018)</cite> , which achieves high scores on Word and Semantic textual similarity tasks.",
  "y": "uses"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_0",
  "x": "Since its inception, papers have applied different methods such as feature based (Kiritchenko et al., 2014) , Recursive Neural Networks (RecNN) <cite>(Dong et al., 2014)</cite> , Recurrent Neural Networks (RNN) (Tang et al., 2016a) , attention applied to RNN (Wang et al., 2016; Chen et al., 2017; Tay et al., 2017) , Neural Pooling (NP) Wang et al., 2017) , RNN combined with NP (Zhang et al., 2016) , and attention based neural networks (Tang et al., 2016b) .",
  "y": "background"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_1",
  "x": "First, Chen et al. (2017) compared results across SemEval's laptop and restaurant reviews in English (Pontiki et al., 2014) , a Twitter dataset <cite>(Dong et al., 2014)</cite> and their own Chinese news comments dataset.",
  "y": "background"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_2",
  "x": "They did perform a comparison across different languages, domains, corpora types, and different methods; SVM with features (Kiritchenko et al., 2014) , Rec-NN <cite>(Dong et al., 2014)</cite> , TDLSTM (Tang et al., 2016a) , Memory Neural Network (MNet) (Tang et al., 2016b) and their own attention method.",
  "y": "background"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_3",
  "x": "As we can see from table 2, generally the social media datasets (Twitter and YouTube) contain more targets per sentence with the exception of<cite> Dong et al. (2014)</cite> and Mitchell et al. (2013) .",
  "y": "differences"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_4",
  "x": "Vo and Zhang (2015) created the first NP method for TDSA. All of their experiments are performed on<cite> Dong et al. (2014)</cite> Twitter data set.",
  "y": "background"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_5",
  "x": "We test all of the methods on the test data set of<cite> Dong et al. (2014)</cite> and show the difference between the original and reproduced models in figure 2 .",
  "y": "uses similarities"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_6",
  "x": "The experiments are performed on the<cite> Dong et al. (2014)</cite> and Wang et al. (2017) Twitter datasets where we train and test on the previously specified train and test splits.",
  "y": "similarities uses"
 },
 {
  "id": "d0007c7f1f9ecfbdd7b6ad7c59cc92_7",
  "x": "The experiments are performed on the<cite> Dong et al. (2014)</cite> dataset where we train and test on the specified splits.",
  "y": "similarities uses"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_0",
  "x": "Word representations and more recently, word embeddings, learned from large amounts of text have been quite successful as features in various NLP tasks (Koo et al., 2008; Turian et al., 2010; Collobert et al., 2011; Dhillon et al., 2012; Al-Rfou' et al., 2013; <cite>Bansal et al., 2014</cite>; Guo et al., 2014; Pennington et al., 2014; Yu and Dredze, 2014; Faruqui et al., 2014; Wang et al., 2015) .",
  "y": "background"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_1",
  "x": "Word representations and more recently, word embeddings, learned from large amounts of text have been quite successful as features in various NLP tasks (Koo et al., 2008; Turian et al., 2010; Collobert et al., 2011; Dhillon et al., 2012; Al-Rfou' et al., 2013; <cite>Bansal et al., 2014</cite>; Guo et al., 2014; Pennington et al., 2014; Yu and Dredze, 2014; Faruqui et al., 2014; Wang et al., 2015) . While these word representations do capture useful, dense relationships among known and unknown words, one still has to work with sparse conjunctions of features on the multiple words involved in the substructure that a task factors on, e.g., head-argument links in dependency parsing. Therefore, most statistical dependency parsers still suffer from millions of such conjoined, template-based, n-ary features on word clusters or embeddings (Koo et al., 2008; <cite>Bansal et al., 2014</cite>) .",
  "y": "background"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_2",
  "x": "In this work, we propose to address both these issues by learning simple dependency link embeddings on 'head-argument' pairs (as a single concatenated unit), which allows us to work directly with linguistically-intuitive, higher-order substructures, and also fire significantly fewer and simpler features in dependency parsing, as opposed to word cluster and embedding features in previous work (Koo et al., 2008; <cite>Bansal et al., 2014</cite>) , while still maintaining <cite>their</cite> strong accuracies.",
  "y": "motivation differences"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_3",
  "x": "At the same time, these link embedding features maintain dependency parsing improvements similar to the complex, template-based features on word clusters and embeddings by previous work (Koo et al., 2008; <cite>Bansal et al., 2014</cite> ) (up to 9% relative error reduction), and also stack statistically significantly over <cite>them</cite> (up to an additional 5% relative error reduction). Another advantage of this approach (versus <cite>previous work</cite> on feature embeddings or special neural networks for parsing) is that these link embeddings can be imported as off-the-shelf, dense, syntactic features into various other NLP tasks, similar to word embedding features, but now with richer, structured information, and in tasks where plain word embeddings have not proven useful .",
  "y": "differences motivation"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_4",
  "x": "2 We use the original skip-gram model and simply change the context tuple data on which the model is trained, similar to <cite>Bansal et al. (2014)</cite> and Levy and Goldberg (2014) .",
  "y": "similarities"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_5",
  "x": "The BROWN cluster features are based on <cite>Bansal et al. (2014)</cite> , <cite>who</cite> follow Koo et al. (2008) Koo et al. (2008) ).",
  "y": "uses"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_6",
  "x": "Also note the difference of our unary bucket features from the binary bucket features of <cite>Bansal et al. (2014)</cite> , <cite>who</cite> had to work with pairwise, conjoined features of the head and the argument.",
  "y": "differences"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_7",
  "x": "Also note the difference of our unary bucket features from the binary bucket features of <cite>Bansal et al. (2014)</cite> , <cite>who</cite> had to work with pairwise, conjoined features of the head and the argument. Hence, <cite>they</cite> used features on conjunctions of the two bucket values from the head and argument word vectors, firing one pairwise feature per dimension, because firing features on all dimension pairs (corresponding to an outer product) led to an infeasible number of features. The result discussion of these feature differences in presented in \u00a73.2.",
  "y": "differences"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_8",
  "x": "For all experiments (unless otherwise noted), we follow the 2nd-order MSTParser setup of <cite>Bansal et al. (2014)</cite> , in terms of data splits, parameters, preprocessing, and feature thresholding.",
  "y": "uses"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_9",
  "x": "First, we compare the number of features in Table 2 . Our dense, unary, link-embedding based Bucket and Bit-string features are substantially fewer than the sparse, n-ary, template-based features used in the MSTParser baseline, in BROWN, and in the word embedding SKIP DEP result of B<cite>ansal et al. (2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_10",
  "x": "Moreover, the Bit-string result (92.6) is the same, i.e., has no statistically significant difference from the BROWN result (92.7), and also from the <cite>Bansal et al. (2014</cite>) SKIP DEP result (92.7). Therefore, the main contribution of these link embeddings is that their significantly simpler, smaller, and faster set of unary features can match the performance of complex, template-based BROWN features (and of the dependency-based word embedding features of <cite>Bansal et al. (2014)</cite> ), and also stack over them.",
  "y": "similarities"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_11",
  "x": "8 Moreover, unlike <cite>Bansal et al. (2014)</cite> , our Bucket features achieve statistically significant improvements, most likely because <cite>they</cite> fired D pairwise, conjoined features, one per dimension d, consisting of the two bucket values from the head and argument word vectors.",
  "y": "differences"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_12",
  "x": "As mentioned earlier, there has been a lot of useful, previous work on using word embeddings for NLP tasks such as similarity, tagging, NER, sentiment analysis, and parsing (Turian et al., 2010; Collobert et al., 2011; Dhillon et al., 2012; Huang et al., 2012; Al-Rfou' et al., 2013; Hisamoto et al., 2013; Andreas and Klein, 2014; <cite>Bansal et al., 2014;</cite> Guo et al., 2014; Pennington et al., 2014; Wang et al., 2015) , inter alia.",
  "y": "background"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_13",
  "x": "As mentioned earlier, there has been a lot of useful, previous work on using word embeddings for NLP tasks such as similarity, tagging, NER, sentiment analysis, and parsing (Turian et al., 2010; Collobert et al., 2011; Dhillon et al., 2012; Huang et al., 2012; Al-Rfou' et al., 2013; Hisamoto et al., 2013; Andreas and Klein, 2014; <cite>Bansal et al., 2014;</cite> Guo et al., 2014; Pennington et al., 2014; Wang et al., 2015) , inter alia. In related work, <cite>Bansal et al. (2014)</cite> also use dependency context to tailor word embeddings to dependency parsing.",
  "y": "background"
 },
 {
  "id": "d0b4d9566f16915cb5a5244f351e61_14",
  "x": "In related work, <cite>Bansal et al. (2014)</cite> also use dependency context to tailor word embeddings to dependency parsing. However, <cite>their</cite> embedding features are still based on the sparse set of n-ary, word-based templates from previous work (McDonald et al., 2005a; Koo et al., 2008) . Our structured link embeddings achieve similar improvements <cite>as theirs</cite> (and better in the case of direct, per-dimension bucket features) with a substantially smaller and simpler (unary) set of features that are aimed to directly capture hidden relationships between the substructures that dependency parsing factors on.",
  "y": "differences motivation"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_0",
  "x": "By using a larger value of k, the number of nearest neighbors to use for determining the class of a test example, and through 10-fold cross validation to automatically determine the best k, we have obtained improved disambiguation accuracy on a large sense-tagged corpus first used in <cite>(Ng and Lee, 1996)</cite> .",
  "y": "differences"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_1",
  "x": "Many different learning approaches have been used, including neural networks (Leacock et al., 1993) , probabilistic algorithms (Bruce and Wiebe, 1994; Gale et al., 1992a; Gale et al., 1995; Leacock et al., 1993; Yarowsky, 1992) , decision lists (Yarowsky, 1994) , exemplar-based learning algorithms (Cardie, 1993; <cite>Ng and Lee, 1996)</cite> , etc.",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_2",
  "x": "On the other hand, <cite>our past work</cite> on WSD <cite>(Ng and Lee, 1996)</cite> used an exemplar-based (or nearest neighbor) learning approach.",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_3",
  "x": "By using 10-fold cross validation (Kohavi and John, 1995) on the training set to automatically determine the best k to use, we have obtained improved disambiguation accuracy on a large sensetagged corpus first used in <cite>(Ng and Lee, 1996)</cite> .",
  "y": "differences"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_4",
  "x": "Section 4 presents the disambiguation accuracy of PEBLS and Naive-Bayes on the large corpus of <cite>(Ng and Lee, 1996)</cite> .",
  "y": "uses"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_5",
  "x": "<cite>We</cite> have used the default values for all parameter settings in <cite>our previous work</cite> on exemplar-based WSD reported in <cite>(Ng and Lee, 1996)</cite> .",
  "y": "uses"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_6",
  "x": "This corpus was first reported in <cite>(Ng and Lee, 1996)</cite> , and it contains about 192,800 sense-tagged word occurrences of 191 most frequently occurring and ambiguous words of English.",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_7",
  "x": "In our present study, we evaluated PEBLS and Naive-Bayes on a much larger corpus containing sense-tagged occurrences of 121 nouns and 70 verbs. This corpus was first reported in <cite>(Ng and Lee, 1996)</cite> , and it contains about 192,800 sense-tagged word occurrences of 191 most frequently occurring and ambiguous words of English.",
  "y": "uses"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_8",
  "x": "Both test sets are identical to the ones reported in <cite>(Ng and Lee, 1996)</cite> .",
  "y": "similarities"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_9",
  "x": "Local collocations have been found to be the single most informative set of features for WSD <cite>(Ng and Lee, 1996)</cite> .",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_10",
  "x": "2The first five of these seven features were also used in <cite>(Ng and Lee, 1996)</cite> . , 1996) .",
  "y": "similarities"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_11",
  "x": "The accuracy figures of LEXAS as reported in <cite>(Ng and Lee, 1996)</cite> are reproduced in the third row of Table 1 .",
  "y": "uses"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_12",
  "x": "However, the feature value pruning method of <cite>(Ng and Lee, 1996)</cite> only selects surrounding words and local collocations as feature values if they are indicative of some sense class as measured by conditional probability (See <cite>(Ng and Lee, 1996)</cite> for details).",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_13",
  "x": "However, all possible feature values (collocated words) are used, without employing the feature value pruning method used in <cite>(Ng and Lee, 1996)</cite> .",
  "y": "differences"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_14",
  "x": "Note that the accuracy figures of PEBLS with k = 1 are 1.0% and 1.6% higher than the accuracy figures of <cite>(Ng and Lee, 1996)</cite> in the third row, also with k = 1.",
  "y": "differences"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_15",
  "x": "The feature value pruning method of <cite>(Ng and Lee, 1996)</cite> is intended to keep only feature values deemed important for classification.",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_16",
  "x": "<cite>Our past work</cite> <cite>(Ng and Lee, 1996)</cite> suggests that multiple sources of knowledge are indeed useful for WSD.",
  "y": "background"
 },
 {
  "id": "d160d5a44f795f2b694d5ee538d713_17",
  "x": "Also, given the relative importance of the various knowledge sources as reported in <cite>(Ng and Lee, 1996)</cite> , it may be possible to improve disambignation performance by introducing feature weighting.",
  "y": "future_work"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_0",
  "x": "Therefore, this task has attracted more attention in recent years (Serban et al., 2016;<cite> Elsahar et al., 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_1",
  "x": "In comparison, <cite>Elsahar et al. (2018)</cite> obtain obvious degradation on all metrics while there is only a slight decline in our model.",
  "y": "differences"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_2",
  "x": "In order to improve the generalization for KBQG, <cite>Elsahar et al. (2018)</cite> utilized extra contexts as input via distant supervisions (Mintz et al., 2009) , then a decoder is equipped with attention and part-ofspeech (POS) copy mechanism to generate questions.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_3",
  "x": "In order to improve the generalization for KBQG, <cite>Elsahar et al. (2018)</cite> utilized extra contexts as input via distant supervisions (Mintz et al., 2009) , then a decoder is equipped with attention and part-ofspeech (POS) copy mechanism to generate questions. Nevertheless, we observe that there are still two important research issues (RIs) which are not processed well or even neglected.",
  "y": "background motivation"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_4",
  "x": "Previous work<cite> (Elsahar et al., 2018)</cite> usually obtained predicate textual contexts through distant supervision.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_5",
  "x": "We make statistic in the resources released by <cite>Elsahar et al. (2018)</cite> , and find that only 44% predicates have predicate textual context 2 .",
  "y": "motivation uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_6",
  "x": "In previous work, <cite>Elsahar et al. (2018)</cite> only regarded a most frequently mentioned entity type as the textual context for the subject or object in the triplet.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_7",
  "x": "Therefore, generated questions from <cite>Elsahar et al. (2018)</cite> may be difficult to contain definitive answers.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_8",
  "x": "Specifically, besides using predicate contexts from the distant supervision utilized by <cite>Elsahar et al. (2018)</cite> , we further leverage the domain, range and even topic for the given predicate as contexts, which are off-the-shelf in KBs (e.g. the range and the topic for the predicate fb:location/containedby are \"location\" and \"containedby\", respectively 1 ).",
  "y": "extends"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_9",
  "x": "Furthermore, in addition to the most frequently mentioned entity type as contexts used by <cite>Elsahar et al. (2018)</cite> , we leverage the type that best describes the entity as contexts (e.g. a refined entity type 3 \"US state\" combines a broad type \"administrative region\" for the entity \"New York\"), which is helpful to refine the entity information.",
  "y": "extends"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_10",
  "x": "Similarly, the predicate embedding e p and the object embedding e o are mapped from the KB embedding matrix E f , where E f is pre-trained using TransE (Bordes et al., 2013) to capture much more fact information in previous work<cite> (Elsahar et al., 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_11",
  "x": "<cite>Elsahar et al. (2018)</cite> demonstrated the effectiveness of POS copy for the context.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_12",
  "x": "For the subject and object context, we combine the most frequently mentioned entity type<cite> (Elsahar et al., 2018)</cite> with the type that best describe the entity 3 .",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_13",
  "x": "Following (Serban et al., 2016;<cite> Elsahar et al., 2018)</cite> , we adopt some word-overlap based metrics (WBMs) for natural language generation including BLEU-4 (Papineni et al., 2002) , ROUGE L (Lin, 2004) and METEOR (Denkowski and Lavie, 2014) .",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_14",
  "x": "Following (Serban et al., 2016;<cite> Elsahar et al., 2018)</cite> , we adopt some word-overlap based metrics (WBMs) for natural language generation including BLEU-4 (Papineni et al., 2002) , ROUGE L (Lin, 2004) and METEOR (Denkowski and Lavie, 2014) . To better evaluate generated questions, we run two further evaluations as follows.",
  "y": "extends"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_15",
  "x": "(3) <cite>Elsahar et al. (2018)</cite> : We compare our methods with the model utilizing copy actions, the best performing model in <cite>Elsahar et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_16",
  "x": "To make our model comparable to the comparison methods, we keep most parameter values the same as <cite>Elsahar et al. (2018)</cite> .",
  "y": "similarities"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_17",
  "x": "It is evident that our model is remarkably better than baselines on all metrics, where the BLEU4 score increases 4.53 compared with the strongest baseline<cite> (Elsahar et al., 2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_18",
  "x": "Identification Serban et al. (2016) 53.5 <cite>Elsahar et al. (2018)</cite> 71.5 Our Model ans loss 75.5 from each model, and then two annotators are employed to judge whether the generated question expresses the given predicate.",
  "y": "differences"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_19",
  "x": "Table 4 : Ablation study by removing the main components, where \"w/o\" means without, and \"w/o diversified contexts\" represents that diversified contexts are replaced by contexts used in <cite>Elsahar et al. (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_20",
  "x": "Specifically, the last line in Table 4 , replacing diversified contexts with contexts used in <cite>Elsahar et al. (2018)</cite> , has more obvious performance degradation.",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_21",
  "x": "Naturalness Serban et al. (2016) 2.96 <cite>Elsahar et al. (2018)</cite> 2.23 Our Model ans loss 3.56 Human evaluation is important for generated questions.",
  "y": "differences"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_22",
  "x": "Following <cite>Elsahar et al. (2018)</cite> , we sample 100 questions from each system, and then two annotators measure the naturalness by a score of 0-5.",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_23",
  "x": "As shown in Table 5 , <cite>Elsahar et al. (2018)</cite> Pre-trained KB embeddings may provide rich structured relational information among entities.",
  "y": "uses"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_24",
  "x": "Data Type Accuracy human-labeled data 68.97 + gen data (Serban et al., 2016) 68.53 + gen data<cite> (Elsahar et al., 2018)</cite> 69.13 + gen data (Our Model ans loss ) 69.57 Previous experiments demonstrate that our model can deliver more precise questions.",
  "y": "differences"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_25",
  "x": "To improve the generalization, <cite>Elsahar et al. (2018)</cite> introduced extra contexts for the input fact, which achieved significant performances.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_26",
  "x": "To improve the generalization, <cite>Elsahar et al. (2018)</cite> introduced extra contexts for the input fact, which achieved significant performances. However, these contexts may make it difficult to generate questions that express the given predicate and associate with a definitive answer. Therefore, we focus on the two research issues: expressing the given predicate and referring to a definitive answer for generated questions.",
  "y": "motivation background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_27",
  "x": "<cite>Elsahar et al. (2018)</cite> exploited POS copy action to better capture textual contexts.",
  "y": "background"
 },
 {
  "id": "d2028986dc30ccc0ca840ca3b2f454_28",
  "x": "<cite>Elsahar et al. (2018)</cite> exploited POS copy action to better capture textual contexts. To incorporate advantages from above copy mechanisms, we introduce KB copy and context copy which can copy KB element and textual context, and they do not rely on POS tagging.",
  "y": "background differences"
 },
 {
  "id": "d2c95c3198f21e793549d7b16bdaf8_0",
  "x": "The goal of an EL approach is as follows: Given a piece of text, a reference knowledge base K and a set of entity mentions in that text, map each entity mention to the corresponding resource in K <cite>[4]</cite> .",
  "y": "background"
 },
 {
  "id": "d2c95c3198f21e793549d7b16bdaf8_1",
  "x": "However, MAG (Multilingual AGDISTIS) <cite>[4]</cite> showed that the underlying models being trained on English corpora make them prone to failure when migrated to a different language.",
  "y": "motivation"
 },
 {
  "id": "d2c95c3198f21e793549d7b16bdaf8_2",
  "x": "Independently of the chosen graph algorithm, the highest candidate score among the set of candidates is chosen as correct disambiguation for a given mention <cite>[4]</cite> .",
  "y": "background"
 },
 {
  "id": "d2c95c3198f21e793549d7b16bdaf8_3",
  "x": "-Search by Context -This boolean parameter provides a search of candidates using a context index <cite>[4]</cite> .",
  "y": "uses background"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_0",
  "x": "Our design most closely resembles the pipeline proposed by the top system last year<cite> (Wang and Lan, 2015)</cite> , in that argument extraction for explicit relations is performed separately for Arg1 and Arg2, the non-explicit sense classifier is run twice.",
  "y": "similarities"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_1",
  "x": "The features are based on previous work (Pitler et al., 2009; Lin et al., 2014;<cite> Wang and Lan, 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_2",
  "x": "We employ the features proposed in Lin et al. (2014) and additional features described in last year's top system<cite> (Wang and Lan, 2015)</cite> . The position classifier is trained using the Maximum Entropy algorithm and achieves an F1 score of 99.186% on the development data. In line with prior work<cite> (Wang and Lan, 2015)</cite> , we consider PS to be the sentence that immediately precedes the connective.",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_3",
  "x": "We follow the constituent-based approach proposed in Kong et al. (2014) , without the joint inference and enhance it using features in<cite> Wang and Lan (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_4",
  "x": "PS Arg1 Extractor: We implement features described in<cite> Wang and Lan (2015)</cite> and add novel features.",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_5",
  "x": "We used the constituent split implemented in<cite> Wang and Lan (2015)</cite> . Based on earlier work <cite>(Wang and Lan, 2015</cite>; Lin et al., 2014) , we implement the following features: surface form of the verbs in the sentence (three features), last word of the current constituent (curr), last word of the previous constituent (prev), the first word of curr, and the lowercased form of the connective.",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_6",
  "x": "PS Arg2 Extractor: Similar to PS Arg1 extractor, for this component we implement features described in<cite> Wang and Lan (2015)</cite> and add novel features.",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_7",
  "x": "\u2022 C parent-category linked context, previous connective and its POS of \"as\"(the connective and its POS of previous relation, if the connective of current relation is \"as\"), previous connective and its POS of \"when\", adopted from<cite> Wang and Lan (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_8",
  "x": "Following<cite> Wang and Lan (2015)</cite>, we extract sentence pairs that satisfy the following three criteria:",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_9",
  "x": "We use features in Lin et al. (2009) and<cite> Wang and Lan (2015)</cite> and augment these with novel features.",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_10",
  "x": "Implicit Arg2 Extractor: We use most of the features in Lin et al. (2014) and<cite> Wang and Lan (2015)</cite> to train the Arg2 extractor (for more details and explanation about the features, we refer the reader to the respective papers):",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_12",
  "x": "Base features refer to features used in<cite> Wang and Lan (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_13",
  "x": "We compare our baseline model that implements the features proposed in<cite> Wang and Lan (2015)</cite> with the model that employs additional features introduced in 4.4.",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_14",
  "x": "Our baseline model performs slightly better than the one reported in<cite> Wang and Lan (2015)</cite> : we obtain 90.55 vs. 90.14, as reported in<cite> Wang and Lan (2015)</cite> .",
  "y": "differences"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_15",
  "x": "We implement the features in<cite> Wang and Lan (2015)</cite> and add our novel features shown in Table 1 .",
  "y": "uses"
 },
 {
  "id": "d2ce392240108203377d8e51e89d09_16",
  "x": "We note that in<cite> Wang and Lan (2015)</cite> the numbers that correspond to the entire sentence baselines are not the same as those that we obtain, so we do not report a direct comparison with their models.",
  "y": "differences"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_0",
  "x": "Text segmentation deals with automatically breaking down the structure of text into such topically contiguous segments, i.e., it aims to identify the points of topic shift (Hearst 1994; Choi 2000; Brants, Chen, and Tsochantaridis 2002; Riedl and Biemann 2012; Du, Buntine, and Johnson 2013; Glava\u0161, Nanni, and Ponzetto 2016; <cite>Koshorek et al. 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_1",
  "x": "Similarly, a recently proposed state-of-the-art supervised neural segmentation model<cite> (Koshorek et al. 2018</cite> ) directly learns to predict binary sentence-level segmentation decisions and has no explicit mechanism for modeling coherence. In this work, in contrast, we propose a supervised neural model for text segmentation that explicitly takes coherence into account: we augment the segmentation prediction objective with an auxiliary coherence modeling objective. Our proposed model, dubbed Coherence-Aware Text Segmentation (CATS), encodes a sentence sequence using two hierarchically connected Transformer networks (Vaswani et al. 2017; Devlin et al. 2018 ).",
  "y": "differences background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_2",
  "x": "Similar to<cite> (Koshorek et al. 2018)</cite> , CATS' main learning objective is a binary sentence-level segmentation prediction. However, CATS augments the segmentation objective with an auxiliary coherence-based objec-tive which pushes the model to predict higher coherence for original text snippets than for corrupt (i.e., fake) sentence sequences. We empirically show (1) that even without the auxiliary coherence objective, the Two-Level Transformer model for Text Segmentation (TLT-TS) yields state-of-the-art performance across multiple benchmarks, (2) that the full CATS model, with the auxiliary coherence modeling, further significantly improves the segmentation, and (3) that both TLT-TS and CATS are robust in domain transfer.",
  "y": "similarities differences"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_3",
  "x": [
   "Koshorek et al. (2018) leveraged the manual structuring of Wikipedia pages into sections to automatically create a large segmentation-annotated corpus. WIKI-727K consists of 727,746 documents created from English (EN) Wikipedia pages, divided into training (80%), development (10%), and test portions (10%). We train, optimize, and evaluate our models on respective portions of the WIKI-727K dataset."
  ],
  "y": "uses background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_4",
  "x": [
   "Koshorek et al. (2018) additionally created a small evaluation set WIKI-50 to allow for comparative evaluation against unsupervised segmentation models, e.g., the GRAPHSEG model of Glava\u0161, Nanni, and Ponzetto (2016) , for which evaluation on large datasets is prohibitively slow."
  ],
  "y": "background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_5",
  "x": "Analogous to the WIKI-50 dataset created by<cite> Koshorek et al. (2018)</cite> from English (EN) Wikipedia, we created WIKI-50-CS, WIKI-50-FI, and WIKI-50-TR datasets consisting of 50 randomly selected pages from Czech (CS), Finnish (FI), and Turkish (TR) Wikipedia, respectively.",
  "y": "extends similarities"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_6",
  "x": "Following (Glava\u0161, Nanni, and Ponzetto 2016; <cite>Koshorek et al. 2018)</cite> , we set k to the half of the average ground truth segment size of the dataset.",
  "y": "uses"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_7",
  "x": "Following previous work (Riedl and Biemann 2012; Glava\u0161, Nanni, and Ponzetto 2016; <cite>Koshorek et al. 2018)</cite> , we also adopt the standard text segmentation measure P k (Beeferman, Berger, and Lafferty 1999) as our evaluation metric. P k score is the probability that a model makes a wrong prediction as to whether the first and last sentence of a randomly sampled snippet of k sentences belong to the same segment (i.e., the probability of the model predicting the same segment for the sentences from different segment or different segments for the sentences from the same segment).",
  "y": "uses"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_8",
  "x": "We compare CATS against the state-ofthe-art neural segmentation model of<cite> Koshorek et al. (2018)</cite> and against GRAPHSEG (Glava\u0161, Nanni, and Ponzetto 2016) , the state-of-the-art unsupervised text segmentation model.",
  "y": "background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_10",
  "x": "The improved performance that TLT-TS has with respect to the model of<cite> Koshorek et al. (2018)</cite> is consistent with improvements that Transformer-based architectures yield in comparison with models based on recurrent components in other NLP tasks (Vaswani et al. 2017; Devlin et al. 2018) .",
  "y": "background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_12",
  "x": "Moreover,<cite> Koshorek et al. (2018)</cite> report human performance on the WIKI-50 dataset of 14.97, which is a mere one P k point better than the performance of our coherence-aware CATS model.",
  "y": "background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_13",
  "x": [
   "While the hierarchical segmentation received a non-negligible research attention (Yaari 1997; Eisenstein 2009; Du, Buntine, and John-son 2013) , the vast majority of the proposed models (including this work) focus on linear segmentation (Hearst 1994; Beeferman, Berger, and Lafferty 1999; Choi 2000; Brants, Chen, and Tsochantaridis 2002; Misra et al. 2009; Riedl and Biemann 2012; Glava\u0161, Nanni, and Ponzetto 2016; Koshorek et al. 2018, inter alia) ."
  ],
  "y": "background"
 },
 {
  "id": "d3672a2d7129beef6703598f1558c4_14",
  "x": "Finally,<cite> Koshorek et al. (2018)</cite> identify Wikipedia as a free large-scale source of manually segmented texts that can be used to train a supervised segmentation model. They train a neural model that hierarchically combines two bidirectional LSTM networks and report massive improvements over unsupervised segmentation on a range of evaluation datasets. The model we presented in this work has a similar hierarchical architecture, but uses Transfomer networks instead of recurrent encoders. Crucially, CATS additionally defines an auxiliary coherence objective, which is coupled with the (primary) segmentation objective in a multi-task learning model.",
  "y": "motivation differences background"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_0",
  "x": "In<cite> (Mikolov et al., 2013b)</cite> , the linear relation is extended to the bilingual scenario, where a linear transform is learned to project semantically identical words from one language to another.",
  "y": "background"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_1",
  "x": "This work largely follows the methodology and experimental settings of<cite> (Mikolov et al., 2013b)</cite> , while we normalize the embedding and use an orthogonal transform to conduct bilingual translation.",
  "y": "uses similarities"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_2",
  "x": "Our method in this paper and the linear projection method in <cite>(Mikolov et al., 2013b</cite> ) both belong to this category.",
  "y": "similarities"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_3",
  "x": "The bilingual word translation provided by <cite>(Mikolov et al., 2013b</cite> ) learns a linear transform from the source language to the target language by the linear regression.",
  "y": "background"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_4",
  "x": "A high accuracy was reported on a word translation task, where a word projected to the vector space of the target language is expected to be as close as possible to its translation<cite> (Mikolov et al., 2013b)</cite> .",
  "y": "background"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_5",
  "x": "For an easy comparison, we largely follow Mikolov's settings in<cite> (Mikolov et al., 2013b)</cite> and set English and Spanish as the source and target language, respectively.",
  "y": "uses similarities"
 },
 {
  "id": "d3f5f9b1ef8bda3d33c563d252d58a_6",
  "x": "These results are comparable with the results reported in <cite>(Mikolov et al., 2013b</cite>",
  "y": "similarities"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_0",
  "x": "We use a window size of 4 words based on the experiments in<cite> (Razmara et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_1",
  "x": "A comparison of different association measures appears in (Marton et al., 2009; <cite>Razmara et al., 2013</cite>; Saluja et al., 2014) and our preliminary experiments validated the choice of the same association measure as in these papers, namely Pointwise Mutual Information (Lin, 1998) (PMI) .",
  "y": "similarities"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_2",
  "x": "Thus, we use the heuristic applied in previous works (Marton et al., 2009; <cite>Razmara et al., 2013</cite>; Saluja et al., 2014) to reduce the search space.",
  "y": "uses"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_3",
  "x": "(1): 1) A graph of source phrases is constructed as in<cite> (Razmara et al., 2013)</cite> ; 2) translations are propagated as labels through the graph as explained in Fig. 2 ; and 3) new translation rules obtained from graph-propagation are integrated with the original phrase table.",
  "y": "uses"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_4",
  "x": "The MAD graph propagation generalizes the approach used in<cite> (Razmara et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_5",
  "x": "We apply this method in our low resource setting experiments (Sec. 5.3) to compare our bipartite and tripartite results to<cite> Razmara et al. (2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_6",
  "x": "But as we wish to fairly compare our approach with<cite> Razmara et al. (2013)</cite> on low resource setting, we follow their setup in Sec. 5.3: Moses (Koehn et al., 2007) as SMT pipeline, GIZA++ (Och and Ney, 2003) for word alignment and MERT (Och, 2003) for tuning.",
  "y": "uses"
 },
 {
  "id": "d51bf6d22d21dcd91e080f6f0b5dcb_7",
  "x": "In this experiment we use a setup similar to (Razmara et al., 2013 we use 10K French-English parallel sentences, randomly chosen from Europarl to train translation system, as reported in<cite> (Razmara et al., 2013)</cite> .",
  "y": "uses"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_0",
  "x": "Defining precise rules for morphologically complex texts, especially for the purpose of infix removal is sometimes impossible<cite> [5]</cite> .",
  "y": "motivation"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_1",
  "x": "We opted the query expansion approach which is a widely used approach to compensate the shortage of inflections [9, 3, <cite>5]</cite> .",
  "y": "uses"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_2",
  "x": "We used the following probabilistic framework to this end<cite> [5]</cite> :",
  "y": "uses"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_3",
  "x": "To avoid adding noisy terms, we only compute the joint probabilities between either a pair of translation candidates from the dictionary (c i,j and c i ,j ) or a pair of a candidate from the dictionary and an inflection from the collection (c i,j and c i ,j )<cite> [5]</cite> .",
  "y": "uses"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_4",
  "x": "We removed Persian stop words from the queries and documents [4, <cite>5]</cite> .",
  "y": "uses"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_5",
  "x": "Dadashkarimi et al., demonstrated that Google has better coverage compared to other English-Persian dictionaries<cite> [5]</cite> .",
  "y": "background"
 },
 {
  "id": "d52dfb30158deae64a1c3d787d9b95_6",
  "x": "Iterative translation disambiguation (ITD) [11] , joint cross-lingual topical relevance model (JCLTRLM) [7] , top-ranked translation (TOP-1), and the bi-gram coherence translation method (BiCTM), introduced in<cite> [5]</cite> (assume |c i | = 0), are the baselines without any morphological processing units.",
  "y": "uses"
 },
 {
  "id": "d5a71358168d262dd1e9734c80234b_0",
  "x": "For example, if one accepts the framework of the Penn Treebank, it is easy to move on to representations of \"deeper\" structure as suggested in three papers in this volume <cite>(Miltsakaki et al., 2004</cite>; Babko-Malaya et al., 2004; Meyers et al., 2004) .",
  "y": "background"
 },
 {
  "id": "d5a71358168d262dd1e9734c80234b_1",
  "x": "The first six papers describe linguistic annotation in four languages: Spanish (Alc\u00e1ntara and Moreno, 2004), English <cite>(Miltsakaki et al., 2004</cite>; Babko-Malaya et al., 2004; Meyers et al., 2004) , Czech (Sgall et al., 2004) and German (Baumann et al., 2004).",
  "y": "background"
 },
 {
  "id": "d5a71358168d262dd1e9734c80234b_2",
  "x": "For example, if one accepts the framework of the Penn Treebank, it is easy to move on to representations of \"deeper\" structure as suggested in three papers in this volume <cite>(Miltsakaki et al., 2004</cite>; Babko-Malaya et al., 2004; Meyers et al., 2004) .",
  "y": "background"
 },
 {
  "id": "d5a71358168d262dd1e9734c80234b_3",
  "x": "The first six papers describe linguistic annotation in four languages: Spanish (Alc\u00e1ntara and Moreno, 2004) , English <cite>(Miltsakaki et al., 2004</cite>; Babko-Malaya et al., 2004; Meyers et al., 2004) , Czech (Sgall et al., 2004) and German (Baumann et al., 2004) .",
  "y": "background"
 },
 {
  "id": "d61f75366022f043d4c3a005b5a73d_0",
  "x": "The works differ in the way they acquire morphological knowledge (from using linguistically derived morphological analyzers on one end, to approximating morphology using substrings while relying on the concatenative nature of morphology, on the other) and in the model form (cDSMs (Lazaridou et al., 2013) , RNN (Luong et al., 2013) , LBL (Botha and Blunsom, 2014) , CBOW (Qiu et al., 2014) , SkipGram (Soricut and Och, 2015; <cite>Bojanowski et al., 2016)</cite> , GGM (Cotterell et al., 2016) ).",
  "y": "background"
 },
 {
  "id": "d61f75366022f043d4c3a005b5a73d_1",
  "x": "We generalize<cite> Bojanowski et al (2016)</cite> by replacing the set of ngrams G(w) with a set P(w) of explicit linguistic properties.",
  "y": "extends"
 },
 {
  "id": "d61f75366022f043d4c3a005b5a73d_2",
  "x": "Our model form is a generalization of the fastText model<cite> (Bojanowski et al., 2016)</cite> , which in turn extends the skip-gram model of Mikolov et al (2013) .",
  "y": "extends similarities"
 },
 {
  "id": "d61f75366022f043d4c3a005b5a73d_3",
  "x": "Our implementation is based on the fastText 2 library<cite> (Bojanowski et al., 2016)</cite> , which we modify as described above.",
  "y": "extends"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_0",
  "x": "Recent trends in speech recognition [7, <cite>8,</cite> 9] have demonstrated impressive performance on Switchboard and Fisher data.",
  "y": "background"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_1",
  "x": "Advanced variants of DNNs, such as convolutional neural nets (CNNs) [12] , recurrent neural nets (RNNs) [13] , long short-term memory nets (LSTMs) [14] , time-delay neural nets (TDNNs) [15, 29] , <cite>VGG-nets</cite> <cite>[8]</cite> , have significantly improved recognition performance, bringing them closer to human performance [9] .",
  "y": "background"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_2",
  "x": "For the sake of simplicity, we used a CNN acoustic model in our experiment, where the baseline system's performance is directly comparable to the state-of-the-art CNN performance reported in <cite>[8]</cite> .",
  "y": "uses"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_3",
  "x": "Also, the CNN models always gave better results, confirming similar observations from studies reported earlier <cite>[8]</cite> .",
  "y": "background"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_4",
  "x": "The FSH corpus contains speech from quite a diverse set of speakers, helping to reduce the WER of the CH subset more significantly than the SWB subset, a trend reflected in results reported in the literature <cite>[8]</cite> .",
  "y": "similarities"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_5",
  "x": "Table 1 and 2 also demonstrates that sequence training always gave additive performance gain over crossentropy training, supporting the in <cite>[8,</cite> 21] .",
  "y": "uses similarities"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_6",
  "x": "Future studies should investigate RNN or other neural network-based language modeling techniques that are known to perform better than word n-gram LMs. Also, advanced acoustic modeling, through the use of timedelayed neural nets (TDNNs), long short-term memory neural nets (LSTMs), and the <cite>VGG nets</cite>, should also be explored as their performance has been mostly reported using MFB features, and the use of multi-view features can help further improve their performance.",
  "y": "future_work"
 },
 {
  "id": "d72f0608fddd1bf1cdef7ca6a20bdf_7",
  "x": "Table 1 presents the word error rates (WER) from the baseline CNN model trained with the SWB data when evaluated on the NIST 2000 CTS test set, for both cross-entropy (CE) training and sequence training (ST) using MMI. Also, the CNN models always gave better results, confirming similar observations from studies reported earlier <cite>[8]</cite> .",
  "y": "uses similarities"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_0",
  "x": "This paper presents a novel approach to improve reordering in phrase-based machine translation by using richer, syntactic representations of units of bilingual language models (BiLMs). The best models demonstrate significant improvements in BLEU and TER over the phrase-based baseline, as well as over the lexicalized BiLM by <cite>Niehues et al. (2011)</cite> .",
  "y": "background"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_1",
  "x": "In this paper, we base our approach to reordering on bilingual language models (Marino et al., 2006;<cite> Niehues et al., 2011)</cite> . Instead of directly characterizing reordering, they model sequences of elementary translation events as a Markov process.",
  "y": "background similarities"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_2",
  "x": "1 Originally, Marino et al. (2006) used this kind of model as the translation model, while more recently it has been used as an additional model in PBSMT systems<cite> (Niehues et al., 2011)</cite> .",
  "y": "background"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_3",
  "x": "We adopt and generalize the approach of <cite>Niehues et al. (2011)</cite> to investigate several variations of bilingual language models. Our method consists of labeling elementary translation events (tokens of bilingual LMs) with their different contextual properties.",
  "y": "extends uses"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_4",
  "x": "Also previous contributions to bilingual language modeling (Marino et al., 2006;<cite> Niehues et al., 2011)</cite> have mostly used lexical information, although Crego and Yvon (2010a) and Crego and Yvon (2010b) label bilingual to-kens with a rich set of POS tags. But in general, reordering is considered to be a syntactic phenomenon and thus the relevant features are syntactic (Fox, 2002; Cherry, 2008) .",
  "y": "motivation background"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_5",
  "x": "Our contributions can be summarized as follows: We argue that the contextual information used in the original bilingual models<cite> (Niehues et al., 2011)</cite> is insufficient and introduce a simple model that exploits source-side syntax to improve reordering (Sections 2 and 3).",
  "y": "background motivation"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_6",
  "x": "The richer representation allows for a finer distinction between reorderings. For example, Arabic has a morphological marker of definiteness on both nouns and adjectives. If we first translate a definite adjective and then an indefinite noun, it will probably not be a likely sequence according to the translation model. This kind of intuition underlies the model of <cite>Niehues et al. (2011)</cite> , a bilingual LM (BiLM), which defines elementary translation events t 1 , ..., t n as follows: where e i is the i-th target word and A : E \u2192 P(F ) is an alignment function, E and F referring to target and source sentences, and P(\u00b7) is the powerset function. In other words, the i-th translation event consists of the i-th target word and all source words aligned to it.",
  "y": "background"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_7",
  "x": "<cite>Niehues et al. (2011)</cite> refer to the defined translation events t i as bilingual tokens and we adopt this terminology. Our choice of the above definition is supported by the fact that it produces an unambiguous segmentation of a parallel sentence into tokens.",
  "y": "background similarities"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_8",
  "x": "Since <cite>Niehues et al. (2011)</cite> have shown their model to work successfully as an additional feature in combination with commonly used standard phrase-based features, we use their approach as the main point of reference and base our approach on their segmentation method.",
  "y": "uses"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_10",
  "x": "<cite>Niehues et al. (2011)</cite> also described an alternative variant of the original BiLM, where words are substituted by their POS tags (Figure 2 .a, shaded part). Also, however, POS information by itself may be insufficiently expressive to separate cor- , it still is a likely sequence. Indeed, the log-probabilities of the two sequences with respect to a 4-gram BiLM model 5 result in a higher probability of \u221210.25 for the incorrect reordering than for the correct one (\u221210.39). Since fully lexicalized bilingual tokens suffer from data sparsity and POS-based bilingual tokens are insufficiently expressive, the question is which level of syntactic information strikes the right balance between expressiveness and generality.",
  "y": "motivation background"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_11",
  "x": "In this section, we introduce our model which combines the BiLM from <cite>Niehues et al. (2011)</cite> with source dependency information. We further give details on how the proposed models are trained and integrated into a phrase-based decoder.",
  "y": "background similarities"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_13",
  "x": "We consider two variants of BiLM discussed by <cite>Niehues et al. (2011)</cite> : the standard one, Lex\u2022Lex, and the simplest syntactic one, Pos\u2022Pos. Results for the experiments can be found in Table 2 .",
  "y": "background"
 },
 {
  "id": "d8e73e9c00acffc34ade1331709d92_14",
  "x": "We argued that the very limited contextual information used in the original bilingual models<cite> (Niehues et al., 2011)</cite> can capture reorderings only to a limited degree and proposed a method to incorporate information from a source dependency tree in bilingual units.",
  "y": "background motivation"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_0",
  "x": "An important feature that enables an immediate use of the MT-based representations in other downstream tasks is the creation of fixed-sized sentence embeddings <cite>(C\u00edfka and Bojar, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_1",
  "x": "An important feature that enables an immediate use of the MT-based representations in other downstream tasks is the creation of fixed-sized sentence embeddings <cite>(C\u00edfka and Bojar, 2018)</cite> . However, the effects of the size of sentence embeddings and the relation between translation performance and meaning representation quality are not entirely clear.",
  "y": "motivation"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_2",
  "x": "Recent studies based on NMT either focus entirely on the use of MT-based sentence embeddings in other tasks (Schwenk, 2018) , on translation quality (Lu et al., 2018) , on speed comparison (Britz et al., 2017) , or only exploring a bilingual scenario <cite>(C\u00edfka and Bojar, 2018)</cite> .",
  "y": "background"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_3",
  "x": "In contrast to previous work <cite>(C\u00edfka and Bojar, 2018)</cite> , we demonstrate that there is a correlation between translation performance and trainable downstream tasks when adjusting the size of the intermediate layer.",
  "y": "differences"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_4",
  "x": "Due to the attentive connection between encoders and decoders we call this layer attention bridge, and its architecture is an adaptation from the model proposed by<cite> C\u00edfka and Bojar (2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_5",
  "x": "4 SentEval: Classification tasks Table 1 shows the performance of our models on two popular tasks (SNLI and SICK-E) as in<cite> C\u00edfka and Bojar (2018)</cite> as well as the average of all 10 SentEval downstream tasks.",
  "y": "similarities"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_6",
  "x": "4 SentEval: Classification tasks Table 1 shows the performance of our models on two popular tasks (SNLI and SICK-E) as in<cite> C\u00edfka and Bojar (2018)</cite> as well as the average of all 10 SentEval downstream tasks. The experiments reveal two important findings: (1) In contrast with the results from<cite> C\u00edfka and Bojar (2018)</cite>, our scores demonstrate that an increasing number of attention heads is beneficial for classification-based downstream tasks.",
  "y": "differences"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_7",
  "x": "Results with \u2020 taken from<cite> C\u00edfka and Bojar (2018).</cite> of multilingual training.",
  "y": "uses"
 },
 {
  "id": "d92e92b9a375914f3dd74868f463fc_8",
  "x": "This is in line with the findings of<cite> C\u00edfka and Bojar (2018)</cite> and could also be expected as the model is more strongly pushed into a dense semantic abstraction that is beneficial for measuring similarities without further training.",
  "y": "similarities"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_0",
  "x": "A number of approaches for question answering have been proposed recently that use reinforcement learning to reason over a knowledge graph<cite> (Das et al., 2018</cite>; Lin et al., 2018; Chen et al., 2018; Zhang et al., 2018) .",
  "y": "background"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_1",
  "x": "The closest works to ours are the works by Lin et al. (2018) , Zhang et al. (2018) and <cite>Das et al. (2018)</cite> , which consider the question answering task in a reinforcement learning setting in which the agent always chooses to answer.",
  "y": "similarities"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_2",
  "x": "We base our work on the recent reinforcement learning approaches introduced in <cite>Das et al. (2018)</cite> and Lin et al. (2018) .",
  "y": "uses"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_3",
  "x": "The agent is rewarded based on the final state. For example, in <cite>Das et al. (2018)</cite> and Lin et al. (2018) the agent obtains a reward of 1 if the correct answer entity is reached as the final state and 0 otherwise (i.e., R(s T ) = I{e T = e a }).",
  "y": "background"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_4",
  "x": "In the framework of <cite>Das et al. (2018)</cite> a binary reward is used which rewards the learner for the answer being wrong or correct.",
  "y": "background"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_5",
  "x": "Both the public dataset and the proprietary dataset are <cite>Das et al. (2018)</cite> , using the same train/val/test splits for FB15k-237. We extend the publicly available implementation of <cite>Das et al. (2018)</cite> for our experimentation.",
  "y": "similarities uses"
 },
 {
  "id": "da8f30113f1126a78cefed06a15076_6",
  "x": "Unlike <cite>Das et al. (2018)</cite> , we also train entity embeddings after initializing them with random values. This resulted in the final QA Score of 47.58%, around 8% higher than standard RL and 12% higher than <cite>Das et al. (2018)</cite> . The final QA Score also increased from 28.72% to 39.55%, and also significantly improved over <cite>Das et al. (2018)</cite> and Lin et al. (2018) .",
  "y": "extends differences"
 },
 {
  "id": "db6c35071fe4e93c11acca4056e9ac_0",
  "x": "Previously proposed models (summarized in Section 2) exhibit several issues that the neural network-based baseline approach (detailed in Section 3.1) overcomes: (i) our model uses automatically extracted features without the need of external parsers nor manually extracted features (see Gupta et al. (2016) ; Miwa and Bansal (2016) ; Li et al. (2017) ), (ii) all entities and the corresponding relations within the sentence are extracted at once, instead of examining one pair of entities at a time (see Adel and Sch\u00fctze (2017) ), and (iii) we model relation extraction in a multi-label setting, allowing multiple relations per entity (see Katiyar and Cardie (2017) ; <cite>Bekoulis et al. (2018a)</cite> ).",
  "y": "differences"
 },
 {
  "id": "db6c35071fe4e93c11acca4056e9ac_1",
  "x": "Finally, <cite>Bekoulis et al. (2018a)</cite> use LSTMs in a joint model for extracting just one relation at a time, but increase the complexity of the NER part.",
  "y": "background"
 },
 {
  "id": "db6c35071fe4e93c11acca4056e9ac_2",
  "x": "Finally, <cite>Bekoulis et al. (2018a)</cite> use LSTMs in a joint model for extracting just one relation at a time, but increase the complexity of the NER part. Our baseline model enables simultaneous extraction of multiple relations from the same input.",
  "y": "differences"
 },
 {
  "id": "db6c35071fe4e93c11acca4056e9ac_3",
  "x": "Finally, <cite>Bekoulis et al. (2018a)</cite> use LSTMs in a joint model for extracting just one relation at a time, but increase the complexity of the NER part. Our baseline model enables simultaneous extraction of multiple relations from the same input. Then, we further extend this strong baseline using adversarial training.",
  "y": "extends differences"
 },
 {
  "id": "db6c35071fe4e93c11acca4056e9ac_4",
  "x": "For the Dutch Real Estate Classifieds, DREC (Bekoulis et al., 2017) dataset, we use train-test splits as in <cite>Bekoulis et al. (2018a)</cite> .",
  "y": "uses"
 },
 {
  "id": "db6c35071fe4e93c11acca4056e9ac_5",
  "x": "In the boundaries evaluation, the baseline has an improvement of \u223c3% on both tasks compared to <cite>Bekoulis et al. (2018a)</cite> , whose quadratic scoring layer complicates NER.",
  "y": "differences"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_0",
  "x": "One common approach to measuring compositionality is to compare distributional representations of an MWE and its component words (e.g., Schone and Jurafsky, 2001; Baldwin et al., 2003; Katz and Giesbrecht, 2006; Reddy et al., 2011; Schulte im Walde et al., 2013; <cite>Salehi et al., 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_1",
  "x": "One common approach to measuring compositionality is to compare distributional representations of an MWE and its component words (e.g., Schone and Jurafsky, 2001; Baldwin et al., 2003; Katz and Giesbrecht, 2006; Reddy et al., 2011; Schulte im Walde et al., 2013; <cite>Salehi et al., 2015</cite>) . The hypothesis behind <cite>this line of work</cite> is that the representation of a compositional MWE will be more similar to the representations of its component words than the representation of a non-compositional MWE will be to those of its component words.",
  "y": "background"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_2",
  "x": "One common approach to measuring compositionality is to compare distributional representations of an MWE and its component words (e.g., Schone and Jurafsky, 2001; Baldwin et al., 2003; Katz and Giesbrecht, 2006; Reddy et al., 2011; Schulte im Walde et al., 2013; <cite>Salehi et al., 2015</cite>) . One issue faced by <cite>such approaches</cite> is that token-level instances of MWEs must be identified in a corpus in order to form distributional representations of them. Although word-level language models are widely used, and their performance can be higher than character-level language models, character-level models have the advantage that they can model out-of-vocabulary words (Mikolov et al., 2012) .",
  "y": "motivation background"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_3",
  "x": "One common approach to measuring compositionality is to compare distributional representations of an MWE and its component words (e.g., Schone and Jurafsky, 2001; Baldwin et al., 2003; Katz and Giesbrecht, 2006; Reddy et al., 2011; Schulte im Walde et al., 2013; <cite>Salehi et al., 2015</cite>) . One issue faced by <cite>such approaches</cite> is that token-level instances of MWEs must be identified in a corpus in order to form distributional representations of them. Although word-level language models are widely used, and their performance can be higher than character-level language models, character-level models have the advantage that they can model out-of-vocabulary words (Mikolov et al., 2012) . In this paper we consider whether character-level neural network language models capture knowledge of MWE compositionality.",
  "y": "motivation"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_4",
  "x": "2 Once vector representations of an MWE and its component words are obtained, following <cite>Salehi et al. (2015)</cite> , the following equations are then used to compute the compositionality of an MWE: where MWE is the vector representation of the MWE, and C 1 and C 2 are vector representations for the first and second components of the MWE, respectively.",
  "y": "uses"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_5",
  "x": "We train language models over a portion of English and German Wikipedia dumps -following <cite>Salehi et al. (2015)</cite> -from 20 January 2018.",
  "y": "uses"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_6",
  "x": "The proposed model is evaluated over the same three datasets as <cite>Salehi et al. (2015)</cite> , <cite>which</cite> cover two languages (English and German) and two kinds of MWEs (noun compounds and verb-particle constructions).",
  "y": "uses"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_7",
  "x": "The binary compositionality judgements are converted to continuous values as in <cite>Salehi et al. (2015)</cite> by dividing the number of judgements that an expression is compositional by the total number of judgements.",
  "y": "uses"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_8",
  "x": "We evaluate our proposed approach following <cite>Salehi et al. (2015)</cite> by computing Pearson's correlation between the predicted compositionality (i.e., from either comp 1 or comp 2 ) and human ratings for overall compositionality.",
  "y": "uses"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_9",
  "x": "For comp 1 , we set \u03b1 to 0.7 for ENC and GNC following <cite>Salehi et al. (2015)</cite> ; for EVPC we set \u03b1 to 0.5.",
  "y": "uses"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_10",
  "x": "For example, using comp 1 with representations of the MWE and component words obtained from word2vec (Mikolov et al., 2013) , <cite>Salehi et al. (2015)</cite> achieve correlations of 0.717, 0.289, and 0.400 for ENC, the verb component of EVPC, and GNC, respectively.",
  "y": "background"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_11",
  "x": "These correlations are well below those of previous work. For example, using comp 1 with representations of the MWE and component words obtained from word2vec (Mikolov et al., 2013) , <cite>Salehi et al. (2015)</cite> achieve correlations of 0.717, 0.289, and 0.400 for ENC, the verb component of EVPC, and GNC, respectively.",
  "y": "differences"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_12",
  "x": "Word embedding models -such as that used in the approach to predicting compositionality of <cite>Salehi et al. (2015)</cite> -typically do not learn representations for low frequency items.",
  "y": "background"
 },
 {
  "id": "dcf84cf05e3e7950cabbdd8d8f304c_13",
  "x": "These correlations are significant (p < 0.05). Word embedding models -such as that used in the approach to predicting compositionality of <cite>Salehi et al. (2015)</cite> -typically do not learn representations for low frequency items. 9 These results demonstrate that the proposed model is able to predict the compositionality for low frequency items, that would not typically be in-vocabulary for word embedding models, and for which compositionality models based only on word embeddings would not be able to make predictions.",
  "y": "differences"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_0",
  "x": "There have been quite a number of recent papers on parallel text: Brown et al (1990 Brown et al ( , 1991 Brown et al ( , 1993 , Chen (1993) , <cite>Church (1993)</cite> , , Dagan et al (1993) , Church (1991, 1993) , Isabelle (1992) , Kay and Rgsenschein (1993) , Klavans and Tzoukermann (1990) , Kupiec (1993) , Matsumoto (1991) , Ogden and Gonzales (1993) , Shemtov (1993) , Simard et al (1992) , WarwickArmstrong and Russell (1990) , Wu (to appear).",
  "y": "background"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_1",
  "x": "There have been quite a number of recent papers on parallel text: Brown et al (1990 Brown et al ( , 1991 Brown et al ( , 1993 , Chen (1993) , <cite>Church (1993)</cite> , , Dagan et al (1993) , Church (1991, 1993) , Isabelle (1992) , Kay and Rgsenschein (1993) , Klavans and Tzoukermann (1990) , Kupiec (1993) , Matsumoto (1991) , Ogden and Gonzales (1993) , Shemtov (1993) , Simard et al (1992) , WarwickArmstrong and Russell (1990) , Wu (to appear). Most of this work has been focused on European language pairs, especially English-French. It remains an open question how well these methods might generalize to other language pairs, especially pairs such as English-Japanese and EnglishChinese.",
  "y": "motivation background"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_2",
  "x": "In previous work , we have reported some preliminary success in aligning the English and Japanese versions of the AWK manual (Aho, Kernighan, Weinberger (1980) ), using charalign<cite> (Church, 1993)</cite> , a method that looks for character sequences that are the same in both the source and target.",
  "y": "background"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_3",
  "x": "In previous work , we have reported some preliminary success in aligning the English and Japanese versions of the AWK manual (Aho, Kernighan, Weinberger (1980) ), using charalign<cite> (Church, 1993)</cite> , a method that looks for character sequences that are the same in both the source and target. In general, this approach doesn't work between languages such as English and Japanese which are written in different alphabets.",
  "y": "background motivation"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_4",
  "x": "These tables were computed from a small fragment of the Canadian Hansards that has been used in a number of other studies: <cite>Church (1993)</cite> and Simard et al (1992 show where the concordances were found in the texts.",
  "y": "uses"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_5",
  "x": "This algorithm was applied to a fragment of the Canadian Hansards that has been used in a number of other studies: <cite>Church (1993)</cite> and Simard et al (1992) .",
  "y": "uses"
 },
 {
  "id": "dcfad33f4322738906e2fdffe2e721_6",
  "x": "Currently, word_align depends on charalign<cite> (Church, 1993)</cite> to generate a starting point, which limits its applicability to European languages since char_align was designed for language pairs that share a common alphabet.",
  "y": "uses background"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_0",
  "x": "Recent work demonstrated that word embeddings induced from large text collections encode many human biases (e.g., Bolukbasi et al., 2016;<cite> Caliskan et al., 2017)</cite> .",
  "y": "motivation background"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_1",
  "x": "In order to measure the extent to which various societal biases are captured by word embeddings,<cite> Caliskan et al. (2017)</cite> proposed the Word Embedding Association Test (WEAT).",
  "y": "background"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_2",
  "x": "We first introduce the WEAT dataset<cite> (Caliskan et al., 2017)</cite> and then describe XWEAT, our multilingual and cross-lingual extension of WEAT designed for comparative bias analyses across languages and in cross-lingual embedding spaces.",
  "y": "uses"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_3",
  "x": "The Word Embedding Association Test (WEAT)<cite> (Caliskan et al., 2017)</cite> is an adaptation of the Implicit Association Test (IAT) (Nosek et al., 2002) .",
  "y": "background"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_4",
  "x": "We adopt the general bias-testing framework from<cite> Caliskan et al. (2017)</cite> , but we span our study over multiple dimensions: (1) corpora -we analyze the consistency of biases across distributional vectors induced from different types of text; (2) embedding models -we compare biases across distributional vectors induced by different embedding models (on the same corpora); and (3) languageswe measure biases for word embeddings of different languages, trained from comparable corpora.",
  "y": "extends uses"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_5",
  "x": "Furthermore, unlike<cite> Caliskan et al. (2017)</cite> , we test whether biases depend on the selection of the similarity metric.",
  "y": "extends"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_6",
  "x": "We adopt the general bias-testing framework from<cite> Caliskan et al. (2017)</cite> , but we span our study over multiple dimensions: (1) corpora -we analyze the consistency of biases across distributional vectors induced from different types of text; (2) embedding models -we compare biases across distributional vectors induced by different embedding models (on the same corpora); and (3) languageswe measure biases for word embeddings of different languages, trained from comparable corpora. Furthermore, unlike<cite> Caliskan et al. (2017)</cite> , we test whether biases depend on the selection of the similarity metric.",
  "y": "extends"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_7",
  "x": "We first describe the WEAT framework<cite> (Caliskan et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_8",
  "x": "The tested statistic is the difference between X and Y in average similarity of their terms with terms from A and B: with association difference for term t computed as: where t is the distributional vector of term t and f is a similarity or distance metric, fixed to cosine similarity in the original work<cite> (Caliskan et al., 2017)</cite> .",
  "y": "background"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_9",
  "x": "5 This is consistent with the original results obtained by<cite> Caliskan et al. (2017)</cite> .",
  "y": "similarities"
 },
 {
  "id": "de9eb9b7dff69743252b3ff0ef8894_10",
  "x": "To this end, we have extended previous analyses based on the WEAT test<cite> (Caliskan et al., 2017</cite>; McCurdy and Serbetci, 2017) in multiple dimensions: across seven languages, four embedding models, and three different types of text.",
  "y": "extends uses"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_0",
  "x": "1 The CGT transport federation have risen against \"the lack of consultation\" and consider that employees have \"nothing positive to expect from this restructuring.\" 2 While studies have shown that discourse usage of discourse connectives can be accurately identified for English [13, <cite>20]</cite> , only a few studies have focused on the disambiguation of discourse connectives in other languages.",
  "y": "motivation background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_1",
  "x": "Most of previous work on the disambiguation of discourse connectives have focused on English discourse connectives [13, 14, <cite>20]</cite> .",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_2",
  "x": "One of earliest and pioneer work on the disambiguation of discourse connectives, Pitler and Nenkova<cite> [20]</cite> , showed that four syntactic features (see Section 3.4 for details about the features) and the connective itself can disambiguate discourse connectives with an accuracy of 95.04% within the PDTB [22] .",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_3",
  "x": "Later, Lin et al. [13] used the context of the connective (i.e. the previous and the following word of the connective) and added seven lexico-syntactic features to the feature set proposed by Pitler and Nenkova<cite> [20]</cite> .",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_4",
  "x": "Inspired by Pitler and Nenkova<cite> [20]</cite> , Alsaif and Markert [4] proposed an approach for the disambiguation of Arabic Discourse connectives.",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_5",
  "x": "Alsaif and Markert have shown that the features proposed by Pitler and Nenkova<cite> [20]</cite> work well for Arabic with an accuracy of 91.2%.",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_6",
  "x": "As mentioned in Section 2, Pitler and Nenkova<cite> [20]</cite> have shown that the context of discourse connectives in the syntactic tree is very discriminating for the disambiguation of English discourse connectives.",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_7",
  "x": "Regardless of its source, this disparity motivated us to investigate the applicability of features proposed for the disambiguation of English discourse connectives for French. As mentioned in Section 2, Pitler and Nenkova<cite> [20]</cite> have shown that the context of discourse connectives in the syntactic tree is very discriminating for the disambiguation of English discourse connectives.",
  "y": "uses"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_8",
  "x": "In addition to the four features above, Pitler and Nenkova<cite> [20]</cite> used the discourse connective itself (case sensitive) as an additional feature for the classifier.",
  "y": "background"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_9",
  "x": "In addition to the four features above, Pitler and Nenkova<cite> [20]</cite> used the discourse connective itself (case sensitive) as an additional feature for the classifier. We slightly modified this feature by using the case-folded version of the discourse connective (called the Conn Feature).",
  "y": "extends"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_10",
  "x": "These two features are as informative as the case-sensitive connective string proposed by Pitler and Nenkova<cite> [20]</cite> , however, separating these features gives the classifier more flexibility when building its model.",
  "y": "similarities differences"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_11",
  "x": "Similarly to Pitler and Nenkova<cite> [20]</cite> , we report results using a maximum entropy classifier using ten-fold cross-validation over the extracted datasets.",
  "y": "similarities"
 },
 {
  "id": "e0df566d073649431c3454a52813e9_12",
  "x": "In this paper, we have investigated the applicability of the syntactic and lexical features proposed by Pitler and Nenkova<cite> [20]</cite> for the disambiguation of English discourse connectives for French.",
  "y": "extends"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_0",
  "x": "The largest improvement comes from using the learned MBN features but our approach also improves results for MFCCs, which are the same features as were used in <cite>[15]</cite> .",
  "y": "similarities differences"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_1",
  "x": "Our work is most closely related to the models presented in [12, 13, 14,<cite> 15]</cite> .",
  "y": "similarities"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_2",
  "x": "Our work is most closely related to the models presented in [12, 13, 14,<cite> 15]</cite> . In the current study we improve upon these previous approaches to visual grounding of speech and present state-of-the-art image-caption retrieval results.",
  "y": "uses"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_3",
  "x": "The work by [12, 13, 14,<cite> 15]</cite> and the results presented here are a step towards more cognitively plausible models of language learning as it is more natural to learn language without prior assumptions about the lexical level.",
  "y": "background"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_4",
  "x": "The approach is based on our own text-based model described in [8] and on the speech-based models described in [13,<cite> 15]</cite> and we refer to those studies for more details.",
  "y": "uses background"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_5",
  "x": "We use importance sampling to select the mismatched pairs; rather than using all the other samples in the mini-batch as mismatched pairs (as done in [8,<cite> 15]</cite> ), we calculate the loss using only the hardest examples (i.e. mismatched pairs with high cosine similarity).",
  "y": "differences"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_6",
  "x": "The main differences with the approaches described in [13,<cite> 15]</cite> are the use of multi-layered GRUs, importance sampling, the cyclic learning rate, snapshot ensembling and the use of vectorial rather than scalar attention.",
  "y": "differences"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_7",
  "x": "While our model is not explicitly trained to recognise words or segment the speech signal, previous work has shown that such information can be extracted by visual grounding models<cite> [15,</cite> 28] .",
  "y": "background"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_8",
  "x": "<cite>[15]</cite> use a binary decision task: given a word and a sentence embedding, decide if the word occurs in the sentence.",
  "y": "background"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_9",
  "x": "We compare our models to [12] and <cite>[15]</cite> , and include our own character-based model for comparison.",
  "y": "uses"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_10",
  "x": "We compare our models to [12] and <cite>[15]</cite> , and include our own character-based model for comparison. [12] is a convolutional approach, whereas <cite>[15]</cite> is an approach using recurrent highway networks with scalar attention.",
  "y": "uses"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_11",
  "x": "[12] is a convolutional approach, whereas <cite>[15]</cite> is an approach using recurrent highway networks with scalar attention.",
  "y": "background"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_12",
  "x": "The largest improvement is the MBN model which outperforms the results reported in <cite>[15]</cite> by as much as 23.2 percentage points on R@10.",
  "y": "differences"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_13",
  "x": "Both our MFCC and MBN based model significantly outperform previous spoken captionto-image methods on the Flickr8k dataset. The largest improvement is the MBN model which outperforms the results reported in <cite>[15]</cite> by as much as 23.2 percentage points on R@10.",
  "y": "differences"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_14",
  "x": "The work presented in <cite>[15]</cite> has made the first efforts in this regard and we aim to extend this to a larger database with sentences from multiple domains.",
  "y": "uses future_work"
 },
 {
  "id": "e41a1adcb5c9d91f2130bd249ed598_15",
  "x": "We are currently collecting the Semantic Textual Similarity (STS) database in spoken format and the next step will be to investigate whether the model presented here also learns to capture sentence level semantic information and understand language in a deeper sense than recognising word presence. The work presented in <cite>[15]</cite> has made the first efforts in this regard and we aim to extend this to a larger database with sentences from multiple domains.",
  "y": "future_work"
 },
 {
  "id": "e803782890224294066ce447671981_0",
  "x": "The <cite>patternmatching approach</cite> proposed by <cite>Johnson (2002)</cite> for a similar task for phrase structure trees is extended with machine learning techniques.",
  "y": "extends"
 },
 {
  "id": "e803782890224294066ce447671981_1",
  "x": "Evaluating the algorithm on the Penn Treebank shows an improvement of both precision and recall, compared to the results presented in <cite>(Johnson, 2002)</cite> .",
  "y": "differences"
 },
 {
  "id": "e803782890224294066ce447671981_2",
  "x": "In (Clark et al., 2002) long-range dependencies are included in parser's probabilistic model, while <cite>Johnson (2002)</cite> presents a method for recovering non-local dependencies after parsing has been performed.",
  "y": "background"
 },
 {
  "id": "e803782890224294066ce447671981_3",
  "x": "More specifically, <cite>Johnson (2002)</cite> describes a <cite>pattern-matching algorithm</cite> for inserting empty nodes and identifying their antecedents in phrase structure trees or, to put it differently, for recovering non-local dependencies.",
  "y": "background"
 },
 {
  "id": "e803782890224294066ce447671981_4",
  "x": "From a training corpus with annotated empty nodes <cite>Johnson's algorithm</cite> first extracts those local fragments of phrase trees which connect empty nodes with their antecedents, thus \"licensing\" corresponding non-local dependencies.",
  "y": "background"
 },
 {
  "id": "e803782890224294066ce447671981_5",
  "x": "From a training corpus with annotated empty nodes <cite>Johnson's algorithm</cite> first extracts those local fragments of phrase trees which connect empty nodes with their antecedents, thus \"licensing\" corresponding non-local dependencies. Next, the extracted tree fragments are used as patterns to match against previously unseen phrase structure trees: when a pattern is matched, <cite>the algorithm</cite> introduces a corresponding non-local dependency, inserting an empty node and (possibly) coindexing it with a suitable antecedent.",
  "y": "background"
 },
 {
  "id": "e803782890224294066ce447671981_6",
  "x": "In <cite>(Johnson, 2002 )</cite> <cite>the author</cite> notes that the biggest weakness of <cite>the algorithm</cite> seems to be that it fails to robustly distinguish co-indexed and free empty nodes and it is lexicalization that may be needed to solve this problem.",
  "y": "motivation"
 },
 {
  "id": "e803782890224294066ce447671981_7",
  "x": "In <cite>(Johnson, 2002 )</cite> <cite>the author</cite> notes that the biggest weakness of <cite>the algorithm</cite> seems to be that it fails to robustly distinguish co-indexed and free empty nodes and it is lexicalization that may be needed to solve this problem. Moreover, <cite>the author</cite> suggests that <cite>the algorithm</cite> may suffer from overlearning, and using more abstract \"skeletal\" patterns may be helpful to avoid this.",
  "y": "motivation"
 },
 {
  "id": "e803782890224294066ce447671981_8",
  "x": "The evaluation of our algorithm on data automatically derived from the Penn Treebank shows an increase in both precision and recall in recovery of non-local dependencies by approximately 10% over the results reported in <cite>(Johnson, 2002)</cite> .",
  "y": "differences"
 },
 {
  "id": "e803782890224294066ce447671981_9",
  "x": "As in <cite>(Johnson, 2002)</cite> , our patterns are minimal connected fragments containing both nodes involved in a non-local dependency.",
  "y": "uses similarities"
 },
 {
  "id": "e803782890224294066ce447671981_10",
  "x": "The definition of a structure matching a pattern, and the algorithms for pattern matching and pattern extraction from a corpus are straightforward and similar to those described in <cite>(Johnson, 2002)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e803782890224294066ce447671981_12",
  "x": "In order to compare our results to the results presented in <cite>(Johnson, 2002)</cite> , we measured the overall performance of the algorithm across patterns and non-local dependency labels. This corresponds to the row \"Overall\" of Table 4 in <cite>(Johnson, 2002)</cite> , repeated here in Table 4 .",
  "y": "similarities"
 },
 {
  "id": "e803782890224294066ce447671981_13",
  "x": "We also evaluated the procedure on NP traces across all patterns, i.e., on nonlocal dependencies with NP-SBJ, NP-OBJ or NP-PRD labels. This corresponds to rows 2, 3 and 4 of Table 4 in <cite>(Johnson, 2002)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e803782890224294066ce447671981_17",
  "x": "The two algorithms are designed for slightly different purposes: while <cite>Johnson's approach</cite> allows one to recover free empty nodes (without antecedents), we look for nonlocal dependencies, which corresponds to identification of co-indexed empty nodes (note, however, the modifications we describe in Section 2, when we actually transform free empty nodes into co-indexed empty nodes).",
  "y": "differences"
 },
 {
  "id": "e803782890224294066ce447671981_18",
  "x": "The results presented in the previous section show that it is possible to improve over the simple <cite>pattern matching algorithm</cite> of <cite>(Johnson, 2002)</cite> , using dependency rather than phrase structure information, more skeletal patterns, as was suggested by <cite>Johnson</cite>, and a set of features associated with instances of patterns.",
  "y": "differences"
 },
 {
  "id": "e803782890224294066ce447671981_19",
  "x": "Obviously, because of parsing errors the performance drops significantly: e.g., in the experiments reported in <cite>(Johnson, 2002 )</cite> the overall fscore decreases from 0.75 to 0.68 when evaluating on parser output (see Table 4 ).",
  "y": "background"
 },
 {
  "id": "e803782890224294066ce447671981_20",
  "x": "We extend the pattern matching approach of <cite>Johnson (2002)</cite> with machine learning techniques, and use dependency structures instead of constituency trees.",
  "y": "extends differences"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_0",
  "x": "Large-scale knowledge bases (KBs), such as Freebase [Bollacker et al., 2008] , WordNet<cite> [Miller, 1995]</cite> , Yago<cite> [Suchanek et al., 2007]</cite> , and NELL [Carlson et al., 2010] , are critical to natural language processing applications, e.g., question answering [Dong et al., 2015] , relation extraction<cite> [Riedel et al., 2013]</cite> , and language modeling [Ahn et al., 2016] .",
  "y": "background"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_1",
  "x": "Traditional KB completion approaches, such as Markov logic networks<cite> [Richardson and Domingos, 2006]</cite> , suffer from feature sparsity and low efficiency.",
  "y": "motivation"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_2",
  "x": "TransH [Wang et al., 2014] and TransR<cite> [Lin et al., 2015b]</cite> are representative variants of TransE. These variants consider entities from multiple aspects and various relations on different aspects.",
  "y": "background"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_3",
  "x": "Consequently, a promising new research direction is to use relation paths to learn knowledge embeddings<cite> [Neelakantan et al., 2015</cite>; Guu et al., 2015;<cite> Toutanova et al., 2016]</cite> .",
  "y": "motivation"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_4",
  "x": "However, the consistent semantics expressed by some relation paths p is unreliable for reasoning new facts of that entity pair<cite> [Lin et al., 2015a]</cite> .",
  "y": "motivation"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_5",
  "x": "As the path ranking algorithm (PRA)<cite> [Lao et al., 2011]</cite> suggests, relation paths that end in many possible tail entities are more likely to be unreliable for the entity pair.",
  "y": "background"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_6",
  "x": "A third current related work is PTransE<cite> [Lin et al., 2015a</cite> ] and the path ranking algorithm (PRA)<cite> [Lao et al., 2011]</cite> .",
  "y": "background"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_7",
  "x": "PRA, as one of the most promising research innovations for knowledge base completion, has also attracted considerable attention<cite> [Lao et al., 2015</cite>; Gardner and Mitchell, 2015; Wang et al., 2016;<cite> Nickel et al., 2016]</cite> .",
  "y": "background"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_8",
  "x": "We follow the same evaluation procedures as used in [Bordes et al., 2013; Wang et al., 2014;<cite> Lin et al., 2015b]</cite> .",
  "y": "uses"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_9",
  "x": "Because we use the same dataset, the baseline results reported in<cite> [Lin et al., 2015b</cite>;<cite> Lin et al., 2015a</cite>; Ji et al., 2016] are directly used for comparison.",
  "y": "uses"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_10",
  "x": "In particular, for the 1-to-N, N-to-1, and N-to-N types of relations [Bordes et al., 2013] 75.9 70.9 77.8 TransE (bern) [Bordes et al., 2013] 75.9 81.5 85.3 TransH (unif) [Wang et al., 2014] 77.7 76.5 78.4 TransH (bern) [Wang et al., 2014] 78.8 83.3 85.8 TransR (unif)<cite> [Lin et al., 2015b]</cite> 85.5 74.7 79.2 TransR (bern)<cite> [Lin et al., 2015b]</cite> 85.9 82.5 87.0 PTransE (ADD, 2-hop)<cite> [Lin et al., 2015a]</cite> 80.9 73.5 83.4 PTransE (MUL, 2-hop)<cite> [Lin et al., 2015a]</cite> 79.4 73.6 79.3 PTransE (ADD, 3-hop)<cite> [Lin et al., 2015a]</cite> 80 that plague knowledge embedding models, RPE (ACOM) improves 4.1%, 4.6%, and 4.9% on head entity's prediction and 6.9%, 7.0%, and 5.1% on tail entity's prediction compared with previous state-of-the-art performances achieved by PTransE (ADD, 2-hop).",
  "y": "differences"
 },
 {
  "id": "e826db8ca46b47ba56945c50512a03_11",
  "x": "We directly compare our model with prior work using the results about knowledge embedding models reported in<cite> [Lin et al., 2015b]</cite> n=50, m=50, \u03b3 1 =5, \u03b3 2 =6, \u03b1=0.0001, B=1440, \u03bb=0.8, and \u03b7=0.05, taking the L 1 norm on WN11; n=100, m=100, \u03b3 1 =3, \u03b3 2 =6, \u03b1=0.0001, B=960, \u03bb=0.8, and \u03b7=0.05, taking the L 1 norm on FB13; and n=100, m=100, \u03b3 1 =4, \u03b3 2 =5, \u03b1=0.0001, B=4800, \u03bb=1, and \u03b7 =0.05, taking the L 1 norm on FB15K.",
  "y": "uses"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_0",
  "x": "While several techniques for merging both spaces have been proposed [<cite>1</cite>, 2, 3, 4, 5, 6] , little effort has been made in finding the most appropriate image embeddings to be used in that process.",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_1",
  "x": "In fact, <cite>most approaches</cite> simply use a one-layer CNN embedding [7, 8] .",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_2",
  "x": "We do so by integrating the FNE into the multimodal embedding pipeline defined by <cite>Kiros et al. [1]</cite> , which is based in the use of a Gated Recurrent Units neural network (GRU) [10] for text encoding and CNN for image encoding.",
  "y": "extends"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_3",
  "x": "The generic pipeline defined by <cite>Kiros et al. [1]</cite> has been recently outperformed in image annotation and image search tasks by methods specifically targeting one of those tasks [4, 18] .",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_4",
  "x": "We choose to test our contribution on <cite>this pipeline</cite> for its overall competitive performance, expecting that any conclusion may generalize when applied to other solutions and tasks (e.g., caption generation).",
  "y": "motivation uses"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_5",
  "x": "Results obtained by the pipeline including the FNE are compared with the original pipeline of <cite>Kiros et al. [1]</cite> using a one-layer embedding, and also with the methods currently obtaining state-of-the-art results on the three datasets.",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_6",
  "x": "In the last few years, several solutions have been proposed to the problem of building common representations for images and text with the goal of enabling cross-domain search [<cite>1</cite>, 2, 3, 4, 5] .",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_7",
  "x": "This paper builds upon the methodology described by <cite>Kiros et al. [1]</cite> , <cite>which</cite> is in turn based on previous works in the area of Neural Machine Translation [14] .",
  "y": "extends"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_8",
  "x": "In their work, <cite>Kiros et al. [1]</cite> define a vectorized representation of an input text by using GRU RNNs.",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_9",
  "x": "Similarly to the approach of <cite>Kiros et al. [1]</cite> , most image annotation and image retrieval approaches rely on the use of CNN features for image representation.",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_10",
  "x": "In our approach, we integrate the FNE with the multimodal embedding pipeline of <cite>Kiros et al. [1]</cite> .",
  "y": "extends"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_11",
  "x": "In our approach, we integrate the FNE with the multimodal embedding pipeline of <cite>Kiros et al. [1]</cite> . To do so we use the FNE to obtain an image representation instead of the output of the last layer of a CNN, as the <cite>original model</cite> does.",
  "y": "extends differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_12",
  "x": "To combine both embeddings, <cite>Kiros et al. [1]</cite> use an affine transformation on the image representation (in our case, the FNE) identical to a fully connected neural network layer.",
  "y": "differences background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_13",
  "x": "The elements of the <cite>multimodal pipeline</cite> that are tuned during the training phase of the model are shown in orange in Figure  1 .",
  "y": "background"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_14",
  "x": "To properly measure the relevance of the FNE, we compare the results of the FN-MME with those of the <cite>original multimodal pipeline</cite> reported by <cite>Kiros et al. [1]</cite> (CNN-MME).",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_15",
  "x": "Additionally, we define a second baseline by using the <cite>original multimodal pipeline</cite> with a training configuration closer to the one used for the FNE experiments (i.e., same source CNN, same MME dimensionality, etc.).",
  "y": "extends"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_16",
  "x": "These splits are the same ones used by <cite>Kiros et al. [1]</cite> and by Karpathy and Fei-Fei [22] .",
  "y": "uses"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_17",
  "x": "The original setup [<cite>1]</cite> limited the word embedding to the 300 most frequent words, while using 300 GRUs.",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_18",
  "x": "For both image annotation and image retrieval tasks on the Flickr8k dataset, Table 1 shows the results of the proposed FN-MME, the reported results of the <cite>original model</cite> <cite>CNN-MME</cite>, the results of the original model when using our configuration CNN-MME*, and the current state-of-the-art (SotA).",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_19",
  "x": "We include these for the MSCOCO dataset, which was not evaluated in the <cite>original paper</cite> <cite>[1]</cite> .",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_20",
  "x": "On all cases, the multimodal pipeline proposed by <cite>Kiros et al. [1]</cite> obtains equal or better results when using the FNE.",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_21",
  "x": "On all cases, the multimodal pipeline proposed by <cite>Kiros et al. [1]</cite> obtains equal or better results when using the FNE. This is the case for the <cite>originally reported results</cite> (<cite>CNN-MME</cite>), for the results made available later on by the original authors (CNN-MME \u2020), and for the experiments we do using same configuration as the FN-MME (CNN-MME*).",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_22",
  "x": "For the multimodal pipeline of <cite>Kiros et al. [1]</cite> , using the Full-Network image embedding results in consistently higher performances than using a one-layer image embedding.",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_23",
  "x": "Since this happens for all models using the same pipeline (CNN-MME, CNN-MME \u2020, CNN-MME*), these results indicate that the original architecture of <cite>Kiros et al. [1]</cite> is itself outperformed in general by more problem-specific techniques.",
  "y": "differences"
 },
 {
  "id": "e90c9a93ec445a636fcee924306d95_24",
  "x": "If the boost in performance obtained by the FNE on the <cite>Kiros et al. [1]</cite> pipeline translates to these other methods, such combination would be likely to define new state-of-the-art results on both tasks.",
  "y": "future_work"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_0",
  "x": "For constituent-based parsing using the Chinese Treebank (CTB), <cite>Wang et al. (2006)</cite> have shown that a shift-reduce parser can give competitive accuracy scores together with high speeds, by using an SVM to make a single decision at each point in the parsing process.",
  "y": "background"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_1",
  "x": "For constituent-based parsing using the Chinese Treebank (CTB), <cite>Wang et al. (2006)</cite> have shown that a shift-reduce parser can give competitive accuracy scores together with high speeds, by using an SVM to make a single decision at each point in the parsing process. In this paper we describe a global discriminative model for Chinese shift-reduce parsing, and compare it with Wang et al.'s approach.",
  "y": "motivation"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_2",
  "x": "We apply the same shift-reduce procedure as <cite>Wang et al. (2006)</cite> , but instead of using a local classifier for each transition-based action, we train a generalized perceptron model over complete sequences of actions, so that the parameters are learned in the context of complete parses.",
  "y": "uses differences"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_3",
  "x": "The shift-reduce process used by our beam-search decoder is based on the greedy shift-reduce parsers of Sagae and Lavie (2005) and <cite>Wang et al. (2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_4",
  "x": "Sagae and Lavie (2005) and <cite>Wang et al. (2006)</cite> only used the first three transition actions, setting the final state as all incoming words having been processed, and the stack containing only one node.",
  "y": "background"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_5",
  "x": "Sagae and Lavie (2005) and <cite>Wang et al. (2006)</cite> only used the first three transition actions, setting the final state as all incoming words having been processed, and the stack containing only one node. However, there are a small number of sentences (14 out of 3475 from the training data) that have unary-branching roots. For these sentences, Wang's parser will be unable to produce the unary-branching roots because the parsing process terminates as soon as the root is found. We define a separate action to terminate parsing, allowing unary reduces to be applied to the root item before parsing finishes.",
  "y": "extends"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_6",
  "x": "<cite>Wang et al. (2006)</cite> give a detailed example showing how a segmented and POS-tagged sentence can be incrementally processed using the shift-reduce actions to produce a binary tree.",
  "y": "background"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_7",
  "x": "<cite>Wang et al. (2006)</cite> give a detailed example showing how a segmented and POS-tagged sentence can be incrementally processed using the shift-reduce actions to produce a binary tree. We show this example in Figure 1 .",
  "y": "uses"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_8",
  "x": "In the deterministic parser of <cite>Wang et al. (2006)</cite> , the highest scoring action predicted by the classifier may prevent a valid binary tree from being built.",
  "y": "background"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_9",
  "x": "The context S 0 , S 1 , S 2 , S 3 and N 0 , N 1 , N 2 , N 3 for the feature templates is taken from <cite>Wang et al. (2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_10",
  "x": "However, <cite>Wang et al. (2006)</cite> used a polynomial kernel function with an SVM and did not manually create feature combinations.",
  "y": "background"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_11",
  "x": "However, <cite>Wang et al. (2006)</cite> used a polynomial kernel function with an SVM and did not manually create feature combinations. Since we used the linear perceptron algorithm we manually combined Unigram features into Bigram and Trigram features.",
  "y": "differences"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_12",
  "x": "The \"Bracket\" row shows bracket-related features, which were inspired by <cite>Wang et al. (2006)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_13",
  "x": "<cite>Wang et al. (2006)</cite> used a range of other features, including rhythmic features of S 0 and S 1 (Sun and Jurafsky, 2003) , features from the most recently found node that is to the left or right of S 0 and S 1 , the number of words and the number of punctuations in S 0 and S 1 , the distance between S 0 and S 1 and so on.",
  "y": "background"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_14",
  "x": "<cite>Wang et al. (2006)</cite> used a range of other features, including rhythmic features of S 0 and S 1 (Sun and Jurafsky, 2003) , features from the most recently found node that is to the left or right of S 0 and S 1 , the number of words and the number of punctuations in S 0 and S 1 , the distance between S 0 and S 1 and so on. We did not include these features in our parser, because they did not lead to improved performance during development experiments.",
  "y": "differences"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_15",
  "x": "The rows represent the model from Bikel and Chiang (2000) , Bikel (2004) , the SVM and ensemble models from <cite>Wang et al. (2006)</cite> , and our parser, respectively.",
  "y": "similarities"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_16",
  "x": "The rows in the table represent the models from Bikel and Chiang (2000), Levy and Manning (2003) , Xiong et al. (2005) , Bikel (2004), Chiang and Bikel (2002) , the SVM model from <cite>Wang et al. (2006)</cite> and the ensemble system from <cite>Wang et al. (2006)</cite> , and the parser of this paper, respectively.",
  "y": "uses"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_17",
  "x": "Our parser gave comparable accuracies to the SVM and ensemble models from <cite>Wang et al. (2006)</cite> .",
  "y": "similarities"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_18",
  "x": "Our parser gave comparable accuracies to the SVM and ensemble models from <cite>Wang et al. (2006)</cite> . However, comparison with Table 3 shows that our parser is more sensitive to POS-tagging errors than some of the other models.",
  "y": "differences"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_19",
  "x": "Our parser is based on the shift-reduce parsing process from Sagae and Lavie (2005) and <cite>Wang et al. (2006)</cite> , and therefore it can be classified as a transition-based parser (Nivre et al., 2006 ).",
  "y": "uses"
 },
 {
  "id": "e9a7e0d6d09fb2a2dd1972d6d16682_20",
  "x": "An important difference between our parser and the <cite>Wang et al. (2006)</cite> parser is that our parser is based on a discriminative learning model with global features, whilst the parser from <cite>Wang et al. (2006)</cite> is based on a local classifier that optimizes each individual choice.",
  "y": "differences"
 },
 {
  "id": "e9b2f32ed29589b4a6d49d3b30fc3a_0",
  "x": "By segmenting words into morphemes, we can improve the performance of natural language systems including machine translation <cite>(Brown et al. 1993</cite> ) and information retrieval (Franz, M. and McCarley, S. 2002) .",
  "y": "extends motivation"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_0",
  "x": "Neural network-based encoder-decoder models are cutting-edge methodologies for tackling natural language generation (NLG) tasks, i.e., machine translation (Cho et al., 2014) , image captioning (Vinyals et al., 2015) , video description (Venugopalan et al., 2015) , and headline generation (<cite>Rush et al., 2015</cite>) .",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_1",
  "x": "The method is essentially an extension of <cite>attention-based summarization</cite> (<cite>ABS</cite>) (<cite>Rush et al., 2015</cite>) .",
  "y": "extends"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_2",
  "x": "Our proposed method encodes results obtained from an AMR parser by using a modified version of Tree-LSTM encoder (Tai et al., 2015) as additional information of the <cite>baseline ABS model</cite>.",
  "y": "extends"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_5",
  "x": "<cite>ABS</cite> proposed in <cite>Rush et al. (2015)</cite> has achieved state-of-the-art performance on the benchmark data of headline generation including the DUC-2004 dataset (Over et al., 2007) .",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_6",
  "x": "Figure 1 illustrates the model structure of <cite>ABS</cite>.",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_7",
  "x": "Figure 1 illustrates the model structure of <cite>ABS</cite>. <cite>The model</cite> predicts a word sequence (summary) based on the combination of the neural network language model and an input sentence encoder.",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_8",
  "x": "Then, <cite>ABS</cite> outputs a summary\u0176 given an input sentence X as follows:",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_9",
  "x": "To demonstrate the effectiveness of our proposed method, we conducted experiments on benchmark data of the abstractive headline generation task described in <cite>Rush et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_11",
  "x": "The training data was obtained from the first sentence and the headline of a document in the annotated <cite>Gigaword</cite> corpus (Napoles et al., 2012) 4 .",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_12",
  "x": "The development data is DUC-2003 data, and test data are both DUC-2004 (Over et al., 2007) and sentence-headline pairs obtained from the annotated <cite>Gigaword</cite> corpus as well as training data 5 .",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_13",
  "x": "For evaluation on <cite>Gigaword</cite>, we forced the system outputs to be at most 8 words as in <cite>Rush et al. (2015)</cite> since the average length of headline in <cite>Gigaword</cite> is 8.3 words.",
  "y": "uses similarities"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_14",
  "x": "Note that, for further evaluation, we prepared 2,000 sentence-headline pairs randomly sampled from the test data section of the <cite>Gigaword</cite> corpus as our additional test data.",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_15",
  "x": "In our experiments, we refer to the baseline neural attention-based abstractive summarization method described in <cite>Rush et al. (2015)</cite> as \"<cite>ABS</cite>\", and our proposed method of incorporating AMR structural information by a neural encoder to the baseline method described in Section 3 as \"<cite>ABS</cite>+AMR\".",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_17",
  "x": "For <cite>ABS</cite>+AMR, we used the two-step training scheme to accelerate the training speed.",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_18",
  "x": "The first phase learns the parameters of the <cite>ABS</cite>.",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_19",
  "x": "The second phase trains the parameters of the AMR encoder by using 1 million training pairs while the parameters of the baseline <cite>ABS</cite> were fixed and unchanged to prevent overfitting.",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_20",
  "x": "<cite>ABS</cite> (re-run) represents the performance of <cite>ABS</cite> re-trained by the distributed scripts 7 .",
  "y": "background"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_21",
  "x": "We can see that the proposed method, <cite>ABS</cite>+AMR, outperforms the baseline <cite>ABS</cite> on all datasets.",
  "y": "differences"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_22",
  "x": "In particular, <cite>ABS</cite>+AMR achieved statistically significant gain from <cite>ABS</cite> (re-run) for ROUGE-1 and ROUGE-2 on DUC-2004.",
  "y": "differences"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_23",
  "x": "However in contrast, we observed that the improvements on <cite>Gigaword</cite> (the same test data as <cite>Rush et al. (2015)</cite> ) seem to be limited compared with the DUC-2004 dataset.",
  "y": "similarities uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_26",
  "x": "<cite>Gigaword</cite> test data provided by <cite>Rush et al. (2015)</cite> is already pre-processed.",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_27",
  "x": "To provide evidence of this assumption, we also evaluated the performance on our randomly selected 2,000 sentence-headline test data also taken from the test data section of the annotated <cite>Gigaword</cite> corpus.",
  "y": "uses"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_29",
  "x": "We found the statistical difference between <cite>ABS</cite>(re-run) and <cite>ABS</cite>+AMR on ROUGE-1 and ROUGE-2.",
  "y": "differences"
 },
 {
  "id": "eb51af7d0487fc0795616aecfae9fb_35",
  "x": "For headline generation tasks, Chopra et al. (2016) exploited the RNN decoder (and its variant) with the attention mechanism instead of the method of <cite>Rush et al. (2015)</cite> : the combination of the feed-forward neural network language model and attention-based sentence encoder. also adapted the RNN encoder-decoder with attention for headline generation tasks.",
  "y": "background"
 },
 {
  "id": "ecdd75533aff56771f0320694efc9a_0",
  "x": "We submitted three systems for Hindi \u2192 Nepali direction in which we have examined the performance of a Recursive Neural Network (RNN) based Neural Machine Translation (NMT) system, a semi-supervised NMT system where monolingual data of both languages is utilized using the architecture by <cite>(Artetxe et al., 2017)</cite> and a system trained with extra synthetic sentences generated using copy of source and target sentences without using any additional monolingual data.",
  "y": "uses"
 },
 {
  "id": "ecdd75533aff56771f0320694efc9a_1",
  "x": "In past, to improve the performance of NMT systems various techniques like Back-Translation (Sennrich et al., 2016a) , utilizing other similar language pairs through pivoting (Cheng et al., 2017) or transfer learning (Zoph et al., 2016) , complete unsupervised architectures <cite>(Artetxe et al., 2017)</cite> (Lample et al., 2018 ) and many others have been proposed.",
  "y": "background"
 },
 {
  "id": "ecdd75533aff56771f0320694efc9a_2",
  "x": "The Unsupervised NMT approach proposed in <cite>(Artetxe et al., 2017)</cite> follows an architecture where encoder is shared and decoder is separate for each language.",
  "y": "background"
 },
 {
  "id": "ecdd75533aff56771f0320694efc9a_3",
  "x": "We have utilized architecture proposed in <cite>(Artetxe et al., 2017)</cite> where encoder is shared and decoders are separate for each language and model is trained by alternating between denoising and back-translation.",
  "y": "uses"
 },
 {
  "id": "ecdd75533aff56771f0320694efc9a_4",
  "x": "To train all three systems we have utilized the implementation of <cite>(Artetxe et al., 2017)</cite> .",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_0",
  "x": "Several papers recently demonstrated the potential of very weakly supervised or entirely unsupervised approaches to bilingual dictionary induction (BDI) (Barone, 2016; Artetxe et al., 2017; Zhang et al., 2017; <cite>Conneau et al., 2018</cite>; , the task of identifying translational equivalents across two languages.",
  "y": "background"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_2",
  "x": "In addition to an unsupervised approach to aligning monolingual word embedding spaces with adversarial training,<cite> Conneau et al. (2018)</cite> present a supervised alignment algorithm that assumes a gold-standard seed dictionary and performs Procrustes Analysis (Sch\u00f6nemann, 1966) .",
  "y": "background"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_3",
  "x": "The implementation of PA in<cite> Conneau et al. (2018)</cite> yields notable improvements over earlier work on BDI, even though it learns a simple linear transform of the source language space into the target language space.",
  "y": "background"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_4",
  "x": "In this work, we show that projecting both source and target vector spaces into a third space (Faruqui and Dyer, 2014) , using a variant of PA known as Generalized Procrustes Analysis (Gower, 1975) , makes it easier to learn the alignment between two word vector spaces, as compared to the single linear transform used in<cite> Conneau et al. (2018)</cite> .",
  "y": "differences"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_5",
  "x": "In our experiments, we generally use the same hyper-parameters as used in<cite> Conneau et al. (2018)</cite> , unless otherwise stated.",
  "y": "uses similarities"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_6",
  "x": "When extracting dictionaries for the bootstrapping procedure, we use cross-domain local scaling (CSLS, see<cite> Conneau et al. (2018)</cite> for details) as a metric for ranking candidate translation pairs, and we only use the ones that rank higher than 15,000.",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_7",
  "x": "Instead of doing a single training epoch, however, we run PA and GPA with early stopping, until five epochs of no improvement in the validation criterion as used in<cite> Conneau et al. (2018)</cite> , i.e. the average cosine similarity between the top 10,000 most frequent words in the source language and their candidate translations as induced with CSLS.",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_8",
  "x": "Our metric is Precision at k\u00d7100 (P@k), i.e. percentage of correct translations retrieved among the k nearest neighbor of the source words in the test set<cite> (Conneau et al., 2018)</cite> .",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_9",
  "x": "Unless stated otherwise, experiments were carried out using the publicly available pre-trained fastText embeddings, trained on Wikipedia data, 5 and bilingual dictionaries-consisting of 5000 and 1500 unique word pairs for training and testing, respectively-provided by<cite> Conneau et al. (2018)</cite> 6 .",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_10",
  "x": "Common benchmarks For a more extensive comparison with previous work, we include results on English-{Finnish, German, Italian} dictionaries used in<cite> Conneau et al. (2018)</cite> and Artetxe et al. (2018) -the second best approach to BDI known to us, which also uses Procrustes Analysis.",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_11",
  "x": "We use train and test bilingual dictionaries from Dinu et al. (2015) for English-Italian and from Artetxe et al. (2017) for English-{Finnish, German}. Following<cite> Conneau et al. (2018)</cite> , we report results with a set of CBOW embeddings trained on the WaCky corpus (Barone, 2016) , and with Wikipedia embeddings.",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_13",
  "x": "To explore the latter issue and to further compare the capabilities of PA and GPA, we perform a Procrustes fit test, where we learn alignments in a fully supervised fashion, using the test dictionaries of<cite> Conneau et al. (2018)</cite> 9 for both training and evaluation 10 .",
  "y": "uses"
 },
 {
  "id": "edfce6b99a4804c0908b39ea38d707_14",
  "x": "In most recent work, this mapping is constrained to be orthogonal and solved using Procrustes Analysis (Xing et al., 2015; Artetxe et al., 2017 Artetxe et al., , 2018 <cite>Conneau et al., 2018</cite>; Lu et al., 2015) .",
  "y": "background"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_0",
  "x": "However, since new named entities arise regularly, it becomes increasingly difficult to maintain an up-to-date dictionary and/or adapt a named entity classifier to a new domain; for example, sequence labeling techniques that use feature templates (Finkel et al., 2005; Sarawagi and Cohen, 2004) are not robust for unknown named entities because their feature space is very sparse<cite> (Primadhanty et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_1",
  "x": "However, since new named entities arise regularly, it becomes increasingly difficult to maintain an up-to-date dictionary and/or adapt a named entity classifier to a new domain; for example, sequence labeling techniques that use feature templates (Finkel et al., 2005; Sarawagi and Cohen, 2004) are not robust for unknown named entities because their feature space is very sparse<cite> (Primadhanty et al., 2015)</cite> . Therefore, in this paper, we propose the use of matrix factorization for named entity classification to consider the relationships between sparse features.",
  "y": "motivation"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_2",
  "x": "To address the task of unknown named entity classification, <cite>Primadhanty et al. (2015)</cite> explored the use of sparse combinatorial features.",
  "y": "background"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_3",
  "x": "We compared factorization machines with a log-linear model, a polynomial-kernel SVM, and a state-ofthe-art log-bilinear model using nuclear norm for regularization<cite> (Primadhanty et al., 2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_4",
  "x": "We used the dataset provided by <cite>Primadhanty et al. (2015)</cite> ; this dataset was created for evaluating unknown named entity classification and is context features: Right and left contexts of the candidate in a sentence (do not take the order into account).",
  "y": "uses"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_5",
  "x": "We used a subset of features from experiments performed by <cite>Primadhanty et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_6",
  "x": "Note that <cite>Primadhanty et al. (2015)</cite> used additional features such as Brown clustering and parts-of-speech (POS) features, which we did not use.",
  "y": "differences"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_7",
  "x": "We observed here that, aside from LOC, we obtained competitive results to the state-of-the-art named entity classifier proposed by <cite>Primadhanty et al. (2015)</cite> with fewer features.",
  "y": "similarities"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_8",
  "x": "The accuracy of LOC, however, was lower than that of the log-bilinear model<cite> (Primadhanty et al., 2015)</cite> .",
  "y": "differences"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_9",
  "x": "Figure 1 plots the F1-score of our proposed method as dimension k changes for matrix factor- ization using the same development data as that of <cite>Primadhanty et al. (2015)</cite> .",
  "y": "uses"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_10",
  "x": "Both our approach and the methods of <cite>Primadhanty et al. (2015)</cite> address the problem of incorporating sparse combinatorial features by dimension reduction (i.e., matrix factorization); however, they differ in terms of the objective function to be optimized.",
  "y": "similarities differences"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_11",
  "x": "<cite>Primadhanty et al. (2015)</cite> use maximum likelihood estimation as an objective function; whereas other objective functions such as hinge loss can be used in factorization machines.",
  "y": "background"
 },
 {
  "id": "eee36102d3feac0f673cd33562d40f_12",
  "x": "Both our approach and the methods of <cite>Primadhanty et al. (2015)</cite> address the problem of incorporating sparse combinatorial features by dimension reduction (i.e., matrix factorization); however, they differ in terms of the objective function to be optimized. <cite>Primadhanty et al. (2015)</cite> use maximum likelihood estimation as an objective function; whereas other objective functions such as hinge loss can be used in factorization machines.",
  "y": "differences"
 },
 {
  "id": "f1a800c7cd47ac2edf2172cedb5889_0",
  "x": "Does that mean that we can do away with explicit modeling of morphology altogether? Consider two challenges in parsing MRLs raised by <cite>Tsarfaty et al. (2010</cite> Tsarfaty et al. ( , 2013 :",
  "y": "motivation"
 },
 {
  "id": "f1a800c7cd47ac2edf2172cedb5889_1",
  "x": "For the second, <cite>Tsarfaty et al. (2010)</cite> and Seeker and Kuhn (2013) reported that morphological case is beneficial across morphologically rich languages with extensive case systems, where case syncretism is pervasive and often hurts parsing performance. But <cite>these studies</cite> focus on vintage parsers; do neural parsers with character-level representations also solve this second problem?",
  "y": "motivation background"
 },
 {
  "id": "f1a800c7cd47ac2edf2172cedb5889_2",
  "x": "These results are interesting, since in vintage parsers, predicted case usually harmed accuracy (<cite>Tsarfaty et al., 2010</cite>) .",
  "y": "background"
 },
 {
  "id": "f1a800c7cd47ac2edf2172cedb5889_3",
  "x": "We found that predicted case improves accuracy, although the effect is different across languages. These results are interesting, since in vintage parsers, predicted case usually harmed accuracy (<cite>Tsarfaty et al., 2010</cite>) .",
  "y": "differences"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_0",
  "x": "This paper gives an Abstract Categorial Grammar (ACG) account of<cite> (Kallmeyer and Kuhlmann, 2012)</cite>'s process of transformation of the derivation trees of Tree Adjoining Grammar (TAG) into dependency trees. We make explicit how the requirement of keeping a direct interpretation of dependency trees into strings results into lexical ambiguity. Since the ACG framework has already been used to provide a logical semantics from TAG derivation trees, we have a unified picture where derivation trees and dependency trees are related but independent equivalent ways to account for the same surface-meaning relation.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_1",
  "x": "While alternative proposals have succeeded in linking derivation trees to semantic representations using unification (Kallmeyer and Romero, 2004; Kallmeyer and Romero, 2007) or using an encoding (Pogodalla, 2004; Pogodalla, 2009) of TAG into the ACG framework (de Groote, 2001) , only recently<cite> (Kallmeyer and Kuhlmann, 2012)</cite> has proposed a transformation from standard derivation trees to dependency trees. This paper provides an ACG perspective on this transformation.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_2",
  "x": "The goal is twofold. First, it exhibits the underlying lexical blow up of the yield functions associated with the elementary trees in<cite> (Kallmeyer and Kuhlmann, 2012)</cite> . Second, using the same framework as (Pogodalla, 2004; Pogodalla, 2009 ) allows us to have a shared perspective on a phrase-structure architecture and a dependency one and an equivalence on the surface-meaning relation they define.",
  "y": "background motivation"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_3",
  "x": "3 The TAG literature typically uses this example, and<cite> (Kallmeyer and Kuhlmann, 2012)</cite> as well, to show the mismatch between the derivation trees and the expected se- This sentence is usually analyzed in TAG with a derivation tree where the to love component scopes over all the other arguments, and where claims and seems are unrelated, as Fig. 2(a) shows.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_4",
  "x": "bol and L yield (X 0 ) = X. Then, the derivation tree, the derived tree, and the yield of Fig. 2 are represented by: Trees<cite> (Kallmeyer and Kuhlmann, 2012)</cite> 's process to translate derivation trees into dependency trees is a two-step process. The first one does the actual transformation, using macro-tree transduction, while the second one modifies the way to get the yield from the dependency trees rather than from the derivation ones.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_5",
  "x": "This transformation aims at modeling the differences in scope of the argument between the derivation tree for (1) shown in Fig. 2 (a) and the corresponding dependency tree shown in Fig. 2 (b). For instance, in the derivation trees, claims and seems are under the scope of to love while in the dependency tree this order is reversed. According to<cite> (Kallmeyer and Kuhlmann, 2012)</cite> , such edge reversal is due to the fact that an edge between a complement taking adjunction (CTA) and an initial tree has to be reversed, while the other edges remain unchanged.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_6",
  "x": "Moreover, in case an initial tree accepts several adjunction of CTAs,<cite> (Kallmeyer and Kuhlmann, 2012)</cite> hypothesizes that the farther from the head a CTA is, the higher it is in the dependency tree.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_7",
  "x": "In order to do such reversing operations,<cite> (Kallmeyer and Kuhlmann, 2012)</cite> uses Macro Tree Transducers (MTTs) (Engelfriet and Vogler, 1985) . Note that the MTTs they use are linear, i.e. non-copying. It means that any node of an input tree cannot be translated more than once.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_8",
  "x": "The yield of the derived tree resulting from the operations of the derivation tree \u03b3 of Fig. 3 defined in<cite> (Kallmeyer and Kuhlmann, 2012)</cite> , w 2 where x, y denotes a tuple of strings.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_9",
  "x": "Were we not interested in the yields but only in the dependency structures, we wouldn't have to manage this ambiguity. This is true both for<cite> (Kallmeyer and Kuhlmann, 2012)</cite> 's approach and ours. But as we have here a unified framework for the two-step process they propose, this lexical blow up will result in a multiplicity of types as Section 5 shows.",
  "y": "motivation background similarities"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_10",
  "x": "In order to encode the MTT acting on derivation trees, we introduce a new abstract vocabulary \u03a3 der\u03b8 for disambiguated derivation trees as in (Yoshinaka, 2006 to love is used to model sentences where both adjunctions are performed into \u03b3 to love . C 10 to love and C 01 to love are used for sentences where only one adjunction at the s or at the vp node occurs respectively. C 00 to love : np np s is used when no adjunction occurs. 6 This really mimics (Yoshinaka, 2006) 's encoding of<cite> (Kallmeyer and Kuhlmann, 2012)</cite> MTT rules: . . . are designed in order to indicate that a given adjunction has n adjunctions above it (i.e. which scope over it).",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_11",
  "x": "In this paper, we have given an ACG perspective on the transformation of the derivation trees of TAG to the dependency trees proposed in<cite> (Kallmeyer and Kuhlmann, 2012)</cite> . Figure 4 illustrates the architecture we propose. This transformation is a two-step process using first a macrotree transduction then an interpretation of dependency trees as (tuples of) strings.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_12",
  "x": "The encoding of the second step then made explicit the lexical blow up for the interpretation of the functional symbols of the dependency trees in<cite> (Kallmeyer and Kuhlmann, 2012</cite> )'s construct. It also provides a push out (in the categorical sense) of the two morphisms from the disambiguated derivation trees to the derived trees and to the dependency trees. The diagram is completed with the yield function from the derived trees and from the dependency trees to the string vocabulary.",
  "y": "background"
 },
 {
  "id": "f1eae0918a246174b1866ba71d4efc_13",
  "x": "Finally, under the assumption of<cite> (Kallmeyer and Kuhlmann, 2012)</cite> of plausible dependency structures, we get two possible grammatical approaches to the surface-semantics relation that are related but independent: it can be equivalently modeled using either a phrase structure or a dependency model.",
  "y": "background"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_0",
  "x": "Restricting our attention to voicemail transcripts means that our focus and goals are similar to those of <cite>Huang et al. (2001)</cite> , but the features and techniques we use are very different.",
  "y": "similarities"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_1",
  "x": "<cite>Huang et al. (2001)</cite> discuss three approaches: hand-crafted rules; grammatical inference of subsequential transducers; and log-linear classifiers with bigram and trigram features used as taggers (Ratnaparkhi, 1996) .",
  "y": "background"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_2",
  "x": "We shall see that hand-crafted rules achieve very good recall, just as <cite>Huang et al. (2001)</cite> had observed, and the pruning phase successfully eliminates most undesirable candidates without affecting recall too much.",
  "y": "similarities"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_3",
  "x": "While this is less of a problem when evaluating on manual transcriptions, the experience reported in<cite> (Huang et al., 2001)</cite> suggests that the relatively high error rate of speech recognizers may negatively affect performance of caller name extraction on automatically generated transcripts.",
  "y": "background"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_4",
  "x": "Since a direct comparison to the log-linear named entity tagger described in<cite> (Huang et al., 2001</cite> ) (we refer to this approach as HZP log-linear below) is not possible due to the use of different corpora and annotation standards, we applied a similar named entity tagger based on a log-linear model with trigram features to our data (we refer to this approach as Col log-linear as the tagger was provided by Michael Collins).",
  "y": "uses"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_6",
  "x": "Like <cite>Huang et al. (2001)</cite> , we count a proposed caller phrase as correct if and only if it matches the annotation of the evaluation data perfectly.",
  "y": "similarities"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_7",
  "x": "While the results for the approach proposed here appear clearly worse than those reported by <cite>Huang et al. (2001)</cite> , we hasten to point out that this is most likely not due to any difference in the corpora that were used.",
  "y": "differences"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_8",
  "x": "This is corroborated by the fact that we were able to obtain performance much closer to that of the best, finely tuned log-linear model from<cite> (Huang et al., 2001</cite> ) by using a generic named entity tagger that was not adapted in any way to the particular task at hand.",
  "y": "similarities"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_10",
  "x": "The difference between the approach in<cite> (Huang et al., 2001</cite> ) and ours may be partly due to the performance of the ASR components: <cite>Huang et al. (2001)</cite> report a word error rate of 'about 35%', whereas we used a recognizer (Bacchiani, 2001 ) with a word error rate of only 23%.",
  "y": "differences"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_11",
  "x": "Rows HZP rules and HZP log-linear refer to the rule-based baseline and the best log-linear model of<cite> (Huang et al., 2001</cite> ) and the figures are simply taken from that paper; row Col log-linear refers to the same named entity tagger we used in the previous section and is included for comparison with the HZP models; row JA digits refers to the simple baseline where we extract strings of spoken digits of plausible lengths.",
  "y": "background"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_12",
  "x": "The results are summarized in Table 5 , which also repeats the best results from<cite> (Huang et al., 2001)</cite> , using the same terminology as earlier: rows HZP strict and HZP containment refer to the best model from<cite> (Huang et al., 2001</cite> ) -corresponding to row HZP log-linear in Table 4 -when evaluated using the strict criterion and containment, respectively; and row JA containment refers to our own best model -corresponding to row JA extract + classify in Ta It is not very plausible that the differences between the approaches in Table 5 would be due to a difference in the performance of the ASR components that generated the message transcripts.",
  "y": "uses"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_13",
  "x": "Also, for most phone numbers the labeling is uncontroversial, so we expect the corpora used by <cite>Huang et al. (2001)</cite> and ourselves to be extremely similar in terms of mark-up of phone numbers.",
  "y": "similarities"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_14",
  "x": "This places less of a burden on the grammar developers than having to write an accurate set of rules like the baseline of<cite> (Huang et al., 2001</cite> ).",
  "y": "uses"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_15",
  "x": "\u2022 The combined performance of our simple extraction grammar and the second-phase classifier exceeded the performance of all other methods, including the current state of the art<cite> (Huang et al., 2001</cite> ).",
  "y": "differences"
 },
 {
  "id": "f28720b1597ca1273303f3774167f8_16",
  "x": "Generic methods like the named entity tagger used by <cite>Huang et al. (2001)</cite> may not be the best tools for particular tasks; in fact, we do not expect the bigram and trigram features used by such taggers to be sufficient for accurately extracting phone numbers.",
  "y": "background"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_0",
  "x": "Discourse structure annotations have been demonstrated to be of high utility for a number of NLP applications, including automatic text summarization (Marcu, 1998; Marcu, 1999; Cristea et al., 2005) , sentence compression<cite> (Sporleder and Lapata, 2005)</cite> , natural language generation (Prasad et al., 2005) and question answering (Verberne et al., 2006) .",
  "y": "background"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_1",
  "x": "<cite>Sporleder and Lapata (2005)</cite> also used the RST Treebank as training data for data-driven discourse parsing algorithms, though their focus, in contrast to Soricut and Marcu (2003) , was to avoid contextfree parsing and rely exclusively on features in their model that could be derived via finite-state chunkers and taggers.",
  "y": "background"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_2",
  "x": "In this paper we take up the question posed by the results of <cite>Sporleder and Lapata (2005)</cite> : how much, if any, accuracy reduction should we expect if we choose to use only finite-state derived features, rather than those derived from full contextfree parses? If little accuracy is lost, as their results suggest, then it would make sense to avoid relatively expensive context-free parsing, particularly if the amount of text to be processed is large or if there are real-time processing constraints on the system.",
  "y": "motivation"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_3",
  "x": "While <cite>Sporleder and Lapata (2005)</cite> demonstrated that their finite-state system could perform as well as the SPADE system, which uses context-free parse trees, this does not directly answer the question of the utility of context-free derived features for this task.",
  "y": "background"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_4",
  "x": "<cite>Sporleder and Lapata (2005)</cite> went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i.e., sentences which themselves are atomic edus.",
  "y": "background"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_5",
  "x": "<cite>Sporleder and Lapata (2005)</cite> went further and established a smaller subset of 608 sentences, which omitted sentences with only one segment, i.e., sentences which themselves are atomic edus. Since the primary focus of this paper is on segmentation, there is no strong reason to omit any sentences from the test set, hence our results will evaluate on all 991 test sentences, with two exceptions.",
  "y": "differences"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_6",
  "x": "First, in Section 2.3, we compare SPADE results under our configuration with results from <cite>Sporleder and Lapata (2005)</cite> in order to establish comparability, and this is done on their 608 sentence subset.",
  "y": "uses"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_7",
  "x": "In <cite>Sporleder and Lapata (2005)</cite> , they were primarily interested in labeled segmentation, where the segment initial boundary was labeled with the segment type.",
  "y": "background"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_8",
  "x": "Thus, in section 2.3, for comparison with reported results in <cite>Sporleder and Lapata (2005)</cite> , our F1-score is defined accordingly, i.e., seg- mentation boundaries j such that 0 \u2264 j < k. In addition, we will report unlabeled bracketing precision, recall and F1-score, as defined in the PARSEVAL metrics (Black et al., 1991) and evaluated via the widely used evalb package.",
  "y": "uses"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_9",
  "x": "Table 1 compares segmentation results of three systems on the <cite>Sporleder and Lapata (2005)</cite> 608 sentence subset of the evaluation data: (1) their best reported system; (2) the SPADE system results reported in that paper; and (3) the SPADE system results with our current configuration.",
  "y": "uses"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_10",
  "x": "This feature set is very close to that used in <cite>Sporleder and Lapata (2005)</cite> , but not identical.",
  "y": "similarities"
 },
 {
  "id": "f4792ef9808a1a3c415f6f57351335_11",
  "x": "This label set has been shown to be of particular utility for indicating which segments are more important to include in an automatically created summary or compressed sentence<cite> (Sporleder and Lapata, 2005</cite>; Marcu, 1998; Marcu, 1999; Cristea et al., 2005) .",
  "y": "background"
 },
 {
  "id": "f54235664f013f0fec918222be9198_0",
  "x": "While Klein and Manning's approach may be described as an \"all-substrings\" approach to unsupervised parsing, an even richer model consists of an \"all-subtrees\" approach to unsupervised parsing, called U-DOP <cite>(Bod 2006)</cite> .",
  "y": "background"
 },
 {
  "id": "f54235664f013f0fec918222be9198_1",
  "x": "While we do not achieve as high an f-score as the UML-DOP model in<cite> Bod (2006)</cite> , we will show that U-DOP* can operate without subtree sampling, and that the model can be trained on corpora that are two orders of magnitude larger than in<cite> Bod (2006)</cite> .",
  "y": "uses differences"
 },
 {
  "id": "f54235664f013f0fec918222be9198_2",
  "x": "We will use the same allsubtrees methodology as in<cite> Bod (2006)</cite> , but now by applying the efficient and consistent DOP*-based estimator.",
  "y": "extends"
 },
 {
  "id": "f54235664f013f0fec918222be9198_3",
  "x": "Moreover, DOP*'s estimation procedure is very efficient, while the EM training procedure for UML-DOP proposed in<cite> Bod (2006)</cite> is particularly time consuming and can only operate by randomly sampling trees.",
  "y": "background"
 },
 {
  "id": "f54235664f013f0fec918222be9198_4",
  "x": "The total number of nodes is cubic in sentence length n. This means that there are O(n 3 ) many nodes that receive a unique address as described above, to which next our PCFG reduction is applied. This is a huge reduction compared to<cite> Bod (2006)</cite> where the number of subtrees of all trees increases with the Catalan number, and only ad hoc sampling could make the method work.",
  "y": "differences"
 },
 {
  "id": "f54235664f013f0fec918222be9198_5",
  "x": "Note that the direct conversion of parse forests into a PCFG reduction also allows us to efficiently implement the maximum likelihood extension of U-DOP known as UML-DOP <cite>(Bod 2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "f54235664f013f0fec918222be9198_6",
  "x": "To evaluate U-DOP* against UML-DOP and other unsupervised parsing models, we started out with three corpora that are also used in Manning (2002, 2004) and<cite> Bod (2006)</cite> : Penn's WSJ10 which contains 7422 sentences \u2264 10 words after removing empty elements and punctuation, the German NEGRA10 corpus and the Chinese Treebank CTB10 both containing 2200+ sentences \u2264 10 words after removing punctuation.",
  "y": "uses"
 },
 {
  "id": "f54235664f013f0fec918222be9198_7",
  "x": "All trees in the test set were binarized beforehand, in the same way as in<cite> Bod (2006)</cite> .",
  "y": "uses"
 },
 {
  "id": "f54235664f013f0fec918222be9198_8",
  "x": "Table 1 shows the f-scores for U-DOP* and UML-DOP against the f-scores for U-DOP reported in<cite> Bod (2006)</cite> , the CCM model in Klein and Manning (2002) , the DMV dependency model in Klein and Manning (2004) It should be kept in mind that an exact comparison can only be made between U-DOP* and UML-DOP in table 1, since these two models were tested on 90%/10% splits, while the other models were applied to the full WSJ10, NEGRA10 and CTB10 corpora.",
  "y": "uses"
 },
 {
  "id": "f54235664f013f0fec918222be9198_9",
  "x": "While a similar result was obtained in<cite> Bod (2006)</cite> , the absolute difference between unsupervised parsing and the treebank grammar was extremely small in<cite> Bod (2006)</cite>: 1.8%, while the difference in table 5 is 7.2%, corresponding to 19.7% error reduction.",
  "y": "differences"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_0",
  "x": "Recently, <cite>Yang et al. (2019)</cite> showed that combining a BERT-based reader with passage retrieval using the Anserini IR toolkit yields a large improvement in question answering directly from a Wikipedia corpus, measured in terms of exact match on a standard benchmark (Chen et al., 2017) .",
  "y": "background"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_1",
  "x": "Interestingly, the approach of <cite>Yang et al. (2019)</cite> represents a simple method to combining BERT with off-the-shelf IR.",
  "y": "background"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_2",
  "x": "Recently, <cite>Yang et al. (2019)</cite> showed that combining a BERT-based reader with passage retrieval using the Anserini IR toolkit yields a large improvement in question answering directly from a Wikipedia corpus, measured in terms of exact match on a standard benchmark (Chen et al., 2017) . Interestingly, the approach of <cite>Yang et al. (2019)</cite> represents a simple method to combining BERT with off-the-shelf IR. In this paper, we build on these initial successes to explore how much further we can push this simple architecture by data augmentation, taking advantage of distant supervision techniques to gather more and higher-quality * equal contribution training data to fine tune BERT.",
  "y": "extends"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_3",
  "x": "Experiments show that, using the same reader model as <cite>Yang et al. (2019)</cite> , our simple data-augmentation techniques yield additional large improvements.",
  "y": "uses differences"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_4",
  "x": "We use the same exact setup as the \"paragraph\" variant of BERTserini<cite> (Yang et al., 2019)</cite> , where the input corpus is pre-segmented into paragraphs at index time, each of which is treated as a \"document\" for retrieval purposes.",
  "y": "uses"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_5",
  "x": "One major shortcoming with BERTserini is that <cite>Yang et al. (2019)</cite> only fine tune on SQuAD, which means that the BERT reader is exposed to an impoverished set of examples; all SQuAD data come from a total of only 442 documents.",
  "y": "differences"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_6",
  "x": "Following <cite>Yang et al. (2019)</cite> , to evaluate answers in an end-to-end setup, we disregard the paragraph context from the original datasets and use only the answer spans.",
  "y": "uses"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_7",
  "x": "In addition, we compute recall (R), the fraction of questions for which the correct answer appears in any retrieved paragraph; to make our results comparable to <cite>Yang et al. (2019)</cite> , Anserini returns the top k = 100 paragraphs to feed into the BERT reader.",
  "y": "similarities"
 },
 {
  "id": "f633ceffdf53849159574a2891eda1_8",
  "x": "The row marked \"SRC\" indicates fine tuning with SQuAD data only and matches the BERTserini condition of <cite>Yang et al. (2019)</cite> ; we report higher scores due to engineering improvements (primarily a Lucene version upgrade).",
  "y": "differences"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_0",
  "x": "Despite its outward simplicity, co-occurrence networks have proven useful in many applications, such as in authorship recognition <cite>[9]</cite> , extractive summarization [10, 11, 12] , stylistic identification [13] and part-of-speech tagging [14] .",
  "y": "background"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_1",
  "x": "Therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. Most importantly, it is clear from some recent studies [8, <cite>9</cite> ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "motivation background future_work"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_2",
  "x": "Despite its outward simplicity, co-occurrence networks have proven useful in many applications, such as in authorship recognition <cite>[9]</cite> , extractive summarization [10, 11, 12] , stylistic identification [13] and part-of-speech tagging [14] . Unfortunately, a major problem arising from the analyses performed with co-occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success of the model. Therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. Most importantly, it is clear from some recent studies [8, <cite>9</cite> ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "motivation"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_3",
  "x": "Unfortunately, a major problem arising from the analyses performed with co-occurrence networks is the difficulty to provide a rigorous interpretation of the factors accounting for the success of the model. Therefore, future investigations should pursue a better interpretation at the network level aiming at the understanding of the fundamental properties of the language. Most importantly, it is clear from some recent studies [8, <cite>9</cite> ] that novel topological measurements should be introduced to capture a wider range of linguistic features.",
  "y": "motivation future_work"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_4",
  "x": "Examples of combinations of distinct strategies are described in <cite>[9]</cite> , [19] and [20].",
  "y": "background"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_5",
  "x": "In (ii), I suggest, for example, the introduction of a hybrid classifier that could consider both linguistic (deeper linguistic processing [18] ) and topological attributes at the same time in a hybrid way. Examples of combinations of distinct strategies are described in <cite>[9]</cite> , [19] and [20].",
  "y": "uses"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_6",
  "x": "Examples of combinations of distinct strategies are described in <cite>[9]</cite> , [19] and [20] .",
  "y": "background"
 },
 {
  "id": "f78b11352d01b6567392f8cb3c7642_7",
  "x": "In (ii), I suggest, for example, the introduction of a hybrid classifier that could consider both linguistic (deeper linguistic processing [18] ) and topological attributes at the same time in a hybrid way. Examples of combinations of distinct strategies are described in <cite>[9]</cite> , [19] and [20] .",
  "y": "uses"
 },
 {
  "id": "f856c4fb5e6e00729d33b15b24aff6_0",
  "x": "My own slow progress <cite>(Cassell et al., 2000</cite>; Koller and Stone, 2007) shows that there's still lots of hard work needed to develop suitable techniques.",
  "y": "motivation future_work"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_0",
  "x": "In that time, researchers have explored architectures ranging from convolutional neural networks (Kalchbrenner and Blunsom, 2013) to recurrent neural networks (Chung et al., 2014) to attentional models (Bahdanau et al., 2015;<cite> Luong et al., 2015)</cite> and achieved better performance than traditional statistical or syntax-based MT techniques on many language pairs.",
  "y": "background"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_1",
  "x": "NMT models first achieved state-of-the-art performance on the WMT English\u2192German news-domain task in 2015<cite> (Luong et al., 2015)</cite> and subsequent improvements have been reported since then (Sennrich et al., 2015a; Li and Jurafsky, 2016) .",
  "y": "background"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_2",
  "x": "Recently, a third component has been added to many of these models: an attention mechanism, whereby the decoder can attend directly to localized information from the input sentence during the output generation process (Bahdanau et al., 2015;<cite> Luong et al., 2015)</cite> .",
  "y": "background"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_3",
  "x": "The attention mechanism in our four-layer model is what <cite>Luong (2015)</cite> describes as \"Global attention (dot)\"; the mechanism in our five-layer Y-LSTM model is described in Section 2.1.",
  "y": "similarities uses"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_4",
  "x": "Models may use computed alignments between source and target sentences to directly copy or transform a word from the input sentence whose corresponding translation is not present in the vocabulary<cite> (Luong et al., 2015)</cite> or they may conduct sentence tokenization at the level of individual characters (Ling et al., 2015) or subword units such as morphemes (Sennrich et al., 2015b) .",
  "y": "background"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_5",
  "x": "The model identified as metamind-single is based on the attention-based encoder-decoder framework described in <cite>Luong (2015)</cite> , using the attention mechanism referred to as \"Global attention (dot).",
  "y": "similarities uses"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_6",
  "x": "The beam search decoder differs slightly from <cite>Luong (2015)</cite> in that we normalize output sentence probabilities by length, following , rather than performing ad-hoc adjustments to correct for short output sentences.",
  "y": "differences"
 },
 {
  "id": "fa33495582abd0c6efe8f599c73d0e_7",
  "x": "The Y-LSTM model underperformed relative to the model based on <cite>Luong (2015)</cite> , but provided a small additional boost to the ensemble.",
  "y": "differences"
 },
 {
  "id": "fca14f99953b9dc30a594525ee92b5_0",
  "x": "In this paper, we first present a short review and comparison of two representative efforts on this topic [<cite>6</cite>, 7] , where both efforts involve using an auto-encoder and can be applied to the same task (i.e., voice conversion), but the key disentangling algorithms and underlying ideas are very different.",
  "y": "uses background"
 },
 {
  "id": "fca14f99953b9dc30a594525ee92b5_1",
  "x": "In [<cite>6</cite>] , the authors proposed an unsupervised <cite>factorized hierarchical variational autoencoder (FHVAE)</cite>.",
  "y": "background"
 },
 {
  "id": "fca14f99953b9dc30a594525ee92b5_2",
  "x": "In [<cite>6</cite>] and subsequent efforts [8, 9, 10] , the authors further showed that the disentangled representation is also helpful in the speech recognition task.",
  "y": "background"
 },
 {
  "id": "fca14f99953b9dc30a594525ee92b5_3",
  "x": "Different from [<cite>6</cite>] , in [7] , the authors propose a supervised approach based on adversarial training [11, 12, 13, 14] (illustrated in Figure 2 (left)).",
  "y": "differences"
 },
 {
  "id": "fca14f99953b9dc30a594525ee92b5_4",
  "x": "That is, in [<cite>6</cite>] , z1 and z2 are in fact corresponding to general fast-changing and slow-changing information, i.e., z1 may contain other fast-changing information such as emotion, while z2 may contain slow-changing factors such as background and channel noise.",
  "y": "background"
 },
 {
  "id": "fca14f99953b9dc30a594525ee92b5_5",
  "x": "In contrast, a coarse-grained disentangled representation [<cite>6</cite>, 7] may only support a simple voice speaker conversion task.",
  "y": "differences"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_0",
  "x": "For example, most work observes that stochastic gradient descent (SGD) gives best performance on NER task (<cite>Chiu and Nichols, 2016;</cite> Lample et al., 2016; Ma and Hovy, 2016) , while Reimers and Gurevych (2017b) report that SGD is the worst optimizer on the same datasets.",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_1",
  "x": "Ling et al. (2015) give results only on POS dataset, while some papers (<cite>Chiu and Nichols, 2016</cite>; Lample et al., 2016; Strubell et al., 2017) report results on the NER dataset only.",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_2",
  "x": "Most work uses the development set to select hyperparameters (Lample et al., 2016; Ma and Hovy, 2016) , while others add development set into training set (<cite>Chiu and Nichols, 2016</cite>; Peters et al., 2017) .",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_3",
  "x": "A typical data preprocessing step is to normize digit characters (<cite>Chiu and Nichols, 2016;</cite> Lample et al., 2016; Yang et al., 2016; Strubell et al., 2017) .",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_4",
  "x": "Strubell et al. (2017) and <cite>Chiu and Nichols (2016)</cite> apply word spelling features and further integrate context features.",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_5",
  "x": "<cite>Chiu and Nichols (2016)</cite> search for the hyperparameters for each task and show that the system performance is sensitive to the choice of hyperparameters.",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_6",
  "x": "Some literature reports results using mean and standard deviation under different random seeds (<cite>Chiu and Nichols, 2016</cite>; Peters et al., 2017; Liu et al., 2018) .",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_7",
  "x": "built a BiLSTM-CRF structure, which has been extended by adding character-level LSTM (Lample et al., 2016; Liu et al., 2018) , GRU (Yang et al., 2016) , and CNN (<cite>Chiu and Nichols, 2016</cite>; Ma and Hovy, 2016) features.",
  "y": "extends"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_8",
  "x": "built a BiLSTM-CRF structure, which has been extended by adding character-level LSTM (Lample et al., 2016; Liu et al., 2018) , GRU (Yang et al., 2016) , and CNN (<cite>Chiu and Nichols, 2016</cite>; Ma and Hovy, 2016) features. <cite>These models</cite> achieve state-of-the-art results in the literature.",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_9",
  "x": "3) Our findings are more consistent with <cite>most previous work</cite> on configurations such as usefulness of character information (Lample et al., 2016; Ma and Hovy, 2016) , optimizer (<cite>Chiu and Nichols, 2016</cite>; Lample et al., 2016; Ma and Hovy, 2016) and tag scheme (Ratinov and Roth, 2009; Dai et al., 2015) .",
  "y": "similarities"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_10",
  "x": "Character information has been proven to be critical for sequence labeling tasks (<cite>Chiu and Nichols, 2016</cite>; Lample et al., 2016; Ma and Hovy, 2016) , with LSTM and CNN being used to model character sequence information (\"Char Rep.\").",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_11",
  "x": "Using a CNN structure to encode character sequences was firstly proposed by Santos and Zadrozny (2014), and followed by many subsequent investigations (dos Santos et al., 2015; <cite>Chiu and Nichols, 2016</cite>; Ma and Hovy, 2016) .",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_12",
  "x": "LSTM has been widely used in sequence labeling (Lample et al., 2016; Ma and Hovy, 2016; <cite>Chiu and Nichols, 2016;</cite> Liu et al., 2018) .",
  "y": "background"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_13",
  "x": "We re-implement the structure of several reports (<cite>Chiu and Nichols, 2016</cite>; Ma and Hovy, 2016; Peters et al., 2017) , which take the CCNN+WLSTM+CRF architecture.",
  "y": "uses"
 },
 {
  "id": "fd5a6307b398f37d8729c21cfce6c1_14",
  "x": "Our observation is consistent with most literature (<cite>Chiu and Nichols, 2016</cite>; Lample et al., 2016; Ma and Hovy, 2016) .",
  "y": "similarities"
 },
 {
  "id": "fd9122d20c390ea115c27092170739_0",
  "x": "The few existing studies all attempted to develop a unified statistical model to compute the probability of a word having a particular POS category for all Chinese unknown words (Chen et al., 1997; <cite>Wu and Jiang, 2000</cite>; Goh, 2003) .",
  "y": "background"
 },
 {
  "id": "fd9122d20c390ea115c27092170739_1",
  "x": "The rule-based approach was rejected with the claim that rules are bound to overgenerate<cite> (Wu and Jiang, 2000)</cite> .",
  "y": "background"
 },
 {
  "id": "fd9122d20c390ea115c27092170739_2",
  "x": "The few existing studies all attempted to develop a unified statistical model to compute the probability of a word having a particular POS category for all Chinese unknown words (Chen et al., 1997; <cite>Wu and Jiang, 2000</cite>; Goh, 2003) . This approach tends to miss one or more pieces of information contributed by the type, length, internal structure, or context of individual unknown words, and fails to combine the strengths of different models.",
  "y": "motivation background"
 },
 {
  "id": "fd9122d20c390ea115c27092170739_3",
  "x": "Second,<cite> Wu and Jiang (2000)</cite> argued that assigning POS to Chinese unknown words on the basis of the internal structure of those words will \"result in massive overgeneration\" (p. 48).",
  "y": "background"
 },
 {
  "id": "fd9122d20c390ea115c27092170739_4",
  "x": "Second,<cite> Wu and Jiang (2000)</cite> argued that assigning POS to Chinese unknown words on the basis of the internal structure of those words will \"result in massive overgeneration\" (p. 48). We will show that overgeneration can be controlled by additional constraints.",
  "y": "differences background"
 },
 {
  "id": "fd9122d20c390ea115c27092170739_5",
  "x": "The models we will consider are a rule-based model, the trigram model, and the statistical model developed by<cite> Wu and Jiang (2000)</cite> .",
  "y": "uses"
 },
 {
  "id": "fddb1d19895976661babdc17d232ee_0",
  "x": "To that end, we propose to use an attention-based model and gradient-weighted class activation maps [9] , inspired by the recent successes of the attention mechanism in other domains [15, <cite>16]</cite> .",
  "y": "uses"
 },
 {
  "id": "fddb1d19895976661babdc17d232ee_1",
  "x": "Weights \u03b1 i are computed with attention mechanism implemented as a two-layer neural network<cite> [16]</cite> : the first layer produces a hidden representation u i = tanh(W u q i + b u ) and the second layer outputs unnormalized importance a i = W a u i + b a .",
  "y": "uses"
 },
 {
  "id": "fddb1d19895976661babdc17d232ee_2",
  "x": "For visualizations in the text domain, we use attention weights \u03b2 t used to compute text representation d. These weights capture relative importance of words in their context to headline popularity, as shown in<cite> [16]</cite> in the context of sentiment analysis.",
  "y": "uses background"
 },
 {
  "id": "fe1d6ca4a88c03cfb2ae94ef45030d_0",
  "x": "There has also been growing interest in deep learning models for keyphrase generation <cite>(Meng et al. 2017</cite>; Chan et al. 2019) .",
  "y": "motivation"
 },
 {
  "id": "fe1d6ca4a88c03cfb2ae94ef45030d_1",
  "x": "As with most GAN architectures, our model also consists of a generator (G) and discriminator (D), which are trained in an alternating fashion<cite> (Goodfellow et al. 2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "fe1d6ca4a88c03cfb2ae94ef45030d_2",
  "x": "We employ catSeq model<cite> (Yuan et al. 2018)</cite> for the generation process, which uses an encoder-decoder framework: the encoder being a bidirectional Gated Recurrent Unit (bi-GRU) and the decoder a forward GRU.",
  "y": "uses"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_0",
  "x": "More recently, <cite>Wiegand and Klakow (2010)</cite> explored convolution kernels for OH extraction and found that tree kernels outperform all other kernel types.",
  "y": "background"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_1",
  "x": "2 We use the definition of OHs as described in<cite> (Wiegand and Klakow, 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_2",
  "x": "With this definition we train a supervised classifier based on convolution kernels (Collins and Duffy, 2001 ) as this method has been shown to be quite effective for OH extraction<cite> (Wiegand and Klakow, 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_3",
  "x": "In addition to <cite>Wiegand and Klakow (2010)</cite> , we have to discard the content of candidate NPs (e.g. the candidate opinion holder NP [N P Cand [N N S advocates] ] is reduced to [N P Cand ]), the reason for this being that in our automatically generated training set, OHs will always be protoOHs.",
  "y": "extends"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_4",
  "x": "We also augment the tree kernels themselves with additional information by 3 wordnet.princeton.edu following <cite>Wiegand and Klakow (2010)</cite> who add for each word that belongs to a predictive semantic class another node that directly dominates the pertaining leaf node and assign it a label denoting that class.",
  "y": "uses"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_5",
  "x": "While <cite>Wiegand and Klakow (2010)</cite> made use of manually built lexicons, we use our predictive predicates extracted from contexts of protoOHs.",
  "y": "differences"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_6",
  "x": "Both resources have been found predictive for OH extraction (Bloom et al., 2007;<cite> Wiegand and Klakow, 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_7",
  "x": "These are commonly accepted heuristics which have already been used in previous work as features (Choi et al., 2005;<cite> Wiegand and Klakow, 2010)</cite> .",
  "y": "background"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_8",
  "x": "The table also compares two different versions of the rule-based classifier being the classifier as presented in \u00a74.2 (left half of Table 3 ) and a classifier additionally incorporating the two heuristics (right half): \u2022 If the candidate NP follows according to, then it is labeled as an OH. \u2022 The candidate NP can only be an OH if it represents a person or a group of persons. These are commonly accepted heuristics which have already been used in previous work as features (Choi et al., 2005;<cite> Wiegand and Klakow, 2010)</cite> .",
  "y": "uses"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_9",
  "x": "As a maximum amount of labeled training data we chose 60000 instances (i.e. NPs) which is even a bit more than used in<cite> (Wiegand and Klakow, 2010)</cite> .",
  "y": "differences"
 },
 {
  "id": "fed51218e78d35aae39d287c95a95a_10",
  "x": "This observation is consistent with<cite> (Wiegand and Klakow, 2010)</cite> where, however, AL and SL are considered for augmentation.",
  "y": "similarities"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_0",
  "x": "<cite>Ziering and Van der Plas (2014)</cite> propose an approach that refrains from using any human annotation.",
  "y": "background"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_1",
  "x": "<cite>Ziering and Van der Plas (2014)</cite> propose an approach that refrains from using any human annotation. They use the fact, that languages differ in their preference for open or closed compounding (i.e., multiword vs. one-word compounds), for inducing the English bracketing of 3NCs. Although this approach achieves a solid accuracy, a crucial limitation is coverage, because restricting to six paraphrasing patterns ignores many other predictive cases. Moreover, the system needs part of speech (PoS) tags and splitting information for determining 2NCs and is therefore rather language-dependent.",
  "y": "motivation"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_2",
  "x": "Using less restricted forms of cross-lingual supervision, we achieve a much higher coverage than <cite>Ziering and Van der Plas (2014)</cite> .",
  "y": "differences"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_3",
  "x": "While AWDB is designed for bracketing NPs of any length, we first experiment with bracketing 3NCs, the largest class of 3 + NCs (93.8% on the basic dataset of <cite>Ziering and Van der Plas (2014)</cite>), for which bracketing is a binary classification (i.e., LEFT or RIGHT).",
  "y": "background"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_4",
  "x": "Although AWDB can also process compounds including adjectives (e.g., active inclusion policy aligned to the Dutch beleid voor actieve insluiting (policy for active inclusion)), for a direct comparison with the system of <cite>Ziering and Van der Plas (2014)</cite> , that analyses 3NCs, we restrict ourselves to noun sequences.",
  "y": "uses"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_5",
  "x": "We use the Europarl 2 compound database 3 developed by <cite>Ziering and Van der Plas (2014)</cite> .",
  "y": "uses"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_6",
  "x": "We compare AWDB with the bracketing approach of <cite>Ziering and Van der Plas (2014)</cite>.",
  "y": "uses"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_7",
  "x": "We created a back-off model for the bracketing system of <cite>Ziering and Van der Plas (2014)</cite> and for AWDB that falls back to using \u03c7 2 if no bracketing structure can be derived (system \u2192 \u03c7 2 ).",
  "y": "uses"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_8",
  "x": "The test set used by <cite>Ziering and Van der Plas (2014)</cite> is very small and the labeling is less fine-grained. Thus, we decided to create our own test set.",
  "y": "motivation"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_9",
  "x": "Our first result is that type-based cross-lingual bracketing outperforms token-based and achieves up to 91.2% in coverage. As expected, the system of <cite>Ziering and Van der Plas (2014)</cite> does not cover more than 48.1%.",
  "y": "differences"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_10",
  "x": "AWDB outperforms <cite>Ziering and Van der Plas (2014)</cite> significantly 7 .",
  "y": "differences"
 },
 {
  "id": "ff5122ce817d506fbcb269b7ae41fe_11",
  "x": "The harmonic mean numbers for the system of <cite>Ziering and Van der Plas (2014)</cite> illustrate that coverage gain of types outweighs a higher accuracy of tokens.",
  "y": "background"
 },
 {
  "id": "ff73758fbef3ddc779a772e634b74e_0",
  "x": "In previous work, explanations have been categorised as either explaining 1) machine learning as in [11] who showed that they can increase trust; 2) explaining plans [2, 13] ; 3) verbalising robot [12] or agent rationalisation <cite>[3]</cite> .",
  "y": "background"
 },
 {
  "id": "ff73758fbef3ddc779a772e634b74e_1",
  "x": "Similar human-provided rationalisation has been used to generate explanations of deep neural models for game play <cite>[3]</cite> .",
  "y": "background"
 },
 {
  "id": "ffcefdc73338187d4a6b2dc2f0bb47_0",
  "x": "Recent work on deep learning syntactic parsing models has achieved notably good results, e.g.,<cite> Dyer et al. (2016)</cite> with 92.4 F 1 on Penn Treebank constituency parsing and Vinyals et al. (2015) with 92.8 F 1 .",
  "y": "background"
 },
 {
  "id": "ffcefdc73338187d4a6b2dc2f0bb47_1",
  "x": "The first (Zaremba et al., 2014) gives the basic language modeling architecture that we have adopted, while the other two (Vinyals et al., 2015; <cite>Dyer et al., 2016)</cite> are parsing models that have the current best results in NN parsing.",
  "y": "background"
 },
 {
  "id": "ffcefdc73338187d4a6b2dc2f0bb47_2",
  "x": "Recurrent Neural Network Grammars (RNNG), a generative parsing model, defines a joint distribution over a tree in terms of actions the model takes to generate the tree<cite> (Dyer et al., 2016)</cite> :",
  "y": "background"
 },
 {
  "id": "ffcefdc73338187d4a6b2dc2f0bb47_3",
  "x": "Given x, we produce Y (x), 50-best trees, with Charniak parser and find y with LSTM-LM as<cite> Dyer et al. (2016)</cite> do with their discriminative and generative models.",
  "y": "similarities"
 },
 {
  "id": "ffcefdc73338187d4a6b2dc2f0bb47_5",
  "x": "As shown in Table 2 , with 92.6 F 1 LSTM-LM (G) outperforms an ensemble of five MTPs (Vinyals et al., 2015) and RNNG<cite> (Dyer et al., 2016)</cite> , both of which are trained on the WSJ only.",
  "y": "background"
 },
 {
  "id": "ffcefdc73338187d4a6b2dc2f0bb47_6",
  "x": "In fact, we see that a generative parsing model, LSTM-LM, is more effective than discriminative parsing models<cite> (Dyer et al., 2016)</cite> .",
  "y": "differences"
 }
]