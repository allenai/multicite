[
 {
  "id": "008d5261ee7385a2b7e39772938f51_0",
  "x": [
   "To compare our work with <cite>Athar (2011)</cite> , we also applied a three-class annotation scheme."
  ],
  "y": "uses"
 },
 {
  "id": "008d5261ee7385a2b7e39772938f51_1",
  "x": [
   "This setup has been shown to produce good results earlier as well (Pang et al., 2002; <cite>Athar, 2011</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "008d5261ee7385a2b7e39772938f51_2",
  "x": [
   "The baseline score, shown in bold, is obtained with no context window and is comparable to the results reported by <cite>Athar (2011)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "008d5261ee7385a2b7e39772938f51_3",
  "x": [
   "Although these results are not better than the context-less baseline, the reason might be data sparsity since existing work on citation sentiment analysis uses more data <cite>(Athar, 2011)</cite> ."
  ],
  "y": "extends background"
 },
 {
  "id": "008d5261ee7385a2b7e39772938f51_4",
  "x": [
   "While different schemes have been proposed for annotating citations according to their function (Spiegel-Rosing, 1977; Nanba and Okumura, 1999; Garzone and Mercer, 2000) , the only recent work on citation sentiment detection using a relatively large corpus is by <cite>Athar (2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "008d5261ee7385a2b7e39772938f51_5",
  "x": [
   "While different schemes have been proposed for annotating citations according to their function (Spiegel-Rosing, 1977; Nanba and Okumura, 1999; Garzone and Mercer, 2000) , the only recent work on citation sentiment detection using a relatively large corpus is by <cite>Athar (2011)</cite> .",
   "However, <cite>this work</cite> does not handle citation context."
  ],
  "y": "background"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_0",
  "x": [
   "Our proposed method raises the expressive power of a language model based on the matrix factorization interpretation of language modeling introduced by <cite>Yang et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_1",
  "x": [
   "However, <cite>Yang et al. (2018)</cite> proved that existing RNN language models have low expressive power due to the Softmax bottleneck, which means the output matrix of RNN language models is low rank when we interpret the training of RNN language models as a matrix factorization problem."
  ],
  "y": "motivation"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_2",
  "x": [
   "However, <cite>Yang et al. (2018)</cite> proved that existing RNN language models have low expressive power due to the Softmax bottleneck, which means the output matrix of RNN language models is low rank when we interpret the training of RNN language models as a matrix factorization problem.",
   "To solve the Softmax bottleneck, <cite>Yang et al. (2018)</cite> proposed Mixture of Softmaxes (MoS), which increases the rank of the matrix by combining multiple probability distributions computed from the encoded fixed-length vector."
  ],
  "y": "background"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_3",
  "x": [
   "To solve the Softmax bottleneck, <cite>Yang et al. (2018)</cite> proposed Mixture of Softmaxes (MoS), which increases the rank of the matrix by combining multiple probability distributions computed from the encoded fixed-length vector."
  ],
  "y": "background"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_4",
  "x": [
   "To solve the Softmax bottleneck, <cite>Yang et al. (2018)</cite> proposed Mixture of Softmaxes (MoS), which increases the rank of the matrix by combining multiple probability distributions computed from the encoded fixed-length vector."
  ],
  "y": "extends"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_5",
  "x": [
   "3 Language Modeling as Matrix Factorization <cite>Yang et al. (2018)</cite> indicated that the training of language models can be interpreted as a matrix 2 Actually, we apply a bias term in addition to the weight matrix but we omit it to simplify the following discussion."
  ],
  "y": "extends"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_6",
  "x": [
   "<cite>Yang et al. (2018)</cite> also argued that rank(A ) is as high as vocabulary size V based on the following two assumptions:",
   "In summary, <cite>Yang et al. (2018)</cite> indicated that D h N is much smaller than rank(A) because its scale is usually 10 2 and vocabulary size V is at least 10 4 ."
  ],
  "y": "background"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_7",
  "x": [
   "To construct a high-rank matrix, <cite>Yang et al. (2018)</cite> proposed Mixture of Softmaxes (MoS)."
  ],
  "y": "background"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_8",
  "x": [
   "To construct a high-rank matrix, <cite>Yang et al. (2018)</cite> proposed Mixture of Softmaxes (MoS)."
  ],
  "y": "extends"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_9",
  "x": [
   "The top row ( \u2020) represents MoS scores reported in <cite>Yang et al. (2018)</cite> as a baseline."
  ],
  "y": "uses"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_10",
  "x": [
   "The top row ( \u2020) represents MoS scores reported in <cite>Yang et al. (2018)</cite> as a baseline.",
   "\u2021 represents the perplexity obtained by the implementation of <cite>Yang et al. (2018)</cite> 6 with identical hyperparameters except for i 3 ."
  ],
  "y": "uses"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_11",
  "x": [
   "Moreover, the top row of Table 3 shows the perplexity of AWD-LSTM with MoS reported in <cite>Yang et al. (2018)</cite> for comparison."
  ],
  "y": "uses"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_12",
  "x": [
   "In contrast, AWD-LSTM-MoS<cite> (Yang et al., 2018)</cite> and AWD-LSTM-DOC outputted matrices whose ranks equal the vocabulary size."
  ],
  "y": "similarities"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_13",
  "x": [
   "We compare AWD-LSTM-DOC with AWD-LSTM (Merity et al., 2018) and AWD-LSTMMoS<cite> (Yang et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_14",
  "x": [
   "As described in Section 3, <cite>Yang et al. (2018)</cite> interpreted training language modeling as matrix factorization and improved performance by computing multiple probability distributions."
  ],
  "y": "background"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_15",
  "x": [
   "As described in Section 3, <cite>Yang et al. (2018)</cite> interpreted training language modeling as matrix factorization and improved performance by computing multiple probability distributions."
  ],
  "y": "extends"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_16",
  "x": [
   "We proposed Direct Output Connection (DOC), a generalization method of MoS introduced by <cite>Yang et al. (2018)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "00a2e4d0cacfb1fb7098bd324d960a_17",
  "x": [
   "We proposed Direct Output Connection (DOC), a generalization method of MoS introduced by <cite>Yang et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_0",
  "x": [
   "Recent work has moved away from the original \"one word, one embedding\" paradigm to investigate contextualized embedding models (Peters et al., 2017 (Peters et al., , 2018<cite> Akbik et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_1",
  "x": [
   "Recently, <cite>Akbik et al. (2018)</cite> proposed a character-level contextualized embeddings ap- context."
  ],
  "y": "background"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_2",
  "x": [
   "Recently, <cite>Akbik et al. (2018)</cite> proposed a character-level contextualized embeddings ap- context."
  ],
  "y": "motivation"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_3",
  "x": [
   "It requires an embed() function that produces a contextualized embedding for a given word in a sentence context (see <cite>Akbik et al. (2018)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_4",
  "x": [
   "It requires an embed() function that produces a contextualized embedding for a given word in a 1 https://github.com/zalandoresearch/flair sentence context (see <cite>Akbik et al. (2018)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_5",
  "x": [
   "For our experiments, we follow the training and evaluation procedure outlined in <cite>Akbik et al. (2018)</cite> and follow most hyperparameter suggestions as given by the in-depth study presented in Reimers and Gurevych (2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_6",
  "x": [
   "The default setup of <cite>Akbik et al. (2018)</cite> recommends contextual string embeddings to be used in combination with standard word embeddings."
  ],
  "y": "background"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_7",
  "x": [
   "The default setup of <cite>Akbik et al. (2018)</cite> recommends contextual string embeddings to be used in combination with standard word embeddings."
  ],
  "y": "similarities uses"
 },
 {
  "id": "013f0e54384a8a4662a746eb4c30d9_8",
  "x": [
   "Our baseline are contextual string embeddings without pooling, i.e. the original setup proposed in <cite>Akbik et al. (2018)</cite> 2 ."
  ],
  "y": "uses"
 },
 {
  "id": "0143619c1c54129702aafb585463d2_0",
  "x": [
   "While useful, citation texts might lack the appropriate context from the reference article<cite> [4,</cite> 5, 18] ."
  ],
  "y": "background"
 },
 {
  "id": "0143619c1c54129702aafb585463d2_1",
  "x": [
   "To our knowledge, the only published results on TAC 201<cite>4</cite> is<cite> [4]</cite> , where the authors utilized query reformulation (QR) based on UMLS ontology."
  ],
  "y": "background"
 },
 {
  "id": "0143619c1c54129702aafb585463d2_2",
  "x": [
   "In addition to<cite> [4]</cite> , we also implement several other strong baselines to better evaluate the e ectiveness of our model: 1) BM25; 2) VSM: Vector Space Model that was used in<cite> [4]</cite> ; 3) DESM: Dual Embedding Space Model which is a recent embedding based retrieval model [12] ; and <cite>4</cite>) LMD-LDA: Language modeling with LDA smoothing which is a recent extension of the LMD to also account for the latent topics [10] ."
  ],
  "y": "differences extends"
 },
 {
  "id": "0143619c1c54129702aafb585463d2_3",
  "x": [
   "The best baseline performance is the query reformulation (QR) method by<cite> [4]</cite> which improves over other baselines."
  ],
  "y": "background"
 },
 {
  "id": "0143619c1c54129702aafb585463d2_4",
  "x": [
   "The most relevant prior work to ours is<cite> [4]</cite> where the authors approached the problem using a vector space model similarity ranking and query reformulations."
  ],
  "y": "similarities"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_0",
  "x": [
   "The key challenge in open RE is to reason jointly over the universal schema consisting of KB relations and surface relations<cite> (Riedel et al., 2013)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_1",
  "x": [
   "A number of matrix or tensor factorization models have recently been proposed in the context of relation extraction<cite> Riedel et al., 2013</cite>; Huang et al., 2014; ."
  ],
  "y": "background"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_2",
  "x": [
   "CORE is inspired by the combined factorization and entity model (FE) of<cite> Riedel et al. (2013)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_3",
  "x": [
   "For this reason,<cite> Riedel et al. (2013)</cite> argued and experimentally validated that open RE models can outperform targeted IE methods."
  ],
  "y": "background"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_4",
  "x": [
   "This assumption generally does not hold for the surface relations extracted by open IE systems<cite> (Riedel et al., 2013)</cite> ; examples of other types of relationships between relations include implication or mutual exclusion."
  ],
  "y": "background"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_5",
  "x": [
   "Closest to our work is the \"universal schema\" matrix factorization approach of<cite> Riedel et al. (2013)</cite> , which combines a latent features model, a neighborhood model and an entity model but does not incorporate context."
  ],
  "y": "similarities"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_6",
  "x": [
   "Following<cite> Riedel et al. (2013)</cite> , we adopt the open-world assumption instead, i.e., we treat each unobserved facts as unknown."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_7",
  "x": [
   "Since we ultimately use our model to rank tuples for each relation individually, we consider as negative evidence for x only unobserved facts from the same relation<cite> (Riedel et al., 2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_8",
  "x": [
   "2 Our experimental study closely follows the one of<cite> Riedel et al. (2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_9",
  "x": [
   "We made use of the dataset of<cite> Riedel et al. (2013)</cite> , but extended it with contextual information."
  ],
  "y": "extends"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_10",
  "x": [
   "From the raw dataset described above, we filtered out all surface relations with less than 10 instances, and all tuples with less than two instances, as in<cite> Riedel et al. (2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_11",
  "x": [
   "In contrast to previous work<cite> (Riedel et al., 2013</cite>; , we retain partially-linked and non-linked facts in our dataset."
  ],
  "y": "differences"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_12",
  "x": [
   "To keep the experimental study feasible and comparable to previous studies, we use the full training data but evaluate each model's predictions on only the subsample of 10k tuples (\u2248 6% of all tuples) of<cite> Riedel et al. (2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_13",
  "x": [
   "Our study focused on these two factorization models because they outperformed other models (including nonfactorization models) in previous studies<cite> (Riedel et al., 2013</cite>; ."
  ],
  "y": "differences"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_15",
  "x": [
   "NFE is the full model proposed in the \"universal schema\" work of<cite> Riedel et al. (2013)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_16",
  "x": [
   "The NFE model outperformed tensor models as well as clustering methods and distantly supervised methods in the experimental study of<cite> Riedel et al. (2013)</cite> for open RE tasks."
  ],
  "y": "background"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_17",
  "x": [
   "We use the original source code of<cite> Riedel et al. (2013)</cite> for training."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_18",
  "x": [
   "NFE<cite> (Riedel et al., 2013)</cite> .",
   "NFE is the full model proposed in the \"universal schema\" work of<cite> Riedel et al. (2013)</cite> .",
   "The NFE model outperformed tensor models as well as clustering methods and distantly supervised methods in the experimental study of<cite> Riedel et al. (2013)</cite> for open RE tasks.",
   "We use the original source code of<cite> Riedel et al. (2013)</cite> for training."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_19",
  "x": [
   "To evaluate the prediction performance of each method, we followed<cite> Riedel et al. (2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_20",
  "x": [
   "If all # facts are found and ranked top, then MAP 100 # = 1. Note that our definition of MAP 100 # differs slightly from<cite> Riedel et al. (2013)</cite> ; our metric is more robust because it is based on completely labeled evaluation data."
  ],
  "y": "differences"
 },
 {
  "id": "029def00e36495beb31bde4cc87298_21",
  "x": [
   "These choices correspond to the ones of<cite> Riedel et al. (2013)</cite> ; no further tuning was performed."
  ],
  "y": "uses"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_0",
  "x": [
   "Ponzetto and Strube (2006) and <cite>Ratinov and Roth (2012)</cite> precompute a fixed alignment of the mentions to the knowledge base entities."
  ],
  "y": "background"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_1",
  "x": [
   "Unfortunately, this results in fewer alignments, and improvements are only shown on mentions that are easier to align and corefer (such as the non-transcript documents in <cite>Ratinov and Roth (2012)</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_2",
  "x": [
   "Our paper provides the following contributions: (1) an approach that jointly reasons about both within-doc entities and their alignment to KBentities by dynamically adjusting a ranked list of candidate alignments, during coreference, (2) Utilization of a larger set of surface string variations for each entity candidate by using links that appear all over the web (Spitkovsky and Chang, 2012) , (3) A combination of these approaches that improves upon a competitive baseline without a knowledge base by 1.09 B 3 F1 points on the ACE 2004 data, and outperforms the state-of-the-art coreference system (Stoyanov and Eisner, 2012) by 0.41 B 3 F1 points, and (4) Accurate predictions on documents that are difficult for coreference, such as the transcript documents that were omitted from the evaluation in <cite>Ratinov and Roth (2012)</cite> , and documents that contain a large number of mentions."
  ],
  "y": "uses"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_3",
  "x": [
   "Linking is often noisy, so only selecting the high-precision links as in <cite>Ratinov and Roth (2012)</cite> results in too few matches, while picking an aggregation of all links results in more noise due to lower precision (Rahman and Ng, 2011) ."
  ],
  "y": "background"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_4",
  "x": [
   "Linking is often noisy, so only selecting the high-precision links as in <cite>Ratinov and Roth (2012)</cite> results in too few matches, while picking an aggregation of all links results in more noise due to lower precision (Rahman and Ng, 2011) ."
  ],
  "y": "differences"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_5",
  "x": [
   "Given these entities, there are many possible features that may be used for disambiguation of the mentions, such as gender and fine-grained Wikipedia categories as used by <cite>Ratinov and Roth (2012)</cite> , however most of these features may not be relevant to the task of within-document coreference."
  ],
  "y": "background"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_6",
  "x": [
   "Given these entities, there are many possible features that may be used for disambiguation of the mentions, such as gender and fine-grained Wikipedia categories as used by <cite>Ratinov and Roth (2012)</cite> , however most of these features may not be relevant to the task of within-document coreference."
  ],
  "y": "differences"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_7",
  "x": [
   "This approach is comparable to the fixed alignment model, as in the approaches of Ponzetto and Strube (2006) and <cite>Ratinov and Roth (2012)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_8",
  "x": [
   "Since these transcripts provide an additional challenge for alignment and coreference, <cite>Ratinov and Roth (2012)</cite> only use the set of non-transcripts for their evaluation."
  ],
  "y": "differences"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_9",
  "x": [
   "To identify the transcripts in the test set, we use the approximation from <cite>Ratinov and Roth (2012)</cite> that considers a document to be non-transcribed if it contains proper noun mentions and at least a third of those start with a capital letter."
  ],
  "y": "uses"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_10",
  "x": [
   "Our static linking matches the performance of <cite>Ratinov and Roth (2012)</cite> on the non-transcripts."
  ],
  "y": "similarities"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_11",
  "x": [
   "<cite>Ratinov and Roth (2012)</cite> extend the multi-sieve coreference model (Raghunathan et al., 2010) by identifying at most a single candidate for each mention, and incorporating high-precision attributes extracted from Wikipedia."
  ],
  "y": "background"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_12",
  "x": [
   "<cite>Ratinov and Roth (2012)</cite> extend the multi-sieve coreference model (Raghunathan et al., 2010) by identifying at most a single candidate for each mention, and incorporating high-precision attributes extracted from Wikipedia."
  ],
  "y": "differences"
 },
 {
  "id": "03c57679549ff600a024d436d5a107_13",
  "x": [
   "Wikifier (Ratinov et al., 2011) analyzes the context around the mentions and the entities jointly, and was used to align mentions for coreference in <cite>Ratinov and Roth (2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "04461d946dadc759e4be1207655159_0",
  "x": [
   "Chiang's hierarchical phrase-based (HPB) translation model utilizes synchronous context free grammar (SCFG) for translation derivation (Chiang, 2005; <cite>Chiang, 2007)</cite> and has been widely adopted in statistical machine translation (SMT)."
  ],
  "y": "background"
 },
 {
  "id": "04461d946dadc759e4be1207655159_1",
  "x": [
   "Like Chiang (2005) and<cite> Chiang (2007)</cite> , our HD-HPB translation model adopts a synchronous context free grammar, a rewriting system which generates source and target side string pairs simultaneously using a context-free grammar."
  ],
  "y": "similarities"
 },
 {
  "id": "04461d946dadc759e4be1207655159_2",
  "x": [
   "Instead of collapsing all non-terminals in the source language into a single symbol X as in<cite> Chiang (2007)</cite> , given a word sequence f i j from position i to position j, we first find heads and then concatenate the POS tags of these heads as f i j 's non-terminal symbol."
  ],
  "y": "differences"
 },
 {
  "id": "04461d946dadc759e4be1207655159_3",
  "x": [
   "For rule extraction, we first identify initial phrase pairs on word-aligned sentence pairs by using the same criterion as most phrase-based translation models (Och and Ney, 2004 ) and Chiang's HPB model (Chiang, 2005; <cite>Chiang, 2007)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "04461d946dadc759e4be1207655159_4",
  "x": [
   "This is the same as the hierarchical rules defined in Chiang's HPB model<cite> (Chiang, 2007)</cite> , except that we use head POSinformed non-terminal symbols in the source language."
  ],
  "y": "differences similarities"
 },
 {
  "id": "04461d946dadc759e4be1207655159_5",
  "x": [
   "Given the word alignment in Figure 1 , Table 1 demonstrates the difference between hierarchical rules in<cite> Chiang (2007)</cite> and HD-HRs defined here."
  ],
  "y": "differences"
 },
 {
  "id": "04461d946dadc759e4be1207655159_6",
  "x": [
   "To alleviate these problems, we filter our HD-HRs according to the same constraints as described in<cite> Chiang (2007)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "04461d946dadc759e4be1207655159_8",
  "x": [
   "Given e for the translation output in the target language, s and t for strings of terminals and nonterminals on the source and target side, respectively, we use a feature set analogous to the default feature set of<cite> Chiang (2007)</cite> , including:"
  ],
  "y": "similarities"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_0",
  "x": [
   "<cite>Weighted Textual Matrix Factorization [WTMF]</cite> (<cite>Guo and Diab, 2012b</cite> ) is a latent variable model that outperforms Latent Semantic Analysis [LSA] (Deerwester et al., 1990) and Latent Dirichelet Allocation [LDA] (Blei et al., 2003) models by a large margin in the SS task, yielding state-of-the-art performance on the LI06 (Li et al., 2006 ) SS dataset."
  ],
  "y": "background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_1",
  "x": [
   "<cite>Weighted Textual Matrix Factorization [WTMF]</cite> (<cite>Guo and Diab, 2012b</cite> ) is a latent variable model that outperforms Latent Semantic Analysis [LSA] (Deerwester et al., 1990) and Latent Dirichelet Allocation [LDA] (Blei et al., 2003) models by a large margin in the SS task, yielding state-of-the-art performance on the LI06 (Li et al., 2006 ) SS dataset.",
   "However, all of these models make harsh simplifying assumptions on how a token is generated: (1) in LSA/<cite>WTMF</cite>, a token is generated by the inner product of the word latent vector and the document latent vector; (2) in LDA, all the tokens in a document are sampled from the same document level topic distribution."
  ],
  "y": "motivation"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_2",
  "x": [
   "In this paper, we explicitly encode lexical semantics, both corpus-based and knowledge-based information, in the <cite>WTMF</cite> model, by which we are able to achieve even better results in SS task."
  ],
  "y": "uses motivation"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_3",
  "x": [
   "Consider the following example: In <cite>WTMF</cite>/LSA/LDA, a word will receive semantics from all the other words in a sentence, hence, the word oil, in the above example, will be assigned the incorrect finance topic that reflects the sentence level semantics."
  ],
  "y": "uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_4",
  "x": [
   "We also integrate knowledge-based semantics in the <cite>WTMF</cite> framework."
  ],
  "y": "extends"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_5",
  "x": [
   "<cite>Our</cite> previous work (<cite>Guo and Diab, 2012b</cite> ) models the sentences in the weighted matrix factorization framework ( Figure 1 )."
  ],
  "y": "background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_6",
  "x": [
   "Similar words pairs can be seamlessly modeled in <cite>WTMF</cite>, since in the matrix factorization framework a latent vector profile is explicitly created for each word, while in LDA all the data structures are designed for documents/sentences."
  ],
  "y": "background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_7",
  "x": [
   "Similar words pairs can be seamlessly modeled in <cite>WTMF</cite>, since in the matrix factorization framework a latent vector profile is explicitly created for each word, while in LDA all the data structures are designed for documents/sentences."
  ],
  "y": "motivation uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_8",
  "x": [
   "The graphical model of <cite>WTMF</cite> is illustrated in Figure 2a ."
  ],
  "y": "uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_9",
  "x": [
   "In (<cite>Guo and Diab, 2012b</cite>) <cite>we</cite> use Alternating Least Square [ALS] for inference, which is to set the derivative of equation 1 for P/Q to 0 and iteratively compute P/Q by fixing the other matrix (Srebro and Jaakkola, 2003) ."
  ],
  "y": "background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_10",
  "x": [
   "In (<cite>Guo and Diab, 2012b</cite>) <cite>we</cite> use Alternating Least Square [ALS] for inference, which is to set the derivative of equation 1 for P/Q to 0 and iteratively compute P/Q by fixing the other matrix (Srebro and Jaakkola, 2003) ."
  ],
  "y": "motivation"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_11",
  "x": [
   "where P \u00b7,s(i) are the latent vectors of similar words of word i; the length of these vectors in the current iteration are stored in L s(i) (similarly L i is the current length of P \u00b7,i ) (cf. (Steck, 2010; <cite>Guo and Diab, 2012b</cite>) for optimization details)."
  ],
  "y": "uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_12",
  "x": [
   "In (<cite>Guo and Diab, 2012b</cite>) <cite>we</cite> use Alternating Least Square [ALS] for inference, which is to set the derivative of equation 1 for P/Q to 0 and iteratively compute P/Q by fixing the other matrix (Srebro and Jaakkola, 2003) .",
   "where P \u00b7,s(i) are the latent vectors of similar words of word i; the length of these vectors in the current iteration are stored in L s(i) (similarly L i is the current length of P \u00b7,i ) (cf. (Steck, 2010; <cite>Guo and Diab, 2012b</cite>) for optimization details)."
  ],
  "y": "extends"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_13",
  "x": [
   "We build the model WTMF+PK on the same corpora as used in <cite>our</cite> previous work (<cite>Guo and Diab, 2012b</cite>) , comprising the following: Brown corpus (each sentence is treated as a document), sense definitions from Wiktionary and Wordnet (only definitions without target words and usage examples)."
  ],
  "y": "uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_14",
  "x": [
   "We include three baselines LSA, LDA and <cite>WTMF</cite> using the setting described in (<cite>Guo and Diab, 2012b</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_15",
  "x": [
   "For <cite>WTMF</cite>, we run 20 iterations and fix the missing words weight at w m = 0.01 with a regularization coefficient set at \u03bb = 20, which is the best condition found in (<cite>Guo and Diab, 2012b</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_16",
  "x": [
   "We include three baselines LSA, LDA and <cite>WTMF</cite> using the setting described in (<cite>Guo and Diab, 2012b</cite>) .",
   "Table 1 shows <cite>WTMF</cite> is already a very strong baseline: it outperforms LSA and LDA by a large margin."
  ],
  "y": "uses background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_17",
  "x": [
   "Table 1 shows <cite>WTMF</cite> is already a very strong baseline: it outperforms LSA and LDA by a large margin."
  ],
  "y": "differences uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_18",
  "x": [
   "Same as in (<cite>Guo and Diab, 2012b</cite>) , LSA performance degrades dramatically when trained on a corpus of sentence sized documents, yielding results worse than the surface words baseline 31% (Agirre et al., 2012) ."
  ],
  "y": "similarities"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_19",
  "x": [
   "Using corpus-based selectional preference semantics alone (model 4 WTMF+P in Table  1 ) boosts the performance of <cite>WTMF</cite> by +1.17% on the test set, while using knowledge-based semantics alone (model 5 WTMF+K) improves the over the <cite>WTMF</cite> results by an absolute +2.31%."
  ],
  "y": "differences extends"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_20",
  "x": [
   "Figure 3c illustrates the impact of dimension K = {50, 75, 100, 125, 150} on <cite>WTMF</cite> and WTMF+PK."
  ],
  "y": "differences uses"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_21",
  "x": [
   "Our previous experiments (<cite>Guo and Diab, 2012b</cite>) show that <cite>WTMF</cite> is the state-of-the-art model on LI06."
  ],
  "y": "background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_22",
  "x": [
   "With lexical semantics explicitly modeled, WTMF+PK yields better results than <cite>WTMF</cite> (see Table 1 )."
  ],
  "y": "differences background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_23",
  "x": [
   "With lexical semantics explicitly modeled, WTMF+PK yields better results than <cite>WTMF</cite> (see Table 1 )."
  ],
  "y": "differences"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_24",
  "x": [
   "It should be noted that LI06 prefers a smaller similar word pair weight ( a \u03b4 = 0.1 yields the best performance around of 90.75%), yet in almost all conditions WTMF+PK outperforms <cite>WTMF</cite> as shown in Figure 3d ."
  ],
  "y": "differences background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_25",
  "x": [
   "It should be noted that LI06 prefers a smaller similar word pair weight ( a \u03b4 = 0.1 yields the best performance around of 90.75%), yet in almost all conditions WTMF+PK outperforms <cite>WTMF</cite> as shown in Figure 3d ."
  ],
  "y": "differences"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_26",
  "x": [
   "In (<cite>Guo and Diab, 2012b</cite>; Guo and Diab, 2012c) , we show the superiority of the latent space approach in <cite>WTMF</cite>."
  ],
  "y": "background"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_27",
  "x": [
   "In (<cite>Guo and Diab, 2012b</cite>; Guo and Diab, 2012c) , we show the superiority of the latent space approach in <cite>WTMF</cite>.",
   "In this paper, we improve the <cite>WTMF</cite> model and achieve state-of-the-art Pearson correlation on two standard SS datasets."
  ],
  "y": "differences extends"
 },
 {
  "id": "048944feaff977c8cf057d52594c72_28",
  "x": [
   "In this paper, we improve the <cite>WTMF</cite> model and achieve state-of-the-art Pearson correlation on two standard SS datasets."
  ],
  "y": "differences extends"
 },
 {
  "id": "053ce92029e643bfade157b3172c05_0",
  "x": [
   "In order to ease the process of engineering such a large grammar, we have made use of the lexical knowledge representation language DATR (Evans & Gazdar, 1996) to compactly encode the elementary trees <cite>(Evans et al., 1995</cite>; Smets & Evans, 1998) ."
  ],
  "y": "uses"
 },
 {
  "id": "053ce92029e643bfade157b3172c05_1",
  "x": [
   "Following<cite> (Evans et al., 1995)</cite> and (Smets & Evans, 1998 ) the LEXSYS grammar is encoded using DATR, a non-monotonic knowledge representation language."
  ],
  "y": "similarities uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_0",
  "x": [
   "Our shared task submission adopts the bidirectional LSTM-CNN model of<cite> Chiu and Nichols (2016)</cite>, as it has been shown to perform well on both newswire and Web texts."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_1",
  "x": [
   "Recently, neural network models -especially those that use recursive models -have shown that state of the art performance can be achieved with little feature engineering (Collobert et al., 2011; Santos et al., 2015; <cite>Chiu and Nichols, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_2",
  "x": [
   "Our shared task submission is based on the model of<cite> Chiu and Nichols (2016)</cite> , a hybrid model of bidirectional long short-term memory (BLSTM) networks and convolutional neural networks (CNN) that automatically learns both character-and word-level features, and which holds the current state-of-the-art on both newswire texts (CoNLL 2003) and diverse corpora including Web texts (OntoNotes 5.0)."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_3",
  "x": [
   "Our primary contribution is adapting the model of<cite> Chiu and Nichols (2016)</cite> to Twitter data by developing a text normalization method to effectively apply word embeddings to large vocabulary Web texts and automatically constructing lexicons for the shared task's target NE classes from publicly-available sources."
  ],
  "y": "extends"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_4",
  "x": [
   "In Section 2, we describe the adaptations made to<cite> Chiu and Nichols (2016)</cite> 's model."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_5",
  "x": [
   "Our system is based on the BLSTM-CNN model of<cite> Chiu and Nichols (2016)</cite> , and, unless otherwise noted, follows their training and tagging methodology, which the reader is referred to for more details."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_6",
  "x": [
   "The neural embeddings of Collobert et al. (2011) were chosen because<cite> Chiu and Nichols (2016)</cite> reported them to be the highest performing on both CoNLL-2003 and OntoNotes 5.0 datasets."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_7",
  "x": [
   "Following<cite> Chiu and Nichols (2016)</cite> , we use a CNN to extract features from 25 dim."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_8",
  "x": [
   "To generate lexicon features, we apply the partial matching algorithm of<cite> Chiu and Nichols (2016)</cite> to the input text, as shown in Figure 2 ."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_9",
  "x": [
   "Following<cite> Chiu and Nichols (2016)</cite>, we used different symbols for word-level capitalization feature each assigned a randomly initialized embedding: allCaps, upperInitial, lowercase, mixedCaps and noinfo."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_10",
  "x": [
   "We follow the training and inference methodology of<cite> Chiu and Nichols (2016)</cite> , training our neural network to maximize the sentence-level log-likelihood from Collobert et al. (2011) ."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_11",
  "x": [
   "For a more detailed survey, see<cite> (Chiu and Nichols, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_12",
  "x": [
   "Our system adopts the architecture of<cite> Chiu and Nichols (2016)</cite> , which combined BLSTMs to maximize context over the tagged word sequence and word-level CNNs to automatically generate characterlevel features with a partial-matching lexicon to achieve the state-of-the-art for NER on both CoNLL 2003 and OntoNotes datasets."
  ],
  "y": "uses"
 },
 {
  "id": "05bf376f0a18cf313ead7189b029b6_13",
  "x": [
   "In this paper, we described the DeepNNNER entry to the WNUT 2016 Shared Task #2: Named Entity Recognition in Twitter, which adopted the BLSTM-CNN model of<cite> Chiu and Nichols (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "062e9348de5fda68e61fff3ca4f186_0",
  "x": [
   "The third type of projection, P Acc , integrates syntactic information in the edge weights calculated by the following formula: While the entity grid <cite>(Barzilay and Lapata, 2008)</cite> uses information about sentences which do not share entities by means of the \"--\" transition, the entity graph cannot employ this negative information."
  ],
  "y": "motivation background"
 },
 {
  "id": "062e9348de5fda68e61fff3ca4f186_1",
  "x": [
   "Results for Guinaudeau and Strube (2013) , G&S, are reproduced, results for<cite> Barzilay and Lapata (2008)</cite> , B&L, and Elsner and Charniak (2011) , E&C, were reproduced by Guinaudeau and Strube (2013) ."
  ],
  "y": "background"
 },
 {
  "id": "062e9348de5fda68e61fff3ca4f186_2",
  "x": [
   "We follow<cite> Barzilay and Lapata (2008)</cite> for evaluating whether the normalized entity graph can decide whether automatic or human summaries are more coherent (80 pairs of summaries extracted from DUC 2003)."
  ],
  "y": "uses"
 },
 {
  "id": "062e9348de5fda68e61fff3ca4f186_3",
  "x": [
   "Human coherence scores are associated with each pair of summarized documents <cite>(Barzilay and Lapata, 2008)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "062e9348de5fda68e61fff3ca4f186_4",
  "x": [
   "In experiments,<cite> Barzilay and Lapata (2008)</cite> assume that articles taken from Encyclopedia Britannica are more difficult to read (less coherent) than the corresponding articles from Encyclopedia Britannica Elementary, its version for children."
  ],
  "y": "uses background motivation"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_0",
  "x": [
   "With the availability of annotated corpora, such as Penn Discourse Treebank (PDTB) (Prasad et al., 2008) , statistical discourse parsers were developed (Lin et al., 2012;<cite> Ghosh et al., 2011</cite>; Xu et al., 2012) ."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_1",
  "x": [
   "In the first approach the parser decision is not conditioned on whether the relation is intra-or inter-sentential (e.g.<cite> (Ghosh et al., 2011)</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_2",
  "x": [
   "In<cite> (Ghosh et al., 2011</cite> ) the decision is made on tokenlevel, and the problem is cast as sequence labeling using conditional random fields (CRFs) (Lafferty et al., 2001) ."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_3",
  "x": [
   "In<cite> (Ghosh et al., 2011</cite> ) the decision is made on tokenlevel, and the problem is cast as sequence labeling using conditional random fields (CRFs) (Lafferty et al., 2001) .",
   "In this paper we focus on argument span extraction, and extend the token-level sequence labeling approach of<cite> (Ghosh et al., 2011)</cite> with the separate models for arguments of intra-sentential and intersentential explicit discourse relations."
  ],
  "y": "extends"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_4",
  "x": [
   "In this paper we follows the approach of<cite> (Ghosh et al., 2011</cite> (Prasad et al., 2008) ); and distribution of Arg2 with respect to extent in inter-sentential explicit discourse relations."
  ],
  "y": "uses"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_5",
  "x": [
   "CRF-based discourse parser of<cite> Ghosh et al. (2011)</cite> , which processes SS and PS cases with the same model, uses \u00b12 sentence window as a hypothesis space (5 sentences: 1 sentence containing the connective, 2 preceding and 2 following sentences)."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_6",
  "x": [
   "The task has a very high baseline and even higher performance on supervised machine learning, Table 3 : Feature sets for Arg2 and Arg1 argument span extraction in<cite> (Ghosh et al., 2011)</cite> which is an additional motivation to process intra-and inter-sentential relations separately."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_7",
  "x": [
   "We replicate and evaluate the discourse parser of<cite> (Ghosh et al., 2011)</cite> , then modify it to process intraand inter-sentential explicit relations separately."
  ],
  "y": "extends"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_8",
  "x": [
   "Previous Sentence Feature (PREV) signals if a sentence immediately precedes the sentence starting with a connective, and its value is the first token of the connective<cite> (Ghosh et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_9",
  "x": [
   "Via templates these features are enriched with ngrams: tokens with 2-grams in the window of \u00b11 to- Figure 1: Single model discourse parser architecture of<cite> (Ghosh et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_10",
  "x": [
   "The discourse parser of<cite> (Ghosh et al., 2011</cite> ) is a cascade of CRF models to sequentially label Arg2 and Arg1 spans (since Arg2 label is a feature for Arg1 model) (see Figure 1 )."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_11",
  "x": [
   "The performance is higher than<cite> (Ghosh et al., 2011</cite> ) -Arg2: F 1 of 79.1 and Arg1: F 1 of 57.3 -due to improvements in feature and instance extraction, such as the treatment of multi-word connectives."
  ],
  "y": "differences"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_12",
  "x": [
   "First, in this paper it is different from<cite> (Ghosh et al., 2011)</cite> ; thus, we first describe it and evaluate the difference."
  ],
  "y": "differences"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_13",
  "x": [
   "Following<cite> (Ghosh et al., 2011)</cite> PDTB is split as Sections 02-22 for training, 00-01 for development, and 23-24 for testing."
  ],
  "y": "uses"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_14",
  "x": [
   "<cite>Ghosh et al. (2011)</cite> report using CONLL-based evaluation script."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_15",
  "x": [
   "Thus, CONLL-based evaluation yields incorrect number of test instances:<cite> Ghosh et al. (2011)</cite> report 1,028 SS and 617 PS test instances for PDTB sections 23-24 (see caption of Table 7 in the original paper), which is 1,645 in total; whereas there is only 1,595 explicit relations in these sections."
  ],
  "y": "background"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_16",
  "x": [
   "Following<cite> (Ghosh et al., 2011)</cite> and (Lin et al., 2012) , argument initial and final punctuation marks are removed; and precision (p), recall (r) and F 1 score are computed using the equations 1 -3."
  ],
  "y": "uses"
 },
 {
  "id": "06917a1dd02d55c827e7e07eeae2da_17",
  "x": [
   "We extend the approach of<cite> (Ghosh et al., 2011)</cite> to argument span extraction cast as token-level sequence labeling using CRFs and integrate argument position classification and immediately previous sentence heuristic."
  ],
  "y": "extends"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_0",
  "x": [
   "Seq2seq models have also been applied to constituency parsing <cite>(Vinyals et al., 2015)</cite> and provided a fairly good result."
  ],
  "y": "background"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_1",
  "x": [
   "Our aim is to update the Seq2seq approach proposed in<cite> Vinyals et al. (2015)</cite> as a stronger baseline of constituency parsing."
  ],
  "y": "uses"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_2",
  "x": [
   "Our starting point is an RNN-based Seq2seq model with an attention mechanism that was applied to constituency parsing <cite>(Vinyals et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_4",
  "x": [
   "As described in<cite> Vinyals et al. (2015)</cite> , not all the outputs (predicted linearized parse trees) obtained from the Seq2seq parser are valid (well-formed) as a parse tree."
  ],
  "y": "motivation background"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_5",
  "x": [
   "As described in<cite> Vinyals et al. (2015)</cite> , not all the outputs (predicted linearized parse trees) obtained from the Seq2seq parser are valid (well-formed) as a parse tree."
  ],
  "y": "motivation"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_6",
  "x": [
   "In constituency parsing, several systems also incorporate pre-trained word embeddings, such as<cite> Vinyals et al. (2015)</cite> ; Durrett and Klein (2015) ."
  ],
  "y": "background"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_7",
  "x": [
   "In constituency parsing, several systems also incorporate pre-trained word embeddings, such as<cite> Vinyals et al. (2015)</cite> ; Durrett and Klein (2015) ."
  ],
  "y": "motivation"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_8",
  "x": [
   "We used the standard split of training (Sec.02-21), development (Sec.22), and test data (Sec.23) and strictly followed the instructions for the evaluation settings explained in<cite> Vinyals et al. (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_9",
  "x": [
   "As explained in<cite> Vinyals et al. (2015)</cite> , we did not apply any parse tree binarization or special unary treatment, which were used as common techniques in the literature."
  ],
  "y": "uses"
 },
 {
  "id": "0732eaa37366d7ae092f4de0ed72cb_10",
  "x": [
   "We postprocessed such malformed parse trees by simple rules introduced in <cite>(Vinyals et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "0751f2ced4f7ced37cf206fea051fa_0",
  "x": [
   "In <cite>(S\u00e1nchez and Bened\u00ed, 2006b</cite> ), SITGs were used for obtaining word phrases, reporting preliminary results on the EuroParl corpus."
  ],
  "y": "background"
 },
 {
  "id": "0751f2ced4f7ced37cf206fea051fa_1",
  "x": [
   "In <cite>(S\u00e1nchez and Bened\u00ed, 2006b</cite> ), SITGs were used for obtaining word phrases, reporting preliminary results on the EuroParl corpus."
  ],
  "y": "extends"
 },
 {
  "id": "0751f2ced4f7ced37cf206fea051fa_2",
  "x": [
   "First, we built an initial SITG by following the method described in <cite>(S\u00e1nchez and Bened\u00ed, 2006b</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "0751f2ced4f7ced37cf206fea051fa_3",
  "x": [
   "<cite>(S\u00e1nchez and Bened\u00ed, 2006b</cite> ) Translation results of this setup can be seen in Table 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "0751f2ced4f7ced37cf206fea051fa_4",
  "x": [
   "Comparatively, the best result that<cite> (S\u00e1nchez and Bened\u00ed, 2006b)</cite> reported in the Spanish-English task was a BLEU score of 23.0, which they obtained by combining segments extracted from both the bracketed and the non-bracketed corpus."
  ],
  "y": "background"
 },
 {
  "id": "0751f2ced4f7ced37cf206fea051fa_5",
  "x": [
   "Comparatively, the best result that<cite> (S\u00e1nchez and Bened\u00ed, 2006b)</cite> reported in the Spanish-English task was a BLEU score of 23.0, which they obtained by combining segments extracted from both the bracketed and the non-bracketed corpus."
  ],
  "y": "differences"
 },
 {
  "id": "0860b08831b01e7e98c66ced63b256_0",
  "x": [
   "The dependency-based word embedding can relieve the problem of data sparseness, since even without occurrence of dependency word pairs in a corpus, dependency scores can be still calculated by word embeddings <cite>[12]</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_0",
  "x": [
   "Previous work on bridging anaphora resolution (Poesio et al., 2004;<cite> Hou et al., 2013b)</cite> use syntactic preposition patterns to calculate word relatedness."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_1",
  "x": [
   "Previous work on bridging anaphora resolution (Poesio et al., 2004;<cite> Hou et al., 2013b)</cite> use syntactic preposition patterns to calculate word relatedness."
  ],
  "y": "motivation background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_2",
  "x": [
   "We show that this simple approach achieves the competitive results compared to the best system in<cite> Hou et al. (2013b)</cite> which explores Markov Logic Networks to model the problem."
  ],
  "y": "differences"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_3",
  "x": [
   "Additionally, we further improve the results for bridging anaphora resolution reported in Hou (2018) by combining our simple deterministic approach with<cite> Hou et al. (2013b)</cite>'s best system MLN II."
  ],
  "y": "extends"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_4",
  "x": [
   "Most previous empirical research on bridging (Poesio and Vieira, 1998; Poesio et al., 2004; Markert et al., 2003; Lassalle and Denis, 2011;<cite> Hou et al., 2013b)</cite> focus on bridging anaphora resolution, a subtask of bridging resolution that aims to choose the antecedents for bridging anaphors."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_5",
  "x": [
   "For this substask, most previous work (Poesio et al., 2004; Lassalle and Denis, 2011;<cite> Hou et al., 2013b)</cite> calculate semantic relatedness between an anaphor and its antecedent based on word co-occurrence counts using certain syntactic patterns."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_6",
  "x": [
   "We show that this simple, efficient method achieves the competitive results on ISNotes for the task of bridging anaphora resolution compared to the best system in<cite> Hou et al. (2013b)</cite> which explores Markov Logic Networks to model the problem."
  ],
  "y": "differences"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_7",
  "x": [
   "Pre-vious work on bridging anaphora resolution (Poesio et al., 2004; Lassalle and Denis, 2011;<cite> Hou et al., 2013b</cite> ) explored word co-occurrence counts in certain syntactic preposition patterns to calculate word relatedness."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_8",
  "x": [
   "Based on this corpus,<cite> Hou et al. (2013b)</cite> proposed a joint inference framework for bridging anaphora resolution using Markov logic networks (Domingos and Lowd, 2009 framework resolves all bridging anaphors in one document together by modeling that semantically related anaphors are likely to share the same antecedent."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_9",
  "x": [
   "Our approach is deterministic and simple, but achieves the competitive results compared to the advanced machine learning-based approach <cite>(Hou et al., 2013b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_10",
  "x": [
   "We also improve the result reported in Hou (2018) on the same corpus by combining our deterministic approach with the best system from<cite> Hou et al. (2013b)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_11",
  "x": [
   "Following<cite> Hou et al. (2013b)</cite> 's experimental setup, we resolve bridging anaphors to entity antecedents."
  ],
  "y": "uses"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_12",
  "x": [
   "In<cite> Hou et al. (2013b)</cite> , features are extracted by using entity information."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_13",
  "x": [
   "In<cite> Hou et al. (2013b)</cite> , features are extracted by using entity information."
  ],
  "y": "extends"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_14",
  "x": [
   "Note that our simple antecedent candidate selection strategy (described in Section 4) allows us to include 76% of NP antecedents compared to 77% in pairwise model III from<cite> Hou et al. (2013b)</cite> where they add top 10% salient entities as additional antecedent candidates."
  ],
  "y": "differences"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_15",
  "x": [
   "In<cite> Hou et al. (2013b)</cite> , salient entities on each text are measured through the lengths of the coreference chains based on the gold coreference annotation."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_16",
  "x": [
   "Following<cite> Hou et al. (2013b)</cite> , we measure accuracy on the number of bridging anaphors, instead of on all links between bridging anaphors and their antecedent instantiations."
  ],
  "y": "uses"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_17",
  "x": [
   "Table 6 lists the best results of the two models for bridging anaphora resolution from<cite> Hou et al. (2013b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_18",
  "x": [
   "acc models from<cite> Hou et al. (2013b)</cite> Table 6 : Results of using NP head plus modifications in different word representations for bridging anaphora resolution compared to the best results of two models from<cite> Hou et al. (2013b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_19",
  "x": [
   "Finally, our method based on embeddings bridging achieves an accuracy of 39.52%, which is competitive to the best result (41.32%) reported in<cite> Hou et al. (2013b)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_20",
  "x": [
   "For bridging anaphora resolution, Hou (2018) integrates a much simpler deterministic approach by combining an NP head with its noun modifiers (appearing before the head) based on embeddings PP into the MLN II system <cite>(Hou et al., 2013b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_21",
  "x": [
   "For bridging anaphora resolution, Hou (2018) integrates a much simpler deterministic approach by combining an NP head with its noun modifiers (appearing before the head) based on embeddings PP into the MLN II system <cite>(Hou et al., 2013b)</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_22",
  "x": [
   "We show that this simple and efficient method achieves the competitive result on bridging anaphora resolution compared to the advanced machine learning-based approach in<cite> Hou et al. (2013b)</cite> which is heavily dependent on a lot of carefully designed complex features."
  ],
  "y": "differences"
 },
 {
  "id": "087a2a35ad2428d6b17c6906447349_23",
  "x": [
   "For the task of bridging anaphora resolution,<cite> Hou et al. (2013b)</cite> pointed out that considering only head noun knowledge is not enough and future work needs to explore wider context to resolve context-specific bridging relations."
  ],
  "y": "future_work"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_0",
  "x": [
   "<cite>Wang et al. (2014a)</cite> rely on Wikipedia anchors, making the applicable scope quite limited."
  ],
  "y": "motivation"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_1",
  "x": [
   "Extensive experiments show that, the proposed approach consistently performs comparably or even better than the method of <cite>Wang et al. (2014a)</cite> , which is encouraging as we do not use any anchor information."
  ],
  "y": "differences"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_2",
  "x": [
   "An important milestone, the approach of <cite>Wang et al. (2014a)</cite> solves issue (1) by jointly embedding entities, relations, and words into the same vector space and hence is able to deal with words/phrases beyond entities in KBs."
  ],
  "y": "background"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_3",
  "x": [
   "We conduct extensive experiments on the tasks of triplet classification, link prediction, relational fact extraction, and analogical reasoning to compare with the previous approach <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_4",
  "x": [
   "Most knowledge embedding models thereafter including this paper are variants of this model (Wang et al., 2014b; <cite>Wang et al., 2014a</cite>; Lin et al., 2015) ."
  ],
  "y": "background uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_5",
  "x": [
   "<cite>Wang et al. (2014a)</cite> combines knowledge embedding and word embedding in a joint framework so that the entities/relations and words are in the same vector space and hence operators like inner product (similarity) between them are meaningful."
  ],
  "y": "background"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_6",
  "x": [
   "We follow the jointly embedding framework of <cite>(Wang et al., 2014a)</cite> , i.e., learning optimal embeddings by minimizing the following loss"
  ],
  "y": "uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_7",
  "x": [
   "Our focus is on a new alignment model L A while the knowledge model L K and text model L T are the same as the counterparts in <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_8",
  "x": [
   "where z(h, r, t) = b \u2212 0.5 \u00b7 h + r \u2212 t 2 2 , b = 7 as suggested by <cite>Wang et al. (2014a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_9",
  "x": [
   "Alignment Model This part is different from <cite>Wang et al. (2014a)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_10",
  "x": [
   "As to the methods, \"Separately\" denotes the method of separately embedding knowledge bases and text. \"Jointly(anchor)\" and \"Jointly(name)\" denote the jointly embedding methods based on Alignment by Wikipedia Anchors and Alignment by Entity Names in <cite>(Wang et al., 2014a)</cite> respectively."
  ],
  "y": "uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_11",
  "x": [
   "For triplet classification, a large dataset provided by <cite>(Wang et al., 2014a )</cite> is used as the knowledge base."
  ],
  "y": "uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_12",
  "x": [
   "Following the settings in <cite>(Wang et al., 2014a)</cite> , we apply the same preprocessing steps, including sentence segmentation, tokenization, and named entity recognition."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_13",
  "x": [
   "It is used in (Socher et al., 2013; Wang et al., 2014b; <cite>Wang et al., 2014a)</cite> .",
   "We follow the same protocol in <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_14",
  "x": [
   "We follow the same protocol in <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_15",
  "x": [
   "<cite>Wang et al. (2014a)</cite> confirm this observation and show that jointly embedding brings further encouraging improvement over TransE. In this experiment, we follow the same settings as <cite>(Wang et al., 2014a)</cite> to investigate the performance of our new alignment model."
  ],
  "y": "motivation uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_16",
  "x": [
   "We use the same public dataset NYT+FB, released by Riedel et al. (2010) and used in and <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_17",
  "x": [
   "Since both Mintz and MIML are probabilistic models, we use the same method in <cite>(Wang et al., 2014a)</cite> to linearly combine the scores."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_18",
  "x": [
   "We use the original dataset released by (Mikolov et al., 2013b) and follow the same evaluation protocol of <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_19",
  "x": [
   "(3) We further verify that \"Jointly(name)\", i.e., using entity names for alignment, indeed pollutes word embeddings, which is consistent with the reports in <cite>(Wang et al., 2014a)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "08c64c92b77dbd9e999092a2fec3d1_20",
  "x": [
   "The above four experiments are consistent in results: without using any anchor information, alignment by entity description is able to achieve better or comparable performance, compared to alignment by Wikipedia anchors proposed by <cite>Wang et al. (2014a)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "08d3f7a0938ab85d9a251b6a2364ed_0",
  "x": [
   "They define a deduction system for (an isomorphic variant of)<cite> Attardi's (2006)</cite> transition system, which covers a subset of non-projective trees."
  ],
  "y": "background"
 },
 {
  "id": "08d3f7a0938ab85d9a251b6a2364ed_4",
  "x": [
   "We now introduce the widely-used<cite> Attardi (2006)</cite> system, which includes transitions that create arcs between non-consecutive subtrees, thus allowing it to produce some non-projective trees."
  ],
  "y": "background"
 },
 {
  "id": "08d3f7a0938ab85d9a251b6a2364ed_5",
  "x": [
   "As shown in Fig. 1 ,<cite> Attardi's (2006)</cite> system has two degree-2 transitions (re s 0 ,s 2 and re s 2 ,s 0 ) that allow it to cover 87.24% of the nonprojective trees in UD 2.1."
  ],
  "y": "background"
 },
 {
  "id": "08d3f7a0938ab85d9a251b6a2364ed_6",
  "x": [
   "A key observation is that a degree-D Attardi system does not contain all possible transitions of degree within D. Since prior empirical work has ascertained that transition systems using more transitions with degree greater than 1 can handle more non-projective treebank trees <cite>(Attardi, 2006</cite>; G\u00f3mez-Rodr\u00edguez, 2016) , we hypothesize that adding some of these \"missing\" reduce transitions into the system's inventory should increase coverage."
  ],
  "y": "background"
 },
 {
  "id": "08d3f7a0938ab85d9a251b6a2364ed_7",
  "x": [
   "Since each such deduction rule corresponds to a reduce transition, each revision to the deduction system yields a variant of<cite> Attardi's (2006)</cite> parser."
  ],
  "y": "background"
 },
 {
  "id": "08d3f7a0938ab85d9a251b6a2364ed_8",
  "x": [
   "On the other hand, since their addition doesn't affect the asymptotic run-time, we define ALLDEG1 to include all five degree-1 transitions from R into the<cite> Attardi (2006)</cite> system."
  ],
  "y": "uses"
 },
 {
  "id": "09493a62815b4b826248d6d9be47cb_0",
  "x": [
   "However, while these tools have proven to be effective for patient records and research papers, they achieve moderate results on social media texts (Nikfarjam et al., 2015;<cite> Limsopatham and Collier, 2016)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "09493a62815b4b826248d6d9be47cb_1",
  "x": [
   "<cite>Limsopatham and Collier (2016)</cite> utilized convolutional neural networks (CNNs) for phrase normalization in user reviews, while Tutubalina et al. (2018) , Han et al. (2017) , and Belousov et al. (2017) applied recurrent neural networks (RNNs) to UGTs, achieving similar results."
  ],
  "y": "background"
 },
 {
  "id": "09493a62815b4b826248d6d9be47cb_2",
  "x": [
   "These tasks are devoted to the normalization of (1)<cite> (Limsopatham and Collier, 2016)</cite> 73.39 ----CNN<cite> (Limsopatham and Collier, 2016)</cite> 81.41 ----RNN<cite> (Limsopatham and Collier, 2016)</cite> 79.98 ----Attentional Char-CNN (Niu et al., 2018) 84.65 ----Hierarchical Char-CNN (Han et al., 2017) - Table 2 : The performance of the proposed models and the state-of-the-art methods in terms of accuracy."
  ],
  "y": "background"
 },
 {
  "id": "0984f12a6fea858c7f18263cc2fb01_0",
  "x": [
   "This task has only received attention in a monolingual English setting, helped by the availability of English datasets, e.g. Flickr8K (Hodosh et al., 2013) , Flickr30K <cite>(Young et al., 2014)</cite> , and MS COCO (Chen et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "0984f12a6fea858c7f18263cc2fb01_1",
  "x": [
   "Multi30K is an extension of the Flickr30K dataset <cite>(Young et al., 2014)</cite> with 31,014 German translations of English descriptions and 155,070 independently collected German descriptions."
  ],
  "y": "extends"
 },
 {
  "id": "0984f12a6fea858c7f18263cc2fb01_2",
  "x": [
   "The Flickr30K Dataset contains 31,014 images sourced from online photo-sharing websites <cite>(Young et al., 2014)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "0984f12a6fea858c7f18263cc2fb01_3",
  "x": [
   "The Flickr30K Dataset contains 31,014 images sourced from online photo-sharing websites <cite>(Young et al., 2014)</cite> ."
  ],
  "y": "extends background"
 },
 {
  "id": "0984f12a6fea858c7f18263cc2fb01_4",
  "x": [
   "The descriptions were collected as similarly as possible to the original Flickr30K dataset by translating the instructions used by<cite> Young et al. (2014)</cite> into German."
  ],
  "y": "uses"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_0",
  "x": [
   "Syntactic analysis of search queries is important for a variety of tasks including better query refinement, improved matching and better ad targeting<cite> (Barr et al., 2008)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_1",
  "x": [
   "However, search queries differ substantially from traditional forms of written language (e.g., no capitalization, few function words, fairly free word order, etc.), and are therefore difficult to process with natural language processing tools trained on standard corpora<cite> (Barr et al., 2008)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_2",
  "x": [
   "As a reference, <cite>Barr et al. (2008)</cite> report 79.3% when annotating queries with 19 POS tags."
  ],
  "y": "uses"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_3",
  "x": [
   "As a reference, <cite>Barr et al. (2008)</cite> report 79.3% when annotating queries with 19 POS tags."
  ],
  "y": "differences"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_4",
  "x": [
   "This is consistent with the analysis in <cite>Barr et al. (2008)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_5",
  "x": [
   "This is consistent with the analysis in <cite>Barr et al. (2008)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_6",
  "x": [
   "5 Related Work <cite>Barr et al. (2008)</cite> manually annotate a corpus of 2722 queries with 19 POS tags and use it to train and evaluate POS taggers, and also describe the linguistic structures they find."
  ],
  "y": "background"
 },
 {
  "id": "0a226accf1fa8b471176916a76f1c6_7",
  "x": [
   "5 Related Work <cite>Barr et al. (2008)</cite> manually annotate a corpus of 2722 queries with 19 POS tags and use it to train and evaluate POS taggers, and also describe the linguistic structures they find."
  ],
  "y": "background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_0",
  "x": [],
  "y": "background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_1",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_2",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_3",
  "x": [
   "In Spanish and Bulgarian projected data extracted by<cite> Ganchev et al. (2009)</cite> In this paper, we present a dependency parsing algorithm which can train on partial projected parses and can take rich syntactic information as features for learning."
  ],
  "y": "background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_4",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_5",
  "x": [
   "While Hwa et al. (2005) requires full projected parses to train their parser,<cite> Ganchev et al. (2009)</cite> and Jiang and Liu (2010) can learn from partially projected trees.",
   "However, the discriminative training in<cite> (Ganchev et al., 2009</cite> ) doesn't allow for richer syntactic context and it doesn't learn from all the relations in the partial dependency parse."
  ],
  "y": "motivation background"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_6",
  "x": [
   "We evaluated our system (section 5) on Bulgarian and Spanish projected dependency data used in<cite> (Ganchev et al., 2009</cite> ) for comparison."
  ],
  "y": "extends"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_7",
  "x": [
   "While the Hindi projected treebank was obtained using the method described in section 4, Bulgarian and Spanish projected datasets were obtained using the approach in<cite> (Ganchev et al., 2009)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_8",
  "x": [
   "The datasets of Bulgarian and Spanish that contributed to the best accuracies for<cite> Ganchev et al. (2009)</cite> were used in our work (7 rules dataset for Bulgarian and 3 rules dataset for Spanish)."
  ],
  "y": "uses"
 },
 {
  "id": "0a7710557d020087035f4a94b5661c_9",
  "x": [
   "For Bulgarian and Spanish, we used the same test data that was used in the work of<cite> Ganchev et al. (2009)</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "0c2f7cea9f27b4799736fbcba48192_0",
  "x": [
   "It has furthermore proven to be useful for sentiment analysis, emotion recognition and irony detection <cite>(Felbo et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "0c2f7cea9f27b4799736fbcba48192_1",
  "x": [
   "We observed a performance improvement over competitive baselines such as FastText (FT) (Joulin et al., 2017) and Deepmoji <cite>(Felbo et al., 2017)</cite> , which is most noticeable in the case of infrequent emojis."
  ],
  "y": "differences"
 },
 {
  "id": "0c2f7cea9f27b4799736fbcba48192_2",
  "x": [
   "Our base architecture is the Deepmoji model <cite>(Felbo et al., 2017)</cite> , which is based on two stacked word-based bi-directional LSTM recurrent neural networks with skip connections between the first and the second LSTM."
  ],
  "y": "uses"
 },
 {
  "id": "0c2f7cea9f27b4799736fbcba48192_3",
  "x": [
   "In<cite> Felbo et al. (2017)</cite> , attention is computed as follows:"
  ],
  "y": "background"
 },
 {
  "id": "0c2f7cea9f27b4799736fbcba48192_4",
  "x": [
   "In<cite> Felbo et al. (2017)</cite> , attention is computed as follows:"
  ],
  "y": "uses"
 },
 {
  "id": "0c2f7cea9f27b4799736fbcba48192_5",
  "x": [
   "In order to put our proposed labelwise attention mechanism in context, we compare its performance with a set of baselines: (1 <cite>(Felbo et al., 2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_0",
  "x": [
   "Consequently, many strategies are proposed to balance the IV and OOV performance (Goh et al., 2005) , <cite>(Zhang et al., 2006a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_1",
  "x": [
   "Among these strategies, the confidence measure used to combine the results of CT and DS is a straight-forward one, which is introduced in <cite>(Zhang et al., 2006a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_2",
  "x": [
   "The basic assumption of such combination is that DS method performs better on IV words and <cite>Zhang derives</cite> this belief from the fact that DS achieves higher IV recall rate as Table 1 shows."
  ],
  "y": "background"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_3",
  "x": [
   "Furthermore, our error analysis on the results of combination reveals that confidence measure in <cite>(Zhang et al., 2006a)</cite> has a representation flaw and we propose an EIV tag method to revise it."
  ],
  "y": "motivation"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_6",
  "x": [
   "Here, the term \"dictionary-based\" is exactly the method implemented in <cite>(Zhang et al., 2006a)</cite> , it does not mean the generative language model in general."
  ],
  "y": "uses"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_7",
  "x": [
   "In <cite>(Zhang et al., 2006a)</cite> , the above CT method is developed as subword-based tagging."
  ],
  "y": "background"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_10",
  "x": [
   "Here, we repeat two experiments described in <cite>(Zhang et al., 2006a)</cite> , namely dictionary-based approach and subword-based tagging."
  ],
  "y": "uses"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_11",
  "x": [
   "Based on IV and OOV recall as we show in Table 1 , <cite>Zhang argues</cite> that the DS performs better on IV word identification while CT performs better on OOV words. But we can see from the results in Table 6 (the lines about DS and CT), the IV precision of DS approach is much lower than that of CT on all the four corpora, which also causes a lower F measure of IV."
  ],
  "y": "differences"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_12",
  "x": [
   "We show in this section that there is a representation flaw in the formula of confidence measure in <cite>(Zhang et al., 2006a )</cite>."
  ],
  "y": "motivation"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_13",
  "x": [
   "When both results of CT and DS are available, the CM can be calculated according to the following formula in <cite>(Zhang et al., 2006a)</cite> :"
  ],
  "y": "background"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_14",
  "x": [
   "In the experiment of this paper, MP is used as CM because it is equivalent to <cite>Zhang\"s CM</cite> but more convenient to express."
  ],
  "y": "similarities"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_15",
  "x": [
   "We repeat the experiments about CM in <cite>Zhang\"s paper</cite> <cite>(Zhang et al., 2006a)</cite> and show that there is a representation flaw in the CM formula."
  ],
  "y": "uses motivation"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_16",
  "x": [
   "In this paper, \uf061 = 0.8 and t = 0.7 (Parameters in two papers, <cite>Zhang et al. 2006a</cite> and Zhang et al. 2006b , are different. And our parameters are consistent with Zhang et al. 2006b which is confirmed by Dr Zhang through email) are used in CM, namely MP= 0.875 is the threshold."
  ],
  "y": "differences"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_17",
  "x": [
   "Table 5 illustrates that, after combining the two results, most original errors on IV words are corrected because DS can achieve higher IV recall as described in <cite>Zhang\"s paper</cite>. But on OOV part, more new errors are introduced by CM and these new errors decrease the precision of the IV words."
  ],
  "y": "background"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_18",
  "x": [
   "We can see from the Table 5 columns about EIV, there are more errors eliminated than the new errors introduced after EIV condition added into CM and most CT tags of subwords contained in OOV words maintained unchanged as we supposed. And then, our results (in Table  6 lines about EIV) are comparable with that in <cite>Zhang\"s paper</cite>."
  ],
  "y": "similarities"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_20",
  "x": [
   "Even on IV word, this pure CT approach outperforms <cite>Zhang\"s CT method</cite> and produces comparable results with combination with EIV tags, which shows that pure CT method can perform well on IV words too."
  ],
  "y": "differences"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_21",
  "x": [
   "Table 6 Results of different approach used in our experiments (White background lines are the results we repeat <cite>Zhang\"s methods</cite> and they have some trivial difference with Table 1. ) Therefore, the most important thing worth to pay attention in future study is how to integrate linguistic information into the statistical model effectively, no matter character or word information."
  ],
  "y": "differences uses"
 },
 {
  "id": "0c8a99cac11953f26308128bfc058b_22",
  "x": [
   "Furthermore, our experiments show that confidence measure in <cite>Zhang\"s paper</cite> has a representation flaw and we propose an EIV tag method to revise the combination."
  ],
  "y": "motivation"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_0",
  "x": [
   "Recently, the mechanism of self-attention<cite> [22,</cite> 24] was proposed, which uses the whole sequence at once to model feature interactions that are arbitrarily distant in time."
  ],
  "y": "background"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_1",
  "x": [
   "Its use in both encoder-decoder and feedforward contexts has led to faster training and state-of-the-art results in translation (via the Transformer<cite> [22]</cite> ), sentiment analysis [25] , and other tasks."
  ],
  "y": "background"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_2",
  "x": [
   "Our proposed framework ( Figure 1a ) is built around self-attention layers, as used in the Transformer encoder<cite> [22]</cite> , previous explorations of self-attention in ASR [19, 27] , and defined in Section 2.3."
  ],
  "y": "similarities uses"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_3",
  "x": [
   "Maximum path length Table 1 : Operation complexity of each layer type, based on<cite> [22]</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_4",
  "x": [
   "The first sublayer performs multi-head, scaled dot-product, self-attention<cite> [22]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_5",
  "x": [
   "The second sublayer is a position-wise feed-forward network<cite> [22]</cite> FFN(H) = ReLU(HW1 + b1)W2 + b2 where parameters"
  ],
  "y": "background"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_6",
  "x": [
   "Self-attention is inherently content-based<cite> [22]</cite> , and so one often encodes position into the post-embedding vectors."
  ],
  "y": "background"
 },
 {
  "id": "0e4deda746127b97f68080bc8f13c8_7",
  "x": [
   "As self-attention architectures can be unstable in early training, we clip gradients to a global norm of 1 and use the standard linear warmup period before inverse square decay associated with these architectures [19, <cite>22]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_0",
  "x": [
   "In our previous work <cite>[7]</cite> , we applied a dual RNN in order to obtain a richer representation by blending the content and acoustic knowledge."
  ],
  "y": "background"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_1",
  "x": [
   "In our previous work <cite>[7]</cite> , we applied a dual RNN in order to obtain a richer representation by blending the content and acoustic knowledge."
  ],
  "y": "extends"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_2",
  "x": [
   "Recently,<cite> [7,</cite> 18] combined acoustic information and conversation transcripts using a neural network-based model to improve emotion classification accuracy."
  ],
  "y": "background"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_3",
  "x": [
   "Motivated by the architecture used in<cite> [7,</cite> 17, 19] , we train a recurrent encoder to predict the categorical class of a given audio signal."
  ],
  "y": "motivation"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_4",
  "x": [
   "To follow previous research <cite>[7]</cite> , we also add another prosodic feature vector, p, with each ot to generate a more informative vector representation of the signal, o A t ."
  ],
  "y": "uses"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_5",
  "x": [
   "Previous research used multi-modal information independently using neural network model by concatenating features from each modality<cite> [7,</cite> 21] ."
  ],
  "y": "background"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_6",
  "x": [
   "Previous research used multi-modal information independently using neural network model by concatenating features from each modality<cite> [7,</cite> 21] ."
  ],
  "y": "differences"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_7",
  "x": [
   "For consistent comparison with previous works<cite> [7,</cite> 18] , all utterances labeled \"excitement\" are merged with those labeled \"happiness\"."
  ],
  "y": "uses"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_8",
  "x": [
   "As this research is extended work from previous research <cite>[7]</cite> , we use the same feature extraction method as done in our previous work."
  ],
  "y": "extends"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_9",
  "x": [
   "We use the same dataset and features as other researchers<cite> [7,</cite> 18] ."
  ],
  "y": "uses"
 },
 {
  "id": "0fd26c6dffab3fba2d120d2c58dff6_10",
  "x": [
   "In audio-BRE ( Fig. 2(a) ), most of the emotion labels are frequently misclassified as neutral class, supporting the claims of<cite> [7,</cite> 25] ."
  ],
  "y": "similarities"
 },
 {
  "id": "0fd87fbdbe64e7d002ca31783448fb_0",
  "x": [
   "Many researches have been conducted to involve AI into poem generation [Zhang and Lapata, 2014; Cheng et al., 2018] , creation of classical or pop music<cite> [Manzelli et al., 2018</cite>; Hadjeres et al., 2017] and automatic images generation [van den Oord et al., 2016; Yan et al., 2016; Xu et al., 2018] ."
  ],
  "y": "background"
 },
 {
  "id": "0fd87fbdbe64e7d002ca31783448fb_1",
  "x": [
   "We adopted open-source software jieba 2 for Chinese and Stanford parser<cite> [Toutanova and Manning, 2000]</cite> for English POS tagging."
  ],
  "y": "uses"
 },
 {
  "id": "0fd87fbdbe64e7d002ca31783448fb_2",
  "x": [
   "As imagination is the soul for artistic Mind Map, Mappa Mundi employs several features to increase information variety<cite> [Liu et al., 2019]</cite> during topic expansion."
  ],
  "y": "background"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_0",
  "x": [
   "However, like more recent approaches <cite>(Artetxe et al., 2017)</cite> , our model operates directly over pretrained word embeddings, induces a joint cross-lingual embedding space, and scales to large vocabulary sizes."
  ],
  "y": "similarities"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_1",
  "x": [
   "To this end, we provide a reinterpretation of<cite> Artetxe et al. (2017)</cite> as a latent-variable model with an IBM Model 1-style (Brown et al., 1993 ) dictionary prior, which allows a clean side-by-side analytical comparison."
  ],
  "y": "extends"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_2",
  "x": [
   "Viewed in this light, the difference between our approach and<cite> Artetxe et al. (2017)</cite> , the strongest baseline, is whether one-to-one alignments or one-to-many alignments are admitted between the words of the languages' respective lexicons."
  ],
  "y": "differences"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_3",
  "x": [
   "Thus, we conclude that our hard constraint on one-to-one alignments is primarily responsible for the improvements over<cite> Artetxe et al. (2017)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_4",
  "x": [
   "As for assumption (ii), previous work (Xing et al., 2015;<cite> Artetxe et al., 2017)</cite> has achieved some success using an orthogonal transformation; recently, however, demonstrated that monolingual embedding spaces are not approximately isomorphic and that there is a complex relationship between word form and meaning, which is only inadequately modeled by current approaches, which for example cannot model polysemy."
  ],
  "y": "background"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_5",
  "x": [
   "As for assumption (ii), previous work (Xing et al., 2015;<cite> Artetxe et al., 2017)</cite> has achieved some success using an orthogonal transformation; recently, however, demonstrated that monolingual embedding spaces are not approximately isomorphic and that there is a complex relationship between word form and meaning, which is only inadequately modeled by current approaches, which for example cannot model polysemy."
  ],
  "y": "background uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_6",
  "x": [
   "We additionally enforce the constraint that \u2126 is a real orthogonal matrix, i.e., \u2126 \u2126 = I. Previous work (Xing et al., 2015;<cite> Artetxe et al., 2017)</cite> found that the orthogonality constraint leads to noticeable improvements."
  ],
  "y": "background uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_7",
  "x": [
   "The self-training method of<cite> Artetxe et al. (2017)</cite> , our strongest baseline in \u00a76, may also be interpreted as a latent-variable model in the spirit of our exposition in \u00a73."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_8",
  "x": [
   "We show how this corresponds to an alignment distribution that is equivalent to IBM Model 1 (Brown et al., 1993) , and that<cite> Artetxe et al. (2017)</cite> 's selftraining method is actually a form of Viterbi EM."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_9",
  "x": [
   "To formalize<cite> Artetxe et al. (2017)</cite> 's contribution as a latent-variable model, we lay down some more notation."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_10",
  "x": [
   "Why a Reinterpretation? The reinterpretation of<cite> Artetxe et al. (2017)</cite> as a probabilistic model yields a clear analytical comparison between our method and theirs."
  ],
  "y": "extends"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_11",
  "x": [
   "Why a Reinterpretation? The reinterpretation of<cite> Artetxe et al. (2017)</cite> as a probabilistic model yields a clear analytical comparison between our method and theirs."
  ],
  "y": "differences extends"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_12",
  "x": [
   "Datasets For bilingual dictionary induction, we use the English-Italian dataset by and the English-German and English-Finnish datasets by<cite> Artetxe et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_13",
  "x": [
   "We follow<cite> Artetxe et al. (2017)</cite> and train monolingual embeddings with word2vec, CBOW, and negative sampling (Mikolov et al., 2013a ) on a 2.8 billion word corpus for English (ukWaC + Wikipedia + BNC), a 1.6 billion word corpus for Italian (itWaC), a 0.9 billion word corpus for German (SdeWaC), and a 2.8 billion word corpus for Finnish (Common Crawl)."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_14",
  "x": [
   "Seed dictionaries Following<cite> Artetxe et al. (2017)</cite>, we use dictionaries of 5,000 words, 25 words, and a numeral dictionary consisting of words matching the [0-9]+ regular expression in both vocabularies."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_15",
  "x": [
   "Implementation details Similar to<cite> Artetxe et al. (2017)</cite> , we stop training when the improvement on the average cosine similarity for the induced dictionary is below 1 \u00d7 10 \u22126 between succeeding iterations."
  ],
  "y": "similarities"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_16",
  "x": [
   "Finally, we compare with Artetxe et al. (2016) who add dimension-wise mean centering to Xing et al. (2015) , and<cite> Artetxe et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_17",
  "x": [
   "Both Mikolov et al. (2013c) and<cite> Artetxe et al. (2017)</cite> are special cases of our famework and comparisons to these approaches thus act as an ablation study."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_18",
  "x": [
   "Likewise, as discussed in \u00a75,<cite> Artetxe et al. (2017)</cite> make use of a Viterbi EM style algorithm with a different prior over edge sets."
  ],
  "y": "background"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_19",
  "x": [
   "12 Training takes a similar amount of time as <cite>(Artetxe et al., 2017)</cite> due to faster convergence."
  ],
  "y": "similarities"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_20",
  "x": [
   "On cross-lingual word similarity, our approach yields the best performance on WordSim-353 and RG-65 for English-German and is only outperformed by<cite> Artetxe et al. (2017)</cite> on English-Italian Wordsim-353."
  ],
  "y": "differences"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_21",
  "x": [
   "We show the target language words with the highest hubness using our method and<cite> Artetxe et al. (2017)</cite> for English-German with a 5,000 seed lexicon and the full vocabulary in Table 3 ."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_22",
  "x": [
   "17 Hubs are fewer and occur less often with our method, demonstrating that the prior-to some en-tr en-bn en-hi et-fi<cite> Artetxe et al. (2017)</cite> extent-aids with resolving hubness."
  ],
  "y": "differences"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_23",
  "x": [
   "We perform experiments with our method with and without a rank constraint and<cite> Artetxe et al. (2017)</cite> for three truly lowresource language pairs, English-{Turkish, Bengali, Hindi}. We additionally conduct an experiment for Estonian-Finnish, similarly to ."
  ],
  "y": "uses"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_24",
  "x": [
   "Surprisingly, the method by<cite> Artetxe et al. (2017)</cite> a similar self-learning method that uses word embeddings, with an implicit one-to-many alignment based on nearest neighbor queries."
  ],
  "y": "similarities"
 },
 {
  "id": "10319b67b6fcc1870791cf67b39299_25",
  "x": [
   "We have presented a novel latent-variable model for bilingual lexicon induction, building on the work of<cite> Artetxe et al. (2017)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_0",
  "x": [
   "To compensate for the absence of direct supervision, work in crosslingual learning and distant supervision has discovered creative use for a number of alternative data sources to learn feasible models: -aligned parallel corpora to project POS annotations to target languages (Yarowsky et al., 2001; Agi\u0107 et al., 2015; Fang and Cohn, 2016) , -noisy tag dictionaries for type-level approximation of full supervision<cite> (Li et al., 2012)</cite> , -combination of projection and type constraints (Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013) , -rapid annotation of seed training data ."
  ],
  "y": "background"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_1",
  "x": [
   "To compensate for the absence of direct supervision, work in crosslingual learning and distant supervision has discovered creative use for a number of alternative data sources to learn feasible models: -aligned parallel corpora to project POS annotations to target languages (Yarowsky et al., 2001; Agi\u0107 et al., 2015; Fang and Cohn, 2016) , -noisy tag dictionaries for type-level approximation of full supervision<cite> (Li et al., 2012)</cite> , -combination of projection and type constraints (Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013) , -rapid annotation of seed training data ."
  ],
  "y": "motivation"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_2",
  "x": [
   "Dictionaries are a useful source for distant supervision<cite> (Li et al., 2012</cite>; T\u00e4ckstr\u00f6m et al., 2013) .",
   "There are several ways to exploit such information: i) as type constraints during encoding (T\u00e4ckstr\u00f6m et al., 2013) , ii) to guide unsupervised learning<cite> (Li et al., 2012)</cite> , or iii) as additional signal at training."
  ],
  "y": "background"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_3",
  "x": [
   "Dictionaries are a useful source for distant supervision<cite> (Li et al., 2012</cite>; T\u00e4ckstr\u00f6m et al., 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_4",
  "x": [
   "We evaluate two dictionary sources, motivated by ease of accessibility to many languages: WIK-TIONARY, a word type dictionary that maps tokens to one of the 12 Universal POS tags<cite> (Li et al., 2012</cite>; Petrov et al., 2012) ; and UNIMORPH, a morphological dictionary that provides inflectional paradigms across 350 languages (Kirov et al., 2016) ."
  ],
  "y": "uses"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_5",
  "x": [
   "For Wiktionary, we use the freely available dictionaries from <cite>Li et al. (2012)</cite> and ."
  ],
  "y": "uses"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_6",
  "x": [
   "-LI: Wiktionary supervision<cite> (Li et al., 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_7",
  "x": [
   "On the test sets (Table 4 , right) DSDS reaches 87.2 over 8 test languages intersecting <cite>Li et al. (2012)</cite> and Agi\u0107 et al. (2016) ."
  ],
  "y": "similarities"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_8",
  "x": [
   "This is in slight contrast to 50 iterations that <cite>Li et al. (2012)</cite> recommend, although selecting 50 does not dramatically hurt the scores; ii) Our replication falls \u223c5 points short of their 84.9 accuracy."
  ],
  "y": "differences"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_9",
  "x": [
   "There is a large 33-point accuracy gap between the scores of <cite>Li et al. (2012)</cite> , where the dictionaries are large, and the other languages in Figure 4 , with smaller dictionaries."
  ],
  "y": "background"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_10",
  "x": [
   "Most successful work on low-resource POS tagging is based on projection (Yarowsky et al., 2001) , tag dictionaries<cite> (Li et al., 2012)</cite> , annotation of seed training data or even more recently some combination of these, e.g., via multi-task learning (Fang and not <cite>Li et al. (2012)</cite> Figure 4: The performance of LI with our dictionary data over EM iterations, separate for the languages from <cite>Li et al. (2012)</cite> and all the remaining languages in Table 1 . Cohn, 2016; Kann et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "1042e7b6ef7b73f29ad75b193f9e3b_11",
  "x": [
   "Most successful work on low-resource POS tagging is based on projection (Yarowsky et al., 2001) , tag dictionaries<cite> (Li et al., 2012)</cite> , annotation of seed training data or even more recently some combination of these, e.g., via multi-task learning (Fang and not <cite>Li et al. (2012)</cite> Figure 4: The performance of LI with our dictionary data over EM iterations, separate for the languages from <cite>Li et al. (2012)</cite> and all the remaining languages in Table 1 . Cohn, 2016; Kann et al., 2018) ."
  ],
  "y": "differences extends"
 },
 {
  "id": "10acbeba830b2f8b3feb30de542c56_0",
  "x": [
   "The Touchdown dataset <cite>(Chen et al., 2019)</cite> provides instructions by human annotators for navigation through New York City streets and for resolving spatial descriptions at a given location."
  ],
  "y": "background"
 },
 {
  "id": "10acbeba830b2f8b3feb30de542c56_2",
  "x": [
   "To address this, recent tasks based on simulated environments include photo-realistic visual input, such as Room-to-Room (R2R; Anderson et al., 2018) , Talk-the-Walk (de Vries et al., 2018) and Touchdown <cite>(Chen et al., 2019)</cite> , all of which rely on panorama photos."
  ],
  "y": "background"
 },
 {
  "id": "10acbeba830b2f8b3feb30de542c56_3",
  "x": [
   "We re-implement the best-reported models on the navigation and spatial description resolution tasks from<cite> Chen et al. (2019)</cite> to compare performance with our data release to the original Touchdown paper."
  ],
  "y": "uses"
 },
 {
  "id": "10acbeba830b2f8b3feb30de542c56_4",
  "x": [
   "Following<cite> Chen et al. (2019)</cite> , we report mean distance error and accuracy with different thresholds (40px, 80px, and 120px), which measures the proportion of evaluation items where the pixel chosen by the model is within the specified pixel distance."
  ],
  "y": "uses"
 },
 {
  "id": "10acbeba830b2f8b3feb30de542c56_6",
  "x": [
   "TC, SPD, and SED are defined in<cite> Chen et al. (2019)</cite> and nDTW and SDTW are defined in Ilharco et al. (2019) ."
  ],
  "y": "background"
 },
 {
  "id": "1265a336e56a4535f0a904ca89b220_0",
  "x": [
   "The Google Books Ngram corpus (GBN; Michel et al. (2011 ), Lin et al. (2012 ) is used in most of the studies we already mentioned, including our current study and its predecessor <cite>(Hellrich and Hahn, 2016a)</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "1265a336e56a4535f0a904ca89b220_1",
  "x": [
   "It is thus a continuation of prior work, in which we investigated historical English texts only <cite>(Hellrich and Hahn, 2016a)</cite> , and also influenced by the design decisions of Kim et al. (2014) and Kulkarni et al. (2015) which were the first to use word embeddings in diachronic studies."
  ],
  "y": "background"
 },
 {
  "id": "1265a336e56a4535f0a904ca89b220_2",
  "x": [
   "SGNS is preferred in general, yet SGHS showed slight benefits in some reliability scenarios in our prior investigations <cite>(Hellrich and Hahn, 2016a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1265a336e56a4535f0a904ca89b220_3",
  "x": [
   "We nevertheless discourage using samples instead of full corpora, as we observed extremely low reliability values between different samples <cite>(Hellrich and Hahn, 2016a)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "1265a336e56a4535f0a904ca89b220_5",
  "x": [
   "We processed the full subcorpora for each time span, due to the extremely low reliability values between samples we observed in previous investigations <cite>(Hellrich and Hahn, 2016a)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "1265a336e56a4535f0a904ca89b220_6",
  "x": [
   "Reliability at different top-n cut-offs is very similar for all languages and time spans under scrutiny, confirming previous observations in<cite> Hellrich and Hahn (2016a)</cite> and strengthening the suggestion to use only top-1 reliability for evaluation."
  ],
  "y": "similarities"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_0",
  "x": [
   "When combined with our two-stage fine-tuning pipeline, our method achieves improved common sense reasoning and state-of-the-art perplexity on the WritingPrompts<cite> (Fan et al., 2018)</cite> story generation dataset."
  ],
  "y": "uses"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_1",
  "x": [
   "When fine-tuning is combined with multi-task learning in a two-stage pipeline, we improve the model's CSR and outperform state-of-the-art perplexity on the WritingPrompts<cite> (Fan et al., 2018)</cite> Our primary task is to perform language modeling (Elman, 1990; Bengio et al., 2003; Dai and Le, 2015) on the WritingPrompts dataset."
  ],
  "y": "uses"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_2",
  "x": [
   "WritingPrompts<cite> (Fan et al., 2018</cite> ) is a dataset of prompts and short stories crawled from Reddit."
  ],
  "y": "background"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_3",
  "x": [
   "Because GPT2 uses subword tokenization (Sennrich et al., 2016) , it is not directly comparable to the wordlevel perplexity obtained in<cite> Fan et al. (2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_4",
  "x": [
   "Prompt ranking<cite> (Fan et al., 2018)</cite> assesses how well a model matches a story to its given prompt."
  ],
  "y": "background"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_5",
  "x": [
   "Following<cite> Fan et al. (2018)</cite> , we count a random story sample as correct when it ranks the true prompt with the lowest perplexity."
  ],
  "y": "uses"
 },
 {
  "id": "13fe4afa75c5a02727cb8ce3a73297_7",
  "x": [
   "Story Generation: Recent work in neural story generation (Kiros et al., 2015; Roemmele, 2016) has shown success in using hierarchical methods (Yao et al., 2018; <cite>Fan et al., 2018)</cite> to generate stories."
  ],
  "y": "background"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_0",
  "x": [
   "In particular, the method of <cite>Chen and Manning (2014)</cite> is the same as our NN baseline."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_1",
  "x": [
   "In particular, the method of <cite>Chen and Manning (2014)</cite> is the same as our NN baseline."
  ],
  "y": "similarities"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_2",
  "x": [
   "Recently, <cite>Chen and Manning (2014)</cite> use a neural network (NN) to replace linear models, and report improved accuracies."
  ],
  "y": "background"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_3",
  "x": [
   "We take <cite>Chen and Manning (2014)</cite> , which uses the arc-standard transition system (Nivre, 2008) ."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_4",
  "x": [
   "We take <cite>Chen and Manning (2014)</cite> , which uses the arc-standard transition system (Nivre, 2008) .",
   "<cite>Chen and Manning (2014)</cite> can be viewed as a neutral alternative of MaltParser (Nivre, 2008) ."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_5",
  "x": [
   "Following <cite>Chen and Manning (2014)</cite> , training of all the models using a cross-entropy loss objective with a L2-regularization, and mini-batched AdaGrad (Duchi et al., 2011) ."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_6",
  "x": [
   "We take the Neural model of <cite>Chen and Manning (2014)</cite> as another baseline (Figure 1(b) )."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_7",
  "x": [
   "We use the arc-standard features \u03a6 e as <cite>Chen and Manning (2014)</cite> , which is also based on the arc-eager templates of Zhang and Nivre (2011) , similar to those of the baseline model L."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_8",
  "x": [
   "Following <cite>Chen and Manning (2014)</cite> , we use the pre-trained word embedding released by Collobert et al. (2011) , and set h = 200 for the hidden layer size, \u03bb = 10 \u22128 for L2 regularization, and \u03b1 = 0.01 for the initial learning rate of Adagrad."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_9",
  "x": [
   "<cite>Chen and Manning (2014)</cite> fine-tune word embeddings in supervised training, consistent with Socher et al. (2013) ."
  ],
  "y": "background"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_10",
  "x": [
   "Note also tat for all experiments, the POS and label embedding features of <cite>Chen and Manning (2014)</cite> are fine-tuned, consistent with their original method."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_11",
  "x": [
   "We test the effect of dropout (Hinton et al., 2012) during training, using a default ratio of 0.5 according to <cite>Chen and Manning (2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_12",
  "x": [
   "Our logistic regression linear parser and re-implementation of <cite>Chen and Manning (2014)</cite> give comparable accuracies to the perceptron ZPar 2 and Stanford NN Parser 3 , respectively."
  ],
  "y": "similarities uses"
 },
 {
  "id": "14fa8c3b947667244d30dd30dae89a_13",
  "x": [
   "Our parser enjoys the fast speed of deterministic parsers, and in particular the baseline NN parser<cite> (Chen and Manning, 2014)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "1781b27c13dca15752cb6aa8a9fc38_0",
  "x": [
   "This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process , Chinese restaurant process (Blei et al., 2010) , hierarchical Pitman-Yor process (Teh, 2006) , Indian buffet process (Ghahramani and Griffiths, 2005) , recurrent neural network (Mikolov et al., 2010; Van Den Oord et al., 2016) , long short-term memory (Hochreiter and Schmidhuber, 1997; , sequence-to-sequence model (Sutskever et al., 2014), variational auto-encoder (Kingma and Welling, 2014) , generative adversarial network (Goodfellow et al., 2014) , attention mechanism (Chorowski et al., 2015; Seo et al., 2016) , memory-augmented neural network (Graves et al., 2014; Graves et al., 2014) , stochastic neural network <cite>Miao et al., 2016)</cite> , predictive state neural network (Downey et al., 2017) , policy gradient (Yu et al., 2017) and reinforcement learning (Mnih et al., 2015) ."
  ],
  "y": "uses background"
 },
 {
  "id": "1786b6c1c6532d5baa092cca40e389_0",
  "x": [
   "Corpora combining semantic and syntactic annotations constitute the backbone for the development of probabilistic models that automatically identify the semantic relationships, or semantic roles, conveyed by sentential constituents<cite> (Gildea and Jurafsky, 2002)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1786b6c1c6532d5baa092cca40e389_1",
  "x": [
   "The representation of test (8), stereotype (<cite>10</cite>), and find out (11) in terms of two Notion relations, one of which is treated as more salient, reifies the concept of relative significance of Proto-Role properties in the verbal semantics."
  ],
  "y": "uses"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_0",
  "x": [
   "Recently, pre-trained language representation models such as GPT (Radford et al., 2018 (Radford et al., , 2019 , ELMo (Peters et al., 2018) , BERT<cite> (Devlin et al., 2019)</cite> and XLNet have achieved promising results in NLP tasks, including reading comprehension (Rajpurkar et al., 2016) , natural language inference (Bowman et al., 2015; Williams et al., 2018) and sentiment classification (Socher et al., 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_1",
  "x": [
   "Although pre-trained language representation models have achieved transformative performance, the pre-training tasks like masked language model and next sentence prediction<cite> (Devlin et al., 2019)</cite> neglect to consider the linguistic knowledge."
  ],
  "y": "motivation"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_2",
  "x": [
   "Thus contextual language representation based on pre-trained models including CoVe (McCann et al., 2017) , ELMo (Peters et al., 2018) , GPT (Radford et al., 2018 (Radford et al., , 2019 and BERT<cite> (Devlin et al., 2019)</cite> becomes prevalent recently."
  ],
  "y": "background"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_3",
  "x": [
   "Various pre-training tasks were explored including traditional NLP tasks like machine translation (Mc-Cann et al., 2017) and language model (Peters et al., 2018; Radford et al., 2018 Radford et al., , 2019 , or other tasks such as masked language model and next sentence prediction<cite> (Devlin et al., 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_4",
  "x": [
   "With the advent of BERT<cite> (Devlin et al., 2019)</cite> achieving state-of-the-art performances on various NLP tasks, many variants of BERT have been proposed."
  ],
  "y": "background"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_5",
  "x": [
   "Compared with the vanilla pretrained models like BERT<cite> (Devlin et al., 2019)</cite> , our model enriches the input sequence with its linguistic knowledge including part-of-speech tags and sentiment polarity labels, and utilizes a modified masked language model to capture the relationship between sentence-level sentiment labels and word-level knowledge in addition to context dependency."
  ],
  "y": "differences"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_6",
  "x": [
   "During pre-training, Label-aware masked language model (LA-MLM) and next sentence prediction (NSP) are adopted as the pre-training tasks where the setting of NSP is identical to the one proposed by<cite> Devlin et al. (2019)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_7",
  "x": [
   "We follow the fine-tuning setting of the existing work <cite>(Devlin et al., 2019</cite>; : Sentence-level Sentiment Classification: The input of this task is a text sequence ([CLS], x 1 , x 2 , \u00b7 \u00b7 \u00b7 , x n , [SEP])."
  ],
  "y": "uses"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_8",
  "x": [
   "Since our method can adapt to all the BERTstyle pre-training models, we used vanilla BERT<cite> (Devlin et al., 2019)</cite> as the base framework to construct Transformer blocks in this paper and leave the exploration of other models like RoBERTa as future work."
  ],
  "y": "uses"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_10",
  "x": [
   "Due to the sparsity of aspect terms compared with aspect categories, our model improved a larger margin on the task of aspect category sentiment classification than the<cite> (Devlin et al., 2019)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "183cf87042a3ad2180ead67555d247_11",
  "x": [
   "Note that we directly used the results of BERT on SST-2, MNLI, QNLI and MRPC which are reported by<cite> Devlin et al. (2019)</cite> and reimplemented the BERT model fine-tuned on the rest of the tasks by ourselves."
  ],
  "y": "uses"
 },
 {
  "id": "19233e4954d7e75ac01112a4c07e64_0",
  "x": [
   "First, we discuss our baseline model which is similar to the machine translation encoder-alignerdecoder model of Luong et al. (2015) , and presented by<cite> Chopra et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "19233e4954d7e75ac01112a4c07e64_1",
  "x": [
   "Our baseline model is a strong, multi-layered encoder-attention-decoder model with bilinear attention, similar to Luong et al. (2015) and following the details in<cite> Chopra et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "19233e4954d7e75ac01112a4c07e64_2",
  "x": [
   "Following previous work (Nallapati et al., 2016; <cite>Chopra et al., 2016</cite>; Rush et al., 2015) , we use the full-length F1 variant of Rouge (Lin, 2004) for the Gigaword results, and the 75-bytes length limited Recall variant of Rouge for DUC."
  ],
  "y": "uses"
 },
 {
  "id": "19233e4954d7e75ac01112a4c07e64_4",
  "x": [
   "Baseline Results and Previous Work Our baseline is a strong encoder-attention-decoder model based on Luong et al. (2015) and presented by<cite> Chopra et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "19233e4954d7e75ac01112a4c07e64_5",
  "x": [
   "In Table 2 , we again see that et al. (2015) 28.18 8.49 23.81<cite> Chopra et al. (2016)</cite> 28.97 8.26 24.06 Nallapati et al. (2016) our Luong et al. (2015) baseline model achieves competitive performance with previous work, esp."
  ],
  "y": "similarities"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_0",
  "x": [
   "In this technical report, we introduce FastFusionNet, an efficient variant of FusionNet <cite>[12]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_1",
  "x": [
   "In this technical report, we analyze the inference bottlenecks of FusionNet <cite>[12]</cite> and introduce FastFusionNet that tackles them."
  ],
  "y": "differences extends"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_2",
  "x": [
   "FusionNet <cite>[12]</cite> is reading comprehension model built on top of DrQA by introducing Fully-aware attention layers (context-question attention and context self-attention), contextual embeddings [21] , and more RNN layers."
  ],
  "y": "background"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_3",
  "x": [
   "Figure 2 provides an analysis of the individual components of FusionNet that the contextual embedding layer, i.e. CoVe [21] , with several layers of wide LSTMs, takes up to 35.5% of the inference time while only contributing a 1.1% improvement of F1 Score (from 82.5% to 83.6%) Huang et al. <cite>[12]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_4",
  "x": [
   "Here we introduce FastFusionNet which addresses the inference bottlenecks of FusionNet <cite>[12]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_5",
  "x": [
   "We closely follow the implementation of Huang et al. <cite>[12]</cite> described in their paper except for the changes above."
  ],
  "y": "differences extends"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_6",
  "x": [
   "Following Huang et al. <cite>[12]</cite> , the hidden size of each SRU is set to 125, resulting in a 250-d output feature of each BiSRU regardless of the input size."
  ],
  "y": "similarities uses"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_7",
  "x": [
   "Like others <cite>[12]</cite> we use a randomly initialized the trainable embedding layer with 12 dimensions for POS tags and 8 dimensions for NER."
  ],
  "y": "similarities"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_8",
  "x": [
   "The Question-Context Attention Layer is a fully-aware attention module <cite>[12]</cite> which takes the history (concatenation of GloVe, low-level, and high-level features) of each context word and question words as query and key for three attention modules, and represents each context word as three different vectors:"
  ],
  "y": "similarities"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_9",
  "x": [
   "Our FastFusionNet reaches F1 75% in 4 epochs and achieves at F1 82.5% at the end which matches the reported F1 82.5% of FusionNet without CoVe on SQuAD development set <cite>[12]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "195f41862b929318787aad9d8e5a1c_10",
  "x": [
   "<cite>[12]</cite> here since our reimplementation is about 0.5% F1 score worse."
  ],
  "y": "differences"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_0",
  "x": [
   "Our work is similar in spirit to e.g. (Roy, 2002; Skocaj et al., 2011) but advances it in several aspects <cite>(Yu et al., 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_1",
  "x": [
   "\u2022 VOILA's dialogue strategy is optimised via Reinforcement Learning to achieve an optimal trade-off between the accuracy of the concepts it learns/has learnt from users, and the effort that the dialogues incur on the users: this is a form of active learning where the agent only asks about something if it doesn't already know the answer with some appropriate confidence (see <cite>(Yu et al., 2016)</cite> for more detail)."
  ],
  "y": "background"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_2",
  "x": [
   "\u2022 VOILA's dialogue strategy is optimised via Reinforcement Learning to achieve an optimal trade-off between the accuracy of the concepts it learns/has learnt from users, and the effort that the dialogues incur on the users: this is a form of active learning where the agent only asks about something if it doesn't already know the answer with some appropriate confidence (see <cite>(Yu et al., 2016)</cite> for more detail)."
  ],
  "y": "differences"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_3",
  "x": [
   "We developed a multimodal framework in support of building an interactive learning system, which loosely follows that of<cite> Yu et al. (2016)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_4",
  "x": [
   "Following previous work <cite>(Yu et al., 2016)</cite> , here we use a positive confidence threshold, which determines when the agent believes its own predictions."
  ],
  "y": "uses"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_5",
  "x": [
   "For instance, the learner can ask either polar or WH-questions about an attribute if its confidence score is higher than a certain threshold; otherwise, there should be no interaction about that attribute. But as<cite> Yu et al. (2016)</cite> point out the confidence score from a classifier is not reliable enough at the early stages of learning, so in order to find an optimum dialogue policy, a threshold should be able to dynamically adjust according to the previous learning performance of the agent."
  ],
  "y": "motivation"
 },
 {
  "id": "196e7ca5ccd6754ac986137ec55cd3_6",
  "x": [
   "Following previous work <cite>(Yu et al., 2016)</cite> , here we use a positive confidence threshold, which determines when the agent believes its own predictions.",
   "For instance, the learner can ask either polar or WH-questions about an attribute if its confidence score is higher than a certain threshold; otherwise, there should be no interaction about that attribute. But as<cite> Yu et al. (2016)</cite> point out the confidence score from a classifier is not reliable enough at the early stages of learning, so in order to find an optimum dialogue policy, a threshold should be able to dynamically adjust according to the previous learning performance of the agent."
  ],
  "y": "differences extends uses"
 },
 {
  "id": "1a8c7d22709cae34fbc1eb70fe5189_0",
  "x": [
   "This tutorial discusses a framework of online global discriminative learning and beam-search decoding for syntactic processing (Zhang and Clark, 2011b) , which has recently been applied to a wide variety of natural language processing (NLP) tasks, including word segmentation (Zhang and Clark, 2007) , dependency parsing (Zhang and Clark, 2008b; Huang and Sagae, 2010; Zhang and Nivre, 2011; Bohnet and Kuhn, 2012) , context free grammar (CFG) parsing <cite>(Collins and Roark</cite>, 2004; Zhang and Clark, 2009; Zhu et al., 2013) , combinational categorial grammar (CCG) parsing (Zhang and Clark, 2011a; Xu et al., 2014) and machine translation (Liu, 2013) , achieving stateof-the-art accuracies and efficiencies."
  ],
  "y": "uses"
 },
 {
  "id": "1a8c7d22709cae34fbc1eb70fe5189_1",
  "x": [
   "We start with a detailed introduction of the framework, describing the averaged perceptron algorithm (Collins, 2002) and its efficient implementation issues (Zhang and Clark, 2007) , as well as beam-search and the early-update strategy <cite>(Collins and Roark, 2004)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_0",
  "x": [
   "<cite>Levy et al. (2017)</cite> present a reformulation of RE, where the task is framed as reading comprehension."
  ],
  "y": "motivation background"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_1",
  "x": [
   "Zero-shot relation extraction <cite>Levy et al. (2017)</cite> propose a novel approach towards achieving this generalization by transforming relations into natural language question templates."
  ],
  "y": "motivation background"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_2",
  "x": [
   "2 Slot-filling data To extract the contexts for each triple in our dataset we use the distant supervision method described by <cite>Levy et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_3",
  "x": [
   "Querification <cite>Levy et al. (2017)</cite> created 1192 question templates for 120 Wikidata properties."
  ],
  "y": "extends"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_5",
  "x": [
   "Following <cite>Levy et al. (2017)</cite> , we distinguish between the traditional RE setting where the aim is to generalize to unseen entities (UnENT) and the zero-shot setting (UnREL) where the aim is to do so for unseen relation types (see Section 2)."
  ],
  "y": "motivation similarities"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_6",
  "x": [
   "This approach was shown by <cite>Levy et al. (2017)</cite> to have significantly better paraphrasing abilities than when only one question template or simpler relation descriptions are employed."
  ],
  "y": "uses"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_7",
  "x": [
   "Evaluation Our evaluation methodology follows <cite>Levy et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_11",
  "x": [
   "All monolingual models' word embeddings were initialised using fastText embeddings trained on each language's Wikipedia and common crawl corpora, 7 except for the comparison experiments described in sub-section 5.1 where GloVe (Pennington et al., 2014) was used for comparability with <cite>Levy et al. (2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1ac16c74cc5bb4099ae07f89d7f148_12",
  "x": [
   "UnENT UnREL <cite>Levy et al. (2017)</cite> Faruqui and Kumar (2015) employed a pipeline of machine translation systems to translate to English, then Open RE systems to perform RE on the translated text, followed by crosslingual projection back to source language."
  ],
  "y": "background"
 },
 {
  "id": "1b424cab4d7008997a31be8c2e5198_0",
  "x": [
   "Most notably, for the natural language inference task, augmenting the hypothesis (u) and premise (v) representations with |u\u2212v| and u \u00b7 v considerably improves performance in a siamese architecture <cite>Mou et al. (2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1b424cab4d7008997a31be8c2e5198_1",
  "x": [
   "Most notably, for the natural language inference task, augmenting the hypothesis (u) and premise (v) representations with |u\u2212v| and u \u00b7 v considerably improves performance in a siamese architecture <cite>Mou et al. (2016)</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "1b424cab4d7008997a31be8c2e5198_2",
  "x": [
   "The standard matching feature of <cite>Mou et al. (2016)</cite> uses a concatenation of u, v, |u\u2212v| and u \u00b7 v. We define the following new matching feature vector that scales the multiplicative term by a constant factor \u03b7 > 0."
  ],
  "y": "uses background"
 },
 {
  "id": "1b424cab4d7008997a31be8c2e5198_3",
  "x": [
   "Choosing \u03b7 = 1 in w poly2 reduces it to the matching feature vector proposed by <cite>Mou et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1bcd442a685e5fb2d0f3f44d3c66c3_0",
  "x": [
   "Several recent works<cite> (Lazaridou, Peysakhovich, and Baroni 2016</cite>; Havrylov and Titov 2017; Lazaridou et al. 2018; <cite>Mordatch and Abbeel 2018)</cite> , have shown that in multi-agent cooperative setting of referential games, deep reinforcement learning can successfully induce communication protocols."
  ],
  "y": "motivation background"
 },
 {
  "id": "1bcd442a685e5fb2d0f3f44d3c66c3_1",
  "x": [
   "In<cite> (Lazaridou, Peysakhovich, and Baroni 2016)</cite> , the authors have restricted the message to be a single symbol token picked from a fixed vocabulary while in (Havrylov and Titov 2017) , the message is considered to be a sequence of symbols."
  ],
  "y": "background"
 },
 {
  "id": "1bcd442a685e5fb2d0f3f44d3c66c3_2",
  "x": [
   "(<cite>Mordatch and Abbeel 2018)</cite> further extends the scope of mode of communication by also studying the emergence of non-verbal communication."
  ],
  "y": "background"
 },
 {
  "id": "1bcd442a685e5fb2d0f3f44d3c66c3_3",
  "x": [
   "In our work, we have used two referential game setups that are slight modifications to the ones used in<cite> (Lazaridou, Peysakhovich, and Baroni 2016</cite>; Lazaridou et al. 2018 )."
  ],
  "y": "differences extends"
 },
 {
  "id": "1bcd442a685e5fb2d0f3f44d3c66c3_4",
  "x": [
   "In all other cases and intermediate timesteps, the payoff is 0. Because of the high dimensional search space introduced due to brushstrokes, we use Proximal Policy Optimization (PPO)<cite> (Schulman et al. 2017)</cite> for optimizing the weights of sender and receiver agents."
  ],
  "y": "background"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_0",
  "x": [
   "Hate speech in the form of racism and sexism is commonplace on the internet <cite>(Waseem and Hovy, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_1",
  "x": [
   "We provide an evaluation on our own data set and run our models on <cite>the data set</cite> released by <cite>Waseem and Hovy (2016)</cite>."
  ],
  "y": "uses"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_2",
  "x": [
   "Our data set extends the <cite>Waseem and Hovy (2016)</cite> data set by 4, 033 tweets."
  ],
  "y": "extends"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_3",
  "x": [
   "Our data set is obtained by sampling tweets from the 130k tweets extracted by <cite>Waseem and Hovy (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_4",
  "x": [
   "The order of the tweets is selected by our database connection, thus allowing for an overlap with the data set released by <cite>Waseem and Hovy (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_5",
  "x": [
   "Racism Sexism Neither Count 1 95 2780 Given the distribution of the labels in <cite>Waseem and Hovy (2016)</cite> and our annotated data set (see Table  2 ), it is to be expected the largest overlap occurs with tweets annotated as negative for hate speech."
  ],
  "y": "similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_6",
  "x": [
   "Observing Table 2 , we see that the label distribution in our data set generally differs from the distribution in <cite>Waseem and Hovy (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_7",
  "x": [
   "In fact, we see that the amateur majority voted labels is the only distribution that tends towards a label distribution similar to <cite>Waseem and Hovy (2016)</cite> Our annotation effort deviates from <cite>Waseem and Hovy (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_8",
  "x": [
   "We present the annotators with <cite>the tests</cite> from <cite>Waseem and Hovy (2016)</cite> .",
   "If a tweet fails any of <cite>the tests</cite>, the annotators are instructed to label it as the relevant form of hate speech."
  ],
  "y": "uses"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_9",
  "x": [
   "Overlap Considering the overlap with the <cite>Waseem and Hovy (2016)</cite>, we see that the agreement is extremely low (mean pairwise \u03ba = 0.14 between all annotator groups and <cite>Waseem and Hovy (2016)</cite> )."
  ],
  "y": "similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_10",
  "x": [
   "Interestingly, we see that the vast majority of disagreements between our annotators and <cite>Waseem and Hovy (2016)</cite> , are disagreements where our annotators do not find hate speech but <cite>Waseem and Hovy (2016)</cite> the influence of the features listed in Table 4 for each annotator group."
  ],
  "y": "differences"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_11",
  "x": [
   "Gender Following the indication that gender can positively influence classification scores <cite>(Waseem and Hovy, 2016)</cite> , we compute the gender of the users in our data set."
  ],
  "y": "uses"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_12",
  "x": [
   "To counteract the low coverage in <cite>Waseem and Hovy (2016)</cite> , we use a lexicon trained on Twitter (Sap et al., 2014) to calculate the probability of gender."
  ],
  "y": "extends"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_13",
  "x": [
   "Results Running our system on the <cite>Waseem and Hovy (2016)</cite> data set, we find that our best performing system does not substantially outperform on the binary classification task <cite>Waseem and Hovy (2016</cite> Interestingly, the main cause of error is false positives."
  ],
  "y": "similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_14",
  "x": [
   "<cite>Waseem and Hovy (2016)</cite> may suffer from personal bias, as the only the authors annotated, and only the annotations positive for hate speech were reviewed by one other person."
  ],
  "y": "differences"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_15",
  "x": [
   "<cite>Waseem and Hovy (2016)</cite> and Ross et al. (2016) focus on building corpora which <cite>they annotate</cite> for containing hate speech."
  ],
  "y": "background"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_16",
  "x": [
   "Our work closely resembles <cite>Waseem and Hovy (2016)</cite> , as <cite>they also run</cite> classification experiments on a hate speech data set."
  ],
  "y": "similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_17",
  "x": [
   "<cite>Waseem and Hovy (2016)</cite> obtain an F1-score of 73.91 on <cite>their data set</cite>, using character n-grams and gender information."
  ],
  "y": "background"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_18",
  "x": [
   "Our best model is on par with previous work on the <cite>Waseem and Hovy (2016)</cite> data set for the binary classification task but under-performs for the multi-class classification task."
  ],
  "y": "differences similarities"
 },
 {
  "id": "1c51e45e2917268e0ab5ce43a69655_19",
  "x": [
   "Finally, we will review the negative class in <cite>Waseem and Hovy (2016)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_0",
  "x": [
   "Recently, with the rise of machine learning and especially deep learning techniques, researchers are starting to bring more data-driven approaches to this field<cite> (Sproat and Jaitly, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_1",
  "x": [
   "Recently, with the rise of machine learning and especially deep learning techniques, researchers are starting to bring more data-driven approaches to this field<cite> (Sproat and Jaitly, 2016)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_2",
  "x": [
   "Recently, methods based on neural networks have been applied to TN and ITN<cite> (Sproat and Jaitly, 2016</cite>; Pusateri et al., 2017; Yolchuyeva et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_3",
  "x": [
   "Recent data-driven approaches examine window-based sequence-to-sequence (seq2seq) models and convolutional neural networks (CNN) to normalize a central piece of text with the help of context<cite> (Sproat and Jaitly, 2016</cite>; Yolchuyeva et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_4",
  "x": [
   "Following <cite>Sproat and Jaitly (2016)</cite>, we implement a seq2seq model trained on window-based data."
  ],
  "y": "uses"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_5",
  "x": [
   "A window center might contain 1 or more words (e.g., \"8 AM\") and the grouping is provided by the dataset where each input sentence is segmented into chunks corresponding to labels such as TIME, DATE, ORDINAL<cite> (Sproat and Jaitly, 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_6",
  "x": [
   "The data for the window-based seq2seq model and full sentence seq2seq were generated from the publicly available release of parallel written/speech formatted text from <cite>Sproat and Jaitly (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_7",
  "x": [
   "Our datasets were randomly sampled from a set of 4.9M sentences in the training data portion of the <cite>Sproat and Jaitly (2016)</cite> data release and split into training, validation, and test data."
  ],
  "y": "uses"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_8",
  "x": [
   "We follow <cite>Sproat and Jaitly (2016)</cite> in down-sampling window-based training data to constrain the proportion of \"<self>\" tokens to 10% of the data."
  ],
  "y": "uses"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_9",
  "x": [
   "Our first approach replicates the window-based seq2seq model of <cite>Sproat and Jaitly (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_10",
  "x": [
   "* TELEPHONE is not reported in <cite>Sproat and Jaitly (2016)</cite> but included in the dataset; ** we removed ELECTRONIC category."
  ],
  "y": "differences"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_11",
  "x": [
   "As shown in Figure 2 , our replicated windowbased model achieves reasonable performance compared with <cite>Sproat and Jaitly (2016)</cite> , considering our training set is much smaller."
  ],
  "y": "similarities"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_12",
  "x": [
   "Data with TELEPHONE labels were not included in the initial analysis of <cite>Sproat and Jaitly (2016)</cite> , but were made available in the dataset release."
  ],
  "y": "differences"
 },
 {
  "id": "1c89c8f4849d1c8214a3e5f6b9ff1a_13",
  "x": [
   "Our labels are generated directly from the Google FST<cite> (Sproat and Jaitly, 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1e232f9dfa7d499d1ba39fcebf3d1a_0",
  "x": [
   "Systems, such as treebank-based parsers<cite> (Charniak, 2001</cite>; Collins, 1999) and semantic role labelers (Gildea and Jurafsky, 2002; Xue, 2008) , are trained and tested on hand-annotated data."
  ],
  "y": "background"
 },
 {
  "id": "1e232f9dfa7d499d1ba39fcebf3d1a_1",
  "x": [
   "For example, users of the Charniak parser<cite> (Charniak, 2001)</cite> should add the AUX category to the PTB parts of speech and adjust their systems to account for the conversion of the word ain't into the tokens IS and n't."
  ],
  "y": "background"
 },
 {
  "id": "1e232f9dfa7d499d1ba39fcebf3d1a_2",
  "x": [
   "We use Charniak, UMD and KNP parsers<cite> (Charniak, 2001</cite>; Huang and Harper, 2009; Kurohashi and Nagao, 1998) , JET Named Entity tagger (Grishman et al., 2005; Ji and Grishman, 2006) and other resources in conjunction with languagespecific GLARFers that incorporate hand-written rules to convert output of these processors into a final representation, including logic1 structure, the focus of this paper."
  ],
  "y": "uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_0",
  "x": [
   "We also explore the effects of using joke structure, in the form of humour anchors<cite> (Yang et al., 2015)</cite> , for improving the performance of semantic features and show that, while an intriguing idea, humour anchors contain several pitfalls that can hurt performance."
  ],
  "y": "uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_1",
  "x": [
   "For example, the representation of joke semantics has been fairly basic, typically computing word embedding similarities between all word pairs in a document<cite> (Yang et al., 2015)</cite> , and bear little resemblance to the way humans actually interpret humour."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_2",
  "x": [
   "For example, the representation of joke semantics has been fairly basic, typically computing word embedding similarities between all word pairs in a document<cite> (Yang et al., 2015)</cite> , and bear little resemblance to the way humans actually interpret humour."
  ],
  "y": "background uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_3",
  "x": [
   "Specifically, we experiment with integrating the extraction of humour anchors, the \"meaningful, complete, minimal set of word spans\"<cite> (Yang et al., 2015)</cite> that allow humour to occur, into the humour classification process itself, the first work to do so."
  ],
  "y": "uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_4",
  "x": [
   "As overlap and incongruity are difficult to measure directly, one common approach is instead to use word embeddings, such as Word2Vec (Mikolov et al., 2013) , to calculate the cosine similarities between pairs of vectors representing words in a document <cite>(Yang et al., 2015</cite>; Shahaf et al., 2015; Kukova\u010dec et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_5",
  "x": [
   "Despite the issues mentioned in Section 2.1,<cite> Yang et al. (2015)</cite> 's \"incongruity\" feature set, maximum and minimum word embedding similarities between pairs of words in a document, perform fairly well."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_6",
  "x": [
   "However,<cite> Yang et al. (2015)</cite> does not use their extracted HAs to improve their humour classification performance."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_7",
  "x": [
   "However, these models are much more complex than<cite> Yang et al. (2015)</cite> 's approach, require more training data, and suffer from a lack of interpretability."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_8",
  "x": [
   "We evaluate our classifiers across two separate datasets: Pun of the Day (PotD), collected in<cite> Yang et al. (2015)</cite> , and 16000 One-Liner (OL), collected in Mihalcea and Strapparava (2005) ."
  ],
  "y": "uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_9",
  "x": [
   "PotD consists of positive examples collected from the Pun of the Day website 2 and negative examples collected from a combination of news sources, question/answer forums, and lists of proverbs<cite> (Yang et al., 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_10",
  "x": [
   "We evaluate our classifiers across two separate datasets: Pun of the Day (PotD), collected in<cite> Yang et al. (2015)</cite> , and 16000 One-Liner (OL), collected in Mihalcea and Strapparava (2005) .",
   "PotD consists of positive examples collected from the Pun of the Day website 2 and negative examples collected from a combination of news sources, question/answer forums, and lists of proverbs<cite> (Yang et al., 2015)</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_11",
  "x": [
   "For our baseline we implemented our own version of<cite> Yang et al. (2015)</cite> 's highest performing classifier."
  ],
  "y": "extends"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_12",
  "x": [
   "Similar to<cite> Yang et al. (2015)</cite> , we compute the minimum, maximum, and average Word2Vec similarity between ordered word pairs."
  ],
  "y": "similarities"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_13",
  "x": [
   "Not only is this a common humour recognition feature <cite>(Yang et al., 2015</cite>; Shahaf et al., 2015; Kukova\u010dec et al., 2017) , but it also acts as a point of comparison for word association strength."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_14",
  "x": [
   "Similar to<cite> Yang et al. (2015)</cite> , we compute the minimum, maximum, and average Word2Vec similarity between ordered word pairs.",
   "Not only is this a common humour recognition feature <cite>(Yang et al., 2015</cite>; Shahaf et al., 2015; Kukova\u010dec et al., 2017) , but it also acts as a point of comparison for word association strength."
  ],
  "y": "similarities background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_15",
  "x": [
   "HAs are extracted using the method described in<cite> Yang et al. (2015)</cite> using the same baseline humour model described in Section 3.2 for anchor candidate evaluation."
  ],
  "y": "uses"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_16",
  "x": [
   "In general, our model performs slightly worse than the<cite> Yang et al. (2015)</cite> baseline."
  ],
  "y": "differences"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_17",
  "x": [
   "One interesting aspect to note is that our model uses only 28 feature dimensions compared to<cite> Yang et al. (2015)</cite> 's 318."
  ],
  "y": "differences"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_18",
  "x": [
   "The wonderfully simple extraction method described in<cite> Yang et al. (2015)</cite> only makes HAs more intriguing."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_19",
  "x": [
   "As described in Section 2.2,<cite> Yang et al. (2015)</cite> 's HA extraction algorithm requires a fully trained humour model, the accuracy of which undoubtedly affects the quality of the extracted HAs."
  ],
  "y": "background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_20",
  "x": [
   "As described in Section 2.2,<cite> Yang et al. (2015)</cite> 's HA extraction algorithm requires a fully trained humour model, the accuracy of which undoubtedly affects the quality of the extracted HAs."
  ],
  "y": "similarities background"
 },
 {
  "id": "1f5326cacca33bfc80a9ddcb4ae313_21",
  "x": [
   "We chose our baseline<cite> Yang et al. (2015)</cite> humour classifier as our anchor candidate scorer for simplicity but their HA extraction algorithm is able to work with any humour recognition model so long as it is robust to word order and capable of generating a humour score (in our case, we used humour probability)."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_0",
  "x": [
   "State-of-the-art NLG models are built using recurrent neural network (RNN) based sequence to sequence models<cite> (Du\u0161ek and Jurcicek, 2016a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_1",
  "x": [
   "Recent advances have been in the direction of developing a fully trainable context aware NLG model<cite> (Du\u0161ek and Jurcicek, 2016a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_2",
  "x": [
   "We evaluate our model on the Alex Context natural language generation (NLG) dataset of <cite>Du\u0161ek and Jurcicek (2016a)</cite> and demonstrate that our model outperforms the RNNbased model of <cite>Du\u0161ek and Jurcicek (2016a)</cite> (TGen model) in automatic metrics."
  ],
  "y": "differences uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_3",
  "x": [
   "Model proposed by <cite>Du\u0161ek and Jurcicek (2016a)</cite> serves as a baseline sequence to sequence generation model (TGen model) for SDS which takes into account the context."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_4",
  "x": [
   "This reranker is based on n-gram precision scores and promotes responses having phrase overlaps with user utterances<cite> (Du\u0161ek and Jurcicek, 2016a</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_5",
  "x": [
   "This reranker is based on n-gram precision scores and promotes responses having phrase overlaps with user utterances<cite> (Du\u0161ek and Jurcicek, 2016a</cite> )."
  ],
  "y": "background uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_6",
  "x": [
   "We implement the N-gram match reranker as given by <cite>Du\u0161ek and Jurcicek (2016a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_7",
  "x": [
   "For the dataset which we have used<cite> (Du\u0161ek and Jurcicek, 2016a)</cite> , there are 19 such classes of DA types and slot-value combinations."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_8",
  "x": [
   "The weighted reranking penalties of all the n-best responses are subtracted from their log-probabilities similar to <cite>Du\u0161ek and Jurcicek (2016a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_9",
  "x": [
   "The studies in this work are performed on Alex Context natural language generation (NLG) dataset<cite> (Du\u0161ek and Jurcicek, 2016a</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_10",
  "x": [
   "Data is delexicalized and split into training, validation and test sets as done by <cite>Du\u0161ek and Jurcicek (2016a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_11",
  "x": [
   "The performance of the proposed ConvSeq2Seq model for NLG is compared with that of TGen model<cite> (Du\u0161ek and Jurcicek, 2016a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_12",
  "x": [
   "Our model has also been evaluated using the metric script \"mtevalv11b.pl\" (version 11b) to compare our results with those stated in<cite> (Du\u0161ek and Jurcicek, 2016a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "1fd85a350d9ec7ac12151cfe4412e4_13",
  "x": [
   "BLEU and NIST scores of the TGen model given in Table 2 match with that represented in<cite> (Du\u0161ek and Jurcicek, 2016a)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_0",
  "x": [
   "Transformer (Vaswani et al., 2017 ) is a relative new architecture which outperforms traditional deep learning models such as Recurrent Neural Networks (RNNs) (Sutskever et al., 2014) and Temporal Convolutional Networks (TCNs) (Bai et al., 2018) for sequence modeling tasks across neural machine translations (Vaswani et al., 2017) , language understanding (Devlin et al., 2018) , sequence prediction<cite> (Dai et al., 2019)</cite> , image generation (Child et al., 2019) , video activity classification (Wang et al., 2018) , music generation (Huang et al., 2018a) , and multimodal sentiment analysis (Tsai et al., 2019a) ."
  ],
  "y": "background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_1",
  "x": [
   "It should be noted that some applications has only the decoder self-attention such as sequence prediction<cite> (Dai et al., 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_2",
  "x": [
   "We note that this operation is orderagnostic to the permutation in the input se-quence (order is encoded with extra positional embedding (Vaswani et al., 2017; Shaw et al., 2018;<cite> Dai et al., 2019)</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_3",
  "x": [
   "We note that this operation is orderagnostic to the permutation in the input se-quence (order is encoded with extra positional embedding (Vaswani et al., 2017; Shaw et al., 2018;<cite> Dai et al., 2019)</cite> )."
  ],
  "y": "motivation background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_4",
  "x": [
   "Furthermore, our proposed formulation highlights naturally the main components of Transformer's attention, enabling a better understanding of this mechanism: recent variants of Transformers (Shaw et al., 2018; Huang et al., 2018b; <cite>Dai et al., 2019</cite>; Child et al., 2019; Wang et al., 2018; Tsai et al., 2019a) can be expressed through these individual components."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_5",
  "x": [
   "Next, we show that this new formulation allows us to explore new family of attention while at the same time offering a framework to categorize previous attention variants (Vaswani et al., 2017; Shaw et al., 2018; Huang et al., 2018b; <cite>Dai et al., 2019</cite>; Child et al., 2019; Wang et al., 2018; Tsai et al., 2019a) ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_6",
  "x": [
   "t i can be a mixture of sine and cosine functions (Vaswani et al., 2017) or parameters that can be learned during back-propagation<cite> (Dai et al., 2019</cite>; Ott et al., 2019) ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_7",
  "x": [
   "Recent work (Shaw et al., 2018; <cite>Dai et al., 2019</cite>; Huang et al., 2018b; Child et al., 2019; Parmar et al., 2018; Tsai et al., 2019a) proposed modifications to the Transformer for the purpose of better modeling inputs positional relation (Shaw et al., 2018; Huang et al., 2018b;<cite> Dai et al., 2019)</cite> , appending additional keys in S x k<cite> (Dai et al., 2019)</cite> , modifying the mask applied to Eq. (1) (Child et al., 2019) , or applying to distinct feature types Parmar et al., 2018; Tsai et al., 2019a) ."
  ],
  "y": "background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_8",
  "x": [
   "Recent work (Shaw et al., 2018; <cite>Dai et al., 2019</cite>; Huang et al., 2018b; Child et al., 2019; Parmar et al., 2018; Tsai et al., 2019a) proposed modifications to the Transformer for the purpose of better modeling inputs positional relation (Shaw et al., 2018; Huang et al., 2018b;<cite> Dai et al., 2019)</cite> , appending additional keys in S x k<cite> (Dai et al., 2019)</cite> , modifying the mask applied to Eq. (1) (Child et al., 2019) , or applying to distinct feature types Parmar et al., 2018; Tsai et al., 2019a) ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_9",
  "x": [
   "The new formulation defines a larger space for composing attention by manipulating its individual components, and at the same time it is able to categorize different variants of attention in prior work (Shaw et al., 2018; Huang et al., 2018b; <cite>Dai et al., 2019</cite>; Child et al., 2019; Wang et al., 2018; Tsai et al., 2019a) ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_10",
  "x": [
   "Due to distinct data types, these applications admit various kernel feature space: (Vaswani et al., 2017;<cite> Dai et al., 2019)</cite> :"
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_11",
  "x": [
   "Positional Embedding k(\u22c5, \u22c5) The kernel construction on X = (F \u00d7 T ) has distinct design in variants of Transformers (Vaswani et al., 2017; <cite>Dai et al., 2019</cite>; Huang et al., 2018b; Shaw et al., 2018; Child et al., 2019) ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_12",
  "x": [
   "(i) Absolute Positional Embedding (Vaswani et al., 2017; <cite>Dai et al., 2019</cite>; Ott et al., 2019) : For the original Transformer (Vaswani et al., 2017) , each t i is represented by a vector with each dimension being sine or cosine functions."
  ],
  "y": "background uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_13",
  "x": [
   "For learned positional embedding<cite> (Dai et al., 2019</cite>; Ott et al., 2019) , each t i is a learned parameter and is fixed for the same position for different sequences."
  ],
  "y": "background uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_14",
  "x": [
   "(ii) Relative Positional Embedding in Transformer-XL<cite> (Dai et al., 2019)</cite> : t represents the indicator of the position in the sequence, and the kernel is chosen to be asymmetric of mixing sine and cosine functions:"
  ],
  "y": "background uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_16",
  "x": [
   "(ii) Transformer-XL<cite> (Dai et al., 2019)</cite> , Music Transformer (Huang et al., 2018b) , Self-Attention with Relative Positional Embedding (Shaw et al., 2018) :"
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_17",
  "x": [
   "(iv) Decoder Self-Attention in Transformer-XL<cite> (Dai et al., 2019)</cite> : For each query x q in the decoded sequence, M (x q , S x k ) returns a set containing S 1 and additional memories (M (x q , S x k ) = S 1 + S mem , M (x q , S x k ) \u2283 S 1 )."
  ],
  "y": "background uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_18",
  "x": [
   "For performance-wise comparisons, Transformer-XL<cite> (Dai et al., 2019)</cite> showed that, the additional memories in M (x q , S x k ) are able to capture longer-term dependency than the original Transformer (Vaswani et al., 2017) and hence results in better performance."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_19",
  "x": [
   "Sparse Transformer (Child et al., 2019) showed that although having much fewer elements in M (x q , S x k ), if the elements are carefully chosen, the attention can still reach the same performance as Transformer-XL<cite> (Dai et al., 2019)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_20",
  "x": [
   "In our experiment, we find it reaching competitive performance as comparing to the current state-of-the-art designs (Eq. (5) by<cite> Dai et al. (2019)</cite> )."
  ],
  "y": "similarities uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_21",
  "x": [
   "We conduct experiments on neural machine translation (NMT) and sequence prediction (SP) tasks since these two tasks are commonly chosen for studying Transformers (Vaswani et al., 2017;<cite> Dai et al., 2019)</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_22",
  "x": [
   "For the choice of datasets, we pick IWSLT'14 German-English (De-En) dataset (Edunov et al., 2017) for NMT and WikiText-103 dataset (Merity et al., 2016) for SP as suggested by Edunov et al. (Edunov et al., 2017) and<cite> Dai et al. (Dai et al., 2019)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_23",
  "x": [
   "Similar to prior work (Vaswani et al., 2017;<cite> Dai et al., 2019)</cite> , we report BLEU score for NMT and perplexity for SP."
  ],
  "y": "similarities"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_24",
  "x": [
   "Other than manipulating the kernel choice of the non-positional features, we fix the configuration by Vaswani et al. (2017) for NMT and the configuration by<cite> Dai et al. (2019)</cite> for SP."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_25",
  "x": [
   "Second, we see that PE in the product kernel proposed by<cite> Dai et al. (Dai et al., 2019)</cite> may not constantly outperform the other integration types (it has lower BLEU score for NMT)."
  ],
  "y": "differences uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_26",
  "x": [
   "Note that, for fairness, other than manipulating the kernel choice of the non-positional features, we fix the configuration by Vaswani et al. (Vaswani et al., 2017) for NMT and the configuration by<cite> Dai et al. (Dai et al., 2019)</cite> for SP."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_27",
  "x": [
   "The need of the positional embedding (PE) in the attention mechanism is based on the argument that the attention mechanism is an order-agnostic (or, permutation equivariant) operation (Vaswani et al., 2017; Shaw et al., 2018; Huang et al., 2018b; <cite>Dai et al., 2019</cite>; Child et al., 2019) ."
  ],
  "y": "background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_28",
  "x": [
   "The need of the positional embedding (PE) in the attention mechanism is based on the argument that the attention mechanism is an order-agnostic (or, permutation equivariant) operation (Vaswani et al., 2017; Shaw et al., 2018; Huang et al., 2018b; <cite>Dai et al., 2019</cite>; Child et al., 2019) ."
  ],
  "y": "differences background"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_29",
  "x": [
   "For clarification, we are not attacking the claim made by the prior work (Vaswani et al., 2017; Shaw et al., 2018;  Huang et al., 2018b; <cite>Dai et al., 2019</cite>; Child et al., 2019 ), but we aim at providing a new look at the order-invariance problem when considering the attention mechanism with masks (masks refer to the set filtering function in our kernel formulation)."
  ],
  "y": "differences"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_30",
  "x": [
   "Denote \u03a0 as the set of all permutations over [n] = {1, \u22ef, n}. A function f unc \u2236 X n \u2192 Y n is permutation equivariant iff for any permutation \u03c0 \u2208 \u03a0, f unc(\u03c0x) = \u03c0f unc(x). showed that the standard attention (encoder self-attention (Vaswani et al., 2017;<cite> Dai et al., 2019)</cite> ) is permutation equivariant."
  ],
  "y": "uses"
 },
 {
  "id": "20330d309c218dc2e1521b9644ed9c_31",
  "x": [
   "Here, we present the non-permutation-equivariant problem on the decoder self-attention: (Vaswani et al., 2017;<cite> Dai et al., 2019)</cite> is not permutation equivariant."
  ],
  "y": "uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_0",
  "x": [
   "When there is a mismatch between data distributions, the RE performance of these systems tends to degrade dramatically<cite> (Plank and Moschitti, 2013)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_1",
  "x": [
   "The only study explicitly targeting this problem so far is by<cite> Plank and Moschitti (2013)</cite> who find that the out-of-domain performance of kernel-based relation extractors can be improved by embedding semantic similarity information generated from word clustering and latent semantic analysis (LSA) into syntactic tree kernels."
  ],
  "y": "background"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_2",
  "x": [
   "In fact,<cite> Plank and Moschitti (2013)</cite> only use the 10-bit cluster prefix in their study."
  ],
  "y": "motivation background"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_3",
  "x": [
   "The application of word representations such as word clusters in domain adaptation of RE <cite>(Plank and Moschitti, 2013</cite> ) is motivated by its successes in semi-supervised methods (Chan and Roth, 2010; Sun et al., 2011) where word representations help to reduce data-sparseness of lexical information in the training data."
  ],
  "y": "background"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_4",
  "x": [
   "Following<cite> Plank and Moschitti (2013)</cite> , we assume that we only have labeled data in a single source domain but no labeled as well as unlabeled target data."
  ],
  "y": "uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_5",
  "x": [
   "Unfortunately, this feature set includes the human-annotated (gold-standard) information on entity and mention types which is often missing or noisy in reality<cite> (Plank and Moschitti, 2013)</cite> .",
   "Therefore, following the settings of<cite> Plank and Moschitti (2013)</cite> , we will only assume entity boundaries and not rely on the gold standard information in the experiments."
  ],
  "y": "motivation uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_6",
  "x": [
   "Therefore, following the settings of<cite> Plank and Moschitti (2013)</cite> , we will only assume entity boundaries and not rely on the gold standard information in the experiments."
  ],
  "y": "uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_7",
  "x": [
   "We use the ACE 2005 corpus for DA experiments (as in<cite> Plank and Moschitti (2013)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_8",
  "x": [
   "We follow the standard practices on ACE<cite> (Plank and Moschitti, 2013)</cite> and use news (the union of bn and nw) as the source domain and bc, cts and wl as our target domains."
  ],
  "y": "uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_9",
  "x": [
   "As noted in<cite> Plank and Moschitti (2013)</cite> , the distributions of relations as well as the vocabularies of the domains are quite different."
  ],
  "y": "background"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_10",
  "x": [
   "For word clusters, we experiment with two possibilities: (i) only using a single prefix length of 10 (as<cite> Plank and Moschitti (2013)</cite> did) (denoted by WC10) and (ii) applying multiple prefix lengths of 4, 6, 8, 10 together with the full string (denoted by WC)."
  ],
  "y": "uses"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_11",
  "x": [
   "Our baseline performance is worse than that of<cite> Plank and Moschitti (2013)</cite> only on the target domain cts and better in the other cases."
  ],
  "y": "differences"
 },
 {
  "id": "206b65ee4e69a01e8a0892dc0f2b30_12",
  "x": [
   "(v): Finally, the in-domain performance is also improved consistently demonstrating the robustness of word representations<cite> (Plank and Moschitti, 2013)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_0",
  "x": [
   "<cite>Ambati et al. (2013)</cite> showed that the performance of Malt (Nivre et al., 2007b) on the free word order language, Hindi, is improved by using lexical categories from Combinatory Categorial Grammar (CCG) (Steedman, 2000) ."
  ],
  "y": "background"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_1",
  "x": [
   "In this paper, we extend <cite>this work</cite> and show that CCG categories are useful even in the case of English, a typologically different language, where parsing accuracy of dependency parsers is already extremely high."
  ],
  "y": "extends"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_2",
  "x": [
   "Conversely, <cite>Ambati et al. (2013)</cite> showed that a Hindi dependency parser (Malt) could be improved by using CCG categories."
  ],
  "y": "background"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_3",
  "x": [
   "Using an algorithm similar to Cakici (2005) and Uematsu et al. (2013) , <cite>they first created</cite> a <cite>Hindi CCGbank</cite> from a Hindi dependency treebank and built a supertagger."
  ],
  "y": "background"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_4",
  "x": [
   "<cite>They provided</cite> CCG categories from a supertagger as features to Malt and obtained overall improvements of 0.3% and 0.4% in unlabelled and labelled attachment scores respectively."
  ],
  "y": "background"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_5",
  "x": [
   "We used the English (Hockenmaier and Steedman, 2007) and <cite>Hindi CCGbanks</cite> (Ambati et al., 1 http://w3.msi.vxu.se/ nivre/research/Penn2Malt.html 2013) for our experiments."
  ],
  "y": "uses"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_6",
  "x": [
   "We used Clark and Curran (2004) 's supertagger for English, and <cite>Ambati et al. (2013)</cite> 's supertagger for Hindi."
  ],
  "y": "uses"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_7",
  "x": [
   "In addition to the above mentioned features, <cite>Ambati et al. (2013)</cite> employed morphological features useful for Hindi."
  ],
  "y": "background"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_8",
  "x": [
   "For Hindi, we also did all our experiments using automatic features <cite>Ambati et al. (2013)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_9",
  "x": [
   "Following <cite>Ambati et al. (2013)</cite> , we used supertags which occurred at least K times in the training data, and backed off to coarse POS-tags otherwise."
  ],
  "y": "uses"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_10",
  "x": [
   "<cite>Ambati et al. (2013)</cite> reported similar improvements for Malt as well."
  ],
  "y": "similarities"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_11",
  "x": [
   "This is true both in the case of English (a fixed word order language) and Hindi (free word order and morphologically richer language), extending the result of <cite>Ambati et al. (2013)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_12",
  "x": [
   "<cite>Ambati et al. (2013)</cite> showed that for Hindi, providing CCG categories as features improved Malt in better handling of long distance dependencies."
  ],
  "y": "uses"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_13",
  "x": [
   "In contrast, for Malt, <cite>Ambati et al. (2013)</cite> had shown that coarse-grained supertags gave larger improvements of 0.3% and 0.4% in UAS and LAS respectively."
  ],
  "y": "background"
 },
 {
  "id": "21c2160667b3ff919e39285cd1ece7_14",
  "x": [
   "In contrast, for Malt, <cite>Ambati et al. (2013)</cite> had shown that coarse-grained supertags gave larger improvements of 0.3% and 0.4% in UAS and LAS respectively."
  ],
  "y": "differences"
 },
 {
  "id": "2292b2c0366ef12a5dd25e544f6b2d_0",
  "x": [
   "First, we consider Berant and Liang (2014) 's own extension of the semantic parser of <cite>Berant et al. (2013)</cite> by using paraphrases."
  ],
  "y": "uses"
 },
 {
  "id": "2292b2c0366ef12a5dd25e544f6b2d_1",
  "x": [
   "Response-based learning has been applied in previous work to semantic parsing itself (Kwiatowski et al. (2013) , <cite>Berant et al. (2013)</cite> , Goldwasser and Roth (2013) , inter alia)."
  ],
  "y": "background"
 },
 {
  "id": "2292b2c0366ef12a5dd25e544f6b2d_2",
  "x": [
   "Our baseline system is the parser of <cite>Berant et al. (2013)</cite> , called SEMPRE."
  ],
  "y": "uses"
 },
 {
  "id": "2292b2c0366ef12a5dd25e544f6b2d_3",
  "x": [
   "For semantic parsing we use the SEMPRE and PARASEMPRE tools of <cite>Berant et al. (2013)</cite> and Berant and Liang (2014) which were trained on the training portion of the FREE917 corpus 7 ."
  ],
  "y": "uses"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_0",
  "x": [
   "UKP-Athene <cite>(Hanselowski et al., 2018)</cite> , the highest document retrieval scoring team, uses MediaWiki API 1 to search the Wikipedia database for the claims noun phrases."
  ],
  "y": "background"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_1",
  "x": [
   "Enhanced Sequential Inference Model (ESIM) (Chen et al., 2016) with some small modifications has been used in (Nie et al., 2019;<cite> Hanselowski et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_2",
  "x": [
   "The UKP-Athene team <cite>(Hanselowski et al., 2018)</cite> achieved the highest sentence retrieval recall using ESIM and pairwise training."
  ],
  "y": "background"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_3",
  "x": [
   "ESIM has been widely used among the FEVER challenge participants (Nie et al., 2019; Yoneda et al., 2018;<cite> Hanselowski et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_4",
  "x": [
   "Following the UKP-Athene promising document retrieval component <cite>(Hanselowski et al., 2018)</cite> , which results in more than 93% development set document recall, we exactly use their method to collect a set of top documents D c l top for the claim c l ."
  ],
  "y": "uses"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_5",
  "x": [
   "In addition, we experiment with the modified Hinge loss functions like <cite>(Hanselowski et al., 2018)</cite> :"
  ],
  "y": "uses"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_8",
  "x": [
   "x shows the UNC, UCL, UPK-Athene, DREAM XLNet, and DREAM RoBERTa scores (Nie et al., 2019; Yoneda et al., 2018;<cite> Hanselowski et al., 2018</cite>; Zhong et al., 2019) methods surpass the pairwise methods in terms of recall-precision performance."
  ],
  "y": "differences"
 },
 {
  "id": "22da24997f66a6dafa911f83f061e5_9",
  "x": [
   "The BERT claim verification system even if it is trained on the UKP-Athene sentence retrieval component <cite>(Hanselowski et al., 2018)</cite> , the state of the art method with the highest recall, improves both label accuracy and FEVER score."
  ],
  "y": "differences"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_0",
  "x": [
   "Meanwhile, word representation models based on subword units, such as characters or word segments, have been shown to perform well in many NLP tasks such as POS tagging (dos Santos and Zadrozny, 2014; Ling et al., 2015) , language modeling (Ling et al., 2015; Kim et al., 2016; Vania and Lopez, 2017) , machine translation (Vylomova et al., 2016; Lee et al., 2016; Sennrich et al., 2016) , dependency parsing (Ballesteros et al., 2015) , and sequence labeling<cite> (Rei et al., 2016</cite>; Lample et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_1",
  "x": [
   "We employed the neural sequence labeling model of<cite> (Rei et al., 2016)</cite> and experimented with two word representation models: word-level and character-level."
  ],
  "y": "uses"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_2",
  "x": [
   "They usually employ a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) with CRF as the output layer, and a CNN (Ma and Hovy, 2016) or LSTM (Lample et al., 2016;<cite> Rei et al., 2016)</cite> composes the character embeddings."
  ],
  "y": "background"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_3",
  "x": [
   "Therefore, for the neural models, we just picked the implementation provided in<cite> (Rei et al., 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_4",
  "x": [
   "The loss function contains not only the log likelihood of the training data and the similarity score but also a language modeling loss, which is not mentioned in<cite> (Rei et al., 2016)</cite> but discussed in the subsequent work (Rei, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_5",
  "x": [
   "We used an almost identical setting to<cite> Rei et al. (2016)</cite> : words are lowercased, but characters are not, digits are replaced with zeros, singleton words in the training set are converted into unknown tokens, word and character embedding sizes are 300 and 50 respectively."
  ],
  "y": "similarities uses"
 },
 {
  "id": "237ac6f9b635e56119be956d7521e1_6",
  "x": [
   "We reported an empirical evaluation of neural sequence labeling models by<cite> Rei et al. (2016)</cite> on NER in Indonesian conversational texts."
  ],
  "y": "uses"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_0",
  "x": [
   "To circumvent this problem,<cite> Khapra et al. (2009)</cite> proposed a WSD method that can be applied to a language even when no sense tagged corpus for that language is available."
  ],
  "y": "motivation"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_1",
  "x": [
   "In section 4 we discuss the work of<cite> Khapra et al. (2009)</cite> on parameter projection for multilingual WSD."
  ],
  "y": "background"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_2",
  "x": [
   "Recent work by<cite> Khapra et al. (2009)</cite> has shown that it is possible to project the parameters learnt from the annotation work of one language to another language provided aligned Wordnets for two languages are available."
  ],
  "y": "background"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_3",
  "x": [
   "The work of<cite> Khapra et al. (2009)</cite> as described above does not attempt to reach an optimal costbenefit point in this economic system."
  ],
  "y": "background"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_4",
  "x": [
   "Ours is thus a 3-factor economic model (crosslinking, annotation and accuracy) as opposed to the 2-factor model (cross-linking, accuracy) proposed by<cite> Khapra et al. (2009)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_5",
  "x": [
   "The model proposed by <cite>Khapra et al. (2009</cite> ) is a deterministic model where the expected count for (Sense S, Marathi Word W ), i.e., the number of times the word W appears in sense S is approximated by the count for the corresponding cross linked Hindi word."
  ],
  "y": "background"
 },
 {
  "id": "2407cfa8572ccbab7f9a081f45a4ad_6",
  "x": [
   "We used the same dataset as described in<cite> Khapra et al. (2009)</cite> for all our experiments."
  ],
  "y": "similarities uses"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_0",
  "x": [
   "In this paper, we introduce graded matrix grammars of natural language, a variant of the matrix grammars proposed by <cite>Rudolph and Giesbrecht (2010)</cite> , and show a close correspondence between this matrix-space model and weighted finite automata."
  ],
  "y": "extends"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_1",
  "x": [
   "To overcome the limitations of VSMs, <cite>Rudolph and Giesbrecht (2010)</cite> proposed Compositional Matrix-Space Models (CMSM) as a recent alternative model to work with distributional approaches."
  ],
  "y": "background"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_2",
  "x": [
   "In this paper, we are concerned with Graded Matrix Grammars, a variant of the Matrix Grammars of <cite>Rudolph and Giesbrecht (2010)</cite> , where instead of the \"yes or no\" decision, if a sequence is part of a language, a real-valued score is assigned."
  ],
  "y": "extends"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_4",
  "x": [
   "More formally, according to <cite>Rudolph and Giesbrecht (2010)</cite> , the underlying idea can be described as follows: \"Given a mapping \u00b7 : \u03a3 \u2192 S from a set of tokens in \u03a3 into some semantical space S, the composition operation is defined by mapping sequences of meanings to meanings: : S \u2192 S. So, the meaning of the sequence of tokens \u03c3 1 \u00b7 \u00b7 \u00b7 \u03c3 n can be obtained by first applying the function \u00b7 to each token and then to the sequence \u03c3 1 \u00b7 \u00b7 \u00b7 \u03c3 n , as shown in Figure 2 \"."
  ],
  "y": "background"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_5",
  "x": [
   "Figure 2: Principle of compositionality, illustration taken from <cite>Rudolph and Giesbrecht (2010)</cite> In compositional matrix-space models, this general idea is instantiated as follows: we have S = R n\u00d7n , i.e., the semantical space consists of quadratic matrices of real numbers."
  ],
  "y": "uses"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_6",
  "x": [
   "<cite>Rudolph and Giesbrecht (2010)</cite> showed theoretically that by employing matrices instead of vectors, CMSMs subsume a wide range of linguistic models such as statistical models (vector-space models and word space models)."
  ],
  "y": "background"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_7",
  "x": [
   "In this section, we introduce the notion of a graded matrix grammar which constitutes a slight variation of matrix grammars as introduced by <cite>Rudolph and Giesbrecht (2010)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "26658b95c9bac96f1206da96b95921_8",
  "x": [
   "Inspired by the work of <cite>Rudolph and Giesbrecht (2010)</cite> they use CMSMs to model composition, and present an algorithm for learning a matrix for each word via ordered logistic regression, which is evaluated with promising results."
  ],
  "y": "background"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_0",
  "x": [
   "<cite>Xiang et al. (2013)</cite> formalized the problem as classifying each IP node (roughly corresponds to S and SBAR in Penn Treebank) in the phrase structure."
  ],
  "y": "background"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_1",
  "x": [
   "As it has annotations for pro and trace, we show our method has substantial improvements over the state-of-the-art machine learning-based method<cite> (Xiang et al., 2013)</cite> for Chinese empty category detection as well as linguistically-motivated manually written rule-based method similar to (Campbell, 2004 )."
  ],
  "y": "differences"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_2",
  "x": [
   "We also use<cite> Xiang et al's (2013)</cite> model as another baseline."
  ],
  "y": "uses"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_3",
  "x": [
   "The probability model of<cite> (Xiang et al., 2013)</cite> is formulated as MaxEnt model:"
  ],
  "y": "background"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_4",
  "x": [
   "<cite>Xiang et al. (2013)</cite> grouped their features into four types: tree label features, lexical features, empty category features and conjunction features as shown in Table 1 ."
  ],
  "y": "background"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_5",
  "x": [
   "As the features for<cite> (Xiang et al., 2013)</cite> were developed for Chinese Penn Treebank, we modify their features for Keyaki Treebank: First, the traversal order is changed from post-order (bottom-up) to pre-order (top-down)."
  ],
  "y": "extends"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_6",
  "x": [
   "Table 2 shows the accuracies of Japanese empty category detection, using the original and our modification of the<cite> (Xiang et al., 2013)</cite> with ablation test."
  ],
  "y": "uses"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_8",
  "x": [
   "We evaluated them using the word-position-level identification metrics described in<cite> (Xiang et al., 2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_9",
  "x": [
   "In the gold parse condition, the two baselines, the rule-based method (RULE) and the modified<cite> (Xiang et al., 2013)</cite> method, achieved the F-measure of 62.6% and 68.6% respectively."
  ],
  "y": "differences"
 },
 {
  "id": "26743b7d006e485be1b850a4424a5f_10",
  "x": [
   "In the gold parse condition, the two baselines, the rule-based method (RULE) and the modified<cite> (Xiang et al., 2013)</cite> method, achieved the F-measure of 62.6% and 68.6% respectively."
  ],
  "y": "uses"
 },
 {
  "id": "27aeffca1f7a9a6b40743284a2871d_0",
  "x": [
   "The adaptor grammar framework is a nonparametric extension of probabilistic context-free grammars (Johnson et al., 2007) , which was initially intended to allow fast prototyping of models of unsupervised language acquisition (Johnson, 2008), but it has been shown to have applications in text data mining and information retrieval as well <cite>Hardisty et al., 2010</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_0",
  "x": [
   "Prior argumentative relation mining studies have often used features extracted from argument components to model different aspects of the relations between the components, e.g., relative distance, word pairs, semantic similarity, textual entailment (Cabrio and Villata, 2012;<cite> Stab and Gurevych, 2014b</cite>; Boltu\u017ei\u0107 and\u0160najder, 2014; Peldszus and Stede, 2015b) ."
  ],
  "y": "background"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_1",
  "x": [
   "Unlike argument component identification where textual inputs are typically sentences or clauses (Moens et al., 2007;<cite> Stab and Gurevych, 2014b</cite>; Levy et al., 2014; Lippi and Torroni, 2015) , textual inputs of argumentative relation mining vary from clauses (Stab and Gurevych, 2014b; Peldszus, 2014 ) to multiple-sentences (Biran and Rambow, 2011; Cabrio and Villata, 2012; Boltu\u017ei\u0107 an\u010f Snajder, 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_2",
  "x": [
   "In our work, we follow <cite>Stab and Gurevych (2014b)</cite> and use the predicted labels of argument components as features during argumentative relation mining."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_3",
  "x": [
   "We, however, take advantage of an enhanced argument component model (Nguyen and Litman, 2016 ) to obtain more reliable argument component labels than in<cite> (Stab and Gurevych, 2014b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_4",
  "x": [
   "Finally, prior research has explored predicting different argumentative relationship labels between pairs of argument components, e.g., attachment (Peldszus and Stede, 2015a) , support vs. non-support (Biran and Rambow, 2011; Cabrio and Villata, 2012;<cite> Stab and Gurevych, 2014b)</cite> , {implicit, explicit}\u00d7{support, attack} (Boltu\u017ei\u0107 and\u0160najder, 2014) , verifiability of support (Park and Cardie, 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_5",
  "x": [
   "Finally, prior research has explored predicting different argumentative relationship labels between pairs of argument components, e.g., attachment (Peldszus and Stede, 2015a) , support vs. non-support (Biran and Rambow, 2011; Cabrio and Villata, 2012;<cite> Stab and Gurevych, 2014b)</cite> , {implicit, explicit}\u00d7{support, attack} (Boltu\u017ei\u0107 and\u0160najder, 2014) , verifiability of support (Park and Cardie, 2014) ."
  ],
  "y": "similarities"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_6",
  "x": [
   "3 Because the corpus has been utilized for different argument mining tasks (Stab and Gurevych, 2014b; Nguyen and Litman, 2015; Nguyen and Litman, 2016) , we use this corpus to demonstrate our context-aware argumentative relation mining approach, and adapt the model developed by <cite>Stab and Gurevych (2014b)</cite> to serve as the baseline for evaluating our proposed approach."
  ],
  "y": "extends"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_7",
  "x": [
   "4 Argumentative Relation Tasks 4.1 Task 1: Support vs. Non-support Our first task follows<cite> (Stab and Gurevych, 2014b)</cite> : given a pair of source and target argument components, identify whether the source argumentatively supports the target or not."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_8",
  "x": [
   "4 Argumentative Relation Tasks 4.1 Task 1: Support vs. Non-support Our first task follows<cite> (Stab and Gurevych, 2014b)</cite> : given a pair of source and target argument components, identify whether the source argumentatively supports the target or not.",
   "Note that when a support relation does not hold, the source may attack or has no relation with the target compo- <cite>Stab and Gurevych (2014b)</cite> split the corpus into an 80% training set and a 20% test set which have similar label distributions.",
   "We use this split to train and test our proposed models, and directly compare our models' performance to the reported performance in<cite> (Stab and Gurevych, 2014b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_9",
  "x": [
   "Because this task was not studied in<cite> (Stab and Gurevych, 2014b)</cite> , we adapt Stab and Gurevych's model to use as the baseline."
  ],
  "y": "extends"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_10",
  "x": [
   "Given a pair of argument components, we follow<cite> (Stab and Gurevych, 2014b)</cite> by first extracting 3 feature sets: structural (e.g., word counts, sentence position), lexical (e.g., word pairs, first words), and grammatical production rules (e.g., S\u2192NP,VP)."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_11",
  "x": [
   "<cite>Stab and Gurevych (2014b)</cite> used a 55-discourse marker set to extract indicator features."
  ],
  "y": "background"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_12",
  "x": [
   "<cite>Stab and Gurevych (2014b)</cite> used a 55-discourse marker set to extract indicator features."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_13",
  "x": [
   "<cite>Stab and Gurevych (2014b)</cite> used predicted label of argument components as features for both training and testing their argumentation structure identification model."
  ],
  "y": "background"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_14",
  "x": [
   "<cite>Stab and Gurevych (2014b)</cite> used predicted label of argument components as features for both training and testing their argumentation structure identification model."
  ],
  "y": "extends"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_16",
  "x": [
   "Because temporal relations were shown not helpful for argument mining tasks (Biran and Rambow, 2011;<cite> Stab and Gurevych, 2014b)</cite> , we exclude them here."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_17",
  "x": [
   "We use the training set as determined in<cite> (Stab and Gurevych, 2014b)</cite> to train/test 9 the models using LibLINEAR algorithm (Fan et al., 2008) without parameter or feature optimization."
  ],
  "y": "uses"
 },
 {
  "id": "27be8a173136e48a15f637278fd831_18",
  "x": [
   "We also compare our baseline to the reported performance (REPORT) for Support vs. Non-support classification in<cite> (Stab and Gurevych, 2014b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_0",
  "x": [
   "Recent approaches to this task have been based on slot-filling (Yang et al., 2011;<cite> Elliott and Keller, 2013)</cite> , combining web-scale ngrams , syntactic tree substitution (Mitchell et al., 2012) , and description-by-retrieval (Farhadi et al., 2010; Ordonez et al., 2011; Hodosh et al., 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_1",
  "x": [
   "We perform the correlation analysis on the Flickr8K data set of Hodosh et al. (2013) , and the data set of <cite>Elliott and Keller (2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_2",
  "x": [
   "The test data of <cite>Elliott and Keller (2013)</cite> contains 101 images paired with three reference descriptions."
  ],
  "y": "background"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_3",
  "x": [
   "<cite>Elliott and Keller (2013)</cite> generated two-sentence descriptions for each of the test images using four variants of a slot-filling model, and collected five human judgements of the semantic correctness and grammatical correctness of the description on a scale of 1-5 for each imagedescription pair, resulting in a total of 2,042 human judgement-description pairings."
  ],
  "y": "background"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_4",
  "x": [
   "The test data of <cite>Elliott and Keller (2013)</cite> contains 101 images paired with three reference descriptions.",
   "<cite>Elliott and Keller (2013)</cite> generated two-sentence descriptions for each of the test images using four variants of a slot-filling model, and collected five human judgements of the semantic correctness and grammatical correctness of the description on a scale of 1-5 for each imagedescription pair, resulting in a total of 2,042 human judgement-description pairings."
  ],
  "y": "uses"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_5",
  "x": [
   "Unigram BLEU without a brevity penalty has been reported by ), Ordonez et al. (2011 , and Kuznetsova et al. (2012) ; to the best of our knowledge, the only image description work to use higher-order n-grams with BLEU is <cite>Elliott and Keller (2013)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_6",
  "x": [
   "A similar pattern is observed in the <cite>Elliott and Keller (2013)</cite> data set, though the correlations are lower across all measures."
  ],
  "y": "similarities"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_7",
  "x": [
   "There are no fluency judgements available for Flickr8K, but <cite>Elliott and Keller (2013)</cite> report grammaticality judgements for their data, which are comparable to fluency ratings."
  ],
  "y": "uses"
 },
 {
  "id": "280affafa32147a63e7eeda8d5f763_8",
  "x": [
   "We failed to find significant correlations between grammatlicality judgements and any of the automatic measures on the <cite>Elliott and Keller (2013)</cite> data."
  ],
  "y": "uses"
 },
 {
  "id": "28805bfa8f8b847110664d7e05b1b3_0",
  "x": [
   "Previously, a graph based framework has been proposed that models word semantic similarity from parsed text <cite>(Minkov and Cohen, 2008)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "28805bfa8f8b847110664d7e05b1b3_1",
  "x": [
   "To this end, we consider a path constrained graph walk (PCW) algorithm, which allows one to learn meaningful paths given a small number of labeled examples and incorporates this information in assessing node relatedness in the graph <cite>(Minkov and Cohen, 2008)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "28805bfa8f8b847110664d7e05b1b3_2",
  "x": [
   "PCW have been successfully applied to the extraction of named entity coordinate terms, including city and person names, from graphs representing newswire text <cite>(Minkov and Cohen, 2008)</cite> , where the specialized measures learned outperformed the state-ofthe-art dependency vectors method (Pad\u00f3 and Lapata, 2007) for small-and medium-sized corpora."
  ],
  "y": "background"
 },
 {
  "id": "28805bfa8f8b847110664d7e05b1b3_3",
  "x": [
   "PCW have been successfully applied to the extraction of named entity coordinate terms, including city and person names, from graphs representing newswire text <cite>(Minkov and Cohen, 2008)</cite> , where the specialized measures learned outperformed the state-ofthe-art dependency vectors method (Pad\u00f3 and Lapata, 2007) for small-and medium-sized corpora."
  ],
  "y": "uses"
 },
 {
  "id": "28805bfa8f8b847110664d7e05b1b3_4",
  "x": [
   "PCW is a graph walk variant proposed recently that is intended to bias the random walk process to follow meaningful edge sequences (paths) <cite>(Minkov and Cohen, 2008)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "28805bfa8f8b847110664d7e05b1b3_5",
  "x": [
   "In conducting the constrained walk, we applied a threshold of 0.5 to truncate paths associated with lower probability of reaching a relevant response, following on previous work <cite>(Minkov and Cohen, 2008)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_0",
  "x": [
   "Recently Deep Neural Network Based (DNN) models have also been applied for detection of cyberbullying [10] , <cite>[11]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_1",
  "x": [
   "In <cite>[11]</cite> , authors have used DNN models for detection of cyberbullying and have expanded their models across multiple social media platforms."
  ],
  "y": "background"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_2",
  "x": [
   "In this contribution, we begin by reproducing and validating the <cite>[11]</cite> proposed models and their results on the three datasets, Formspring [12] , Twitter [13] and Wikipedia [14] , which have been used by the authors."
  ],
  "y": "uses"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_3",
  "x": [
   "Recently Deep Neural Network Based (DNN) models have also been applied for detection of cyberbullying [10] , <cite>[11]</cite> .",
   "In <cite>[11]</cite> , authors have used DNN models for detection of cyberbullying and have expanded their models across multiple social media platforms."
  ],
  "y": "extends"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_4",
  "x": [
   "In this study, we have first reproduced the experiments conducted in <cite>[11]</cite> on the datasets used by the authors namely, Formspring [12] , Wikipedia [14] , and Twitter [13] ."
  ],
  "y": "uses"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_5",
  "x": [
   "Following <cite>[11]</cite> we also implemented the transfer learning procedure to evaluate to what extent the DNN models trained on a social network, here Twitter, Formspring, and Wiki, can successfully detect cyberbullying posts in another social network, i.e., YouTube."
  ],
  "y": "uses"
 },
 {
  "id": "289ea9be270f68e23ca1809f997be9_6",
  "x": [
   "In this study, we successfully reproduced the reference literature <cite>[11]</cite> for detection of cyberbullying incidents in social media platforms using DNN based models."
  ],
  "y": "uses"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_0",
  "x": [
   "<cite>Prabhumoye et al. (2018)</cite> propose to transfer style through backtranslation."
  ],
  "y": "background"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_1",
  "x": [
   "We introduce two approaches which extend the back-translation models proposed by <cite>Prabhumoye et al. (2018)</cite> exploring back-translation setups that preserve the content of the sentence better."
  ],
  "y": "extends"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_3",
  "x": [
   "While the previous work (<cite>Prabhumoye et al., 2018</cite>) focuses on creating a representation by translating to a pivot language, preserving meaning in the generated sentences is still an unsolved question."
  ],
  "y": "motivation"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_4",
  "x": [
   "<cite>Prabhumoye et al. (2018)</cite> introduces the technique of back-translation to perform style transfer."
  ],
  "y": "background"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_5",
  "x": [
   "<cite>They</cite> first transfer a sentence to one pivot language and use the encoding of the sentence in the pivot language to train the generative models corresponding to the two styles."
  ],
  "y": "background"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_6",
  "x": [
   "<cite>They</cite> also use feedback from a pre-trained classifier to guide the generators to generate the desired style."
  ],
  "y": "background"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_7",
  "x": [
   "This model is denoted as <cite>Back-translated Style Transfer</cite> (<cite>BST</cite>) in the future."
  ],
  "y": "background"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_8",
  "x": [
   "We use these translation systems for training the style specific decoders following the procedure in (<cite>Prabhumoye et al., 2018</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_9",
  "x": [
   "We use three tasks described in (<cite>Prabhumoye et al., 2018</cite>) to evaluate our models."
  ],
  "y": "uses"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_11",
  "x": [
   "We have reproduced the classifiers described in (<cite>Prabhumoye et al., 2018</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_12",
  "x": [
   "We reuse the instructions provided by (<cite>Prabhumoye et al., 2018</cite>) for the three tasks. But unlike (<cite>Prabhumoye et al., 2018</cite>), we perform our evaluation on Amazon Mechanical Turk."
  ],
  "y": "differences uses"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_14",
  "x": [
   "As reported by <cite>them</cite>, the <cite>BST</cite> model performs better in preservation of meaning for the tasks of gender and political slant transfer."
  ],
  "y": "background"
 },
 {
  "id": "28eeecadd8d3348de6daec3c801ae4_16",
  "x": [
   "The over-all averaged scores for the two models MBST and MBST+F is the same 3.08, whereas it is much lower 2.79 for <cite>BST</cite> and 2.57 for CAE."
  ],
  "y": "differences"
 },
 {
  "id": "2915e49791d14f5b802225d10f33fb_0",
  "x": [
   "Machine Learning methods have been widely applied for sentiment analysis (Pang et al. 2008;<cite> Pang et al. 2002</cite>; Tan et al. 2008 )."
  ],
  "y": "background"
 },
 {
  "id": "2915e49791d14f5b802225d10f33fb_1",
  "x": [
   "Documents are initially pre-processed as follows: (i) Negation handling is performed as<cite> Pang et al. (2002)</cite> , \"NOT_\" is added to every words occurring after the negation word (no, not, isn't, can't, never, couldn't, didn't, wouldn't, don't) and first punctuation mark in the sentence."
  ],
  "y": "similarities uses"
 },
 {
  "id": "2915e49791d14f5b802225d10f33fb_2",
  "x": [
   "Binary weighting scheme has been identified as a better weighting scheme as compared to frequency based schemes for sentiment classification<cite> (Pang et al. 2002)</cite> ; therefore we also used binary weighting method for representing text."
  ],
  "y": "motivation background"
 },
 {
  "id": "2915e49791d14f5b802225d10f33fb_3",
  "x": [
   "Support Vector Machine (SVM) and Na\u00efve Bayes (NB) classifiers are the mostly used for sentiment classification <cite>(Pang et al. 2002</cite>; Tan et al. 2008) ."
  ],
  "y": "background"
 },
 {
  "id": "2abfa447cea31af26d06d4325c94ac_0",
  "x": [
   "Recent successes in statistical syntactic parsing based on supervised techniques trained on a large corpus of syntactic trees (Collins, 1999; Charniak, 2000;<cite> Henderson, 2003)</cite> have brought the hope that the same approach could be applied to the more ambitious goal of recovering the propositional content and the frame semantics of a sentence."
  ],
  "y": "background"
 },
 {
  "id": "2abfa447cea31af26d06d4325c94ac_1",
  "x": [
   "We present work to test the hypothesis that a current statistical parser <cite>(Henderson, 2003)</cite> can output rich information comprising both a parse tree and semantic role labels robustly, that is without any significant degradation of the parser's accuracy on the original parsing task."
  ],
  "y": "uses"
 },
 {
  "id": "2abfa447cea31af26d06d4325c94ac_2",
  "x": [
   "To achieve the complex task of assigning semantic role labels while parsing, we use a family of state-of-the-art history-based statistical parsers, the Simple Synchrony Network (SSN) parsers <cite>(Henderson, 2003)</cite> , which use a form of left-corner parse strategy to map parse trees to sequences of derivation steps."
  ],
  "y": "uses"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_0",
  "x": [
   "For instance, in studies performed on the text genres web debate forums (Somasundaran and Wiebe, 2010; Anand et al., 2011; Walker et al., 2012; Hasan and Ng, 2013) , news paper text (Ferreira and Vlachos, 2016; Fake News Challenge, 2017) and tweets (Augenstein et al., 2016;<cite> Mohammad et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_1",
  "x": [
   "This was, for instance, shown by a recent shared task on three-category stance classification of tweets, where an F-score of 0.59 was achieved by a classifier that outperformed submissions from 19 shared task teams <cite>(Mohammad et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_2",
  "x": [
   "Following the principle of the guidelines by<cite> Mohammad et al. (2017)</cite> , we classified the posts as taking a stance against or for vaccination, or to be undecided."
  ],
  "y": "similarities uses"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_3",
  "x": [
   "This follows the approach of<cite> Mohammad et al. (2017)</cite> , as well as of many of the previously performed vaccine sentiment studies."
  ],
  "y": "similarities uses"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_4",
  "x": [
   "The eight annotators that classified each tweet in the study by<cite> Mohammad et al. (2017)</cite> were employed through a crowdsourcing platform, which was made possible by that the stance targets were chosen with the criterion that they should be commonly known in the United States."
  ],
  "y": "background"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_5",
  "x": [
   "The choice of machine learning model was primarily based on that a linear support vector machine was successful on data from the previously mentioned shared task of stance detection of tweets <cite>(Mohammad et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "2adb3a645a57b8f441a80bb5a46045_6",
  "x": [
   "For instance, features constructed using an arguing lexicon (Somasun-daran and Wiebe, 2010), or word embeddings constructed in an unsupervised fashion using a large corpus from the same text genre as the text to classify <cite>(Mohammad et al., 2017)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_0",
  "x": [
   "To address these limitations, Vaswani et al. have proposed the Transformer, a machine translation model that introduces a new deep learning architecture solely based on \"attention\" mechanisms <cite>[2]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_1",
  "x": [],
  "y": "extends"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_2",
  "x": [
   "\u2022 Reduction layer: a new layer design that fits the pipeline proposed by Vaswani et al. <cite>[2]</cite> and compresses the input embedding size for subsequent layers (this is especially beneficial when employing pre-trained embeddings)."
  ],
  "y": "uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_3",
  "x": [
   "\u2022 Column-wise cross-attention: we modify the crossattention operation by <cite>[2]</cite> and propose a new technique that is better suited to question-answering."
  ],
  "y": "extends"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_4",
  "x": [
   "Vaswani et al. were the first to apply attention directly over the word-embeddings, and thus derived a new neural network architecture which, without any recurrence, achieved state-ofthe-art results in machine translation <cite>[2]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_5",
  "x": [
   "In recent years, attention mechanisms have been used with success in a variety of NLP tasks, such as machine translation <cite>[2]</cite> , [27] and natural language inference [28] , [29] ."
  ],
  "y": "background"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_6",
  "x": [
   "The Transformer is a machine translation model introduced in <cite>[2]</cite> that achieved state-of-the-art results by combining feedforward neural networks with a multiplicative attention mechanism applied over position-encoded embedding vectors."
  ],
  "y": "background uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_7",
  "x": [
   "Additionally, Vaswani et al. <cite>[2]</cite> suggest a multi-head attention, in which U, K and V are divided into n heads heads and the attention in the i th head is computed as"
  ],
  "y": "background"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_8",
  "x": [
   "This type of attention is often called \"self-attention\" or \"self-alignment\" <cite>[2]</cite> , [21] ."
  ],
  "y": "background"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_9",
  "x": [
   "We also identified another QA model [32] that is inspired by the architecture introduced by Vaswani et al. <cite>[2]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_10",
  "x": [
   "In particular, we introduce the convolutional attention, the column-wise cross-attention, and the reduction layer, which build on the Transformer model <cite>[2]</cite> to enable its application to question-answering."
  ],
  "y": "extends"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_11",
  "x": [
   "We add positional information to each word embedding using a trigonometric encoder as proposed in <cite>[2]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_12",
  "x": [
   "where f k are scalars, which were chosen according to <cite>[2]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_13",
  "x": [
   "Indeed, in <cite>[2]</cite> , the final vectorial representation of a piece of text is defined by the sum of the embeddings \u2126 with the position encoding E, which would require d model = d input ."
  ],
  "y": "background"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_14",
  "x": [
   "Indeed, in <cite>[2]</cite> , the final vectorial representation of a piece of text is defined by the sum of the embeddings \u2126 with the position encoding E, which would require d model = d input ."
  ],
  "y": "differences"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_15",
  "x": [
   "In FABIR the attention mechanism is inspired by the Transformer model introduced in <cite>[2]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_16",
  "x": [
   "In contrast to Vaswani et al. <cite>[2]</cite> , where the softmax in (12d) is applied in a row-wise manner, we suggest column-wise cross-attention."
  ],
  "y": "differences"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_17",
  "x": [
   "Following the architecture suggested by Vaswani et al. <cite>[2]</cite> , the feedforward sublayer is implemented in (15) with a two-layer neural network:"
  ],
  "y": "uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_18",
  "x": [
   "Nonetheless, we observed that the new architecture introduced by Vaswani et al. <cite>[2]</cite> is more susceptible to overfitting than RNNs when presented with large embedding sizes."
  ],
  "y": "motivation"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_19",
  "x": [
   "As suggested in <cite>[2]</cite> , we have chosen the Adam optimizer [41] with the same hyperparameters, except for the learning rate, which was divided by two in our implementation."
  ],
  "y": "differences uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_20",
  "x": [
   "For regularization, we applied residual and attention dropout <cite>[2]</cite> of 0.9 in processing layers and of 0.8 in the reduction layer."
  ],
  "y": "uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_21",
  "x": [
   "Most importantly, when the convolutional attention was replaced by the standard attention mechanism proposed in <cite>[2]</cite> , the performance dropped by 2.4% in F1 and 2.5% in EM."
  ],
  "y": "uses"
 },
 {
  "id": "2b25e38db7fd20c92d677b73af110c_22",
  "x": [
   "Moreover, being thoroughly compatible with the Transformer <cite>[2]</cite> , these new mechanisms are valuable assets to further developments in attention models."
  ],
  "y": "uses"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_0",
  "x": [
   "There has been a recent shift of research attention in the word segmentation literature from statistical methods to deep learning (Zheng et al., 2013; Pei et al., 2014; Morita et al., 2015; Chen et al., 2015b; Cai and Zhao, 2016;<cite> Zhang et al., 2016b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_1",
  "x": [
   "In addition to character embeddings, distributed representations of character bigrams Pei et al., 2014) and words (Morita et al., 2015;<cite> Zhang et al., 2016b)</cite> have also been shown to improve segmentation accuracies."
  ],
  "y": "background"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_2",
  "x": [
   "With respect to non-linear modeling power, various network structures have been exploited to represent contexts for segmentation disambiguation, including multi-layer perceptrons on fivecharacter windows (Zheng et al., 2013; Pei et al., 2014; Chen et al., 2015a) , as well as LSTMs on characters (Chen et al., 2015b; Xu and Sun, 2016) and words (Morita et al., 2015; Cai and Zhao, 2016;<cite> Zhang et al., 2016b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_3",
  "x": [
   "For structured learning and inference, CRF has been used for character sequence labelling models (Pei et al., 2014; Chen et al., 2015b) and structural beam search has been used for word-based segmentors (Cai and Zhao, 2016;<cite> Zhang et al., 2016b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_4",
  "x": [
   "Following Cai and Zhao (2016) and<cite> Zhang et al. (2016b)</cite> , we adopt a globally optimised beam-search framework for neural structured prediction (Andor et al., 2016; Zhou et al., 2015; Wiseman and Rush, 2016) , which allows word information to be modelled explicitly."
  ],
  "y": "uses"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_5",
  "x": [
   "Similar to<cite> Zhang et al. (2016b)</cite> and Cai and Zhao (2016) , we use word context on top of character context."
  ],
  "y": "similarities"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_6",
  "x": [
   "Similar to<cite> Zhang et al. (2016b)</cite> and Cai and Zhao (2016) , we use word context on top of character context."
  ],
  "y": "differences similarities"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_7",
  "x": [
   "Similar to<cite> Zhang et al. (2016b)</cite> and Cai and Zhao (2016) , our model is a global structural model, using the overall score to disambiguate states, which correspond to sequences of inter-dependent transition actions."
  ],
  "y": "similarities"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_8",
  "x": [
   "For the latter, we follow recent work (Chen et al., 2015b;<cite> Zhang et al., 2016b)</cite> , using a bidirectional LSTM to encode input character sequence."
  ],
  "y": "uses"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_9",
  "x": [
   "For the latter, we follow<cite> Zhang et al. (2016b)</cite> and Cai and Zhao (2016) , using an uni-directional LSTM on words that have been recognized."
  ],
  "y": "uses"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_10",
  "x": [
   "We fine-tune character and character bigram embeddings, but not word embeddings, acccording to<cite> Zhang et al. (2016b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_11",
  "x": [
   "This shows that word contexts are far less important in our model compared to character contexts, and also compared to word contexts in previous word-based segmentors <cite>(Zhang et al., 2016b</cite>; Cai and Zhao, 2016) ."
  ],
  "y": "differences"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_12",
  "x": [
   "This is likely due to the difference in our neural network structures, and that we fine-tune both character and character bigram embeddings, which significantly enlarges the adjustable parameter space as compared with<cite> Zhang et al. (2016b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_13",
  "x": [
   "Zhang et al. (2016b) Both our model and<cite> Zhang et al. (2016b)</cite> use global learning and beam search, but our network is different."
  ],
  "y": "differences similarities"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_14",
  "x": [
   "Besides, the character and character bigram embeddings are fine-tuned in our model while<cite> Zhang et al. (2016b)</cite> set the embeddings fixed during training."
  ],
  "y": "differences"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_15",
  "x": [
   "We study the F-measure distribution with respect to sentence length on our baseline model, multitask pretraining model and<cite> Zhang et al. (2016b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_16",
  "x": [
   "As shown in Figure 5 , the models give different error distributions, with our models being more robust to the sentence length compared with<cite> Zhang et al. (2016b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_17",
  "x": [
   "Without multitask pretraining, our model gives an F-score of 95.44%, which is higher than the neural segmentor of<cite> Zhang et al. (2016b)</cite> , which gives the best accuracies among pure neural segments on this dataset."
  ],
  "y": "differences"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_18",
  "x": [
   "In addition, it also outperforms the best neural models, in particular<cite> Zhang et al. (2016b)</cite> Table 7 : Main results on CTB6."
  ],
  "y": "differences"
 },
 {
  "id": "2b5d8cab263c9edbe005674910a7b1_19",
  "x": [
   "Similar to Table 7 , our method gives the best accuracies on all corpora except for MSR, where it underperforms the hybrid model of<cite> Zhang et al. (2016b)</cite> by 0.2%."
  ],
  "y": "differences"
 },
 {
  "id": "2b7ba7f7aa2a03ad0de84e007c1f64_0",
  "x": [
   "Researchers<cite> (He et al., 2018)</cite> recently studied natural language negotiations in buyer-seller bargaining setup, which is comparatively less restricted than previously studied game environments (Asher et al., 2016; Lewis et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "2b7ba7f7aa2a03ad0de84e007c1f64_1",
  "x": [
   "Researchers<cite> (He et al., 2018)</cite> recently studied natural language negotiations in buyer-seller bargaining setup, which is comparatively less restricted than previously studied game environments (Asher et al., 2016; Lewis et al., 2017) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "2b7ba7f7aa2a03ad0de84e007c1f64_2",
  "x": [
   "We focus on buyer-seller negotiations<cite> (He et al., 2018)</cite> where two individuals negotiate the price of a given product."
  ],
  "y": "uses"
 },
 {
  "id": "2b7ba7f7aa2a03ad0de84e007c1f64_3",
  "x": [
   "We provide a sample negotiation from the test set<cite> (He et al., 2018</cite> ) along with our model predictions in Table 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "2b7ba7f7aa2a03ad0de84e007c1f64_4",
  "x": [
   "Dataset: For our explorations, we use the Craigslist Bargaining dataset (CB) introduced by<cite> He et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2b7ba7f7aa2a03ad0de84e007c1f64_5",
  "x": [
   "This can be a viable middleground between following the average human behavior through supervised learning or exploring the wild by optimizing on rewards using reinforcement learning (Lewis et al., 2017; <cite>He et al., 2018)</cite> ."
  ],
  "y": "future_work"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_0",
  "x": [
   "Much work that followed improved upon this strategy, by improving the features (Ng and Cardie, 2002b) , the type of classifier<cite> (Denis and Baldridge, 2007)</cite> , and changing mention links to be to the most likely antecedent rather than the most recent positively labeled antecedent (Ng and Cardie, 2002b) ."
  ],
  "y": "background"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_1",
  "x": [
   "More recently,<cite> Denis and Baldridge (2007)</cite> utilized an integer linear programming (ILP) solver to better combine the decisions made by these two complementary classifiers, by finding the globally optimal solution according to both classifiers."
  ],
  "y": "background"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_2",
  "x": [
   "When describing our model, we build upon the notation used by<cite> Denis and Baldridge (2007)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_3",
  "x": [
   "Prior work (Soon et al., 2001; <cite>Denis and Baldridge, 2007)</cite> has generated training data for pairwise classifiers in the following manner."
  ],
  "y": "background"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_4",
  "x": [
   "The COREF-ILP model of<cite> Denis and Baldridge (2007)</cite> took a different approach at test time: for each mention they would work backwards and add a link for all previous mentions which the classifier deemed coreferent."
  ],
  "y": "background"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_5",
  "x": [
   "Our D&B-STYLE baseline used the same test time method as<cite> Denis and Baldridge (2007)</cite> , however at training time we created data for all mention pairs."
  ],
  "y": "uses"
 },
 {
  "id": "2bb115f1c3e753e9dc66735887a52d_6",
  "x": [
   "For comparison, we also give the results of the COREF-ILP system of<cite> Denis and Baldridge (2007)</cite> , which was also based on a na\u00efve pairwise classifier."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_0",
  "x": [
   "This task is a rather easier task which prepare a pair of complex and simple representations than a challenging task which changes the substitute pair in a given context (Specia et al., 2012; <cite>Kajiwara and Yamamoto, 2015</cite>) ."
  ],
  "y": "differences uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_1",
  "x": [
   "<cite>Kajiwara and Yamamoto (2015)</cite> constructed an evaluation dataset for Japanese lexical simplification 1 in languages other than English."
  ],
  "y": "background"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_2",
  "x": [
   "However, there are four drawbacks in the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> : (1) <cite>they</cite> extracted sentences only from a newswire corpus; (2) <cite>they</cite> substituted only a single target word; (3) <cite>they</cite> did not allow ties; and (4) <cite>they</cite> did not integrate simplification ranking considering the quality."
  ],
  "y": "motivation background"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_3",
  "x": [
   "Hence, we propose a new dataset addressing the problems in <cite>the dataset</cite> of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_4",
  "x": [
   "However, there are four drawbacks in the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> : (1) <cite>they</cite> extracted sentences only from a newswire corpus; (2) <cite>they</cite> substituted only a single target word; (3) <cite>they</cite> did not allow ties; and (4) <cite>they</cite> did not integrate simplification ranking considering the quality.",
   "Hence, we propose a new dataset addressing the problems in <cite>the dataset</cite> of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "motivation extends"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_5",
  "x": [
   "The evaluation dataset for the English Lexical Simplification task (Specia et al., 2012) Figure 1: A part of the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_6",
  "x": [
   "3 Problems in previous datasets for Japanese lexical simplification <cite>Kajiwara and Yamamoto (2015)</cite> followed Specia et al. (2012) to construct an evaluation dataset for Japanese lexical simplification."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_7",
  "x": [
   "3 Problems in previous datasets for Japanese lexical simplification <cite>Kajiwara and Yamamoto (2015)</cite> followed Specia et al. (2012) to construct an evaluation dataset for Japanese lexical simplification.",
   "Namely, <cite>they</cite> split the data creation process into two steps: substitute extraction and simplification ranking.",
   "During the substitute extraction task, <cite>they</cite> collected substitutes of each target word in 10 different contexts."
  ],
  "y": "motivation"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_8",
  "x": [
   "<cite>They</cite> gathered substitutes from five annotators using crowdsourcing."
  ],
  "y": "background"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_9",
  "x": [
   "<cite>They</cite> used crowdsourcing to find five annotators different from those who performed the substitute extraction task."
  ],
  "y": "background"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_10",
  "x": [
   "Figure 1 shows a part of the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_11",
  "x": [
   "Figure 1 shows a part of the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_12",
  "x": [
   "Because <cite>Kajiwara and Yamamoto (2015)</cite> extracted sentences from a newswire corpus, <cite>their</cite> dataset has a poor variety of expression."
  ],
  "y": "motivation background"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_13",
  "x": [
   "When each annotator assigns a simplification ranking to a substitution list, a tie cannot be assigned in previous datasets (Specia et al., 2012; <cite>Kajiwara and Yamamoto, 2015</cite>) ."
  ],
  "y": "differences"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_14",
  "x": [
   "<cite>Kajiwara and Yamamoto (2015)</cite> and Specia et al. (2012) use an average score to integrate rankings, but it might be biased by outliers."
  ],
  "y": "motivation"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_15",
  "x": [
   "It follows the data creation procedure of <cite>Kajiwara and Yamamoto's (2015)</cite> dataset with improvements to resolve the problems described in Section 3."
  ],
  "y": "uses extends"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_16",
  "x": [
   "It is about the same size as previous work (Specia et al., 2012; <cite>Kajiwara and Yamamoto, 2015</cite>) ."
  ],
  "y": "similarities"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_17",
  "x": [
   "The baseline integration ranking used an average score (<cite>Kajiwara and Yamamoto, 2015</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_18",
  "x": [
   "This score is higher than that from <cite>Kajiwara and Yamamoto (2015)</cite> by 0.190."
  ],
  "y": "differences"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_19",
  "x": [
   "Our method achieved better accuracy in ranking integration than previous methods (Specia et al., 2012; <cite>Kajiwara and Yamamoto, 2015</cite>) and is similar to the results from De Belder and Moens (2012) ."
  ],
  "y": "differences"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_20",
  "x": [
   "We calcu- late 1-best accuracy in our dataset and the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_21",
  "x": [
   "Annotated data is collected by our and <cite>Kajiwara and Yamamoto (2015)</cite>'s work in ranking substitutes task, and which size is 21,700 ((2010 + 2330) 5) rankings."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_22",
  "x": [
   "Then, we calculate correlation between the accuracies of annotated data and either those of <cite>Kajiwara and Yamamoto (2015)</cite> or those of our dataset."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_23",
  "x": [
   "The Pearson coefficient shows that our dataset correlates with human annotation better than the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> , possibly because we controlled each sentence to include only one complex word."
  ],
  "y": "differences extends"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_24",
  "x": [
   "Because our dataset is balanced, the accuracy of Web corpus-based metrics (Frequency and Number of Users) closer than the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_25",
  "x": [
   "Finally, to compare two datasets, we used the Pearson product-moment correlation coefficient between our dataset and the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> against the annotated data."
  ],
  "y": "uses"
 },
 {
  "id": "2d3ec2e77947cb23af773926ec917b_26",
  "x": [
   "Finally, to compare two datasets, we used the Pearson product-moment correlation coefficient between our dataset and the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> against the annotated data.",
   "The Pearson coefficient shows that our dataset correlates with human annotation better than the dataset of <cite>Kajiwara and Yamamoto (2015)</cite> , possibly because we controlled each sentence to include only one complex word."
  ],
  "y": "differences extends"
 },
 {
  "id": "2e636754342e9bb857068922519dbc_0",
  "x": [
   "More specifically, these techniques enhanced NLP algorithms through the use of contextualized text embeddings at word, sentence, and paragraph levels (Mikolov et al., 2013; Le and Mikolov, 2014; Peters et al., 2017; <cite>Devlin et al., 2018</cite>; Logeswaran and Lee, 2018; Radford et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "2e636754342e9bb857068922519dbc_1",
  "x": [
   "This embedding model has been proven to offer a better contextualization compared to a bidirectional LSTM model<cite> (Devlin et al., 2018)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "2e636754342e9bb857068922519dbc_2",
  "x": [
   "The idea behind this model is to pre-train a bidirectional representation by jointly conditioning on both left and right contexts in all layers using a transformer (Vaswani et al., 2017;<cite> Devlin et al., 2018)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "2e636754342e9bb857068922519dbc_3",
  "x": [
   "The first version is based on the original BERT release<cite> (Devlin et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2e636754342e9bb857068922519dbc_4",
  "x": [
   "The model has 12 attention layers and all texts are converted to lowercase by the tokenizer<cite> (Devlin et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_0",
  "x": [
   "In the past year, the field of Natural Language Processing (NLP) has seen the rise of pretrained language models such as as ELMo (Peters et al., 2018) , ULMFiT (Howard and Ruder, 2018) and <cite>BERT</cite> (<cite>Devlin et al., 2019</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_1",
  "x": [
   "In the past year, the field of Natural Language Processing (NLP) has seen the rise of pretrained language models such as as ELMo (Peters et al., 2018) , ULMFiT (Howard and Ruder, 2018) and <cite>BERT</cite> (<cite>Devlin et al., 2019</cite>) .",
   "<cite>These approaches</cite> train a deep-learning language model on large volumes of unlabeled text, which is subsequently fine-tuned for particular NLP tasks."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_2",
  "x": [
   "In the past year, the field of Natural Language Processing (NLP) has seen the rise of pretrained language models such as as ELMo (Peters et al., 2018) , ULMFiT (Howard and Ruder, 2018) and <cite>BERT</cite> (<cite>Devlin et al., 2019</cite>) .",
   "Applying <cite>these models</cite> to the General Language Understanding Evaluation (GLUE) benchmark introduced by Wang et al. (2018) has achieved the best performance to date on tasks ranging from sentiment classification to question answering (<cite>Devlin et al., 2019</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_3",
  "x": [
   "In the past year, the field of Natural Language Processing (NLP) has seen the rise of pretrained language models such as as ELMo (Peters et al., 2018) , ULMFiT (Howard and Ruder, 2018) and <cite>BERT</cite> (<cite>Devlin et al., 2019</cite>) .",
   "The benefit of <cite>these models</cite> has also been demonstrated in specialized NLP domains."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_5",
  "x": [
   "While large pretrained models offer significantly increased performance, they come with their own constraints, as the number of parameters in the <cite>classic BERT-base model</cite> exceeds 100 million."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_6",
  "x": [
   "As such, <cite>their</cite> computational cost can thus be prohibitively high at both training and prediction time (<cite>Devlin et al., 2019</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_7",
  "x": [
   "More recent work has addressed this challenge by 'distilling' the models, training smaller versions of <cite>BERT</cite> which reduce the number of parameters to train by 40% while retaining more than 95% of the full model performance and even outperforming it on two out of eleven GLUE tasks ."
  ],
  "y": "background"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_8",
  "x": [
   "We apply the <cite>BERT</cite> approach to the following three previously explored LAK tasks on MOOC forum data (Wei et al., 2017) : Confusion detection, urgency of teacher intervention and sentimentality classification."
  ],
  "y": "extends"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_9",
  "x": [
   "Language Models: We constructed two models, EduBERT and EduDistilBERT, which respectively refine <cite>BERT-base</cite> and DistilBERT , <cite>both of which</cite> were trained on general domain text from books and Wikipedia (<cite>Devlin et al., 2019</cite>) ."
  ],
  "y": "extends"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_10",
  "x": [
   "Language Models: We constructed two models, EduBERT and EduDistilBERT, which respectively refine <cite>BERT-base</cite> and DistilBERT , <cite>both of which</cite> were trained on general domain text from books and Wikipedia (<cite>Devlin et al., 2019</cite>) .",
   "Both models are initialized from their <cite>base model</cite> and finetuned on educational data, using the Transformers library ."
  ],
  "y": "extends"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_11",
  "x": [
   "We compare between the four classifiers <cite>BERT-base</cite>, DistilBERT, EduBERT and EduDistilBERT."
  ],
  "y": "uses"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_12",
  "x": [
   "Best results for these tasks were achieved with the following parameters: two learning epochs, maximal sequence length of 300 (<cite>BERT-base</cite>, EDUBERT) and 512 for the distilled models, all other parameter values were equal to the ones used for pre-training."
  ],
  "y": "uses"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_13",
  "x": [
   "Table 1 compares EduBERT, EduDistilBERT to <cite>their base versions</cite>, as well as the state-of-the-art (SoA) for urgency detection (Guo et al. 2019) ."
  ],
  "y": "uses"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_14",
  "x": [
   "Table 1 compares EduBERT, EduDistilBERT to <cite>their base versions</cite>, as well as the state-of-the-art (SoA) for urgency detection (Guo et al. 2019) .",
   "Table 2 compares all of the <cite>models</cite> for all three tasks to the SoA using the same measures of accuracy as Wei et al. (2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "2eeffe385539b28c7d31eeb176e926_15",
  "x": [
   ". EduBERT and EduDistilBERT are fine-tuned on millions of tokens, in contrast to the billions of tokens required to make the most of the architecture potential (<cite>Devlin et al., 2019</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "307c18e2928c4a45f574a9c3a36b76_0",
  "x": [
   "This research has been applied to a wide array of domains such as Wikipedia talk pages (Strzalkowski et al., 2010; Taylor et al., 2012; Danescu-Niculescu-Mizil et al., 2012; Swayamdipta and Rambow, 2012) , blogs (Rosenthal, 2014) as well as workplace interactions <cite>(Bramsen et al., 2011</cite>; Gilbert, 2012; Prabhakaran, 2015) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "307c18e2928c4a45f574a9c3a36b76_1",
  "x": [
   "While early work <cite>(Bramsen et al., 2011</cite>; Gilbert, 2012) focused on surface level lexical features aggregated at corpus level, more recent work has looked into the thread structure of emails as well (Prabhakaran and Rambow, 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "307c18e2928c4a45f574a9c3a36b76_2",
  "x": [
   "However, both <cite>(Bramsen et al., 2011</cite>; Gilbert, 2012) and (Prabhakaran and Rambow, 2014 ) group all messages sent by an individual to another individual (at the corpus-level and at the thread-level, respectively) and rely on word-ngram * Authors (listed in alphabetical order) contributed equally."
  ],
  "y": "background"
 },
 {
  "id": "307c18e2928c4a45f574a9c3a36b76_3",
  "x": [
   "Grouped: Here, we group all emails A sent to B across all threads in the corpus, and vice versa, and use these sets of emails to predict the power relation between A and B. This formulation is similar those in <cite>(Bramsen et al., 2011</cite>; Gilbert, 2012) , but our results are not directly comparable since, unlike them, we rely on the ground truth of power relations from (Agarwal et al., 2012) ; however, we created an SVM model that uses word-ngram features similar to theirs as a baseline to our proposed neural architectures."
  ],
  "y": "differences similarities extends"
 },
 {
  "id": "307c18e2928c4a45f574a9c3a36b76_4",
  "x": [
   "We use support vector machine (SVM) based approaches as our baseline, since they are the state-of-the art in this problem (Prabhakaran and Rambow, 2014;<cite> Bramsen et al., 2011</cite>; Gilbert, 2012) ."
  ],
  "y": "background uses"
 },
 {
  "id": "307c18e2928c4a45f574a9c3a36b76_5",
  "x": [
   "We use the performance reported by (Prabhakaran and Rambow, 2014) using SVM as baseline for the Per-Thread formulation (using the same train-dev-test splits) and implemented an SVM baseline for the Grouped formulation (not directly comparable to performance reported by <cite>(Bramsen et al., 2011</cite>; Gilbert, 2012) )."
  ],
  "y": "differences extends"
 },
 {
  "id": "310272015a781b05c42015c0559b18_0",
  "x": [
   "Saffran et al. (1996) assume transitional probability, but<cite> Brent (1999a)</cite> claims mutual information (MI) is more appropriate."
  ],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_1",
  "x": [
   "This paper replicates<cite> Brent's (1999a)</cite> mutualinformation model on a corpus of childdirected speech in Modern Greek, and introduces a variant model using a global threshold."
  ],
  "y": "differences similarities background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_2",
  "x": [
   "Several models (e.g., Batchelder, 2002;<cite> Brent's (1999a)</cite> MBDP-1 model; Davis, 2000; de Marcken, 1996; Olivier, 1968) simultaneously address the question of vocabulary acquisition, using previously learned word-candidates to bootstrap later segmentations."
  ],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_3",
  "x": [],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_4",
  "x": [],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_5",
  "x": [
   "Saffran et al. assume implicitly, and<cite> Brent (1999a)</cite> explicitly, that the proper comparison is local-in Brent, dependent solely on the adjacent pairs of segments."
  ],
  "y": "motivation background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_6",
  "x": [
   "In order to see that, we must examine<cite> Brent's (1999a)</cite> suggested implementation of Saffran et al. (1996) more closely."
  ],
  "y": "motivation background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_7",
  "x": [
   "Neither<cite> Brent's (1999a)</cite> implementation of Saffran's et al. (1996) heuristic nor utterance-boundary heuristic can explain how these might be learned."
  ],
  "y": "motivation background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_8",
  "x": [],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_9",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_10",
  "x": [
   "While in its general approach the study reported here replicates the mutual-information and transitional-probability models in<cite> Brent (1999a)</cite> , it differs slightly in the details of their use."
  ],
  "y": "differences background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_11",
  "x": [
   "4 Secondly, we compare the use of a global threshold (described in more detail in Section 2.3, below) to<cite> Brent's (1999a)</cite> use of the local context (as described in Section 1.3 above)."
  ],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_12",
  "x": [
   "Like <cite>(Brent, 1999a)</cite> , but unlike Saffran et al. (1996) , our model focuses on pairs of segments, not on pairs of syllables."
  ],
  "y": "similarities background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_13",
  "x": [
   "Like<cite> Brent (1999a)</cite> and indeed most models in the literature, this model assumes (for sake of convenience and simplicity) that the child hears each segment produced within an utterance without error."
  ],
  "y": "uses background motivation"
 },
 {
  "id": "310272015a781b05c42015c0559b18_14",
  "x": [
   "The second metric, the percentage of word tokens detected, is the same as<cite> Brent (1999a)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "310272015a781b05c42015c0559b18_15",
  "x": [
   "The last metric (word type) is slightly more conservative than<cite> Brent's (1999a)</cite> in that the word type must have been actually spoken in the same utterance (not the same block of 500 utterances) in which it was detected to count as a match."
  ],
  "y": "extends motivation"
 },
 {
  "id": "310272015a781b05c42015c0559b18_16",
  "x": [
   "Tables 2 and 3 present the results over the test set for both the global and the local comparisons of the predictability statistics proposed by Saffran et al. (1996) and<cite> Brent (1999a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "310272015a781b05c42015c0559b18_17",
  "x": [
   "The findings here confirm<cite> Brent's (1999a)</cite> contention that mutual information is a better measure of predictability than is transitional probability-at least for the task of identifying words, not just boundaries."
  ],
  "y": "similarities"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_0",
  "x": [
   "In this study we apply the methods of Foltz et al. (1998) ,<cite> Hearst (1994</cite> Hearst ( , 1997 , and a new technique utilizing an orthonormal basis to topic segmentation of tutorial dialogue."
  ],
  "y": "uses"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_1",
  "x": [
   "Both<cite> Hearst (1994</cite> Hearst ( , 1997 and Foltz et al. (1998) use vector space methods discussed below to represent and compare units of text."
  ],
  "y": "background"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_2",
  "x": [
   "However,<cite> Hearst (1994</cite> Hearst ( , 1997 and Foltz et al. (1998) differ on how text units are defined and on how to interpret the results of a comparison."
  ],
  "y": "background"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_3",
  "x": [
   "The text unit's definition in<cite> Hearst (1994</cite> Hearst ( , 1997 and Foltz et al. (1998) is generally task dependent, depending on what size gives the best results."
  ],
  "y": "background"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_4",
  "x": [
   "Hearst likewise chooses a large unit, 6 token-sequences of 20 tokens <cite>(Hearst, 1994)</cite> , but varies these parameters dependent on the characteristics of the text to be segmented, e.g. paragraph size."
  ],
  "y": "background"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_5",
  "x": [
   "A variant of<cite> Hearst (1994</cite> Hearst ( , 1997 was created by using LSA instead of the standard vector space method."
  ],
  "y": "differences"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_6",
  "x": [
   "The JTextTile software was used to implement<cite> Hearst (1994)</cite> on dialogue."
  ],
  "y": "uses"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_7",
  "x": [
   "This combination matches<cite> Hearst (1994)</cite> 's heuristic of choosing the window size to be the average paragraph length."
  ],
  "y": "uses"
 },
 {
  "id": "3128481fa4e5d2c4af7deba2c28950_9",
  "x": [
   "It may be that<cite> Hearst (1994</cite> Hearst ( , 1997 )'s segmentation criterion, i.e. depth scores, do not translate well to dialogue."
  ],
  "y": "differences"
 },
 {
  "id": "318487ac270ca272ec11a3de6c0685_0",
  "x": [
   "On a standard paraphrase identification task (Dolan et al., 2004) , this method improves on both traditional TF-IDF and Weighted Textual Matrix Factorization (WTMF;<cite> Guo and Diab, 2012)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "318487ac270ca272ec11a3de6c0685_2",
  "x": [
   "While previous work has performed paraphrase classification using distance or similarity in the latent space<cite> (Guo and Diab, 2012</cite>; Socher et al., 2011) , more direct supervision can be applied."
  ],
  "y": "background"
 },
 {
  "id": "318487ac270ca272ec11a3de6c0685_4",
  "x": [
   "As in prior work<cite> (Guo and Diab, 2012)</cite> , the threshold is tuned on held-out training data."
  ],
  "y": "similarities uses"
 },
 {
  "id": "318487ac270ca272ec11a3de6c0685_5",
  "x": [
   "To compare with<cite> Guo and Diab (2012)</cite> , we set the latent dimensionality to K = 100, which was the same in their paper."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_0",
  "x": [
   "Translation from speech utterances is a challenging problem that has been studied both under statistical, symbolic approaches (Ney, 1999; Casacuberta et al., 2004; Kumar et al., 2015) and more recently using neural models <cite>(Sperber et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_1",
  "x": [
   "<cite>Sperber et al. (2017)</cite> proposes a lattice-tosequence model which, in theory, can address both problems above."
  ],
  "y": "background"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_2",
  "x": [
   "However, <cite>their model</cite> suffers from training speed performance due to the lack of efficient batching procedures and they rely on transcriptions for pretraining."
  ],
  "y": "motivation"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_3",
  "x": [
   "1 This procedure is also done in <cite>Sperber et al. (2017)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_4",
  "x": [
   "Following previous work (Post et al., 2013; <cite>Sperber et al., 2017)</cite> , we lowercase and remove punctuation from the English translations."
  ],
  "y": "uses"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_5",
  "x": [
   "For the word-based models, we remove any tokens with frequency lower than 2 (as in <cite>Sperber et al. (2017)</cite> ), while for subword models we do not perform any threshold pruning."
  ],
  "y": "uses"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_6",
  "x": [
   "We also slightly outperform <cite>Sperber et al. (2017)</cite> in the setting where they ignore lattice scores, as in our approach."
  ],
  "y": "differences"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_7",
  "x": [
   "Most importantly, we are able to reach those results while being two orders of magnitude faster at training time: <cite>Sperber et al. (2017)</cite> report taking 1.5 days for each epoch while our architecture can process each epoch in 15min."
  ],
  "y": "differences"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_8",
  "x": [
   "The reason is because <cite>their model</cite> relies on the CPU while our GGNN-based model can be easily batched and computed in a GPU."
  ],
  "y": "differences"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_9",
  "x": [
   "Given those differences in training time, it is worth mentioning that the best model in <cite>Sperber et al. (2017)</cite> is surpassed by our best ensemble using lattices only."
  ],
  "y": "differences"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_10",
  "x": [
   "It is worth noticing that <cite>Sperber et al. (2017)</cite> has a more principled approach to incorporate scores: by modifying the attention module."
  ],
  "y": "differences"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_11",
  "x": [
   "The approaches used by <cite>Sperber et al. (2017)</cite> can provide a starting point in this direction."
  ],
  "y": "uses"
 },
 {
  "id": "3251c6cd1afccf6ad8d5391a4360b0_12",
  "x": [
   "The approaches used by <cite>Sperber et al. (2017)</cite> can provide a starting point in this direction."
  ],
  "y": "future_work"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_0",
  "x": [
   "Previous approaches include rule-based methods based on finite state transducers (Farley, 2009; Littell, 2018; Kazeminejad et al., 2017) , hybrid models (Mager et al., 2018b; Moeller et al., 2018) , and supervised machine learning, particularly deep learning approaches (Micher, 2017; <cite>Kann et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_1",
  "x": [
   "We experiment with four UtoAztecan languages: Mexicanero (MX), Nahuatl (NH), Wixarika (WX) and Yorem Nokki (YN)<cite> (Kann et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_2",
  "x": [
   "We use the datasets introduced by<cite> Kann et al. (2018)</cite> in an unsupervised fashion (unsegmented words)."
  ],
  "y": "uses"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_3",
  "x": [
   "We design several AG learning setups: 1) use the best-on-average AG setup from Eskander et al. (2016) ; 2) optimize for language using just the small training vocabulary (unsegmented) and dev vocabulary (segmented) from<cite> Kann et al. (2018)</cite> ; 3) approximate the effect of having some linguistic knowledge; 4) learn from all languages at once and 5) add additional unsupervised data for NH and WX (Section 3)."
  ],
  "y": "uses"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_4",
  "x": [],
  "y": "uses"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_5",
  "x": [
   "They were constructed so they include both segmentable as well as non-<cite> Kann et al. (2018)</cite> , for training we do not use the segmented version of the data (our approach is unsupervised)."
  ],
  "y": "uses"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_6",
  "x": [
   "In the dataset from<cite> (Kann et al., 2018)</cite> , the maximum number of morphemes per word for MX is seven with an average of 2.13; for NH, six with an average of 2.2; for WX, maximum of ten with an average of 3.3; and for YN, the maximum is ten, with an average of 2.13."
  ],
  "y": "background"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_7",
  "x": [
   "However, since affixes and stems are not distinguished in the training annotations from<cite> Kann et al. (2018)</cite> , we only consider the first and last morphemes that appear at least five times."
  ],
  "y": "motivation"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_8",
  "x": [
   "Since the vocabulary in<cite> Kann et al. (2018)</cite> for each language is small, and the languages are from the same language family, one data augmentation approach is to train on all languages and test then on each language individually."
  ],
  "y": "motivation"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_9",
  "x": [
   "We evaluate the different AG setups on the blind test set from<cite> Kann et al. (2018)</cite> and compare our AG approaches to state-of-the-art unsupervised systems as well as supervised models including the best supervised deep learning models from<cite> Kann et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_13",
  "x": [
   "An interesting observation is that for YN we only used the words in the training set of<cite> Kann et al. (2018)</cite> (unsegmented) , without any data augmentation."
  ],
  "y": "uses"
 },
 {
  "id": "34346688a7e5166ee7b559ccbfe8e3_14",
  "x": [
   "For MX and WX, the neural models from<cite> Kann et al. (2018)</cite> (BestMTT and BestDA), outperform our unsupervised AG-based approaches."
  ],
  "y": "differences"
 },
 {
  "id": "3452953ac579f1c05870442456a49c_0",
  "x": [
   "In recent studies, various classes of features are explored to capture lexical and semantic regularities for identifying the sense of implicit relations, including linguistically informed features like polarity tags, Levin verb classes, length of verb phrases, language model based features, contextual features, constituent parse features and dependency parse features <cite>(Lin et al., 2009</cite>; Pitler et al., 2009; Zhou et al., 2010; Zhang et al., 2015; Chen et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "3452953ac579f1c05870442456a49c_1",
  "x": [
   "The test set that is currently most often used for 11 way classification is section 23 <cite>(Lin et al., 2009</cite>; Ji and Eisenstein, 2015; Rutherford et al., 2017) , which contains only about 761 implicit relations."
  ],
  "y": "background"
 },
 {
  "id": "3452953ac579f1c05870442456a49c_2",
  "x": [
   "Previous work in this task has been done over two schemes of evaluation: first-level 4-ways classification (Pitler et al., 2009; Rutherford and Xue, 2014; Chen et al., 2016) , second-level 11-way classification <cite>(Lin et al., 2009</cite>; Ji and Eisenstein, 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "3452953ac579f1c05870442456a49c_3",
  "x": [
   "We follow the preprocessing method in <cite>(Lin et al., 2009</cite>; Rutherford et al., 2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "3452953ac579f1c05870442456a49c_4",
  "x": [
   "As a label set, we use 11-way distinction as proposed in<cite> Lin et al., (2009)</cite>; Ji and Eisenstein (2015) ."
  ],
  "y": "uses"
 },
 {
  "id": "3477c0225d6a0e55365242d95a3dc9_0",
  "x": [
   "Word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of NLP tasks [7, 8, <cite>9]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "365171603fb13c6534ef4abab092d6_0",
  "x": [
   "Our contributions are as follows: (1) we achieve state-of-the-art results on benchmark Twitter geolocation datasets; (2) we show that the model is less sensitive to the specific location discretisation method; (3) we release the first broad-coverage dataset for evaluation of lexical dialectology models; (4) we incorporate our text-based model into a network-based model<cite> (Rahimi et al., 2015a)</cite> and improve the performance utilising both network and text; and (5) we use the model's embeddings for extraction of local terms and show that it outperforms two baselines."
  ],
  "y": "extends background"
 },
 {
  "id": "365171603fb13c6534ef4abab092d6_1",
  "x": [
   "Network-based methods also use either real-valued coordinates (Jurgens et al., 2015) or discretised regions<cite> (Rahimi et al., 2015a)</cite> as labels, and use label propagation over the interaction graph (e.g. @-mentions)."
  ],
  "y": "background"
 },
 {
  "id": "365171603fb13c6534ef4abab092d6_2",
  "x": [
   "More recent methods have focused on representation learning by using sparse coding (Cha et al., 2015) or neural networks (Liu and Inkpen, 2015) , utilising both text and network information<cite> (Rahimi et al., 2015a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "365171603fb13c6534ef4abab092d6_3",
  "x": [
   "4 The results reported in Rahimi et al. (2015b;<cite> 2015a)</cite> for TWITTER-WORLD were over a superset of the dataset; the results reported here are based on the actual dataset."
  ],
  "y": "differences"
 },
 {
  "id": "365171603fb13c6534ef4abab092d6_4",
  "x": [
   "While the focus of this paper is text-based user geolocation, state-of-the-art results for the three datasets have been achieved with hybrid text+network-based models, where the predictions of the text-based model are fed into a mention network as \"dongle\" nodes to each user node, providing a personalised geolocation prior for each user<cite> (Rahimi et al., 2015a)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "365171603fb13c6534ef4abab092d6_5",
  "x": [
   "We also incorporated the MLP predictions into a network-based model based on the method of <cite>Rahimi et al. (2015a)</cite> , and improved upon their work."
  ],
  "y": "extends background"
 },
 {
  "id": "373795850c8f182051214a8ee09461_0",
  "x": [
   "In the last decade, standard DSMs using bag-of-words or syntactic cooccurrence counts have been enhanced by integration into neural networks Levy et al., 2015; Nguyen et al., 2016) , or by integrating perceptual information (Silberer and Lapata, 2014; Bruni et al., 2014; <cite>Kiela et al., 2014</cite>; Lazaridou et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "373795850c8f182051214a8ee09461_1",
  "x": [
   "Furthermore, we zoom into factors that might influence the quality of predictions, such as lexical and empirical target properties (e.g., ambiguity, frequency, compositionality); and filters to optimise the visual space, such as dispersion and imageability filters<cite> (Kiela et al., 2014)</cite> , and a novel clustering filter."
  ],
  "y": "background"
 },
 {
  "id": "373795850c8f182051214a8ee09461_2",
  "x": [
   "We therefore apply the dispersion-based filter suggested by<cite> Kiela et al. (2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "373795850c8f182051214a8ee09461_3",
  "x": [
   "For GS-NN, the compositionality of concrete and imaginable targets is predicted better than for abstract and less imaginable targets, as one would expect and has been shown by<cite> Kiela et al. (2014)</cite> ; for GS-PV, the opposite is the case."
  ],
  "y": "similarities"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_0",
  "x": [
   "In recent years, an increasing number of studies have investigated character-level models with subwords in both unsupervised<cite> (Bojanowski et al., 2017</cite>; Pagliardini et al., 2018) and supervised learning (Zhang et al., 2015; Sennrich et al., 2016; Wieting et al., 2016; Lee et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_1",
  "x": [
   "By enriching the information of the word, sub-words are useful for capturing morphological changes<cite> (Bojanowski et al., 2017)</cite> and the meaning of short phrases (Wieting et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_2",
  "x": [
   "In addition, OOV (or unseen) words can be composed from sub-words, which are present at training<cite> (Bojanowski et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_3",
  "x": [
   "Each n-gram is explicitly modeled as a composition of its sub-n-grams just like each word is modeled as a composition of sub-words in the subword information skipgram model (SISG)<cite> (Bojanowski et al., 2017)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_5",
  "x": [
   "As baseline systems, we use C-BOW, Skipgram (Mikolov et al., 2013) , Subword Information Skip-gram (SISG)<cite> (Bojanowski et al., 2017)</cite> and Segmentation-free word embedding for unsegmented languages (Sembei) (Oshikiri, 2017) for the word-level tasks."
  ],
  "y": "uses"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_6",
  "x": [
   "Most of the settings are the same as that of <cite>Bojanowski et al. (2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "375b9c865d9f1b559387aa01a20a78_7",
  "x": [
   "In order to show comparable results, we use the null vector for these OOV words following <cite>Bojanowski et al. (2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_0",
  "x": [
   "In particular, we use methods proposed by Marie and Fujita (2018) , <cite>Artetxe et al. (2018b)</cite> , and Lample et al. (2018) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_1",
  "x": [
   "This code is derived from <cite>Artetxe et al. (2018b)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_2",
  "x": [
   "As in <cite>Artetxe et al. (2018b)</cite> , the term was set to 0.001."
  ],
  "y": "similarities"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_3",
  "x": [
   "For backward refinement<cite> (Artetxe et al., 2018b)</cite> , source synthetic data were generated from the target monolingual data using the target to source phrase table P (0) t\u2192s and source language model LM s ."
  ],
  "y": "background"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_4",
  "x": [
   "In fact, Lample et al. (2018) , <cite>Artetxe et al. (2018b)</cite> and Marie and Fujita (2018) use the News Crawl of source and target language as training data."
  ],
  "y": "background"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_5",
  "x": [
   "The implementation made by <cite>Artetxe et al. (2018b)</cite> 6 was modified to conduct the experiments."
  ],
  "y": "differences extends"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_6",
  "x": [
   "<cite>Artetxe et al. (2018b)</cite> and Lample et al. (2018) reported that the BLEU score (Papineni et al., 2002) of unsupervised MT with backward-refinement improves with increasing iterations."
  ],
  "y": "background"
 },
 {
  "id": "3bbc588f06e326e1d75985fe253a5f_8",
  "x": [
   "In this study, we apply the USMT method of <cite>Artetxe et al. (2018b)</cite> and Marie and Fujita (2018) to GEC."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_0",
  "x": [
   "Previous approaches have used structured predictors such as hidden Markov models (HMMs) or conditional random fields (CRFs), which consider the interactions between neighboring words and parts of speech (Nagata, 1994; Asahara and Matsumoto, 2000;<cite> Kudo et al., 2004)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_1",
  "x": [
   "We find experimental evidence that pointwise MA can exceed the accuracy of a state-of-the-art structured approach<cite> (Kudo et al., 2004)</cite> on in-domain data, and is significantly more robust to out-of-domain data."
  ],
  "y": "differences"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_2",
  "x": [
   "This can be formulated as a two-step process of first segmenting words, then estimating POSs (Ng and Low, 2004) , or as a single joint process of finding a morpheme/POS string from unsegmented text <cite>(Kudo et al., 2004</cite>; Nakagawa, 2004; Kruengkrai et al., 2009) ."
  ],
  "y": "background"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_3",
  "x": [
   "The CRF-based method presented by<cite> Kudo et al. (2004)</cite> is generally accepted as the state-of-the-art in this paradigm."
  ],
  "y": "background"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_4",
  "x": [
   "We follow<cite> Kudo et al. (2004)</cite> in defining our feature set, as summarized in Table 1 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_5",
  "x": [
   "1 More fine-grained POS tags have provided small boosts in accuracy in previous research<cite> (Kudo et al., 2004)</cite> , but these increase the annotation burden, which is contrary to our goal."
  ],
  "y": "background"
 },
 {
  "id": "3ced64da2c64b0963c4c3d88fd60e0_7",
  "x": [
   "As an evaluation measure, we follow Nagata (1994) and<cite> Kudo et al. (2004)</cite> and use Word/POS tag pair Fmeasure, so that both word boundaries and POS tags must be correct for a word to be considered correct."
  ],
  "y": "uses"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_1",
  "x": [
   "Many approaches have been used in DP, the majority of them using machine learning algorithms, such as probabilistic models<cite> (Soricut and Marcu, 2003)</cite> , SVMs (Reitter, 2003; duVerle and Prendinger, 2009; Hernault et al., 2010; Feng and Hirst, 2012) and dynamic conditional random field (Joty et al., 2012) ."
  ],
  "y": "background"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_2",
  "x": [
   "Many approaches have been used in DP, the majority of them using machine learning algorithms, such as probabilistic models<cite> (Soricut and Marcu, 2003)</cite> , SVMs (Reitter, 2003; duVerle and Prendinger, 2009; Hernault et al., 2010; Feng and Hirst, 2012) and dynamic conditional random field (Joty et al., 2012) ."
  ],
  "y": "motivation"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_3",
  "x": [
   "2 Related Work 2.1 Supervised Discourse Parsing<cite> Soricut and Marcu (2003)</cite> use two probabilistic models to perform a sentence-level analysis, one for segmentation and other to identify the relations and build the rhetorical structure."
  ],
  "y": "background"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_4",
  "x": [
   "With the aim of surpassing the limitation of labeled RST in Portuguese to develop a good DP, we employ SSNEL in the task by adapting the work of<cite> Soricut and Marcu (2003)</cite> and Hernault et al. (2010) ."
  ],
  "y": "uses"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_5",
  "x": [
   "This work focuses on the identification of rhetorical relations at the sentence level, and as is common since the work of<cite> Soricut and Marcu (2003)</cite> , fine-grained relations were grouped: 29 sentence-level rhetorical relations were found and grouped into 16 groups."
  ],
  "y": "similarities background uses"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_6",
  "x": [
   "Syntactic information is crucial in SPADE<cite> (Soricut and Marcu, 2003)</cite> and for Portuguese the parser most similar to that used by Soricut and Marcu is the LX-parser (Stanford parser trained to Portuguese (Silva et al., 2010) )."
  ],
  "y": "uses"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_7",
  "x": [
   "Syntactic information is crucial in SPADE<cite> (Soricut and Marcu, 2003)</cite> and for Portuguese the parser most similar to that used by Soricut and Marcu is the LX-parser (Stanford parser trained to Portuguese (Silva et al., 2010) )."
  ],
  "y": "background"
 },
 {
  "id": "3d99ad1ba1696c8ef743f233530601_8",
  "x": [
   "Using separated test data, we tried to avoid possible overfitting on training data, but the size of test data may not lead to a fair evaluation<cite> Soricut and Marcu (2003)</cite> or Joty et al. (2012) , since HILDA-PT used different corpora (RST-DT-PT instead of RST-DT), and some reported results are for the complete DP."
  ],
  "y": "background"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_0",
  "x": [
   "An alternative way of dealing with structural differences is to reorder source language sentences to minimize structural divergence with the target language, (Xia and McCord, 2004; Collins et al., 2005;<cite> Wang et al., 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_1",
  "x": [
   "For example <cite>Wang et al. (2007)</cite> introduced a set of rules to decide if a (DE) construction should be reordered or not before translating to English:",
   "Indeed, <cite>Wang et al. (2007)</cite> found that the precision of their NP rules is only about 54.6% on a small human-judged set."
  ],
  "y": "motivation background"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_3",
  "x": [
   "Similar to<cite> (Wang et al., 2007)</cite> , we only consider the majority case when the phrase with (DE) is a noun phrase modifier."
  ],
  "y": "background similarities"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_4",
  "x": [
   "This is implicitly done in the work of <cite>Wang et al. (2007)</cite> where they use rules to decide if a certain DE and the words next to it will need to be reordered."
  ],
  "y": "background similarities"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_6",
  "x": [
   "2 As a baseline, we use the rules introduced in <cite>Wang et al. (2007)</cite> to decide if the DEs require reordering or not.",
   "So, in order to compare our classifier's performance with the rules in <cite>Wang et al. (2007)</cite> , we have to map our five-class results into two classes."
  ],
  "y": "extends"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_8",
  "x": [
   "Secondly, we want to incorporate the rules in<cite> (Wang et al., 2007)</cite> as features in the log-linear classifier."
  ],
  "y": "uses"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_9",
  "x": [
   "Features 1-3 are inspired by the rules in<cite> (Wang et al., 2007)</cite> , and the fourth rule is based on the observation that even though the predicative adjective VA acts as a verb, it actually corresponds to adjectives in English as described in (Xia, 2000) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_11",
  "x": [
   "Also, we reorder the training data, the tuning and the test sets with the NP rules in<cite> (Wang et al., 2007)</cite> and compare our results with this second baseline (WANG-NP)."
  ],
  "y": "background uses"
 },
 {
  "id": "3dbdf61d07a3e35ac1b6ecc7ab3999_12",
  "x": [
   "Our approach DE-Annotated reorders the Chinese sentence, which is similar to the approach proposed by <cite>Wang et al. (2007)</cite> (WANG-NP)."
  ],
  "y": "differences similarities"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_0",
  "x": [
   "this setting, we apply the methodology used by <cite>Shoemark et al. (2017)</cite> in the context of the 2014 Scottish independence referendum to a dataset of tweets related to the Catalonian referendum."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_1",
  "x": [
   "With respect to political separatism, <cite>Shoemark et al. (2017)</cite> studied the use of Scots, a language local to Scotland, in the context of the 2014 Scotland independence referendum."
  ],
  "y": "background"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_2",
  "x": [
   "Our main methodological divergence from <cite>Shoemark et al. (2017)</cite> relates to the linguistic phenomenon at hand: while Scots is mainly manifested as interleaving individual words within English text (code-mixing), Catalan is a distinct language which, when used, usually replaces Spanish altogether for the entire tweet (code-switching)."
  ],
  "y": "similarities"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_3",
  "x": [
   "After removing retweets and tweets from users whose tweets frequently contained URLs (i.e., likely bots), our final \"Catalonian Independence Tweets\" (CT) dataset is made up of 11,670 tweets from 10,498 users (cf. the Scottish referendum set IT with 59,664 tweets and 18,589 users in <cite>Shoemark et al. (2017)</cite> )."
  ],
  "y": "similarities uses"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_4",
  "x": [
   "They are shown with their frequencies (including variants) in Table 1 (cf. the 47 hashtags and similar frequency distribution in Table 1 of <cite>Shoemark et al. (2017)</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_5",
  "x": [
   "the 693,815 control tweets in Table 6 of <cite>Shoemark et al. (2017)</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_6",
  "x": [
   "This is consistent with <cite>Shoemark et al. (2017)</cite> , who found more Scots usage among proindependence users (d = 0.00555 for pro/anti tweets, d = 0.00709 for all tweets)."
  ],
  "y": "similarities"
 },
 {
  "id": "3e0704e0928f2df8b7c2ffa9863a55_7",
  "x": [
   "Table 7 in <cite>Shoemark et al. (2017)</cite> ; d u = \u22120.0015 for all controls)."
  ],
  "y": "differences"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_0",
  "x": [
   "Since Ramshaw and Marcus approached NP chunking using a machine learning method, many researchers have used various machine learning techniques [2, 4, 5, <cite>6,</cite> 10, 11, 13, 14] ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_1",
  "x": [
   "Chunking in Korean texts with only simple heuristic rules obtained through observation on the text shows a good performance similar to other machine learning methods<cite> [6]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_2",
  "x": [
   "Park et al. proposed a hybrid of rule-based and machine learning method to handle exceptional cases of the rules, to improve the performance of chunking in Korean texts [5,<cite> 6]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_3",
  "x": [
   "Chunking in Korean texts with only simple heuristic rules obtained through observation on the text shows a good performance similar to other machine learning methods<cite> [6]</cite> .",
   "Park et al. proposed a hybrid of rule-based and machine learning method to handle exceptional cases of the rules, to improve the performance of chunking in Korean texts [5,<cite> 6]</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_4",
  "x": [
   "For example, when the part-of-speech of current word is one of determiner, pronoun and noun, the following seven rules for NP chunking in Table 1 can find most NP chunks in text, with about 89% accuracy<cite> [6]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_5",
  "x": [
   "Park et al. proposed a hybrid of the rule-based and the machine learning method to resolve this problem [5,<cite> 6]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_6",
  "x": [
   "In Korean, there are four basic phrases: noun phrase (NP), verb phrase (VP), adverb phrase (ADVP), and independent phrase (IP)<cite> [6]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_7",
  "x": [
   "Park et al. reported the performance of various chunking methods<cite> [6]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "3e86788379f2c0074ff16687d68fc9_8",
  "x": [
   "Park et al. reported the performance of various chunking methods<cite> [6]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "3ec2dc9530699f55b8a4c234532daf_0",
  "x": [
   "This task aims to select the best-matched response from a set of candidates, given the context of a conversation which is composed of multiple utterances<cite> (Lowe et al., 2015</cite>; Lowe et al., 2017; Wu et al., 2017 )."
  ],
  "y": "background"
 },
 {
  "id": "3ec2dc9530699f55b8a4c234532daf_1",
  "x": [
   "This approach has the advantage of providing informative and fluent responses because they select a proper response for the current conversation from a repository by means of response selection algorithms<cite> (Lowe et al., 2015</cite>; Lowe et al., 2017 EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EA  EB  EB  EB  EB  EB   E0  E1  E2  E3  E4  E5  E18  E19  E6  E7  E8  E9  E10  E11  E17  E12  E13  E14  E15  E16  E20  E21  E22  E23  E24  E25 [ E0  E0  E0  E0  E0  E0  E0  E0  E1  E1  E1  E1  E1  E1  E0  E1  E1  E1  E1  E1  E0  E1  E1  E1  E1  E1 Speaker Embeddings + + + + + + + + + + + + + + + + + + + + + + + + + + Figure 1 : The input representation of SA-BERT."
  ],
  "y": "similarities background"
 },
 {
  "id": "3ec2dc9530699f55b8a4c234532daf_2",
  "x": [
   "We tested SA-BERT on five public multi-turn response selection datasets, Ubuntu Dialogue Corpus V1<cite> (Lowe et al., 2015)</cite> , Ubuntu Dialogue Corpus V2 (Lowe et al., 2017) , Douban Conversation Corpus (Wu et al., 2017) , E-commerce Dialogue Corpus (Zhang et al., 2018b) and DSTC 8-Track 2-Subtask 2 Corpus (Seokhwan Kim, 2019)."
  ],
  "y": "uses background"
 },
 {
  "id": "3ec2dc9530699f55b8a4c234532daf_3",
  "x": [
   "We used the same evaluation metrics as those used in previous work<cite> (Lowe et al., 2015</cite>; Lowe et al., 2017; Wu et al., 2017; Zhang et al., 2018b; Seokhwan Kim, 2019) ."
  ],
  "y": "uses"
 },
 {
  "id": "400bd47879aaed0aa1195bafe54e76_0",
  "x": [
   "Consequently, it is unknown if Indonesian word embeddings introduced in, e.g., (Al-Rfou et al., 2013) and <cite>(Grave et al., 2018)</cite> , capture syntactic or semantic information as measured by analogy tasks."
  ],
  "y": "background"
 },
 {
  "id": "400bd47879aaed0aa1195bafe54e76_1",
  "x": [
   "We used fastText pretrained embeddings introduced in (Bojanowski et al., 2017 ) and <cite>(Grave et al., 2018)</cite> , which have been trained on Indonesian Wikipedia and Indonesian Wikipedia plus Common Crawl data respectively."
  ],
  "y": "uses"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_0",
  "x": [
   "Techniques for generating lower-rank representations have also been employed, such as PPMI-SVD <cite>(Levy et al., 2015)</cite> and GloVe (Pennington et al., 2014) , both achieving state-of-the-art performance on a variety of tasks."
  ],
  "y": "background"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_1",
  "x": [
   "The performance of the PPMI matrix on word similarity tasks can be further improved by using context-distribution smoothing <cite>(Levy et al., 2015)</cite> and subsampling the corpus (Mikolov et al., 2013b) ."
  ],
  "y": "background"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_2",
  "x": [
   "As word embeddings with lower dimensionality may improve efficiency and generalization <cite>(Levy et al., 2015)</cite> , the improved PPMI * matrix can be factorized as a product of two lower rank matrices."
  ],
  "y": "background"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_3",
  "x": [
   "Although the optimal value of p is highly task-dependent (\u00d6sterlund et al., 2015) , we set p = 0.5 as it has been shown to perform well on the word similarity and analogy tasks we use in our experiments <cite>(Levy et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_4",
  "x": [
   "The PPMI* matrix used by both PPMI-SVD and LexVec was constructed using smoothing of \u03b1 = 3/4 suggested in <cite>(Levy et al., 2015)</cite> and an unweighted window of size 2."
  ],
  "y": "uses"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_5",
  "x": [
   "2 Additionally, SGNS uses 5 negative samples (Mikolov et al., 2013b) , a window of size 10 (<cite> Levy et al., 2015)</cite> , for 5 iterations with initial learning rate set to the default 0.025."
  ],
  "y": "uses"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_6",
  "x": [
   "All methods generate both word and context matrices (W andW ): W is used for SGNS, PPMI-SVD and W +W for GloVe (following<cite> Levy et al. (2015)</cite> , and W and W +W for LexVec."
  ],
  "y": "uses"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_7",
  "x": [
   "For evaluation, we use standard word similarity and analogy tasks (Mikolov et al., 2013b; Pennington et al., 2014;<cite> Levy et al., 2015</cite> factorization of logM ) and Skip-gram (implicit factorization of the shifted PMI matrix), and compare the stochastic and mini-batch approaches."
  ],
  "y": "uses"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_8",
  "x": [
   "This is inline with results for PPMI-SVD and SGNS models <cite>(Levy et al., 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_9",
  "x": [
   "This is inline with results for PPMI-SVD and SGNS models <cite>(Levy et al., 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "40742bac72bbbaed4755ff0b74d599_10",
  "x": [],
  "y": "similarities"
 },
 {
  "id": "40d370558d873499e493a83f106f17_0",
  "x": [
   "Large-scale distributional thesauri created automatically from corpora (Grefenstette, 1994;<cite> Lin, 1998</cite>; Weeds et al., 2004; Ferret, 2012) are an inexpensive and fast alternative for representing semantic relatedness between words, when manually constructed resources like WordNet (Fellbaum, 1998 ) are unavailable or lack coverage."
  ],
  "y": "background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_1",
  "x": [
   "Much attention has been devoted to refining thesaurus quality, improving informativeness and similarity measures<cite> (Lin, 1998</cite>; Curran and Moens, 2002; Ferret, 2010) , identifying and demoting bad neighbors (Ferret, 2013) , or using more relevant contexts (Broda et al., 2009; Biemann and Riedl, 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_2",
  "x": [
   "The contexts in which a target word appears can be extracted in terms of a window of cooccurring (content) words surrounding the target (Freitag et al., 2005; Ferret, 2012; Erk and Pado, 2010) or in terms of the syntactic dependencies in which the target appears<cite> (Lin, 1998</cite>; McCarthy et al., 2003; Weeds et al., 2004) ."
  ],
  "y": "background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_3",
  "x": [
   "The informativeness of each context is calculated using measures like PMI, and t-test while the similarity between contexts is calculated using measures like <cite>Lin's (1998)</cite> , cosine, Jensen-Shannon divergence, Dice or Jaccard."
  ],
  "y": "background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_4",
  "x": [
   "Evaluation of the quality of distributional thesauri is a well know problem in the area<cite> (Lin, 1998</cite>; Curran and Moens, 2002) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_5",
  "x": [
   "For instance, for intrinsic evaluation, the agreement between thesauri has been examined, looking at the average similarity of a word in the thesauri<cite> (Lin, 1998)</cite> , and at the overlap and rank agreement between the thesauri for target words like nouns (Weeds et al., 2004) ."
  ],
  "y": "background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_6",
  "x": [
   "Evaluation of the quality of distributional thesauri is a well know problem in the area<cite> (Lin, 1998</cite>; Curran and Moens, 2002) .",
   "For instance, for intrinsic evaluation, the agreement between thesauri has been examined, looking at the average similarity of a word in the thesauri<cite> (Lin, 1998)</cite> , and at the overlap and rank agreement between the thesauri for target words like nouns (Weeds et al., 2004) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "40d370558d873499e493a83f106f17_7",
  "x": [
   "For instance, for intrinsic evaluation, the agreement between thesauri has been examined, looking at the average similarity of a word in the thesauri<cite> (Lin, 1998)</cite> , and at the overlap and rank agreement between the thesauri for target words like nouns (Weeds et al., 2004) ."
  ],
  "y": "motivation"
 },
 {
  "id": "40d370558d873499e493a83f106f17_8",
  "x": [
   "The thesauri were constructed using <cite>Lin's (1998)</cite> method."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_0",
  "x": [
   "May et al. <cite>[21]</cite> establish a preliminary study of social bias in BERT, but their analysis relies only on sentence level encodings."
  ],
  "y": "motivation background"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_1",
  "x": [
   "We adapt the Sentence Encoder Association Test (SEAT) <cite>[21]</cite> to evaluate how these techniques displays bias in contextual word representations."
  ],
  "y": "extends"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_2",
  "x": [
   "Zhao et al. [35] and Basta et al. [1] demonstrate gender bias in ELMo [25] word embeddings, whereas May et al. <cite>[21]</cite> evaluate various models of contextual word representations on a sentential generalization of WEAT."
  ],
  "y": "background"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_3",
  "x": [
   "We adopt the methodology of Caliskan et al. [5] and May et al. <cite>[21]</cite> to test social and intersectional bias using embedding association tests with contextual word representations."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_4",
  "x": [
   "We follow May et al. <cite>[21]</cite> in describing WEATs and SEATs."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_5",
  "x": [
   "May et al. <cite>[21]</cite> adopt the WEAT tests [5] into Sentence Encoder Association Tests (SEATs) to test biases using sentence encodings."
  ],
  "y": "background"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_6",
  "x": [
   "May et al. <cite>[21]</cite> suggest that although they find less bias in sentence encoders than context free word embeddings, the sentence templates may not be as semantically bleached as expected, and that a lack of evidence of bias should not be taken as a lack of bias."
  ],
  "y": "background"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_7",
  "x": [
   "For race and gender, we are interested in attributes of pleasantness (P/U: Pleasant/Unpleasant), work (Career/Family), discipline (Science/Arts) [5] and the Heilman double bind [15,<cite> 21]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_8",
  "x": [
   "We preserve and report the original WEATs, SEATs and tests introduced by May et al. <cite>[21]</cite> where possible."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_9",
  "x": [
   "We also prefer tests using names (e.g. Alice) as concept words over group terms (e.g. European American), since names were demonstrated to have a significant association more often than group terms <cite>[21]</cite> For intersectional identities, we are focused primarily on the identity which is the subject of discussion in the work of Crenshaw [9] : being both African American and female."
  ],
  "y": "background uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_10",
  "x": [
   "Specifically, <cite>[21]</cite> , which targets the stereotype of black women as loud, angry, and imposing [8] ."
  ],
  "y": "background"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_11",
  "x": [
   "For comparison with previous work [1,<cite> 21,</cite> 35] , we also report on other word representation models: CBoW-GLoVe [24] , ELMo [25] , BERT bert-base-cased (bbc) and bert-large-cased (blc) versions [10] , and GPT [26] ."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_12",
  "x": [
   "We use PyTorch, as well as the framework and code from May et al. <cite>[21]</cite> , to conduct the experiments 6 ."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_13",
  "x": [
   "Similar to May et al. <cite>[21]</cite> , in the continuous bag of words (CBoW) model we encode sentences as the average of word embeddings using 300-dimensional GloVe vectors 7 trained on the Common Crawl corpus [24] ."
  ],
  "y": "similarities"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_14",
  "x": [
   "Following May et al. <cite>[21]</cite> , the sentence encoding of ELMo is a sequence of vectors, one for each token."
  ],
  "y": "uses"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_15",
  "x": [
   "Similar to May et al. <cite>[21]</cite> and the original word [26] , we use the representation corresponding to the last word in the sequence as the sentence encoding."
  ],
  "y": "similarities"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_16",
  "x": [
   "Different from May et al. <cite>[21]</cite> , we use the implementation of GPT from Hugging Face, and not the jiant project 10 ."
  ],
  "y": "differences"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_17",
  "x": [
   "The Caliskan Tests are detailed in Caliskan et al. [5] , and the double bind tests are detailed in May et al. <cite>[21]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "41a23b1ae47d83315a047497691117_18",
  "x": [
   "Following May et al. <cite>[21]</cite> , examples of such templates (non-exhaustive) are as below."
  ],
  "y": "uses"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_0",
  "x": [
   "Transformer<cite> [34]</cite> is based solely on the attention mechanism, and dispensing with recurrent and convolutions entirely."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_1",
  "x": [
   "Specifically, Ashish et.al<cite> [34]</cite> compute the attention function on a set of queries simultaneously, packed together into a matrix Q, while the keys and values are also packed together into matrices K and V , respectively."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_2",
  "x": [
   "Specifically, Ashish et.al<cite> [34]</cite> compute the attention function on a set of queries simultaneously, packed together into a matrix Q, while the keys and values are also packed together into matrices K and V , respectively."
  ],
  "y": "motivation"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_3",
  "x": [
   "In order to address this challenge, we first prove that the output of the attention function of the self-attention model<cite> [34]</cite> can be linearly represented by a group of orthonormal base vectors."
  ],
  "y": "uses"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_4",
  "x": [
   "The second challenge is that the attention model after compressing can not be directly integrated into the encoder and decoder framework of Transformer <cite>[34,</cite> 7] ."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_5",
  "x": [
   "After that, it can be integrated into the encoder and decoder framework of Transformer <cite>[34,</cite> 7] and trained end-to-end."
  ],
  "y": "uses"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_6",
  "x": [
   "Then, we describe in Section 2.2 multi-head attention<cite> [34]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_7",
  "x": [
   "In practice, Transformer<cite> [34]</cite> processes query, keys and values as matrices Q, K, and V respectively."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_8",
  "x": [
   "where d is the number of columns of Q and K. In these work <cite>[34,</cite> 12, 7] , they all use the multi-head attention, as introduced in<cite> [34]</cite> ,",
   "In this work<cite> [34]</cite> , multiple groups of parameters (W Q i , W K i and W V i ) are used, which results in a large number of redundant parameters."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_9",
  "x": [
   "Previous work<cite> [34]</cite> gets the multi-head attention by multiple groups of linear mappings."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_10",
  "x": [
   "Previous work<cite> [34]</cite> gets the multi-head attention by multiple groups of linear mappings."
  ],
  "y": "similarities"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_11",
  "x": [
   "h is the number of heads in<cite> [34]</cite> , and d is the dimension of factor matrices."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_12",
  "x": [
   "The minimum number of sequential operations in Multi-linear attention for different layers is lower than that of the self-attention in Transformer<cite> [34]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_13",
  "x": [
   "Different from the architectures of convolutional neural network (CNNs) and recurrent neural networks (RNNs) language modeling, the Transformer<cite> [34]</cite> and its variants [7, 12, 10] achieve excellent results in language modeling processing."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_14",
  "x": [
   "Vaswani et al.<cite> [34]</cite> uses a segment-level recurrence mechanism and a novel positional encoding scheme to resolve this question."
  ],
  "y": "background"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_15",
  "x": [
   "In this task, we have trained the Transformer model<cite> [34]</cite> on WMT 2016 English-German dataset [30] ."
  ],
  "y": "uses"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_16",
  "x": [
   "In this section, we only compared the results with Transformer<cite> [34]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "41de1ad534ca00b7a99260de7bb0b2_17",
  "x": [
   "For the other baseline, we use the basic Transformer architecture<cite> [34]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "43d670e583caab9b38ddce999b8872_0",
  "x": [
   "First introduced for evaluating user simulations by Schatzmann et al. (2005) , such a framework has gained recent prominence for the evaluation of end-to-end dialogue systems<cite> (Lowe et al., 2015a</cite>; Kadlec et al., 2015; Dodge et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "43d670e583caab9b38ddce999b8872_1",
  "x": [
   "With the huge size of current dialogue datasets that contain millions of utterances<cite> (Lowe et al., 2015a</cite>; Banchs, 2012; Ritter et al., 2010) and the increasing amount of natural language data, it is conceivable that retrieval-based systems will be able to have engaging conversations with humans."
  ],
  "y": "background"
 },
 {
  "id": "43d670e583caab9b38ddce999b8872_2",
  "x": [
   "We performed a user study on three different datasets: the SubTle Corpus of movie dialogues (Banchs, 2012) , the Twitter Corpus (Ritter et al., 2010) , and the Ubuntu Dialogue Corpus<cite> (Lowe et al., 2015a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "43d670e583caab9b38ddce999b8872_3",
  "x": [
   "This task has gained some popularity recently for evaluating dialogue systems<cite> (Lowe et al., 2015a</cite>; Kadlec et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "43d670e583caab9b38ddce999b8872_4",
  "x": [
   "The number of utterances in the context were sampled according to the procedure in<cite> (Lowe et al., 2015a)</cite> , with a maximum context length of 6 turns -this was done for both the human trials and ANN model."
  ],
  "y": "uses"
 },
 {
  "id": "43d670e583caab9b38ddce999b8872_5",
  "x": [
   "We also presents results on the same task for a state-of-the-art artificial neural network (ANN) dialogue model (see<cite> (Lowe et al., 2015a)</cite> for implementation details)."
  ],
  "y": "uses"
 },
 {
  "id": "4498072885df2a126e2db553cf3aca_0",
  "x": [
   "An important insight from work on distributional methods is that the definition of context is often critical to the success of a system<cite> (Shwartz et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4498072885df2a126e2db553cf3aca_1",
  "x": [
   "Most unsupervised distributional approaches for hypernymy detection are based on variants of the Distributional Inclusion Hypothesis (Weeds et al., 2004; Kotlerman et al., 2010; Santus et al., 2014; Lenci and Benotto, 2012;<cite> Shwartz et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4498072885df2a126e2db553cf3aca_2",
  "x": [
   "Although most unsupervised distributional approaches are based on the DIH, we also consider the distributional SLQS model based on on an alternative informativeness hypothesis (Santus et al., 2014;<cite> Shwartz et al., 2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4498072885df2a126e2db553cf3aca_3",
  "x": [
   "This allowed us to use the same metric on all detection benchmarks, and is consistent with evaluations in <cite>Shwartz et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4498072885df2a126e2db553cf3aca_4",
  "x": [
   "Distributional models: For the distributional baselines, we employ the large, sparse distributional space of <cite>Shwartz et al. (2017)</cite> , which is computed from UkWaC and Wikipedia, and is known to have strong performance on several of the detection tasks."
  ],
  "y": "uses"
 },
 {
  "id": "45723171ec398550e687c57d42e7cc_0",
  "x": [
   "The social media mining for health applications (SMM4H) shared task<cite> (Weissenbacher et al., 2018)</cite> hosts four tasks aiming to identify mentions of different aspects medication use on Twitter."
  ],
  "y": "background"
 },
 {
  "id": "457f9916ed4d7eafacea57e208c760_0",
  "x": [
   "A client may connect to the server and open up a dialogue (see Figure 1 in <cite>(Busemann et al., 1997)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "457f9916ed4d7eafacea57e208c760_1",
  "x": [
   "The use of SMES in COSMA, semantic analysis and inference, the dialogue model mapping between human and machine dialogue structures, utterance generation, the architectural framework of the server, and the PASHA agent system are described in <cite>(Busemann et al., 1997)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "457f9916ed4d7eafacea57e208c760_2",
  "x": [
   "We demonstrate extended versions of the systems described in <cite>(Busemann et al., 1997)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_0",
  "x": [
   "Specifically, by extending scalar self-attention models such as those proposed in<cite> Lin et al. (2017)</cite> , we propose vectorbased multi-head attention, which includes the widely used max pooling, mean pooling, and scalar selfattention itself as special cases."
  ],
  "y": "motivation similarities background"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_1",
  "x": [],
  "y": "differences background"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_2",
  "x": [
   "Instead of using AA T \u2212 I 2 F to encourage the diversity for scalar attention matrix as in<cite> Lin et al. (2017)</cite> , we propose the following formula to encourage the diversity for vectorial attention matrices."
  ],
  "y": "differences"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_3",
  "x": [
   "Age Dataset To compare our models with that of<cite> Lin et al. (2017)</cite> , we use the same Age dataset in our experiment here, which is an Author Profiling dataset."
  ],
  "y": "uses"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_4",
  "x": [
   "We use the same data split as in<cite> Lin et al. (2017)</cite> , i.e., 68,485 samples for training, 4,000 for development, and 4,000 for testing."
  ],
  "y": "uses"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_5",
  "x": [
   "We use the same data split as in<cite> Lin et al. (2017)</cite> , i.e., 500,000 samples for training, 2,000 for development, and 2,000 for testing."
  ],
  "y": "uses"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_7",
  "x": [
   "The BiLSTM with self-attention proposed by<cite> Lin et al. (2017)</cite> achieves better result than CNN and BiLSTM with max pooling."
  ],
  "y": "background"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_8",
  "x": [
   "One of our baseline models using max pooling on BiLSTM achieves accuracies of 65.00% and 82.30% on the Yelp and the Age dataset respectively, which is already better than the self-attention model proposed by<cite> Lin et al. (2017)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_10",
  "x": [
   "The green lines indicate scalar selfattention pooling added on top of the BiLSTMs, same as in<cite> Lin et al. (2017)</cite> , and the blue lines indicate vector-based attention used in our generalized pooling methods."
  ],
  "y": "differences background"
 },
 {
  "id": "4588d13c734d1ca0f348e056b1d39e_11",
  "x": [
   "Our future work includes exploring more effective MLP to use the structures of multi-head vectors, inspired by the idea from<cite> Lin et al. (2017)</cite> ."
  ],
  "y": "background future_work"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_0",
  "x": [
   "Very recently, datasets have been introduced that extend this task to longer temporal sequences such as movies or photo albums (Rohrbach et al., 2016; Pan et al., 2016; Lu and Grauman, 2013; <cite>Huang et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_1",
  "x": [
   "A more direct dataset was recently released<cite> (Huang et al., 2016)</cite> , where multi-sentence stories are collected describing photo albums via Amazon Mechanical Turk."
  ],
  "y": "background"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_2",
  "x": [
   "In this paper, we make use of the Visual Storytelling Dataset<cite> (Huang et al., 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_3",
  "x": [
   "Previous works include storyline graph modeling Xing, 2014), unsupervised mining (Sigurdsson et al., 2016) , blog-photo alignment , and language retelling<cite> (Huang et al., 2016</cite>; Park and Kim, 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_4",
  "x": [
   "While (Park and collects data by mining Blog Posts,<cite> (Huang et al., 2016)</cite> collects stories using Mechanical Turk, providing more directly relevant stories."
  ],
  "y": "background"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_5",
  "x": [
   "Following<cite> (Huang et al., 2016)</cite> , we choose a Gated Recurrent Unit (GRU) as the RNN unit to encode the photo sequence."
  ],
  "y": "uses"
 },
 {
  "id": "460a83a07ca3aa4d56deabad4f9831_6",
  "x": [
   "We use the Visual Storytelling Dataset<cite> (Huang et al., 2016)</cite> , consisting of 10,000 albums with 200,000 photos."
  ],
  "y": "uses"
 },
 {
  "id": "4625b603beb2308b8b306dd4c01823_0",
  "x": [
   "For example, we show that training our best model for only one epoch with < 40% of the data enables better performance than the baseline reported by <cite>Klinger et al. (2018)</cite> for the task."
  ],
  "y": "differences"
 },
 {
  "id": "4625b603beb2308b8b306dd4c01823_1",
  "x": [
   "<cite>Klinger et al. (2018)</cite> propose yet a fourth method for collecting emotion data that depends on the existence of the expression \"emotion-word + one of the following words (when, that or because)\" in a tweet, regardless of the position of the emotion word."
  ],
  "y": "background"
 },
 {
  "id": "4625b603beb2308b8b306dd4c01823_2",
  "x": [
   "The full details of the dataset can be found in <cite>Klinger et al. (2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4625b603beb2308b8b306dd4c01823_3",
  "x": [
   "As an additional baseline, we compare to <cite>Klinger et al. (2018)</cite> who propose a model based on Logistic Regression with a bag of word unigrams (BOW)."
  ],
  "y": "uses"
 },
 {
  "id": "4625b603beb2308b8b306dd4c01823_4",
  "x": [
   "As the Table shows, all our models achieve sizable gains over the logistic regression model introduced by<cite> (Klinger et al., 2018)</cite> as a baseline for the competition (F-score = 60%)."
  ],
  "y": "differences"
 },
 {
  "id": "4625b603beb2308b8b306dd4c01823_5",
  "x": [
   "Interestingly, as Figure 3 shows, the model exceeds the baseline model reported by the task organizers<cite> (Klinger et al., 2018)</cite> when trained on only 10% of the training data."
  ],
  "y": "differences"
 },
 {
  "id": "47e109fd12ddbeebba894cead282d2_0",
  "x": [
   "Why aren't you giving it the same treatment you do to evolution?\" Because it doesn't carry the same weight. ;P bates (Thomas et al., 2006; Bansal et al., 2008; Yessenalina et al., 2010; Balahur et al., 2009; Burfoot et al., 2011) ; (2) company-internal discussion sites (Murakami and Raymond, 2010; Agrawal et al., 2003) ; and (3) online social and political public forums (Somasundaran and Wiebe, 2009;<cite> Somasundaran and Wiebe, 2010</cite>; Wang and Ros\u00e9, 2010; Biran and Rambow, 2011) ."
  ],
  "y": "background"
 },
 {
  "id": "47e109fd12ddbeebba894cead282d2_1",
  "x": [
   "These properties may function to engage the audience and persuade them to form a particular opinion, but they make computational analysis of such debates challenging, with the best performance to date averaging 64% over several topics <cite>(Somasundaran and Wiebe, 2010</cite> Second, the affordances of different online debate sites provide differential support for dialogic relations between forum participants."
  ],
  "y": "background"
 },
 {
  "id": "47e109fd12ddbeebba894cead282d2_2",
  "x": [
   "For example, the research of<cite> Somasundaran and Wiebe (2010)</cite> , does not explicitly model dialogue or author relations."
  ],
  "y": "background"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_0",
  "x": [
   "Although traditional AES methods typically rely on handcrafted features (Larkey, 1998; Foltz et al., 1999; Attali and Burstein, 2006; Dikli, 2006; Wang and Brown, 2008; Chen and He, 2013; Somasundaran et al., 2014; Yannakoudakis et al., 2014; <cite>Phandi et al., 2015</cite>) , recent results indicate that state-of-the-art deep learning methods reach better performance (Alikaniotis et al., 2016; Dong and Zhang, 2016; Taghipour and Ng, 2016; Song et al., 2017; Tay et al., 2018) , perhaps because these methods are able to capture subtle and complex information that is relevant to the task (Dong and Zhang, 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_1",
  "x": [
   "The empirical results indicate that our approach yields a better performance than state-of-the-art approaches (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016; Tay et al., 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_2",
  "x": [
   "Since the official test data of the ASAP competition is not released to the public, we, as well as others before us (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016;  1 https://www.kaggle.com/c/asap-aes/data Tay et al., 2018) , use only the training data in our experiments."
  ],
  "y": "motivation similarities uses"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_3",
  "x": [
   "We closely followed the same settings for data preparation as (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_4",
  "x": [
   "For the cross-domain experiments, we use the same source\u2192target domain pairs as (<cite>Phandi et al., 2015;</cite> Dong and Zhang, 2016) , namely, 1\u21922, 3\u21924, 5\u21926 and 7\u21928."
  ],
  "y": "similarities uses"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_5",
  "x": [
   "The sub-sample sizes are n t = {10, 25, 50, 100}. The sub-sampling is repeated for 5 times as in (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016) to reduce bias."
  ],
  "y": "similarities"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_6",
  "x": [
   "We compare our approach with stateof-the-art methods based on handcrafted features (<cite>Phandi et al., 2015</cite>) , as well as deep features (Dong and Zhang, 2016; Tay et al., 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_7",
  "x": [
   "We note that results for the cross-domain setting are reported only in some of these recent works (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_8",
  "x": [
   "We used functions from the VLFeat li- Table 2 : In-domain automatic essay scoring results of our approach versus several state-of-the-art methods (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016; Tay et al., 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_9",
  "x": [
   "We first note that the histogram intersection string kernel alone reaches better overall performance (0.780) than all previous works (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016; Tay et al., 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_10",
  "x": [
   "For each and every source\u2192target pair, we report better results than both state-of-theart methods (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016) ."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_11",
  "x": [
   "We observe that the difference between our best QWK scores and the <cite>other approaches</cite> are sometimes much higher in the cross-domain setting than in the in-domain setting."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_12",
  "x": [
   "We particularly notice that the difference from (<cite>Phandi et al., 2015</cite>) when n t = 0 is always higher than 10%."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_13",
  "x": [
   "Our highest improvement (more than 54%, from 0.187 to 0.728) over (<cite>Phandi et al., 2015</cite>) is recorded for the pair 5\u21926, when n t = 0."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_14",
  "x": [
   "Our score in this case (0.728) is even higher than both scores of <cite>Phandi et al. (2015)</cite> and Dong and Zhang (2016) when they use n t = 50."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_15",
  "x": [
   "We concluded that this simple apSource\u2192Target Method n t = 0 n t = 10 n t = 25 n t = 50 n t = 100 1\u21922 (<cite>Phandi et al., 2015</cite>) Table 3 : Corss-domain automatic essay scoring results of our approach versus two state-of-the-art methods (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016) ."
  ],
  "y": "differences"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_16",
  "x": [
   "Results are reported in terms of the quadratic weighted kappa (QWK) measure, using the same evaluation procedure as (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "4821d5a283c1d4ba162b58e5fac8bc_17",
  "x": [
   "We compared our approach on the Automated Student Assessment Prize data set, in both in-domain and crossdomain settings, with several state-of-the-art approaches (<cite>Phandi et al., 2015</cite>; Dong and Zhang, 2016; Tay et al., 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "484bc7c9c66bf4028eef4103beec7f_0",
  "x": [
   "Our previous work focused on only the segmentation part of the voice identification task <cite>(Brooke et al., 2012)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "484bc7c9c66bf4028eef4103beec7f_1",
  "x": [
   "Our work here is built on our earlier work <cite>(Brooke et al., 2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "484bc7c9c66bf4028eef4103beec7f_2",
  "x": [
   "Our approach to voice identification in The Waste Land consists first of identifying the boundaries of voice spans <cite>(Brooke et al., 2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "484bc7c9c66bf4028eef4103beec7f_3",
  "x": [
   "For a more detailed discussion of the feature set, see<cite> Brooke et al. (2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "484bc7c9c66bf4028eef4103beec7f_4",
  "x": [
   "For the automatic segmentation model, we use the settings from<cite> Brooke et al. (2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_0",
  "x": [
   "Carvalho et al. <cite>[3]</cite> proposed a similar multi-modal embedding method for aligning text and image representations in a shared latent space."
  ],
  "y": "background"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_1",
  "x": [
   "We chose 512-dimensional word embedding for our model with self-attention, whereas [17] and <cite>[3]</cite> chose a vector length of 300."
  ],
  "y": "differences"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_2",
  "x": [
   "We have trained our model using cosine similarity loss with margin as in [17] and with the triplet loss proposed by <cite>[3]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_3",
  "x": [
   "Since the timing of freezing layers proved not to be of importance unless the recipe path is trained first, we used the same strategy under the cosine distance objective [17] and for the triplet loss <cite>[3]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_4",
  "x": [
   "Similarly to [17] and <cite>[3]</cite> , we evaluated our model on 10 subsets of 1000 samples each."
  ],
  "y": "similarities"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_6",
  "x": [
   "Both [17] and <cite>[3]</cite> use time-consuming instruction text preprocessing over the skip-thought technique [15] ."
  ],
  "y": "background"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_7",
  "x": [
   "Both [17] and <cite>[3]</cite> use time-consuming instruction text preprocessing over the skip-thought technique [15] ."
  ],
  "y": "differences"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_9",
  "x": [
   "AdaMine <cite>[3]</cite> creates more distinct class clusters than in [17] ."
  ],
  "y": "uses"
 },
 {
  "id": "489d0077e05269327e7fe4e7f7e4a3_10",
  "x": [
   "On the recipe retrieval task, our method performs similarly to our baseline implementation of <cite>[3]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_0",
  "x": [
   "It has attracted considerable attention in recent years [1, 2,<cite> 3,</cite> 4, 5, 6, 7, 8] ."
  ],
  "y": "background"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_1",
  "x": [
   "To deal with this problem, Huang and Lee<cite> [3]</cite> proposed a contrastive approach based on documentlevel top-bag-of-word similarity to reflect distances among the three varieties of Mandarin in China, Taiwan and Singapore, which is a kind of word-level uni-gram feature."
  ],
  "y": "background"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_3",
  "x": [
   "In order to investigate the detailed characteristics of different dialects of Mandarin Chinese, we extend <cite>3</cite> dialects in Huang and Lee<cite> [3]</cite> to 6 dialects."
  ],
  "y": "extends"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_5",
  "x": [
   "Huang and Lee<cite> [3]</cite> presented the top-bag-of-word similarity based contrastive approach to reflect distances among the three varieties of Mandarin in Mainland China, Taiwan and Singapore."
  ],
  "y": "background"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_7",
  "x": [
   "Among the above related works, study<cite> [3]</cite> is the most related work to ours."
  ],
  "y": "similarities"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_8",
  "x": [
   "The differences between study<cite> [3]</cite> and our work are two-fold:"
  ],
  "y": "differences"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_9",
  "x": [
   "In order to investigate the detailed characteristic of different dialects of Mandarin Chinese, we extend dialects in Huang and Lee<cite> [3]</cite> to 6 dialects."
  ],
  "y": "extends"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_10",
  "x": [
   "The differences between study<cite> [3]</cite> and our work are two-fold:",
   "In order to investigate the detailed characteristic of different dialects of Mandarin Chinese, we extend dialects in Huang and Lee<cite> [3]</cite> to 6 dialects.",
   "(2)The top-bag-of-word they proposed in Huang and Lee<cite> [3]</cite> is word uni-gram feature essentially."
  ],
  "y": "differences"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_11",
  "x": [
   "However, Huang and Lee<cite> [3]</cite> did not use character-level n-grams."
  ],
  "y": "differences"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_19",
  "x": [
   "Baseline system 1: As mentioned in Section 2, we take the Huang and Lee<cite> [3]</cite> 's top-bag-of-word similarity-based approach as one of our baseline system."
  ],
  "y": "uses"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_22",
  "x": [
   "Also the bi-gram and word segmentation based features are better than the Huang and Lee<cite> [3]</cite> 's method (baseline system 1) for 6-way, <cite>3</cite>-way and 2-way dialect identification in the GCR."
  ],
  "y": "differences"
 },
 {
  "id": "48add0c1226863808c3c3a8c29a12e_28",
  "x": [
   "Similar to Huang and Lee<cite> [3]</cite> 's work, in order to eliminate the trivial issue of character encoding (simplified and traditional character), we convert Taiwan and Hong Kong texts to the same simplified character set using Zhconvertor 6 utility to focus on actual linguistic and textual features."
  ],
  "y": "similarities"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_0",
  "x": [
   "Our proposed supervised and unsupervised approaches perform better than the supervised and unsupervised approaches of <cite>Fazly et al. (2009)</cite> , respectively."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_1",
  "x": [
   "Many studies, however, have taken a word sense disambiguation-inspired approach to MWE identification (e.g., Birke and Sarkar, 2006; Katz and Giesbrecht, 2006; Li et al., 2010) , treating literal combinations and MWEs as different word senses, and have exploited linguistic knowledge of MWEs (e.g., Patrick and Fletcher, 2005; Uchiyama et al., 2005; Hashimoto and Kawahara, 2008; <cite>Fazly et al., 2009</cite>; Fothergill and Baldwin, 2012) ."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_2",
  "x": [
   "They are a common and productive type of English idiom, and occur cross-lingually (<cite>Fazly et al., 2009</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_3",
  "x": [
   "<cite>Fazly et al. (2009)</cite> exploit this property in their unsupervised approach, referred to as CFORM."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_4",
  "x": [
   "<cite>They</cite> define lexico-syntactic patterns for VNIC token instances based on the noun's determiner (e.g., a, the, or possibly no determiner), the number of the noun (singular or plural), and the verb's voice (active or passive)."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_5",
  "x": [
   "<cite>They</cite> propose a statistical method for automatically determining a given VNIC type's canonical idiomatic form, based on the frequency of its usage in these patterns in a corpus."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_6",
  "x": [
   "2 <cite>They</cite> then classify a given token instance of a VNIC as idiomatic if it occurs in its canonical form, and as literal otherwise."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_7",
  "x": [
   "<cite>Fazly et al</cite>. also consider a supervised approach that classifies a given VNIC instance based on the similarity of its context to that of idiomatic and literal instances of the same expression seen during training."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_8",
  "x": [
   "In this work we first propose a supervised approach to identifying VNIC token instances based on word embeddings that outperforms the supervised method of <cite>Fazly et al. (2009)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_9",
  "x": [
   "We then propose an unsupervised approach to this task, that combines word embeddings with <cite>Fazly et al</cite>.'s unsupervised CFORM approach, that improves over <cite>CFORM</cite>."
  ],
  "y": "differences uses"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_10",
  "x": [
   "Finally, to form the feature vector representing a VNIC instance, we subtract e from c, and append to this vector a single binary feature representing whether the VNIC instance occurs in its canonical form, as determined by <cite>Fazly et al. (2009)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_11",
  "x": [
   "Our unsupervised approach combines the word embedding-based representation used in the supervised approach (without relying on training a supervised classifier, of course) with the unsupervised CFORM method of <cite>Fazly et al. (2009)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_12",
  "x": [
   "Following <cite>Fazly et al. (2009)</cite> , the supervised approach was evaluated using a leave-one-token-out strategy."
  ],
  "y": "uses"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_13",
  "x": [
   "All of these accuracies are higher than those reported by <cite>Fazly et al. (2009)</cite> for their supervised approach."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_14",
  "x": [
   "They are also substantially higher than the most-frequent class baseline, and the unsupervised CFORM method of <cite>Fazly et al</cite>."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_15",
  "x": [
   "The CFORM method of <cite>Fazly et al. (2009 )</cite> is a strong unsupervised benchmark for this task, and relies on the lexico-syntactic pattern in which an MWE token instance occurs."
  ],
  "y": "background"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_16",
  "x": [
   "A smaller window size for the word embedding features might be better able to capture similar information to <cite>CFORM</cite>, which could explain the good performance of the model using a window size of 1."
  ],
  "y": "similarities"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_17",
  "x": [
   "Moreover, the unsupervised CFORM method of <cite>Fazly et al. (2009)</cite> gives substantially higher accuracies than this supervised approach."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_18",
  "x": [
   "For k = 4 and 5 on TEST, this approach surpasses the unsupervised CFORM method of <cite>Fazly et al. (2009)</cite> ; however, on DEV this approach does not outperform <cite>Fazly et al</cite>.'s CFORM approach for any of the val-ues of k considered."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_19",
  "x": [
   "Analyzing the results on individual expressions indicates that the unsupervised approach gives especially low accuracy for hit roof -which is in DEV-as compared to the CFORM method of <cite>Fazly et al.</cite>, which could contribute to the overall lower accuracy of the unsupervised approach on this dataset."
  ],
  "y": "differences"
 },
 {
  "id": "491879c73f8aa9f11bfae01abc795d_20",
  "x": [
   "In this paper we proposed supervised and unsupervised approaches, based on word embeddings, to identifying token instances of VNICs that performed better than the supervised approach, and unsupervised CFORM approach, of <cite>Fazly et al. (2009)</cite> , respectively."
  ],
  "y": "differences"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_0",
  "x": [
   "Much of the focus for mitigating unintended bias in NLP is either targeted at reducing gender stereotypes in text (Bolukbasi et al., 2016b,a; Zhao et al., 2017; Zhang et al., 2018) , or inequality of sentiment or toxicity for various protected groups <cite>(Caliskan-Islam et al., 2016</cite>; Bakarov, 2018; Dixon et al.; Garg et al., 2018; Kiritchenko and Mohammad, 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_1",
  "x": [
   "(Bolukbasi et al., 2016b ) defines a useful metric for identifying gender bias and<cite> (Caliskan-Islam et al., 2016)</cite> defines a metric called the WEAT score for evaluating unfair correlations with sentiment for various demographics in text."
  ],
  "y": "background"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_2",
  "x": [
   "Unfortunately metrics like these leverage vector space arguments between only two identities at a time like man vs woman (Bolukbasi et al., 2016a) , or European American names vs. African American names<cite> (Caliskan-Islam et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_3",
  "x": [
   "Unfortunately metrics like these leverage vector space arguments between only two identities at a time like man vs woman (Bolukbasi et al., 2016a) , or European American names vs. African American names<cite> (Caliskan-Islam et al., 2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_4",
  "x": [
   "GloVe and Word2vec embeddings have been shown to contain unintended bias in (Bolukbasi et al., 2016a;<cite> Caliskan-Islam et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_5",
  "x": [
   "First, we compare the RNSB metric for 3 pretrained word embeddings, showing that our metric is consistent with other word embedding analysis like WEAT<cite> (Caliskan-Islam et al., 2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4a093e0ca9a499c19e4721366d88f6_6",
  "x": [
   "Although the RNSB metric is not directly comparable to WEAT scores, these results are still consistent with some of the bias predicted by<cite> (Caliskan-Islam et al., 2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4a63ef4085639a66d1c7f6344f7548_0",
  "x": [
   "To overcome these limitations, many syntaxbased SMT models have been proposed (Wu, 1997; Chiang, 2007; Ding et al., 2005; Eisner, 2003; Quirk et al., 2005;<cite> Liu et al., 2007</cite>; Zhang et al., 2007; Zhang et al., 2008a; Zhang et al., 2008b; Gildea, 2003; Galley et al., 2004; Bod, 2007) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "4a63ef4085639a66d1c7f6344f7548_1",
  "x": [
   "For example, forest-to-string transformation rules have been integrated into the tree-to-string translation framework by (Liu et al., 2006;<cite> Liu et al., 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4a63ef4085639a66d1c7f6344f7548_2",
  "x": [
   "<cite>Liu et al. (2007)</cite> differentiated the rules in their tree-to-string model which integrated with forest 1 -to-string into fully lexicalized rules, non-lexicalized rules and partial lexicalized rules according to the lexicalization levels."
  ],
  "y": "background"
 },
 {
  "id": "4a63ef4085639a66d1c7f6344f7548_3",
  "x": [
   "A few researches have made some exploratory investigations towards the effects of different rules by classifying the translation rules into different subcategories<cite> (Liu et al., 2007</cite>; Zhang et al., 2008a; DeNeefe et al., 2007) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "4a63ef4085639a66d1c7f6344f7548_4",
  "x": [
   "Further, the syntax rules can be divided into three categories according to the lexicalization levels<cite> (Liu et al., 2007</cite>; Zhang et al., 2008a source and target sides are non-lexicons (nonterminals)"
  ],
  "y": "background"
 },
 {
  "id": "4a63ef4085639a66d1c7f6344f7548_5",
  "x": [
   "In the future works, aiming to analyze the rule contributions and the redundances issues using the presented rule classification based on some real translation systems, we plan to implement some synchronous grammar based syntax translation models such as the one presented in<cite> (Liu et al., 2007)</cite> or in (Zhang et al., 2008a) ."
  ],
  "y": "future_work"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_0",
  "x": [
   "Specifically, we focus on a new reading comprehension dataset called DROP <cite>(Dua et al., 2019)</cite> , which requires Discrete Reasoning Over the content of Paragraphs to obtain the final answer."
  ],
  "y": "uses"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_1",
  "x": [
   "First, to produce various answer types,<cite> Dua et al. (2019)</cite> extend previous one-type answer prediction (Seo et al., 2017) to multi-type prediction that supports span extraction, counting, and addition/subtraction."
  ],
  "y": "background"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_2",
  "x": [
   "First, to produce various answer types,<cite> Dua et al. (2019)</cite> extend previous one-type answer prediction (Seo et al., 2017) to multi-type prediction that supports span extraction, counting, and addition/subtraction."
  ],
  "y": "motivation"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_3",
  "x": [
   "Third, to support numerical reasoning, prior work <cite>(Dua et al., 2019)</cite> learns to predict signed numbers for obtaining an arithmetic expression that can be executed by a symbolic system."
  ],
  "y": "background"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_4",
  "x": [
   "Third, to support numerical reasoning, prior work <cite>(Dua et al., 2019)</cite> learns to predict signed numbers for obtaining an arithmetic expression that can be executed by a symbolic system."
  ],
  "y": "motivation"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_5",
  "x": [
   "Following<cite> Dua et al. (2019)</cite> , we first predict the answer type of a given passage-question pair, and then adopt individual prediction strategies."
  ],
  "y": "uses"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_6",
  "x": [
   "Following<cite> Dua et al. (2019)</cite> , we design a multi-type answer predictor to selectively produce different kinds of answers such as span, count number, and arithmetic expression."
  ],
  "y": "uses"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_7",
  "x": [
   "Answer type prediction Inspired by the Augmented QANet model <cite>(Dua et al., 2019)</cite> , we use the contextualized token representations from the last four blocks (H L\u22123 , ..., H L ) as the inputs to our answer predictor, which are denoted as M 0 , M 1 , M 2 , M 3 , respectively."
  ],
  "y": "uses"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_8",
  "x": [
   "Arithmetic expression In order to model the process of performing addition or subtraction among multiple numbers mentioned in the passage, we assign a three-way categorical variable (plus, minus, or zero) for each number to indicate its sign, similar to<cite> Dua et al. (2019)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_9",
  "x": [
   "Since DROP does not indicate the answer type but only provides the answer string, we therefore adopt the weakly supervised annotation scheme, as suggested in Berant et al. (2013);<cite> Dua et al. (2019)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_10",
  "x": [
   "Dataset We consider the reading comprehension benchmark that requires Discrete Reasoning Over Paragraphs (DROP) <cite>(Dua et al., 2019)</cite> prehensive understanding of the context as well as the ability of numerical reasoning are required."
  ],
  "y": "uses"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_11",
  "x": [
   "Baselines Following the implementation of Augmented QANet (NAQANet) <cite>(Dua et al., 2019)</cite> , we introduce a similar baseline called Augmented BERT (NABERT)."
  ],
  "y": "similarities"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_12",
  "x": [
   "Recently,<cite> Dua et al. (2019)</cite> released a new benchmark named DROP that demands discrete reasoning as well as deeper paragraph understanding to find the answers."
  ],
  "y": "background"
 },
 {
  "id": "4a90cd18be0df0c41a94febe2f68ef_13",
  "x": [
   "Recently,<cite> Dua et al. (2019)</cite> released a new benchmark named DROP that demands discrete reasoning as well as deeper paragraph understanding to find the answers."
  ],
  "y": "uses"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_0",
  "x": [
   "Recently, <cite>Locascio et al. (2016)</cite> designed the Deep-Regex model based on the sequence-to-sequence (Seq2Seq) model (Sutskever et al., 2014) using minimal domain knowledge during the learning phase while still accurately predicting regular expressions from NLs."
  ],
  "y": "background"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_1",
  "x": [
   "<cite>Locascio et al. (2016)</cite> proposed the Deep-Regex model based on Seq2Seq for generating regular expressions from natural language descriptions together with a dataset of 10,000 NL-RX pairs."
  ],
  "y": "background"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_2",
  "x": [
   "Datasets: <cite>Locascio et al. (2016)</cite> created a set of NL-RX pair data by arbitrarily creating and combining data in a tree form."
  ],
  "y": "background"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_3",
  "x": [
   "Similar to <cite>Locascio et al. (2016)</cite> , we randomly generate regular expression pairs up to depth three and label the equivalence between each pair."
  ],
  "y": "similarities"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_4",
  "x": [
   "On the other hand, NL-RX-Synth is data generated automatically and NL-RX-Turk is made from ordinary people by paraphrasing NL descriptions in NL-RX-Synth using Mechanical Turk<cite> (Locascio et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_5",
  "x": [
   "Specifically, there are some ambiguities since <cite>Locascio et al. (2016)</cite> tried to obtain data from machine-generated sentences."
  ],
  "y": "background"
 },
 {
  "id": "4b65a59fc2331b9771ea09a12f32de_6",
  "x": [
   "We now describe how <cite>Locascio et al. (2016)</cite> generated their synthetic regular expression data."
  ],
  "y": "background"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_0",
  "x": [
   "BERT <cite>(Devlin et al., 2018)</cite> , for example, trains on the BooksCorpus (Zhu et al., 2015) and English Wikipedia, for a combined 3,200M words."
  ],
  "y": "background"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_1",
  "x": [
   "For language modeling, we create training data similar to those in BERT <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_2",
  "x": [
   "Commonly known as a cloze task,<cite> Devlin et al. (2018)</cite> introduced a framework that pretrained transformers (Vaswani et al., 2017) based on masked token prediction."
  ],
  "y": "background"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_3",
  "x": [
   "Unlike<cite> Devlin et al. (2018)</cite> , we run the randomization script once per each training epoch."
  ],
  "y": "differences"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_4",
  "x": [
   "Otherwise, we follow the procedure in<cite> Devlin et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_5",
  "x": [
   "We do this process after the cloze task masking, similar to<cite> Devlin et al. (2018)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_6",
  "x": [
   "Contrary to<cite> Devlin et al. (2018)</cite> , we do language model fine-tuning in addition to classification finetuning."
  ],
  "y": "differences"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_7",
  "x": [
   "For masked tokens, we predict that token through bidirectional context, the same as<cite> Devlin et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_8",
  "x": [
   "For next sentence prediction, we use the unbiased method previously introduced as well as in<cite> Devlin et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_9",
  "x": [
   "For BERT baselines, we use the process in<cite> Devlin et al. (2018)</cite> , and use the [CLS] token, without attention, for classification."
  ],
  "y": "uses"
 },
 {
  "id": "4bc12aca138835b5ed80b0cf69febf_10",
  "x": [
   "Commonly known as a cloze task,<cite> Devlin et al. (2018)</cite> introduced a framework that pretrained transformers (Vaswani et al., 2017) based on masked token prediction.",
   "Unlike<cite> Devlin et al. (2018)</cite> , we run the randomization script once per each training epoch.",
   "Otherwise, we follow the procedure in<cite> Devlin et al. (2018)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_0",
  "x": [
   "Most of the previous coreference resolution methods have similar classification phases, implemented either as decision trees (Soon et al., 2001) or as maximum entropy classifiers<cite> (Luo et al., 2004)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_1",
  "x": [
   "In contrast, globally optimized clustering decisions were reported in<cite> (Luo et al., 2004)</cite> and (DaumeIII and Marcu, 2005a) , where all clustering possibilities are considered by searching on a Bell tree representation or by using the Learning as Search Optimization (LaSO) framework (DaumeIII and Marcu, 2005b) respectively, but the first search is partial and driven by heuristics and the second one only looks back in text."
  ],
  "y": "motivation background"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_2",
  "x": [
   "BESTCUT replaces the bottom-up search in a tree representation (as it was performed in<cite> (Luo et al., 2004)</cite> ) with the top-down problem of obtaining the best partitioning of a graph."
  ],
  "y": "differences background extends"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_4",
  "x": [
   "We created the training examples in the same way as<cite> (Luo et al., 2004)</cite> , by pairing all mentions of the same type, obtaining their feature vectors and taking the outcome (coreferent/noncoreferent) from the key files."
  ],
  "y": "uses"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_5",
  "x": [
   "We duplicated the statistical model used by<cite> (Luo et al., 2004)</cite> , with three differences.",
   "Third, as opposed to<cite> (Luo et al., 2004)</cite> , who represented all numerical features quantized, we translated each numerical feature into a set of binary features that express whether the value is in certain intervals."
  ],
  "y": "extends"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_7",
  "x": [
   "The clusterization algorithms that we implemented to evaluate in comparison with our method are<cite> (Luo et al., 2004)</cite> 's Belltree and Link-Best (best-first clusterization) from (Ng and Cardie, 2002) ."
  ],
  "y": "uses"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_8",
  "x": [
   "Since we aimed to measure the performance of coreference, the metrics used for evaluation are the ECM-F<cite> (Luo et al., 2004)</cite> and the MUC P, R and F scores (Vilain et al., 1995) ."
  ],
  "y": "uses"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_9",
  "x": [
   "This only shows that none of them is particularly poor, but it is not a relevant way of comparing methods-the MUC metric has been found too indulgent by researchers (<cite> (Luo et al., 2004)</cite> , (Baldwin et al., 1998) Table 4 : Comparison of results between three clusterization algorithms on ACE Phase 2."
  ],
  "y": "background"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_10",
  "x": [
   "Baseline system has the<cite> (Luo et al., 2004)</cite> features."
  ],
  "y": "uses"
 },
 {
  "id": "4cb16f436d910d82c3661052c1fa30_12",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_0",
  "x": [
   "We evaluate the performance of our SGNNs on Dialogue Act classification, because (1) it is an important step towards dialog interpretation and conversational analysis aiming to understand the intent of the speaker at every utterance of the conversation and (2) deep learning methods reached state-of-the-art <cite>(Lee and Dernoncourt, 2016</cite>; Khanpour et al., 2016; Tran et al., 2017; Ortega and Vu, 2017) ."
  ],
  "y": "similarities"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_1",
  "x": [
   "\u2022 Exhaustive experimental evaluation on dialog act datasets, outperforming state-of-theart deep CNN<cite> (Lee and Dernoncourt, 2016)</cite> and RNN variants (Khanpour et al., 2016; Ortega and Vu, 2017 )."
  ],
  "y": "differences"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_2",
  "x": [
   "We use the train, validation and test splits as defined in <cite>(Lee and Dernoncourt, 2016</cite>; Ortega and Vu, 2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_3",
  "x": [
   "Unlike prior approaches <cite>(Lee and Dernoncourt, 2016</cite>; Ortega and Vu, 2017 ) that rely on pre-trained word embeddings, we learn the projection weights on the fly during training, i.e word embeddings (or vocabularies) do not need to be stored."
  ],
  "y": "differences"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_4",
  "x": [
   "We compare our model against a majority class baseline and Naive Bayes classifier<cite> (Lee and Dernoncourt, 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_5",
  "x": [
   "We compare our model against a majority class baseline and Naive Bayes classifier<cite> (Lee and Dernoncourt, 2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_6",
  "x": [
   "We also compare our performance against prior work using HMMs (Stolcke et al., 2000) and recent deep learning methods like CNN<cite> (Lee and Dernoncourt, 2016)</cite> , RNN (Khanpour et al., 2016) and RNN with gated attention (Tran et al., 2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_7",
  "x": [
   "To the best of our knowledge, <cite>(Lee and Dernoncourt, 2016</cite>; Ortega and Vu, 2017; Tran et al., 2017) are the latest approaches in dialog act classification, which also reported on the same data splits."
  ],
  "y": "background"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_8",
  "x": [
   "Our study also shows that the proposed method is very effective for such natural language tasks compared to more complex neural network architectures such as deep CNN<cite> (Lee and Dernoncourt, 2016)</cite> and RNN variants (Khanpour et al., 2016; Ortega and Vu, 2017) ."
  ],
  "y": "differences"
 },
 {
  "id": "4cc18724e62db32e748838080cbfd0_10",
  "x": [
   "Experiments on multiple dialog act datasets showed that our model outperforms state-of-the-art deep leaning methods <cite>(Lee and Dernoncourt, 2016</cite>; Khanpour et al., 2016; Ortega and Vu, 2017) ."
  ],
  "y": "differences"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_1",
  "x": [
   "Parisien and Stevenson (2011) and<cite> Kawahara et al. (2014)</cite> showed distinct ways of applying the Hierarchical Dirichlet Process (Teh et al., 2006) to uncover the latent clusters from cluster examples."
  ],
  "y": "background"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_2",
  "x": [
   "In<cite> Kawahara et al. (2014)</cite> , two identical DPMM's were used."
  ],
  "y": "background"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_3",
  "x": [
   "The DPMM used in<cite> Kawahara et al. (2014)</cite> is shown in Figure 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_4",
  "x": [
   "According to <cite>(Kawahara et al., 2014)</cite> , the best features for inducing verb classes are joint slot:token pairs."
  ],
  "y": "background"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_5",
  "x": [
   "When incorporating supervision, we flatten VerbNet, using only the top-level categories, simplifying the selection process for y. In<cite> Kawahara et al. (2014)</cite> , slot features were most effective features at producing a VerbNet-like structure; we follow suit."
  ],
  "y": "uses"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_6",
  "x": [
   "For evaluation, we compare using the same dataset and metrics as<cite> Kawahara et al. (2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_7",
  "x": [
   "We report each metric, and the F1 score combining them, to compare the clustering accuracy with respect to the gold standard G. We use the clustering from<cite> Kawahara et al. (2014)</cite> as a baseline for comparison."
  ],
  "y": "uses"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_8",
  "x": [
   "Therefore, to compare apples-to-apples, we calculate the nPU, niPU, and F1 of the<cite> Kawahara et al. (2014)</cite> full clustering against the evaluation set."
  ],
  "y": "uses"
 },
 {
  "id": "4d2488844c1f6f39f1f4b8f3487288_9",
  "x": [
   "We have expanded the work in<cite> Kawahara et al. (2014)</cite> by explicitly modeling a VerbNet class for each verb sense, drawn from a product of experts based on the cluster and verb."
  ],
  "y": "extends"
 },
 {
  "id": "4d8ae52583d41b4124800c419963df_0",
  "x": [
   "We use the feature set introduced by<cite> Zwarts and Johnson (2011)</cite> , but instead of n-gram scores, we apply the LSTM language model probabilities."
  ],
  "y": "extends"
 },
 {
  "id": "4d8ae52583d41b4124800c419963df_1",
  "x": [
   "In order to alleviate this problem, we follow<cite> Zwarts and Johnson (2011)</cite> by training LMs on different corpora, but we apply state-ofthe-art recurrent neural network (RNN) language models."
  ],
  "y": "extends"
 },
 {
  "id": "4d8ae52583d41b4124800c419963df_2",
  "x": [
   "Our reranker optimizes the expected f-score approximation described in<cite> Zwarts and Johnson (2011)</cite> with L2 regularisation."
  ],
  "y": "uses"
 },
 {
  "id": "4d8ae52583d41b4124800c419963df_3",
  "x": [
   "This is because the fluent sentence itself is part of the language model <cite>(Zwarts and Johnson, 2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_0",
  "x": [
   "It extends previous work by<cite> Barbu (2015)</cite> through incorporating recall-based machine translation and part-of-speech-tagging features."
  ],
  "y": "differences extends"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_1",
  "x": [
   "The system is based on previous work by<cite> Barbu (2015)</cite> and uses language-independent features with language-specific plug-ins, such as machine translation, part-of-speech tagging, and language classification."
  ],
  "y": "differences extends"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_2",
  "x": [
   "In Section 3, we describe our method and, in Section 4, show how it compares to <cite>Barbu's (2015)</cite> approach as well as other submissions to this shared task."
  ],
  "y": "similarities"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_3",
  "x": [
   "To the best of our knowledge, Barbu provided the first and so far only research contribution on automatic TM cleaning, which the author himself described as \"a neglected research area\"<cite> (Barbu, 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_4",
  "x": [
   "As outlined above, comparing machine translated source segments to their actual target segments has proven effective in <cite>Barbu's (2015)</cite> experiments."
  ],
  "y": "background"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_5",
  "x": [
   "Our feature extraction pipeline, including <cite>Barbu's (2015)</cite> as well as our own features (see Section 3.1), is implemented in Scala."
  ],
  "y": "similarities"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_6",
  "x": [
   "From the various feature combinations we tested, we found the following to be most successful: ratio_words, pos_sim_all, language_detection, mt_cfs, mt_bleu, ratio_chars (as described in Section 3.1), alongside cg_score, only_capletters_dif, and punctuation_similarity (from<cite> Barbu, 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_7",
  "x": [
   "Prior to submission, we benchmarked our system against the two baselines provided by the organizers: a dummy classifier assigning random classes according to the overall class distribution in the training data (Baseline 1), and a classifier based on the Church-Gale algorithm as adapted by<cite> Barbu (2015)</cite> (Baseline 2)."
  ],
  "y": "similarities"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_8",
  "x": [
   "More importantly, however, we compared our system to <cite>Barbu's (2015)</cite> approach, using the classification algorithms which reportedly worked best with the 17 features in his work."
  ],
  "y": "similarities uses"
 },
 {
  "id": "4da1c39dbbeaa2c9dac22118d0c698_9",
  "x": [
   "Again, we compared our system's performance to <cite>Barbu's (2015)</cite> method, using 2 /3-1 /3 splits of the training data (5-fold cross-validation)."
  ],
  "y": "similarities"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_0",
  "x": [
   "More recently, <cite>Lau et al. (2014)</cite> proposed a methodology to automate the word intrusion task directly."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_1",
  "x": [
   "These methodologies evaluate coherence over the top-N topic words, where N is selected arbitrarily: for Chang et al. (2009) , N = 5, whereas for Newman et al. (2010) , Aletras and Stevenson (2013) and <cite>Lau et al. (2014)</cite> , N = 10."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_2",
  "x": [
   "The germ of this paper came when using the automatic word intrusion methodology<cite> (Lau et al., 2014)</cite> , and noticing that introducing one extra word to a given topic can dramatically change the accuracy of intruder word prediction."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_3",
  "x": [
   "The germ of this paper came when using the automatic word intrusion methodology<cite> (Lau et al., 2014)</cite> , and noticing that introducing one extra word to a given topic can dramatically change the accuracy of intruder word prediction."
  ],
  "y": "motivation background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_4",
  "x": [
   "We experiment with the automatic word intrusion<cite> (Lau et al., 2014)</cite> and discover that correlation with human ratings decreases systematically as cardinality increases."
  ],
  "y": "uses"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_5",
  "x": [
   "Although there are existing datasets with human-annotated coherence scores (Newman et al., 2010; Aletras and Stevenson, 2013;<cite> Lau et al., 2014</cite>; Chang et al., 2009) , these topics were annotated using a fixed cardinality setting (e.g. 5 or 10)."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_6",
  "x": [
   "Following <cite>Lau et al. (2014)</cite> , we use two domains: (1) WIKI, a collection of 3.3 million English Wikipedia articles (retrieved November 28th 2009); and (2) NEWS, a collection of 1.2 million New York Times articles from 1994 to 2004 (English Gigaword)."
  ],
  "y": "uses"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_7",
  "x": [
   "2 There are two primary approaches to assessing topic coherence: (1) via word intrusion (Chang et (2) by directly measuring observed coherence (Newman et al., 2010;<cite> Lau et al., 2014)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_8",
  "x": [
   "2 There are two primary approaches to assessing topic coherence: (1) via word intrusion (Chang et (2) by directly measuring observed coherence (Newman et al., 2010;<cite> Lau et al., 2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_9",
  "x": [
   "<cite>Lau et al. (2014)</cite> proposed an automated approach to the word intrusion task."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_10",
  "x": [
   "This result is consistent with previous studies<cite> (Lau et al., 2014)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_11",
  "x": [
   "Newman et al. (2010) found PMI to be the best association measure, and later studies (Aletras and Stevenson, 2013;<cite> Lau et al., 2014)</cite> found that normalised PMI (NPMI: Bouma (2009)) improves PMI further."
  ],
  "y": "background"
 },
 {
  "id": "4e1b01c1faebc447891bc0b847316d_12",
  "x": [
   "Newman et al. (2010) found PMI to be the best association measure, and later studies (Aletras and Stevenson, 2013;<cite> Lau et al., 2014)</cite> found that normalised PMI (NPMI: Bouma (2009)) improves PMI further."
  ],
  "y": "uses"
 },
 {
  "id": "4edb60770ebeafc56446aeca9a3b2e_0",
  "x": [
   "Figure 1: The two paths above consist of the same relations (locatedIn \u2192 locatedIn) and, hence, the model of <cite>Neelakantan (2015)</cite> will assign them the same score for the relation AirportServesPlace without considering the fact that Yankee Stadium is not an airport."
  ],
  "y": "background"
 },
 {
  "id": "4edb60770ebeafc56446aeca9a3b2e_1",
  "x": [
   "Another line of work in relation extraction performs reasoning on the paths (multi-hop reasoning on paths of length \u2265 1) connecting an entity pair (Lao et al., 2011; Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014;<cite> Neelakantan et al., 2015</cite>; Guu et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "4edb60770ebeafc56446aeca9a3b2e_2",
  "x": [
   "In this work, we extend the method of <cite>Neelakantan (2015)</cite> by incorporating entity type information."
  ],
  "y": "extends"
 },
 {
  "id": "4edb60770ebeafc56446aeca9a3b2e_3",
  "x": [
   "This paper extends the Recurrent Neural Network model of <cite>Neelakantan (2015)</cite> by jointly reasoning over the relations and entity types occurring in the paths between an entity pair."
  ],
  "y": "extends"
 },
 {
  "id": "4edb60770ebeafc56446aeca9a3b2e_4",
  "x": [
   "In the following section, we first briefly describe the model proposed by <cite>Neelakantan (2015)</cite> (RNN model henceforth) followed by our extensions to it."
  ],
  "y": "extends background"
 },
 {
  "id": "4edb60770ebeafc56446aeca9a3b2e_5",
  "x": [
   "We rank the entity pairs in the test set based on their scores and calculate the Mean Average Precision (MAP) score for the ranking following previous work<cite> Neelakantan et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4f0dec0ce2d7639c250be00d5efee4_0",
  "x": [
   "Word collocation is one source of information that has been proposed as a useful tool to post-process word recognition results( <cite>[1,</cite> 4] )."
  ],
  "y": "background"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_1",
  "x": [
   "Nonetheless, several properties distinguish our corpus of peer reviews from other types of reviews: 1) The helpfulness of our peer reviews is directly rated using a discrete scale from one to five instead of being defined as a function of binary votes (e.g. the percentage of \"helpful\" votes<cite> (Kim et al., 2006)</cite> ); 2) Peer reviews frequently refer to the related students' papers, thus review analysis needs to take into account paper topics; 3) Within the context of education, peer-review helpfulness often has a writing specific semantics, e.g. improving revision likelihood; 4) In general, peer-review corpora collected from classrooms are of a much smaller size compared to online product reviews."
  ],
  "y": "differences"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_2",
  "x": [
   "As shown in Table 1 , we first mine generic linguistic features from reviews and papers based on the results of syntactic analysis of the texts, aiming to replicate the feature sets used by<cite> Kim et al. (2006)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_3",
  "x": [
   "Following<cite> Kim et al. (2006)</cite> , we train our helpfulness model using SVM regression with a radial basis function kernel provided by SVM light (Joachims, 1999) ."
  ],
  "y": "uses"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_4",
  "x": [
   "Note that in isolation, MET (paper ratings) are not significantly correlated with peer-review helpfulness, which is different from prior findings of product reviews<cite> (Kim et al., 2006)</cite> where product scores are significantly correlated with product-review helpfulness."
  ],
  "y": "differences"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_5",
  "x": [
   "When comparing the performance between predicting helpfulness ratings versus ranking, we observe r \u2248 r s consistently for our peer reviews, while<cite> Kim et al. (2006)</cite> reported r < r s for product reviews."
  ],
  "y": "differences"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_6",
  "x": [
   "4 Finally, we observed a similar feature redundancy effect as<cite> Kim et al. (2006)</cite> did, in that simply combining all features does not improve the model's performance."
  ],
  "y": "similarities"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_7",
  "x": [
   "Evaluation of the specialized features is shown in Table 3 , where all features examined are signifi- 4 The best performing single feature type reported<cite> (Kim et al., 2006)</cite> was review unigrams: r = 0.398 and rs = 0.593."
  ],
  "y": "background"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_8",
  "x": [
   "Given only 267 peer reviews in our case compared to more than ten thousand product reviews<cite> (Kim et al., 2006)</cite> , this is an important consideration."
  ],
  "y": "differences motivation"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_9",
  "x": [
   "Though our absolute quantitative results are not directly comparable to the results of<cite> Kim et al. (2006)</cite> , we indirectly compared them by analyzing the utility of features in isolation and combined."
  ],
  "y": "uses"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_10",
  "x": [
   "We also found that SVM regression does not favor ranking over predicting helpfulness as in<cite> (Kim et al., 2006)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "4f1a48dc79b9a099783d7e63741883_11",
  "x": [
   "More importantly, meta-data, which are found to significantly affect the perceived helpfulness of product reviews<cite> (Kim et al., 2006</cite>; Danescu-Niculescu-Mizil et al., 2009) , have no predictive power for peer reviews."
  ],
  "y": "differences"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_0",
  "x": [
   "Taking a small step towards this goal, recent work has begun developing artificial agents that follow natural language navigation instructions in perceptually-rich, simulated environments<cite> [4,</cite> 6] ."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_1",
  "x": [
   "Google StreetView images in Touchdown [6] or Matterport3D panoramas captured in homes in Vision-and-Language Navigation (VLN)<cite> [4]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_2",
  "x": [
   "In this work, we focus in on the Vision-and-Language Navigation (VLN)<cite> [4]</cite> task and lift these implicit assumptions by instantiating it in continuous 3D environments rendered in a high-throughput simulator [19] ."
  ],
  "y": "uses"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_5",
  "x": [
   "There have been a number of recent tasks proposed in this space<cite> [4,</cite> 6, 13, 20] ."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_6",
  "x": [
   "Most related to our work is the Vision-and-Language Navigation (VLN) task of Anderson et al.<cite> [4]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_7",
  "x": [
   "In overview, we develop this setting by transferring nav-graph-based Room-to-Room (R2R)<cite> [4]</cite> trajectories to reconstructed continuous Matterport3D environments in the Habitat simulator [19] ."
  ],
  "y": "uses"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_8",
  "x": [
   "In contrast to the simulator used in VLN<cite> [4]</cite> , Habitat allows agents to navigate freely in the continuous environments."
  ],
  "y": "differences"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_9",
  "x": [
   "Note that this is similar to the egocentric RGB perception in the original VLN task<cite> [4]</cite> but differs from the panoramic observation space adopted by nearly all follow-up work [9, 17, 26, 29] ."
  ],
  "y": "similarities"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_10",
  "x": [
   "In contrast, actions to move between panoramas in<cite> [4]</cite> traverse 2.25m on average and can include avoiding obstacles."
  ],
  "y": "differences"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_11",
  "x": [
   "To enable agent interaction with these panoramas, Anderson et al.<cite> [4]</cite> developed the Matterport3D Simulator."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_12",
  "x": [
   "Based on this simulator, Anderson et al.<cite> [4]</cite> collect the Roomto-Room (R2R) dataset containing 7189 trajectories each with three humangenerated instructions on average."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_13",
  "x": [
   "While there are many differences in the details, these models are conceptually similar to early<cite> [4]</cite> and more recent [29] work in the nav-graph based VLN task."
  ],
  "y": "similarities"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_14",
  "x": [
   "Aside from modeling details, much of the remaining progress in VLN has come from adjusting the training regime -adding auxiliary losses / rewards [17, 29] , mitigating exposure bias during training<cite> [4,</cite> 29] , or reducing data sparsity by incorporating synthetically generated data augmentation [9, 26] ."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_15",
  "x": [
   "Aside from modeling details, much of the remaining progress in VLN has come from adjusting the training regime -adding auxiliary losses / rewards [17, 29] , mitigating exposure bias during training<cite> [4,</cite> 29] , or reducing data sparsity by incorporating synthetically generated data augmentation [9, 26] ."
  ],
  "y": "motivation"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_16",
  "x": [
   "Prior work has shown significant gains by addressing this issue for VLN through scheduled sampling<cite> [4]</cite> or reinforcement learning fine-tuning [26, 29] ."
  ],
  "y": "background"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_17",
  "x": [
   "Prior work has shown significant gains by addressing this issue for VLN through scheduled sampling<cite> [4]</cite> or reinforcement learning fine-tuning [26, 29] ."
  ],
  "y": "similarities"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_18",
  "x": [
   "We report standard metrics for visual navigation tasks defined in [2, <cite>4,</cite> 18] -trajectory length in meters (TL), navigation error in meters from goal at termination (NE), oracle success rate (OS), success rate (SR), success weighted by inverse path length (SPL), and normalized dynamic-time warping (nDTW)."
  ],
  "y": "uses"
 },
 {
  "id": "4f646eceef2e5fc447a367488b6aaf_19",
  "x": [
   "For full details on these metrics, see [2, <cite>4,</cite> 18] ."
  ],
  "y": "uses"
 },
 {
  "id": "51575bb1ffb066d9570551f3347622_0",
  "x": [
   "Word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of NLP tasks <cite>[7,</cite> 8, 9 ]."
  ],
  "y": "background"
 },
 {
  "id": "51575bb1ffb066d9570551f3347622_1",
  "x": [
   "Word embeddings have become increasingly popular lately, proving to be valuable as a source of features in a broad range of NLP tasks <cite>[7,</cite> 8, 9] ."
  ],
  "y": "background"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_0",
  "x": [
   "The context of usage is even more crucial for characterizing meanings of ambiguous or polysemous words: a definition that does not take disambiguating context into account will be of limited use <cite>(Gadetsky et al., 2018)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_1",
  "x": [
   "3 Definition modeling as a sequence-to-sequence task<cite> Gadetsky et al. (2018)</cite> remarked that words are often ambiguous or polysemous, and thus generating a correct definition requires that we either use sense-level representations, or that we disambiguate the word embedding of the definiendum."
  ],
  "y": "background"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_2",
  "x": [
   "The disambiguation that<cite> Gadetsky et al. (2018)</cite> proposed was based on a contextual cue-ie."
  ],
  "y": "background"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_3",
  "x": [
   "Despite some key differences, all of the previously proposed architectures we are aware of (Noraset et al., 2017;<cite> Gadetsky et al., 2018</cite>; followed a pattern similar to sequence-to-sequence models."
  ],
  "y": "background"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_4",
  "x": [
   "Being simple and natural, the SELECT approach resembles architectures like that of<cite> Gadetsky et al. (2018)</cite> and : the full encoder is dedicated to altering the embedding of the definiendum on the basis of its context; in that, the encoder may be seen as a dedicated contextualization sub-module."
  ],
  "y": "similarities"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_5",
  "x": [
   "In the dataset of<cite> Gadetsky et al. (2018)</cite> (henceforth D Gad ), each example consists of a definiendum, the definientia for one of its meanings and a contextual cue sentence."
  ],
  "y": "background"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_6",
  "x": [
   "Perplexity measures for Noraset et al. (2017) and<cite> Gadetsky et al. (2018)</cite> are taken from the authors' respective publications."
  ],
  "y": "uses"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_7",
  "x": [
   "Like<cite> Gadetsky et al. (2018)</cite> , we conclude that disambiguating the definiendum, when done correctly, improves performances: our best performing contex-tual model outranks the non-contextual variant by 5 to 6 points."
  ],
  "y": "similarities"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_8",
  "x": [
   "Note also that we do not rely on taskspecific external resources (unlike Noraset et al., 2017; or on pre-training (unlike<cite> Gadetsky et al., 2018)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_9",
  "x": [
   "Another possibility would be to pre-train the model, as was done by<cite> Gadetsky et al. (2018)</cite> : in our case in particular, the encoder could be trained for POS-tagging or lemmatization."
  ],
  "y": "future_work"
 },
 {
  "id": "5177188d88391f08325262dbdefabf_10",
  "x": [
   "This was demonstrated by comparison both to the previous contextualized model by<cite> Gadetsky et al. (2018)</cite> and to the Transformerbased SELECT variation of our model, which differs from the proposed architecture only in the context encoding pipeline."
  ],
  "y": "similarities"
 },
 {
  "id": "52b9efca757fe5a376ca6b548d77ce_0",
  "x": [
   "There has also been some success incorporating selectional preferences<cite> (Sun and Korhonen, 2009)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "52b9efca757fe5a376ca6b548d77ce_1",
  "x": [
   "We used the spectral clustering (SPEC) method and settings as in<cite> Sun and Korhonen (2009)</cite> but adopted the Bhattacharyya kernel (Jebara and Kondor, 2003) to improve the computational efficiency of the approach given the high dimensionality of the quadratic feature space."
  ],
  "y": "uses"
 },
 {
  "id": "52b9efca757fe5a376ca6b548d77ce_2",
  "x": [
   "The mean-filed bound of the Bhattacharyya kernel is very similar to the KL divergence kernel (Jebara et al., 2004) which is frequently used in verb clustering experiments (Korhonen et al., 2003;<cite> Sun and Korhonen, 2009)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "52b9efca757fe5a376ca6b548d77ce_3",
  "x": [
   "The clustering results are evaluated using FMeasure as in<cite> Sun and Korhonen (2009)</cite> which provides the harmonic mean of precision (P ) and recall (R) P is calculated using modified purity -a global measure which evaluates the mean precision of clusters."
  ],
  "y": "uses"
 },
 {
  "id": "52b9efca757fe5a376ca6b548d77ce_4",
  "x": [
   "The result of F3 is 6.4% higher than the result (F=63.28) reported in<cite> Sun and Korhonen (2009)</cite> using the F1 feature."
  ],
  "y": "differences"
 },
 {
  "id": "52b9efca757fe5a376ca6b548d77ce_5",
  "x": [
   "Unlike these previous works, we will use selectional preferences to generalize the argument heads but will do so using preferences from distributional data <cite>(Sun and Korhonen, 2009</cite> ) rather than WordNet, and use all argument head data in all frames."
  ],
  "y": "uses"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_0",
  "x": [
   "One is a phrase-based translation in which a phrasal unit is employed for translation <cite>(Koehn et al., 2003)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_1",
  "x": [
   "In a phrase-based statistical translation <cite>(Koehn et al., 2003)</cite> , a bilingual text is decomposed as K phrase translation pairs (\u0113 1 ,f\u0101 1 ), (\u0113 2 ,f\u0101 2 ), ...: The input foreign sentence is segmented into phrasesf K 1 , mapped into corresponding English\u0113 K 1 , then, reordered to form the output English sentence according to a phrase alignment index mapping\u0101."
  ],
  "y": "background"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_2",
  "x": [
   "The phrase extraction algorithm is based on those presented by<cite> Koehn et al. (2003)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_3",
  "x": [
   "Second, phrase translation pairs are extracted from the word aligned corpus <cite>(Koehn et al., 2003)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_4",
  "x": [
   "The decoding process is very similar to those described in <cite>(Koehn et al., 2003)</cite> : It starts from an initial empty hypothesis."
  ],
  "y": "similarities uses"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_5",
  "x": [
   "Our phrase-based model uses a standard pharaoh feature functions listed as follows <cite>(Koehn et al., 2003)</cite> :"
  ],
  "y": "similarities uses"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_6",
  "x": [
   "For details, please refer to<cite> Koehn et al. (2003)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "537ec54aac2c3e3c62070468dcd8a3_7",
  "x": [
   "For each differently tokenized corpus, we computed word alignments by a HMM translation model (Och and Ney, 2003) and by a word alignment refinement heuristic of \"grow-diagfinal\" <cite>(Koehn et al., 2003)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_0",
  "x": [
   "Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000) , English<cite> (Yamada and Matsumoto, 2003)</cite> , Turkish (Oflazer, 2003) , and Swedish (Nivre et al., 2004) ."
  ],
  "y": "background"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_1",
  "x": [
   "Moreover, the deterministic dependency parser of<cite> Yamada and Matsumoto (2003)</cite> , when trained on the Penn Treebank, gives a dependency accuracy that is almost as good as that of Collins (1997) and Charniak (2000) ."
  ],
  "y": "background"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_2",
  "x": [
   "The parser described in this paper is similar to that of<cite> Yamada and Matsumoto (2003)</cite> in that it uses a deterministic parsing algorithm in combination with a classifier induced from a treebank."
  ],
  "y": "similarities uses"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_3",
  "x": [
   "The parser described in this paper is similar to that of<cite> Yamada and Matsumoto (2003)</cite> in that it uses a deterministic parsing algorithm in combination with a classifier induced from a treebank."
  ],
  "y": "differences extends"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_4",
  "x": [
   "As far as we know, this makes it different from all previous systems for dependency parsing applied to the Penn Treebank (Eisner, 1996; <cite>Yamada and Matsumoto, 2003)</cite> , although there are systems that extract labeled grammatical relations based on shallow parsing, e.g. Buchholz (2002) ."
  ],
  "y": "differences"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_5",
  "x": [
   "This permits us to make exact comparisons with the parser of<cite> Yamada and Matsumoto (2003)</cite> , but also the parsers of Collins (1997) and Charniak (2000) , which are evaluated on the same data set in<cite> Yamada and Matsumoto (2003)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_6",
  "x": [
   "The proportion of non-root words that are assigned the correct head<cite> (Yamada and Matsumoto, 2003)</cite> .",
   "The proportion of root words that are analyzed as such<cite> (Yamada and Matsumoto, 2003)</cite> .",
   "The proportion of sentences whose unlabeled dependency structure is completely correct<cite> (Yamada and Matsumoto, 2003)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_7",
  "x": [
   "Therefore, we have also included the labeled attachment score restricted to the G set for the parser using the B set (BG), and we see then that the attachment score improves, especially for Model 2. (All differences are significant beyond the .01 level; McNemar's test.) Table 2 shows the dependency accuracy, root accuracy and complete match scores for our best parser (Model 2 with label set B) in comparison with Collins (1997) (Model 3) , Charniak (2000) , and<cite> Yamada and Matsumoto (2003)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_8",
  "x": [
   "5 It is clear that, with respect to unlabeled accuracy, our parser does not quite reach state-of-the-art performance, even if we limit the competition to deterministic methods such as that of<cite> Yamada and Matsumoto (2003)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_9",
  "x": [
   "First of all, the part-of-speech tagger used for preprocessing in our experiments has a lower accuracy than the one used by<cite> Yamada and Matsumoto (2003)</cite> (96.1% vs. 97.1%) ."
  ],
  "y": "differences"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_10",
  "x": [
   "Secondly, since 5 The information in the first three rows is taken directly from<cite> Yamada and Matsumoto (2003)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "53ed85f4bfa634656062ad6ba342d2_11",
  "x": [
   "6 Although none of the previous results on labeling accuracy is strictly comparable to ours, it nevertheless seems fair to conclude that the<cite> (Yamada and Matsumoto, 2003)</cite> labeling accuracy of the present parser is close to the state of the art, even if its capacity to derive correct structures is not."
  ],
  "y": "differences"
 },
 {
  "id": "5596207b89d917db38c04af49c08aa_0",
  "x": [
   "Benefiting from the availability of large-scale benchmark datasets such as SQuAD (Rajpurkar et al., 2016) , the attention-based neural networks has spread to machine comprehension and question answering tasks to allow the model to attend over past output vectors (Wang & Jiang, 2017; Seo et al., 2017; Xiong et al., 2017;<cite> Hu et al., 2017</cite>; Pan et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "5596207b89d917db38c04af49c08aa_2",
  "x": [
   "Different from the commonly used approaches that every single model has exactly one question and passage encoder (Seo et al., 2017;<cite> Hu et al., 2017)</cite> , our encoder layers simultaneously calculate multiple question and passage representations, for the purpose of serving different parts of attention functions of different phases."
  ],
  "y": "differences"
 },
 {
  "id": "5596207b89d917db38c04af49c08aa_4",
  "x": [
   "Our directly available baseline is one implementation of MReader, re-named as Iterative Aligner which has very similar results as those of MReader <cite>(Hu et al., 2017)</cite> 71.1 / 79.5 71.3 / 79.7 75.6 / 82.8 75.9 / 82.9 MReader <cite>(Hu et al., 2017)</cite> N As shown in Table 3 , in the single model setting, our model PhaseCond is clearly more effective than all the single-layered models (BiDAF and RNET) and multi-layered models (MReader and Iterative Aligner)."
  ],
  "y": "similarities"
 },
 {
  "id": "55e429045af4434f9cb27ae8c6db66_0",
  "x": [
   "Traditional approaches treat AES as a classification (Larkey, 1998; Rudner and Liang, 2002) , regression (Attali and Burstein, 2004;<cite> Phandi et al., 2015)</cite> , or ranking classification problem (Yannakoudakis et al., 2011; Chen and He, 2013) , addressing AES by supervised learning."
  ],
  "y": "background"
 },
 {
  "id": "55e429045af4434f9cb27ae8c6db66_1",
  "x": [
   "Feature templates follow <cite>(Phandi et al., 2015)</cite> , extracted by EASE 1 , which are briefly listed in Table 1 . \"Useful n-grams\" are determined using the Fisher test to separate the good scoring essays and bad scoring essays."
  ],
  "y": "uses"
 },
 {
  "id": "55e429045af4434f9cb27ae8c6db66_2",
  "x": [
   "ML-\u03c1 <cite>(Phandi et al., 2015)</cite> was proposed to address this issue."
  ],
  "y": "uses"
 },
 {
  "id": "55e429045af4434f9cb27ae8c6db66_3",
  "x": [
   "The settings of data preparation follow <cite>(Phandi et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "55e429045af4434f9cb27ae8c6db66_4",
  "x": [
   "For domainadaptation (cross-domain) experiments, we follow <cite>(Phandi et al., 2015)</cite> , picking four pairs of essay prompts, namely, 1\u21922, 3\u21924, 5\u21926 and 7\u21928, where 1\u21922 denotes prompt 1 as source domain and prompt Hyper-parameters We use Adagrad for optimization."
  ],
  "y": "uses"
 },
 {
  "id": "57af9690eb41ff3f9217da6138425f_0",
  "x": [
   "Ideally, in addition to papers such as Kameyama's and Walker's, this collection could perhaps also have featured extended versions of papers, such as those of Kehler (1997) and Hahn and Strube (1997) , that highlight certain weaknesses of the original centering model or suggest extensions or alternative solutions <cite>(Strube 1998)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_0",
  "x": [
   "Our study focuses on racial bias in hate speech and abusive language detection datasets<cite> (Waseem, 2016</cite>; Waseem and Hovy, 2016; Golbeck et al., 2017; Founta et al., 2018) , all of which use data collected from Twitter."
  ],
  "y": "background"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_1",
  "x": [
   "While not directly measuring bias, prior work has explored how annotation schemes and the identity of the annotators<cite> (Waseem, 2016</cite> ) might be manipulated to help to avoid bias."
  ],
  "y": "background"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_2",
  "x": [
   "To account for potential bias in the previous dataset,<cite> Waseem (2016)</cite> relabeled 2876 tweets in the dataset, along with a new sample from the tweets originally collected."
  ],
  "y": "background"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_3",
  "x": [
   "For<cite> Waseem (2016)</cite> we see that there is no significant difference in the estimated rates at which tweets are classified as racist across groups, although the rates remain low."
  ],
  "y": "similarities"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_4",
  "x": [
   "Table 3 shows that for tweets containing the word \"n*gga\", classifiers trained on Waseem and Hovy (2016) and<cite> Waseem (2016)</cite> are both predict black-aligned tweets to be instances of sexism approximately 1.5 times as often as white-aligned tweets."
  ],
  "y": "background"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_5",
  "x": [
   "We see similar results for Waseem and Hovy (2016) and<cite> Waseem (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_6",
  "x": [
   "Classifiers trained on data from Waseem and Hovy (2016) and<cite> Waseem (2016)</cite> only predicted a small fraction of the tweets to be racism.",
   "Given this result, and the gender biases identified in these data by Park et al. (2018), it not apparent that the purportedly expert annotators were any less biased than amateur annotators<cite> (Waseem, 2016)</cite> ."
  ],
  "y": "similarities background"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_7",
  "x": [
   "Some studies sampled tweets using small, ad hoc sets of keywords created by the authors (Waseem and Hovy, 2016;<cite> Waseem, 2016</cite>; Golbeck et al., 2017) , an approach demonstrated to produce poor results (King et al., 2017) ."
  ],
  "y": "background uses"
 },
 {
  "id": "57e65909baf823ff00a9a10a64fffd_8",
  "x": [
   "The datasets considered here relied upon a range of different annotators, from the authors (Golbeck et al., 2017; Waseem and Hovy, 2016) and crowdworkers Founta et al., 2018) to activists<cite> (Waseem, 2016)</cite> .",
   "Even the classifier trained on expert-labeled data<cite> (Waseem, 2016)</cite> flags black-aligned tweets as sexist at almost twice the rate of white-aligned tweets."
  ],
  "y": "differences extends"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_0",
  "x": [
   "In recent years, there has been a surge of interest in performing end-to-end relation extraction, jointly recognizing entities and relations given free text inputs (Li and Ji, 2014; Miwa and Sasaki, 2014; <cite>Miwa and Bansal, 2016</cite>; ."
  ],
  "y": "motivation"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_1",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> were among the first to use neural networks for end-to-end relation extraction, showing highly promising results.",
   "In particular, <cite>they</cite> used bidirectional LSTM (Graves et al., 2013) to learn hidden word representations under a sentential context, and further leveraged treestructured LSTM (Tai et al., 2015) to encode syntactic information, given the output of a parser."
  ],
  "y": "background"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_2",
  "x": [
   "On the other hand, <cite>Miwa and Bansal (2016)</cite> 's model is trained locally, without considering structural correspondences between incremental decisions."
  ],
  "y": "motivation background"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_3",
  "x": [
   "We take a different approach to representation learning, addressing two potential limitations of <cite>Miwa and Bansal (2016)</cite> .",
   "First, <cite>Miwa and Bansal (2016)</cite> rely on external syntactic parsers for obtaining syntactic information, which is crucial for relation extraction (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008) ."
  ],
  "y": "motivation"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_4",
  "x": [
   "We take a different approach to representation learning, addressing two potential limitations of <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_5",
  "x": [
   "In contrast, the method of <cite>Miwa and Bansal (2016)</cite> must consider tree LSTM formulations that are specific to grammar formalisms, which can be structurally different (Tai et al., 2015) ."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_6",
  "x": [
   "Second, <cite>Miwa and Bansal (2016)</cite> did not explicitly learn the representation of segments when predicting entity boundaries or making relation classification decisions, which can be intuitively highly useful, and has been investigated in several studies (Wang and Chang, 2016; ."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_7",
  "x": [
   "Evaluation on two benchmark datasets shows that our method outperforms previous methods of <cite>Miwa and Bansal (2016)</cite> , Li and Ji (2014) and Miwa and Sasaki (2014) , giving the best reported results on both benchmarks."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_8",
  "x": [
   "We follow Miwa and Sasaki (2014) and , treating relation extraction as a tablefilling problem, performing entity detection and relation classification using a single incremental model, which is similar in spirit to <cite>Miwa and Bansal (2016)</cite> by performing the task end-to-end."
  ],
  "y": "similarities"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_9",
  "x": [
   "We map entity words into labels under the BILOU (Begin, Inside, Last, Outside, Unit) scheme, assuming that there are no overlapping entities in one sentence (Li and Ji, 2014; Miwa and Sasaki, 2014; <cite>Miwa and Bansal, 2016</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_10",
  "x": [
   "Following <cite>Miwa and Bansal (2016)</cite> , we use a neural network to learn the vector representation of T i\u22121 , and then use Equation 1 to rank candidate next labels."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_11",
  "x": [
   "The above two components have also been used by <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_12",
  "x": [
   "We follow <cite>Miwa and Bansal (2016)</cite> , learning global context representations using LSTMs."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_13",
  "x": [
   "Different from <cite>Miwa and Bansal (2016)</cite> , who use the output hidden vectors {h i } of LSTMs to represent words, we exploit segment representations as well."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_14",
  "x": [
   "For example, the shortest dependency path has been used by several relation extraction models (Bunescu and Mooney, 2005; <cite>Miwa and Bansal, 2016</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_15",
  "x": [
   "For example, the shortest dependency path has been used by several relation extraction models (Bunescu and Mooney, 2005; <cite>Miwa and Bansal, 2016</cite>) ."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_16",
  "x": [
   "Our exploration of syntactic features has two main advantages over the method of <cite>Miwa and Bansal (2016)</cite> , where dependency path LSTMs are used for relation classification."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_17",
  "x": [
   "On the one hand, incorrect dependency paths between entity pairs can propagate to relation classification in <cite>Miwa and Bansal (2016)</cite> , because these paths rely on explicit discrete outputs from a syntactic parser."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_18",
  "x": [
   "Previous work (<cite>Miwa and Bansal, 2016</cite>; trains model parameters by modeling each step for labeling one input sentence separately."
  ],
  "y": "background"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_19",
  "x": [
   "For the ACE05 dataset, we follow Li and Ji (2014) and <cite>Miwa and Bansal (2016)</cite> , splitting and preprocessing the dataset into training, development and test sets."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_20",
  "x": [
   "For the local model, we follow <cite>Miwa and Bansal (2016)</cite> , training parameters only for entity detection during the first 20 iterations."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_21",
  "x": [
   "Compared with <cite>Miwa and Bansal (2016)</cite> features for entity detection."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_22",
  "x": [
   "For the local model, we apply scheduled sampling (Bengio et al., 2015) , which has been shown to improve the performance of relation extraction by <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_23",
  "x": [
   "We also compare our feature integration method with the traditional methods based on syntactic outputs which <cite>Miwa and Bansal (2016)</cite> and all previous methods use."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_24",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> , who exploit end-to-end LSTM neural networks with local optimization, and L&J (2014) and M&S (2014) refer to Li and Ji (2014) and Miwa and Sasaki (2014) , respectively, which are both globally optimized models using discrete features, giving the top F-scores among statistical models."
  ],
  "y": "differences"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_25",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> exploit the shortest dependency path, which can make the distance between two entities closer compared with their sequential dis-tance, thus facilitating relation extraction."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_26",
  "x": [
   "Recent work shows that joint learning and decoding with a single model brings more benefits for the two tasks (Li and Ji, 2014; Miwa and Sasaki, 2014; <cite>Miwa and Bansal, 2016</cite>; , and we follow this line of work in the study."
  ],
  "y": "uses"
 },
 {
  "id": "580713b57ae47692af0d0c86a07fd1_27",
  "x": [
   "LSTM features have been extensively exploited for NLP tasks, including tagging Lample et al., 2016) , parsing (Kiperwasser and Goldberg, 2016; Dozat and Manning, 2016) , relation classification Vu et al., 2016; <cite>Miwa and Bansal, 2016</cite>) and sentiment analysis ."
  ],
  "y": "background"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_0",
  "x": [
   "4.3.pdf and Rilof, 2009; Liao and Grishman, 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013a) or a joint inference architecture that performs the two subtasks at the same time to benefit from their inter-dependencies (Riedel and McCallum, 2011a; Riedel and McCallum, 2011b;<cite> Li et al., 2013b</cite>; Venugopal et al., 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_1",
  "x": [
   "Although this approach has achieved the top performance (Hong et al., 2011;<cite> Li et al., 2013b)</cite> , it suffers from at least two issues:"
  ],
  "y": "motivation"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_2",
  "x": [
   "Given a sentence, for every token in that sentence, we want to predict if the current token is an event trigger: i.e, does it express some event in the pre-defined event set or not<cite> (Li et al., 2013b)</cite> ?"
  ],
  "y": "background uses"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_3",
  "x": [
   "For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaning 529 documents (14,849 sentences) as the previous studies on this dataset (Ji and Grishman, 2008; Liao and Grishman, 2010;<cite> Li et al., 2013b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_4",
  "x": [
   "The state-of-the-art systems for event detection on the ACE 2005 dataset have followed the traditional feature-based approach with rich hand-designed feature sets, and statistical classifiers such as MaxEnt and perceptron for structured prediction in a joint architecture (Hong et al., 2011;<cite> Li et al., 2013b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_5",
  "x": [
   "As we can see from the table, considering the systems that only use sentence level information, CNN1 significantly outperforms the MaxEnt classifier as well as the joint beam search with local features from <cite>Li et al. (2013b)</cite> (an improvement of 1.6% in F1 score), and performs comparably with the joint beam search approach using both local and global features<cite> (Li et al., 2013b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_6",
  "x": [
   "More interestingly, when the entity type information is incorporated into CNN1, we obtain CNN2 that still only needs sentence level information but achieves the stateof-the-art performance for this task (an improvement of 1.5% over the best system with only sentence level information<cite> (Li et al., 2013b)</cite> )."
  ],
  "y": "differences"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_7",
  "x": [
   "Table 3 compares the performance of CNN1 and the feature-based systems in a more realistic setting, where entity mentions and types are acquired from an automatic high-performing name tagger and information extraction system<cite> (Li et al., 2013b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "586a0f40a9299ef2753d2b0575eff8_9",
  "x": [
   "First, rather than relying on the symbolic and concrete forms (i.e words, types etc) to construct features as the traditional feature-based systems (Ji and Grishman, 2008;<cite> Li et al., 2013b)</cite> do, CNNs automatically induce their features from word embeddings, the general distributed representation of words that is shared across domains."
  ],
  "y": "differences"
 },
 {
  "id": "59a7c1fffdd45f8e152d060a4b9f50_0",
  "x": [
   "We present results using support vector regression (SVR) with RBF (radial basis functions) kernel (Smola and Sch\u00f6lkopf, 2004) for sentence and document translation prediction tasks and Global Linear Models (GLM) (Collins, 2002) with dynamic learning (GLMd) <cite>(Bi\u00e7ici, 2013</cite>; Bi\u00e7ici and Way, 2014) for word-level translation performance prediction."
  ],
  "y": "uses"
 },
 {
  "id": "59a7c1fffdd45f8e152d060a4b9f50_1",
  "x": [
   "We use mean absolute error (MAE), relative absolute error (RAE), root mean squared error (RMSE), and correlation (r) as well as relative MAE (MAER) and relative RAE (MRAER) to evaluate (Bi\u00e7ici, 2015;<cite> Bi\u00e7ici, 2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "59a7c1fffdd45f8e152d060a4b9f50_2",
  "x": [
   "We develop individual RTM models for each subtask and use GLMd model <cite>(Bi\u00e7ici, 2013</cite>; Bi\u00e7ici and Way, 2014) , for predicting the quality at the word-level."
  ],
  "y": "uses"
 },
 {
  "id": "59a7c1fffdd45f8e152d060a4b9f50_3",
  "x": [
   "In Table 6 , we list the RTM test results for tasks and subtasks that predict HTER or METEOR from QET15, QET14 (Bi\u00e7ici and Way, 2014) , and QET13<cite> (Bi\u00e7ici, 2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "59a7c1fffdd45f8e152d060a4b9f50_4",
  "x": [
   "Table 6 : Test performance of the top individual RTM results when predicting HTER or METEOR also including results from QET14 (Bi\u00e7ici and Way, 2014) and QET13<cite> (Bi\u00e7ici, 2013)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_0",
  "x": [
   "Such a scheme facilitates the detection of decision discussions<cite> (Fern\u00e1ndez et al., 2008)</cite> , and by indicating which utterances contain particular types of information, it also aids their summarization."
  ],
  "y": "background"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_1",
  "x": [
   "Only very recent research has specifically investigated the automatic detection of decisions, namely (Hsueh and Moore, 2007) and<cite> (Fern\u00e1ndez et al., 2008)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_2",
  "x": [
   "Unlike Hsueh and Moore (2007),<cite> Fern\u00e1ndez et al. (2008)</cite> made an attempt at modelling the structure of decision-making dialogue."
  ],
  "y": "background"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_3",
  "x": [
   "Note that (Purver et al., 2007) had previously pursued the same basic approach as<cite> Fern\u00e1ndez et al. (2008)</cite> in order to detect action items."
  ],
  "y": "background"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_4",
  "x": [
   "While both Hsueh and Moore (2007), and<cite> Fern\u00e1ndez et al. (2008)</cite> attempted off-line decision detection, in this paper, we attempt real-time decision detection."
  ],
  "y": "differences"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_5",
  "x": [
   "We take the same basic approach as<cite> Fern\u00e1ndez et al. (2008)</cite> , and make changes to its implementation so that it can work effectively in real-time."
  ],
  "y": "differences"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_6",
  "x": [
   "We use the same annotation scheme as<cite> (Fern\u00e1ndez et al., 2008</cite> ) in order to model decision-making dialogue."
  ],
  "y": "uses"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_7",
  "x": [
   "The reader can find a comparison between these annotations and our own manual transcript annotations in<cite> (Fern\u00e1ndez et al., 2008)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_9",
  "x": [
   "For 1 and 2, we use the same lenient-match metric as<cite> (Fern\u00e1ndez et al., 2008</cite>; Hsueh and Moore, 2007) , which allows a margin of 20 seconds preceding and following a hypothesized DDA."
  ],
  "y": "uses"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_10",
  "x": [
   "For 3, we follow<cite> (Fern\u00e1ndez et al., 2008</cite>; Purver et al., 2007) and use a windowed metric that divides the dialogue into 30-second windows and evaluates on a per window basis."
  ],
  "y": "uses"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_11",
  "x": [
   "Hence, while<cite> Fern\u00e1ndez et al. (2008)</cite> demonstrated that the hierarchical classification approach could improve off-line decision detection, we have demonstrated here that it can also improve realtime decision detection."
  ],
  "y": "differences"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_12",
  "x": [
   "7 Conclusion<cite> (Fern\u00e1ndez et al., 2008)</cite> described an approach to decision detection in multi-party meetings and demonstrated how it could work relatively well in an off-line system."
  ],
  "y": "background"
 },
 {
  "id": "5b17eb75600820a80b3573bf74c427_13",
  "x": [
   "In this paper then, we have taken the same basic approach to decision detection as<cite> Fern\u00e1ndez et al. (2008)</cite> , but changed the way in which it is implemented so that it can work effectively in realtime."
  ],
  "y": "differences background"
 },
 {
  "id": "5c63296c36cbd95e07f05f2563a2a1_0",
  "x": [
   "Recently, Convolutional Neural Network (CNN) was introduced into many models for extracting sub-word information from a word (Santos and Guimaraes, 2015;<cite> Ma and Hovy, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "5c63296c36cbd95e07f05f2563a2a1_1",
  "x": [
   "Above all, BLSTM-CNNs-CRF<cite> (Ma and Hovy, 2016</cite> ) achieved state-of-theart performance on the standard English corpus: CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) ."
  ],
  "y": "background"
 },
 {
  "id": "5c63296c36cbd95e07f05f2563a2a1_2",
  "x": [
   "In this study, we specifically examine BLSTMCNNs-CRF<cite> (Ma and Hovy, 2016)</cite> because it achieves state-of-the-art performance in the CoNLL 2003 corpus."
  ],
  "y": "motivation"
 },
 {
  "id": "5c63296c36cbd95e07f05f2563a2a1_3",
  "x": [
   "In this study, we specifically examine BLSTMCNNs-CRF<cite> (Ma and Hovy, 2016)</cite> because it achieves state-of-the-art performance in the CoNLL 2003 corpus."
  ],
  "y": "background"
 },
 {
  "id": "5c63296c36cbd95e07f05f2563a2a1_4",
  "x": [
   "Other conditions are the same as those reported for an earlier study<cite> (Ma and Hovy, 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_0",
  "x": [
   "Fine-grained opinion mining aims to detect structured user opinions in text, which has drawn much attention in the natural language processing (NLP) community <cite>(Kim and Hovy, 2006</cite>; Breck et al., 2007; Ruppenhofer et al., 2008; Wilson et al., 2009; Qiu et al., 2011; Cardie, 2013, 2014; Liu et al., 2015; Wiegand et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_1",
  "x": [
   "Earlier work attempts to exploit a well-trained SRL model to recognize possible semantic roles for a given opinion expression, and then map the semantic roles into opinion roles <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008) ."
  ],
  "y": "background"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_2",
  "x": [
   "Earlier work attempts to exploit a well-trained SRL model to recognize possible semantic roles for a given opinion expression, and then map the semantic roles into opinion roles <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008) ."
  ],
  "y": "motivation"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_3",
  "x": [
   "Results show that SRL is highly effective for ORL, which is consistent with previous findings <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008; Marasovi\u0107 and Frank, 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_4",
  "x": [
   "The results show that SRL information is very helpful for ORL, which is consistent with previous studies <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008; Marasovi\u0107 and Frank, 2018) ."
  ],
  "y": "similarities"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_5",
  "x": [
   "Results show that SRL is highly effective for ORL, which is consistent with previous findings <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008; Marasovi\u0107 and Frank, 2018) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_6",
  "x": [
   "Several works even directly transfer semantic roles into opinion roles for ORL <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008) , treating opinion expressions as the major predicates."
  ],
  "y": "background"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_7",
  "x": [
   "Several works even directly transfer semantic roles into opinion roles for ORL <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008) , treating opinion expressions as the major predicates."
  ],
  "y": "extends"
 },
 {
  "id": "5cf0215cd20c86f329c8debc0daeb8_8",
  "x": [
   "According to the above findings, we design a simple system by mapping SRL outputs into ORL directly <cite>(Kim and Hovy, 2006</cite>; Ruppenhofer et al., 2008) ."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_0",
  "x": [
   "The central aspects of our discussion are (a) three dependency formats: two 'classic' representations for dependency parsing, namely, Stanford Basic (SB) and CoNLL Syntactic Dependencies (CD), and bilexical dependencies from the HPSG English Resource Grammar (ERG), so-called DELPH-IN Syntactic Derivation Tree (DT), proposed recently by Ivanova et al. (2012) ; (b) three state-of-the art statistical parsers: Malt (Nivre et al., 2007) , MST (McDonald et al., 2005) and the parser of <cite>Bohnet and Nivre (2012)</cite> ; (c) two approaches to wordcategory disambiguation, e.g. exploiting common PTB tags and using supertags (i.e. specialized ERG lexical types)."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_2",
  "x": [
   "<cite>Bohnet and Nivre (2012)</cite> parser: transitionbased dependency parser with joint tagger that implements global learning and beam search."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_3",
  "x": [
   "In this section we give a detailed analysis of parsing into SB, CD and DT dependencies with Malt, MST and the <cite>Bohnet and Nivre (2012)</cite> parser."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_4",
  "x": [
   "For Malt and MST we perform the experiments on gold PoS tags, whereas the <cite>Bohnet and Nivre (2012)</cite> parser predicts PoS tags during testing."
  ],
  "y": "differences"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_5",
  "x": [
   "Prior to each experiment with Malt, we used MaltOptimizer to obtain settings and a feature model; for MST we exploited default configuration; for the <cite>Bohnet and Nivre (2012)</cite> parser we set the beam parameter to 80 and otherwise employed the default setup."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_6",
  "x": [
   "This is explained by the fact that the <cite>Bohnet and Nivre (2012)</cite> parser implements a novel approach to parsing: beam-search algorithm with global structure learning."
  ],
  "y": "background"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_7",
  "x": [
   "The <cite>Bohnet and Nivre (2012)</cite> parser outperforms Malt on CD and DT and MST on SB, CD and DT with PTB tags even though it does not receive gold PTB tags during test phase but predicts them (Table 2 , Predicted PTB tags)."
  ],
  "y": "differences"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_8",
  "x": [
   "For the <cite>Bohnet and Nivre (2012)</cite> parser the complexity of supertag prediction has significant negative influence on the attachment and labeling accuracies ( Table 2 , Predicted supertags)."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_9",
  "x": [
   "The addition of gold PTB tags as a feature lifts the performance of the <cite>Bohnet and Nivre (2012)</cite> parser to the level of performance of Malt and MST on CD with gold supertags and Malt on SB with gold supertags (compare Table 2 , Predicted supertags + gold PTB, and Table 1 , Gold supertags)."
  ],
  "y": "extends"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_10",
  "x": [
   "For the <cite>Bohnet and Nivre (2012)</cite> parser we also observe small rise of accuracy when gold supertags are provided as a feature for prediction of PTB tags (compare Predicted PTB tags and Predicted PTB tags + gold supertags sections of Table 2 )."
  ],
  "y": "extends"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_11",
  "x": [
   "The parsers have different running times: it takes minutes to run an experiment with Malt, about 2 hours with MST and up to a day with the <cite>Bohnet and Nivre (2012)</cite> parser."
  ],
  "y": "differences"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_12",
  "x": [
   "The <cite>Bohnet and Nivre (2012)</cite> parser predicts supertags with an average accuracy of 89.73% which is significantly lower than state-ofthe-art 95% (Ytrest\u00f8l, 2011) ."
  ],
  "y": "differences"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_13",
  "x": [
   "VBP (verb, non-3rd person singular present), VBZ (verb, 3rd person singular present) and VBG (verb, gerund or present participle) are the PTB tags that have error rates in 10 highest error rates list for each parser (Malt, MST and the <cite>Bohnet and Nivre (2012)</cite> parser) with each dependency format (SB, CD and DT) and with each PoS tag set (PTB PoS and supertags) when PTB tags are included as CPOSTAG feature."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_14",
  "x": [
   "The error rate of Malt, MST and the <cite>Bohnet and Nivre (2012)</cite> parser for the coordination is not so high for SB and CD ( 1% and 2% correspondingly with MaltParser, PTB tags) whereas for DT the error rate on the CPOSTAGS is especially high (26% with MaltParser, PTB tags)."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_15",
  "x": [
   "The <cite>Bohnet and Nivre (2012)</cite> parser succeeds in finding the correct conjucts (shown in bold font) on DT and makes mistakes on SB and CD in some difficult cases like the following ones: a) <. . ."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_16",
  "x": [
   "In this survey we gave a comparative experimental overview of (i) parsing three dependency schemes, viz., Stanford Basic (SB), CoNLL Syntactic Dependencies (CD) and DELPH-IN Syntactic Derivation Tree (DT), (ii) with three leading dependency parsers, viz., Malt, MST and the <cite>Bohnet and Nivre (2012)</cite> parser (iii) exploiting two different tagsets, viz., PTB tags and supertags."
  ],
  "y": "uses"
 },
 {
  "id": "5d3c08596677a1f8ac48fa17766bb4_17",
  "x": [
   "From the parser perspective, the <cite>Bohnet and Nivre (2012)</cite> parser performs better than Malt and MST not only on conventional formats but also on the new representation, although this parser solves a harder task than Malt and MST."
  ],
  "y": "differences"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_0",
  "x": [
   "To combat the noisy training data produced by heuristic labeling in distant supervision, researchers (Bunescu and Mooney, 2007; Riedel et al., 2010; <cite>Hoffmann et al., 2011</cite>; Surdeanu et al., 2012) exploited multi-instance learning models."
  ],
  "y": "background"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_1",
  "x": [
   "To combat the noisy training data produced by heuristic labeling in distant supervision, researchers (Bunescu and Mooney, 2007; Riedel et al., 2010; <cite>Hoffmann et al., 2011</cite>; Surdeanu et al., 2012) exploited multi-instance learning models."
  ],
  "y": "motivation"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_2",
  "x": [
   "We further note that iterative bootstrapping over a single distant supervision system is difficult, because state-of-the-art systems (Surdeanu et al., 2012; <cite>Hoffmann et al., 2011</cite>; Riedel et al., 2010; Mintz et al., 2009) , detect only few false negatives in the training data due to their high-precision low-recall features, which were originally proposed by Mintz et al. (2009) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_3",
  "x": [
   "We further note that iterative bootstrapping over a single distant supervision system is difficult, because state-of-the-art systems (Surdeanu et al., 2012; <cite>Hoffmann et al., 2011</cite>; Riedel et al., 2010; Mintz et al., 2009) , detect only few false negatives in the training data due to their high-precision low-recall features, which were originally proposed by Mintz et al. (2009) .",
   "We present a reliable and novel way to address these issues and achieve significant improvement over the <cite>MULTIR</cite> system (<cite>Hoffmann et al., 2011</cite>) , increasing recall from 47.7% to 61.2% at comparable precision."
  ],
  "y": "extends"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_4",
  "x": [
   "While relation extraction systems exploit rich and complex features that are necessary to extract the exact relation (Mintz et al., 2009; Riedel et al., 2010; <cite>Hoffmann et al., 2011</cite>) , passage retrieval components use coarse features in order to provide different and complementary feedback to information extraction models."
  ],
  "y": "background"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_5",
  "x": [
   "While relation extraction systems exploit rich and complex features that are necessary to extract the exact relation (Mintz et al., 2009; Riedel et al., 2010; <cite>Hoffmann et al., 2011</cite>) , passage retrieval components use coarse features in order to provide different and complementary feedback to information extraction models."
  ],
  "y": "extends"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_6",
  "x": [
   "We use a state-of-the-art open-source system, <cite>MULTIR</cite> (<cite>Hoffmann et al., 2011</cite>) , as the relation extraction component."
  ],
  "y": "uses"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_7",
  "x": [
   "<cite>MULTIR</cite> is based on multi-instance learning, which assumes that at least one sentence of those matching a given entity-pair contains the relation of interest (Riedel et al., 2010) in the given knowledge base to tolerate false positive noise in the training data and superior than previous models (Riedel et al., 2010; Mintz et al., 2009 ) by allowing overlapping relations.",
   "<cite>MULTIR</cite> uses features which are based on Mintz et al. (2009) and consist of conjunctions of named entity tags, syntactic dependency paths between arguments, and lexical information."
  ],
  "y": "background"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_8",
  "x": [
   "For evaluating extraction accuracy, we follow the experimental setup of <cite>Hoffmann et al. (2011)</cite> , and use <cite>their</cite> implementation of <cite>MULTIR 4</cite> with 50 training iterations as our baseline."
  ],
  "y": "uses"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_9",
  "x": [
   "Our complete system, which we call IRMIE, combines our passage retrieval component with <cite>MULTIR</cite>."
  ],
  "y": "uses"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_10",
  "x": [
   "We use the same datasets as in <cite>Hoffmann et al. (2011)</cite> and Riedel et al. (2010) , which include 3-years of New York Times articles aligned with Freebase."
  ],
  "y": "uses"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_11",
  "x": [
   "The sentential extraction evaluation is performed on a small amount of manually annotated sentences, sampled from the union of matched sentences and Table 1 : Overall sentential extraction performance evaluated on the original test set of <cite>Hoffmann et al. (2011)</cite> and our corrected test set: Our proposed relevance feedback technique yields a substantial increase in recall."
  ],
  "y": "uses"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_12",
  "x": [
   "We define S e as the sentences where some system extracted a relation and S F as the sentences that match the arguments of a fact in \u2206. The sentential precision and recall is computed on a randomly sampled set of sentences from S e \u222a S F , in which each sentence is manually labeled whether it expresses any relation in R. Figure 3 shows the precision/recall curves for <cite>MULTIR</cite> with and without pseudo-relevance feedback computed on the test dataset of 1000 sentence used by <cite>Hoffmann et al. (2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_13",
  "x": [
   "Because the two types of lexical features used in our passage retrieval models are not used in <cite>MUL-TIR</cite>, we created another baseline MULTIRLEX by adding these features into <cite>MULTIR</cite> in order to rule out the improvement from additional information."
  ],
  "y": "extends"
 },
 {
  "id": "5e34591c2a7b1664e1275372c40b79_14",
  "x": [
   "Note that the sentences are sampled from the union of Freebase matches and sentences from which some systems in <cite>Hoffmann et al. (2011)</cite> extracted a relation."
  ],
  "y": "uses"
 },
 {
  "id": "5e6d5bb4fb5be2b18ce3256302bf28_0",
  "x": [
   "Generation of referring expression (GRE) is an important task in the field of Natural Language Generation (NLG) systems (Reiter and <cite>Dale, 1995)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "5e6d5bb4fb5be2b18ce3256302bf28_1",
  "x": [
   "It always generates shortest possible referring description to identify an object. But Reiter and<cite> Dale (1995)</cite> later proved that Full Brevity requirement is an NP-Hard task, thus computationally intractable and offered an alternative polynomial time Incremental Algorithm."
  ],
  "y": "background"
 },
 {
  "id": "5e6d5bb4fb5be2b18ce3256302bf28_2",
  "x": [
   "The scheme is based on Incremental algorithm<cite> (Reiter and Dale 1995)</cite> and incorporates the attractive properties (e.g. speed, simplicity etc) of that algorithm."
  ],
  "y": "uses"
 },
 {
  "id": "5e6d5bb4fb5be2b18ce3256302bf28_3",
  "x": [
   "Reiter and<cite> Dale (1995)</cite> pointed out the notion of 'PreferredAttributes' (e.g. Type, Size, Color etc) which is a sequence of attributes of an object that human speakers generally use to identify that object from the contrast set."
  ],
  "y": "uses"
 },
 {
  "id": "5eb321d3c63642a4b148e1276eab20_0",
  "x": [
   "Recent years witness the boost of neural models in this task, e.g.,<cite> (Shimaoka et al. 2016)</cite> employs an attention based LSTM to attain sentence representations and achieves state-of-the-art performance."
  ],
  "y": "background"
 },
 {
  "id": "5eb321d3c63642a4b148e1276eab20_1",
  "x": [
   "Recent years witness the boost of neural models in this task, e.g.,<cite> (Shimaoka et al. 2016)</cite> employs an attention based LSTM to attain sentence representations and achieves state-of-the-art performance."
  ],
  "y": "motivation background"
 },
 {
  "id": "5eb321d3c63642a4b148e1276eab20_2",
  "x": [
   "Firstly PAN employs LSTM to generate representations of sentences s i following<cite> (Shimaoka et al. 2016)</cite> , where s i \u2208 R d is the semantic representation of s i , i \u2208 {1, 2, ..., n}. Afterwards, we build path-based attention \u03b1 i,t over sentences s i for each type t \u2208 T e , which is expected to focus on relevant sentences to type t. Then, the representation of sentence set S e for type t, denoted by s e,t \u2208 R d , is calculated through weighted sum of vectors of sentences."
  ],
  "y": "uses"
 },
 {
  "id": "5eb321d3c63642a4b148e1276eab20_3",
  "x": [
   "Experiments are carried on two widely used datasets OntoNotes and FIGER(GOLD), and the training dataset of OntoNotes is noisy compared to FIGER(GOLD)<cite> (Shimaoka et al. 2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "5eb321d3c63642a4b148e1276eab20_4",
  "x": [
   "We employ Strict Accuracy (Acc), Loose Macro F1 (Ma-F1), and Loose Micro F1 (Mi-F1) as evaluation measures following <cite>(Shimaoka et al. 2016</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "5eb321d3c63642a4b148e1276eab20_5",
  "x": [
   "The baselines are chosen from two aspects: (1) Predicting types in a unified process using raw noisy data, i.e., TLSTM<cite> (Shimaoka et al. 2016)</cite> , and other methods shown in Table2."
  ],
  "y": "uses"
 },
 {
  "id": "5f25b6a3bcaca2e4beb59ce0f3eb5f_0",
  "x": [
   "This is an extension and further validation of the results achieved by <cite>Manion and Sainudiin (2014)</cite>."
  ],
  "y": "extends"
 },
 {
  "id": "5f25b6a3bcaca2e4beb59ce0f3eb5f_2",
  "x": [
   "In-Degree Centrality as implemented in<cite> (Manion and Sainudiin, 2014)</cite> observes F-Score improvement (F + \u2206F) by applying the iterative approach."
  ],
  "y": "background"
 },
 {
  "id": "5f25b6a3bcaca2e4beb59ce0f3eb5f_3",
  "x": [
   "Secondly, as shown by <cite>Manion and Sainudiin (2014)</cite> with a simple linear regression, the iterative approach increases WSD performance for documents that have a higher degree of document monosemy -the percentage of unique monosemous lemmas in a document."
  ],
  "y": "background"
 },
 {
  "id": "5f25b6a3bcaca2e4beb59ce0f3eb5f_4",
  "x": [
   "Formalised in<cite> (Manion and Sainudiin, 2014)</cite> , this run can act as a baseline to gauge any improvement for Run2 and Run3 that apply the iterative approach."
  ],
  "y": "background"
 },
 {
  "id": "5f2f4087b80aa8dc3a5ccdb686983d_0",
  "x": [
   "For our experiments we use the dataset described in<cite> (DeVault et al., 2011b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "5f2f4087b80aa8dc3a5ccdb686983d_2",
  "x": [
   "This score is .79; see <cite>DeVault et al. (2011b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "5f5a59f8fbf999b9eecfe7c1897b2c_0",
  "x": [
   "These approaches can generally be classified in two categories: models that integrate base parsers at learning time, e.g., using stacking (Nivre and McDonald, 2008; Attardi and Dell'Orletta, 2009) , and approaches that combine independently-trained models only at parsing time (Sagae and Lavie, 2006; <cite>Hall et al., 2007</cite>; Attardi and Dell'Orletta, 2009 )."
  ],
  "y": "background"
 },
 {
  "id": "5f5a59f8fbf999b9eecfe7c1897b2c_1",
  "x": [
   "parser variants are built by varying the parsing algorithm (we used three parsing models: Nivre's arceager (AE), Nivre's arc-standard (AS), and Covington's non-projective model (CN)), and the parsing direction (left to right (\u2192) or right to left (\u2190)), similar to<cite> (Hall et al., 2007)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "5f5a59f8fbf999b9eecfe7c1897b2c_2",
  "x": [
   "The parameters of the Malt models were set to the values reported in<cite> (Hall et al., 2007)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "5f5a59f8fbf999b9eecfe7c1897b2c_3",
  "x": [
   "To guarantee that the resulting dependency tree is well-formed, most previous work used the dynamic programming algorithm of Eisner (1996) for reparsing (Sagae and Lavie, 2006;<cite> Hall et al., 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_0",
  "x": [
   "In addition, we further show that this approach is also beneficial for small sample humor recognition tasks through a semi-supervised label propagation procedure, which achieves about 0.7 accuracy on the 16000 One-Liners (Mihalcea and Strapparava, 2005) and Pun of the Day<cite> (Yang et al., 2015)</cite> humour classification datasets using only 10% of known labels."
  ],
  "y": "motivation"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_1",
  "x": [
   "While early works tend to frame humor recognition as a binary classification task (Mihalcea and Strapparava, 2005; <cite>Yang et al., 2015)</cite> , the last few years have seen the emergence of humor recognition as a pairwise relative ranking task (Cattle and Ma, 2016; Shahaf et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_2",
  "x": [
   "State-of-the-art humor recognition algorithms usually require a considerable amount of training data with labels to learn effective features<cite> (Yang et al., 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_3",
  "x": [
   "In addition, by applying a semi-supervised label propagation procedure (Zhou et al., 2003) , we can also use the tensor embedding method for small sample humor recognition, achieving about 0.7 accuracy with only 10% of known labels on the 16000 One-Liners (Mihalcea and Strapparava, 2005) and Pun of the Day<cite> (Yang et al., 2015)</cite> datasets."
  ],
  "y": "motivation background"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_4",
  "x": [
   "Semantic features range from attempts to measure incongruity (Cattle and Ma, 2018; Shahaf et al., 2015; <cite>Yang et al., 2015)</cite> to the use of word embeddings as inputs to neural models (Bertero and Fung, 2016; Donahue et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_5",
  "x": [
   "Although learning-based methods have shown significant performance improvement recently<cite> (Yang et al., 2015)</cite> , one of their main bottlenecks is the lack of appropriate training corpora.",
   "While previous works have employed data crawled from websites (Mihalcea and Strapparava, 2005; <cite>Yang et al., 2015)</cite> , Twitter (Cattle and Ma, 2016; Reyes et al., 2012) , sitcom subtitles (Bertero and Fung, 2016; Purandare and Litman, 2006) , or the New Yorker Cartoon Caption Contest (Radev et al., 2015; Shahaf et al., 2015) , these datasets are generally not released publicly."
  ],
  "y": "differences"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_6",
  "x": [
   "The objective of tensor decomposition is to find an approximation\u0174 of W so<cite> Yang et al. (2015)</cite> that:\u0174"
  ],
  "y": "background"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_7",
  "x": [
   "To show the effectiveness of label propagation of our tensor embedding method for small sample humor recognition, we conduct an experiment on two humor classification datasets 16000 One-Liners (Mihalcea and Strapparava, 2005) and Pun of the Day<cite> (Yang et al., 2015)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "5fc7df69445712a50228d0bf80f30a_8",
  "x": [
   "Our own implementation of<cite> Yang et al. (2015)</cite> is included as a baseline.",
   "While<cite> Yang et al. (2015)</cite> uses a large portion of data for training and combine different features, we find that at similar portion of training data (90%), the results of our method are comparable to it."
  ],
  "y": "similarities uses"
 },
 {
  "id": "604807137ee5d9a6775821496c6af5_0",
  "x": [
   "This is based on the observations from existing literature (Bhatt et al., 2015;<cite> Blitzer et al., 2007)</cite> which suggest that if the source and target collections are similar, the adaptation performance tends to be better than if the two collections are dissimilar."
  ],
  "y": "uses"
 },
 {
  "id": "604807137ee5d9a6775821496c6af5_1",
  "x": [
   "During generalization, it learns shared common representation<cite> (Blitzer et al., 2007</cite>; Ji et al., 2011; Pan et al., 2010) which minimizes the divergence between two collections."
  ],
  "y": "uses"
 },
 {
  "id": "604807137ee5d9a6775821496c6af5_2",
  "x": [
   "We leverage one of the widely used structural correspondence learning (SCL) approach<cite> (Blitzer et al., 2007)</cite> to compute shared representations."
  ],
  "y": "uses"
 },
 {
  "id": "604807137ee5d9a6775821496c6af5_3",
  "x": [
   "We also evaluated the performance of domain adaptation (DA) module of SODA on the Amazon review dataset<cite> (Blitzer et al., 2007)</cite> which is a benchmark dataset for sentiment categorization."
  ],
  "y": "uses"
 },
 {
  "id": "604807137ee5d9a6775821496c6af5_4",
  "x": [
   "Table 2 shows that DA module of SODA outperforms 1) a widely used domain adaptation technique , namely, structural correspondence learning (SCL)<cite> (Blitzer et al., 2007</cite>; Blitzer et al., 2006) , 2) the baseline (BL) where a classifier trained on one domain is applied on another domain, and 3) the in-domain classifier."
  ],
  "y": "differences"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_0",
  "x": [
   "We extend <cite>our</cite> previous work on constituency parsing <cite>(Kitaev and Klein, 2018)</cite> by incorporating pre-training for ten additional languages, and compare the benefits of no pre-training, ELMo , and BERT (Devlin et al., 2018)."
  ],
  "y": "extends"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_1",
  "x": [
   "In <cite>our</cite> earlier work <cite>(Kitaev and Klein, 2018)</cite> , <cite>we</cite> showed that such representations are helpful for constituency parsing."
  ],
  "y": "background"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_2",
  "x": [
   "However, <cite>these</cite> results only considered the LSTM-based ELMo representations , and only for the English language."
  ],
  "y": "motivation"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_3",
  "x": [
   "We now extend <cite>this</cite> work to show that using only self-attention also works by substituting BERT (Devlin et al., 2018) ."
  ],
  "y": "extends"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_4",
  "x": [
   "Our parser as described in <cite>Kitaev and Klein (2018)</cite> accepts as input a sequence of vectors corresponding to words in a sentence, transforms these repre-1 https://github.com/nikitakit/self-attentive-parser sentations using one or more self-attention layers, and finally uses these representations to output a parse tree."
  ],
  "y": "background"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_5",
  "x": [
   "The extra layers on top of BERT use word-based tokenization instead of sub-words, apply the factored version of self-attention proposed in <cite>Kitaev and Klein (2018)</cite> , and are randomly-initialized instead of being pre-trained."
  ],
  "y": "uses"
 },
 {
  "id": "6092234b23f2620c356c2e417c2ce8_6",
  "x": [
   "All other hyperparameters are unchanged from <cite>Kitaev and Klein (2018)</cite> and Devlin et al. (2018) ."
  ],
  "y": "similarities"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_0",
  "x": [
   "In student papers, identifying revision purposes with respect to argument structure has been used to predict the grade improvement in the paper after revision<cite> (Zhang and Litman, 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_1",
  "x": [
   "Existing works on the analysis of writing revisions (Adler et al., 2011; Bronner and Monz, 2012; Daxenberger and Gurevych, 2013;<cite> Zhang and Litman, 2015)</cite> typically compare two versions of a text to extract revisions, then classify the purpose of each revision in isolation."
  ],
  "y": "background"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_2",
  "x": [
   "There are multiple works on the classification of revisions (Adler et al., 2011; Javanmardi et al., 2011; Bronner and Monz, 2012; Daxenberger and Gurevych, 2013;<cite> Zhang and Litman, 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_3",
  "x": [
   "To label our data, we adapt the schema defined in<cite> (Zhang and Litman, 2015)</cite> as it can be reliably annotated and is argument- (Faigley and Witte, 1981) ."
  ],
  "y": "extends"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_4",
  "x": [
   "As <cite>Zhang and Litman (2015)</cite> reported that both Rebuttals and multiple labels for a single revision were rare, we merge Rebuttal and Warrant into one Warrant category 1 and allow only a single (primary) label per revision."
  ],
  "y": "motivation"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_5",
  "x": [
   "Corpus A was collected in our earlier pa-per<cite> (Zhang and Litman, 2015)</cite> , although the original annotations were modified as described above."
  ],
  "y": "uses"
 },
 {
  "id": "622bd6f16d55ab5853389286cdda56_6",
  "x": [
   "Our previous work<cite> (Zhang and Litman, 2015)</cite> used three types of features primarily from prior work (Adler et al., 2011; Bronner and Monz, 2012; Daxenberger and Gurevych, 2013) for argumentative revision classification."
  ],
  "y": "background"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_0",
  "x": [
   "Recently, the mechanism of self-attention<cite> [22,</cite> 24] was proposed, which uses the whole sequence at once to model feature interactions that are arbitrarily distant in time."
  ],
  "y": "background"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_1",
  "x": [
   "Its use in both encoder-decoder and feedforward contexts has led to faster training and state-of-the-art results in translation (via the Transformer<cite> [22]</cite> ), sentiment analysis [25] , and other tasks."
  ],
  "y": "background"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_2",
  "x": [
   "Our proposed framework ( Figure 1a ) is built around self-attention layers, as used in the Transformer encoder<cite> [22]</cite> , previous explorations of self-attention in ASR [19, 27] , and defined in Section 2.3."
  ],
  "y": "similarities uses"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_3",
  "x": [
   "Maximum path length Table 1 : Operation complexity of each layer type, based on<cite> [22]</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_4",
  "x": [
   "The first sublayer performs multi-head, scaled dot-product, self-attention<cite> [22]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_5",
  "x": [
   "The second sublayer is a position-wise feed-forward network<cite> [22]</cite> FFN(H) = ReLU(HW1 + b1)W2 + b2 where parameters"
  ],
  "y": "background"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_6",
  "x": [
   "Self-attention is inherently content-based<cite> [22]</cite> , and so one often encodes position into the post-embedding vectors."
  ],
  "y": "background"
 },
 {
  "id": "642aa9fe999d0b2b3793cb1603c04c_7",
  "x": [
   "As self-attention architectures can be unstable in early training, we clip gradients to a global norm of 1 and use the standard linear warmup period before inverse square decay associated with these architectures [19, <cite>22]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "653327ecbc925624d509c679fbe0ba_0",
  "x": [
   "Recently, the other line has studied to pre-train a language model over large corpus to learn the inherent word-level knowledge in an unsupervised way<cite> [4,</cite> 8] , which achieves very promising performance."
  ],
  "y": "background"
 },
 {
  "id": "653327ecbc925624d509c679fbe0ba_1",
  "x": [
   "Pre-trained language model such as BERT and GPT<cite> [4,</cite> 8] is also used as a kind of commonsense knowledge source."
  ],
  "y": "background"
 },
 {
  "id": "653327ecbc925624d509c679fbe0ba_2",
  "x": [
   "Here we utilize BERT <cite>[4]</cite> as the pretrained encoder for its superior performance in a range of natural language understanding tasks."
  ],
  "y": "uses"
 },
 {
  "id": "653327ecbc925624d509c679fbe0ba_3",
  "x": [
   "Following <cite>[4]</cite> , we first convert the concept to a set of BPE tokens tokens A and tokens B, with beginning index i and j in the input sequence respectively."
  ],
  "y": "uses"
 },
 {
  "id": "653327ecbc925624d509c679fbe0ba_4",
  "x": [
   "We use the uncased BERT(base) <cite>[4]</cite> as pre-trained language model."
  ],
  "y": "uses"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_0",
  "x": [
   "Recently,<cite> McDonald et al. (2005b)</cite> formalized dependency parsing as a maximum spanning tree (MST) problem, which can be solved in quadratic time relative to the length of the sentence."
  ],
  "y": "background"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_1",
  "x": [
   "We now formalize weighted non-projective dependency parsing similarly to<cite> (McDonald et al., 2005b)</cite> and then describe a modified and more efficient version that can be integrated into a phrasebased decoder."
  ],
  "y": "uses"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_2",
  "x": [
   "Since i and j are both free variables, feature computation in<cite> (McDonald et al., 2005b)</cite> takes time O(n 3 ), even though parsing itself takes O(n 2 ) time."
  ],
  "y": "motivation"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_3",
  "x": [
   "Building upon the theoretical work of (Chu and Liu, 1965; Edmonds, 1967) ,<cite> McDonald et al. (2005b)</cite> present a quadratic-time dependency parsing algorithm that is just 0.7% less accurate than \"full-fledged\" chart parsing (which, in the case of dependency parsing, runs in time O(n 3 ) (Eisner, 1996) )."
  ],
  "y": "background"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_4",
  "x": [
   "Adapting the approach of<cite> McDonald et al. (2005b)</cite> for machine translation, we incrementally build dependency structure left-toright in time O(n 2 ) during decoding."
  ],
  "y": "extends"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_5",
  "x": [
   "In this section, we review dependency parsing formulated as a maximum spanning tree problem<cite> (McDonald et al., 2005b)</cite> , which can be solved in quadratic time, and then present its adaptation and novel application to phrase-based decoding."
  ],
  "y": "background"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_6",
  "x": [
   "While it seems difficult to improve the asymptotic running time of the Eisner algorithm beyond what is presented in (Eisner and Satta, 1999) ,<cite> McDonald et al. (2005b)</cite> show O(n 2 )-time parsing is possible if trees are not required to be projective."
  ],
  "y": "background"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_7",
  "x": [
   "That is not the case: dependency accuracy for nonprojective parsing is 90.2% for English<cite> (McDonald et al., 2005b)</cite> , only 0.7% lower than a projective parser (McDonald et al., 2005a ) that uses the same set of features and learning algorithm."
  ],
  "y": "background"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_8",
  "x": [
   "In the case of dependency parsing for Czech,<cite> (McDonald et al., 2005b)</cite> even outperforms projective parsing, and was one of the top systems in the CoNLL-06 shared task in multilingual dependency parsing."
  ],
  "y": "background"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_9",
  "x": [
   "The O(n 3 ) non-projective parser of <cite>(McDonald et al., 2005b</cite> ) is slightly more accurate than our version, though ours runs in O(n 2 ) time. \"Local classifier\" refers to non-projective dependency parsing without removing loops as a post-processing step."
  ],
  "y": "differences"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_10",
  "x": [
   "Table 4 shows that the accuracy of our truly O(n 2 ) parser is only .25% to .34% worse than the O(n 3 ) implementation of<cite> (McDonald et al., 2005b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_11",
  "x": [
   "The training data consists of about 28 million English words and 23.3 million 5 Note that our results on WSJ are not exactly the same as those reported in <cite>(McDonald et al., 2005b</cite> ), since we used slightly different head finding rules."
  ],
  "y": "differences"
 },
 {
  "id": "6580dc2f7316cea4e0933ff515a704_12",
  "x": [
   "In this paper, we presented a non-projective dependency parser whose time-complexity of O(n 2 ) improves upon the cubic time implementation of<cite> (McDonald et al., 2005b)</cite> , and does so with little loss in dependency accuracy (.25% to .34%)."
  ],
  "y": "uses"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_0",
  "x": [
   "This paper investigates the task of noun compound interpretation, building on the sense collocation approach proposed by <cite>Moldovan et al. (2004)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_1",
  "x": [
   "It has been shown that NCs with semantically similar compo-nents share the same SR ; this is encapsulated by the phrase coined as sense collocation in <cite>Moldovan et al. (2004)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_2",
  "x": [
   "A majority of research undertaken in interpreting NCs have been based on two statistical methods: SEMANTIC SIMILARITY (Barker and Szpakowicz, 1998; Rosario, 2001;<cite> Moldovan et al., 2004</cite>; Kim and Baldwin, 2005; Nastase, 2006; Girju, 2007; and SEMANTIC INTER-PRETABILITY (Vanderwende, 1994; Lapata, 2002; Kim and Baldwin, 2006; Nakov, 2006) ."
  ],
  "y": "background"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_3",
  "x": [
   "A majority of research undertaken in interpreting NCs have been based on two statistical methods: SEMANTIC SIMILARITY (Barker and Szpakowicz, 1998; Rosario, 2001;<cite> Moldovan et al., 2004</cite>; Kim and Baldwin, 2005; Nastase, 2006; Girju, 2007; and SEMANTIC INTER-PRETABILITY (Vanderwende, 1994; Lapata, 2002; Kim and Baldwin, 2006; Nakov, 2006) ."
  ],
  "y": "uses"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_4",
  "x": [
   "A significant contribution to this area is by <cite>Moldovan et al. (2004)</cite> , who used the sense collocation (i.e. pair-of-word-senses) as their primary feature in disambiguating NCs."
  ],
  "y": "background"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_5",
  "x": [
   "As mentioned above, <cite>Moldovan et al. (2004)</cite> showed that the sense collocation of NCs is a key feature when interpreting NCs."
  ],
  "y": "background"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_6",
  "x": [
   "The original method described in <cite>Moldovan et al. (2004)</cite> only relies on observed sense collocations."
  ],
  "y": "motivation"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_7",
  "x": [
   "At first, we describe the principal idea of sense collocation method on NC interpretation and the probability model proposed in<cite> (Moldovan et al., 2004)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_8",
  "x": [
   "The basic idea behind sense collocation method in <cite>Moldovan et al. (2004)</cite> was based on the \"pair-ofword-senses\" from the component nouns in noun compounds as features of the classifier."
  ],
  "y": "background"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_9",
  "x": [
   "We extend the approach of <cite>Moldovan et al. (2004)</cite> by adding similar words as features focusing on hypernyms, hyponyms and sister words of the modifier and head noun."
  ],
  "y": "extends"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_10",
  "x": [
   "2 The performance of the original method proposed in <cite>Moldovan et al. (2004)</cite> is considered as a benchmark."
  ],
  "y": "uses"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_12",
  "x": [
   "2 The performance of the original method proposed in <cite>Moldovan et al. (2004)</cite> is considered as a benchmark.",
   ".217 .496 .544 .552 .573 .562 .588 .568 .557 .197 .142 .547 .547 533 .573 .600 .606 .586 .607 .630 .467 .453 IA .507 .581 .595 .608 .649 .671 .653 .629 .645 .500 .500 PP .655 .667 .679 .691 .679 .737 .700 .690 .687 .655 .655 OE .558 .636 .623 .610 .662 .645 .662 .625 .712 .558 .558 TT .636 .697 .727 .712 .742 .766 .732 .717 .650 .515 .394 PW .634 .620 .690 .690 .629 .657 .585 .731 .630 .633 .634 CC .514 .676 .703 .689 .689 .676 .667 .647 .698 .446 .514 All .579 .632 .649 .653 .662 .679 .654 .661 .667 .541 .534 Table 4 : Results for each of the 2-way classification tasks: B = baseline, M+ = <cite>Moldovan et al. (2004)</cite> method, H i = ith-order Hypernym, O = Hyponym and S = Sister word; the best performing system is indicated in boldface and that of extended sense collocation as proposed in this paper."
  ],
  "y": "uses"
 },
 {
  "id": "66392c3b6fa3744de79f056f615a75_13",
  "x": [
   "In the automatic interpretation of NCs, many claims have been made for the increase in performance, but these works make their own assumptions for interpretation (Barker and Szpakowicz, 1998;<cite> Moldovan et al., 2004</cite>; Kim and Baldwin, 2005; Girju, 2007; Seaghdha, 2007) ."
  ],
  "y": "background"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_0",
  "x": [
   "Unlike the previous study<cite> (Kogan et al., 2009)</cite> , in which a regression model is employed to predict stock return volatilities via text information, our work utilizes learning-to-rank methods to model the ranking of relative risk levels directly."
  ],
  "y": "differences"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_1",
  "x": [
   "The difficulty of predicting the values is partially because of the huge amount of noise within texts<cite> (Kogan et al., 2009</cite> ) and partially because of the weak connection between texts and the quantities."
  ],
  "y": "background"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_2",
  "x": [
   "In addition to the improvements, through the learned ranking models, we also discover meaningful words that are financially risk-related, some of which were not identified in<cite> (Kogan et al., 2009</cite> )."
  ],
  "y": "differences"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_3",
  "x": [
   "In recent year, there have been some studies conducted on mining financial reports, such as (Lin et al., 2008; <cite>Kogan et al., 2009</cite>; Leidner and Schilder, 2010) ."
  ],
  "y": "background"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_4",
  "x": [
   "The distribution over ln(v) across companies tends to have a bell shape<cite> (Kogan et al., 2009)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_5",
  "x": [
   "In this paper, the 10-K Corpus<cite> (Kogan et al., 2009</cite> ) is used to conduct the experiments; only Section 7 \"management's discussion and analysis of financial conditions and results of operations\" (MD&A) is included in the experiments since typically Section 7 contains the most important forward-looking statements."
  ],
  "y": "similarities"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_6",
  "x": [
   "For regression, linear kernel is adopted with \u03b5 = 0.1 and the trade-off C is set to the default choice of SVM light , which are the similar settings of<cite> (Kogan et al., 2009</cite> )."
  ],
  "y": "similarities"
 },
 {
  "id": "6678c19792be8d9ad66cf923d00c23_7",
  "x": [
   "Almost all the terms found by our ranking approach are financially meaningful; in addition, some of highly risk-correlated terms are not even reported in<cite> (Kogan et al., 2009)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_0",
  "x": [
   "Our method is based on the method described in (<cite>Hoshino et al., 2013</cite>) , and extends <cite>their</cite> rules to handle abbreviation and passivization frequently found in scientific papers."
  ],
  "y": "uses extends"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_1",
  "x": [
   "Experimental results show that our proposed method improves performance of both (<cite>Hoshino et al., 2013</cite>) 's system and our phrase-based SMT baseline without preordering."
  ],
  "y": "differences"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_2",
  "x": [
   "Specifically, previous work in the literature uses morphological analysis (Katz-Brown and Collins, 2008) , dependency structure (Katz-Brown and Collins, 2008) and predicate-argument structure (Komachi et al., 2006; <cite>Hoshino et al., 2013</cite>) for preordering in Japanese-English statistical machine translation."
  ],
  "y": "background"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_3",
  "x": [
   "However, these preordering methods are tested on limited domains: travel (Komachi et al., 2006) and patent (Katz-Brown and Collins, 2008; <cite>Hoshino et al., 2013</cite>) corpora."
  ],
  "y": "motivation"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_4",
  "x": [
   "Following (<cite>Hoshino et al., 2013</cite>) , we perform predicate-argument structure analysis on the Japanese side to preorder Japanese sentences to form an SVO-like word order."
  ],
  "y": "uses"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_5",
  "x": [
   "\u2022 We propose an extension to (<cite>Hoshino et al., 2013</cite>) in order to deal with abbreviation and passivization frequently found in scientific papers."
  ],
  "y": "extends motivation"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_6",
  "x": [
   "Third, <cite>Hoshino et al. (2013)</cite> proposed predicate-argument structure-based preordering rules in two-level for the Japanese-English patent translation task."
  ],
  "y": "background"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_7",
  "x": [
   "Since <cite>this method</cite> is the one we re-implemented in this paper, we will describe <cite>their method</cite> in detail below."
  ],
  "y": "uses"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_8",
  "x": [
   "3 Extension to (<cite>Hoshino et al., 2013</cite>) Our proposed preordering model is based on (<cite>Hoshino et al., 2013</cite>) with three extensions to better handle academic writing in scientific papers."
  ],
  "y": "uses extends"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_9",
  "x": [
   "<cite>Hoshino et al. (2013)</cite> proposed to move a predicate after the subject (inter-chunk preordering)."
  ],
  "y": "background"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_10",
  "x": [
   "\u2022 preordered data by our re-implementation of (<cite>Hoshino et al., 2013</cite>) , and"
  ],
  "y": "uses"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_11",
  "x": [
   "Also, following (<cite>Hoshino et al., 2013</cite>) , we did not consider event nouns as predicates."
  ],
  "y": "uses"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_12",
  "x": [
   "In terms of BLEU, our re-implementation of (<cite>Hoshino et al., 2013</cite>) is below the baseline method while our proposed methods better than the baseline."
  ],
  "y": "differences"
 },
 {
  "id": "668e8967d702d4538c85935de083f7_13",
  "x": [
   "All the preordering models using (<cite>Hoshino et al., 2013</cite>) are our re-implementation of their paper."
  ],
  "y": "uses"
 },
 {
  "id": "66b6283cf1f20977286f99ef21b3c7_0",
  "x": [
   "My own slow progress (Cassell et al., 2000; <cite>Koller and Stone, 2007)</cite> shows that there's still lots of hard work needed to develop suitable techniques."
  ],
  "y": "motivation future_work"
 },
 {
  "id": "672d4299e60752e866293d72f97905_0",
  "x": [
   "Psycholinguistic properties have been used in various approaches, such as for Lexical Simplification<cite> [12]</cite> , for Text Simplification at the sentence level, with the aim of reducing the difficulty of informative text for language learners [18] , to predict the reading times (RTs) of each word in a sentence to assess sentence complexity [14] and also to create robust text level readability models [17] , which is also one of the purposes of this paper."
  ],
  "y": "background"
 },
 {
  "id": "672d4299e60752e866293d72f97905_1",
  "x": [
   "As for the automatic inference, this work is strongly based on the results of<cite> [12]</cite> which proposed an automatic bootstrapping method for regression to populate the MRC Database."
  ],
  "y": "similarities"
 },
 {
  "id": "672d4299e60752e866293d72f97905_2",
  "x": [
   "To the best of our knowledge there are only two studies that propose regression methods to automatically estimate missing psycholinguistic properties in the MRC Database [4, <cite>12]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "672d4299e60752e866293d72f97905_3",
  "x": [
   "[<cite>12]</cite> automatically estimate missing psycholinguistic properties in the MRC Database through a bootstrapping algorithm for regression."
  ],
  "y": "background"
 },
 {
  "id": "672d4299e60752e866293d72f97905_4",
  "x": [
   "The fact that the methods developed by [4] and<cite> [12]</cite> are based on a large, scarce lexical resources as WordNet, led us to raise the question \"Could we have a similar performance with a simpler set of features which are easily obtainable for most languages?\"."
  ],
  "y": "motivation background"
 },
 {
  "id": "672d4299e60752e866293d72f97905_5",
  "x": [
   "One critical difference between the strategy of<cite> [12]</cite> and ours is that they concatenate all features to train a regressor, while we take a different approach."
  ],
  "y": "differences motivation"
 },
 {
  "id": "672d4299e60752e866293d72f97905_6",
  "x": [
   "We choose this regression method due to the promising results reported by<cite> [12]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "6869f08e826aa434471c51c010ef28_0",
  "x": [
   "In a more recent attempt <cite>[19]</cite> , we further proposed a framework of discovering multi-level acoustic patterns with varying model granularity."
  ],
  "y": "background"
 },
 {
  "id": "6869f08e826aa434471c51c010ef28_1",
  "x": [
   "Note that in our previous work <cite>[19]</cite> , the effect of the third dimension, the acoustic granularity which is the number of Gaussians in each state, was shown to be negligible, thus here we simply set the number of Gaussians in each state to be 4 in all cases."
  ],
  "y": "background"
 },
 {
  "id": "6869f08e826aa434471c51c010ef28_2",
  "x": [
   "In this section we summarize the way to perform spoken term detection <cite>[19]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "6869f08e826aa434471c51c010ef28_4",
  "x": [
   "However, previous experiments showed that the extra improvements brought in this way is almost negligible, probably because here we have jointly considered the M \u00d7 N different pattern sequences based on the M \u00d7 N different pattern sets (e.g. including longer /shorter patterns), so the different time-warped matching and insertion/deletion between d and q is already automatically included <cite>[19]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "6a693f9cbc6dbb3676d765eee97db7_0",
  "x": [
   "Over the past decade, there has been tremendous progress on learning parsing models from treebank data (Magerman, 1995; Collins, 1999; Charniak, 1997; Ratnaparkhi, 1999; Charniak, 2000;<cite> Wang et al., 2005</cite>; McDonald et al., 2005) ."
  ],
  "y": "background"
 },
 {
  "id": "6a693f9cbc6dbb3676d765eee97db7_1",
  "x": [
   "For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997;<cite> Wang et al., 2005)</cite> , and yet they are not being used in current large margin training algorithms."
  ],
  "y": "background"
 },
 {
  "id": "6a693f9cbc6dbb3676d765eee97db7_2",
  "x": [
   "For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997;<cite> Wang et al., 2005)</cite> , and yet they are not being used in current large margin training algorithms."
  ],
  "y": "motivation background"
 },
 {
  "id": "6a693f9cbc6dbb3676d765eee97db7_3",
  "x": [
   "This formulation is sufficiently general to capture most dependency parsing models, including probabilistic dependency models<cite> (Wang et al., 2005</cite>; Eisner, 1996) as well as non-probabilistic models (McDonald et al., 2005; Wang et al., 2006) ."
  ],
  "y": "uses"
 },
 {
  "id": "6a693f9cbc6dbb3676d765eee97db7_4",
  "x": [
   "To learn an accurate dependency parser from data, the first approach I investigated is based on a strictly lexical parsing model where all the parameters are based on words<cite> (Wang et al., 2005)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "6da7dcbcb7f52f31ec23c8131d438d_0",
  "x": [
   "Recently, pretrained language representations with self-supervised objectives (Peters et al., 2018; <cite>Devlin et al., 2018</cite>; Radford et al., 2018) have further pushed forward the state-of-the-art on many English tasks."
  ],
  "y": "background"
 },
 {
  "id": "6da7dcbcb7f52f31ec23c8131d438d_1",
  "x": [
   "This is facilitated by recent advances in learning joint multilingual representations (Lample and Conneau, 2019; Artetxe and Schwenk, 2018;<cite> Devlin et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "6da7dcbcb7f52f31ec23c8131d438d_2",
  "x": [
   "In our work, we propose a self-learning framework to incorporate the predictions of the multilingual BERT model<cite> (Devlin et al., 2018)</cite> on non-English data into an English training procedure."
  ],
  "y": "extends"
 },
 {
  "id": "6da7dcbcb7f52f31ec23c8131d438d_3",
  "x": [
   "For the encoder, we invoke the multilingual BERT model<cite> (Devlin et al., 2018)</cite> , which supports 104 languages 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "6da7dcbcb7f52f31ec23c8131d438d_4",
  "x": [
   "With models such as ELMo (Peters et al., 2018) , GPT-2 (Radford et al., 2018) , and BERT<cite> (Devlin et al., 2018)</cite> , important progress has been made in learning improved sentence representations with context-specific encodings of words via a language modeling objective."
  ],
  "y": "background"
 },
 {
  "id": "6da7dcbcb7f52f31ec23c8131d438d_5",
  "x": [],
  "y": "background"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_0",
  "x": [
   "In this work, we focus on Arabic DID which can can be posed as a five class classification problem, given that the Arabic language can be divided into five major dialects; Egyptian (EGY), Gulf (GLF), Lavantine (LAV), Modern Standard Arabic (MSA) and North African (NOR) <cite>[2]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_1",
  "x": [
   "One of the most successful acoustic approaches is, the use of i-Vector framework for LID, where i-Vectors are extracted for each speech utterance, using an i-Vector extractor that consists of a GMM-UBM trained on top of BNF, followed by a Total Variability Subspace Model<cite> [2,</cite> 11] ."
  ],
  "y": "differences extends"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_2",
  "x": [
   "This model combination approach has been shown to give performace improvements on the DID task <cite>[2]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_3",
  "x": [
   "Details about the phone recognizer can be found in <cite>[2]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_4",
  "x": [
   "We use the same Deep Neural Network (DNN) based ASR system to extract the BNF as in our previous works<cite> [2,</cite> 13] ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_5",
  "x": [
   "In this work, GMM-UBM model has 2048 gaussian components, MFCC features are extracted using a 25 ms window and the i-Vectors are 400 dimensional <cite>[2]</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_6",
  "x": [
   "This method has been shown to improve DID (LID) performance<cite> [2,</cite> 11] ."
  ],
  "y": "background"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_7",
  "x": [
   "Training and test data used in this work is the same as used in <cite>[2]</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "6e92b1fa4f3b78a099cb222b3eb9a9_8",
  "x": [
   "More details about the train and test data can be found in<cite> [2,</cite> 18] ."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_0",
  "x": [
   "Abstract denotation is proposed to capture the meaning of this abstract version of DCS tree, and a textual inference system based on abstract denotation is built (<cite>Tian et al., 2014</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_1",
  "x": [
   "To elaborate the above discussion and to provide more topics to the literature, in this paper we discuss the following four questions: ( \u00a72) How well can tree transformation approximate logical inference? ( \u00a73) With rigorous inference on DCS trees, where does logic contribute in the system of <cite>Tian et al. (2014)</cite> In the tree transformation based approach to RTE, it has been realized that some gaps between T and H cannot be filled even by a large number of tree transformation rules extracted from corpus (BarHaim et al., 2007a) ."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_2",
  "x": [
   "3 Alignment with logical clues <cite>Tian et al. (2014)</cite> proposed a way to generate onthe-fly knowledge to fill knowledge gaps: if H is not proven, compare DCS trees of T and H to generate path alignments (e.g. blamed for death \u223c cause loss of life, as underscored in Figure 1) ; evaluate the path alignments by a similarity score function; and path alignments with a score greater than a threshold (0.4) are accepted and converted to inference rules."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_3",
  "x": [
   "The word vectors <cite>Tian et al. (2014)</cite> use to calculate similarities are reported able to capture semantic compositions by simple additions and subtractions (Mikolov et al., 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_4",
  "x": [
   "<cite>Tian et al. (2014)</cite> used some logical clues to filter out irrelevant path alignments, which helps to keep a high precision."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_5",
  "x": [
   "Logical inference is shown to be useful for RTE, as <cite>Tian et al. (2014)</cite> demonstrates a system with competitive results."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_6",
  "x": [
   "However, despite the expectation that all entailment matters can be explained logically, our observation is that currently logical inference only fills very limited short gaps from T to H. The logical phenomena easily addressed by <cite>Tian et al. (2014)</cite> Table 2 : Proportion (%) of exit status of Prover9"
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_7",
  "x": [
   "The system of <cite>Tian et al. (2014)</cite> generated onthe-fly knowledge to join several fragments in T and wrongly proved H. In examples of such complexity, distributional similarity is no longer reliable."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_8",
  "x": [
   "We plot the running time of <cite>Tian et al. (2014)</cite> 's inference engine (single-threaded) on a 2.27GHz Xeon CPU, with respect to the weighted sum of all statements 2 , as shown in Figure 3 ."
  ],
  "y": "uses"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_9",
  "x": [
   "As such, we use <cite>Tian et al. (2014)</cite> 's inference engine to pin down statements that are actually needed for proving H (usually just 2 or 3 statements), and try to prove H by Prover9 again, using only necessary statements."
  ],
  "y": "uses"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_10",
  "x": [
   "Improvement of similarity score To calculate phrase similarities, <cite>Tian et al. (2014)</cite> use the cosine similarity of sums of word vectors, which ignores syntactic information."
  ],
  "y": "background"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_11",
  "x": [
   "Improvement of similarity score To calculate phrase similarities, <cite>Tian et al. (2014)</cite> use the cosine similarity of sums of word vectors, which ignores syntactic information."
  ],
  "y": "extends"
 },
 {
  "id": "6ed955baf28ad1c7fd6d590e660c20_12",
  "x": [
   "We plot the running time of <cite>Tian et al. (2014)</cite> 's inference engine (single-threaded) on a 2.27GHz Xeon CPU, with respect to the weighted sum of all statements 2 , as shown in Figure 3 ."
  ],
  "y": "similarities"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_0",
  "x": [
   "Bidirectional Encoder Representations from Transformers (BERT;<cite> Devlin et al., 2018)</cite> represents one of the latest developments in this line of work."
  ],
  "y": "background"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_1",
  "x": [
   "Bidirectional Encoder Representations from Transformers (BERT;<cite> Devlin et al., 2018)</cite> currently represents state of the art, vastly outperforming previous models, such as the Generative Pretrained Transformer (GPT; Radford et al.) and Embeddings from Language Models (ELMo; Peters et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_2",
  "x": [
   "We begin with the pre-trained BERT base and BERT large models, which respectively represent the normal and large model variants <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_3",
  "x": [
   "We begin with the pre-trained BERT base and BERT large models, which respectively represent the normal and large model variants <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_4",
  "x": [
   "As is the case with<cite> Devlin et al. (2018)</cite> , we find that choosing a batch size of 16, learning rate of 2\u00d710 \u22125 , and MSL of 512 tokens yields optimal performance on the validation sets of all datasets."
  ],
  "y": "similarities"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_5",
  "x": [
   "Originally,<cite> Devlin et al. (2018)</cite> find that fine-tuning for three or four epochs works well for both small and large datasets alike."
  ],
  "y": "background"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_6",
  "x": [
   "Originally,<cite> Devlin et al. (2018)</cite> find that fine-tuning for three or four epochs works well for both small and large datasets alike."
  ],
  "y": "motivation"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_7",
  "x": [
   "Trending with<cite> Devlin et al. (2018)</cite> , BERT large achieves state-of-the-art results on all four datasets, followed by BERT base (see Table 2 , rows 11 and 12)."
  ],
  "y": "similarities background"
 },
 {
  "id": "70d41cad40091bcc30a1fd544c277d_8",
  "x": [
   "Contrary to<cite> Devlin et al. (2018)</cite> , who achieve state of the art on small datasets with only a few epochs of fine-tuning, we find that smaller datasets require many more epochs to converge."
  ],
  "y": "differences"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_0",
  "x": [
   "The dataset for the shared task was introduced by <cite>Thorne et al. (2018)</cite> and consists of 185,445 claims."
  ],
  "y": "background"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_1",
  "x": [
   "Table 1 : Examples of claims, the extracted evidence from Wikipedia and the verdicts from the shared task dataset<cite> (Thorne et al., 2018)</cite> The baseline system described by <cite>Thorne et al. (2018)</cite> uses 3 major components:"
  ],
  "y": "background"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_2",
  "x": [
   "<cite>Thorne et al. (2018)</cite> used the document retrieval component from the DrQA system (Chen et al., 2017) , which returns the k nearest documents for a query using cosine similarity between binned unigram and bigram TF-IDF vectors."
  ],
  "y": "background"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_3",
  "x": [
   "<cite>Thorne et al. (2018)</cite> used a modified document retrieval component of DrQA (Chen et al., 2017) to select the top most similar sentences w.r.t the claim, using bigram TF-IDF with binning."
  ],
  "y": "background"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_4",
  "x": [
   "<cite>Thorne et al. (2018)</cite> used the decomposable attention model (Parikh et al., 2016) for this task."
  ],
  "y": "background"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_5",
  "x": [
   "We see that our best approach (combined) achieved a high coverage 94.4% compared to the baseline<cite> (Thorne et al., 2018)</cite> of 55.3%."
  ],
  "y": "differences"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_6",
  "x": [
   "For sentence selection, we used the modified document retrieval component of DrQA (Chen et al., 2017) to select sentences using bigram TF-IDF with binning as proposed by<cite> (Thorne et al., 2018)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_7",
  "x": [
   "Our evidence recall is 78.4 as compared to 45.05 in the development set of FEVER<cite> (Thorne et al., 2018)</cite> , which demonstrates the importance of document retrieval in fact extraction and verification."
  ],
  "y": "differences"
 },
 {
  "id": "70dc108166d6b5fb9da39c451c3229_8",
  "x": [
   "Unlike <cite>Thorne et al. (2018)</cite> , we did not concatenate evidences, but trained our model for each claim-evidence pair."
  ],
  "y": "differences"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_0",
  "x": [
   "In addition to reducing search errors compared to greedy search, it also enables the use of global models that accommodate richer non-local features without overfitting, leading to recent state-of-the-art accuracies of transition-based dependency parsing<cite> (Zhang and Nivre, 2011</cite>; Bohnet and Kuhn, 2012; Bohnet and Nivre, 2012) that are competitive with the best graph-based dependency parsers."
  ],
  "y": "background"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_1",
  "x": [
   "For another example, it would be interesting to know whether a local, greedy, transition-based parser can be equipped with the rich features of<cite> Zhang and Nivre (2011)</cite> to improve its accuracy, and in particular whether MaltParser (Nivre et al., 2006) can achieve the same level of accuracies as ZPar<cite> (Zhang and Nivre, 2011)</cite> by using the same range of rich feature definitions."
  ],
  "y": "motivation"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_2",
  "x": [
   "Second, we show that the accuracies of a local, greedy transition-based parser cannot be improved by adding the rich features of<cite> Zhang and Nivre (2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_3",
  "x": [
   "We present empirical studies of the error distribution of global, beam-search transition-based dependency parsing, using ZPar<cite> (Zhang and Nivre, 2011)</cite> as a representative system."
  ],
  "y": "uses"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_4",
  "x": [
   "Global learning is implemented in the same way as<cite> Zhang and Nivre (2011)</cite> , using the averaged perceptron algorithm (Collins, 2002) and early update (Collins and Roark, 2004) ."
  ],
  "y": "uses"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_5",
  "x": [
   "Figure 1 shows the UAS of ZPar under different settings, where 'global' refers to a global model trained using the same method as<cite> Zhang and Nivre (2011)</cite> , 'local' refers to a local classifier trained using the averaged perceptron, 'base features' refers to the set of base feature templates in<cite> Zhang and Nivre (2011)</cite> , and 'all features' refers to the set of base and all extended feature templates in<cite> Zhang and Nivre (2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "730738d63cabcd4e63ec4300a8091b_6",
  "x": [
   "For further evidence, we add rich non-local features in the same increments as<cite> Zhang and Nivre (2011)</cite> to both ZPar and MaltParser, and evaluate UAS on the same development data set."
  ],
  "y": "uses"
 },
 {
  "id": "7404a4e4e23eea9663b580f9959689_0",
  "x": [
   "The edit operations include: (M)atching an element in S with an element in T; (I)nserting an element into T, and (D)eleting an element in S. 1 The generation task is part of the NEWS 2009 machine transliteration shared task<cite> (Li et al., 2009)</cite> Based on all representative symbols used for each of the two languages, emission costs for each of the edit operations and transition parameters can be estimated and used in measuring the similarity between two strings."
  ],
  "y": "background uses"
 },
 {
  "id": "7404a4e4e23eea9663b580f9959689_1",
  "x": [
   "The data used is divided according to the experimental runs that were specified for the NEWS 2009 shared transliteration task<cite> (Li et al., 2009</cite> ): a standard run and non-standard runs."
  ],
  "y": "uses"
 },
 {
  "id": "7404a4e4e23eea9663b580f9959689_3",
  "x": [
   "These include<cite> (Li et al., 2009)</cite> : Accuracy (ACC), Fuzziness in Top-1 (Mean F Score), Mean Reciprocal Rank (MRR), Mean Average Precision for reference transliterations (MAP_R), Mean Average Precision in 10 best candidate transliterations (MAP_10), Mean Average Precision for the system (MAP_sys)."
  ],
  "y": "uses"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_0",
  "x": [
   "To train these fully data driven models, large-scale datasets for both English and Chinese were recently introduced<cite> (Wang et al., 2017</cite>; Koncel-Kedziorski et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_1",
  "x": [
   "In response to the success of representation learning elsewhere in NLP, sequence to sequence (seq2seq) models have been applied to algebra problem solving<cite> (Wang et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_2",
  "x": [
   "In this paper, we thoroughly examine datadriven techniques on three larger algebra word problem datasets (Huang et al., 2016; Koncel-Kedziorski et al., 2016;<cite> Wang et al., 2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_3",
  "x": [
   "Following <cite>Wang et al. (2017)</cite> , we use Jaccard distance in this model."
  ],
  "y": "uses"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_4",
  "x": [
   "Following <cite>Wang et al. (2017)</cite> we evaluate a seq2seq with LSTMs as the encoder and decoder."
  ],
  "y": "uses"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_5",
  "x": [
   "Datasets For comparison, we report solution accuracy on the Chinese language Math23K dataset<cite> (Wang et al., 2017)</cite> , and the English language DRAW (Upadhyay and Chang, 2015) and MAWPS (Koncel-Kedziorski et al., 2016) datasets."
  ],
  "y": "uses"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_6",
  "x": [
   "To prune these quantities, we implement a significant number identifier (SNI) as discussed in <cite>Wang et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_7",
  "x": [
   "The state of the art for Math23K, described in <cite>Wang et al. (2017)</cite> , uses a hybrid Jaccard retrieval and seq2seq model."
  ],
  "y": "background"
 },
 {
  "id": "742d9ca22bf801b0ade5fd1671473c_8",
  "x": [
   "More recently, <cite>Wang et al. (2017)</cite> provide a large dataset of Chinese algebra word problems and learn a hybrid model consisting of both retrieval and seq2seq components."
  ],
  "y": "extends"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_0",
  "x": [
   "Over a decade of research has considered conversation disentanglement (Shen et al., 2006) , but using datasets that are either small (2,500 messages,<cite> Elsner and Charniak, 2008)</cite> or not released (Adams and Martell, 2008) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_1",
  "x": [
   "3 Related Work IRC Disentanglement Data: The most significant work on conversation disentanglement is a line of papers developing data and models for the #Linux IRC channel<cite> (Elsner and Charniak, 2008</cite>; Elsner and Schudy, 2009; Charniak, 2010, 2011) ."
  ],
  "y": "background"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_2",
  "x": [
   "3 Related Work IRC Disentanglement Data: The most significant work on conversation disentanglement is a line of papers developing data and models for the #Linux IRC channel<cite> (Elsner and Charniak, 2008</cite>; Elsner and Schudy, 2009; Charniak, 2010, 2011) ."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_3",
  "x": [
   "Models: <cite>Elsner and Charniak (2008)</cite> explored various message-pair feature sets and linear classifiers, combined with local and global inference methods."
  ],
  "y": "background"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_4",
  "x": [
   "Models: <cite>Elsner and Charniak (2008)</cite> explored various message-pair feature sets and linear classifiers, combined with local and global inference methods."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_5",
  "x": [
   "4 Annotating the #Linux data enables comparison with <cite>Elsner and Charniak (2008)</cite> , while the #Ubuntu channel has over 34 million messages, making it an interesting largescale resource for dialogue research."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_6",
  "x": [
   "In Channel Two, we also see mistakes and ambiguous cases, including a particularly long discussion about a user's financial difficulties that could be divided in multiple ways (also noted by <cite>Elsner and Charniak (2008)</cite> )."
  ],
  "y": "similarities"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_9",
  "x": [
   "(2) One-to-One Overlap (1-1,<cite> Elsner and Charniak, 2008)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_10",
  "x": [
   "Second, <cite>Elsner and Charniak (2008)</cite> and Lowe et al. (2017) per-form similarly, with one doing better on VI and the other on 1-1, though <cite>Elsner and Charniak (2008)</cite> do consistently better across the exact conversation extraction metrics."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_11",
  "x": [
   "Decreasing the data size to match <cite>Elsner and Charniak (2008)</cite> 's training set leads to worse results, both if the sentences are from diverse contexts (3rd row), and if they are from just two contexts (bottom row)."
  ],
  "y": "differences uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_12",
  "x": [
   "For channel Two, we consider two annotations of the same underlying text: ours and <cite>Elsner and Charniak (2008)</cite>'s."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_13",
  "x": [
   "We do not evaluate on graphs because <cite>Elsner and Charniak (2008)</cite> 's annotations do not include them."
  ],
  "y": "uses"
 },
 {
  "id": "74623c8d812e3c84e7bc6b46e982f5_14",
  "x": [
   "How far apart consecutive messages in a conversation are: <cite>Elsner and Charniak (2008)</cite> and Mehri and Carenini (2017) use a limit of 129 seconds, Jiang et al. (2018) limit to within 1 hour, Guo et al. (2017) limit to within 8 messages, and we limit to within 100 messages."
  ],
  "y": "differences"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_0",
  "x": [
   "Previous experiments with tasks like language modelling<cite> [Bengio et al., 2009]</cite> , Dependency Parsing, and entailment <cite>[Hashimoto et al., 2016]</cite> have shown faster convergence and performance gains by following a curriculum training regimen in the order of increasingly complicated syntactic and semantic tasks."
  ],
  "y": "background"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_1",
  "x": [
   "<cite>[Hashimoto et al., 2016]</cite> propose a hierarchical multitask neural architecture with the lower layers performing syntactic tasks, and the higher layers performing the more involved semantic tasks while using the lower layer predictions."
  ],
  "y": "background"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_2",
  "x": [
   "Like <cite>[Hashimoto et al., 2016]</cite> , they hypothesize the incorporation of simpler syntactic information into semantic tasks, and provide empirical evidence for the same."
  ],
  "y": "background"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_3",
  "x": [
   "Curriculum learning can be seen as a sequence of training criteria<cite> [Bengio et al., 2009]</cite> , with increasing task or sample difficulty as the training progresses."
  ],
  "y": "motivation background"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_4",
  "x": [
   "In addition to the above tasks, Language Model pretraining has shown significant performance gains as reported by<cite> [Howard and Ruder, 2018]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_5",
  "x": [
   "As noted in earlier efforts<cite> [Howard and Ruder, 2018</cite> ] towards finetuning pretrained models for NLP tasks, aggressive finetuning can cause catastrophic forgetting, thus causing the model to simply fit over the target task and forget any capabilities gained during the pretraining stage."
  ],
  "y": "motivation background"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_6",
  "x": [
   "Gradual Unfreezing: Similar to<cite> [Howard and Ruder, 2018]</cite> , rather than updating all the layers together for finetuning, we explore gradual ordered unfreezing of layers."
  ],
  "y": "similarities uses"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_7",
  "x": [
   "With this purview, similar to<cite> [Howard and Ruder, 2018]</cite> , we propose optimizing different layers in our model to different extents, and keep lower step sizes for the deeper pretrained layers while finetuning on a downstream task."
  ],
  "y": "similarities uses"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_8",
  "x": [
   "We experiment with average pooling and max pooling concatenation over hidden states for semantic prediction, similar to<cite> [Howard and Ruder, 2018]</cite> , and observe increase in model accuracy by 2.2% on sentiment analysis."
  ],
  "y": "background similarities"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_9",
  "x": [
   "We note the convergence of our model with and without curriculum training, and observe that the curriculum training regimen causes faster convergence, as has been observed in previous works [Bengio et al., 2009;<cite> Howard and Ruder, 2018]</cite> ."
  ],
  "y": "background similarities"
 },
 {
  "id": "74cd12a801d1f8a95f8898a8cef9c0_10",
  "x": [
   "As discussed in Section 4.3, for our transfer learning optimization experiments, we segment the optimization of different parameters of our model with different learning rates, in order to limit catastrophic forgetting and interference among the tasks, as proposed by<cite> [Howard and Ruder, 2018]</cite> ."
  ],
  "y": "similarities background"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_0",
  "x": [
   "It's remarkable success is also embodied in machine translation tasks (Bahdanau et al., 2014;<cite> Vaswani et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_1",
  "x": [
   "We customize the transformer<cite> (Vaswani et al., 2017)</cite> featured by non-local operations (Wang et al., 2018) with two * The work was done when Yaoyiran was working at Living Analytics Research Centre, Singapore Management University who is now a PhD student at University of Cambridge."
  ],
  "y": "extends"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_2",
  "x": [
   "then the non-local operation degrades to the multihead self-attention as is described in<cite> (Vaswani et al., 2017)</cite> (formula 2 describes only one attention head):"
  ],
  "y": "uses"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_3",
  "x": [
   "Based on the transformer model<cite> (Vaswani et al., 2017)</cite> , we design a novel co-attention mechanism."
  ],
  "y": "uses"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_4",
  "x": [
   "Different from previously known coattention mechanisms such as (Xiong et al., 2017; Lu et al., 2016a) , our co-attention is built through connecting two multiplicative attention modules<cite> (Vaswani et al., 2017</cite> ) each containing three gates, i.e., Value, Key and Query."
  ],
  "y": "uses extends"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_5",
  "x": [
   "Based on the transformer model<cite> (Vaswani et al., 2017)</cite> , we design a novel co-attention mechanism."
  ],
  "y": "extends"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_6",
  "x": [
   "Based on the transformer model<cite> (Vaswani et al., 2017)</cite> , we design a novel co-attention mechanism.",
   "Different from previously known coattention mechanisms such as (Xiong et al., 2017; Lu et al., 2016a) , our co-attention is built through connecting two multiplicative attention modules<cite> (Vaswani et al., 2017</cite> ) each containing three gates, i.e., Value, Key and Query."
  ],
  "y": "extends"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_7",
  "x": [
   "Attention: Multi-head self-attention has demonstrated its capacity in neural transduction models<cite> (Vaswani et al., 2017)</cite> , language model pre-training (Devlin et al., 2018; Radford et al., 2018) and speech synthesis (Yang et al., 2019c) ."
  ],
  "y": "background"
 },
 {
  "id": "74db2b52e81969742f8f7e5681bd2b_8",
  "x": [
   "While the novel attention mechanism, eschewing recurrence, is famous for modeling global dependencies and considered faster than recurrent layers<cite> (Vaswani et al., 2017)</cite> , recent work points out that it may tend to overlook neighboring information (Yang et al., 2019a; Xu et al., 2019) ."
  ],
  "y": "background"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_0",
  "x": [
   "Natural language to code generation, a subtask of semantic parsing, is the problem of converting natural language (NL) descriptions to code (Ling et al., 2016;<cite> Yin and Neubig, 2017</cite>; Rabinovich et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_1",
  "x": [
   "1 Code available at https://github.com/ sweetpeach/ReCode Tree-based approaches<cite> (Yin and Neubig, 2017</cite>; Rabinovich et al., 2017) represent code as Abstract Syntax Trees (ASTs), which has proven effective in improving accuracy as it enforces the well-formedness of the output code."
  ],
  "y": "background"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_2",
  "x": [
   "1 Code available at https://github.com/ sweetpeach/ReCode Tree-based approaches<cite> (Yin and Neubig, 2017</cite>; Rabinovich et al., 2017) represent code as Abstract Syntax Trees (ASTs), which has proven effective in improving accuracy as it enforces the well-formedness of the output code."
  ],
  "y": "motivation background"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_3",
  "x": [
   "Given an NL description q, our purpose is to generate code (e.g. Python) represented as an AST a. In this work, we start with the syntactic code gen-eration model by<cite> Yin and Neubig (2017)</cite> , which uses sequences of actions to generate the AST before converting it to surface code."
  ],
  "y": "uses"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_4",
  "x": [
   "Interested readers can reference<cite> Yin and Neubig (2017)</cite> for more detail of the neural model, which consists of a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) encoder-decoder with action embeddings, context vectors, parent feeding, and a copy mechanism using pointer networks."
  ],
  "y": "background"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_5",
  "x": [
   "N -gram subtrees from all retrieved sentences are assigned a score, based on the best similarity score<cite> Yin and Neubig (2017)</cite> of all instances where they appeared."
  ],
  "y": "uses"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_6",
  "x": [
   "We evaluate RECODE with the Hearthstone (HS) (Ling et al., 2016) and Django (Oda et al., 2015) datasets, as preprocessed by<cite> Yin and Neubig (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_7",
  "x": [
   "For evaluation metrics, we use accuracy of exact match and the BLEU score following<cite> Yin and Neubig (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_8",
  "x": [
   "For the neural code generation model, we use the settings explained in<cite> Yin and Neubig (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_9",
  "x": [
   "We compare our model with<cite> Yin and Neubig (2017)</cite>'s model that we call YN17 for brevity, and a sequence-to-sequence (SEQ2SEQ) model that we implemented."
  ],
  "y": "uses"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_10",
  "x": [
   "However, when the code consists of complex logic, partial implementation errors occur, leading to low exact match accuracy<cite> (Yin and Neubig, 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_11",
  "x": [
   "However, when the code consists of complex logic, partial implementation errors occur, leading to low exact match accuracy<cite> (Yin and Neubig, 2017)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_12",
  "x": [
   "Another common type of error that we found RECODE's generated outputs is incorrect variable copying, similarly to what is discussed in<cite> Yin and Neubig (2017)</cite> and Rabinovich et al. (2017) ."
  ],
  "y": "similarities"
 },
 {
  "id": "76476d80e1d3f65818592ec4caab0e_13",
  "x": [
   "The closest work to ours are<cite> Yin and Neubig (2017)</cite> and Rabinovich et al. (2017) which represent code as an AST."
  ],
  "y": "similarities"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_0",
  "x": [
   "On one hand, a number of methods have been developed to build hierarchies based on lexical patterns in text (Yang and Callan, 2009; Snow et al., 2006; Kozareva and Hovy, 2010; Navigli et al., 2011; Fu et al., 2014;<cite> Bansal et al., 2014</cite>; Tuan et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_1",
  "x": [
   "On one hand, a number of methods have been developed to build hierarchies based on lexical patterns in text (Yang and Callan, 2009; Snow et al., 2006; Kozareva and Hovy, 2010; Navigli et al., 2011; Fu et al., 2014;<cite> Bansal et al., 2014</cite>; Tuan et al., 2015) ."
  ],
  "y": "motivation extends"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_2",
  "x": [
   "To effectively capture these patterns, in contrast to previous works that rely on various hand-crafted features<cite> Bansal et al., 2014)</cite> , we extract features by leveraging the distributed representations that embed images (Simonyan and Zisserman, 2014) and words as compact vectors, based on which the semantic closeness is directly measured in vector space."
  ],
  "y": "differences"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_3",
  "x": [
   "Many approaches have been recently developed that build hierarchies purely by identifying either lexical patterns or statistical features in text corpora (Yang and Callan, 2009; Snow et al., 2006; Kozareva and Hovy, 2010; Navigli et al., 2011; Zhu et al., 2013; Fu et al., 2014;<cite> Bansal et al., 2014</cite>; Tuan et al., 2014; Tuan et al., 2015; Kiela et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_4",
  "x": [
   "The works of Fu et al. (2014) and <cite>Bansal et al. (2014)</cite> use similar language-based features as ours."
  ],
  "y": "similarities"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_5",
  "x": [
   "In<cite> (Bansal et al., 2014)</cite> , a structural learning model is developed to induce a globally optimal hierarchy."
  ],
  "y": "background"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_6",
  "x": [
   "In<cite> (Bansal et al., 2014)</cite> , a structural learning model is developed to induce a globally optimal hierarchy."
  ],
  "y": "differences"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_7",
  "x": [
   "To apply the model to discover the underlying taxonomy from a given set of categories, we first obtain the marginals of z by averaging over the samples generated through eq 3, then output the optimal taxonomy z * by finding the maximum spanning tree (MST) using the Chu-Liu-Edmonds algorithm (Chu and Liu, 1965;<cite> Bansal et al., 2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_8",
  "x": [
   "Specifically, we employ the Capitalization, Ends with, Contains, Suffix match, LCS and Length different features, which are commonly used in previous works in taxonomy induction (Yang and Callan, 2009;<cite> Bansal et al., 2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_9",
  "x": [
   "We then compare our model with previous state-of-the-art methods (Fu et al., 2014;<cite> Bansal et al., 2014)</cite> with two taxonomy induction tasks."
  ],
  "y": "uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_10",
  "x": [
   "We use Ancestor F 1 as our evaluation metric (Kozareva and Hovy, 2010; Navigli et al., 2011;<cite> Bansal et al., 2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_11",
  "x": [
   "We compare our method to two previously state-of-the-art models by Fu et al. (2014) and <cite>Bansal et al. (2014)</cite> , which are closest to ours."
  ],
  "y": "uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_12",
  "x": [
   "Table 2 : Comparisons among different variants of our model, Fu et al. (2014) and <cite>Bansal et al. (2014)</cite> on two tasks."
  ],
  "y": "uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_13",
  "x": [
   "We compare the following methods: (1) Fu2014, (2) Ours (L), and (3) Ours (LV), as described above; (4) Bansal2014: The model by <cite>Bansal et al. (2014)</cite> retrained using our dataset; (5) Ours (LB): By excluding visual features, but including other language features from <cite>Bansal et al. (2014)</cite> ; (6) Ours (LVB): Our full model further enhanced with all semantic features from <cite>Bansal et al. (2014)</cite> ; (7) Ours (LVB -E): By excluding word embeddingbased language features from Ours (LVB)."
  ],
  "y": "differences uses"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_14",
  "x": [
   "However, when introducing visual features, our performance is comparable (pvalue = 0.058).Furthermore, if we discard visual features but add semantic features from <cite>Bansal et al. (2014)</cite> , we achieve a slight improvement of 0.02 over Bansal2014 (p-value = 0.016), which is largely attributed to the incorporation of word embedding-based features that encode high-level linguistic regularity.",
   "Finally, if we enhance our full model with all semantic features from <cite>Bansal et al. (2014)</cite> , our model outperforms theirs by a gap of 0.04 (p-value < 0.01), which justifies our intuition that perceptual semantics underneath visual contents are quite helpful."
  ],
  "y": "differences"
 },
 {
  "id": "7700b6c3c096d5cd7999c34e7614f7_15",
  "x": [
   "Compared to <cite>Bansal et al. (2014)</cite> , a major difference of our model is that different layers of the taxonomy correspond to different weights w l , while in<cite> (Bansal et al., 2014)</cite> all layers share the same weights."
  ],
  "y": "differences"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_0",
  "x": [
   "In most of the previous studies (Mihalcea and Strapparava, 2005; Purandare and Litman, 2006; <cite>Yang et al., 2015</cite>) , humor recognition was modeled as a binary classification task."
  ],
  "y": "background"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_1",
  "x": [
   "In a recent work (<cite>Yang et al., 2015</cite>) , a new corpus was constructed from the Pun of the Day website.",
   "<cite>Yang et al. (2015)</cite> explained and computed stylistic features based on the following four aspects: (a) Incongruity, (b) Ambiguity, (c) Interpersonal Effect, and (d) Phonetic Style."
  ],
  "y": "background"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_2",
  "x": [
   "1 CNNbased text categorization methods have been applied to humor recognition (e.g., in (Bertero and Fung, 2016b) ) but with limitations: (a) a rigorous comparison with the state-of-the-art conventional method examined in <cite>Yang et al. (2015)</cite> is missing; (b) CNN's performance in the previous research is not quite clear; and (c) some important techniques that can improve CNN performance (e.g., using varied-sized filters and dropout regularization (Hinton et al., 2012)) were not applied."
  ],
  "y": "background"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_3",
  "x": [
   "1 CNNbased text categorization methods have been applied to humor recognition (e.g., in (Bertero and Fung, 2016b) ) but with limitations: (a) a rigorous comparison with the state-of-the-art conventional method examined in <cite>Yang et al. (2015)</cite> is missing; (b) CNN's performance in the previous research is not quite clear; and (c) some important techniques that can improve CNN performance (e.g., using varied-sized filters and dropout regularization (Hinton et al., 2012)) were not applied."
  ],
  "y": "motivation"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_4",
  "x": [
   "Following Mihalcea and Strapparava (2005) and <cite>Yang et al. (2015)</cite> , we selected the same numbers (n = 4726) of 'Laughter' and 'NoLaughter' sentences."
  ],
  "y": "uses"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_5",
  "x": [
   "Following <cite>Yang et al. (2015)</cite> , we applied Random Forest (Breiman, 2001 ) to perform humor recognition by using the following two groups of features."
  ],
  "y": "uses"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_6",
  "x": [
   "The Pun data allows us to verify that our implementation of the conventional model is consistent with the work reported in <cite>Yang et al. (2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "780b96afa8d417aa241e01ad594ce9_7",
  "x": [
   "On the Pun data, the CNN model shows consistent improved performance over the conventional model, as suggested in <cite>Yang et al. (2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_1",
  "x": [
   "<cite>As Bonial et al. (2014)</cite> stated 'PB has previously treated language as if it were purely compositional, and has therefore lumped the majority of MWEs in with lexical verb usages'."
  ],
  "y": "background"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_2",
  "x": [
   "Recently, <cite>Bonial et al. (2014)</cite> have introduced an approach to improve the handling of MWEs in PB while keeping annotation costs low."
  ],
  "y": "background"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_4",
  "x": [
   "In addition, we set up an annotation effort to gather a frequency-balanced, data-driven evaluation set that is larger and more diverse than the annotated set provided by <cite>Bonial et al. (2014)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_5",
  "x": [
   "The <cite>aliasing</cite> process introduced by <cite>Bonial et al. (2014)</cite> tries to extend the coverage of PB for CPs while keeping the number of rolesets that should be newly created to a minimum."
  ],
  "y": "background"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_6",
  "x": [
   "<cite>Bonial et al. (2014)</cite> conducted a pilot study re-annotating 138 CPs involving the verb take."
  ],
  "y": "background"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_7",
  "x": [
   "Roleset id: care.01, to be concerned Arg0: carer, agent Arg1: thing cared for/about Encouraged by the high proportion of CPs that could successfully be aliased in the pilot study by <cite>Bonial et al. (2014)</cite> , we created a method to automatically find aliases for CPs in order to decrease the amount of human intervention, thereby scaling up the coverage of CPs in PB."
  ],
  "y": "motivation"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_8",
  "x": [
   "In order to evaluate our system, we set up an annotation effort loosely following the guidelines provided by <cite>Bonial et al. (2014)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_9",
  "x": [
   "The simple inter-annotator agreement 5 was 67% for annotator A%B, 51% for A&C and 44% for A&D. These agreement figures are higher than the figures in <cite>Bonial et al. (2014)</cite> , and actual agreement is probably even higher, because synonymous rolesets are regarded as disagreements."
  ],
  "y": "differences"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_10",
  "x": [
   "In line with the results from <cite>Bonial et al. (2014)</cite> who aliased 100 out of 138 uncompositional take MWEs, we were also able to alias most of the CPs in our annotation set."
  ],
  "y": "similarities"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_11",
  "x": [
   "In addition, we evaluated our system on the dataset from <cite>Bonial et al. (2014)</cite> , restricted to the type of CP our system handles (LVCs and VPCs) and verb aliases (as opposed to aliases being a noun or adjective roleset)."
  ],
  "y": "uses"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_12",
  "x": [
   "We evaluated our approach on the 160 CPs annotated in the course of this work (Wiki50 set), as well as on the 70 take CPs from <cite>Bonial et al. (2014)</cite> (take set) and compare our results to the baseline."
  ],
  "y": "uses"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_13",
  "x": [
   "We have presented an approach to handle CPs in SRL that extends on work from <cite>Bonial et al. (2014)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "78afdf391c70d7992200b4071e4ac2_14",
  "x": [
   "We set up an annotation effort to gather a frequency-balanced, contextualized evaluation set that is more natural, varied and larger than the pilot annotations provided by <cite>Bonial et al. (2014)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_0",
  "x": [
   "Of particular interest to this work is the work by<cite> Sukhbaatar et al. (2015)</cite> , on end-toend memory networks (N2Ns), which exhibit remarkable reasoning capabilities, e.g. for reasoning and goal-oriented dialogue tasks ."
  ],
  "y": "background"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_1",
  "x": [
   "Of particular interest to this work is the work by<cite> Sukhbaatar et al. (2015)</cite> , on end-toend memory networks (N2Ns), which exhibit remarkable reasoning capabilities, e.g. for reasoning and goal-oriented dialogue tasks ."
  ],
  "y": "background"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_2",
  "x": [
   "While N2Ns generally work well with either weight tying approach, as reported in<cite> Sukhbaatar et al. (2015)</cite> , the performance is uneven on some difficult tasks."
  ],
  "y": "motivation"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_3",
  "x": [
   "End-to-End Memory Networks: Building on top of memory networks ,<cite> Sukhbaatar et al. (2015)</cite> ing the memory position supervision and making the model trainable in an end-to-end fashion, through the advent of supporting memories and a memory access controller."
  ],
  "y": "background"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_4",
  "x": [
   "To enhance the model's ability to cope with more challenging tasks requiring multiple supporting facts from the memory,<cite> Sukhbaatar et al. (2015)</cite> further extended the model by stacking multiple memory layers (also known as \"hops\"), in which case the output of the k th hop is taken as input to the (k + 1) th hop:"
  ],
  "y": "background"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_5",
  "x": [
   "In<cite> Sukhbaatar et al. (2015)</cite> , two types of weight tying were explored for N2N, namely adjacent (\"ADJ\") and layer-wise (\"LW\")."
  ],
  "y": "background"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_6",
  "x": [
   "Table 1 : Accuracy (%) reported in<cite> (Sukhbaatar et al., 2015)</cite> on a selected subset of the 20 bAbI 10k tasks."
  ],
  "y": "background"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_7",
  "x": [
   "Moreover, following<cite> Sukhbaatar et al. (2015)</cite> , we add a linear mapping H 2 R d\u21e5d to the update connection between memory hops, but in our case, down-weight it by 1 z, resulting in:"
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_8",
  "x": [
   "Training Details: Following<cite> Sukhbaatar et al. (2015)</cite>, we hold out 10% of the bAbI training set to form a development set."
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_9",
  "x": [
   "Following<cite> Sukhbaatar et al. (2015)</cite> , linear start is employed in all our experiments for the first 20 epochs."
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_10",
  "x": [
   "Also following<cite> Sukhbaatar et al. (2015)</cite> , we use only the most recent 50 sentences as the memory and set the number of memory hops to 3, the embedding size to 20, and to"
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_11",
  "x": [
   "Consistent with other published results over bAbI<cite> (Sukhbaatar et al., 2015</cite>; Seo et al., 2017) , we repeat training 30 times for each task, and select the model which performs best on the development set."
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_12",
  "x": [
   "We benchmark against other memory network based models: (1) N2N with ADJ and LW<cite> (Sukhbaatar et al., 2015)</cite> ; (2) DMN (Kumar et al., 2016) and its improved version DMN+ (Xiong et al., 2016) ; and (3) GN2N (Liu and Perez, 2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_13",
  "x": [
   "As a large variance can be observed due to how sensitive memory-based models are to parameter initialisation, following<cite> (Sukhbaatar et al., 2015)</cite> and (Liu and Perez, 2017) , we repeat each training 10 times using the Table 4 : Per-response accuracy on the Dialog bAbI tasks."
  ],
  "y": "uses"
 },
 {
  "id": "7a2f56cb4bbcd09ba35934ca76c9a9_14",
  "x": [
   "In terms of baselines, we benchmark against other memory network-based models: 4 (1) N2N<cite> (Sukhbaatar et al., 2015)</cite> ; and (2) GN2N<cite> (Sukhbaatar et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7b4a976ba6a43b5ba42cc350b4d132_0",
  "x": [
   "We propose here to extend the LRP application to a linguistically motivated network architecture, known as <cite>Kernel-Based Deep Architecture</cite> (<cite>KDA</cite>) <cite>[5]</cite> , which frames semantic information captured by linguistic Tree Kernel [2] methods within the neural-based learning paradigm."
  ],
  "y": "uses"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_0",
  "x": [
   "We wish to apply this direct, Bayesian approach to learn better translation rules for syntaxbased statistical MT (SSMT), by which we specifically refer to MT systems using Tree-to-String (TTS) translation templates derived from syntax trees (Liu et al., 2006; Huang et al., 2006;<cite> Galley et al., 2006</cite>; May and Knight, 2007) , as opposed to formally syntactic systems such as Hiero (Chiang, 2007) ."
  ],
  "y": "uses"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_1",
  "x": [
   "The first is synchronous parsing <cite>(Galley et al., 2006</cite>; May and Knight, 2007) , where TTS templates are used to construct synchronous parse trees for an input sentence, and the translations will be generated once the synchronous trees are built up."
  ],
  "y": "background"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_2",
  "x": [
   "The first is synchronous parsing <cite>(Galley et al., 2006</cite>; May and Knight, 2007) , where TTS templates are used to construct synchronous parse trees for an input sentence, and the translations will be generated once the synchronous trees are built up."
  ],
  "y": "background similarities"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_3",
  "x": [
   "This algorithm is referred to as GHKM (Galley et al., 2004) and is widely used in SSMT systems <cite>(Galley et al., 2006</cite>; Liu et al., 2006; Huang et al., 2006) ."
  ],
  "y": "similarities"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_4",
  "x": [
   "The other one is normalization based on the root of the LHS (ROOTN)<cite> (Galley et al., 2006)</cite> , corresponding to the generative process where, given the root of the syntax subtree, the LHS syntax subtree and the RHS string are generated simultaneously."
  ],
  "y": "background"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_5",
  "x": [
   "LHSN, as shown by<cite> Galley et al. (2006)</cite> , cannot accurately restore the true conditional probabilities of the target sentences given the source sentences in the training corpus."
  ],
  "y": "background"
 },
 {
  "id": "7b69c68a602e90c7ee7b9fa8a8facf_6",
  "x": [
   "LHSN, as shown by<cite> Galley et al. (2006)</cite> , cannot accurately restore the true conditional probabilities of the target sentences given the source sentences in the training corpus."
  ],
  "y": "uses"
 },
 {
  "id": "7c3f94a231c83c94b5d93c33ab8bfa_0",
  "x": [
   "This tutorial discusses a framework of online global discriminative learning and beam-search decoding for syntactic processing (Zhang and Clark, 2011b) , which has recently been applied to a wide variety of natural language processing (NLP) tasks, including word segmentation <cite>(Zhang and Clark, 2007)</cite> , dependency parsing (Zhang and Clark, 2008b; Huang and Sagae, 2010; Zhang and Nivre, 2011; Bohnet and Kuhn, 2012) , context free grammar (CFG) parsing (Collins and Roark, 2004; Zhang and Clark, 2009; Zhu et al., 2013) , combinational categorial grammar (CCG) parsing (Zhang and Clark, 2011a; Xu et al., 2014) and machine translation (Liu, 2013) , achieving stateof-the-art accuracies and efficiencies."
  ],
  "y": "background"
 },
 {
  "id": "7c3f94a231c83c94b5d93c33ab8bfa_1",
  "x": [
   "We start with a detailed introduction of the framework, describing the averaged perceptron algorithm (Collins, 2002) and its efficient implementation issues <cite>(Zhang and Clark, 2007)</cite> , as well as beam-search and the early-update strategy (Collins and Roark, 2004) ."
  ],
  "y": "motivation"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_0",
  "x": [
   "Sentence embeddings have been generated using unsupervised learning approaches (e.g. Hill et al., 2016) , and supervised learning (e.g. Bowman et al., 2016;<cite> Conneau et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_1",
  "x": [
   "Some approaches focus on building sentence embeddings for the premises and the hypothesis separately and then combine those using a classifier (e.g. Bowman et al., 2015 Bowman et al., , 2016<cite> Conneau et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_2",
  "x": [
   "Motivated by the success of the architecture of InferSent<cite> (Conneau et al., 2017)</cite> , we build a hierarchical architecture utilizing bidirectional LSTM (BiLSTM) layers and max pooling."
  ],
  "y": "motivation"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_3",
  "x": [
   "We also test our model on a number of transfer learning tasks using the SentEval testing library<cite> (Conneau et al., 2017)</cite> , and show that our model outperforms the InferSent model on 7 out of 10 and SkipThought on 8 out of 9 tasks, comparing to the scores reported by <cite>Conneau et al. (2017)</cite> ."
  ],
  "y": "differences uses"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_4",
  "x": [
   "<cite>Conneau et al. (2017)</cite> explore multiple different sentence embedding architectures ranging from LSTM, BiLSTM and intra-attention to convolution neural networks and the performance of these architectures on NLI tasks."
  ],
  "y": "background"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_5",
  "x": [
   "Motivated by the strong results of the BiLSTM max pooling network by <cite>Conneau et al. (2017)</cite> , we experimented with combining BiLSTM max pooling networks as a hierarchical structure."
  ],
  "y": "motivation extends"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_6",
  "x": [
   "3 We also conducted a linguistic error analysis and compared our results to the results obtained with the InferSent BiLSTM max pooling model of <cite>Conneau et al. (2017)</cite> (our implementation)."
  ],
  "y": "uses"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_7",
  "x": [
   "4 The scores for our implementation of InferSent are on par or slightly higher than the scores reported by <cite>Conneau et al. (2017)</cite> using their training setup."
  ],
  "y": "similarities"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_8",
  "x": [
   "To better understand how well our model generalizes to different tasks, we conducted additional transfer learning tests using the SentEval sentence embedding evaluation library 5<cite> (Conneau et al., 2017)</cite> and compared our results to the results published for InferSent and SkipThought ."
  ],
  "y": "uses"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_9",
  "x": [
   "This allows us to compare our results to the InferSent results which were obtained using a model trained on the same data<cite> (Conneau et al., 2017)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_10",
  "x": [
   "<cite>Conneau et al. (2017)</cite> have shown that including all the training data from SNLI and MultiNLI improves significantly the model performance on transfer learning tasks, compared to training the model only on SNLI data."
  ],
  "y": "background"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_13",
  "x": [
   "InferSent results obtained with our implementation using the architecture and training set-up described in<cite> (Conneau et al., 2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7c8f54479ce1f9d81b49839425f58e_14",
  "x": [
   "For the transfer learning tasks, described in Section 7, we used training data from both the SNLI and the MultiNLI datasets in order to compare to the results by <cite>Conneau et al. (2017)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_0",
  "x": [
   "In the present work, we perform a systematic evaluation of APSyn, testing it on the most popular test sets for similarity estimation -namely WordSim-353 (Finkelstein et al., 2001) , MEN (Bruni et al., 2014) and <cite>SimLex-999</cite> (<cite>Hill et al., 2015</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_1",
  "x": [
   "The results are also discussed in relation to the state-of-the-art DSMs, as reported in <cite>Hill et al. (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_2",
  "x": [
   "Finally, considering the debate about the ability of DSMs to calculate genuine similarity as opposed to word relatedness (Turney, 2001; Agirre et al., 2009; <cite>Hill et al., 2015</cite>) , we test the ability of the models to quantify genuine semantic similarity."
  ],
  "y": "background"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_3",
  "x": [
   "For our evaluation, we used three widely popular datasets: WordSim-353 (Finkelstein et al., 2001) , MEN (Bruni et al., 2014) , <cite>SimLex-999</cite> (<cite>Hill et al., 2015</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_4",
  "x": [
   "However, <cite>Hill et al. (2015)</cite> claimed that the instructions to the annotators were ambiguous with respect to similarity and association, so that the subjects assigned high similarity scores to entities that are only related by virtue of frequent association (e.g. coffee and cup; movie and theater)."
  ],
  "y": "background"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_5",
  "x": [
   "Even though such a classification made a clear distinction between the two types of relations (i.e. similarity and association), <cite>Hill et al. (2015)</cite> argue that these gold standards still carry the scores they had in WordSim-353, which are known to be ambiguous in this regard."
  ],
  "y": "background"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_6",
  "x": [
   "According to <cite>Hill et al. (2015)</cite> , the major weakness of this dataset is that it does not encode word similarity, but a more general notion of association."
  ],
  "y": "background"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_7",
  "x": [
   "<cite>SimLex-999</cite> is the dataset introduced by <cite>Hill et al. (2015)</cite> to address the above mentioned criticisms of confusion between similarity and association."
  ],
  "y": "background"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_8",
  "x": [
   "<cite>Hill et al. (2015)</cite> claim that differently from other datasets, <cite>SimLex-999</cite> interannotator agreement has not been surpassed by any automatic approach."
  ],
  "y": "background"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_9",
  "x": [
   "In order to compare our results with state-of-the-art DSMs, we report the scores for the Vector Cosines calculated on the neural language models (NLM) by <cite>Hill et al. (2015)</cite> , who used the code (or directly the embeddings) shared by the original authors."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_10",
  "x": [
   "As we trained our models on almost the same corpora used by <cite>Hill and colleagues</cite>, the results are perfectly comparable."
  ],
  "y": "similarities"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_12",
  "x": [
   "All of them include the pos-tagged target words used in the three datasets (i.e. MEN, WordSim-353 and <cite>SimLex-999</cite>) and the pos-tagged contexts having frequency above 100 in the two corpora."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_13",
  "x": [
   "Table 2 : Spearman correlation scores for our eight models trained on Wikipedia, in the three datasets <cite>Simlex-999</cite>, WordSim-353 and MEN."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_14",
  "x": [
   "In the bottom the performance of the state-of-the-art models of Collobert and Weston (2008) , Huang et al. (2012), Mikolov et al. (2013) , as reported in <cite>Hill et al. (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_15",
  "x": [
   "In particular, Table 1 describes the performances on <cite>SimLex-999</cite>, WordSim-353 and MEN for the measures applied on RCV Vol."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_16",
  "x": [
   "For the sake of comparison, we also report the results of the state-of-the-art DSMs mentioned in <cite>Hill et al. (2015)</cite> (see Section 2.5)."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_17",
  "x": [
   "The former appears to perform better on <cite>SimLex-999</cite>, while the latter seems to have some advantages on the other datasets."
  ],
  "y": "differences"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_18",
  "x": [
   "This Table 3 : Spearman correlation scores for our eight models trained on RCV1, in the two subsets of might depend on the different type of similarity encoded in <cite>SimLex-999</cite> (i.e. genuine similarity)."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_19",
  "x": [
   "On top of it, despite <cite>Hill et al. (2015)</cite> 's claim that no evidence supports the hypothesis that smaller context windows improve the ability of models to capture similarity (Agirre et al., 2009; Kiela and Clark, 2014) , we need to mention that window 5 was abandoned because of its low performance."
  ],
  "y": "differences"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_20",
  "x": [
   "With reference to the hubness effect, we have conducted a pilot study inspired to the one carried out by Schnabel et al. (2015) , using the words of the <cite>SimLex-999</cite> dataset as query words and collecting for each of them the top 1000 nearest neighbors."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_21",
  "x": [
   "Finally, few words need to be spent with regard to the ability of calculating genuine similarity, as distinguished from word relatedness (Turney, 2001; Agirre et al., 2009; <cite>Hill et al., 2015</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_22",
  "x": [
   "Interestingly, our best models achieve results that are comparable to -or even better than -those reported by <cite>Hill et al. (2015)</cite> for the stateof-the-art word embeddings models."
  ],
  "y": "similarities"
 },
 {
  "id": "7ce85e3c3f58cee33015409b74f99e_23",
  "x": [
   "Concerning the discrimination between similarity and association, the good performance of APSyn on <cite>SimLex-999</cite> (which was built with a specific attention to genuine similarity) and the large difference in performance between the two subsets of WordSim-353 described in Table  3 and Table 4 make us conclude that APSyn is indeed efficient in quantifying genuine similarity."
  ],
  "y": "uses"
 },
 {
  "id": "7e52a90a9a0a703250d5c3c1890058_0",
  "x": [
   "There have been efforts undertaken to apply the grammar engine technique instead (Byamugisha et al., 2016a;<cite> Byamugisha et al., 2016b</cite>; Byamugisha et al., 2016c) , which resulted in theoretical advances in verbalization rules for ontologies, pluralization of nouns, and verb conjugation that address the text generation needs for Runyankore."
  ],
  "y": "background"
 },
 {
  "id": "7e52a90a9a0a703250d5c3c1890058_1",
  "x": [
   "There have been efforts undertaken to apply the grammar engine technique instead (Byamugisha et al., 2016a;<cite> Byamugisha et al., 2016b</cite>; Byamugisha et al., 2016c) , which resulted in theoretical advances in verbalization rules for ontologies, pluralization of nouns, and verb conjugation that address the text generation needs for Runyankore."
  ],
  "y": "uses"
 },
 {
  "id": "7e52a90a9a0a703250d5c3c1890058_2",
  "x": [
   "The CFG specified in <cite>(Byamugisha et al., 2016b)</cite> was implemented using the CFG Java tool (Xu et al., 2011) ."
  ],
  "y": "background"
 },
 {
  "id": "7e52a90a9a0a703250d5c3c1890058_3",
  "x": [
   "The CFG specified in <cite>(Byamugisha et al., 2016b)</cite> was implemented using the CFG Java tool (Xu et al., 2011) ."
  ],
  "y": "uses"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_0",
  "x": [
   "Most modern Q/A systems, however, follow work done by<cite> (Li and Roth, 2002)</cite> in using machine learning classifiers in order to select the one (or more) EATs from a fixed hierarchy of answer types which are most appropriate for a particular question."
  ],
  "y": "background"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_1",
  "x": [
   "For example, the most commonly-used answer type hierarchy (ATH), the University of Illinois (UIUC) answer type hierarchy created by<cite> (Li and Roth, 2002)</cite> , includes only a total of 50 unique expected answer types (generally referred to as \"fine\" answer types), organized into 6 different categories (referred to as \"coarse\" answer types)."
  ],
  "y": "background"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_2",
  "x": [
   "in contrast, the<cite> (Li and Roth, 2002)</cite> UIUC ATH is designed especially for questions, but lacks the ability to extend the depth of the hierarchy when Q/A systems are capable of handling more detailed answer types."
  ],
  "y": "differences"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_3",
  "x": [
   "(A graphical representation of a portion of the LCC ATH is presented in Figure 1 .) The UIUC answer type hierarchy<cite> (Li and Roth, 2002)</cite> We feel that the time is right for work in ATD to move beyond the UIUC ATH and to begin to tackle problems of organizing and learning answer type hierarchies that encompass several hundreds of diverse expected answer types."
  ],
  "y": "background"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_4",
  "x": [
   "In this section, we describe how we used the large ATH introduced in Section 3 in order to annotate a corpus drawn from more than 10,000 questions compiled from (1) existing annotated question corpora<cite> (Li and Roth, 2002)</cite> , (2) collections of questions mined from the web, and (3) questions submitted to LCC's FERRET question-answering system (Hickl et al., 2006a) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_5",
  "x": [
   "In a departure from previous machine-learning based approaches<cite> (Li and Roth, 2002</cite>; Krishnan et al., 2005) , we used a maximum entropy classifier to learn our ATH."
  ],
  "y": "similarities uses"
 },
 {
  "id": "7e73137c97a84fe7fa4941ecd06a91_6",
  "x": [
   "In a departure from previous work in answer type detection (Krishnan et al., 2005;<cite> Li and Roth, 2002)</cite> , we have demonstrated how a large, multi-tiered answer type hierarchy can be created which incorporates many of the entity types included in LCC's wide coverage named entity recognition system, CICEROLITE; this hierarchy was then used in order to create a new corpus of more than 10,000 questions which could be used to train an ATD system."
  ],
  "y": "similarities"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_0",
  "x": [
   "Unsupervised speech representation learning [2, 3, 4, 5, 6,<cite> 7,</cite> 8, 9, 10] is effective in extracting high-level properties from speech."
  ],
  "y": "background"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_1",
  "x": [
   "Contrastive Predictive Coding (CPC) [5] and wav2vec <cite>[7]</cite> use a multi-layer CNN to encode past context, representations are learned by predicting the future in latent space under a contrastive binary classification task."
  ],
  "y": "background"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_2",
  "x": [
   "Unidirectional models are commonly used in the previous approaches [2, 3, 4, 5, 6,<cite> 7]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_3",
  "x": [
   "Unidirectional models are commonly used in the previous approaches [2, 3, 4, 5, 6,<cite> 7]</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_4",
  "x": [
   "Moreover, as previous approaches restrict the power of the pre-trained models to representation extraction only [5, 6,<cite> 7,</cite> 8] , the proposed method is robust and can be fine-tuned easily on downstream tasks."
  ],
  "y": "differences"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_5",
  "x": [
   "Following previous works [2, 3, 4, 5, 6,<cite> 7,</cite> 8] , we evaluate different features and representations on downstream tasks, including: phoneme classification, speaker recognition, and sentiment classification on spoken content."
  ],
  "y": "uses"
 },
 {
  "id": "7f1723c42fc577fdfd7144b7991db1_6",
  "x": [
   "As reported in [6] , the APC approach outperformed CPC representations [5,<cite> 7,</cite> 9] in both two tasks, which makes APC suitable as a strong baseline."
  ],
  "y": "differences"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_0",
  "x": [
   "Recently, Guided Source Separation (GSS) enhancement on the test data was shown to significantly improve the performance of an acoustic model, which had been trained with a large amount of unprocessed and simulated noisy data <cite>[13]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_1",
  "x": [
   "This compares very favorably with the recently published topline in <cite>[13]</cite> , where the single-system best result, i.e., the WER without system combination, was 45.1 % and 47.3 % on DEV and EVAL, respectively, using an augmented training data set of 4500 hrs total."
  ],
  "y": "differences"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_2",
  "x": [
   "It follows the approach presented in <cite>[13]</cite> , which was shown to outperform the baseline version."
  ],
  "y": "uses"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_3",
  "x": [
   "However, having such a large temporal context may become problematic when the speakers are moving, because the estimated spatial covariance matrix can become outdated due to the movement <cite>[13]</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_4",
  "x": [
   "Therefore, the temporal context was only used for dereverberation and the mixture model parameter estimation, while for the estimation of covariance matrices for beamforming the context was dropped and only the original segment length was considered <cite>[13]</cite> ."
  ],
  "y": "uses extends"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_5",
  "x": [
   "To facilitate comparison with the recently published top-line in <cite>[13]</cite> (H/UPB), we have conducted a more focused set of experiments whose results are depicted in Table 4 ."
  ],
  "y": "uses"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_6",
  "x": [
   "As explained in Section 5.1, we opted for <cite>[13]</cite> instead of [14] as baseline because the former system is stronger."
  ],
  "y": "uses"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_7",
  "x": [
   "To have a fair comparison, the results are compared with the single-system performance reported in <cite>[13]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_8",
  "x": [
   "For the single array track, the proposed system without RNN LM rescoring achieves 16 % (11 %) relative WER reduction on the DEV (EVAL) set when compared with System8 in <cite>[13]</cite> (row one in Table 4 )."
  ],
  "y": "differences"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_9",
  "x": [
   "For the multi array track, the proposed system without RNN LM rescoring achieved 6 % (7 %) relative WER reduction on the DEV (EVAL) set when compared with System16 in <cite>[13]</cite> (row six in Table 4 )."
  ],
  "y": "differences"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_10",
  "x": [
   "Finally, cleaning up the training set not only boosted the recognition performance, but managed to do so using a fraction of the training data in <cite>[13]</cite> , as shown in Table 5 ."
  ],
  "y": "uses"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_11",
  "x": [
   "The first row corresponds to the GSS configuration in [14] while the second one corresponds to the GSS configuration in <cite>[13]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7f2622701e1f6c8492ec627b6ac32b_13",
  "x": [
   "Consequently, we have chosen system <cite>[13]</cite> as baseline in this study since is using the stronger GSS configuration."
  ],
  "y": "uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_0",
  "x": [
   "In this paper, following prior work (e.g., <cite>Salton et al., 2016</cite> ), we frame token-level identification of VNCs as a supervised binary classification problem, i.e., idiomatic vs. literal."
  ],
  "y": "uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_1",
  "x": [
   "Surprisingly, we find that an approach based on representing sentences as the average of their word embeddings performs comparably to, or better than, the skip-thoughts based approach previously proposed by <cite>Salton et al. (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_2",
  "x": [
   "Much research on MWE identification has focused on specific kinds of MWEs (e.g., Patrick and Fletcher, 2005; Uchiyama et al., 2005) , including English VNCs (e.g., Fazly et al., 2009; <cite>Salton et al., 2016</cite>) , although some recent work has considered the identification of a broad range of kinds of MWEs (e.g., Schneider et al., 2014; Brooke et al., 2014; Savary et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_3",
  "x": [
   "In the most closely related work to ours, <cite>Salton et al. (2016)</cite> represent token instances of VNCs by embedding the sentence that they occur in using skip-thoughts (Kiros et al., 2015) -an encoderdecoder model that can be viewed as a sentencelevel counterpart to the word2vec (Mikolov et al., 2013 ) skip-gram model."
  ],
  "y": "background"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_4",
  "x": [
   "<cite>Salton et al.</cite> then use these sentence embeddings, representing VNC token instances, as features in a supervised classifier."
  ],
  "y": "background"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_5",
  "x": [
   "<cite>Salton et al.</cite> then use these sentence embeddings, representing VNC token instances, as features in a supervised classifier."
  ],
  "y": "motivation"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_6",
  "x": [
   "Note that this approach is our re-implementation of the skipthoughts based method of <cite>Salton et al. (2016)</cite> , and we use it as a strong baseline for comparison."
  ],
  "y": "uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_7",
  "x": [
   "We use the VNC-Tokens dataset (Cook et al., 2008) -the same dataset used by Fazly et al. (2009) and <cite>Salton et al. (2016)</cite> -to train and evaluate our models."
  ],
  "y": "similarities uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_8",
  "x": [
   "Following <cite>Salton et al. (2016)</cite> , we use DEV and TEST, and ignore all token instances annotated as \"unknown\"."
  ],
  "y": "uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_9",
  "x": [
   "Fazly et al. (2009) and <cite>Salton et al. (2016)</cite> structured their experiments differently.",
   "<cite>Salton et al.</cite>, on the other hand, merge DEV and TEST, and create new training and testing sets, such that each expression is present in the training and testing data, and the ratio of idiomatic to literal usages of each expression in the training data is roughly equal to that in the testing data."
  ],
  "y": "uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_10",
  "x": [
   "We retain We then divide each of these into training and testing sets, using the same ratios of idiomatic to literal usages for each expression as <cite>Salton et al. (2016)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_11",
  "x": [
   "We randomly divide both DEV and TEST into training and testing portions ten times, following <cite>Salton et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_12",
  "x": [
   "Nevertheless, it is remarkable that the relatively simple approach to averaging word embeddings used by word2vec performs as well as, or better than, the much more complex skipthoughts model used by <cite>Salton et al. (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "7f78697390e28cc7798f8cb183cb59_13",
  "x": [
   "We compared these approaches against a linguistically-informed unsupervised baseline, and a model based on skip-thoughts previously applied to this task (<cite>Salton et al., 2016</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_0",
  "x": [
   "Recently, however, <cite>Hirschberg and Litman (1993)</cite> have presented rules for classifying cue phrases in both text and speech.",
   "<cite>Hirschberg and Litman</cite> pre-classi ed a set of naturally occurring cue phrases, described each cue phrase in terms of prosodic and textual features, then manually examined the data to construct rules that best predicted the classi cations from the features."
  ],
  "y": "motivation background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_1",
  "x": [
   "The accuracy of the learned rulesets is often higher than the accuracy of the rules in <cite>(Hirschberg & Litman 1993)</cite> , while the linguistic implications are more precise."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_3",
  "x": [
   "The data from <cite>this study</cite> is used to create the input for the machine learning experiments, while the results are used as a benchmark for evaluating performance."
  ],
  "y": "uses"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_4",
  "x": [
   "<cite>Hirschberg and Litman</cite> each classi ed the 953 tokens (as discourse, sentential or ambiguous) while listening to a recording and reading a transcription."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_5",
  "x": [
   "In <cite>(Hirschberg & Litman 1993)</cite> , every cue phrase was described using the following prosodic features."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_6",
  "x": [
   "In a procedure similar to that described above, <cite>Hirschberg and Litman</cite> rst classi ed and described each of the 48 tokens."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_7",
  "x": [
   "<cite>They</cite> then examined their data manually to develop the prosodic model, which correctly classi ed all of the 48 tokens."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_8",
  "x": [
   "The model uniquely classi es any cue phrase using the features composition of Figure 1 : Decision tree representation of the classi cation models of (<cite>Hirschberg and Litman 1993</cite> Figure 1 ), or in a larger intermediate phrase with an initial position (possibly preceded by other cue phrases) and a L* accent or deaccented, it is classi ed as discourse."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_9",
  "x": [
   "The rst subset (878 examples) consisted of only the classi able tokens, i.e., the tokens that both <cite>Hirschberg and Litman</cite> classi ed as discourse or that both classi ed as sentential."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_10",
  "x": [
   "This section describes experiments that use the machine learning programs C4.5 (Quinlan 1986; and cgrendel (Cohen 1992; 1993) to automatically induce cue phrase classi cation rules from both the data of <cite>(Hirschberg & Litman 1993)</cite> and an extension of this data."
  ],
  "y": "uses extends"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_11",
  "x": [
   "In each experiment, a different subset of the features coded in <cite>(Hirschberg & Litman 1993 )</cite> is examined."
  ],
  "y": "uses"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_12",
  "x": [
   "The potential use of such a lexical feature was noted but not used in <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_13",
  "x": [
   "The classi cations produced <cite>by Hirschberg and by Litman</cite> (discourse, sentential, and ambiguous) are combined into a single classi cation for each cue phrase."
  ],
  "y": "uses"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_14",
  "x": [
   "A cue phrase is classi ed as discourse (or as sentential) if both <cite>Hirschberg and Litman</cite> agreed upon the classi cation discourse (or upon sentential)."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_15",
  "x": [
   "A cue phrase is non-classi able if at least one of <cite>Hirschberg and/or Litman</cite> classi ed the token as ambiguous, or one classi ed it as discourse while the other classi ed it as sentential."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_16",
  "x": [
   "The feature representation shown here follows the representation of <cite>(Hirschberg & Litman 1993 )</cite> except as noted."
  ],
  "y": "similarities"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_17",
  "x": [
   "This feature was not coded in the data from which the prosodic model was developed, but was coded (although not used) in the later data of <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_18",
  "x": [
   "Ambiguous, the last value of A, is assigned when the prosodic anal- ysis of <cite>(Hirschberg & Litman 1993 )</cite> is a disjunction (e.g., \\H*+L or H*\")."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_19",
  "x": [
   "NA (not applicable) in the textual features re ects the fact that 39 recorded examples were not included in the transcription, which was done independently of <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_20",
  "x": [
   "The second input to each learning program is training data, i.e., a set of examples for which the class and feature values are speci ed. Consider the following utterance, taken from the corpus of <cite>(Hirschberg & Litman 1993)</cite>: Example 1 (Now) (now that we have all been welcomed here)] it's time to get on with the business of the conference."
  ],
  "y": "uses"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_21",
  "x": [
   "These sets correspond to the two subsets of the corpus examined in <cite>(Hirschberg & Litman 1993 )</cite> { the classi able tokens, and the classi able non-conjuncts."
  ],
  "y": "similarities"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_22",
  "x": [
   "In contrast (as discussed above), the \\training\" and test sets for the intonational model of <cite>(Hirschberg & Litman 1993)</cite> were taken from di erent corpora, while for the textual model of <cite>(Hirschberg & Litman 1993 )</cite> the test set was a superset of the training set."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_23",
  "x": [
   "The error rates in italics indicate that the performance of the learned ruleset exceeds the performance reported in <cite>(Hirschberg & Litman 1993)</cite> , where the rules of Figure 1 were tested using 100% of the 878 classi able tokens."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_24",
  "x": [
   "(Recall that length was coded by <cite>Hirschberg and Litman</cite> only in <cite>their</cite> test data."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_26",
  "x": [
   "When the feature token is taken into account, however, the learned rulesets outperform the models of <cite>(Hirschberg & Litman 1993</cite> sider this feature), and also provide new insights into cue phrase classi cation."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_27",
  "x": [
   "He developed a genetic learning algorithm to induce decision trees using the non-ambiguous examples of <cite>(Hirschberg & Litman 1993 )</cite> (using the classi cations of only one judge) as well as additional examples."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_28",
  "x": [
   "An examination of Table 2 shows that the error of the best C4.5 and cgrendel rulesets was often lower than 21% (even for theories which did not consider the token), as was the 19.1% error of the textual model of <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_29",
  "x": [
   "A rst set of experiments were presented that used the programs cgrendel (Cohen 1992; 1993) and C4.5 (Quinlan 1986; to induce classi cation rules from the preclassi ed cue phrases and their features that were used as test data in <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_30",
  "x": [
   "In particular, a large number of learned rulesets (including P-P, an extremely simple one feature model) had signicantly lower error rates than the rulesets of <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "8075c3716c0be601a769ccd53b0c5e_31",
  "x": [
   "For example, in a second set of experiments, new classi cation rules were induced using the feature token, which was not considered in <cite>(Hirschberg & Litman 1993)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_0",
  "x": [
   "Features from n-gram counts over resources like Web1T (Brants and Franz, 2006 ) have proven to be useful proxies for syntax<cite> (Bansal and Klein, 2011</cite>; Pitler, 2012) , but they enforce linear word order, and are unable to distinguish between syntactic and non-syntactic co-occurrences."
  ],
  "y": "motivation background"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_1",
  "x": [
   "We compare the performance of our syntactic n-gram features against the surface n-gram features of<cite> Bansal and Klein (2011)</cite> in-domain on newswire and out-of-domain on the English Web Treebank (Petrov and McDonald, 2012) across CoNLL-style (LTH) dependencies."
  ],
  "y": "uses"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_2",
  "x": [
   "We also develop paraphrase-style features like those of<cite> Bansal and Klein (2011)</cite> based on the most frequently occurring words and POS tags before, in between, and after each head-argument ambiguity (see Section 3.2)."
  ],
  "y": "similarities uses"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_3",
  "x": [
   "3 Surface n-gram Features<cite> Bansal and Klein (2011)</cite> demonstrate that features generated from bucketing simple surface n-gram counts and collecting the top paraphrase-based contextual words over Web1T are useful for almost all attachment decisions, boosting dependency parsing accuracy by up to 0.6%."
  ],
  "y": "background"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_4",
  "x": [
   "3 Surface n-gram Features<cite> Bansal and Klein (2011)</cite> demonstrate that features generated from bucketing simple surface n-gram counts and collecting the top paraphrase-based contextual words over Web1T are useful for almost all attachment decisions, boosting dependency parsing accuracy by up to 0.6%."
  ],
  "y": "motivation"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_5",
  "x": [
   "We also extend<cite> Bansal and</cite> Klein's affinity and paraphrase features to second-order."
  ],
  "y": "uses"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_6",
  "x": [
   "Affinity features rely on the intuition that frequently co-occurring words in large unlabeled text collections are likely to be in a syntactic relationship (Nakov and Hearst, 2005;<cite> Bansal and Klein, 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_7",
  "x": [
   "In<cite> Bansal and Klein (2011)</cite> , paraphrase features are generated for all full-parse attachment ambiguities from the surface n-gram corpus."
  ],
  "y": "background"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_8",
  "x": [
   "As with<cite> Bansal and Klein (2011) and</cite> Pitler (2012) , we convert the Penn Treebank to dependencies using pennconverter 3 (Johansson and Nugues, 2007) (henceforth LTH) and generate POS tags with MX-POST (Ratnaparkhi, 1996) ."
  ],
  "y": "uses"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_9",
  "x": [
   "Surface n-gram counts from large web corpora have been used to address NP and PP attachment errors (Volk, 2001; Nakov and Hearst, 2005) Aside from<cite> Bansal and Klein (2011)</cite> , other feature-based approaches to improving dependency parsing include Pitler (2012) , who exploits Brown clusters and point-wise mutual information of surface n-gram counts to specifically address PP and coordination errors."
  ],
  "y": "background"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_10",
  "x": [
   "We extract<cite> Bansal and Klein (2011)</cite> 's affinity and paraphrase-style first-order features from the Google Books English Ngrams corpus, and compare their performance against Web1T counts.",
   "We also extend<cite> Bansal and</cite> Klein's affinity and paraphrase features to second-order."
  ],
  "y": "extends"
 },
 {
  "id": "808e0a94b877182dc06447c8682a63_11",
  "x": [
   "We extract<cite> Bansal and Klein (2011)</cite> 's affinity and paraphrase-style first-order features from the Google Books English Ngrams corpus, and compare their performance against Web1T counts."
  ],
  "y": "extends"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_0",
  "x": [
   "<cite>[21]</cite> further showed that use of synthetic training data can work better than multitask training."
  ],
  "y": "background"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_1",
  "x": [
   "Following recent speech translation <cite>[21]</cite> and recognition [28] models, the encoder is composed of a stack of 8 bidirectional LSTM layers."
  ],
  "y": "similarities uses"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_2",
  "x": [
   "We study two Spanish-to-English translation datasets: the large scale \"conversational\" corpus of parallel text and read speech pairs from <cite>[21]</cite> , and the Spanish Fisher corpus of telephone conversations and corresponding English translations [38] , which is smaller and more challenging due to the spontaneous and informal speaking style."
  ],
  "y": "similarities uses"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_3",
  "x": [
   "This proprietary dataset described in <cite>[21]</cite> was obtained by crowdsourcing humans to read the both sides of a conversational Spanish-English MT dataset."
  ],
  "y": "similarities uses"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_4",
  "x": [
   "In this section, instead of using the human target speech, we use a TTS model to synthesize target In addition, we augment the input source speech by adding background noise and reverberation in the same manner as <cite>[21]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_5",
  "x": [
   "Input feature frames are created by stacking 3 adjacent frames of an 80-channel log-mel spectrogram as in <cite>[21]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_6",
  "x": [
   "Table 2 shows performance of the model trained using different combinations of auxiliary losses, compared to a baseline ST \u2192 TTS cascade model using a speech-to-text translation model <cite>[21]</cite> trained on the same data, and the same Tacotron 2 TTS model used to synthesize training targets."
  ],
  "y": "similarities uses"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_7",
  "x": [
   "Finally, as in <cite>[21]</cite> , we find that pretraining the bottom 6 encoder layers on an ST task improves BLEU scores by over 5 points."
  ],
  "y": "similarities"
 },
 {
  "id": "831342435ca0a4695e2a7f149891e4_8",
  "x": [
   "Other future work includes utilizing weakly supervision to scale up training with synthetic data <cite>[21]</cite> or multitask learning [19, 20] , and transferring prosody and other acoustic factors from the source speech to the translated speech following [45] [46] [47] ."
  ],
  "y": "future_work"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_0",
  "x": [
   "There has been some, thus far limited, work on acoustic word embeddings, focused on a number of embedding models, training approaches, and tasks [10, 11, 12, 13,<cite> 14,</cite> 15, 16, 17] ."
  ],
  "y": "background"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_1",
  "x": [
   "Kamper et al.<cite> [14]</cite> compared several types of acoustic word embeddings for a word discrimination task related to query-by-example search, finding that embeddings based on convolutional neural networks (CNNs) trained with a contrastive loss outperformed the reference vector approach of Levin et al. [12] as well as several other CNN and DNN embeddings and DTW using several feature types."
  ],
  "y": "background"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_2",
  "x": [
   "As in <cite>[14,</cite> 11] , our first approach is to use the word labels of the training segments and train the networks to classify the word."
  ],
  "y": "similarities uses"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_4",
  "x": [
   "The second training approach, based on earlier work of Kamper et al.<cite> [14]</cite> , is to train \"Siamese\" networks [31] ."
  ],
  "y": "uses"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_5",
  "x": [
   "The acoustic features in each frame (the input to the word embedding models x t ) are 39-dimensional MFCCs+\u2206+\u2206\u2206. We use the same train, development, and test partitions as in prior work <cite>[14,</cite> 12] , and the same acoustic features as in<cite> [14]</cite> , for as direct a comparison as possible."
  ],
  "y": "uses"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_6",
  "x": [
   "As in<cite> [14]</cite> , when training the classificationbased embeddings, we use a subset of the training set containing all word types with a minimum of 3 occurrences, reducing the training set size to approximately 9k segments."
  ],
  "y": "similarities uses"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_7",
  "x": [
   "This is a slight departure from earlier work<cite> [14]</cite> , which we found to improve stability in training and performance on the development set."
  ],
  "y": "differences"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_10",
  "x": [
   "There is clear utility in stacking additional layers; however, even with 4 stacked layers the RNNs still underperform the CNN-based embeddings of<cite> [14]</cite> until we begin adding fully connected layers."
  ],
  "y": "differences"
 },
 {
  "id": "845c66e6dfafc21ab90e5aa5cbf947_12",
  "x": [
   "This analysis shows that the embeddings learned by the Siamese RNN network are quite robust to reduced dimensionality, outperforming the classifier model for all dimensionalities 32 or higher and outperforming previously reported dev set performance with CNN-based embeddings<cite> [14]</cite> for all dimensionalities \u2265 16."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_0",
  "x": [
   "We show that such representation together with nCCA, a successful multimodal embedding technique, achieves state-of-the-art performance on the <cite>Visual Madlibs task</cite>."
  ],
  "y": "uses"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_1",
  "x": [
   "Again, such approach achieves a significant improvement over the prior work that also uses CNN+LSTM approach on <cite>Visual Madlibs</cite>."
  ],
  "y": "differences motivation"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_2",
  "x": [
   "The recently introduced <cite>Visual Madlibs task</cite> <cite>[32]</cite> removes ambiguities in question or scene interpretations by introducing a multiple choice \"filling the blank\" task, where a c 2016."
  ],
  "y": "background"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_4",
  "x": [
   "Although related ideas have been explored for visual question answering [22] , and even have been used in <cite>Visual Madlibs</cite> <cite>[32]</cite> , we are first to show a significant improvement of such representation by using object proposals."
  ],
  "y": "differences motivation"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_5",
  "x": [
   "Our approach in the combination with the Normalized Correlation Analysis embedding technique improves on the state-of-the-art of the <cite>Visual Madlibs task</cite>."
  ],
  "y": "extends"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_6",
  "x": [
   "Text-Embedding Loss: Motivated by the popularity of deep architectures for visual question answering, that combine a global CNN image representation with an LSTM [7] question representation [4, 13, 17, 20, 29, 30, 31] , as well as the leading performance of nCCA on the multi-choice <cite>Visual Madlibs task</cite> <cite>[32]</cite> , we propose a novel extension of the CNN+LSTM architecture that chooses a prompt completion out of four candidates (see Figure 4 ) by measuring similarities directly in the embedding space."
  ],
  "y": "extends"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_7",
  "x": [
   "This contrasts with the prior approach of <cite>[32]</cite> that uses a post-hoc comparison between the discrete output of the CNN+LSTM method and all four candidates."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_8",
  "x": [
   "Such an approach integrates more tightly with the multi-choice filling the blanks task, and significantly outperforms the prior CNN+LSTM method <cite>[32]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_9",
  "x": [
   "While such ambiguities can be handled using appropriate metrics [14, 15, 17, 26] , <cite>Visual Madlibs</cite> <cite>[32]</cite> has taken another direction, and handles them directly within the task.",
   "<cite>It</cite> asks machines to fill the blank prompted with a natural language description with a phrase chosen from four candidate completions (Figure 4 )."
  ],
  "y": "background"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_10",
  "x": [
   "While a majority of the most recent work on visual question answering combine LSTM [7] with CNN [11, 23, 24] by concatenation or summation or piece-wise multiplication, Canonical Correlation Analysis (CCA and nCCA) [6] have also been shown to be a very effective multimodal embedding technique <cite>[32]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_11",
  "x": [
   "This puts CNN+LSTM approach closer to nCCA with a tighter integration with the multi-choice <cite>Visual Madlibs task</cite>."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_13",
  "x": [
   "This embedding method has shown outstanding performance on the <cite>Visual Madlibs task</cite> <cite>[32]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_14",
  "x": [
   "The improvement is consistent with the findings of <cite>[32]</cite> , where nCCA performs better than CCA by about five percentage points in average on the hard task."
  ],
  "y": "similarities"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_15",
  "x": [
   "On the other side, for each completion candidate s we compute its representation by averaging over word2vec [18] representations of the words contributing to s. However, in contrast to the prior work <cite>[32]</cite> , instead of comparing the discrete output of the network with the representation of s, we directly optimize an objective in the embedding space."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_17",
  "x": [
   "Although the CNN+LSTM models we trained on <cite>Madlibs</cite> were not quite as accurate as nCCA for selecting the correct multiple-choice answer, they did result in better, sometimes much better, accuracy (as measured by BLEU scores) for targeted generation."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_19",
  "x": [
   "We evaluate our method on the multiple choice task of the <cite>Visual Madlibs dataset</cite>.",
   "<cite>The dataset</cite> consists of about 360k descriptions, spanning 12 different categories specified by different types of templates, of about 10k images."
  ],
  "y": "uses background"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_20",
  "x": [
   "Finally, <cite>Visual Madlibs</cite> considers an easy and difficult tasks that differ in how the negative 3 candidate completions (distractors) are chosen."
  ],
  "y": "background"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_22",
  "x": [
   "Guided by the results of the previous experiments, we compare nCCA that uses Edge Boxes object proposals (nCCA (ours)) with the state-ofthe-arts on <cite>Visual Madlibs</cite> (nCCA <cite>[32]</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_23",
  "x": [
   "The models are trained per category (a model trained over all the categories performs inferior on the hard task <cite>[32]</cite> )."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_24",
  "x": [
   "To see the limits, we compare nCCA (ours) against nCCA (bbox) <cite>[32]</cite> that crops over ground truth bounding boxes from MS COCO segmentations and next averages over theirs representations (Table 3 in <cite>[32]</cite> shows that ground truth bounding boxes outperforms automatically detected bounding boxes, and hence they can be seen as an upper bound for a detection method trained to detect objects on MS COCO)."
  ],
  "y": "differences uses"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_25",
  "x": [
   "On one hand nCCA tops the leaderboard on the <cite>Visual Madlibs task</cite> <cite>[32]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_26",
  "x": [
   "Table 5 : Comparison between our Embedded CNN+LSTM approach that computes the similarity between input and candidate answers in the embedding space, and the plain CNN+LSTM original approach from <cite>[32]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_27",
  "x": [
   "Since the accuracies of CNN+LSTM <cite>[32]</cite> are unavailable for two categories, we report average over 10 categories in this case."
  ],
  "y": "uses"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_28",
  "x": [
   "This contrasts to a post-hoc process used in <cite>[32]</cite> where an image description architecture (CNN+LSTM) first generates a completion that is next compared against the candidates in the word2vec space (see section 3 for more details)."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_29",
  "x": [
   "This contrasts to a post-hoc process used in <cite>[32]</cite> where an image description architecture (CNN+LSTM) first generates a completion that is next compared against the candidates in the word2vec space (see section 3 for more details)."
  ],
  "y": "extends"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_30",
  "x": [
   "Our \"Embedded CNN+LSTM\" outperforms other methods on both tasks confirming our hypothesis. \"Ask Your Neurons\" [17] is also slightly better than the original CNN+LSTM <cite>[32]</cite> (on the 10 categories that the results for CNN+LSTM are available it achieves 49.8% accuracy on the easy task, which is 2.1 percentage points higher than CNN+LSTM)."
  ],
  "y": "differences"
 },
 {
  "id": "866cc7036c626f07fba10ab2a839d8_31",
  "x": [
   "We study an image representation formed by averaging over representations of object proposals, and show its effectiveness through experimental evaluation on the <cite>Visual Madlibs dataset</cite> <cite>[32]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "87a190b1df5a7a941ba7b9a98064a3_0",
  "x": [
   "Similar to<cite> Zhang et al. (2006)</cite> , we employ a convolution parse tree kernel in order to model syntactic structures."
  ],
  "y": "similarities uses"
 },
 {
  "id": "87a190b1df5a7a941ba7b9a98064a3_1",
  "x": [
   "We employ the same convolution tree kernel used by Collins and Duffy (2001) , Moschitti (2004) and<cite> Zhang et al. (2006)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "87a190b1df5a7a941ba7b9a98064a3_2",
  "x": [
   "(1) Compressed Path-enclosed Tree (CPT, T1 in Fig.1 ): Originated from PT in<cite> Zhang et al. (2006)</cite> , we further make two kinds of compression."
  ],
  "y": "uses"
 },
 {
  "id": "87a190b1df5a7a941ba7b9a98064a3_3",
  "x": [
   "This case is also explored by<cite> Zhang et al. (2006)</cite> , and we include it here just for the purpose of comparison."
  ],
  "y": "similarities"
 },
 {
  "id": "87a190b1df5a7a941ba7b9a98064a3_4",
  "x": [
   "Compared with the composite kernel<cite> (Zhang et al, 2006)</cite> , our system further prunes the parse tree and incorporates entity features into the convolution parse tree kernel."
  ],
  "y": "differences"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_0",
  "x": [
   "The first attempt to build an end-to-end speech-to-text translation system (which does not use source language) is <cite>our own work</cite> <cite>[2]</cite> but it was applied to a synthetic (TTS) speech corpus."
  ],
  "y": "background"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_1",
  "x": [
   "This paper is a follow-up of <cite>our previous work</cite> <cite>[2]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_2",
  "x": [
   "While previous works <cite>[2,</cite> 3] investigated the extreme case where source language transcription is not available during learning nor decoding (unwritten language scenario defined in [6, 7] ), we also investigate, in this paper, a midway case where a certain amount of source language transcription is available during training."
  ],
  "y": "extends"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_3",
  "x": [
   "Section 4 describes our evaluation on two datasets: the synthetic dataset used in <cite>[2]</cite> and the audiobook dataset described in section 2."
  ],
  "y": "uses"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_4",
  "x": [
   "We also mirror our experiments on the BTEC synthetic speech corpus, as a follow-up to <cite>[2]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_5",
  "x": [
   "For the three tasks, we use encoder-decoder models with attention [9, 10, 11, <cite>2,</cite> 3] ."
  ],
  "y": "uses"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_6",
  "x": [
   "The speech encoder is a mix between the convolutional encoder presented in [3] and our previously proposed encoder <cite>[2]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_7",
  "x": [
   "Like <cite>[2]</cite> , these features are given as input to two non-linear (tanh) layers, which output new features of size n ."
  ],
  "y": "similarities"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_8",
  "x": [
   "Speech files were preprocessed using Yaafe [13] , to extract 40 MFCC features and frame energy for each frame with a step size of 10 ms and window size of 40 ms, following [14, <cite>2]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_9",
  "x": [
   "Contrary to <cite>[2]</cite> , we only present mono-reference results."
  ],
  "y": "differences"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_10",
  "x": [
   "The large improvements on MT and AST on the BTEC corpus, compared to <cite>[2]</cite> are mostly due to our use of a better decoder, which outputs characters instead of words."
  ],
  "y": "differences"
 },
 {
  "id": "87a87855d67d90c691ab5bedb4d460_11",
  "x": [
   "We present baseline results on End-to-End Automatic Speech Translation on a new speech translation corpus of audiobooks, and on a synthetic corpus extracted from BTEC (follow-up to <cite>[2]</cite> )."
  ],
  "y": "extends"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_0",
  "x": [
   "Very recently, <cite>[8]</cite> proposed a multi-modal <cite>encoder-decoder framework</cite> that, given an image caption, jointly predicts another caption and the features of associated image."
  ],
  "y": "background"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_1",
  "x": [
   "Very recently, <cite>[8]</cite> proposed a multi-modal <cite>encoder-decoder framework</cite> that, given an image caption, jointly predicts another caption and the features of associated image.",
   "<cite>The work</cite> showed promising results for further improving general sentence representations by grounding them visually.",
   "However, according to <cite>the model</cite>, visual association only occurs at the final hidden state of the encoder, potentially limiting the effect of visual grounding."
  ],
  "y": "motivation"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_2",
  "x": [
   "Very recently, <cite>[8]</cite> proposed a multi-modal <cite>encoder-decoder framework</cite> that, given an image caption, jointly predicts another caption and the features of associated image.",
   "<cite>The work</cite> showed promising results for further improving general sentence representations by grounding them visually."
  ],
  "y": "background"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_3",
  "x": [
   "Very recently, <cite>[8]</cite> proposed a multi-modal <cite>encoder-decoder framework</cite> that, given an image caption, jointly predicts another caption and the features of associated image.",
   "<cite>The work</cite> showed promising results for further improving general sentence representations by grounding them visually.",
   "However, according to <cite>the model</cite>, visual association only occurs at the final hidden state of the encoder, potentially limiting the effect of visual grounding."
  ],
  "y": "motivation"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_4",
  "x": [
   "There have been significant studies focusing on improving word embeddings [16, 17] , phrase embeddings [18] , sentence embeddings <cite>[8</cite>, 19] , language models [20] through multi-modal learning of vision and language."
  ],
  "y": "background"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_5",
  "x": [
   "Among all studies, <cite>[8]</cite> is the first to apply skip-gram-like intuition (predicting multiple modalities from langauge) to joint learning of language and vision in the perspective of general sentence representations."
  ],
  "y": "background"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_6",
  "x": [
   "There have been significant studies focusing on improving word embeddings [16, 17] , phrase embeddings [18] , sentence embeddings <cite>[8</cite>, 19] , language models [20] through multi-modal learning of vision and language.",
   "Among all studies, <cite>[8]</cite> is the first to apply skip-gram-like intuition (predicting multiple modalities from langauge) to joint learning of language and vision in the perspective of general sentence representations."
  ],
  "y": "background"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_7",
  "x": [
   "We base our model on the <cite>encoder-decoder framework</cite> introduced in <cite>[8]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_8",
  "x": [
   "Although margin ranking loss has been the dominant choice for training cross-modal feature matching <cite>[8</cite>, 20, 25] , we find that log-exp-sum pairwise ranking [26] yields better results in terms of evaluation performance and efficiency."
  ],
  "y": "differences"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_9",
  "x": [
   "Following the experimental design of <cite>[8]</cite> , we conduct experiments on three different learning objectives: CAP2ALL, CAP2CAP, CAP2IMG."
  ],
  "y": "uses"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_10",
  "x": [
   "We evaluate sentence representation quality using SentEval 2 <cite>[8</cite>, 10] scripts."
  ],
  "y": "uses"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_11",
  "x": [
   "Adhering to the experimental settings of <cite>[8]</cite> , we concatenate sentence representations produced from our model with those obtained from the state-of-the-art unsupervised learning model (Layer Normalized Skip-Thoughts, ST-LN) [33] ."
  ],
  "y": "uses"
 },
 {
  "id": "87af486eb2e968d2055eeab094b3f9_12",
  "x": [
   "These findings show that visually grounding self-attended sentence representations helps to expose word-level visual features onto sentence representations <cite>[8]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "88900d3533701056f6a26bf7c68670_0",
  "x": [
   "Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005;<cite> Kate and Mooney, 2006)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "88900d3533701056f6a26bf7c68670_1",
  "x": [
   "Several learning systems have been developed for semantic parsing, many of them recently (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Ge and Mooney, 2005;<cite> Kate and Mooney, 2006)</cite> ."
  ],
  "y": "differences background"
 },
 {
  "id": "88900d3533701056f6a26bf7c68670_2",
  "x": [
   "We modify KRISP, a supervised learning system for semantic parsing presented in<cite> (Kate and Mooney, 2006)</cite> , to make a semi-supervised system we call SEMISUP-KRISP."
  ],
  "y": "extends"
 },
 {
  "id": "88900d3533701056f6a26bf7c68670_3",
  "x": [
   "Learning System KRISP (Kernel-based Robust Interpretation for Semantic Parsing) <cite>(Kate and Mooney, 2006</cite> ) is a supervised learning system for semantic parsing which takes NL sentences paired with their MRs as training data."
  ],
  "y": "background"
 },
 {
  "id": "88900d3533701056f6a26bf7c68670_4",
  "x": [
   "Experimentally, KRISP compares favorably to other existing semantic parsing systems and is particularly robust to noisy training data<cite> (Kate and Mooney, 2006)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "891d0e17bf2fb79a378c2d77dda768_0",
  "x": [
   "While application of attention [3, 4] and advanced decoding mechanisms like beam search and variation sampling <cite>[5]</cite> have shown improvements, it does not solve the underlying problem."
  ],
  "y": "motivation"
 },
 {
  "id": "891d0e17bf2fb79a378c2d77dda768_1",
  "x": [
   "Outputs are generated through sampling over a multinomial distribution for all methods, instead of argmax on the log-likelihood probabilities, as sampling has shown to produce better output quality <cite>[5]</cite> . Please refer to Supplementary Section Table 3 for training parameters of each dataset and Table 2 for hyperparameters of each encoder."
  ],
  "y": "motivation"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_0",
  "x": [
   "In our previous work<cite> (Papegnies et al., 2019)</cite> , we proposed a radically different method that completely ignores the textual content of the messages, and relies only on a graph-based modeling of the conversation."
  ],
  "y": "background"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_1",
  "x": [
   "Additional references on abusive message detection and conversational network modeling can be found in<cite> (Papegnies et al., 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_2",
  "x": [
   "For this purpose, we take advantage of the content- (Papegnies et al., 2017b) and graph-based<cite> (Papegnies et al., 2019</cite> ) methods that we previously developed."
  ],
  "y": "extends"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_3",
  "x": [
   "For this purpose, we take advantage of the content- (Papegnies et al., 2017b) and graph-based<cite> (Papegnies et al., 2019</cite> ) methods that we previously developed."
  ],
  "y": "uses"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_4",
  "x": [
   "In this section, we summarize the content-based method from (Papegnies et al., 2017b ) (Section 2.1) and the graph-based method from<cite> (Papegnies et al., 2019</cite> ) (Section 2.2)."
  ],
  "y": "background"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_5",
  "x": [
   "Existing methods refers to our previous work described in (Papegnies et al., 2017b ) (content-based method) and<cite> (Papegnies et al., 2019)</cite> (graph-based method), whereas the contribution presented in this article appears on the right side (fusion strategies)."
  ],
  "y": "uses"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_6",
  "x": [
   "It completely ignores the content of the messages, and only focuses on the dynamics of the conversation, based on the interactions between its participants<cite> (Papegnies et al., 2019)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_7",
  "x": [
   "In this work, we use exactly the same measures as in<cite> (Papegnies et al., 2019)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_8",
  "x": [
   "The dataset is the same as in our previous publications (Papegnies et al., 2017b <cite>(Papegnies et al., , 2019</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_9",
  "x": [
   "We use the values matching the best performance, obtained during the greedy search of the parameter space performed in<cite> (Papegnies et al., 2019)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_10",
  "x": [
   "Table 1 presents the Precision, Recall and F -measure scores obtained on the Abuse class, for both baselines (Content-based (Papegnies et al., 2017b) and Graph-based<cite> (Papegnies et al., 2019)</cite> ) and all three proposed fusion strategies (Early Fusion, Late Fusion and Hybrid Fusion)."
  ],
  "y": "uses"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_11",
  "x": [
   "The Graph-Based TF are discussed in depth in our previous article<cite> (Papegnies et al., 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8abb7b77fd6996a905395de9693d42_12",
  "x": [
   "We take advantage of the methods that we previously developed to leverage message content (Papegnies et al., 2017a) and interactions between users<cite> (Papegnies et al., 2019)</cite> , and create a new method using both types of information simultaneously."
  ],
  "y": "extends"
 },
 {
  "id": "8abffa3f807bad5ae2073aa7db215d_0",
  "x": [
   "Another different context type is dependency-based word embedding <cite>[11,</cite> 12, 13] , which considers syntactic contexts rather"
  ],
  "y": "background"
 },
 {
  "id": "8abffa3f807bad5ae2073aa7db215d_1",
  "x": [
   "Another different context type is dependency-based word embedding <cite>[11,</cite> 12, 13] , which considers syntactic contexts rather"
  ],
  "y": "background"
 },
 {
  "id": "8abffa3f807bad5ae2073aa7db215d_2",
  "x": [
   "Bansal et al. [8] and <cite>Melamud et al. [11]</cite> show the benefits of such modified-context embeddings in dependency parsing task."
  ],
  "y": "background"
 },
 {
  "id": "8b223f35a4685d6627d29c907e4742_0",
  "x": [
   "Caliskan et al. proposed Word Embedding Association Test (WEAT) to computationally measure biases in any text repository <cite>[5]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8b223f35a4685d6627d29c907e4742_1",
  "x": [
   "Caliskan et al. proposed Word Embedding Association Test (WEAT) to computationally measure biases in any text repository <cite>[5]</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "8b223f35a4685d6627d29c907e4742_2",
  "x": [
   "Caliskan et al. designed the Word Embedding Association Test (WEAT) by tweaking the IAT test <cite>[5]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8b223f35a4685d6627d29c907e4742_3",
  "x": [
   "We borrowed these attribute and target word sets from Caliskan et al. <cite>[5]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8b5e14bdf3f415725333de672be114_0",
  "x": [
   "More advanced machine learning techniques such as classification and regression have been applied to the task of reading level prediction (Collins- Thompson and Callan, 2004; Schwarm and Ostendorf, 2005; Petersen and Ostendorf, 2009; <cite>Feng et al., 2010)</cite> ; such works are described in further detail in the next Section 2."
  ],
  "y": "background"
 },
 {
  "id": "8b5e14bdf3f415725333de672be114_1",
  "x": [
   "At the same time, we have also extended our previous feature set by introducing a richer set of automatically derived textbased features, proposed by<cite> Feng et al. (2010)</cite> , which capture deeper syntactic complexities of the text."
  ],
  "y": "uses"
 },
 {
  "id": "8b5e14bdf3f415725333de672be114_2",
  "x": [
   "A detailed analysis of various features for automatic readability assessment has been done by<cite> Feng et al. (2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8b5e14bdf3f415725333de672be114_3",
  "x": [
   "We utilize the Stanford Parser (Klein and Manning, 2003) to extract the following features from the XML files based on those used in<cite> (Feng et al., 2010)</cite> :"
  ],
  "y": "uses"
 },
 {
  "id": "8b5e14bdf3f415725333de672be114_4",
  "x": [
   "As mentioned above, the second aim of this study is to see how much benefit we can get from incorporating high-level structural features, such as those used in<cite> (Feng et al., 2010)</cite> (described in Section 4.2), with the features in our previous study."
  ],
  "y": "uses"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_0",
  "x": [
   "Recent work has begun to model different aspects of these naturally occurring lay arguments, with tasks including stance classification (Somasundaran and Wiebe, 2009; Walker et al., 2012) , argument summarization (Misra et al., 2015) , sarcasm detection (Justo et al., 2014) and classification of propositions and arguments <cite>(Park and Cardie, 2014</cite>; Park et al., 2015; Oraby et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_1",
  "x": [
   "The first of these studies<cite> (Park and Cardie, 2014)</cite> compiled online user comments from a discussion website and developed a framework for automatically classifying each proposition as either \"unverifiable\", \"verifiable non-experiential\", or \"verifiable experiential\", where the appropriate types of support are reason, evidence, and optional evidence, respectively."
  ],
  "y": "background"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_2",
  "x": [
   "In classifying propositions,<cite> Park and Cardie (2014)</cite> followed previous work such as Reed et al. (2008) and Palau and Moens (2009) , employing supervised learning methods."
  ],
  "y": "background"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_3",
  "x": [
   "In classifying propositions,<cite> Park and Cardie (2014)</cite> followed previous work such as Reed et al. (2008) and Palau and Moens (2009) , employing supervised learning methods."
  ],
  "y": "differences motivation"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_4",
  "x": [
   "(Merely using clause tags without capturing dependencies for important clauses may not help much in distinguishing objective verifiable claims from unverifiable subjective ones.)<cite> Park and Cardie (2014)</cite> also used tense and person counts for distinguishing verifiable claims from unverifiable claims."
  ],
  "y": "background"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_5",
  "x": [
   "(Merely using clause tags without capturing dependencies for important clauses may not help much in distinguishing objective verifiable claims from unverifiable subjective ones.)<cite> Park and Cardie (2014)</cite> also used tense and person counts for distinguishing verifiable claims from unverifiable claims."
  ],
  "y": "extends"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_6",
  "x": [
   "In online argumentative discourse, claims often serve as implicit arguments with inappropriate or missing justification<cite> (Park and Cardie, 2014)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_7",
  "x": [
   "2<cite> Park and Cardie (2014)</cite> and Park et al. (2015) used this corpus for examining each proposition with respect to its verifiability to determine the desirable types of support for the analysis of arguments."
  ],
  "y": "background"
 },
 {
  "id": "8c202e3610599c9eee23724ef213de_8",
  "x": [
   "2<cite> Park and Cardie (2014)</cite> and Park et al. (2015) used this corpus for examining each proposition with respect to its verifiability to determine the desirable types of support for the analysis of arguments."
  ],
  "y": "similarities"
 },
 {
  "id": "8c530e0c9f7256ac44b1a2adfaf6a9_0",
  "x": [
   "Since, emotion detection is a classification problem, research works have been carried out by using machine learning with lexical features (Sharma et al., 2017) and deep learning with deep neural network (Phan et al., 2016) and convolutional neural network<cite> (Zahiri and Choi, 2018)</cite> to detect the emotions from text."
  ],
  "y": "background"
 },
 {
  "id": "8c530e0c9f7256ac44b1a2adfaf6a9_1",
  "x": [
   "This section reviews the research work reported for emotion detection from text / tweets (Perikos and Hatzilygeroudis, 2013; Rao, 2016; AbdulMageed and Ungar, 2017; Samy et al., 2018; AlBalooshi et al., 2018; Gaind et al., 2019 ) and text conversations (Phan et al., 2016; Sharma et al., 2017;<cite> Zahiri and Choi, 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8c530e0c9f7256ac44b1a2adfaf6a9_2",
  "x": [
   "Instead of using basic CNN, a new recurrent sequential CNN is used by <cite>Zahiri and Choi (2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8c530e0c9f7256ac44b1a2adfaf6a9_3",
  "x": [
   "Instead of using basic CNN, a new recurrent sequential CNN is used by <cite>Zahiri and Choi (2018)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "8dbc779d455ad72def6654564f9e13_0",
  "x": [
   "Here we investigate the unsupervised word discovery and segmentation task, using the bilingual-rooted approach from <cite>Godard et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8dbc779d455ad72def6654564f9e13_1",
  "x": [
   "2 Bilingual Unsupervised Word Segmentation/Discovery Approach: We use the bilingual neuralbased Unsupervised Word Segmentation (UWS) approach from <cite>Godard et al. (2018)</cite> to discover words in Mboshi."
  ],
  "y": "uses"
 },
 {
  "id": "8dbc779d455ad72def6654564f9e13_2",
  "x": [
   "Multilingual Leveraging: In this work we apply two simple methods for including multilingual information into the bilingual models from <cite>Godard et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8e0dcaec15a3b9c4947946a4e885c8_0",
  "x": [
   "Most recent work<cite> (Bao and Bollegala, 2018</cite> ) has focused on the use of an autoencoder (AE) to encode a set of N pretrained embeddings using 3 different variants: (1) Decoupled Autoencoded Meta Embeddings (DAEME) that keep activations separated for each respective embedding input during encoding and uses a reconstruction loss for both predicted embeddings while minimizing the loss for each respective decoded output, (2) Coupled Autoencoded Meta Embeddings (CAEME) which instead learn to predict from a shared encoding and (3) Averaged Autoencoded Meta-Embedding (AAME) is simply an averaging of the embedding set as input instead of using a concatenation."
  ],
  "y": "background"
 },
 {
  "id": "8e0dcaec15a3b9c4947946a4e885c8_1",
  "x": [
   "Before describing the loss functions used, we explain the aforementioned variation on the autoencoding method and how it slightly differs from 1TON/1TON + (Yin and Sch\u00fctze, 2015) and standard AEs<cite> (Bao and Bollegala, 2018)</cite> presented in previous work."
  ],
  "y": "differences uses"
 },
 {
  "id": "8e0dcaec15a3b9c4947946a4e885c8_2",
  "x": [
   "Figure 2 shows a comparison of the previous autoencoder approaches<cite> (Bao and Bollegala, 2018)</cite> (left) and the alternative AE (right), where dashed lines indicate connections during training and bold lines indicate prediction."
  ],
  "y": "uses background"
 },
 {
  "id": "8e0dcaec15a3b9c4947946a4e885c8_3",
  "x": [
   "As stated, we compare against previous methods (Yin and Sch\u00fctze, 2015;<cite> Bao and Bollegala, 2018</cite> ) that use 2 distance, as shown in Equation 1)."
  ],
  "y": "uses"
 },
 {
  "id": "8e0dcaec15a3b9c4947946a4e885c8_4",
  "x": [
   "Table 1 shows the scaled Spearman correlation test scores, where (1) shows the original single embeddings, (2) results for standard metaembedding approaches that either apply a single mathematical operation or employ a linear projection as an encoding, (3) presents the results using autoencoder schemes by<cite> (Bao and Bollegala, 2018</cite> ) that we have used to test the various losses, (4) introduces TAE without concatenating the target Y embedding post-training with MSE loss and (5) shows the results of concatenating Y with the lower-dimensional (200-dimensions) vector that encodes all embeddings apart from the target vector."
  ],
  "y": "uses"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_0",
  "x": [
   "However, as pointed out in (Murray et al., 2010) and<cite> (Oya et al., 2014)</cite> , abstractive summaries are preferred to extractive ones by human judges."
  ],
  "y": "motivation"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_1",
  "x": [
   "Abstractive conversation summarization systems, on the other hand, are mainly based on the extraction of lexical information (Mehdad et al., 2013; <cite>Oya et al., 2014)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_2",
  "x": [
   "The heuristics are evaluated within the template-based abstractive summarization system of<cite> Oya et al. (2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_3",
  "x": [
   "Template Generation follows the approach of<cite> (Oya et al., 2014)</cite> and, starting from human-authored summaries, produces abstract templates applying slot labeling, summary clustering and template fusion steps."
  ],
  "y": "uses"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_4",
  "x": [
   "The clustered templates are further generalized using a word graph algorithm extended to templates in<cite> (Oya et al., 2014)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_5",
  "x": [
   "In this paper, different from<cite> (Oya et al., 2014)</cite> , the sentence ranking is based solely on the n-gram language models trained on the tokens and part-ofspeech tags from the human-authored summaries."
  ],
  "y": "differences"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_6",
  "x": [
   "Following<cite> (Oya et al., 2014)</cite> , we removed 20 dialogs used by the authors for development, and use the remaining dialogs for the threefold cross-validation."
  ],
  "y": "uses"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_7",
  "x": [
   "For AMI corpus, following<cite> (Oya et al., 2014)</cite> , we report ROUGE-2 F-measures on 3-fold cross-validation."
  ],
  "y": "uses"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_8",
  "x": [
   "For AMI corpus, on the other hand, we compare performances to the abstractive systems reported in<cite> (Oya et al., 2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8ef47e16cd41aa3a606cf21c41adb7_9",
  "x": [
   "In the table we also report the performances of the previously published summarization systems that make use of the manual communities -<cite> (Oya et al., 2014)</cite> and (Mehdad et al., 2013) ; and our run of the system of<cite> (Oya et al., 2014)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "8f0aab7fd30ffc56cc477b25e6bb16_0",
  "x": [
   "His chief focus is on semantic relations in FrameNet (Ruppenhofer et al. 2006) , how they can be used for paraphrase <cite>(Ellsworth & Janin 2007)</cite> , and mapping to other resources (Sche\u21b5czyk & Ellsworth 2006; Ferr\u00e1ndez et al. 2010b) ."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_0",
  "x": [
   "Top row: baseline approach by Zellers et al. <cite>[18]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_1",
  "x": [
   "As the task is new, Zellers et al. <cite>[18]</cite> provided a new baseline for it which seeks to tackle the task of predicting answers and predicting rationales separately."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_2",
  "x": [
   "The Visual Commonsense Reasoning task, Zellers et al. <cite>[18]</cite> answers are predicted given the question and image and then, rationales are predicted given the image and question with the correct answer (see figure 1 and 2)."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_3",
  "x": [
   "Precisely, the task is introduced and formulated in <cite>[18]</cite> as follows: given an image and a question related to the image, the model has to predict the correct answer from four possible choices and at the same time, it has to pick the right rationale, again from four options."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_4",
  "x": [
   "Concurrently, it makes our approaches incomparable to the baselines provided by Zellers et al. <cite>[18]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_5",
  "x": [
   "The task in Zellers et al. <cite>[18]</cite> is essentially posed as a question-answering task."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_6",
  "x": [
   "Anderson et al. [1] propose an orthogonal work to <cite>[18]</cite> , in which Faster-RCNN [15] is used to predict the image regions the model should attend to."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_7",
  "x": [
   "We note the difference from our current proposed work -annotations are provided in the VCR 1.0 dataset <cite>[18]</cite> in form of bounding box and segmentation maps."
  ],
  "y": "differences"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_8",
  "x": [
   "Zellers et al. <cite>[18]</cite> propose to jointly learn language and image representation using Bi-LSTM by feeding in image features from CNN for all annotated words."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_9",
  "x": [
   "We seek to build on <cite>[18]</cite> by proposing a method to jointly train prediction and reasoning networks."
  ],
  "y": "extends"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_10",
  "x": [
   "We use the same backbone architecture to predict answers and rationales as in <cite>[18]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_11",
  "x": [
   "<cite>[18]</cite> call this step Grounding."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_12",
  "x": [
   "The dataset used in all experiments in this work is VCR 1.0 <cite>[18]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_13",
  "x": [
   "We train the model using the whole VCR dataset for 20 epochs as was done in <cite>[18]</cite> to align with the baselines."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_14",
  "x": [
   "As mentioned earlier, our approach is not directly comparable to the baseline provided by Zellers et al. <cite>[18]</cite> since they feed the correct answer to the rationale module while we feed in the predicted answer."
  ],
  "y": "differences"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_15",
  "x": [
   "Finally, we train the two networks separately and combine the results of answer prediction module and rationale prediction module using \"AND\" operation as was done by Zellers et al. <cite>[18]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_16",
  "x": [
   "For completeness, we also mention the results of four other baselines from <cite>[18]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_17",
  "x": [
   "These baseline methods use the ResNet-50 (same as <cite>[18]</cite> ) visual architecture and Glove as text representations."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_18",
  "x": [
   "\u2022 Bottom-up and Top-down attention (BottomUpTop-Down) [1] : <cite>[18]</cite> adopted this model as another baseline by passing object regions referenced by the query and response."
  ],
  "y": "background"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_19",
  "x": [
   "Rather, a weighted average of answers (according to probabilities predicted by Q->A module) is provided to the rationale prediction module, unlike the baseline <cite>[18]</cite> , which gives the correct answer as input."
  ],
  "y": "differences"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_20",
  "x": [
   "We also summarize results of other baselines reported in <cite>[18]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "90604f1ab33aafff682df0556aaa4e_21",
  "x": [
   "As can be seen from table 3, our Gumbel-softmax method performs better than the baseline <cite>[18]</cite> in Q->A task."
  ],
  "y": "differences"
 },
 {
  "id": "91685660d3d689c50e7436be46f37e_0",
  "x": [
   "Using a multilayer convolutional encoder-decoder neural network GEC approach<cite> (Chollampatt and Ng, 2018)</cite>, we evaluate the contribution of Wikipedia edits and find that carefully selected Wikipedia edits increase performance by over 5%."
  ],
  "y": "uses"
 },
 {
  "id": "91685660d3d689c50e7436be46f37e_1",
  "x": [
   "On the basis of these resources along with advances in machine translation, the current state-of-the-art English GEC systems use ensembles of neural MT models<cite> (Chollampatt and Ng, 2018)</cite> and hybrid systems with both statistical and neural MT models (Grundkiewicz and Junczys-Dowmunt, 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "91685660d3d689c50e7436be46f37e_2",
  "x": [
   "We create a new GEC corpus for German along with the models needed for the neural GEC approach presented in <cite>Chollampatt and Ng (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "91685660d3d689c50e7436be46f37e_3",
  "x": [
   "As suggested by <cite>Chollampatt and Ng (2018)</cite> , we encode the Wikipedia article text using the BPE model and learn fastText embeddings (Bojanowski et al., 2017) with 500 dimensions."
  ],
  "y": "uses"
 },
 {
  "id": "91685660d3d689c50e7436be46f37e_4",
  "x": [
   "We evaluate the effect of extending the Falko-MERLIN GEC Corpus with Wikipedia edits for a German GEC system using the multilayer convolutional encoder-decoder neural network approach from <cite>Chollampatt and Ng (2018)</cite> , using the same parameters as for English."
  ],
  "y": "uses"
 },
 {
  "id": "91685660d3d689c50e7436be46f37e_6",
  "x": [
   "We evaluate our method using the multilayer convolutional encoder-decoder neural network GEC approach from <cite>Chollampatt and Ng (2018)</cite> and find that augmenting a small gold German GEC corpus with one million filtered Wikipedia edits improves the performance from 39.22 to 44.47 F 0.5 and additional language model reranking increases performance to 45.22."
  ],
  "y": "uses"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_0",
  "x": [
   "<cite>Li and Roth (2002)</cite> use a Sparse Network of Winnows (SNoW) to classify questions with respect to their expected answer type."
  ],
  "y": "background"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_1",
  "x": [
   "Zhang and Lee (2003) used the same taxonomy as <cite>Li and Roth (2002)</cite> , as well as the same training and testing data."
  ],
  "y": "background"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_2",
  "x": [
   "The same taxonomy, training and testing data was used as in <cite>Li and Roth (2002)</cite>"
  ],
  "y": "similarities uses"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_3",
  "x": [
   "The taxonomy used is the taxonomy proposed by <cite>Li and Roth (2002)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_4",
  "x": [
   "This taxonomy has been chosen since it is the most frequently used one in earlier work in the field<cite> (Li and Roth, 2002</cite>; Zhang and Lee, 2003; Hacioglu and Ward, 2003) ."
  ],
  "y": "background"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_5",
  "x": [
   "The corpora used is both the corpus constructed and tagged by <cite>Li and Roth (2002)</cite> , as well as a newly tagged corpus extracted from the AnswerBus logs."
  ],
  "y": "similarities uses"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_6",
  "x": [
   "First, we have used the corpus originally developed by<cite> (Li and Roth, 2002)</cite> , but since the test corpus used consists of questions solely from TREC-10 and the TREC conferences have a specific agenda the test corpus might be slightly different from the training data."
  ],
  "y": "differences extends"
 },
 {
  "id": "918caabbc0bcad04cd07761b29e767_7",
  "x": [
   "The results in this paper indicate that some of the results found in previous work<cite> (Li and Roth, 2002</cite>; Zhang and Lee, 2003; Hacioglu and Ward, 2003) on question classification might be incorrect due to an unbiased training and test corpus."
  ],
  "y": "background"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_0",
  "x": [
   "Evaluated by human graders on 500 random-selected triples from Freebase, questions generated by our system are judged to be more fluent than those of <cite>Serban et al. (2016)</cite> by human graders."
  ],
  "y": "differences"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_1",
  "x": [
   "To tackle this challenge, previous work (Seyler et al., 2015; <cite>Serban et al., 2016</cite> ) relies on massive human-labeled data."
  ],
  "y": "background"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_2",
  "x": [
   "Treating question generation as a machine translation problem, <cite>Serban et al. (2016)</cite> train a neural machine translation (NMT) system with 10,000 triple 1 , question pairs."
  ],
  "y": "background"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_3",
  "x": [
   "In our experiment, we compare with <cite>Serban et al. (2016)</cite> on 500 random selected triples from Freebase (Bollacker et al., 2008) ."
  ],
  "y": "uses"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_4",
  "x": [
   "Evaluated by 3 human graders, questions generated by our system are significantly better then <cite>Serban et al. (2016)</cite> on grammaticality and naturalness."
  ],
  "y": "differences"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_5",
  "x": [
   "For System grammatical naturalness <cite>Serban et al. (2016)</cite> 3.36 3.14 Ours 3.53 3.31 Table 1 : Comparing generated questions domain relevance, we take the seed question set as the in-domain data D in , the domain relevance of expanded question q is defined as:"
  ],
  "y": "differences"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_6",
  "x": [
   "In the first experiment, we compare our end-to-end system with the previous state-of-the-art method <cite>(Serban et al., 2016)</cite> on Freebase (Bollacker et al., 2008) , a domain-general KB."
  ],
  "y": "uses"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_7",
  "x": [
   "We first compare our system with <cite>Serban et al. (2016)</cite> on 500 randomly selected triples from Freebase (Bollacker et al., 2008) 2 ."
  ],
  "y": "uses"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_8",
  "x": [
   "Using the averaged language model score as index, the top 500 questions are selected to compare with the results from <cite>Serban et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_9",
  "x": [
   "We show the averaged human rate in Table 2 , where we can see that our questions are more grammatical and natural than <cite>Serban et al. (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_10",
  "x": [
   "Shown in Table 1 , we compare our questions with <cite>Serban et al. (2016)</cite> where questions in the same line describe the same entity."
  ],
  "y": "uses"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_11",
  "x": [
   "On the other hand, questions from <cite>Serban et al. (2016)</cite> Ma et al. (2015) 85.48 Ours 85.65 Table 3 : Precision on the web snippet dataset was someone who was involved in the leukemia ?\" and \"whats the title of a book of the subject of the bible ?\"), unnatural (\"what 's one of the mountain where can you found in argentina in netflix ?\") or confusing (\"who was someone who was involved in the leukemia ?\")."
  ],
  "y": "differences"
 },
 {
  "id": "91e4fd2556d4a04e477ea97208b218_12",
  "x": [
   "Evaluated by human graders, questions generated by our system are significantly better than these from <cite>Serban et al. (2016)</cite> on 500 random-selected triples from Freebase."
  ],
  "y": "differences"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_0",
  "x": [
   "Results presented by <cite>Tseng (2001)</cite> show that speakers of Mandarin adopt some 30 words for building core structures of utterances in conversation, independently of individual speakers."
  ],
  "y": "background"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_1",
  "x": [
   "Interestingly but also expected in conversational dialogues, the distribution of token frequency across all subjects is highly symmetric<cite> (Tseng 2001)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_2",
  "x": [
   "They are very often observed in Mandarin spoken conversations as mentioned in <cite>Tseng (2001)</cite> and Clancy et al. (1996) ."
  ],
  "y": "background"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_3",
  "x": [
   "In <cite>Tseng (2001)</cite> , each subject used on average 1.6 discourse particles per turn."
  ],
  "y": "background"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_4",
  "x": [
   "They are very often observed in Mandarin spoken conversations as mentioned in <cite>Tseng (2001)</cite> and Clancy et al. (1996) .",
   "In <cite>Tseng (2001)</cite> , each subject used on average 1.6 discourse particles per turn."
  ],
  "y": "motivation"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_5",
  "x": [
   "Regarding the small size of data used in <cite>Tseng (2001)</cite> , it is one of the reasons why the ongoing project is necessary for research of Mandarin spontaneous conversations."
  ],
  "y": "motivation"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_6",
  "x": [
   "In Mandarin conversation, there are words preferably used in turn-initial position<cite> (Tseng 2001</cite> , Chui 2000 ."
  ],
  "y": "background"
 },
 {
  "id": "9227b5afd1ef18ecf83400dc402459_7",
  "x": [
   "Falling tones may not show falling tendency anymore, when the associated words are used for specific discourse functions such as for indicating hesitation or the beginning of a turn<cite> (Tseng 2001)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_0",
  "x": [
   "The production of knowledge bases and the need to answer questions over such resources received researchers attentions to propose different models to find the answer of questions from the knowledge bases, known as KBQA 1 . Answering factoid questions with one relation, also known as simple question answering, has been widely studied in recent years (Dai et al., 2016; Yin et al., 2016; He and Golub, 2016;<cite> Yu et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_1",
  "x": [
   "Moreover, matching question content with relations has also been proposed and shown promising results (Yin et al., 2016;<cite> Yu et al., 2017)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_2",
  "x": [
   "However, most of the recent approaches (Mohammed et al., 2018; Bordes et al., 2015; Dai et al., 2016; He and Golub, 2016;<cite> Yu et al., 2017)</cite> are based on automatically extracted features of terms; thanks to the prominent performance of neural network on representation learning (Mikolov et al., 2013a,b) ."
  ],
  "y": "background"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_3",
  "x": [
   "From another point of view, two mainstreams for extracting relations in KBQA are studied: (a) using a classifier which chooses the most probable relation among all (Mohammed et al., 2018) ; (b) matching questions and relations through learning of an embedding space for representing all relations and question words (Bordes et al., 2015; Dai et al., 2016; Yin et al., 2016; He and Golub, 2016;<cite> Yu et al., 2017)</cite> , in which each relation is considered either as a meaningful sequence of words or as a unique entity."
  ],
  "y": "background"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_4",
  "x": [
   "Additionally, following <cite>Yu et al. (2017)</cite> , we add another neural network (Q'-R), the right part of the architecture, to compute the matching score of Q' with the relation of Q (R)."
  ],
  "y": "differences extends"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_5",
  "x": [
   "Following the previous works by Yin et al. (2016) and <cite>Yu et al. (2017)</cite> , we use the common benchmark dataset of the simple question answering, namely SimpleQuestions, which was originally introduced by Bordes et al. (2015) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_7",
  "x": [
   "Hier-Res-BiLSTM<cite> (Yu et al., 2017)</cite> uses hierarchical residual connections to ease the training procedure of BiL-STM."
  ],
  "y": "background"
 },
 {
  "id": "92d9291093f4ff9f10cca1b8ad2a27_8",
  "x": [
   "The model is reimplemented for SimpleQuestions by <cite>Yu et al. (2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "9340338e7cf8ff8de4db84b462dfe5_0",
  "x": [
   "Previous works appropriate for this task operate on a limited domain and are not able to incorporate temporal information when checking time-dependent claims<cite> (Vlachos and Riedel, 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9340338e7cf8ff8de4db84b462dfe5_1",
  "x": [
   "To validate the extensibility of the system, we complete an additional evaluation of the system using claims taken from <cite>Vlachos and Riedel (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "9340338e7cf8ff8de4db84b462dfe5_2",
  "x": [
   "To learn a model to perform the KB look up (essentially a semantic parsing task), we extend the work of <cite>Vlachos and Riedel (2015)</cite> who used distant supervision (Mintz et al., 2009 ) to generate training data, obviating the need for manual labeling."
  ],
  "y": "extends"
 },
 {
  "id": "9340338e7cf8ff8de4db84b462dfe5_3",
  "x": [
   "We further validate the system by evaluating the ability of this fact checking system to make veracity assessments on simple numerical claims from the data set collected by<cite> (Vlachos and Riedel, 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "9340338e7cf8ff8de4db84b462dfe5_4",
  "x": [
   "Although the range of claims is limited, the system is a fieldtested prototype and has been evaluated on a published data set<cite> (Vlachos and Riedel, 2015)</cite> and on real-world claims presented as part of the HeroX fact checking challenge."
  ],
  "y": "uses"
 },
 {
  "id": "93a1f611592ce6aa5cde7538486f97_0",
  "x": [
   "Meaning shift has recently been investigated with emphasis on neural language models<cite> (Kim et al., 2014</cite>; Kulkarni et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "93a1f611592ce6aa5cde7538486f97_1",
  "x": [
   "Both techniques were already combined in prior work to show, e.g., the increasing association of the lexical item \"gay\" with the meaning dimension of \"homosexuality\"<cite> (Kim et al., 2014</cite>; Kulkarni et al., 2015) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "93a1f611592ce6aa5cde7538486f97_2",
  "x": [
   "Neural language models for tracking semantic changes over time typically distinguish between two different training protocols-continuous training of models<cite> (Kim et al., 2014)</cite> where the model for each time span is initialized with the embeddings of its predecessor, and, alternatively, independent training with a mapping between models for different points in time (Kulkarni et al., 2015) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "93a1f611592ce6aa5cde7538486f97_3",
  "x": [
   "For comparability with earlier studies<cite> (Kim et al., 2014</cite>; Kulkarni et al., 2015) , we use the fiction part of the GOOGLE BOOKS NGRAM corpus (Michel et al., 2011; Lin et al., 2012) ."
  ],
  "y": "uses"
 },
 {
  "id": "93a1f611592ce6aa5cde7538486f97_4",
  "x": [
   "We thus concentrate on two experimental protocols-the one described by <cite>Kim et al. (2014)</cite> (referred to as Kim protocol) and the one from Kulkarni et al. (2015) (referred to as Kulkarni protocol), including close variations thereof."
  ],
  "y": "background uses"
 },
 {
  "id": "966106c9e00f0333bda45d977a9f35_0",
  "x": [
   "We compared convolutional neural network (ConvS2S)<cite> (Gehring et al., 2017)</cite> and recurrent neural network (RNNS2S) (Bahdanau et al., 2014) based sequence to sequence learning architectures."
  ],
  "y": "uses"
 },
 {
  "id": "966106c9e00f0333bda45d977a9f35_1",
  "x": [
   "Recent work<cite> (Gehring et al., 2017)</cite> has shown that a purely CNN based encoder-decoder network is competitive with a RNN based network."
  ],
  "y": "motivation background"
 },
 {
  "id": "966106c9e00f0333bda45d977a9f35_2",
  "x": [
   "In convolutional sequence to sequence model<cite> (Gehring et al., 2017)</cite> , the input sequence is encoded into distributional vector space using a CNN and decoded back to output sequence again using CNN instead of RNN (Sutskever et al., 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "966106c9e00f0333bda45d977a9f35_3",
  "x": [
   "The baseline model with 4 encoder layers and 3 decoder layers was trained using nag optimizer<cite> (Gehring et al., 2017</cite> ) with a learning rate of 0.25 with 0.2 as its dropout value and gradient clipping was also applied."
  ],
  "y": "uses"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_0",
  "x": [
   "Our initial experiments did not use syntactic features <cite>(Nguyen and Grishman, 2016</cite>; Fu et al., 2017 ) that require additional parsers."
  ],
  "y": "differences"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_1",
  "x": [
   "The supervised neural model on a single dataset was introduced by Zeng et al. (2014) and followed by many others (Nguyen and Grishman, 2015; Zhou et al., 2016; Miwa and Bansal, 2016;<cite> Nguyen and Grishman, 2016</cite>; Fu et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_2",
  "x": [
   "Some work <cite>(Nguyen and Grishman, 2016</cite>; Fu et al., 2017) used extra syntax features as input."
  ],
  "y": "background"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_3",
  "x": [
   "Some work <cite>(Nguyen and Grishman, 2016</cite>; Fu et al., 2017) used extra syntax features as input."
  ],
  "y": "motivation"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_4",
  "x": [
   "The entity embedding <cite>(Nguyen and Grishman, 2016</cite>; Fu et al., 2017 ) is included for arguments that are entities rather than common nouns."
  ],
  "y": "uses"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_5",
  "x": [
   "It usually contains one hidden layer (Zeng et al., 2014;<cite> Nguyen and Grishman, 2016</cite>; Fu et al., 2017 ) and a softmax output layer."
  ],
  "y": "background"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_6",
  "x": [
   "It usually contains one hidden layer (Zeng et al., 2014;<cite> Nguyen and Grishman, 2016</cite>; Fu et al., 2017 ) and a softmax output layer."
  ],
  "y": "similarities uses"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_8",
  "x": [
   "Previous work (Gormley et al., 2015;<cite> Nguyen and Grishman, 2016</cite>; Fu et al., 2017) set, and the other half of bc, cts and wl as the test sets."
  ],
  "y": "uses"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_9",
  "x": [
   "We follow<cite> Nguyen and Grishman (2016)</cite> to set the position and entity type embedding size to be 50."
  ],
  "y": "uses"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_10",
  "x": [
   "With syntactic features as <cite>(Nguyen and Grishman, 2016</cite>; Fu et al., 2017) did, it could be further improved."
  ],
  "y": "future_work"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_11",
  "x": [
   "With syntactic features as <cite>(Nguyen and Grishman, 2016</cite>; Fu et al., 2017) did, it could be further improved."
  ],
  "y": "motivation"
 },
 {
  "id": "967c78ccf905c69d732a4c1ef00289_12",
  "x": [
   "We add chunk embedding and on dep path embedding<cite> (Nguyen and Grishman, 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_0",
  "x": [
   "Studies on automatic humor recognition (Mihalcea and Strapparava, 2005;<cite> Yang et al., 2015</cite>; Zhang and Liu, 2014; Purandare and Litman, 2006 ) have defined the recognition task as a binary classification task."
  ],
  "y": "background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_1",
  "x": [
   "Among the studies on humor classification, Mihalcea and Strapparava (2005) and <cite>Yang et al. (2015)</cite> reported high performance on the task."
  ],
  "y": "motivation background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_2",
  "x": [
   "Some humor classification studies (Mihalcea and Strapparava, 2005;<cite> Yang et al., 2015</cite>; Barbieri and Saggion, 2014 ) have used negative instances from different domains or topics, because non-humorous sentences could not be found or are very challenging to collect in target domains or topics."
  ],
  "y": "motivation differences background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_3",
  "x": [
   "Previous studies (Mihalcea and Strapparava, 2005;<cite> Yang et al., 2015</cite>; Zhang and Liu, 2014; Purandare and Litman, 2006; Bertero and Fung, 2016) dealt with the humor recognition task as a binary classification task, which was to categorize a given text as humorous or non-humorous."
  ],
  "y": "background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_4",
  "x": [
   "<cite>Yang et al. (2015)</cite> tried to minimize genre differences between humorous and non-humorous texts in order to avoid a chance that a trained model was optimized to distinguish genre differences."
  ],
  "y": "background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_5",
  "x": [
   "Mihalcea and Strapparava (2005) and <cite>Yang et al. (2015)</cite> borrowed negative instances from different genres such as news websites or proverbs."
  ],
  "y": "differences"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_6",
  "x": [
   "<cite>Yang et al. (2015)</cite> collected a corpus of Pun of Day data 1 ."
  ],
  "y": "background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_7",
  "x": [
   "In order to reduce the differences between positive and negative instances in the data, <cite>Yang et al. (2015)</cite> used two constraints when collecting negative instances."
  ],
  "y": "background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_8",
  "x": [
   "Utilizing the same experimental setup as Mihalcea and Strapparava (2005) and <cite>Yang et al. (2015)</cite> (50% positive and 50% negative instances), we selected 4,726 sentences from among all collected nonhumorous sentences as negative instances."
  ],
  "y": "uses"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_9",
  "x": [
   "Features from <cite>Yang et al. (2015)</cite> , which we implemented, consisted of (1) two incongruity features, (2) six ambiguity features, (3) four interpersonal effect features, (4) four phonetic features, (5) five k-Nearest Neighbor features, and (6) 300 Word2Vec features."
  ],
  "y": "uses"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_10",
  "x": [
   "In this section, we present expeirments that we ran to determine 1) how effective a model trained using 'Pun of Day' data (Pun) is when applied to TED Talk data (Talk), and 2) whether the performance of a model trained using Talk data would be similar to the performance reported in <cite>Yang et al. (2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_11",
  "x": [
   "We reimplemented features developed by <cite>Yang et al. (2015)</cite> and evaluated those features on Talk data."
  ],
  "y": "differences extends"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_12",
  "x": [
   "We followed the experimental setup of <cite>Yang et al. (2015)</cite> in order to see if the performance of our duplicated features was comparable to their reported performance."
  ],
  "y": "differences uses"
 },
 {
  "id": "9684063f991f9a4688d6530fe5a16c_13",
  "x": [
   "<cite>Yang et al. (2015)</cite> borrowed negative instances from different genres such as news websites and proverbs. But, in Talk-to-Talk, both positive and negative instances were from the same genre."
  ],
  "y": "differences"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_0",
  "x": [
   "Visual conversational agents (Das et al. 2017a;<cite> Das et al. 2017b</cite>; ) are AI agents Figure 1 : A human and an AI (a visual conversation agent called ALICE) play the proposed GuessWhich game."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_1",
  "x": [
   "Specifically, <cite>(Das et al. 2017b</cite> ) train two visual conversational agents -a questioning bot QBOT, and an answering bot ABOT -for an image-guessing task."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_2",
  "x": [
   "<cite>(Das et al. 2017b</cite> ) compare supervised baseline models with QBOT-ABOT teams trained through reinforcement learning based self-talk on this image-guessing task."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_3",
  "x": [
   "Mirroring the setting of<cite> (Das et al. 2017b)</cite> , GuessWhich is an image-guessing game that consists of 2 participants -questioner and answerer."
  ],
  "y": "similarities uses"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_4",
  "x": [
   "ALICE RL which is pre-trained with supervised learning and fine-tuned via reinforcement learning for an imageguessing task as in<cite> (Das et al. 2017b)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_5",
  "x": [
   "Our main experimental finding is that despite significant differences between SL and RL agents reported in previous work<cite> (Das et al. 2017b)</cite> , we find no significant difference in performance between ALICE SL or ALICE RL when paired with human partners (Sec. 6.1)."
  ],
  "y": "differences"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_6",
  "x": [
   "Our AI agents are visual conversational models, which have recently emerged as a popular research area in visually-grounded language modeling (Das et al. 2017a;<cite> Das et al. 2017b</cite>; . (Das et al. 2017a ) introduced the task of Visual Dialog and collected the VisDial dataset by pairing subjects on Amazon Mechanical Turk (AMT) to chat about an image (with assigned roles of questioner and answerer)."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_7",
  "x": [
   "<cite>(Das et al. 2017b</cite> ) pre-trained questioner and answerer agents on this VisDial dataset via supervised learning and fine-tuned them via self-talk (reinforcement learning), observing that RL-fine-tuned QBOT-ABOT are better at image-guessing after interacting with each other."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_8",
  "x": [
   "Human evaluation of conversations is typically in the format where humans rate the quality of machine utterances given context, without actually taking part in the conversation, as in <cite>(Das et al. 2017b</cite> ) and (Li et al. 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_10",
  "x": [
   "<cite>(Das et al. 2017b</cite> ) formulate a self-supervised imageguessing task between a questioner bot (QBOT) and an answerer bot (ABOT) which plays out over multiple rounds of dialog."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_12",
  "x": [
   "<cite>(Das et al. 2017b</cite> ) evaluate these agents against strong baselines and report AI-AI team results that are significantly better than chance on a pool of \u223c10k images (rank \u223c1000 for SL, rank \u223c500 for RL)."
  ],
  "y": "background"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_13",
  "x": [
   "Unlike<cite> (Das et al., 2017b)</cite> , we find no significant difference between ALICE SL and ALICE RL ."
  ],
  "y": "differences"
 },
 {
  "id": "9795a839cb79ed971de4c325e01e74_14",
  "x": [
   "This interesting finding stands in stark contrast to the results reported by<cite> (Das et al. 2017b)</cite> , where ALICE RL was found to be significantly more accurate than ALICE SL when evaluated in an AI-AI team."
  ],
  "y": "differences"
 },
 {
  "id": "97fd0f1ce3d4f510c1566d642e9d2c_0",
  "x": [
   "Neural Machine Translation <cite>(Luong et al., 2015</cite>; Bahdanau et al., 2014; Johnson et al., 2017; Vaswani et al., 2017) has been receiving considerable attention in the recent years, given its superior performance without the demand of heavily hand crafted engineering efforts."
  ],
  "y": "background"
 },
 {
  "id": "97fd0f1ce3d4f510c1566d642e9d2c_1",
  "x": [
   "Our NMT model consists of an encoder and a decoder, each of which is a Recurrent Neural Network (RNN) as described in<cite> (Luong et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "97fd0f1ce3d4f510c1566d642e9d2c_2",
  "x": [
   "where c t is the context vector, h enc and h dec are the hidden vectors generated by the encoder and decoder respectively, AttentionFunction(. , .) is the attention mechanism as shown in<cite> (Luong et al., 2015)</cite> and [. ; .] is the concatenation of two vectors."
  ],
  "y": "uses"
 },
 {
  "id": "97fd0f1ce3d4f510c1566d642e9d2c_3",
  "x": [
   "Our NMT model uses a bi-directional RNN as an encoder and a unidirectional RNN as a decoder with global attention<cite> (Luong et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "97fd0f1ce3d4f510c1566d642e9d2c_4",
  "x": [
   "The structure of our NMT model is same as in<cite> Luong et al. (2015)</cite> , an RNN based encoder-decoder model with Global Attention mechanism."
  ],
  "y": "uses"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_0",
  "x": [
   "Until now, their dataset was the only publicly available set of messages with annotated conversations (partially re-annotated by<cite> Mehri and Carenini (2017)</cite> with reply-structure graphs), and has been used for training and evaluation in subsequent work (Wang and Oard, 2009;<cite> Mehri and Carenini, 2017</cite>; Jiang et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_1",
  "x": [
   "Recent work has applied neural networks <cite>(Mehri and Carenini, 2017</cite>; Guo et al. (2017) 1,500 1 48 hr 5 n/a 2 Table 1 : Annotated disentanglement dataset comparison."
  ],
  "y": "background"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_2",
  "x": [
   "Studies that do consider graphs for disentanglement have used small datasets (Dulceanu, 2016;<cite> Mehri and Carenini, 2017)</cite> that are not always released (Wang et al., 2008; Guo et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_3",
  "x": [
   "Values are in the good agreement range proposed by Altman (1990) , and slightly higher than for<cite> Mehri and Carenini (2017)</cite>'s annotations."
  ],
  "y": "differences"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_4",
  "x": [
   "We follow<cite> Mehri and Carenini (2017)</cite> and keep system messages."
  ],
  "y": "similarities uses"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_5",
  "x": [
   "Interestingly, while \u03ba was higher for us than<cite> Mehri and Carenini (2017)</cite> , our scores for conversations are lower."
  ],
  "y": "differences"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_6",
  "x": [
   "For Channel Two we also compare to Wang and Oard (2009) and<cite> Mehri and Carenini (2017)</cite> , but their code was unavailable, preventing evaluation on our data."
  ],
  "y": "similarities"
 },
 {
  "id": "982991efdb6b14f187702e0a577bac_7",
  "x": [
   "How far apart consecutive messages in a conversation are: Elsner and Charniak (2008) and<cite> Mehri and Carenini (2017)</cite> use a limit of 129 seconds, Jiang et al. (2018) limit to within 1 hour, Guo et al. (2017) limit to within 8 messages, and we limit to within 100 messages."
  ],
  "y": "differences"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_0",
  "x": [
   "Most previous research on user geolocation has focused either on text-based classification approaches (Eisenstein et al., 2010; Wing and Baldridge, 2011;<cite> Roller et al., 2012</cite>; Han et al., 2014) or, to a lesser extent, network-based regression approaches (Jurgens, 2013; Compton et al., 2014;<cite> Rahimi et al., 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_1",
  "x": [
   "Most previous research on user geolocation has focused either on text-based classification approaches (Eisenstein et al., 2010; Wing and Baldridge, 2011;<cite> Roller et al., 2012</cite>; Han et al., 2014) or, to a lesser extent, network-based regression approaches (Jurgens, 2013; Compton et al., 2014;<cite> Rahimi et al., 2015)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_2",
  "x": [
   "Our contributions are as follows: (1) we propose the use of Modified Adsorption (Talukdar and Crammer, 2009) as a baseline networkbased geolocation model, and show that it outperforms previous network-based approaches (Jurgens, 2013;<cite> Rahimi et al., 2015)</cite> ; (2) we demonstrate that removing \"celebrity\" nodes (nodes with high in-degrees) from the network increases geolocation accuracy and dramatically decreases network edge size; and (3) we integrate textbased geolocation priors into Modified Adsorption, and show that our unified geolocation model outperforms both text-only and network-only approaches, and achieves state-of-the-art results over three standard datasets."
  ],
  "y": "differences uses"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_3",
  "x": [
   "As shown by<cite> Rahimi et al. (2015)</cite> , geolocation predictions from text can be used as a backoff for disconnected users, but there has been little work that has investigated a more integrated text-and network-based approach to user geolocation."
  ],
  "y": "background"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_4",
  "x": [
   "We evaluate our models over three pre-existing geotagged Twitter datasets: (1) GEOTEXT (Eisen-stein et al., 2010), (2) TWITTER-US <cite>(Roller et al., 2012)</cite> , and (3) TWITTER-WORLD (Han et al., 2012) ."
  ],
  "y": "uses"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_5",
  "x": [
   "The label for the dongle node is based on a textbased l 1 regularised logistic regression model, using the method of<cite> Rahimi et al. (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_6",
  "x": [
   "The results are also compared with prior work on network-based geolocation using label propagation (LP)<cite> (Rahimi et al., 2015)</cite> , text-based classification models (Han et al., 2012; Wing and Baldridge, 2011;<cite> Rahimi et al., 2015</cite>; Cha et al., 2015) , textbased graphical models (Ahmed et al., 2013) , and network-text hybrid models (LP-LR)<cite> (Rahimi et al., 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_7",
  "x": [
   "Our baseline network-based model of MAD-B outperforms the text-based models and also previous network-based models (Jurgens, 2013; Compton et al., 2014;<cite> Rahimi et al., 2015)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "9885b924f6b0806844d4e70d857a35_8",
  "x": [
   "It also makes graph inference over TWITTER-US and TWITTER-WORLD tractable, and results in superior Acc@161 and Median, but slightly inferior Mean, compared to the state-of-the-art results of LR, based on text-based classification<cite> (Rahimi et al., 2015)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_0",
  "x": [
   "Word2vec <cite>[23]</cite> is a recently proposed family of algorithms for training such vector representations from unstructured text data via shal- * Work done while with Yahoo, Inc."
  ],
  "y": "background"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_1",
  "x": [
   "The geometry of the resulting vectors was shown in <cite>[23]</cite> to capture word semantic similarity through the cosine similarity of the corresponding vectors as well as more complex semantic relationships through vector differences, such as vec(\"Madrid\") -vec(\"Spain\") + vec(\"France\") \u2248 vec(\"Paris\")."
  ],
  "y": "background"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_2",
  "x": [
   "In word2vec, each vocabulary word has two associated d-dimensional vectors which must be trained, respectively referred to as input and output vectors, each of which is represented as an array of d single precision floating point numbers <cite>[23]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_3",
  "x": [
   "In this paper we focus on the skipgram approach with random negative examples proposed in <cite>[23]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_4",
  "x": [
   "This has been found to yield the best results among the proposed variants on a variety of semantic tests of the resulting vectors [19,<cite> 23]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_5",
  "x": [
   "\u2022 window sizes bi,j are randomly selected so that each inner sum includes between 1 and a maximum B terms, as in <cite>[23]</cite> and its open-source implementation; 2"
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_6",
  "x": [
   "\u2022 negative examples N i,j,k associated with positive output word w i,k are selected randomly according to a probability distribution suggested in <cite>[23]</cite> ;"
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_7",
  "x": [
   "We follow <cite>[23]</cite> for setting V and select words occurring in the corpus a sufficient number of times (e.g., at least 5 times), or, if this results in too many words, as the most frequently occurring N words, where N is the largest number words that can be handled by available computational resources."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_8",
  "x": [
   "We further also assume a randomized version of (1) according to the subsampling technique of <cite>[23]</cite> , which removes some occurrences of frequent words."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_9",
  "x": [
   "The algorithm for maximizing (1) advocated in <cite>[23]</cite> , and implemented in its open-source counterpart, is a minibatch stochastic gradient descent (SGD)."
  ],
  "y": "uses background"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_10",
  "x": [
   "Our training system is also based on minibatch SGD optimization of (1), however, as described in Section 5, it is carried out in a distributed fashion in a manner quite different from the implementation of <cite>[23]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_11",
  "x": [
   "These include the original open source implementation of word2vec <cite>[23]</cite> , as well as those of Medallia [22] , and Rehurek [28] ."
  ],
  "y": "background"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_12",
  "x": [
   "For w = 10, n = 10, d = 500, values within the ranges recommended in <cite>[23]</cite> , this works out to r(10, 10, 500) \u2248 200, 000 bytes transferred per word with each get and put."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_13",
  "x": [
   "The vectors are initialized in the parameter server shards as in <cite>[23]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_14",
  "x": [
   "\u2022 dotprod: Select negative examplesw in (4) according to a probability distribution derived from the vocabulary histogram proposed in <cite>[23]</cite> , but with the client thread supplied seed initializing the random number generation, and then return all partial dot products required to evaluate the gradient (4) for all positive output, negative output, and input word vectors associated with the minibatch, wherein the partial dot products involve those vector components stored on the designated shard: usv T s ."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_15",
  "x": [
   "The data set is iterated over multiple times and after each iteration, the learning rate \u03b1 is reduced in a manner similar to the open source implementation of <cite>[23]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_16",
  "x": [
   "To compare the proposed distributed system we trained vectors on a publicly available data set collected and processed by the script 'demo-train-big-model-v1-compute-only.sh' from the open-source package of <cite>[23]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_17",
  "x": [
   "This script collects a variety of publicly available text corpuses and processes them using the algorithm described in <cite>[23]</cite> to coalesce sufficiently co-occurring words into phrases."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_18",
  "x": [
   "The first column shows results for the single machine implementation of <cite>[23]</cite> , the second for a 'low parallelism' configuration of our system using 50 Spark executors, minibatch size of 1, and 1 thread per executor, and the third column for a 'high parallelism' configuration again with 50 executors, but with minibatch size increased to 50 and 8 threads per executor."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_19",
  "x": [
   "The various systems were run using the skipgram variant with 500 dimensional vectors, maximum window size of 20 (10 in each direction), 5 negative examples, subsample ratio of 1e-6 (see <cite>[23]</cite> ), initial learning rate of 0.01875, and 3 iterations over the data set."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_20",
  "x": [
   "We are unsure why our system yields better results than the implementation of <cite>[23]</cite> on the wordsim test, yet worse scores on the analogies test."
  ],
  "y": "differences"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_21",
  "x": [
   "We also note that the analogies test scores reported here involve computing the closest vector for each analogy \"question\" over the entire vocabulary and not just over the 1M most frequent words, as in the script 'demo-train-big-model-v1-computeonly.sh' of <cite>[23]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_22",
  "x": [
   "We also compared the cosine similarities for pairs of vectors trained using the proposed distributed system and for corresponding vector pairs trained using the open-source implementation of <cite>[23]</cite> , again on a large search session data set."
  ],
  "y": "uses"
 },
 {
  "id": "98eef9a1dbea3ddd0a8fd1b9c9376c_23",
  "x": [
   "One model was trained using implementation from <cite>[23]</cite> and the other was trained using the proposed distributed system."
  ],
  "y": "uses"
 },
 {
  "id": "99aebc86f34ace0133c9f0922373fe_0",
  "x": [
   "In the third part, a series of deep models including deep unfolding (Chien and Lee, 2018) , Bayesian RNN (Gal and Ghahramani, 2016; Chien and Ku, 2016) , sequence-to-sequence learning (Graves et al., 2006; <cite>Gehring et al., 2017)</cite> , CNN (Kalchbrenner et al., 2014; Xingjian et al., 2015; , GAN (Tsai and Chien, 2017) and VAE are introduced."
  ],
  "y": "background"
 },
 {
  "id": "99b26d9151c7c0a1df1df1300fc764_0",
  "x": [
   "The proposed model can be viewed as a speech version of Word2Vec <cite>[1]</cite>."
  ],
  "y": "extends"
 },
 {
  "id": "99b26d9151c7c0a1df1df1300fc764_1",
  "x": [
   "Natural language processing (NLP) techniques such as Word2Vec<cite> [1,</cite> 2] and GloVe [3] transform words into fixed dimensional vectors, or word embeddings."
  ],
  "y": "background"
 },
 {
  "id": "99b26d9151c7c0a1df1df1300fc764_2",
  "x": [
   "Our work, highly inspired by Word2Vec <cite>[1]</cite> , uses a skipgrams or continuous bag-of-words formulation to focus on neighboring acoustic regions, rather than the acoustic segment associated with the word itself."
  ],
  "y": "motivation"
 },
 {
  "id": "99b26d9151c7c0a1df1df1300fc764_9",
  "x": [
   "The intrinsic method directly tests for semantic or syntactic relationships between words, and includes the tasks of word similarity and word analogy <cite>[1]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "99b26d9151c7c0a1df1df1300fc764_21",
  "x": [
   "This result aligns with the empirical fact that skipgrams Word2Vec is likely to work better than cbow Word2Vec with small training corpus size <cite>[1]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "99b26d9151c7c0a1df1df1300fc764_26",
  "x": [
   "Speech2Vec, which integrates a RNN Encoder-Decoder framework with skipgrams or cbow for training, extends the textbased Word2Vec <cite>[1]</cite> model to learn word embeddings directly from speech."
  ],
  "y": "extends"
 },
 {
  "id": "9a52e0ea1f12e3455fca48ac8f8936_1",
  "x": [
   "The current state of the art on modeling both PTB and WikiText 2 [8] datasets as reported in <cite>[4]</cite> shows little sensitivity to hyper parameters; sharing almost all hyper parameters values between both datasets."
  ],
  "y": "background"
 },
 {
  "id": "9a52e0ea1f12e3455fca48ac8f8936_2",
  "x": [
   "Following a meta-learning approach, we apply a genetic algorithm and a sequential search algorithm, described in the next section, initialized using the best configuration reported in <cite>[4]</cite> to search the space around optimal hyper parameters for the AWD-LSTM model."
  ],
  "y": "uses"
 },
 {
  "id": "9a52e0ea1f12e3455fca48ac8f8936_3",
  "x": [
   "We begin our work by establishing what the baseline and current state of the art model is for a language modeling task <cite>[4]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9a52e0ea1f12e3455fca48ac8f8936_4",
  "x": [
   "Both the population based and sequential search space were manually initialized with four (4) values of each hyperparameter in the neighbourhood of the best values reported in <cite>[4]</cite> as shown in Table I ."
  ],
  "y": "similarities"
 },
 {
  "id": "9a52e0ea1f12e3455fca48ac8f8936_6",
  "x": [
   "In this work we assess the performance of the AWD-LSTM model <cite>[4]</cite> for language modeling to better understand how relevant the published hyper parameters may be for a codemixed corpus and to isolate which hyper parameters could be further tuned to improve performance."
  ],
  "y": "uses"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_0",
  "x": [
   "The learning algorithms applied including: decision tree, decisionlist [15] , neural networks [7] , na\u00efve Bayesian learning ( [5] , [11] ) and maximum entropy <cite>[10]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_1",
  "x": [
   "An interesting study on feature selection for Chinese <cite>[10]</cite> has considered topical features as well as local collocational, syntactic, and semantic features using the maximum entropy model."
  ],
  "y": "background"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_2",
  "x": [
   "In Dang's <cite>[10]</cite> work, collocational features refer to the local PoS information and bi-gram co-occurrences of words within 2 positions of the ambiguous word."
  ],
  "y": "background"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_3",
  "x": [
   "Early researches have proven that using lexical statistical information, such as bi-gram co-occurrences was sufficient to produce close to the best results <cite>[10]</cite> for Chinese WSD."
  ],
  "y": "background"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_4",
  "x": [
   "Early researches have proven that using lexical statistical information, such as bi-gram co-occurrences was sufficient to produce close to the best results <cite>[10]</cite> for Chinese WSD."
  ],
  "y": "differences"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_5",
  "x": [
   "In both Niu [11] and Dang's <cite>[10]</cite> work, topical features as well as the so called collocational features were used."
  ],
  "y": "background"
 },
 {
  "id": "9bab4741e6b9f132c2851bae3a3cf4_6",
  "x": [
   "In both Niu [11] and Dang's <cite>[10]</cite> work, topical features as well as the so called collocational features were used."
  ],
  "y": "differences"
 },
 {
  "id": "9ea99bf57e9113b2f03f2285741397_0",
  "x": [
   "By adding the generated sentences and incorporating syntactic information to the training data, we achieve better performance by 10% compared to an LSTM baseline <cite>[10]</cite> and 5% to the equivalent constraint."
  ],
  "y": "differences"
 },
 {
  "id": "9ea99bf57e9113b2f03f2285741397_1",
  "x": [
   "A multi-task learning approach was introduced to train the syntax representation of languages by constraining the language generator <cite>[10]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9ea99bf57e9113b2f03f2285741397_2",
  "x": [
   "Next, we concatenate both vectors and use it as an input [x w |x p ] to an LSTM layer similar to <cite>[10]</cite> . 4."
  ],
  "y": "similarities"
 },
 {
  "id": "9ea99bf57e9113b2f03f2285741397_3",
  "x": [
   "The split of the dataset is identical to <cite>[10]</cite> and it is showed in Table 1 ."
  ],
  "y": "similarities"
 },
 {
  "id": "9f1d2be80dbfd726a24fb2a05e130b_0",
  "x": [
   "Recent studies pay a great attention to the task of Neural Machine Translation (Cho et al., 2014a; <cite>Sutskever et al., 2014</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "9f1d2be80dbfd726a24fb2a05e130b_1",
  "x": [
   "We conducted a set of experiments to show the effectiveness of <cite>RNN Encoder-Decoder model</cite> (Cho et al., 2014b; <cite>Sutskever et al., 2014</cite>) in the task of machine transliteration using standard benchmark datasets provided by NEWS 2015-16 shared task ."
  ],
  "y": "uses"
 },
 {
  "id": "9f1d2be80dbfd726a24fb2a05e130b_2",
  "x": [
   "In this paper we proposed Neural Machine Transliteration based on successful studies in sequence to sequence learning (<cite>Sutskever et al., 2014</cite>) and Neural Machine Translation (Ling et al., 2015; Costa-Juss\u00e0 and Fonollosa, 2016; Bahdanau et al., 2015; Cho et al., 2014a) ."
  ],
  "y": "uses"
 },
 {
  "id": "9f1d2be80dbfd726a24fb2a05e130b_3",
  "x": [
   "Based on successful studies on Neural Machine Translation (Cho et al., 2014a; <cite>Sutskever et al., 2014</cite>; Hirschberg and Manning, 2015) , in this paper, we proposed a character-based encoderdecoder model which learn to transliterate endto-end."
  ],
  "y": "background uses"
 },
 {
  "id": "9f1d2be80dbfd726a24fb2a05e130b_4",
  "x": [
   "Here, we describe briefly the underlying framework, called <cite>RNN Encoder-Decoder</cite>, proposed by (Cho et al., 2014b) and <cite>(Sutskever et al., 2014)</cite> upon which we build a machine transliteration model that learns to transliterate end-to-end."
  ],
  "y": "background uses"
 },
 {
  "id": "9fdeb20207af1e8ee0c6e5374e3731_0",
  "x": [
   "The SINNET system is the result of several years of research<cite> Agarwal et al., 2012</cite>; Agarwal et al., 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "9fdeb20207af1e8ee0c6e5374e3731_1",
  "x": [
   "In<cite> Agarwal et al. (2012)</cite> , we presented a case study on a manually extracted network from Alice in Wonderland, showing that analyzing networks based on these social events gives us insight into the roles of characters in the story."
  ],
  "y": "background"
 },
 {
  "id": "9fdeb20207af1e8ee0c6e5374e3731_2",
  "x": [
   "Figure 2 shows the network extracted from an abridged version of Alice in Wonderland <cite>(Agarwal et al., 2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "9fdeb20207af1e8ee0c6e5374e3731_3",
  "x": [
   "This network may be used for other In<cite> Agarwal et al. (2012)</cite> , we argued that a static network does not bring out the true nature of a network."
  ],
  "y": "background"
 },
 {
  "id": "a0614f13b4ed0c6370deb26032f62b_0",
  "x": [
   "Beyond language modeling, methods for PCFG induction from treebanks have been a popular topic in the field over the past decade, and some understanding of the impact of flattening trees can be had in <cite>Johnson (1998)</cite> , where the beneficial impact of various tree transformations for probabilistic grammars is presented."
  ],
  "y": "background"
 },
 {
  "id": "a0614f13b4ed0c6370deb26032f62b_1",
  "x": [
   "Beyond language modeling, methods for PCFG induction from treebanks have been a popular topic in the field over the past decade, and some understanding of the impact of flattening trees can be had in <cite>Johnson (1998)</cite> , where the beneficial impact of various tree transformations for probabilistic grammars is presented."
  ],
  "y": "motivation"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_0",
  "x": [
   "The idea of tree-based approaches <cite>[26]</cite> , [27] , [28] , [15] is to transform the derivation of the arithmetic expression to constructing an equivalent tree structure step by step in a bottom-up manner."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_1",
  "x": [
   "One is called expression tree that is used in <cite>[26]</cite> , [28] , [15] and the other is called equation tree in [27] ."
  ],
  "y": "uses"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_2",
  "x": [
   "Roy et al. <cite>[26]</cite> proposed the first algorithmic approach that leverages the concept of expression tree to solve arithmetic word problems."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_3",
  "x": [
   "To further reduce the tree enumeration space, beam search is applied in <cite>[26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_4",
  "x": [
   "The solution in [27] , named ALGES, differs from <cite>[26]</cite> in two major ways."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_5",
  "x": [
   "UnitDep [28] can be viewed as an extension work of <cite>[26]</cite> by the same authors."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_7",
  "x": [
   "2) IL <cite>[26]</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_9",
  "x": [
   "3) CC <cite>[26]</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_10",
  "x": [
   "It is interesting to observe that ALGES [27] , ExpressionTree <cite>[26]</cite> and UNITDEP [28] cannot perform equally well on the three datasets."
  ],
  "y": "uses"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_11",
  "x": [
   "This is similar to the relevance model trained in ExpressionTree <cite>[26]</cite> and UNITDEP [28] ."
  ],
  "y": "similarities"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_12",
  "x": [
   "ExpressionTree <cite>[26]</cite> is an exceptional case without using Stanford Parser."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_13",
  "x": [
   "As shown in Table 5 , a binary indicator to determine whether a quantity refers to a rate is adopted in many solvers <cite>[26]</cite> [28] [15] [40] [45] ."
  ],
  "y": "uses"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_14",
  "x": [
   "A trivial trick used in <cite>[26]</cite> [28] [15] is to examine whether there exists comparative adverbs."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_15",
  "x": [
   "A straightforward example is that if two quantities are associated with the same unit, they can be applied with addition and subtraction <cite>[26]</cite> [28] [15] [40] ."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_16",
  "x": [
   "If one quantity is related to a rate and the other is associated with a unit that is part of the rate, their operator is likely to be multiplication or division <cite>[26]</cite> [27] [28] [15] ."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_17",
  "x": [
   "Finally, a popular quantity-pair feature used in <cite>[26]</cite> [28] [15] [39] [40] [45] examines whether the value of one quantity is greater than the other, which is helpful to determine the correct operands for subtraction operator."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_18",
  "x": [
   "Finally, a popular quantity-pair feature used in <cite>[26]</cite> [28] [15] [39] [40] [45] examines whether the value of one quantity is greater than the other, which is helpful to determine the correct operands for subtraction operator."
  ],
  "y": "uses background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_19",
  "x": [
   "The remain question-related features presented in Table 5 were proposed by Roy et al. <cite>[26]</cite> , [28] and followed by MathDQN [15] ."
  ],
  "y": "uses"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_20",
  "x": [
   "<cite>[26]</cite> [27] [28] [15] directly use dependent verb as one of the features."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_21",
  "x": [
   "<cite>[26]</cite> [27] [28] [15] directly use dependent verb as one of the features."
  ],
  "y": "similarities"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_22",
  "x": [
   "Again, the remaining features come from the works <cite>[26]</cite> , [28] , [15] ."
  ],
  "y": "uses"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_23",
  "x": [
   "<cite>[26]</cite> , [28] , [15] use the number of quantities in the problem text as part of feature space."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_24",
  "x": [
   "Comparative adverbs <cite>[26]</cite> [28] [15] For \"If she drank 25 of them and then bought 30 more.\", \"more\" is a comparative term in the window of quantity \"30\"."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_25",
  "x": [
   "Whether both quantities have the same unit <cite>[26]</cite> [28] [15] [40] For \"Student tickets cost 4 dollars and general admission tickets cost 6 dollars\", quantities \"4\" and \"6\" have the same unit."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_26",
  "x": [
   "If one quantity is related to a rate and the other is associated with a unit that is part of the rate <cite>[26]</cite> [27] [28] [15] For \"each box has 9 pieces\" and \"Paul bought 6 boxes of chocolate candy\", \"9\" is related to a rate ( i.e., pieces/box) and \"6\" is associated to the unit \"box\"."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_27",
  "x": [
   "Number of quantities which happen to have the maximum number of matching tokens with the question <cite>[26]</cite> [28] [15] For \"Rose have 9 apples and 12 erasers. ... 3 friends."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_28",
  "x": [
   "Whether any component of the rate is present in the question <cite>[26]</cite> [28] [15] Given a question \"How many blocks does George have?\" and a quantity 6 associated with rate \"blocks/box\", the feature indicator is set to 1 since block appears in the question."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_29",
  "x": [
   "Whether the question contains terms like \"each\" or \"per\" <cite>[26]</cite> [28] [15] Whether the question contains comparison-related terms like \"more\" or \"less\" <cite>[26]</cite> [28] [15] Whether the question contains terms like \"how many\" [39] [40] [45] [13] It implies that the solution is positive."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_30",
  "x": [
   "Dependent verb of a quantity <cite>[26]</cite> [27] [28] [15] the verb closest to the quantity in the dependency tree Distance vector between the dependent verb and a small collection of predefined verbs that are useful for arithmetic operator classification [21] [24] [27] Whether two quantities have the same dependent verbs <cite>[26]</cite> [28] [15] For \"In the first round she scored 40 points and in the second round she scored 50 points\", the quantities \"40\" and \"50\" both have the same verb \"scored\". Note that \"scored\" appeared twice in the sentence."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_31",
  "x": [
   "Whether both dependent verbs refer to the same verb mention <cite>[26]</cite> [28] [15] For \"She baked 4 cupcakes and 29 cookies.\", the quantities \"4\" and \"29\" both shared the verb \"baked\". Note that \"baked\" appeared only once in the sentence."
  ],
  "y": "background"
 },
 {
  "id": "a0db9c3a74487d3fcd11e79d44e163_32",
  "x": [
   "Number of quantities mentioned in text <cite>[26]</cite> [28] [15] Unigrams and bigrams of sentences in the problem text [20] [39] presented an efficient characteristic pattern detection method by scanning the distribution of black pixels and generating feature points graph."
  ],
  "y": "background"
 },
 {
  "id": "a127218cca5653f1700c0de6c8318a_0",
  "x": [
   "Recently, contextualized word embeddings such as (<cite>Devlin et al., 2019</cite>) were proposed in NLP to capture the context of each word usage in vectors and to model the semantic distances between the usages using contexts as a clue."
  ],
  "y": "background"
 },
 {
  "id": "a127218cca5653f1700c0de6c8318a_1",
  "x": [
   "We built the database by applying the bert-base-uncased model of the PyTorch Pretrained the BERT project 1 (<cite>Devlin et al., 2019</cite>) to the corpus."
  ],
  "y": "uses"
 },
 {
  "id": "a127218cca5653f1700c0de6c8318a_2",
  "x": [
   "Users can 1 <cite>https://github.com/huggingface/ pytorch-pretrained-BERT</cite> 2 Fig. 2 and Fig. 3 shows use cases on a 10, 000-sentence experpt of the BNC corpus to avoid having too many hits hinder the reading of the paper."
  ],
  "y": "uses"
 },
 {
  "id": "a334cda78f8ba6dea709809f0999b6_0",
  "x": [
   "It has been shown that word embeddings capture human biases (such as gender bias) present in these corpora in how they relate words to each other (Bolukbasi et al., 2016;<cite> Caliskan et al., 2017</cite>; Garg et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "a334cda78f8ba6dea709809f0999b6_1",
  "x": [
   "Several methods have been proposed to test for the presence of gender bias in word embeddings; an example being the Word Embedding Association Test (WEAT) <cite>(Caliskan et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a334cda78f8ba6dea709809f0999b6_2",
  "x": [
   "To address this, we applied the WEAT test on four sets of word embeddings trained on corpora from four domains: social media (Twit-ter), a Wikipedia-based gender-balanced corpus (GAP) and a biomedical corpus (PubMed) and news (Google News, in order to reproduce and validate our results against those of<cite> Caliskan et al. (2017)</cite> ) (see Section 3)."
  ],
  "y": "similarities uses"
 },
 {
  "id": "a334cda78f8ba6dea709809f0999b6_3",
  "x": [
   "We largely follow the WEAT Hypothesis testing protocol introduced by<cite> Caliskan et al. (2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "a334cda78f8ba6dea709809f0999b6_4",
  "x": [
   "In<cite> Caliskan et al. (2017)</cite> H o is tested through a permutation test, in which X \u222a Y is partitioned into alternative target listsX and\u0176 exhaustively and computing the one-sided p-value p[s(X,\u0176 , M, F ) > s(X, Y, M, F )], i.e. the proportion of partition permutationsX,\u0176 in which the test statistic s(X,\u0176 , M, F ) is greater than the observed test statistic s(X, Y, M, F )."
  ],
  "y": "background"
 },
 {
  "id": "a334cda78f8ba6dea709809f0999b6_5",
  "x": [
   "Although one would hope to find little gender bias in a news corpus, given that its authors are professional journalists, bias had already been detected by<cite> Caliskan et al. (2017)</cite> and Garg et al. (2018) using methods similar to ours."
  ],
  "y": "similarities"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_0",
  "x": [
   "Research on unsupervised adaptation for acoustic models can be roughly divided into three categories: (1) constrained model adaptation [5, 6, 7] , (2) domain-invariant feature extraction [8, 9, 10] , and (3) labeled in-domain data augmentation by synthesis [11, 12, <cite>13]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_1",
  "x": [
   "Furthermore, with the recent progress on domain translation<cite> [13,</cite> 14, 15] , conditional synthesis of indomain data without parallel data has become achievable, which makes data augmentation-based adaptation a more promising direction to investigate."
  ],
  "y": "background"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_2",
  "x": [
   "Variational autoencoder-based data augmentation (VAE-DA) is a domain adaptation method proposed in<cite> [13]</cite> , which pools in-domain and out-domain to train a VAE that learns factorized latent representations of speech segments."
  ],
  "y": "background"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_3",
  "x": [
   "Variational autoencoder-based data augmentation (VAE-DA) is a domain adaptation method proposed in<cite> [13]</cite> , which pools in-domain and out-domain to train a VAE that learns factorized latent representations of speech segments."
  ],
  "y": "extends"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_4",
  "x": [
   "A key observation made in<cite> [13]</cite> is that nuisance factors, such as speaker identity and room acoustics, are generally constant over segments within an utterance, while linguistic content changes from segment to segment."
  ],
  "y": "background"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_5",
  "x": [
   "We now derive two data augmentation methods similar to those proposed in<cite> [13]</cite> , named nuisance factor replacement and nuisance factor perturbation."
  ],
  "y": "similarities"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_6",
  "x": [
   "Therefore, we adopt a similar soft perturbation scheme as in<cite> [13]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_8",
  "x": [
   "VAE-DA<cite> [13]</cite> results with nuisance factor replacement (repl) and latent nuisance perturbation (p) are shown in the last three rows."
  ],
  "y": "uses"
 },
 {
  "id": "a3ad95d75b7750b8a879fa183e30f6_9",
  "x": [
   "To verify the superiority of the proposed method of drawing random perturbation vectors, we compare two alternative sampling methods: rev-p and uni-p, similar to<cite> [13]</cite> , with the same expected squared Euclidean norm as the proposed method."
  ],
  "y": "similarities"
 },
 {
  "id": "a62f376adefad10c5fb8b6c08ebb63_0",
  "x": [
   "Consequently, much work has been devoted to this task (Wu, 1997; Zens and Ney, 2003;<cite> Wellington et al., 2006</cite>; Macken, 2007; S\u00f8gaard and Kuhn, 2009) ."
  ],
  "y": "background"
 },
 {
  "id": "a62f376adefad10c5fb8b6c08ebb63_1",
  "x": [
   "The task of estimating the consequences of the structural constraints imposed by a particular syntax-based formalism consists in finding what is often called \"empirical lower bounds\" on the coverage of the formalism <cite>(Wellington et al., 2006</cite>; S\u00f8gaard and Kuhn, 2009 )."
  ],
  "y": "background"
 },
 {
  "id": "a62f376adefad10c5fb8b6c08ebb63_2",
  "x": [
   "The assumption in this and related work that enables us to introduce a meaningful notion of alignment capacity is that simultaneously recognized words are aligned (Wu, 1997; Zhang and Gildea, 2004;<cite> Wellington et al., 2006</cite>; S\u00f8gaard and Kuhn, 2009) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "a62f376adefad10c5fb8b6c08ebb63_3",
  "x": [
   "Inside-out alignments were first described by Wu (1997) , and their frequency has been a matter of some debate (Lepage and Denoual, 2005;<cite> Wellington et al., 2006</cite>; S\u00f8gaard and Kuhn, 2009) ."
  ],
  "y": "background"
 },
 {
  "id": "a7559a8775941622d269433937633a_0",
  "x": [
   "Robust grammar-based language modeling is a topic that has received a fair bit of attention over the past decade (Chelba and Jelinek 2000; <cite>Charniak 2001</cite>; Roark 2001; Wang, Stolcke, and Harper 2004, among others) , and while this line of research has not focused on the use of manually built, narrow-domain feature grammars, there is enough similarity between the approach described in this book and the cited papers that the papers would seem to be better comparison points than the class-based language models that are chosen to represent robust approaches in the comparison."
  ],
  "y": "similarities background"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_0",
  "x": [
   "Despite considerable prior work in temporal information extraction, to date state-of-the-art resources are designed for extracting temporally scoped facts about public figures/organizations from newswire or Wikipedia articles<cite> McClosky and Manning, 2012</cite>; Garrido et [11/15/2008] I have noticed some pulling recently and I won't start rads until March."
  ],
  "y": "background"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_1",
  "x": [
   "Previous work only retrieves time-rich sentences that include both the query and some TEs<cite> McClosky and Manning, 2012</cite>; Garrido et al., 2012) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_2",
  "x": [
   "Our task is closest to the temporal slot filling track in the TAC-KBP 2011 shared task and timelining task<cite> (McClosky and Manning, 2012)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_3",
  "x": [
   "Features for the classifier include many of those in <cite>(McClosky and Manning, 2012</cite>; Yoshikawa et al., 2009 ): namely, event keyword and its dominant verb, verb and preposition that dominate TE, dependency path between TE and keyword and its length, unigram and bigram word and POS features."
  ],
  "y": "similarities"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_4",
  "x": [
   "Previous work only retrieves time-rich sentences (i.e., date sentences) (Ling and Weld, 2010;<cite> McClosky and Manning, 2012</cite>; Garrido et al., 2012) ."
  ],
  "y": "motivation background"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_5",
  "x": [
   "In previous work <cite>(McClosky and Manning, 2012</cite>; , the evaluation metric score is defined as 1/((1 + |d|)) where d is the difference between the values in years."
  ],
  "y": "background"
 },
 {
  "id": "a789aea59eebfefb990dfc6367d323_6",
  "x": [
   "In previous work <cite>(McClosky and Manning, 2012</cite>; , the evaluation metric score is defined as 1/((1 + |d|)) where d is the difference between the values in years."
  ],
  "y": "differences background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_0",
  "x": [
   "Classifying stance involves identifying a holistic subjective disposition, beyond the word or sentence (Lin et al., 2006; Malouf and Mullen, 2008; Greene and Resnik, 2009; Somasundaran and Wiebe, 2009;<cite> Somasundaran and Wiebe, 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_1",
  "x": [
   "This could be useful for: (1) creating automatic summaries of each position on an issue (SparckJones, 1999); (2) gaining a deeper understanding of what makes an argument persuasive (Marwell and Schmitt, 1967) ; and (3) identifying the linguistic reflexes of perlocutionary acts such as persuasion and disagreement (Walker, 1996; Greene and Resnik, 2009;<cite> Somasundaran and Wiebe, 2010</cite>; Marcu, 2000) ."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_2",
  "x": [
   "They show that discourse relations such as concessions and the identification of argumentation triggers improves performance over sentiment features alone (Somasundaran and Wiebe, 2009;<cite> Somasundaran and Wiebe, 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_3",
  "x": [
   "The best performance for siding ideological debates in previous work is approximately 64% accuracy over all topics, for a collection of 2nd Amendment, Abortion, Evolution, and Gay Rights debate posts<cite> (Somasundaran and Wiebe, 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_4",
  "x": [
   "Each of our 12 topics consists of more than one debate: each debate was mapped by hand to the topic and topic-siding (as in<cite> (Somasundaran and Wiebe, 2010)</cite>)."
  ],
  "y": "similarities"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_5",
  "x": [
   "Previous work suggests that the unigram baseline can be difficult to beat for certain types of debates <cite>(Somasundaran and Wiebe, 2010</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_6",
  "x": [
   "Previous research in this area suggests the utility of dependency structure to determine the TARGET of an opinion word (Joshi and Penstein-Ros\u00e9, 2009; Somasundaran and Wiebe, 2009;<cite> Somasundaran and Wiebe, 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_7",
  "x": [
   "The overal lack of impact for either the POS generalized dependency features (GDepP) or the Opinion generalized dependency features (GDep0) is surprising given that they improve accuracy for other similar tasks (Joshi and Penstein-Ros\u00e9, 2009;<cite> Somasundaran and Wiebe, 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_8",
  "x": [
   "While our method of extracting the GDepP features is identical to (Joshi and Penstein-Ros\u00e9, 2009 ), our method for extracting GDepO is an approximation of the method of<cite> (Somasundaran and Wiebe, 2010)</cite> , that does not rely on selecting particular patterns indicating the topics of arguing by using a development set."
  ],
  "y": "differences extends"
 },
 {
  "id": "a82bdc55c15bb2bcee77c57641b1b5_9",
  "x": [
   "The best performance of<cite> (Somasundaran and Wiebe, 2010)</cite> below the majority class baseline for all of the features without context."
  ],
  "y": "background"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_0",
  "x": [
   "We experimented with four datasets widely used in literature: BLESS (Baroni and Lenci, 2011) , EVALution (Santus et al., 2015) , Lenci/Benotto (Benotto, 2015) , and Weeds (Weeds et al., 2014) taken from the repository provided by <cite>(Shwartz et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_1",
  "x": [
   "Similar to SLQS, our depth measure is motivated by distributional informativeness hypothesis <cite>(Shwartz et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_2",
  "x": [
   "We compared our numbers with those given in <cite>(Shwartz et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_3",
  "x": [
   "For the case of hypernym vs all other relations, except for EVALution, in all other data sets, our average precision (AP ) using both Jaccard and word2vec ( <cite>(Shwartz et al., 2017)</cite> call this as AP @all) is better than the best unsu- Table 2 : AP = average precision."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_4",
  "x": [
   "The Best AP and Best Measure is taken from <cite>(Shwartz et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_5",
  "x": [
   "pervised measure as reported in <cite>(Shwartz et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_6",
  "x": [
   "Our systems performs worse than the best measure whenever an Informativeness Measure <cite>(Shwartz et al., 2017)</cite> , like SLQS and its variants perform well."
  ],
  "y": "similarities uses"
 },
 {
  "id": "aa496bd71f380e02dd392cda969999_7",
  "x": [
   "For finding the best measure, <cite>(Shwartz et al., 2017)</cite> finds the best by varying the measures as well as the features, whereas we have a fixed system."
  ],
  "y": "differences extends"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_0",
  "x": [
   "The hierarchical lexical database approach can be reclassified into three groups according to usages of the database: gloss based method [5] , conceptual density based method [6, 7] and relative based method [8,<cite> 9,</cite> 10] ."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_1",
  "x": [
   "<cite>[9]</cite> followed the method of [8] , but tried to resolve the ambiguous relative problem by using just unambiguous relatives."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_2",
  "x": [
   "Since WordNet is freely available for research, various kinds of WSD studies based on WordNet can be compared with the method of <cite>[9]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_3",
  "x": [
   "[10] reimplemented the method of <cite>[9]</cite> using a web, which may be a very large corpus, in order to collect example sentences."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_4",
  "x": [
   "They built training datum of all noun words in WordNet whose size is larger than 7GB, but evaluated their method on a small number of nouns of lexical sample task of SENSEVAL-2 as [8] and <cite>[9]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_5",
  "x": [
   "Our method makes use of ambiguous relatives as well as unambiguous relatives unlike <cite>[9]</cite> and hence overcomes the shortage problem of relatives and also reduces the problem of ambiguous relatives in [8] by handling relatives separately instead of putting example sentences of the relatives together into a pool."
  ],
  "y": "differences"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_6",
  "x": [
   "However, both of [8] and <cite>[9]</cite> did not evaluate their methods on a publicly available data."
  ],
  "y": "differences"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_7",
  "x": [],
  "y": "uses"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_8",
  "x": [
   "WordNet was utilized as a lexical database to acquire relatives of target words and the sense disambiguation modules were implemented by using on Na\u00efve Bayesian classifier, which <cite>[9]</cite> adopted though [8] utilized International Roget's Thesaurus and other classifier similar to decision lists."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_9",
  "x": [
   "The main difference between [8] and <cite>[9]</cite> is whether ambiguous relatives are utilized or not."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_10",
  "x": [
   "Considering the difference, we implemented the method of [8] to include the ambiguous relatives into relatives, but the method of <cite>[9]</cite> to exclude the ambiguous relatives."
  ],
  "y": "uses"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_11",
  "x": [
   "7 In the table, All Relatives and Unambiguous Relatives represent the results of the reimplemented methods of [8] and <cite>[9]</cite> , respectively."
  ],
  "y": "uses"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_12",
  "x": [
   "Hence, we may have an idea that our method handles relatives and in particular ambiguous relatives more effectively than [8] and <cite>[9]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_13",
  "x": [
   "Compared with <cite>[9]</cite> , [8] obtains a better performance, and the difference between the performance of them are totally more than 15 % on all of the evaluation data."
  ],
  "y": "background"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_14",
  "x": [
   "When evaluated on the same nouns of the lexical sample task, our proposed method achieved 47.26%, and the method of [8] 45.61%, and the method of <cite>[9]</cite> 38.03%."
  ],
  "y": "differences"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_15",
  "x": [
   "We can observe that in our implementation of the method of <cite>[9]</cite> , the data sparseness problem is very serious since unambiguous relatives are usually not frequent in the raw corpus."
  ],
  "y": "uses"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_16",
  "x": [
   "Also our method more correctly disambiguates senses than [8] and <cite>[9]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "abc19723df6670960705eadbaa6c13_17",
  "x": [
   "In consequence, our method has two advantages over the previous methods ( [8] and <cite>[9]</cite> ): our method 1) handles the ambiguous relatives and unambiguous relatives more effectively, and 2) utilizes only one co-occurrence matrix for disambiguating all contents words instead of collecting training data of the content words."
  ],
  "y": "differences"
 },
 {
  "id": "ad62ec914bb7b002952f22afdca15f_0",
  "x": [
   "Another different context type is dependency-based word embedding [11, 12, <cite>13]</cite> , which considers syntactic contexts rather"
  ],
  "y": "background"
 },
 {
  "id": "ad62ec914bb7b002952f22afdca15f_1",
  "x": [
   "Another different context type is dependency-based word embedding [11, 12, <cite>13]</cite> , which considers syntactic contexts rather"
  ],
  "y": "background"
 },
 {
  "id": "ad62ec914bb7b002952f22afdca15f_2",
  "x": [
   "Second, we extract word-to-word associations (or called word dependency, a dependency implies its close association with other words in either syntactic or semantic perspective) from large amounts of auto-parsed data and adopt word2vecf <cite>[13]</cite> to train dependency-based word embeddings."
  ],
  "y": "uses"
 },
 {
  "id": "aeb6a815732b36d7602a9c43c47cfa_0",
  "x": [
   "Explicit user geolocation metadata (e.g. GPS tags, WiFi footprint, IP address) is not usually available to third-party consumers, giving rise to the need for geolocation based on profile data, text content, friendship graphs (Jurgens et al., 2015) or some combination of these<cite> (Rahimi et al., 2015b</cite>,a) ."
  ],
  "y": "background"
 },
 {
  "id": "aeb6a815732b36d7602a9c43c47cfa_1",
  "x": [
   "4 The results reported in <cite>Rahimi et al. (2015b</cite>; 2015a) for TWITTER-WORLD were over a superset of the dataset; the results reported here are based on the actual dataset."
  ],
  "y": "differences"
 },
 {
  "id": "aeb6a815732b36d7602a9c43c47cfa_2",
  "x": [
   "The embeddings slightly outperform the output layer of logistic regression (LR)<cite> (Rahimi et al., 2015b)</cite>"
  ],
  "y": "differences"
 },
 {
  "id": "aeb6a815732b36d7602a9c43c47cfa_3",
  "x": [
   "The results are also compared with state-of-the-art text-based methods based on a flat<cite> (Rahimi et al., 2015b</cite>; Cha et al., 2015) or hierarchical (Wing and Baldridge, 2014; Melo and Martins, 2015; Liu and Inkpen, 2015) geospatial representation."
  ],
  "y": "differences"
 },
 {
  "id": "af39041414dec545df878404328aab_0",
  "x": [
   "In this paper, we propose to scale up discriminative training of<cite> (He and Deng, 2012)</cite> to train features with 150 million parameters, which is one order of magnitude higher than previously published effort, and to apply discriminative training to redistribute probability mass that is lost due to model pruning."
  ],
  "y": "extends"
 },
 {
  "id": "af39041414dec545df878404328aab_1",
  "x": [
   "The maximum expected BLEU training of<cite> (He and Deng, 2012</cite> ) is a recent effort towards this direction, and in this paper, we extend their work to a scaled-up task of discriminative training of the features of a strong hierarchical phrase-based model and confirm its effectiveness empirically."
  ],
  "y": "extends background"
 },
 {
  "id": "af39041414dec545df878404328aab_2",
  "x": [
   "Our contributions in this paper are two-folded: First of all, we scale up the maximum expected BLEU training proposed in<cite> (He and Deng, 2012)</cite> in a number of ways including using 1) a hierarchical phrase-based model, 2) a richer feature set, and 3) a larger training set with a much larger parameter set, resulting in more than 150 million parameters in the model being updated, which is one order magnitude higher than the phrase-based model reported in<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "af39041414dec545df878404328aab_3",
  "x": [
   "where B(\u00ca 1 ...\u00ca N ) is the BLEU score of the concatenated hypothesis of the entire training data, following<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_4",
  "x": [
   "To alleviate overfitting, we introduce KL-distance based reguralization as in<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_5",
  "x": [
   "The optimization algorithm is based on the Extended Baum Welch (EBW) (Gopalakrishnan et al., 1991) as derived by<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_6",
  "x": [
   "Following<cite> (He and Deng, 2012)</cite> , we focus on discriminative training of p(f |e) and p(e|f ), which in practice affects around 150 million of parameters; hence the title."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_7",
  "x": [
   "Table 1 compares the key components of our baseline system with that of<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_8",
  "x": [
   "As shown, we are working with a stronger system than<cite> (He and Deng, 2012)</cite> , especially in terms of the number of parameters under consideration |\u03b8|."
  ],
  "y": "differences"
 },
 {
  "id": "af39041414dec545df878404328aab_9",
  "x": [
   "For each \u03c4 , we run several iterations of discriminative training where each iteration involves one simultaneous update of p(f |e) and p(e|f ) according to Eq. 4, followed by one update of \u03bb via PRO (as in<cite> (He and Deng, 2012)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_10",
  "x": [
   "This improvement is in the same ballpark as in<cite> (He and Deng, 2012</cite> ) though on a scaledup task."
  ],
  "y": "similarities"
 },
 {
  "id": "af39041414dec545df878404328aab_11",
  "x": [
   "We see this result as confirming the effectiveness of discriminative training but on a larger-scale task, adding to what was reported by<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "af39041414dec545df878404328aab_12",
  "x": [
   "In this paper, we first extend the maximum expected BLEU training of<cite> (He and Deng, 2012)</cite> to train two features of a state-of-the-art hierarchical phrasebased system, namely: p(f |e) and p(e|f )."
  ],
  "y": "extends"
 },
 {
  "id": "af39041414dec545df878404328aab_13",
  "x": [
   "Compared to<cite> (He and Deng, 2012)</cite> , we apply the algorithm to a strong baseline that is trained on a bigger parallel corpora and comes with a richer feature set."
  ],
  "y": "uses"
 },
 {
  "id": "af39041414dec545df878404328aab_14",
  "x": [
   "Our experiments show that discriminative training these two features (out of 50) gives around 0.40 BLEU point improvement, which is consistent with the conclusion of<cite> (He and Deng, 2012)</cite> but in a much larger-scale system."
  ],
  "y": "similarities"
 },
 {
  "id": "af39041414dec545df878404328aab_15",
  "x": [
   "We describe the process to simplify Eq. 1 to Eq. 2, which is omitted in<cite> (He and Deng, 2012)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_0",
  "x": [
   "Some (Ravichandran and Hovy, 2002; Bunescu and Mooney, 2007) targeted specific relations like BornInYear, CorporationAcquired, others (Wu and Weld, 2010; <cite>Fader et al., 2011</cite> ) extracted any phrase denoting a relation in an English sentence."
  ],
  "y": "background"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_1",
  "x": [
   "As a result various knowledge bases have been produced like TopicSignatures (Agirre and Lacalle, 2004) , ConceptNet (Liu and Singh, 2004) , Yago (Suchanek et al., 2007) , NELL (Carlson et al., 2009) and ReVerb<cite> (Fader et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_2",
  "x": [
   "\u2022 We conduct a comparative study with the verb-based relation extraction system ReVerb<cite> (Fader et al., 2011)</cite> and show that our approach accurately extracts more verb-based relations."
  ],
  "y": "differences"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_3",
  "x": [
   "However to build a system that can learn a richer set of relations is not trivial, because often labeled training data is required (Kim and Moldovan, 1993; Soderland et al., 1999) and most methods do not scale to corpora where the number of relations is very large or when the relations are not specified in advance<cite> (Fader et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_4",
  "x": [
   "However, recently developed OpenIE systems like TextRunner (Banko et al., 2007; Banko, 2009) and ReVerb<cite> (Fader et al., 2011)</cite> surmount the necessity of labeled data by extracting arbitrary phrases denoting relations in English sentences."
  ],
  "y": "background"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_5",
  "x": [
   "For our comparative study with existing systems, we used ReVerb 4<cite> (Fader et al., 2011)</cite> , which similarly to our approach was specifically designed to learn verb-based relations from unstructured texts."
  ],
  "y": "similarities"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_6",
  "x": [
   "According to<cite> (Fader et al., 2011)</cite> ReVerb outperforms TextRunner (Banko et al., 2007) and the open Wikipedia extractor WOE (Wu and Weld, 2010) in terms of the quantity and quality of the learned relations."
  ],
  "y": "background"
 },
 {
  "id": "b1c06a67b03d81b249b320413a6e7e_7",
  "x": [
   "We have evaluated the accuracy of our approach using human based evaluation and have compared results against the ReVerb<cite> (Fader et al., 2011)</cite> system and existing knowledge bases like NELL (Carlson et al., 2009) , Yago (Suchanek et al., 2007) and ConceptNet (Liu and Singh, 2004) ."
  ],
  "y": "similarities"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_0",
  "x": [
   "Zero-shot NMT was first demonstrated by<cite> Johnson et al. (2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_1",
  "x": [
   "Hence, there has been a massive increase in work on MT systems that involve more than two languages (Dong et al., 2015; Firat et al., 2016a; Cheng et al., 2017; <cite>Johnson et al., 2017</cite>;<cite> Chen et al., 2017</cite> Neubig and Hu, 2018) etc."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_2",
  "x": [
   "In addition, MNMT systems will be compact, because a single model handles translations for multiple languages<cite> (Johnson et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_3",
  "x": [
   "Zeroshot translation: Translating between language pairs without parallel corpora<cite> (Johnson et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_4",
  "x": [
   "In fact, the number of parameters is only a small multiple of the compact model (the multiplication factor accounts for the language embedding size)<cite> (Johnson et al., 2017)</cite> , but the language embeddings can directly impact the model parameters instead of the weak influence that language tags have."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_5",
  "x": [
   "Each of these methods provide gains over<cite> Johnson et al. (2017)</cite> , and combining all gave the best results."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_6",
  "x": [
   "Mini-batches can be comprised of a mix of samples from different language pairs<cite> (Johnson et al., 2017)</cite> or the training schedule can cycle through mini-batches consisting of a language pair only (Firat et al., 2016a) ."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_7",
  "x": [
   "As there are always vocabulary overlaps between different domains, there are no zero-shot translation<cite> (Johnson et al., 2017)</cite> settings in domain adaptation."
  ],
  "y": "background"
 },
 {
  "id": "b1c9b8e24916b136948610383f8ea2_8",
  "x": [
   "The compact MNMT models can handle code-mixed input, but code-mixed output remains an open problem<cite> (Johnson et al., 2017)</cite> ."
  ],
  "y": "future_work"
 },
 {
  "id": "b208c7180bc3f973b8616937b2801c_0",
  "x": [
   "The main paragraph captioning dataset is the Visual Genome corpus, introduced by <cite>Krause et al. (2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b208c7180bc3f973b8616937b2801c_1",
  "x": [
   "<cite>Krause et al. (2016)</cite> introduced the first large-scale paragraph captioning dataset, a subset of the Visual Genome dataset, along with a number of models for paragraph captioning."
  ],
  "y": "background"
 },
 {
  "id": "b208c7180bc3f973b8616937b2801c_2",
  "x": [
   "The paragraph captioning models proposed by <cite>Krause et al. (2016)</cite> included template-based (nonneural) approaches and two encoder-decoder models."
  ],
  "y": "background"
 },
 {
  "id": "b208c7180bc3f973b8616937b2801c_3",
  "x": [
   "This model is similar to the \"flat\" model in <cite>Krause et al. (2016)</cite> , except that it incorporates attention with a top-down mechanism."
  ],
  "y": "similarities background"
 },
 {
  "id": "b208c7180bc3f973b8616937b2801c_4",
  "x": [
   "Our encoder is a convolutional network pretrained for object detection (as opposed to dense captioning, as in <cite>Krause et al. (2016)</cite> and Liang et al. (2017) )."
  ],
  "y": "differences"
 },
 {
  "id": "b208c7180bc3f973b8616937b2801c_5",
  "x": [
   "Evaluation is done on the Visual Genome dataset with the splits provided by <cite>Krause et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "b2cb08afadadeddc0f8e7267163c0e_0",
  "x": [
   "In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (<cite>Banea et al., 2008</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "b2cb08afadadeddc0f8e7267163c0e_1",
  "x": [
   "In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (<cite>Banea et al., 2008</cite>) ."
  ],
  "y": "motivation"
 },
 {
  "id": "b2cb08afadadeddc0f8e7267163c0e_2",
  "x": [
   "In Romanian, due to markers of politeness and additional verbal modes embedded in the language, experiments have hinted that subjectivity detection may be easier to achieve (<cite>Banea et al., 2008</cite>) ."
  ],
  "y": "motivation"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_0",
  "x": [
   "Ranging from count-based to predictive or task-based methods, in the past years, many approaches were developed to produce word embeddings, such as Neural Probabilistic Language Model [3] , Word2Vec [28] , GloVe [32] , and more recently ELMo <cite>[33]</cite> , to name a few."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_1",
  "x": [
   "Neural Language Models can be tracked back to [3] , and more recently deep bi-directional language models (biLM) <cite>[33]</cite> have successfully been applied to word embeddings in order to incorporate contextual information."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_2",
  "x": [
   "To solve these two issues, Embedding from Language Models (ELMo) <cite>[33]</cite> was recently introduced."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_3",
  "x": [
   "ELMo <cite>[33]</cite> representations are a function of the internal layers of the bi-directional Language Model (biLM), which provides a very rich representation about the tokens."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_4",
  "x": [
   "Like in fastText [4] , ELMo <cite>[33]</cite> breaks the tradition of word embeddings by incorporating sub-word units, but ELMo <cite>[33]</cite> has also some fundamental differences with previous shallow representations such as fastText or Word2Vec."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_5",
  "x": [
   "In ELMo <cite>[33]</cite> , they use a deep representation by incorporating internal representations of the LSTM network, therefore capturing the meaning and syntactical aspects of words."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_6",
  "x": [
   "Since ELMo <cite>[33]</cite> is based on a language model, each token representation is a function of the entire input sentence, which can overcome the limitations of previous word embeddings where each word is usually modeled as an average of their multiple contexts."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_7",
  "x": [
   "Through the lens of the Ludwig Wittgenstein philosophy of language [40] , it is clear that the ELMo <cite>[33]</cite> embeddings are a better approximation to the idea of \"meaning is use\" [40] , where a word can contain a wide spectrum of different meanings depending on context, as opposed to traditional word embeddings that are not only context-independent but have a very limited definition of context."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_8",
  "x": [
   "ELMo (BoW, all layers, 5.5B) <cite>[33]</cite> : this model was obtained from the authors' website at https: //allennlp.org/elmo."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_9",
  "x": [
   "An averaging bag-of-words was employed to produce the sentence embeddings, using features from all three layers of the ELMo <cite>[33]</cite> model."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_10",
  "x": [
   "We did not employ the trainable task-specific weighting scheme described in <cite>[33]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_11",
  "x": [
   "ELMo (BoW, all layers, original) <cite>[33]</cite> : this model was obtained from the authors website at https://allennlp.org/elmo."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_12",
  "x": [
   "An averaging bag-of-words was employed to produce the sentence embeddings, using features from all three layers of the ELMo <cite>[33]</cite> model and averaging along the word dimension."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_13",
  "x": [
   "We did not employ the trainable task-specific weighting scheme described in <cite>[33]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_14",
  "x": [
   "ELMo (BoW, top layer, original) <cite>[33]</cite> : the same model and procedure as in ELMo (BoW, all layers, original) was employed, except that in this experiment, we used only the top layer representation from the ELMo <cite>[33]</cite> model."
  ],
  "y": "extends"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_15",
  "x": [
   "As shown in <cite>[33]</cite> , the higher-level LSTM representations capture context-dependent aspects of meaning, while the lower level representations capture aspects of syntax."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_16",
  "x": [
   "We did not employ the trainable task-specific weighting scheme described in <cite>[33]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_17",
  "x": [
   "As seen in Table 6 , although no method had a consistent performance among all tasks, ELMo <cite>[33]</cite> achieved best results in 5 out of 9 tasks."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_18",
  "x": [
   "Even though ELMo <cite>[33]</cite> was trained on a language model objective, it is important to note that in this experiment a bag-of-words approach was employed."
  ],
  "y": "differences"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_19",
  "x": [
   "Therefore, these results are quite impressive, which lead us to believe that excellent results can be obtained by integrating ELMo <cite>[33]</cite> and the trainable task-specific weighting scheme described in <cite>[33]</cite> into InferSent [10] ."
  ],
  "y": "future_work"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_20",
  "x": [
   "Given that ELMo <cite>[33]</cite> demonstrated excellent results on a broad set of tasks, it is clear that a proper integration of deep representation from language models can potentially improve sentence embedding methods by a significant margin and it is a promising research line."
  ],
  "y": "future_work"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_21",
  "x": [
   "As we can see in Table 8 , ELMo <cite>[33]</cite> was one of the methods that were able to achieve high performance on a broad set of different tasks."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_22",
  "x": [
   "Interestingly, in the BShift (bi-gram shift) task, where the goal is to identify whether if two consecutive tokens within the sentence have been inverted or not, ELMo <cite>[33]</cite> achieved a result that was better by a large margin when compared to all other methods, clearly a benefit of the language model objective, where it makes it easy to spot token inversion in sentences such as \"This is my Eve Christmas\", a sample from the BShift dataset."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_23",
  "x": [
   "However, the <cite>[33]</cite> bag-of-words not only achieved the best result in the SentLent task but also in many downstream tasks."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_24",
  "x": [
   "Our hypothesis is that this is due to the fact that ELMo <cite>[33]</cite> is a deep representation composed by different levels that can capture superficial features such as sentence length as well as deep linguistic properties as seen in the challenging SOMO task."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_25",
  "x": [
   "ELMo <cite>[33]</cite> word embeddings can be seen as analogous to the hypercolumns [15] approach in Computer Vision, where multiple feature levels are aggregated to form a single pixelwise representation."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_26",
  "x": [
   "We leave the exploration of probing tasks for each ELMo <cite>[33]</cite> layer representation to future research, given that it could provide a framework to expose the linguistic properties capture by each representation level of the LSTM."
  ],
  "y": "future_work"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_27",
  "x": [
   "However, in our evaluation, the p-mean [35] approach, which has achieved better results in the WC task did not exceed other techniques such as ELMo <cite>[33]</cite> bag-of-words or InferSent [10] and USE in the downstream classification tasks."
  ],
  "y": "uses"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_28",
  "x": [
   "Especially for evaluating different levels of word representations, where it can be a very useful tool to provide insights on what kind of relationships and linguistic properties each representation level (in the case of deep representations such as ELMo <cite>[33]</cite> ) is capturing."
  ],
  "y": "background"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_29",
  "x": [
   "Finally, we believe that new embedding training techniques that include language models as a way to capture context and meaning, such as ELMo <cite>[33]</cite> , combined with clever techniques of encoding sentences such as in InferSent [10] , can improve the performance of these encoders by a significant margin."
  ],
  "y": "future_work"
 },
 {
  "id": "b3952c840ce970f0e66460ea6e145a_30",
  "x": [
   "We believe that the research direction of incorporating language models and multiple levels of representations can help to provide a wide set of rich features that can capture context-dependent semantics as well as linguistic features, such as seen on ELMo <cite>[33]</cite> downstream and linguistic probing task experiments, but for sentence embeddings."
  ],
  "y": "differences future_work"
 },
 {
  "id": "b4093db328fd6839777a6d34507b34_0",
  "x": [
   "Recently,<cite> Barrett and S\u00f8gaard (2015)</cite> presented evidence that gaze features can be used to discriminate between most pairs of parts of speech (POS) ."
  ],
  "y": "background"
 },
 {
  "id": "b4093db328fd6839777a6d34507b34_1",
  "x": [
   "The data comes from <cite>(Barrett and S\u00f8gaard, 2015)</cite> and is publicly available 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "b4093db328fd6839777a6d34507b34_2",
  "x": [
   "The features predictive of grammatical functions are similar to the features that were found to be predictive of POS <cite>(Barrett and S\u00f8gaard, 2015)</cite> , however, the probability that a word gets first and second fixation were not important features for POS classification, whereas they are contributing to dependency classification."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_0",
  "x": [
   "We also compare our model with an end-toend tree-based LSTM model (SPTree) by <cite>Miwa and Bansal (2016)</cite> and show that our model performs within 1% on entity mentions and 2% on relations."
  ],
  "y": "similarities uses"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_1",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> , for example, propose an RNN comprised of a sequencebased long short term memory (LSTM) for entity identification and a separate tree-based dependency LSTM layer for relation classification using shared parameters between the two components."
  ],
  "y": "background"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_2",
  "x": [
   "In comparison to the dependency treebased LSTM model of <cite>Miwa and Bansal (2016)</cite> , our model performs within 1% on entities and 2% on relations on ACE05 dataset."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_3",
  "x": [
   "Recently, <cite>Miwa and Bansal (2016)</cite> proposed an end-to-end LSTM based sequence and treestructured model."
  ],
  "y": "background"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_4",
  "x": [
   "Recently, <cite>Miwa and Bansal (2016)</cite> proposed an end-to-end LSTM based sequence and treestructured model."
  ],
  "y": "motivation"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_5",
  "x": [
   "We formulate entity detection as a sequence labeling task using BILOU scheme similar to Li and Ji (2014) and <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_6",
  "x": [
   "We select the positive and more confident label similar to <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_7",
  "x": [
   "Multiple Relations Our approach to relation extraction is different from <cite>Miwa and Bansal (2016)</cite> .",
   "<cite>Miwa and Bansal (2016)</cite> present each pair of entities to their model for relation classification."
  ],
  "y": "differences"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_8",
  "x": [
   "For the scope of this paper, we only use the entity head phrase similar to Li and Ji (2014) and <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_9",
  "x": [
   "We use the same data splits as Li and Ji (2014) and <cite>Miwa and Bansal (2016)</cite> such that there are 351 documents for training, 80 for development and the remaining 80 documents for the test set."
  ],
  "y": "uses"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_10",
  "x": [
   "In order to compare our system with the previous systems, we report micro F1-scores, Precision and Recall on both entities and relations similar to Li and Ji (2014) and <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_12",
  "x": [
   "1 We ran the system made publicly available by <cite>Miwa and Bansal (2016)</cite> , on ACE05 dataset for filling in the missing values and comparing our system with theirs at fine-grained level."
  ],
  "y": "uses"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_13",
  "x": [
   "In this section, we perform a fine-grained comparison of our model with respect to the SPTree<cite> (Miwa and Bansal, 2016)</cite> model."
  ],
  "y": "uses"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_15",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> , in one of the ablation tests on ACE05 development set, show that their model can gain upto 2% improvement in recall by entity pretraining."
  ],
  "y": "background"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_16",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> , in one of the ablation tests on ACE05 development set, show that their model can gain upto 2% improvement in recall by entity pretraining."
  ],
  "y": "future_work"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_17",
  "x": [
   "<cite>Miwa and Bansal (2016)</cite> also use additional features such as POS tags in addition to pretrained word embeddings at the input layer."
  ],
  "y": "background"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_18",
  "x": [
   "We also compare our model to an endto-end LSTM model by <cite>Miwa and Bansal (2016)</cite> which comprises of a sequence layer for entity extraction and a tree-based dependency layer for relation classification."
  ],
  "y": "uses"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_19",
  "x": [
   "We also compare our model to an endto-end LSTM model by <cite>Miwa and Bansal (2016)</cite> which comprises of a sequence layer for entity extraction and a tree-based dependency layer for relation classification."
  ],
  "y": "similarities"
 },
 {
  "id": "b56e408c53636ac5fbf5149226319f_20",
  "x": [
   "In future, we plan to explore pretraining methods for our model which were shown to improve recall on entity and relation performance by <cite>Miwa and Bansal (2016)</cite> ."
  ],
  "y": "future_work"
 },
 {
  "id": "b722b98f50669bf3b22208a25f6854_0",
  "x": [
   "Previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks (e.g. semantic measures) <cite>[5]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b722b98f50669bf3b22208a25f6854_1",
  "x": [
   "Previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks (e.g. semantic measures) <cite>[5]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "b722b98f50669bf3b22208a25f6854_2",
  "x": [
   "Previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks (e.g. semantic measures) <cite>[5]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "b722b98f50669bf3b22208a25f6854_3",
  "x": [
   "Previous literature inform us that corpus size and posterior quality do not follow linear correlation for some learning tasks (e.g. semantic measures) <cite>[5]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_0",
  "x": [
   "(3) For entity recognition, we integrate the gazetteer with a simple, but effective machine learning classifier, and experimentally show that the extended gazetteers improve the F 1 score between 7% and 12% over our baseline approach and outperform <cite>(Zhang and Iria, 2009 )</cite> on all learned concepts (subject, location, temporal)."
  ],
  "y": "differences"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_1",
  "x": [
   "Most closely related to our own work, the authors of <cite>(Zhang and Iria, 2009 )</cite> build an approach solely on WIKIPEDIA which does not only exploit the article text but also analyzes the structural elements of WIKIPEDIA:"
  ],
  "y": "similarities"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_2",
  "x": [
   "As <cite>(Zhang and Iria, 2009 )</cite>, we reject redirection entries in this step as ambiguous."
  ],
  "y": "similarities"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_3",
  "x": [
   "This analysis is inspired by <cite>(Zhang and Iria, 2009 )</cite>, but performed on the entire abstract which is clearly dis- <cite>(Zhang and Iria, 2009)</cite> , where this is applied only to the first sentence (as WIKIPEDIA does not directly provide a concept of \"abstract\")."
  ],
  "y": "differences motivation"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_4",
  "x": [
   "It has been previously observed, <cite>(Zhang and Iria, 2009 )</cite> and (Strube and Ponzetto, 2006) , that the category graph of poor quality."
  ],
  "y": "background"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_5",
  "x": [
   "It has been previously observed, <cite>(Zhang and Iria, 2009 )</cite> and (Strube and Ponzetto, 2006) , that the category graph of poor quality."
  ],
  "y": "similarities"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_6",
  "x": [
   "The experiment domains and <cite>(Zhang and Iria, 2009 )</cite>, which we outperform for all entity types, in some cases up to 5% in F 1 score."
  ],
  "y": "differences"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_7",
  "x": [
   "In this evaluation, we use the same setup as in <cite>(Zhang and Iria, 2009 )</cite>: A corpus of 30 full length UK archaeological reports archived by the Arts and Humanities Data Service (AHDS)."
  ],
  "y": "uses"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_8",
  "x": [
   "Finally, we also include the performance numbers report in <cite>(Zhang and Iria, 2009 )</cite> for comparison (since we share <cite>their</cite> evaluation settings)."
  ],
  "y": "uses"
 },
 {
  "id": "b7278824bdae498021b899fbc6c638_9",
  "x": [
   "Table 1 show the results of the comparison: EA-GER significantly improves precision and recall over the baseline system and outperforms <cite>(Zhang and Iria, 2009 )</cite> in all cases."
  ],
  "y": "differences"
 },
 {
  "id": "b7e0879c4cac85054870146e61aa6f_0",
  "x": [
   "Subsequent to the introduction of the task, several methods have been introduced to solve the EmbodiedQA task [5, <cite>6]</cite> , using some combination of reinforcement learning, behavior cloning and hierarchical control."
  ],
  "y": "background"
 },
 {
  "id": "b7e0879c4cac85054870146e61aa6f_1",
  "x": [
   "In a later work, Das et al.<cite> [6]</cite> introduce Neural Modular Control (NMC) which is a hierarchical policy network that operates over expert sub-policy sketches."
  ],
  "y": "background"
 },
 {
  "id": "b7e0879c4cac85054870146e61aa6f_2",
  "x": [
   "Specifically we train the VQA model described in<cite> [6]</cite> on the last 5 frames of oracle navigation for 50 epochs with ADAM and a learning rate of 3e \u2212 4 using batch size 20."
  ],
  "y": "uses"
 },
 {
  "id": "b7e0879c4cac85054870146e61aa6f_3",
  "x": [
   "T 20 T 50 T any Navigation + VQA PACMAN (BC) [5] 48 BOW-CNN VQA-Only 56.5 Table 1 : We compare to the published results from<cite> [6]</cite> for agent spawned at various steps away from the target: 10, 30, 50, and anywhere in the environment."
  ],
  "y": "uses"
 },
 {
  "id": "b7e0879c4cac85054870146e61aa6f_4",
  "x": [
   "Following Das et al.<cite> [6]</cite> , we report the agent's top-1 accuracy on the test set when spawned 10, 20 and 50 steps away from the goal, denoted as T 10 , T 20 and T 50 respectively."
  ],
  "y": "uses"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_0",
  "x": [
   "The Ubuntu Dialogue Corpus is the largest freely available multi-turn based dialog corpus <cite>[1]</cite> 1 ."
  ],
  "y": "background"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_1",
  "x": [
   "In this section we briefly describe the data and evaluation metrics used in <cite>[1]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_2",
  "x": [
   "Note that pointwise method was also used in the original baselines <cite>[1]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_3",
  "x": [
   "The pointwise architectures reported in <cite>[1]</cite> included (i) TF-IDF, (ii) RNN and (iii) LSTM."
  ],
  "y": "background"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_4",
  "x": [
   "To match the original setup of <cite>[1]</cite> we use the same training data 3 ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_5",
  "x": [
   "Baselines from <cite>[1]</cite> Our Table 1 : Results of our experiments compared to the results reported in <cite>[1]</cite> ."
  ],
  "y": "background uses"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_6",
  "x": [
   "In this work we achieved a new state-of-the-art results on the next utterance ranking problem recently introduced in <cite>[1]</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "bb2609c568540390a560757dd40b32_7",
  "x": [
   "This agrees with Figure 3 of the previous evaluation <cite>[1]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "bb45a61408a0ade8ce0aba2b8f9ce7_0",
  "x": [
   "We will then discuss some of the current and upcoming challenges of combining language, vision and actions, and introduce some recently-released interactive 3D simulation environments designed for this purpose (Anderson et al., 2018b; <cite>Das et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "bb45a61408a0ade8ce0aba2b8f9ce7_1",
  "x": [
   "Although models that link vision, language and actions have a rich history (Tellex et al., 2011; Paul et al., 2016; Misra et al., 2017) , we will focus primarily on embodied 3D environments (Anderson et al., 2018b; , considering tasks such as visual navigation from natural language instructions (Anderson et al., 2018b) , and question answering<cite> (Das et al., 2018</cite>; Gordon et al., 2018) ."
  ],
  "y": "background"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_0",
  "x": [
   "Sparsification of the RNN is usually performed either at the level of individual weights (unstructured sparsification) [13, 11,<cite> 1]</cite> or at the level of neurons [14] (structured sparsification -removing weights by groups corresponding to neurons)."
  ],
  "y": "background"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_1",
  "x": [
   "We propose to add an intermediate level of sparsification between individual weights <cite>[1]</cite> and neurons [14] -gates (see fig. 1 , left)."
  ],
  "y": "uses extends"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_2",
  "x": [
   "We implement the idea for LSTM in two frameworks: pruning [14] and Bayesian sparsification <cite>[1]</cite> and observe that resulting gate structures (which gates are constant and which are not) vary for different NLP tasks."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_3",
  "x": [
   "We rely on Sparse Variational Dropout [10,<cite> 1]</cite> to sparsify individual weights."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_5",
  "x": [
   "In the Bayesian framework, we perform an evaluation on the text classification (datasets IMDb [6] and AGNews [17]) and language modeling (dataset PTB, character and word level tasks) following <cite>[1]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_6",
  "x": [
   "Here we regularize and sparsify all layers following <cite>[1]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_7",
  "x": [
   "In <cite>[1]</cite> , SparseVD is adapted to the RNNs."
  ],
  "y": "background"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_8",
  "x": [
   "To estimate the expectation in (1), we sample weights from the approximate posterior distribution in the same way as in <cite>[1]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_9",
  "x": [
   "Since in text classification tasks, usually only a small number of input words are important, we use additional multiplicative weights to sparsify the input vocabulary following Chirkova et al. <cite>[1]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_10",
  "x": [
   "Models for the text classification and the character-level LM are trained in the same setting as in <cite>[1]</cite> (we used the code provided by the authors)."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_12",
  "x": [
   "This configuration corresponds to a model of Chirkova et al. <cite>[1]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "bb5e6e32d7e507bc6d943719c02902_13",
  "x": [
   "This configuration corresponds to a model of Chirkova et al. <cite>[1]</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_0",
  "x": [
   "<cite>[2]</cite> ever proposed a approach to close the goal."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_1",
  "x": [
   "[4] extend the work of <cite>[2]</cite> with a neural network based approach."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_2",
  "x": [
   "<cite>[2]</cite> improved the sentiment classification by involving knowledge."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_3",
  "x": [
   "\u2022 Knowledge Base (KB): The knowledge Base <cite>[2]</cite> mainly used to maintain the previous knowledge."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_4",
  "x": [
   "\u2022 Knowledge-Base Learner (KBL): The Knowledge-Based Learner <cite>[2]</cite> aims to retrieve and transfer previous knowledge to the current task."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_5",
  "x": [
   "Previous classical paper <cite>[2]</cite> chose the sentiment classification as the learning target because it could be regarded as a large task as well as a group of related sub-tasks in the different domains."
  ],
  "y": "motivation"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_6",
  "x": [
   "Previous classical paper <cite>[2]</cite> chose the sentiment classification as the learning target because it could be regarded as a large task as well as a group of related sub-tasks in the different domains."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_7",
  "x": [
   "As the previous work <cite>[2]</cite> , this paper also uses Na\u00efve Bayes as the knowledge can be presented by the probability."
  ],
  "y": "uses"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_8",
  "x": [
   "\"Lifelong Sentiment Classification\" (\"LSC\" for simple below) <cite>[2]</cite> records that which domain does a word have the sentiment orientation."
  ],
  "y": "background"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_9",
  "x": [
   "Although LSC <cite>[2]</cite> already raised a lifelong approach, it only aims to improve the classification accuracy."
  ],
  "y": "motivation"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_10",
  "x": [
   "Although LSC <cite>[2]</cite> already raised a lifelong approach, it only aims to improve the classification accuracy."
  ],
  "y": "extends"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_11",
  "x": [
   "We use the same formula below as in the LSC <cite>[2]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_12",
  "x": [],
  "y": "motivation"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_13",
  "x": [
   "Although LSC <cite>[2]</cite> considered the difference among domains, it still is a typical supervised learning approach."
  ],
  "y": "motivation"
 },
 {
  "id": "bb74dd634a8fc5cdb2f4f3294b6bc5_14",
  "x": [
   "In the experiment, we use the same datasets as LSC <cite>[2]</cite> used."
  ],
  "y": "uses"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_0",
  "x": [
   "In the generation step, a set of possible substitutions for the target word is commonly created by querying semantic databases such as Wordnet (Devlin and Tait, 1998) , learning substitution rules from sentence-aligned parallel corpora of complex-simple texts<cite> (Horn et al., 2014</cite>; Paetzold and Specia, 2017) , and learning word embeddings from a large corpora to obtain similar words of the complex word (Glava\u0161 and\u0160tajner, 2015; Kim et al., 2016; Specia, 2016a, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_1",
  "x": [
   "State-of-the-art approaches to ranking in lexical simplification exploit supervised machine learning-based methods that rely mostly on surface features, such as word frequency, word length and n-gram probability, for training the model<cite> (Horn et al., 2014</cite>; Bingel and S\u00f8gaard, 2016; Specia, 2016a, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_2",
  "x": [
   "State-of-the-art approaches to ranking in lexical simplification exploit supervised machine learning-based methods that rely mostly on surface features, such as word frequency, word length and n-gram probability, for training the model<cite> (Horn et al., 2014</cite>; Bingel and S\u00f8gaard, 2016; Specia, 2016a, 2017) ."
  ],
  "y": "motivation"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_3",
  "x": [
   "Following previous works that used supervised machine learning for ranking in lexical simplification<cite> (Horn et al., 2014</cite>; Paetzold and Specia, 2017) , we train the DSSM using the LexMTurk dataset<cite> (Horn et al., 2014)</cite> , which contains 500 instances composed of a sentence, a target word and substitution candidates ranked by simplicity (Paetzold and Specia, 2017) ."
  ],
  "y": "uses"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_4",
  "x": [
   "Since both datasets contain instances from the LexMturk dataset<cite> (Horn et al., 2014)</cite> , which we use for training the DNN, we remove the overlap instances between training and test datasets 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_5",
  "x": [
   "We adopt the same evaluation metrics featured in Glava\u0161 and\u0160tajner (2015) and<cite> Horn et al. (2014)</cite> : 1) precision: ratio of correct simplifications out of all the simplifications made by the system; 2) accuracy: ratio of correct simplifications out of all words that should have been simplified; and 3) changed: ratio of target words changed by the system."
  ],
  "y": "uses"
 },
 {
  "id": "bd3663405d2d68f943acc73720b42d_6",
  "x": [
   "with default parameters) for ranking substitution candidates, similar to the method described in<cite> (Horn et al., 2014)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_0",
  "x": [
   "This result motivates us to replace the reconstructionbased objective of<cite> Zhang et al. (2017)</cite> with our sentence content probe objective in a semisupervised setting."
  ],
  "y": "motivation"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_1",
  "x": [
   "Methods that embed a paragraph into a single vector have been successfully integrated into many NLP applications, including text classification<cite> (Zhang et al., 2017)</cite> , document retrieval (Le and Mikolov, 2014) , and semantic similarity and relatedness (Dai et al., 2015; Chen, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_2",
  "x": [
   "We specifically investigate the paragraph embedding method of<cite> Zhang et al. (2017)</cite> , which consists of a CNN-based encoder-decoder model paired with a reconstruction objective to learn powerful paragraph embeddings that are capable of accurately reconstructing long paragraphs."
  ],
  "y": "uses"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_4",
  "x": [
   "In this section, we first fully specify our probe task before comparing the model of<cite> Zhang et al. (2017)</cite> to a simple bag-of-words model."
  ],
  "y": "differences"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_5",
  "x": [
   "Paragraphs to train our classifiers are extracted from the Hotel Reviews corpus (Li et al., 2015) , which has previously been used for evaluating the quality of paragraph embeddings (Li et al., 2015; <cite>Zhang et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_6",
  "x": [
   "With fine-tuning, CNN-SC substantially boosts accuracy and generalization We switch gears Table 4 : CNN-SC outperforms other baseline models that do not use external data, including CNN-R. All baseline models are taken from<cite> Zhang et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_8",
  "x": [
   "Text embeddings and probe tasks A variety of methods exist for obtaining fixed-length dense vector representations of words (e.g., Mikolov et al., 2013; Pennington et al., 2014; Peters et al., 2018) , sentences (e.g., Kiros et al., 2015; Conneau et al., 2017; Subramanian et al., 2018; Cer et al., 2018) , and larger bodies of text (e.g., Le and Mikolov, 2014; Dai et al., 2015; Iyyer et al., 2015; Li et al., 2015; Chen, 2017; <cite>Zhang et al., 2017)</cite> To analyze word and sentence embeddings, recent work has studied classification tasks that probe them for various linguistic properties (Shi et al., 2016; Adi et al., 2017; Belinkov et al., 2017a,b; Conneau et al., 2018; Tenney et al., 2019) ."
  ],
  "y": "background"
 },
 {
  "id": "be39cfec0479ace0a7e08508239cb0_9",
  "x": [
   "In this paper, we investigate a state-of-the-art paragraph embedding method proposed by<cite> Zhang et al. (2017)</cite> and discover that it cannot reliably tell whether a given sentence occurs in the input paragraph or not."
  ],
  "y": "motivation"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_0",
  "x": [
   "Our algorithm builds up on the span-based parser <cite>(Cross and Huang, 2016)</cite> ; it employs the strong generalization power of bi-directional LSTMs, and parses efficiently and robustly with an extremely simple span-based feature set that does not use any tree structure information."
  ],
  "y": "differences extends"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_1",
  "x": [
   "3. Even though it simultaneously performs constituency parsing, our parser does not use any explicit syntactic feature, nor does it need any binarization of discourse trees, thanks to the powerful span-based framework of<cite> Cross and Huang (2016)</cite> (Section 3)."
  ],
  "y": "differences extends"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_2",
  "x": [
   "As mentioned above, the input sequences are substantially longer than PTB parsing, so we choose linear-time parsing, by adapting a popular greedy constituency parser, the span-based constituency parser of<cite> Cross and Huang (2016)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_3",
  "x": [
   "But different from<cite> Cross and Huang (2016)</cite> , after a structural action, we choose to keep the last branching point k, i.e., i Some text and the symbol or scaled k j (mostly for combine, but also trivially for shift)."
  ],
  "y": "differences extends"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_4",
  "x": [
   "This midpoint k disappears after a label action; therefore we can use the shape of the last span on the stack (whether it contains the split point, i.e., i xt and the symbol or scaled k j or i Some text and the symbol or scaled j ) to determine the parity of the step and thus no longer need to carry the step z in the state as in<cite> Cross and Huang (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_5",
  "x": [
   "The scoring functions in the deductive system (Figure 4 ) are calculated by an underlying neural model, which is similar to the bi-directional LSTM model in<cite> Cross and Huang (2016)</cite> that evaluates based on span boundary features."
  ],
  "y": "similarities"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_6",
  "x": [
   "We use the \"training with exploration\" strategy (Goldberg and Nivre, 2013) and the dynamic oracle mechanism described in<cite> Cross and Huang (2016)</cite> to make sure the model can handle unseen parsing configurations properly."
  ],
  "y": "similarities uses"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_7",
  "x": [
   "For most of the hyperparameters we settle with the same values suggested by<cite> Cross and Huang (2016)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "be77eed8430b6492c81ae6535f1dd5_8",
  "x": [
   "The result is shown in Table 1 . Note that in constituency level, the accuracy is not directly comparable with the accuracy reported in<cite> Cross and Huang (2016)</cite> , since: a) our parser is trained on a much smaller dataset (RST Treebank is about 1/6 of Penn Treebank); b) the parser is trained to optimize the discourse-level accuracy."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_1",
  "x": [
   "We show that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection <cite>(Bolukbasi et al., 2016)</cite> is, under certain conditions, equivalent to training on an unbiased corpus."
  ],
  "y": "uses"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_2",
  "x": [
   "In addition to gender-appropriate analogies such as king:queen::man:woman, stereotypical analogies such as doctor:nurse::man:woman also hold in SGNS embedding spaces <cite>(Bolukbasi et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_3",
  "x": [
   "We find that contrary to what<cite> Bolukbasi et al. (2016)</cite> suggested, word embeddings should not be normalized before debiasing, as vector length can contain important information (Ethayarajh et al., 2018) ."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_4",
  "x": [
   "In contrast to the supervised method proposed by<cite> Bolukbasi et al. (2016)</cite> for identifying these gender-specific words, we introduce an unsupervised method."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_5",
  "x": [
   "While this subspace projection method precluded gender-biased analogies from holding in the embedding space,<cite> Bolukbasi et al. (2016)</cite> did not provide any theoretical guarantee that the vectors were unbiased (i.e., equivalent to vectors that would be obtained from training on a gender-agnostic corpus with no reconstruction error)."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_6",
  "x": [
   "Experiments by<cite> Bolukbasi et al. (2016)</cite> found that debiasing word embeddings using the subspace projection method precludes gender-biased analogies from holding."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_7",
  "x": [
   "Experiments by<cite> Bolukbasi et al. (2016)</cite> found that debiasing word embeddings using the subspace projection method precludes gender-biased analogies from holding."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_8",
  "x": [
   "This implies that the co-occurrence matrix M d that is reconstructed using the debiased word matrix W d is also unbiased with respect to S. The subspace projection method is therefore far more powerful than initially stated in<cite> Bolukbasi et al. (2016)</cite> : not only can it be applied to any embedding model that implicitly does matrix factorization (e.g., GloVe, SGNS), but debiasing word vectors in this way is equivalent to training on a perfectly unbiased corpus when there is no reconstruction error."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_9",
  "x": [
   "The only other metric of note quantifies association as |cos( w, b)| c , where b is the bias subspace and c \u2208 R the \"strictness\" of the measurement <cite>(Bolukbasi et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_10",
  "x": [
   "To use the terminology in<cite> Bolukbasi et al. (2016)</cite> , RIPA is the scalar projection of a word vector onto a onedimensional bias subspace defined by the unit vector b. In their experiments,<cite> Bolukbasi et al. (2016)</cite> defined b as the first principal component for a set of gender difference vectors (e.g., man \u2212 woman)."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_11",
  "x": [
   "We create lists of biased and appropriate words using the<cite> Bolukbasi et al. (2016)</cite> lists of gender-biased and gender-appropriate analogies."
  ],
  "y": "uses"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_12",
  "x": [
   "Where S is a set of gender-defining word pairs 1 from<cite> Bolukbasi et al. (2016)</cite> and \u03bb , \u03b1 are the model-specific constants defined in section 5.1,"
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_13",
  "x": [
   "Where S is a set of gender-defining word pairs 1 from<cite> Bolukbasi et al. (2016)</cite> and \u03bb , \u03b1 are the model-specific constants defined in section 5.1,"
  ],
  "y": "uses"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_14",
  "x": [
   "The<cite> Bolukbasi et al. (2016)</cite> method of identifying these words is ineffective: it ends up precluding most gender-appropriate analogies (dotted line, left) while preserving most gender-biased analogies (dotted line, right)."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_15",
  "x": [
   "To use the subspace projection method <cite>(Bolukbasi et al., 2016)</cite> , one must have prior knowledge of which words are gender-appropriate, so that they are not debiased."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_16",
  "x": [
   "To create an exhaustive list of gender-appropriate words,<cite> Bolukbasi et al. (2016)</cite> started with a small, human-labelled set of words and then trained an SVM to predict more genderappropriate terms in the vocabulary."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_17",
  "x": [
   "The way in which<cite> Bolukbasi et al. (2016)</cite> evaluated their method is unorthodox: they tested the ability of their debiased embedding space to generate new analogies."
  ],
  "y": "background"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_18",
  "x": [
   "In contrast, the<cite> Bolukbasi et al. (2016)</cite> approach 2 Available at https://github.com/tolga-b/debiaswe preserves only 16.5% of appropriate analogies with a strength of at least 0.5 while preserving 80.0% of biased ones."
  ],
  "y": "differences"
 },
 {
  "id": "bead17ef9512f960461b681a78be4c_19",
  "x": [
   "Recall that we use the same debiasing method as<cite> Bolukbasi et al. (2016)</cite> ; the difference in performance can only be ascribed to how we choose the gender-appropriate words."
  ],
  "y": "differences uses"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_0",
  "x": [
   "I assess the extent to which the recently introduced BERT model captures English syntactic phenomena, using (1) naturally-occurring subject-verb agreement stimuli; (2) <cite>\"coloreless green ideas\"</cite> subject-verb agreement stimuli, in which content words in natural sentences are randomly replaced with words sharing the same part-of-speech and inflection; and (3) manually crafted stimuli for subject-verb agreement and reflexive anaphora phenomena."
  ],
  "y": "motivation"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_1",
  "x": [
   "<cite>(Gulordava et al., 2018 )</cite> also consider subject-verb agreement, but in a <cite>\"colorless green ideas\"</cite> setting in which content words in naturally occurring sentences are replaced with random words with the same partof-speech and inflection, thus ensuring a focus on syntax rather than on selectional-preferences based cues."
  ],
  "y": "differences"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_2",
  "x": [
   "<cite>(Gulordava et al., 2018 )</cite> also consider subject-verb agreement, but in a <cite>\"colorless green ideas\"</cite> setting in which content words in naturally occurring sentences are replaced with random words with the same partof-speech and inflection, thus ensuring a focus on syntax rather than on selectional-preferences based cues."
  ],
  "y": "background"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_3",
  "x": [
   "I adapt the evaluation protocol and stimuli of Linzen et al. (2016) , <cite>Gulordava et al. (2018)</cite> and Marvin and Linzen (2018) to the bidirectional setting required by BERT, and evaluate the pretrained BERT models (both the LARGE and the BASE models)."
  ],
  "y": "extends"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_4",
  "x": [
   "I use the stimuli provided by (Linzen et al., 2016; <cite>Gulordava et al., 2018</cite>; Marvin and Linzen, 2018) , but change the experimental protocol to adapt it to the bidirectional nature of the BERT model."
  ],
  "y": "extends"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_5",
  "x": [
   "<cite>Gulordava et al. (2018)</cite> also start with existing sentences.",
   "However, in order to control for the possibillity of the model learning to rely on \"semantic\" selectional-preferences cues rather than syntactic ones, <cite>they</cite> replace each content word with random words from the same part-ofspeech and inflection.",
   "This results in \"<cite>coloreless green ideas</cite>\" nonce sentences."
  ],
  "y": "background"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_6",
  "x": [
   "This differs from Linzen et al. (2016) and <cite>Gulordava et al. (2018)</cite> by considering the entire sentence (excluding the verb) and not just its prefix leading to the verb, and differs from Marvin and Linzen (2018) by conditioning the focus verb on bidirectional context."
  ],
  "y": "motivation extends"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_7",
  "x": [
   "I also discard the agreement cases involving the verbs is or are in Linzen et al. (2016) and in <cite>Gulordava et al. (2018)</cite> , because some of them are copular construction, in which strong agreement hints can be found also on the object following the verb."
  ],
  "y": "differences extends"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_8",
  "x": [
   "I similarly discard 680 sentences from (Linzen et al., 2016) where the focus verb or its inflection were one of 108 out-ofvocabulary tokens, 6 and 28 sentence-pairs (8 tokens 7 ) from <cite>(Gulordava et al., 2018)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_10",
  "x": [
   "While not strictly comparable, the numbers reported by <cite>Gulordava et al. (2018)</cite> for the LSTM in this condition (on All) is 74.1 \u00b1 1.6."
  ],
  "y": "uses"
 },
 {
  "id": "bebcad79900e9a4a25020ed0d886b5_11",
  "x": [
   "The <cite>Gulordava et al. (2018)</cite> and Marvin and Linzen (2018) conditions rule out the possibility of overly relying on selectional preference cues or memorizing the wikipedia training data, and suggest real syntactic generalization is taking place."
  ],
  "y": "uses background"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_0",
  "x": [
   "Parses are weighted by their probabilities and combined using an adapted version of<cite> Sagae and Lavie (2006)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_1",
  "x": [
   "Researchers have proposed many algorithms to combine parses from multiple parsers into one final parse (Henderson and Brill, 1999; Zeman an\u010f Zabokrtsk\u1ef3, 2005;<cite> Sagae and Lavie, 2006</cite>; Nowson and Dale, 2007; Fossum and Knight, 2009; Petrov, 2010; Johnson and Ural, 2010; Huang et al., 2010; McDonald and Nivre, 2011; Shindo et al., 2012; Narayan and Cohen, 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_2",
  "x": [
   "We then adapt parse combination methods by Henderson and Brill (1999) ,<cite> Sagae and Lavie (2006)</cite> , and Fossum and Knight (2009) to fuse the constituents from the n parses into a single tree."
  ],
  "y": "extends"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_3",
  "x": [
   "Our extension takes the n-best trees from a parser as if they are 1-best parses from n parsers, then follows<cite> Sagae and Lavie (2006)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_4",
  "x": [
   "Varying the threshold changes the precision/recall balance since a high threshold adds only the most confident constituents to the chart <cite>(Sagae and Lavie, 2006)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_5",
  "x": [
   "We also compare against model combination using our reimplementation of<cite> Sagae and Lavie (2006)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_6",
  "x": [
   "The threshold was set to 0.42 to optimize model combination F 1 on development data (similar to Setting 2 for constituency parsing in<cite> Sagae and Lavie (2006)</cite> )."
  ],
  "y": "similarities"
 },
 {
  "id": "c022b7cf4568e26c7408a835eaafb7_7",
  "x": [
   "We explored two ways to apply fusion when starting from constituency parses: (1) fuse constituents and then convert them to dependencies and (2) convert to dependencies then fuse the dependencies as in<cite> Sagae and Lavie (2006)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_0",
  "x": [
   "Since we will compare our results mainly to<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> , we will only employ the gold and silver data."
  ],
  "y": "uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_1",
  "x": [
   "Since we will compare our results mainly to<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> , we will only employ the gold and silver data."
  ],
  "y": "uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_2",
  "x": [
   "We represent the source and target data in the same way as<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> , who represent the source sentence as a sequence of characters, with a special character indicating uppercase characters."
  ],
  "y": "uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_3",
  "x": [
   "We employ a recurrent sequence-to-sequence neural network with attention (Bahdanau et al., 2014) and two bi-LSTM layers, similar to the one used by<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_4",
  "x": [
   "The produced DRSs go through a strict syntactic and semantic validation process, as described in<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_5",
  "x": [
   "We now compare our best models to previous parsers 4 (Bos, 2015;<cite> Van Noord, Abzianidze, Toral, and Bos, 2018)</cite> and two baseline systems, SPAR and SIM-SPAR."
  ],
  "y": "uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_6",
  "x": [
   "As previously indicated,<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> used a similar sequence-to-sequence model as our current approach, but implemented in OpenNMT and without the linguistic features."
  ],
  "y": "differences similarities uses"
 },
 {
  "id": "c067711a58722737ef8b7ea987bcf3_7",
  "x": [
   "When compared to<cite> Van Noord, Abzianidze, Toral, and Bos (2018)</cite> , retrained with the same data used in our systems, the largest improvement (3.6 and 3.5 for dev and test) comes from switching framework and changing certain parameters such as the optimizer and learning rate."
  ],
  "y": "differences"
 },
 {
  "id": "c293e9fb8d6382f185a3efeaf0dbf7_0",
  "x": [
   "Different from Ma and Hovy (2016) and<cite> Liu et al. (2018)</cite> , choose a different data split on the POS dataset."
  ],
  "y": "differences extends"
 },
 {
  "id": "c293e9fb8d6382f185a3efeaf0dbf7_1",
  "x": [
   "Some literature reports results using mean and standard deviation under different random seeds (Chiu and Nichols, 2016; Peters et al., 2017; <cite>Liu et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c293e9fb8d6382f185a3efeaf0dbf7_2",
  "x": [
   "built a BiLSTM-CRF structure, which has been extended by adding character-level LSTM (Lample et al., 2016; <cite>Liu et al., 2018)</cite> , GRU (Yang et al., 2016) , and CNN (Chiu and Nichols, 2016; Ma and Hovy, 2016) features."
  ],
  "y": "background"
 },
 {
  "id": "c293e9fb8d6382f185a3efeaf0dbf7_3",
  "x": [
   "LSTM has been widely used in sequence labeling (Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016; <cite>Liu et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c293e9fb8d6382f185a3efeaf0dbf7_4",
  "x": [
   "The NER dataset has been standardly split in Tjong Kim Sang and De Meulder (2003 (Toutanova et al., 2003; Santos and Zadrozny, 2014; Ma and Hovy, 2016; <cite>Liu et al., 2018)</cite> , we adopt the standard splits by using sections 0-18 as training set, sections 19-21 as development set and sections 22-24 as test set."
  ],
  "y": "differences"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_0",
  "x": [
   "While the seminal work by Bolukbasi et al. (2016a <cite>Bolukbasi et al. ( , 2016b</cite> concerns the identification and mitigation of gender bias in pretrained word embeddings, Zhao et al. (2018) provide insights into the possibilities of learning embeddings that are gender neutral."
  ],
  "y": "background"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_1",
  "x": [
   "Park et al. (2018) discuss different ways of mitigating gender bias, in the context of abusive language detection, ranging from debiasing a model by using the hard debiased word embeddings produced by<cite> Bolukbasi et al. (2016b)</cite> , to manipulating the data prior to training a model by swapping masculine and feminine mentions, and employing transfer learning from a model learned from less biased text."
  ],
  "y": "background"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_2",
  "x": [
   "Gonen and Goldberg (2019) contest the approaches to debiasing word embeddings presented by<cite> Bolukbasi et al. (2016b)</cite> and Zhao et al. (2018) , arguing that while the bias is reduced when measured according to its definition, i.e., dampening the impact of the general gender direction in the vector space, \"the actual effect is mostly hiding the bias, not removing it\"."
  ],
  "y": "background"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_3",
  "x": [
   "We also provide further evidence of the inability of the debiasing method proposed by<cite> Bolukbasi et al. (2016b)</cite> to handle the type of bias we are concerned with."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_4",
  "x": [
   "We apply the debiasing methodology in<cite> (Bolukbasi et al., 2016b)</cite> to the pretrained embedddings."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_5",
  "x": [
   "We use the same methodology for growing a seed set of gender specific words into a larger set as described in<cite> (Bolukbasi et al., 2016b)</cite> , and end up with 486 manually curated gender specific words, including e.g., farfar (paternal grandfather), tvillingsystrar (twin sisters), and matriark (matriarch)."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_6",
  "x": [
   "The approach described by<cite> (Bolukbasi et al., 2016b)</cite> includes an equalize step to make all gender neutral words equidistant to each of the members of a given equality set of word pairs."
  ],
  "y": "background"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_7",
  "x": [
   "We now turn to investigate the effect the hard debiasing operation has on the embedding spaces, using the intrinsic evaluation methodology of<cite> Bolukbasi et al. (2016b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c2952b2da147d5f128cdbd5d8074a5_8",
  "x": [
   "The number of stereotypical analogy pairs output by the Swedish models is small compared to the numbers reported by<cite> Bolukbasi et al. (2016b)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_0",
  "x": [
   "\u2022 We present a novel adaptation of graph-based semi-supervised learning (Zhu et al., 2003) to the sentiment analysis domain, extending past supervised learning work by<cite> Pang and Lee (2005)</cite> ;"
  ],
  "y": "extends"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_1",
  "x": [
   "We experiment with positive-sentence percentage (PSP) based similarity which is proposed in <cite>(Pang and Lee, 2005)</cite> , and mutual-information modulated word-vector cosine similarity."
  ],
  "y": "uses"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_2",
  "x": [
   "2. Optionally, we are given numerical rating predictions\u0177 l+1 , . . . ,\u0177 n on the unlabeled documents from a separate learner, for instance -insensitive support vector regression (Joachims, 1999; Smola and Sch\u00f6lkopf, 2004) used by <cite>(Pang and Lee, 2005)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_3",
  "x": [
   "2. Optionally, we are given numerical rating predictions\u0177 l+1 , . . . ,\u0177 n on the unlabeled documents from a separate learner, for instance -insensitive support vector regression (Joachims, 1999; Smola and Sch\u00f6lkopf, 2004) used by <cite>(Pang and Lee, 2005)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_4",
  "x": [
   "Before moving on to experiments, we note an interesting connection to the supervised learning method in <cite>(Pang and Lee, 2005)</cite> , which formulates rating inference as a metric labeling problem (Kleinberg and Tardos, 2002) ."
  ],
  "y": "similarities"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_5",
  "x": [
   "It corresponds exactly to the supervised, non-transductive version of metric labeling, except we use squared difference while <cite>(Pang and Lee, 2005)</cite> used absolute difference."
  ],
  "y": "differences"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_6",
  "x": [
   "We performed experiments using the movie review documents and accompanying 4-class (C = {0, 1, 2, 3}) labels found in the \"scale dataset v1.0\" available at http://www.cs.cornell.edu/people/pabo/ movie-review-data/ and first used in <cite>(Pang and Lee, 2005)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_8",
  "x": [
   "We compare our graph-based semi-supervised method with two previously studied methods: regression and metric labeling as in <cite>(Pang and Lee, 2005)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_9",
  "x": [
   "For consistency with <cite>(Pang and Lee, 2005)</cite> , supervised metric labeling results with this measure are reported under 'reg+PSP."
  ],
  "y": "similarities"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_10",
  "x": [
   "PSP i is defined in <cite>(Pang and Lee, 2005)</cite> as the percentage of positive sentences in review x i ."
  ],
  "y": "uses"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_11",
  "x": [
   "We identified positive sentences using SVM instead of Na\u00efve Bayes, but the trend is qualitatively the same as in <cite>(Pang and Lee, 2005)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_12",
  "x": [
   "In an attempt to reproduce the findings in <cite>(Pang and Lee, 2005)</cite> , we tuned c, \u03b1 with cross validation."
  ],
  "y": "similarities"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_13",
  "x": [
   "Note that we learned a single set of shared parameters for all authors, whereas <cite>(Pang and Lee, 2005)</cite> tuned k and \u03b1 on a per-author basis."
  ],
  "y": "differences"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_14",
  "x": [
   "<cite>(Pang and Lee, 2005)</cite> found that their metric labeling method, when applied to the 4-class data we are using, was not statistically better than regression, though they observed some improvement for authors (c) and (d)."
  ],
  "y": "background"
 },
 {
  "id": "c384f48d5f04ea8d63bbbb94a3b24b_15",
  "x": [
   "For example, several positive sentences followed by a few concluding negative sentences could indicate an overall negative review, as observed in prior work <cite>(Pang and Lee, 2005)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_0",
  "x": [
   "On the proverb data, the novel features result in compact models that significantly outperform existing features designed for word-level metaphor detection in other genres <cite>(Klebanov et al., 2014)</cite> , such as news and essays."
  ],
  "y": "differences"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_1",
  "x": [
   "Similarly to<cite> Klebanov et al. (2014)</cite> , we classify each content word (i.e., adjective, noun, verb or adverb) appearing in a proverb as being used metaphorically or not.",
   "As a baseline, we use a set of features very similar to the one proposed by<cite> Klebanov et al. (2014)</cite> .",
   "To obtain results more easily comparable with<cite> Klebanov et al. (2014)</cite>, we use the same classifier, i.e., logistic regression, in the implementation bundled with the scikit-learn package (Pedregosa et al., 2011) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_2",
  "x": [
   "Unigrams (u B ):<cite> Klebanov et al. (2014)</cite> use all content word forms as features without stemming or lemmatization."
  ],
  "y": "differences"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_3",
  "x": [
   "Similarly to<cite> Klebanov et al. (2014)</cite> , the mean concreteness ratings, ranging from 1 to 5, are binned in 0.25 increments."
  ],
  "y": "similarities"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_4",
  "x": [
   "Finally, Table 3 shows the effect of the different feature sets on VUAMC used by<cite> Klebanov et al. (2014)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_5",
  "x": [
   "We use the same 12-fold data split as<cite> Klebanov et al. (2014)</cite> , and also in this case we perform a grid-search to optimize the meta-parameter C of the logistic regression classifier."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c3f6140bd69d1eef0124665e651c0c_6",
  "x": [
   "Besides, the addition of N always leads to more balanced models, by compensating for the relatively lower precision of B. Due to the lack of a separate test set, as in the original setup by<cite> Klebanov et al. (2014)</cite> , and to the high dimensionality of B's lexicalized features, we cannot rule out over-fitting as an explanation for the relatively good performance of B on this benchmark.",
   "In particular, our implementation of the B features performs better than reported by<cite> Klebanov et al. (2014)</cite> on all four genres, namely: 0.52 vs. 0.51 for \"news\", 0.51 vs. 0.28 for \"academic\", 0.39 vs. 0.28 for \"conversation\" and 0.42 vs. 0.33 for \"fiction\"."
  ],
  "y": "differences extends"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_0",
  "x": [
   "Approximate parsers have therefore been introduced, based on belief propagation (Smith and Eisner, 2008) , dual decomposition , or multi-commodity flows (Martins et al., 2009<cite> (Martins et al., , 2011</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_1",
  "x": [
   "Instead, we adapt AD 3 , the dual decomposition algorithm proposed by<cite> Martins et al. (2011)</cite> , to handle third-order features, by introducing specialized head automata."
  ],
  "y": "uses"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_2",
  "x": [
   "\u2022 We make our parser substantially faster than the many-components approach of<cite> Martins et al. (2011)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_3",
  "x": [
   "Our parsers add also arbitrary siblings (not necessarily consecutive) and head bigrams, as in<cite> Martins et al. (2011)</cite> , in addition to third-order features for grand-and tri-siblings ."
  ],
  "y": "uses"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_4",
  "x": [
   "In this paper, we employ alternating directions dual decomposition (AD 3 ;<cite> Martins et al., 2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_5",
  "x": [
   "This opens the door for larger subproblems (such as the combination of trees and head automata in instead of a many-components approach <cite>(Martins et al., 2011)</cite> , while still enjoying faster convergence."
  ],
  "y": "differences motivation background"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_6",
  "x": [
   "Past work in dependency parsing considered either (i) a few \"large\" components, such as trees and head automata (Smith and Eisner, 2008; , or (ii) many \"small\" components, coming from a multi-commodity flow formulation (Martins et al., 2009<cite> (Martins et al., , 2011</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_7",
  "x": [
   "Following<cite> Martins et al. (2011)</cite> , the problem of obtaining the best-scored tree can be written as follows:"
  ],
  "y": "uses"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_8",
  "x": [
   "The AD 3 algorithm <cite>(Martins et al., 2011)</cite> alternates among the following iterative updates:"
  ],
  "y": "background"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_9",
  "x": [
   "While closed-form solutions have been developed for some specialized components <cite>(Martins et al., 2011)</cite> , this problem is in general more difficult than the one arising in the subgradient algorithm."
  ],
  "y": "motivation background"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_10",
  "x": [
   "While closed-form solutions have been developed for some specialized components <cite>(Martins et al., 2011)</cite> , this problem is in general more difficult than the one arising in the subgradient algorithm."
  ],
  "y": "extends"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_11",
  "x": [
   "Each score \u03c3 HB (m, h, h ) is obtained via features that look at the heads of consecutive words (as in<cite> Martins et al. (2011)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_12",
  "x": [
   "We handle arbitrary siblings as in<cite> Martins et al. (2011)</cite> , defining O(L 3 ) component functions of the form f ASIB h,m,s (z h,m , z h,s ) = \u03c3 ASIB (h, m, s)."
  ],
  "y": "uses"
 },
 {
  "id": "c4a9b122e8f1b9e98197743c94fea2_13",
  "x": [
   "By looking at the two bottom blocks, we observe that our parser has slightly better accuracies than recent projective parsers, with comparable speed levels (with the exception of the highly optimized vine cascade approach of Rush and Petrov, 2012 Martins et al. (2010<cite> Martins et al. ( , 2011</cite> , , Rush and Petrov (2012) , Zhang and McDonald (2012) ."
  ],
  "y": "similarities"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_0",
  "x": [
   "Other work stores dialogue context in a memory module and repeatedly queries and reasons about this context to select an adequate system response<cite> (Bordes and Weston, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_1",
  "x": [
   "The result is a simple, intuitive, and highly competitive model, which outperforms the more complex model of<cite> Bordes and Weston (2016)</cite> by 6.9%."
  ],
  "y": "differences"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_2",
  "x": [
   "Other cited work using the DSTC2 dataset <cite>(Bordes and Weston, 2016</cite>; Liu and Perez, 2016; Seo et al., 2016) implement similar mechanisms whereby they expand the feature representations of candidate system responses based on whether there is lexical entity class matching with provided dialogue context."
  ],
  "y": "background"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_3",
  "x": [
   "While the goal of the original challenge was building a system for inferring dialogue state, for our study, we use the version of the data from<cite> Bordes and Weston (2016)</cite> , which ignores the dialogue state annotations, using only the raw text of the dialogues."
  ],
  "y": "uses"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_4",
  "x": [
   "We employ several metrics for assessing specific aspects of our model, drawn from previous work: \u2022 Per-Response Accuracy:<cite> Bordes and Weston (2016)</cite> report a per-turn response accuracy, which tests their model's ability to select the system response at a certain timestep."
  ],
  "y": "uses"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_5",
  "x": [
   "Evaluating using this metric on our model is therefore significantly more stringent a test than for the model of<cite> Bordes and Weston (2016)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_6",
  "x": [
   "\u2022 Per-Dialogue Accuracy:<cite> Bordes and Weston (2016)</cite> also report a per-dialogue accuracy, which assesses their model's ability to produce every system response of the dialogue correctly."
  ],
  "y": "differences similarities"
 },
 {
  "id": "c54a1aba5845a52f468cde916c970b_7",
  "x": [
   "In Table 2 , we present the results of our models compared to the reported performance of the best performing model of<cite> (Bordes and Weston, 2016)</cite> , which is a variant of an end-to-end memory network (Sukhbaatar et al., 2015) ."
  ],
  "y": "motivation"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_0",
  "x": [
   "To improve the expressivity of the added paths, instead of the unlexicalized labels, <cite>(Gardner et al., 2013)</cite> augmented the KB graph with verbs (surface relations) from a corpus containing over 600 million Subject-Verb-Object (SVO) triples."
  ],
  "y": "background"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_1",
  "x": [
   "This reduces feature sparsity and has been shown to improve PRA inference <cite>(Gardner et al., 2013)</cite> , (Gardner et al., 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_2",
  "x": [
   "This is different from the scheme in <cite>(Gardner et al., 2013)</cite> and (Gardner et al., 2014) , which adds edges between KB nodes by mining surface relations from an external corpus."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_3",
  "x": [
   "In contrast, the previous approaches of adding edges or embeddings to the KB <cite>(Gardner et al., 2013)</cite> , and vector space random walk PRA (Gardner et al., 2014) are batch procedures."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_4",
  "x": [
   "As we shall see in Section 4, due to a limited search space, on-demand augmentation is much faster compared to algorithms in <cite>(Gardner et al., 2013</cite>; Gardner et al., 2014) ."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_5",
  "x": [
   "Our experiments suggest that ODA provides better performance than <cite>(Gardner et al., 2013)</cite> and nearly the same prediction performance as provided by (Gardner et al., 2014) , but in both cases with the added advantage of faster running time and greater flexibility due to its online and on-demand nature."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_6",
  "x": [
   "Augmenting the KB for improving PRA inference using surface relations mined from an external corpus and using latent edge labels obtained by performing PCA on the surface relations was explored in <cite>(Gardner et al., 2013)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_7",
  "x": [
   "Thus, the number of paths added in this manner is much lower than the number of surface relations added using the procedure in <cite>(Gardner et al., 2013)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_9",
  "x": [
   "<cite>PRA-SVO</cite> and PRA-VS are the systems proposed in <cite>(Gardner et al., 2013)</cite> and (Gardner et al., 2014) respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus."
  ],
  "y": "background"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_10",
  "x": [
   "<cite>PRA-SVO</cite> and PRA-VS are the systems proposed in <cite>(Gardner et al., 2013)</cite> and (Gardner et al., 2014) respectively, where the KB graph is augmented with edges mined from a large subject-verb-object (SVO) triple corpus."
  ],
  "y": "differences motivation"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_12",
  "x": [
   "Improvements in PRA-ODA over <cite>PRA-SVO</cite> is statistically significant with p < 0.007, with <cite>PRA-SVO</cite> as null hypothesis."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_14",
  "x": [
   "For the L 1 and L 2 regularization parameters in the logistic regression classifier, we used the same values as used in (<cite>Gardner et al., 2013</cite>; Gardner et al., 2014) , viz., L 1 = 0.005, and L 2 = 1.0."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_16",
  "x": [
   "We note that the batch augmentation in case of <cite>PRA-SVO</cite> and PRA-VS, and embedding computation in case of PRA-VS are all specific to the relations in the evaluation set, and hence can't be ignored as a one-time offline cost."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_17",
  "x": [
   "We compare the results (PRA-ODA) with the PRA algorithm executed on the NELL KB, NELL KB augmented with surface relations (<cite>PRA-SVO</cite>) (<cite>Gardner et al., 2013</cite>) and vector space random walk PRA (PRA-VS) (Gardner et al., 2014) .",
   "The run times, i.e, the time taken to perform an entire experiment for <cite>PRA-SVO</cite> and PRA-VS includes the time taken to augment NELL KB with SVO edges."
  ],
  "y": "differences"
 },
 {
  "id": "c60a1131c6b1639b772b0e5c59588e_18",
  "x": [
   "An additional advantage of the proposed algorithm is that it can also be run on the top of any PRA based algorithm such as the <cite>PRA-SVO</cite> and PRA-VS."
  ],
  "y": "differences"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_0",
  "x": [
   "We also compare to the recent biLSTM-Max Encoder of <cite>Conneau et al. (2017)</cite> , which served as our model's 1-layer starting point."
  ],
  "y": "uses"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_1",
  "x": [
   "We also compare to the recent biLSTM-Max Encoder of <cite>Conneau et al. (2017)</cite> , which served as our model's 1-layer starting point."
  ],
  "y": "differences"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_2",
  "x": [
   "The overall supervised model uses these shortcutstacked encoders to encode two input sentences into two vectors, and then we use a classifier over the vector combination to label the relationship between these two sentences as that of entailment, contradiction, or neural (similar to the classifier setup of Bowman et al. (2015) and <cite>Conneau et al. (2017)</cite> )."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_3",
  "x": [
   "Figure 1 shows the overview of our encoding model (the standard classifier setup is not shown here; see Bowman et al. (2015) and <cite>Conneau et al. (2017)</cite> for that)."
  ],
  "y": "background"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_4",
  "x": [
   "Then, assuming we have m layers of biLSTM, the final vector representation will be obtained by applying row-max-pool over the output of the last biLSTM layer, similar to <cite>Conneau et al. (2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_5",
  "x": [
   "The closest encoder architecture to ours is that of <cite>Conneau et al. (2017)</cite> , whose model consists of a single-layer biLSTM with a max-pooling layer, which we treat as our starting point."
  ],
  "y": "extends similarities"
 },
 {
  "id": "c6bae8dbdb66092865945e776148e6_7",
  "x": [
   "As shown, each added layer model improves the accuracy and we achieve a substantial improvement in accuracy (around 2%) on both matched and mismatched settings, compared to the single-layer biLSTM in <cite>Conneau et al. (2017)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "c78464cfe0fc44f5fd0da2e4f9d90e_0",
  "x": [
   "However, there have been recent successes in adapting parsers and POS taggers to social media data (Foster et al., 2011; <cite>Gimpel et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c7e304499654516cce43c550256eae_0",
  "x": [
   "For example, POS tags can be projected via word alignments, and the projected POS is then used to train a model in the lowresource language Zhang et al., 2016;<cite> Fang and Cohn, 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "c7e304499654516cce43c550256eae_1",
  "x": [
   "For example, POS tags can be projected via word alignments, and the projected POS is then used to train a model in the lowresource language Zhang et al., 2016;<cite> Fang and Cohn, 2016)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "c7e304499654516cce43c550256eae_2",
  "x": [
   "For example, POS tags can be projected via word alignments, and the projected POS is then used to train a model in the lowresource language Zhang et al., 2016;<cite> Fang and Cohn, 2016)</cite> ."
  ],
  "y": "differences background motivation"
 },
 {
  "id": "c7e304499654516cce43c550256eae_3",
  "x": [
   "Parallel data therefore appears to be the most realistic additional source of information for developing NLP systems in low-resource languages (Yarowsky and Ngai, 2001; T\u00e4ckstr\u00f6m et al., 2013; <cite>Fang and Cohn, 2016</cite>; Zhang et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "c7e304499654516cce43c550256eae_4",
  "x": [
   "Our approach extends the work of<cite> Fang and Cohn (2016)</cite> , who present a model based on distant supervision in the form of cross-lingual projection and use projected tags generated from parallel corpora as distant annotations."
  ],
  "y": "extends"
 },
 {
  "id": "c7e304499654516cce43c550256eae_5",
  "x": [
   "This component allows for a more expressive label mapping than<cite> Fang and Cohn (2016)</cite>'s linear matrix translation."
  ],
  "y": "differences"
 },
 {
  "id": "c7e304499654516cce43c550256eae_6",
  "x": [
   "For a more direct comparison, we include BILSTM-DEBIAS<cite> (Fang and Cohn, 2016)</cite> , applied using our proposed cross-lingual supervision based on dictionaries, instead of parallel corpora; accordingly the key difference is their linear transformation for the distant data, versus our non-linear transformation to the gold data."
  ],
  "y": "differences uses"
 },
 {
  "id": "c7e304499654516cce43c550256eae_7",
  "x": [
   "BILSTM-DEBIAS<cite> (Fang and Cohn, 2016)</cite> performs worse than our proposed method, indicating that a linear transformation is insufficient for modelling distant supervision."
  ],
  "y": "differences"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_0",
  "x": [
   "The major distinction between these methods is in the contrast between the approaches based exclusively on the information contained in the text to be segmented, such as lexical repetition (e.g., <cite>Choi 2000</cite>; Hearst 1997; Heinonen 1998; Kehagias, Pavlina, and Petridis 2003; Utiyama and Isahara 2001) , and those approaches that rest on complementary semantic knowledge extracted from dictionaries and thesauruses (e.g., Kozima 1993; Lin et al. 2004; Morris and Hirst 1991) , or from collocations collected in large corpora (Bolshakov and Gelbukh 2001; Brants, Chen, and Tsochantaridis 2002; Choi et al. 2001; Ferret 2002; Kaufmann 1999; Ponte and Croft 1997) ."
  ],
  "y": "differences background"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_1",
  "x": [
   "Before reporting these experiments, <cite>Choi's algorithm</cite> and the use of LSA within this framework are described."
  ],
  "y": "background"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_3",
  "x": [
   "The segmentation algorithm proposed by <cite>Choi (2000)</cite> is made up of the three steps usually found in any segmentation procedure based on lexical cohesion."
  ],
  "y": "background"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_4",
  "x": [
   "The procedure initially proposed by <cite>Choi (2000)</cite> , C99, rests exclusively on the information contained in the text to be segmented."
  ],
  "y": "background"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_5",
  "x": [
   "In a first evaluation based on the procedure described below, <cite>Choi</cite> showed that its algorithm outperforms several other approaches such as TextTiling (Hearst 1997) and Segmenter (Kan, Klavans, and McKeown 1998) ."
  ],
  "y": "background"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_6",
  "x": [
   "This experiment was based on the procedure and test materials designed by <cite>Choi (2000)</cite> , which was also used by several authors as a benchmark for comparing segmentation systems (Brants et al. 2002; Ferret 2002; Kehagias et al. 2003; Utiyama and Isahara 2001) ."
  ],
  "y": "uses"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_7",
  "x": [
   "For the present experiment, I used the most general test materials built by <cite>Choi (2000)</cite> , in which the size of the segments within each sample varies randomly from 3 to 11 sentences."
  ],
  "y": "uses"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_8",
  "x": [
   "An 11 \u00d7 11 rank mask was used for the ordinal transformation, as recommended by <cite>Choi (2000)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "c856f5ce5d2cdcfc71027d6fa4c6b3_9",
  "x": [
   "The test materials were extracted from the 1997-1998 corpus following the guidelines given in <cite>Choi (2000)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_0",
  "x": [
   "Learning representations (Mikolov et al., 2013) of natural language and language model pre-training <cite>(Devlin et al., 2018</cite>; Radford et al., 2019) has shown promising results recently."
  ],
  "y": "background"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_1",
  "x": [
   "The innovation of BERT <cite>(Devlin et al., 2018)</cite> comes from the \"masked language model\" with a pre-training objective, inspired by the Cloze task (Taylor, 1953) ."
  ],
  "y": "background"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_2",
  "x": [
   "For example, <cite>(Devlin et al., 2018)</cite> has shown that across natural language understanding tasks, using larger hidden layer size, more hidden layers, and more attention heads always leads to better performance."
  ],
  "y": "background"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_3",
  "x": [
   "However, <cite>they</cite> stop at a hidden layer size of 1024."
  ],
  "y": "motivation"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_4",
  "x": [
   "BERT is based on the encoder of the transformer model (Vaswani et al., 2017) , which has been proven to obtain state-of-the-art accuracy across a broad range of NLP applications <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_5",
  "x": [
   "2 Related work 2.1 BERT Our work focuses on improving the transformer architecture (Vaswani et al., 2017) , which motivated the recent breakthrough in language representation, BERT <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_6",
  "x": [
   "We used the same input and output representations, i.e., the embedding and positional encoding, and the same loss objective, i.e., masked LM prediction and next sentence prediction, from the BERT paper <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_7",
  "x": [
   "Following the BERT <cite>(Devlin et al., 2018)</cite> , we use masked language model loss and next sentence prediction (NSP) loss to train the models."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_8",
  "x": [
   "We also use the next sentence prediction loss as introduced in <cite>(Devlin et al., 2018)</cite> to train our models."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_9",
  "x": [
   "We use the same large-scale data which has been used for BERT model pre-training, the BooksCorpus (800M words) (Zhu et al., 2015) and English Wikipedia (2.5B words) (Wikipedia contributors, 2004; <cite>Devlin et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_10",
  "x": [
   "Following the original BERT setup <cite>(Devlin et al., 2018)</cite> , we format the inputs as \"[CLS] TRANS/BERT  108M  12  768  768  12  6.0X  Base  TRANS-BLSTM-SMALL  152M  12  768  768  12  3.3X  TRANS-BLSTM  237M  12  768  768  12  2.5X  Large TRANS/BERT  334M  24  1024  1024  16  2.8X  TRANS-BLSTM-SMALL  487M  24  1024  1024  16  1.4X  TRANS-BLSTM  789M  24  1024  1024  16  1   Table 1 : Parameter size and training speed for TRANS/BERT, TRANS-BLSTM-SMALL, and TRANS-BLSTM on base and large settings respectively."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_11",
  "x": [
   "Similar to <cite>(Devlin et al., 2018)</cite> , the training data generator chooses 15% of the token positions at random for making."
  ],
  "y": "similarities"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_12",
  "x": [
   "1 Nevertheless, our implementation of baseline BERT model obtained higher accuracy than that reported by the original BERT paper <cite>(Devlin et al., 2018)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_13",
  "x": [
   "Following the previous work <cite>(Devlin et al., 2018</cite>; Yang et al., 2019; Liu et al., 2019a; Lan et al., 2019) , we evaluate our models on the General Language Understanding Evaluation (GLUE) benchmark and the Stanford Question Answering Dataset (SQuAD 1.1) (Rajpurkar et al., 2016) ."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_14",
  "x": [
   "Table 2 shows the BERT base models, including the original BERT-base model in <cite>(Devlin et al., 2018)</cite> and our implementation, and the bidirectional LSTM model accuracy over SQuAD 1.1 development dataset."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_16",
  "x": [
   "EM F1 BERT-base <cite>(Devlin et al., 2018)</cite>"
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_17",
  "x": [
   "Following <cite>(Devlin et al., 2018)</cite> , we use a batch size of 32 and 3-epoch fine-tuning over the data for all GLUE tasks."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_18",
  "x": [
   "Additionally similar to <cite>(Devlin et al., 2018)</cite> , for large BERT and TRANS-BLSTM models, we found that finetuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the development set."
  ],
  "y": "similarities"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_19",
  "x": [
   "Table 5 shows the results of GLUE datasets for original BERT <cite>(Devlin et al., 2018)</cite> , ours TRANS/BERT, TRANS-BLSTM-SMALL and TRANS-BLSTM on base and large settings respectively."
  ],
  "y": "uses"
 },
 {
  "id": "caa0ffb1d4e3e5310a28b921333d1e_20",
  "x": [
   "Following the BERT setting <cite>(Devlin et al., 2018)</cite> , we exclude the problematic WNLI set."
  ],
  "y": "uses"
 },
 {
  "id": "cb57b8886be9ea4f0c50fd2c3a178a_0",
  "x": [
   "Recently, there has been much work designing ranking architectures to effectively score query-document pairs, with encouraging results [5,<cite> 6,</cite> 20] ."
  ],
  "y": "background"
 },
 {
  "id": "cb57b8886be9ea4f0c50fd2c3a178a_4",
  "x": [
   "We evaluate our methods on three neural relevance matching methods: PACRR<cite> [6]</cite> , KNRM [20] , and DRMM [5] ."
  ],
  "y": "uses"
 },
 {
  "id": "cb57b8886be9ea4f0c50fd2c3a178a_7",
  "x": [
   "5 Following prior work<cite> [6]</cite> , documents are truncated to 800 tokens."
  ],
  "y": "uses"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_0",
  "x": [
   "To that end, we present results with the CoMiC-EN Content Assessment system (Meurers et al., 2011a) on the dataset published by<cite> Mohler et al. (2011)</cite> and outline what was necessary to perform this comparison."
  ],
  "y": "background uses"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_1",
  "x": [
   "Subsequently, we will zoom into the comparison of two of them, namely CoMiC-EN (Meurers et al., 2011a ) and the one which we call the Texas system <cite>(Mohler et al., 2011)</cite> and discuss the issues that arise with this endeavor. Returning to the bigger picture, we will explore how such systems could be compared in general, in the belief that meaningful comparison of approaches across research strands will be an important ingredient in advancing this relatively new research field."
  ],
  "y": "motivation background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_2",
  "x": [
   "Another recent approach is described by<cite> Mohler et al. (2011)</cite> , hereafter referred to as the Texas system."
  ],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_3",
  "x": [
   "For evaluating their system,<cite> Mohler et al. (2011)</cite> collected student responses from an online learning environment."
  ],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_4",
  "x": [],
  "y": "background uses"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_5",
  "x": [
   "After discussing the broad landscape of Short Answer Evaluation systems, the main characteristics and differences, we now turn to a comparison of two concrete systems, namely CoMiC-EN (Meurers et al., 2011a ) and the Texas system<cite> Mohler et al. (2011)</cite> , to explore what is involved in such a concrete comparison of two systems from different contexts."
  ],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_6",
  "x": [
   "In evaluating the Texas system,<cite> Mohler et al. (2011)</cite> used a corpus of ten assignments and two exams from an introductory computer science class."
  ],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_7",
  "x": [
   "A bias towards correct answers can be observed, which is also mentioned by<cite> Mohler et al. (2011)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_8",
  "x": [],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_9",
  "x": [
   "Therefore,<cite> Mohler et al. (2011)</cite> employ isotonic regression to map the ranking to the 0-5 scale.",
   "In terms of performance,<cite> Mohler et al. (2011)</cite> report that the SVMRank system produces a better correlation measure (r = 0.518) while the SVR system yields a better RMSE (0.978)."
  ],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_10",
  "x": [
   "We chose Support Vector Regression (SVR) using libSVM 4 since that is one of the methods employed by<cite> Mohler et al. (2011)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_11",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_12",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_14",
  "x": [
   "To that end, we gave an overview of the existing systems and picked two for a concrete comparison on the same data, the CoMiC-EN system (Meurers et al., 2011a ) and the Texas system <cite>(Mohler et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_15",
  "x": [],
  "y": "background"
 },
 {
  "id": "cb64ba694c37df9ebc1065a1deac0f_16",
  "x": [],
  "y": "motivation background"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_0",
  "x": [
   "Previous work has made significant progress on this task (Chen and Mooney, 2008;<cite> Angeli et al., 2010</cite>; Konstas and Lapata, 2012) ."
  ],
  "y": "background"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_1",
  "x": [
   "Previous work has made significant progress on this task (Chen and Mooney, 2008;<cite> Angeli et al., 2010</cite>; Konstas and Lapata, 2012) ."
  ],
  "y": "motivation"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_2",
  "x": [
   "Further, our memorybased model captures the long-range contextual dependencies among records and descriptions, which are integral to this task<cite> (Angeli et al., 2010)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_3",
  "x": [
   "Other effective approaches include the use of tree conditional random fields (Lu et al., 2009) and template extraction within a log-linear framework<cite> (Angeli et al., 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_4",
  "x": [
   "<cite>Angeli et al. (2010)</cite> propose a unified conceptto-text model that treats joint content selection and surface realization as a sequence of local decisions represented by a log-linear model."
  ],
  "y": "background"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_5",
  "x": [
   "Beam search offers a way to perform approximate joint inference -however, we empirically found that beam search does not perform any better than greedy search on the datasets that we consider, an observation that is shared with previous work<cite> (Angeli et al., 2010)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_6",
  "x": [
   "Following <cite>Angeli et al. (2010)</cite> , we use WEATHERGOV training, development, and test splits of size 25000, 1000, and 3528, respectively."
  ],
  "y": "uses"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_7",
  "x": [
   "We report the performance of content selection and surface realization using F-1 and two BLEU scores (standard sBLEU and the customized cBLEU of <cite>Angeli et al. (2010)</cite>), respectively (Sec. 5)."
  ],
  "y": "uses"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_8",
  "x": [
   "Table 1 compares our test results against previous methods that include KL12 (Konstas and Lapata, 2012) , KL13 (Konstas and Lapata, 2013) , and ALK10<cite> (Angeli et al., 2010)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_9",
  "x": [
   "We considered beam search as an alternative to greedy search in our primary setup (Eqn. 1), but this performs worse, similar to what previous work found on this dataset<cite> (Angeli et al., 2010)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "cc66b46b34a0d716414e8b845707f9_10",
  "x": [
   "We attribute this improvement to the LSTM-RNN's ability to capture the relationships that exist among the records, which is known to be essential to selective generation (Barzilay and Lapata, 2005;<cite> Angeli et al., 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_0",
  "x": [
   "We present positive results from a fully automated judge for semantic similarity based on Referential Translation Machines<cite> (Bi\u00e7ici and Way, 2014b)</cite> in two semantic similarity tasks at SemEval-2015, Semantic Evaluation Exercises -International Workshop on Semantic Evaluation (Nakov et al., 2015)."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_1",
  "x": [
   "RTMs achieve (i) top performance when predicting the quality of translations (Bi\u00e7ici, 2013; Bi\u00e7ici and Way, 2014a) ; (ii) top performance when predicting monolingual cross-level semantic similarity; (iii) second performance when predicting paraphrase and semantic similarity in Twitter (iv) good performance when judging the semantic similarity of sentences; (iv) good performance when evaluating the semantic relatedness of sentences and their entailment<cite> (Bi\u00e7ici and Way, 2014b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_2",
  "x": [
   "RTMs use Machine Translation Performance Prediction (MTPP) System<cite> Bi\u00e7ici and Way, 2014b)</cite> , which is a state-of-the-art (SoA) performance predictor of translation even without using the translation."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_3",
  "x": [
   "MTPP features for translation acts are provided in<cite> (Bi\u00e7ici and Way, 2014b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_4",
  "x": [
   "We present positive results from a fully automated judge for semantic similarity based on Referential Translation Machines<cite> (Bi\u00e7ici and Way, 2014b)</cite> in two semantic similarity tasks at SemEval-2015, Semantic Evaluation Exercises -International Workshop on Semantic Evaluation (Nakov et al., 2015) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_5",
  "x": [
   "RTMs achieve (i) top performance when predicting the quality of translations (Bi\u00e7ici, 2013; Bi\u00e7ici and Way, 2014a) ; (ii) top performance when predicting monolingual cross-level semantic similarity; (iii) second performance when predicting paraphrase and semantic similarity in Twitter (iv) good performance when judging the semantic similarity of sentences; (iv) good performance when evaluating the semantic relatedness of sentences and their entailment<cite> (Bi\u00e7ici and Way, 2014b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_6",
  "x": [
   "RTMs use Machine Translation Performance Prediction (MTPP) System<cite> Bi\u00e7ici and Way, 2014b)</cite> , which is a state-of-the-art (SoA) performance predictor of translation even without using the translation."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_7",
  "x": [
   "MTPP features for translation acts are provided in<cite> (Bi\u00e7ici and Way, 2014b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_8",
  "x": [
   "More details about the optimization processes are in <cite>(Bi\u00e7ici and Way, 2014b</cite>; Bi\u00e7ici et al., 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_9",
  "x": [
   "Domain specific RTM models obtain improved performance in those domains<cite> (Bi\u00e7ici and Way, 2014b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "cc992a7a918858f9e04b9bb5c15c3f_10",
  "x": [
   "In Table 8 , we list the RAE, MAER, and MRAER obtained for different tasks and subtasks, also listing RTM results from SemEval-2013 , from SemEval-2014<cite> (Bi\u00e7ici and Way, 2014b)</cite> , and and from quality estimation task (QET) (Bi\u00e7ici and Way, 2014a ) of machine translation (Bojar et al., 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_0",
  "x": [
   "According to (Becker, 1985; Huang, 1985; Gu et al., 1991; Chung, 1993; Kuo, 1995; Fu et al., 1996; Lee et al., 1997; Hsu et al., 1999; Chen et al., 2000; Tsai and Hsu, 2002; Gao et al., 2002; Lee, 2003;<cite> Tsai, 2005)</cite> , the approaches of Chinese input methods (i.e. Chinese input systems) can be classified into two types: (1) keyboard based approach: including phonetic and pinyin based (Chang et al., 1991; Hsu et al., 1993; Hsu, 1994; Hsu et al., 1999; Kuo, 1995; Lua and Gan, 1992) , arbitrary codes based (Fan et al., 1988) and structure scheme based (Huang, 1985) ; and (2) non-keyboard based approach: including optical character recognition (OCR) (Chung, 1993) , online handwriting and speech recognition (Fu et al., 1996; Chen et al., 2000) ."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_1",
  "x": [
   "Since the size of problem space for syllable-to-word (STW) conversion is much less than that of syllable-tocharacter (STC) conversion, the most pinyinbased Chinese input systems (Hsu, 1994; Hsu et al., 1999; Tsai and Hsu, 2002; Gao et al., 2002; Microsoft Research Center in Beijing;<cite> Tsai, 2005)</cite> are addressed on STW conversion."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_2",
  "x": [
   "As per (Chung, 1993; Fong and Chung, 1994; Tsai and Hsu, 2002; Gao et al., 2002; Lee, 2003;<cite> Tsai, 2005)</cite> , homophone selection and syllableword segmentation are two critical problems in developing a Chinese input system."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_3",
  "x": [
   "From the studies (Hsu 1994; Tsai and Hsu, 2002; Gao et al., 2002; Kee, 2003;<cite> Tsai, 2005)</cite> , the linguistic approach requires considerable effort in designing effective syntax rules, semantic templates or contextual information, thus, it is more user-friendly than the statistical approach on understanding why such a system makes a mistake."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_4",
  "x": [
   "In our previous work<cite> (Tsai, 2005)</cite> , a wordpair (WP) identifier was proposed and shown a simple and effective way to improve Chinese input systems by providing tonal and toneless STW accuracies of 98.5% and 90.7% on the identified poly-syllabic words, respectively."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_5",
  "x": [
   "In<cite> (Tsai, 2005)</cite> , we have shown that the WP identifier can be used to reduce the over weighting and corpus sparseness problems of bigram models and achieve better STW accuracy to improve Chinese input systems."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_6",
  "x": [
   "Since the identified character ratio of the WP identifier <cite>(Tsai, 2005</cite> ) is about 55%, there are still about 15% improving room left."
  ],
  "y": "motivation"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_7",
  "x": [
   "We conduct STW experiments to show the tonal and toneless STW accuracies of a commercial input product (Microsoft Input Method Editor 2003, MSIME) , and an optimized bigram model, BiGram<cite> (Tsai, 2005)</cite> , can both be improved by our WSM and achieve better STW improvements than that of these systems with the WP identifier."
  ],
  "y": "uses"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_8",
  "x": [
   "Following<cite> (Tsai, 2005)</cite> , the three steps of autogenerating word-pairs (AUTO-WP) for a given Chinese sentence are as below: (the details of AUTO-WP can be found in<cite> (Tsai, 2005))</cite> Step 1. Get forward and backward word segmentations: Generate two types of word segmentations for a given Chinese sentence by forward maximum matching (FMM) and backward maximum matching (BMM) techniques (Chen et al., 1986; Tsai et al., 2004) with the system dictionary."
  ],
  "y": "uses"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_9",
  "x": [
   "The comparative system is the WP identifier<cite> (Tsai, 2005)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_10",
  "x": [
   "In addition, following<cite> (Tsai, 2005)</cite> , an optimized bigram model called BiGram was developed."
  ],
  "y": "uses"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_11",
  "x": [
   "(Note that, as per<cite> (Tsai, 2005)</cite> , the differences between the tonal and toneless STW accuracies of the BiGram and the TriGram are less than 0.3%)."
  ],
  "y": "background"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_12",
  "x": [
   "This observation is similarly with that of our previous work<cite> (Tsai, 2005)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_13",
  "x": [
   "This observation is similarly with that of<cite> (Tsai, 2005)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "cce566b9111abdc7ab7576662922dd_14",
  "x": [
   "In this paper, we present a word support model (WSM) to improve the WP identifier<cite> (Tsai, 2005)</cite> and support the Chinese Language Processing on the STW conversion problem."
  ],
  "y": "extends"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_0",
  "x": [
   "Phoneme-only E2E systems have been shown to have inferior performance compared to grapheme or wordpiece models (WPM) in general <cite>[16,</cite> 17] , but shows better recognition of rare words and proper nouns."
  ],
  "y": "background"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_1",
  "x": [
   "This approach also mitigates accuracy regressions that have been observed when using phoneme-only E2E models <cite>[16,</cite> 17] ."
  ],
  "y": "motivation"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_2",
  "x": [
   "Since phonemes show strength in recognizing rare words<cite> [16]</cite> , we want to present these words as phonemes more often."
  ],
  "y": "motivation"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_3",
  "x": [
   "We use context-independent phonemes as in<cite> [16]</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_4",
  "x": [
   "To generate words as outputs, we search through a decoding graph similar to<cite> [16]</cite> but accept both phonemes and wordpieces."
  ],
  "y": "differences similarities"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_5",
  "x": [
   "Based on<cite> [16]</cite> , we add two improvements to the decoding strategy."
  ],
  "y": "extends"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_6",
  "x": [
   "We attribute the superior per- formance of the wordpiece-phoneme model to the robustness of phonemes to OOV words, as observed in<cite> [16]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "cd10d509dacd8f55993396258eb92a_7",
  "x": [
   "However, we note that the regression is significantly smaller than the all-phoneme model in<cite> [16]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_0",
  "x": [
   "This availability of annotated data in English has translated into the development of a plethora of models, including encoder-decoders (Dong and Lapata, 2016; Jia and Liang, 2016) as well as tree or graph-structured decoders Lapata, 2016, 2018;<cite> Liu et al., 2018</cite>; Yin and Neubig, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_1",
  "x": [
   "To test our approach we leverage the DRT parser of <cite>Liu et al. (2018)</cite> , an encoder-decoder architecture where the meaning representation is reconstructed in three stages, coarse-to-fine, by first building the DRS skeleton (i.e. the 'box' structures) and then fill each DRS with predicates and variables."
  ],
  "y": "extends"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_2",
  "x": [
   "In this section, we describe the modifications to the coarse-to-fine encoder-decoder architecture of <cite>Liu et al. (2018)</cite> ; for more detail, we refer the reader to the original paper."
  ],
  "y": "extends"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_3",
  "x": [
   "We use <cite>Liu et al. (2018)</cite> 's Bi-LSTM as baseline."
  ],
  "y": "uses"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_4",
  "x": [
   "The decoder of <cite>Liu et al. (2018)</cite> reconstructs the DRS in three steps, by first predicting the overall structure (the 'boxes'), then the predicates and finally the referents, with each subsequent step being conditioned on the output of the previous."
  ],
  "y": "background"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_5",
  "x": [
   "We use the PMB v. In order to be used as input to the parser, <cite>Liu et al. (2018)</cite> first convert the DRS into treebased representations, which are subsequently linearized into PTB-style bracketed sequences."
  ],
  "y": "background"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_6",
  "x": [
   "It is worth reminding that unlike other work on the PMB (e.g. van Noord et al., 2018), <cite>Liu et al. (2018)</cite> does not deal with presupposition."
  ],
  "y": "background"
 },
 {
  "id": "cd56849805cdb43bba567f74b31b87_7",
  "x": [
   "Amongst these, tree or graph-structured decoders have recently shown to be state-of-the-art Lapata, 2016, 2018;<cite> Liu et al., 2018</cite>; Cheng et al., 2017; Yin and Neubig, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "ce0441b3ae7b957520d329799f8b9f_0",
  "x": [
   "For example, if one accepts the framework of the Penn Treebank, it is easy to move on to representations of \"deeper\" structure as suggested in three papers in this volume (Miltsakaki et al., 2004; Babko-Malaya et al., 2004; <cite>Meyers et al., 2004)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ce0441b3ae7b957520d329799f8b9f_1",
  "x": [
   "The first six papers describe linguistic annotation in four languages: Spanish (Alc\u00e1ntara and Moreno, 2004), English (Miltsakaki et al., 2004; Babko-Malaya et al., 2004; <cite>Meyers et al., 2004)</cite> , Czech (Sgall et al., 2004) and German (Baumann et al., 2004)."
  ],
  "y": "background"
 },
 {
  "id": "ce0441b3ae7b957520d329799f8b9f_2",
  "x": [
   "For example, if one accepts the framework of the Penn Treebank, it is easy to move on to representations of \"deeper\" structure as suggested in three papers in this volume (Miltsakaki et al., 2004; Babko-Malaya et al., 2004; <cite>Meyers et al., 2004)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ce0441b3ae7b957520d329799f8b9f_3",
  "x": [
   "The first six papers describe linguistic annotation in four languages: Spanish (Alc\u00e1ntara and Moreno, 2004) , English (Miltsakaki et al., 2004; Babko-Malaya et al., 2004; <cite>Meyers et al., 2004)</cite> , Czech (Sgall et al., 2004) and German (Baumann et al., 2004) ."
  ],
  "y": "background"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_0",
  "x": [
   "Recent work by <cite>Lau et al. (2018)</cite> proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier for learning the notion of rhyming: that a line ending word always rhymes with exactly one more ending word in the poem."
  ],
  "y": "background"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_1",
  "x": [
   "Recent work by <cite>Lau et al. (2018)</cite> proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier for learning the notion of rhyming: that a line ending word always rhymes with exactly one more ending word in the poem."
  ],
  "y": "motivation"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_2",
  "x": [
   "Recent work by <cite>Lau et al. (2018)</cite> proposes a quatrain generation method that relies on specific domain knowledge about the dataset to train a classifier for learning the notion of rhyming: that a line ending word always rhymes with exactly one more ending word in the poem."
  ],
  "y": "differences"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_3",
  "x": [
   "Following prior work<cite> (Lau et al., 2018)</cite>, we generate words in each line in reverse order (i.e. right to left), and begin generation with the last line first."
  ],
  "y": "uses"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_4",
  "x": [
   "We initialize the word embeddings in the generator with pre-trained word embeddings<cite> (Lau et al., 2018)</cite> trained on a separate non-sonnet corpus."
  ],
  "y": "uses"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_5",
  "x": [
   "We work with the Shakespeare SONNET dataset<cite> (Lau et al., 2018</cite> ) and a new LIMERICK corpus."
  ],
  "y": "uses"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_6",
  "x": [
   "Fol-lowing prior work<cite> (Lau et al., 2018)</cite> , words are sampled with a temperature value between 0.6 and 0.8."
  ],
  "y": "uses"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_7",
  "x": [
   "Our generator implementation is largely based on that of <cite>Lau et al. (2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_8",
  "x": [
   "Our generator implementation is largely based on that of <cite>Lau et al. (2018)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_9",
  "x": [
   "Following prior work<cite> (Lau et al., 2018)</cite> , we requested human annotators to identify the humanwritten poem when presented with two samples at a time -a quatrain from the Sonnet corpus and a machine-generated quatrain, and report the annotator accuracy on this task."
  ],
  "y": "uses"
 },
 {
  "id": "ce8997b630e9544b0f5812be319a59_10",
  "x": [
   "More recently, neural models for poetry generation have been proposed (Zhang and Lapata, 2014; Ghazvininejad et al., 2016 Ghazvininejad et al., , 2017 Hopkins and Kiela, 2017;<cite> Lau et al., 2018</cite>; Liu et al., 2019) ."
  ],
  "y": "background"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_0",
  "x": [
   "Our paper expands the existing FOIL dataset <cite>(Shekhar et al., 2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_1",
  "x": [
   "We follow the methodology highlighted in<cite> Shekhar et al. (2017)</cite> , which consists of replacing a single word in a human-generated caption with a 'foil' item, making the caption unsuitable to describe the original image."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_2",
  "x": [
   "For T3, we regress over all<cite> Shekhar et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_3",
  "x": [
   "Following<cite> Shekhar et al. (2017)</cite> , we aim at creating a dataset of images associated with both correct and foil captions, where the latter are obtained by replacing one word in the original text."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_4",
  "x": [
   "Following<cite> Shekhar et al. (2017)</cite> , we aim at creating a dataset of images associated with both correct and foil captions, where the latter are obtained by replacing one word in the original text."
  ],
  "y": "extends"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_5",
  "x": [
   "In order to obtain a balanced dataset across the various PoS, we only use a subset of the FOIL-COCO dataset of<cite> Shekhar et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_6",
  "x": [
   "The foil captions are generated by replacing nouns are directly extracted from the FOIL dataset by<cite> Shekhar et al. (2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_7",
  "x": [
   "These numbers, however, do not show to which extent the models are able to avoid the trap of the dataset:<cite> Shekhar et al. (2017)</cite> showed that on the FOIL data, models tend to detect correct captions with reasonable accuracy but fail to identify the incorrect ones, leading to a large bias in classification."
  ],
  "y": "uses"
 },
 {
  "id": "cee22bd0384d3d3fd4e45833341e77_8",
  "x": [
   "These numbers, however, do not show to which extent the models are able to avoid the trap of the dataset:<cite> Shekhar et al. (2017)</cite> showed that on the FOIL data, models tend to detect correct captions with reasonable accuracy but fail to identify the incorrect ones, leading to a large bias in classification."
  ],
  "y": "background"
 },
 {
  "id": "cf7d01faf555f09973e44be400e768_0",
  "x": [
   "We then focus on a new case study of hierarchical deep reinforcement learning for video captioning<cite> (Wang et al., 2018b)</cite> , discussing the techniques of leveraging hierarchies in DRL for NLP generation problems."
  ],
  "y": "uses"
 },
 {
  "id": "cf7d01faf555f09973e44be400e768_1",
  "x": [
   "We then focus on a new case study of hierarchical deep reinforcement learning for video captioning<cite> (Wang et al., 2018b)</cite> , discussing the techniques of leveraging hierarchies in DRL for NLP generation problems."
  ],
  "y": "uses"
 },
 {
  "id": "cf7d01faf555f09973e44be400e768_2",
  "x": [
   "We will show case a recent study<cite> (Wang et al., 2018b</cite> ) that leverages hierarchical deep reinforcement learning for language and vision, and extend the discussion."
  ],
  "y": "uses"
 },
 {
  "id": "cffa735deb802118640005a1d527ee_0",
  "x": [
   "AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality<cite> (Engelson and Dagan, 1996</cite>; Ngai and Yarowsky, 2000; Hwa, 2001; Tomanek et al., 2007a) ."
  ],
  "y": "background"
 },
 {
  "id": "cffa735deb802118640005a1d527ee_1",
  "x": [
   "To calculate the disagreement among the committee members several metrics have been proposed including the vote entropy<cite> (Engelson and Dagan, 1996)</cite> as possibly the most well-known one."
  ],
  "y": "background"
 },
 {
  "id": "cffa735deb802118640005a1d527ee_2",
  "x": [
   "To calculate the disagreement among the committee members several metrics have been proposed including the vote entropy<cite> (Engelson and Dagan, 1996)</cite> as possibly the most well-known one."
  ],
  "y": "similarities background"
 },
 {
  "id": "cffa735deb802118640005a1d527ee_3",
  "x": [
   "Disagreement is measured by vote entropy<cite> (Engelson and Dagan, 1996)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_0",
  "x": [
   "Neural models have consistently shown top performance in shared evaluation tasks (Bojar et al., 2016; Cettolo et al., 2016) and are becoming the technology of choice for commercial MT service providers<cite> (Wu et al., 2016</cite>; Crego et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_1",
  "x": [
   "Translation models are trained until perplexity convergence on held-out data using the Adam algorithm with a maximum step size of 0.0002 (Kingma and Ba, 2015; <cite>Wu et al., 2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_2",
  "x": [
   "Translation models are trained until perplexity convergence on held-out data using the Adam algorithm with a maximum step size of 0.0002 (Kingma and Ba, 2015; <cite>Wu et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_3",
  "x": [
   "While this can lead to much faster convergence, the resulting models are shown to slightly underperform compared to annealing SGD<cite> (Wu et al., 2016)</cite> ."
  ],
  "y": "differences background motivation"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_4",
  "x": [
   "While this can lead to much faster convergence, the resulting models are shown to slightly underperform compared to annealing SGD<cite> (Wu et al., 2016)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_5",
  "x": [
   "While this can lead to much faster convergence, the resulting models are shown to slightly underperform compared to annealing SGD<cite> (Wu et al., 2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_6",
  "x": [
   "7 Learning rates of 0.5 for SGD and 0.0002 for Adam or very similar are shown to work well in NMT implementations including GNMT<cite> (Wu et al., 2016)</cite> , Nematus, Marian, and OpenNMT (http://opennmt.net)."
  ],
  "y": "uses"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_8",
  "x": [
   "As<cite> Wu et al. (2016)</cite> show different levels of effectiveness for different sub-word vocabulary sizes, we evaluate running BPE with 16K and 32K merge operations."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d0fa481abaf6d1b5529e40ff73f00a_9",
  "x": [
   "This trend follows previous work showing that dropout combats overfitting of small data, though the point of inflection is worth noting (Sennrich et al., 2016a; <cite>Wu et al., 2016)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_1",
  "x": [
   "The supervision was either given in the form of meaning representations aligned with sentences (Zettlemoyer and Collins, 2005; Ge and Mooney, 2005; Mooney, 2007) or in a somewhat more relaxed form, such as lists of candidate meanings for each sentence (Kate and Mooney, 2007; Chen and Mooney, 2008) or formal representations of the described world state for each text<cite> (Liang et al., 2009)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_3",
  "x": [
   "We study our set-up on the weather forecast data<cite> (Liang et al., 2009)</cite> where the original textual weather forecasts were complemented by additional forecasts describing the same weather states (see figure 1 for an example)."
  ],
  "y": "uses"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_4",
  "x": [
   "Section 3 redescribes the semantics-text correspondence model<cite> (Liang et al., 2009)</cite> in the context of our learning scenario."
  ],
  "y": "background"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_5",
  "x": [
   "The semantics m can be represented either as a logical formula (see, e.g., (Poon and Domingos, 2009 )) or as a set of field values if database records are used as a meaning representation<cite> (Liang et al., 2009</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_6",
  "x": [
   "As soon as semantics m k are inferred for every k, we find ourselves in the set-up of learning with unaligned semantic states considered in<cite> (Liang et al., 2009)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_7",
  "x": [
   "In this section we redescribe the semantics-text correspondence model<cite> (Liang et al., 2009</cite> ) with an extension needed to model examples with latent states, and also explain how the inference algorithm defined in section 2 can be applied to this model."
  ],
  "y": "extends"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_9",
  "x": [
   "When the world state is observable, learning does not require any approximations, as dynamic programming (a form of the forward-backward algorithm) can be used to infer the posterior distribution on the E-step<cite> (Liang et al., 2009)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_10",
  "x": [
   "As soon as the meaning representations m are inferred, we find ourselves in the set-up studied in<cite> (Liang et al., 2009</cite> ): the state s is no longer latent and we can run efficient inference on the E-step."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_11",
  "x": [
   "To perform the experiments we used a subset of the weather dataset introduced in<cite> (Liang et al., 2009</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_12",
  "x": [
   "Following<cite> Liang et al. (2009)</cite> we evaluate the models on how well they predict these alignments."
  ],
  "y": "uses"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_13",
  "x": [
   "When estimating the model parameters, we followed the training regime prescribed in<cite> (Liang et al., 2009)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_14",
  "x": [
   "Instead of prohibiting records from crossing punctuation, as suggested by<cite> Liang et al. (2009)</cite> , in our implementation we disregard the words not attached to specific fields (attached to the nullfield, see section 3.1) when computing spans of records."
  ],
  "y": "differences"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_15",
  "x": [
   "However, correlation between rain and overcast, as also noted in<cite> (Liang et al., 2009)</cite> , results in the wrong assignment of the rain-related words to the field value corresponding to very cloudy weather."
  ],
  "y": "similarities"
 },
 {
  "id": "d1decbc03929cbf67a412d0a3a2a66_16",
  "x": [
   "We showed how it can be instantiated for the semantics-text correspondence model<cite> (Liang et al., 2009</cite> ) and evaluated it on a dataset of weather forecasts."
  ],
  "y": "uses"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_0",
  "x": [
   "Recent work on deep learning syntactic parsing models has achieved notably good results, e.g., Dyer et al. (2016) with 92.4 F 1 on Penn Treebank constituency parsing and<cite> Vinyals et al. (2015)</cite> with 92.8 F 1 ."
  ],
  "y": "background"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_1",
  "x": [
   "Recent work on deep learning syntactic parsing models has achieved notably good results, e.g., Dyer et al. (2016) with 92.4 F 1 on Penn Treebank constituency parsing and<cite> Vinyals et al. (2015)</cite> with 92.8 F 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_3",
  "x": [
   "The first (Zaremba et al., 2014) gives the basic language modeling architecture that we have adopted, while the other two<cite> (Vinyals et al., 2015</cite>; Dyer et al., 2016) are parsing models that have the current best results in NN parsing."
  ],
  "y": "uses"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_4",
  "x": [
   "We use the Wall Street Journal (WSJ) of the Penn Treebank (Marcus et al., 1993) for training (2-21), development (24) and testing (23) and millions of auto-parsed \"silver\" trees (McClosky et al., 2006; Huang et al., 2010; <cite>Vinyals et al., 2015)</cite> for tritraining."
  ],
  "y": "uses"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_6",
  "x": [
   "As shown in Table 2 , with 92.6 F 1 LSTM-LM (G) outperforms an ensemble of five MTPs<cite> (Vinyals et al., 2015)</cite> and RNNG (Dyer et al., 2016) , both of which are trained on the WSJ only."
  ],
  "y": "differences"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_7",
  "x": [
   "We compare LSTM-LM (GS) to two very strong semi-supervised NN parsers: an ensemble of five MTPs trained on 11 million trees of the highconfidence corpus 4 (HC)<cite> (Vinyals et al., 2015)</cite> ; and an ensemble of six one-to-many sequence models trained on the HC and 4.5 millions of EnglishGerman translation sentence pairs (Luong et al., 2016) ."
  ],
  "y": "uses"
 },
 {
  "id": "d2b9c678a3d4920919f59c3b5903d3_8",
  "x": [
   "Note that the numbers of<cite> Vinyals et al. (2015)</cite> and Luong et al. (2016) are not directly comparable as their models are evaluated on OntoNotesstyle trees instead of PTB-style trees."
  ],
  "y": "differences"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_0",
  "x": [
   "In most of the previous studies (Mihalcea and Strapparava, 2005; Purandare and Litman, 2006; <cite>Yang et al., 2015)</cite> , humor recognition was modeled as a binary classification task"
  ],
  "y": "background"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_1",
  "x": [
   "In a recent work<cite> (Yang et al., 2015)</cite> , a new corpus was constructed from a Pun of the Day website."
  ],
  "y": "background"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_2",
  "x": [
   "1 CNN-based text categorization methods have been applied for humor recognition (e.g., in (Bertero and Fung, 2016b) ) but with limitations: (a) a rigorous comparison with the state-of-the-art conventional method examined in<cite> Yang et al. (2015)</cite> is missing; (b) CNN's performance in the previous research is not quite clear 2 ; and (c) some important techniques that can improve CNN performance (e.g., using variedsized filters and dropout regularization (Hinton et al., 2012) ) were missing."
  ],
  "y": "motivation"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_3",
  "x": [
   "Following (Mihalcea and Strapparava, 2005; <cite>Yang et al., 2015)</cite> , we selected the same sizes (n = 4726) of humorous and non-humorous sentences."
  ],
  "y": "uses background"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_4",
  "x": [
   "1 CNN-based text categorization methods have been applied for humor recognition (e.g., in (Bertero and Fung, 2016b) ) but with limitations: (a) a rigorous comparison with the state-of-the-art conventional method examined in<cite> Yang et al. (2015)</cite> is missing; (b) CNN's performance in the previous research is not quite clear 2 ; and (c) some important techniques that can improve CNN performance (e.g., using variedsized filters and dropout regularization (Hinton et al., 2012) ) were missing."
  ],
  "y": "motivation"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_5",
  "x": [
   "Following<cite> Yang et al. (2015)</cite> , we applied Random Forest (Breiman, 2001 ) to do humor recognition by using the following two groups of features."
  ],
  "y": "uses"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_6",
  "x": [
   "The Pun data allows us to verify that our implementation is consistent with the work reported in<cite> Yang et al. (2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d42e2a9175e024e3ae44118e12fb58_7",
  "x": [
   "7 https://github.com/ EducationalTestingService/skll 8 https://github.com/fchollet/keras 9 The implementation will be released with the paper On the Pun data, the CNN model shows consistent improved performance over the conventional model, as suggested in<cite> Yang et al. (2015)</cite> ."
  ],
  "y": "background similarities"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_0",
  "x": [
   "They locate the source and target fragments independently, making the extracted fragments unreliable<cite> (Munteanu and Marcu, 2006)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_1",
  "x": [
   "2 Related Work<cite> (Munteanu and Marcu, 2006)</cite> is the first attempt to extract parallel fragments from comparable sentences."
  ],
  "y": "background"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_2",
  "x": [
   "<cite>Munteanu and Marcu (2006)</cite> show that the LLR lexicon performs better than the IBM Model 1 lexicon for parallel fragment extraction."
  ],
  "y": "background"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_3",
  "x": [
   "<cite>Munteanu and Marcu (2006)</cite> develop a smoothing filter applying this advantage."
  ],
  "y": "background"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_4",
  "x": [
   "We extract the LLR lexicon from a word-aligned parallel corpus using the same method as<cite> (Munteanu and Marcu, 2006)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_5",
  "x": [
   "Aiming to gain new knowledge that does not exist in the lexicon, we apply a smoothing filter similar to<cite> (Munteanu and Marcu, 2006)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_6",
  "x": [
   "Therefore, unlike<cite> (Munteanu and Marcu, 2006)</cite>, we only apply the averaging filter to the words with negative scores."
  ],
  "y": "differences extends"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_7",
  "x": [
   "In our experiments, we compared our proposed fragment extraction method with<cite> (Munteanu and Marcu, 2006)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_8",
  "x": [
   "We compared our proposed method with<cite> (Munteanu and Marcu, 2006)</cite>."
  ],
  "y": "similarities"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_9",
  "x": [
   "We can see that the average size of fragments extracted by<cite> (Munteanu and Marcu, 2006</cite> ) is unusually long, which is also reported in (Quirk et al., 2007) ."
  ],
  "y": "background"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_10",
  "x": [
   "Note that exact match criteria has a bias against<cite> (Munteanu and Marcu, 2006)</cite> , because their method extacts subsentential fragments which are quite long."
  ],
  "y": "background"
 },
 {
  "id": "d44648766e68cb914c5489e385f42e_11",
  "x": [
   "Adding the fragments extracted by<cite> (Munteanu and Marcu, 2006)</cite> has a negative impact, compared to appending the sentences."
  ],
  "y": "differences"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_0",
  "x": [
   "In this paper, we employ a variety of these methods to learn Schank and Abelson's canonical restaurant script, using a novel dataset of restaurant narratives we have compiled from a website called \"Dinners from Hell.\" Our models learn narrative chains, script-like structures that we evaluate with the \"narrative cloze\" task<cite> (Chambers and Jurafsky, 2008)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_1",
  "x": [
   "In particular, several related techniques approach the problem of script induction as one of learning narrative chains from text corpora<cite> (Chambers and Jurafsky, 2008</cite>; Chambers and Jurafsky, 2009; Jans et al., 2012; Pichotta and Mooney, 2014) ."
  ],
  "y": "background"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_2",
  "x": [
   "Following the work of Church and Hanks (1990) in learning word associations via mutual information, and the DIRT system introduced by Lin and Pantel (2001) ,<cite> Chambers and Jurafsky (2008)</cite> propose a PMI-based system for learning script-like structures called narrative chains."
  ],
  "y": "background"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_3",
  "x": [
   "As defined by<cite> Chambers and Jurafsky (2008)</cite> , a narrative chain is \"a partially ordered set of narrative events that share a common actor,\" where a narrative event is \"a tuple of an event (most simply a verb) and its participants, represented as typed dependencies.\" To learn narrative chains from text, Chambers and Jurafsky extract chains of narrative events linked by a common coreferent within a document."
  ],
  "y": "background"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_4",
  "x": [
   "To learn the restaurant script from our dataset, we implement the models of<cite> Chambers and Jurafsky (2008)</cite> and Jans et al. (2012) , as well as the unigram baseline of Pichotta and Mooney (2014) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_5",
  "x": [
   "This section provides an overview of each of the different methods and parameter settings we employ to learn narrative chains from the Dinners from Hell corpus, starting with the original model<cite> (Chambers and Jurafsky, 2008)</cite> and extending to the modifications of Jans et al. (2012) ."
  ],
  "y": "differences extends"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_6",
  "x": [
   "e n , at insertion point k. The original model, proposed by<cite> Chambers and Jurafsky (2008)</cite> , predicts the event that maximizes unordered pmi,"
  ],
  "y": "background"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_7",
  "x": [
   "In the case of the two PMI-based models, we use the discount score described in Pantel and Ravichandran (2004) and used by<cite> Chambers and Jurafsky (2008)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d4563562cd0dfd8ef6cdb57117fb22_8",
  "x": [
   "Scoring We employ three different scoring metrics: average rank<cite> (Chambers and Jurafsky, 2008)</cite> , mean reciprocal rank, and recall at 50 (Jans et al., 2012) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_0",
  "x": [
   "To bridge the quality gap between a streaming recurrent neural network transducer (RNN-T) [6] and a large conventional model [8] , a two-pass framework has been proposed in<cite> [10]</cite> , which uses a non-streaming LAS decoder to rescore the RNN-T hypotheses."
  ],
  "y": "background"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_1",
  "x": [
   "The results show that our MWER trained 8-hypothesis deliberation model performs 11% relatively better than LAS rescoring<cite> [10]</cite> in VS WER, and up to 15% for proper noun recognition."
  ],
  "y": "differences"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_2",
  "x": [
   "As shown in Fig. 1 , our deliberation network consists of three major components: A shared encoder, an RNN-T decoder [1] , and a deliberation decoder, similar to<cite> [10,</cite> 16] ."
  ],
  "y": "similarities"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_3",
  "x": [
   "There are two major differences between our model and the LAS rescoring<cite> [10]</cite> .",
   "First, the deliberation model attends to both e and yr, while<cite> [10]</cite> only attends to the acoustic embedding, e. Second, our deliberation model encodes yr bidirectionally, while<cite> [10]</cite> only relies on unidirectional encoding e for decoding."
  ],
  "y": "differences"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_4",
  "x": [
   "However, we find training a two-pass model from scratch tends to be unstable in practice<cite> [10]</cite> , and thus use a two-step training process: Train the RNN-T as in [6] , and then fix the RNN-T parameters and only train the deliberation decoder and additional encoder layers as in [7, <cite>10]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_5",
  "x": [
   "The joint training is similar to \"deep finetuning\" in<cite> [10]</cite> but without a pre-trained decoder."
  ],
  "y": "similarities"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_6",
  "x": [
   "In rescoring, we run the deliberation decoder on yr in a teacher-forcing mode<cite> [10]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_7",
  "x": [
   "Note the difference from<cite> [10]</cite> when rescoring a hypothesis is that the deliberation network sees all candidate hypotheses."
  ],
  "y": "differences"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_8",
  "x": [
   "The SxS set contains utterances where the LAS rescoring model<cite> [10]</cite> performs inferior to a state-of-the-art conventional model [8] , and one reason is due to proper nouns."
  ],
  "y": "differences"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_9",
  "x": [
   "We propose to use the deliberation decoder to rescore first-pass RNN-T results, and expect bidirectional encoding to help compared to LAS rescoring<cite> [10]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "d53d1b53168041baea5b5002b46627_10",
  "x": [
   "In Table 4 , we compare deliberation models with an RNN-T [6] and LAS rescoring model<cite> [10]</cite> To understand where the improvement comes from, in Fig. 2 we show an example of deliberation attention distribution on the RNN-T hypotheses (x-axis) at every step of the second-pass decoding (yaxis)."
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_0",
  "x": [
   "We use referential translation machine (RTM) <cite>(Bi\u00e7ici, 2018</cite>; Bi\u00e7ici and Way, 2015) models for building our prediction models."
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_1",
  "x": [
   "We use Global Linear Models (GLM) (Collins, 2002) with dynamic learning (GLMd)<cite> (Bi\u00e7ici, 2018)</cite> for word-and phrase-level translation performance prediction."
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_2",
  "x": [
   "We use prediction averaging<cite> (Bi\u00e7ici, 2018)</cite> to obtain a combined prediction from various prediction outputs better than the components, where the performance on the training set is used to obtain weighted average of the top k predictions,\u0177 with evaluation metrics indexed by j \u2208 J and weights with w:"
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_3",
  "x": [
   "This conversion decreases the number of features and obtains close results<cite> (Bi\u00e7ici, 2018)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_4",
  "x": [
   "We use referential translation machine (RTM) <cite>(Bi\u00e7ici, 2018</cite>; Bi\u00e7ici and Way, 2015) models for building our prediction models."
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_5",
  "x": [
   "We use Global Linear Models (GLM) (Collins, 2002) with dynamic learning (GLMd)<cite> (Bi\u00e7ici, 2018)</cite> for word-and phrase-level translation performance prediction."
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_6",
  "x": [
   "We use prediction averaging<cite> (Bi\u00e7ici, 2018)</cite> to obtain a combined prediction from various prediction outputs better than the components, where the performance on the training set is used to obtain weighted average of the top k predictions,\u0177 with evaluation metrics indexed by j \u2208 J and weights with w:"
  ],
  "y": "uses"
 },
 {
  "id": "d63acda66b0c17c5c6725c0e20b2d9_7",
  "x": [
   "This conversion decreases the number of features and obtains close results<cite> (Bi\u00e7ici, 2018)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_0",
  "x": [
   "During the selection of linguistic indicators, we have taken into consideration previously studied features of readability (Fran\u00e7ois and Fairon, 2012; <cite>Heimann M\u00fchlenbock, 2013</cite>; Vajjala and Meurers, 2012) , L2 Swedish curricula (Levy Scherrer and Lindemalm, 2009; Folkuniversitet, 2013) and aspects of Good Dictionary Examples (GDEX) (Hus\u00e1k, 2010; Kilgarriff et al., 2008) , being that we believe they have some properties in common with exercise items."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_1",
  "x": [
   "Research on L1 readability for Swedish, using machine learning, is described in Heimann M\u00fchlenbock (2013) and<cite> Falkenjack et al. (2013)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_2",
  "x": [
   "These required less sophisticated text processing and had previously been used in several studies with success (Beinborn et al., 2012; Dell'Orletta et al., 2011; Fran\u00e7ois and Fairon, 2012; <cite>Heimann M\u00fchlenbock, 2013</cite>; Vajjala and Meurers, 2012) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_3",
  "x": [
   "Subordinates (11) were detected on the basis of the \"UA\" (subordinate clause minus subordinating conjunction) dependency relation tag<cite> (Heimann M\u00fchlenbock, 2013)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_4",
  "x": [
   "Features DepDepth, Mod, Sub and RightDep, PrepComp have previously been empoyed for Swedish L1 readability at the text level in Heimann M\u00fchlenbock (2013) and<cite> Falkenjack et al. (2013)</cite> respectively."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_5",
  "x": [
   "The NN/VB ratio feature, which has a higher value in written text, can also indicate a more complex sentence (Biber et al., 2004;<cite> Heimann M\u00fchlenbock, 2013)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_6",
  "x": [
   "Both NomR and PN/NN capture idea density, i.e. how complex the relation between the ideas expressed are<cite> (Heimann M\u00fchlenbock, 2013)</cite>."
  ],
  "y": "background"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_7",
  "x": [
   "Previous classification results for a similar task obtained an average of 77.25% of precision for the classification of easy-to-read texts within an L1 Swedish text-level readability study<cite> (Heimann M\u00fchlenbock, 2013)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_8",
  "x": [
   "An informative traditional measure was sentence length, similarly to the results of previous studies (Beinborn et al., 2012; Dell'Orletta et al., 2011; Fran\u00e7ois and Fairon, 2012; <cite>Heimann M\u00fchlenbock, 2013</cite>; Vajjala and Meurers, 2012) ."
  ],
  "y": "similarities"
 },
 {
  "id": "d66ca5ff22e508da239fc7fdf5ac29_9",
  "x": [
   "Moreover, in the case of Swedish L1 text readability the noun/pronoun ratio and modifiers proved to be indicative of textlevel difficulty<cite> (Heimann M\u00fchlenbock, 2013</cite> ), but at the sentence level from the L2 perspective only the latter seemed influential in our experiments."
  ],
  "y": "differences"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_0",
  "x": [
   "This continual change and diversity contrasts with the simplicity and consistency of Zipf's law, by which the frequency a word, f , is inversely proportional to its rank k, as f \u223c k \u2212\u03b3 and Heaps law, by which vocabulary size scales sub-linearly with total number of words, across diverse textual and spoken samples [32, 41, 46, 49, 15, 21, 48,<cite> 42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_1",
  "x": [
   "The Google Ngram corpus [37] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [22, 41,<cite> 42,</cite> 1, 28] of n-grams -an n-gram being n consecutive character strings, separated by spaces -derived from millions of books over multiple centuries [35] , the n-gram data now covers English books from the year 1500 to year 2008."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_2",
  "x": [
   "In English, the Zipf's law in the n-gram data [41] exhibits two regimes: one among words with frequencies above about 0.01% (Zipf's exponent \u03b3 \u2248 1) and another (\u03b3 \u2248 1.4) among words with frequency below 0.0001% <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_3",
  "x": [
   "The n-gram data show Heaps law in that, if N t is corpus size and v t is vocabulary size at time t, then v t \u2248 N \u03b2 t , with \u03b2 \u2248 0.5, for all English words in the corpus <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_4",
  "x": [
   "If the n-gram corpus is truncated by a minimum word count, then as that minimum is raised the Heaps scaling exponent increases from \u03b2 < 0.5, approaching \u03b2 < 1 <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_5",
  "x": [
   "The FNM does not, however, readily yield Heaps law (v t = N \u03b2 t , where \u03b2 < 1), for which \u03b2 \u2248 0.5 among the 1-gram data for English <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_6",
  "x": [
   "Although it did not replicate exactly the particular 1-gram corpus we used here, the Heaps law exponent yielded by the PNM does fall within the range-from 0.44 to 0.54-observed in different English 1-gram corpora <cite>[42]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_7",
  "x": [
   "Our canonical model of the PNM differs somewhat from the explanation by <cite>[42]</cite> , in which a \"decreasing marginal need for additional words\" as the corpus grows is underlain by the \"dependency network between the common words ... and their more esoteric counterparts."
  ],
  "y": "differences"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_8",
  "x": [
   "Fig 3b shows how 100 runs of the PNM yields a Heaps law exponent within the range derived by <cite>[42]</cite> for several different n-grams corpora (all English, English fiction, English GB, English US and English 1M)."
  ],
  "y": "similarities background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_9",
  "x": [
   "Although we track 1-grams from the year 1700, for turnover statistics we follow other studies <cite>[42]</cite> in being cautious about the n-grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as 's' and 'f' (e.g., myfelf, yourfelf, provifions, increafe, afked etc)."
  ],
  "y": "uses"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_10",
  "x": [
   "This continual change and diversity contrasts with the simplicity and consistency of Zipf's law, by which the frequency a word, f , is inversely proportional to its rank k, as f \u223c k \u2212\u03b3 and Heaps law, by which vocabulary size scales sub-linearly with total number of words, across diverse textual and spoken samples [32, 41, 46, 49, 15, 21, 48,<cite> 42]</cite> ."
  ],
  "y": "differences background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_11",
  "x": [
   "The Google Ngram corpus [37] provides new support for these statistical regularities in word frequency dynamics at timescales from decades to centuries [22, 41,<cite> 42,</cite> 1, 28] ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_12",
  "x": [
   "In English, the Zipf's law in the n-gram data [41] exhibits two regimes: one among words with frequencies above about 0.01% (Zipf's exponent \u03b3 \u2248 1) and another (\u03b3 \u2248 1.4) among words with frequency below 0.0001% <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_13",
  "x": [
   "The n-gram data show Heaps law in that, if N t is corpus size and v t is vocabulary size at time t, then v t \u2248 N \u03b2 t , with \u03b2 \u2248 0.5, for all English words in the corpus <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_14",
  "x": [
   "If the n-gram corpus is truncated by a minimum word count, then as that minimum is raised the Heaps scaling exponent increases from \u03b2 < 0.5, approaching \u03b2 < 1 <cite>[42]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_15",
  "x": [
   "The FNM does not, however, readily yield Heaps law (v t = N \u03b2 t , where \u03b2 < 1), for which \u03b2 \u2248 0.5 among the 1-gram data for English <cite>[42]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_16",
  "x": [
   "Fig 3b shows how 100 runs of the PNM yields a Heaps law exponent within the range derived by <cite>[42]</cite> for several different n-grams corpora (all English, English fiction, English GB, English US and English 1M)."
  ],
  "y": "background similarities"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_19",
  "x": [
   "Although it did not replicate exactly the particular 1-gram corpus we used here, the Heaps law exponent yielded by the PNM does fall within the range-from 0.44 to 0.54-observed in different English 1-gram corpora <cite>[42]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_20",
  "x": [
   "Our canonical model of the PNM differs somewhat from the explanation by <cite>[42]</cite> , in which a \"decreasing marginal need for additional words\" as the corpus grows is underlain by the \"dependency network between the common words ... and their more esoteric counterparts."
  ],
  "y": "differences"
 },
 {
  "id": "d68bb5264d157cc4c2d9fa9c8f82b6_21",
  "x": [
   "Although we track 1-grams from the year 1700, for turnover statistics we follow other studies <cite>[42]</cite> in being cautious about the n-grams record before the year 1800, due to misspelled words before 1800 that were surely digital scanning errors related to antique printing styles of that may conflate letters such as 's' and 'f' (e.g., myfelf, yourfelf, provifions, increafe, afked etc)."
  ],
  "y": "uses"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_0",
  "x": [
   "Later work by <cite>Wang et al. (2015b)</cite> adopted a different strategy based on the similarity between the dependency parse of a sentence and the semantic AMR graph.",
   "To learn the parser, <cite>Wang et al. (2015b)</cite> define an algorithm that for each instance in the training data infers the action sequence that convert the input dependency tree into the corresponding AMR graph and train a classifier to predict the actions to be taken during testing."
  ],
  "y": "background"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_1",
  "x": [
   "In our submission to SemEval Task 8 on AMR parsing, we follow the transition-based paradigm of <cite>Wang et al. (2015b)</cite> with modifications to the parsing algorithm, and also use the DAGGER imitation learning algorithm (Ross et al., 2011) to generalise better to unseen data."
  ],
  "y": "differences extends"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_2",
  "x": [
   "In the following subsections we focus on the differences from previous work and in particular that of <cite>Wang et al. (2015b)</cite> who introduced the transitionbased dependency-to-AMR paradigm we follow."
  ],
  "y": "differences"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_3",
  "x": [
   "Flanigan et al. (2014) and <cite>Wang et al. (2015b)</cite> , both use AMR fragments as their smallest unit, which may consist of more than one AMR concept."
  ],
  "y": "differences"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_4",
  "x": [
   "ReplaceHead covers two distinct actions in <cite>Wang et al. (2015b)</cite> ; ReplaceHead and Merge."
  ],
  "y": "background"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_5",
  "x": [
   "Unlike <cite>Wang et al. (2015b)</cite> we do not parameterise Swap or Reattach actions with a label."
  ],
  "y": "differences"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_6",
  "x": [
   "<cite>Wang et al. (2015b)</cite> use all AMR concepts and relations that appear in the training set as possible parameters (l c and l r ) if they appear in any sentence containing the same lemma as \u03c3 0 and \u03b2."
  ],
  "y": "differences"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_7",
  "x": [
   "All features used are detailed in Table 2 , largely based on <cite>Wang et al. (2015b)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d8a250a1a0495ee824837839b74f26_8",
  "x": [
   "The key differences to <cite>Wang et al. (2015b)</cite> are the inclusion of the brown, POSpath, NERpath, prefix and suffix feature types."
  ],
  "y": "differences extends"
 },
 {
  "id": "d9567072d2df6c0010b32e1d1eb676_0",
  "x": [
   "This has led to several attempts to use GANs for text generation, with a generator using either a recurrent neural network (RNN) Guo et al., 2017;<cite> Press et al., 2017</cite>; Rajeswar et al., 2017) , or a Convolutional Neural Network (CNN) (Gulrajani et al., 2017; Rajeswar et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "d9567072d2df6c0010b32e1d1eb676_1",
  "x": [
   "One solution is to perform a continuous relaxation of the GAN output, which leads to generators that emit a nearly discrete continuous distribution<cite> (Press et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "d9567072d2df6c0010b32e1d1eb676_2",
  "x": [
   "\u2022 N-gram overlap:<cite> Press et al., 2017)</cite> : Inspired by BLEU (Papineni et al., 2002) , this measures whether n-grams generated by the model appear in a held-out corpus."
  ],
  "y": "background"
 },
 {
  "id": "d9567072d2df6c0010b32e1d1eb676_3",
  "x": [
   "In RNNbased GANs, the previous output token is used at inference time as the input x t Guo et al., 2017;<cite> Press et al., 2017</cite>; Rajeswar et al., 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_0",
  "x": [
   "Currently, state of the art uses lightweight neural networks [1, 2,<cite> 3,</cite> 4] , which can perform inference in real-time even on low-end devices [4, 5] ."
  ],
  "y": "background"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_1",
  "x": [
   "Thus, our main contributions are as follows: first, we develop a novel web application with an in-browser KWS system based on previous state-of-the-art<cite> [3]</cite> models."
  ],
  "y": "background"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_2",
  "x": [
   "KWS is the task of detecting a spoken phrase in audio, applicable to simple command recognition <cite>[3,</cite> 10] and wake-word detection [2, 1] ."
  ],
  "y": "background"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_3",
  "x": [
   "To achieve this goal, resource-efficient architectures using convolutional neural networks (CNNs) <cite>[3,</cite> 1] and recurrent neural networks (RNNs) [2] have been proposed, while other works make use of low-bitwidth weights [4, 9] ."
  ],
  "y": "background"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_4",
  "x": [
   "To compare with past work<cite> [3]</cite> , we pick the following twelve classes: \"yes,\" \"no,\" \"stop,\" \"go,\" \"left,\" \"right,\" \"on,\" \"off,\" unknown, and silence."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_5",
  "x": [
   "For consistency with past results <cite>[3,</cite> 5] , we train our models on the first version of the Google Speech Commands dataset [10] , which comprises a total of 65,000 spoken utterances for 30 short, one-second phrases."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_6",
  "x": [
   "We use the standard 80%, 10%, and 10% splits for the training, validation, and test sets, respectively <cite>[3,</cite> 10] ."
  ],
  "y": "similarities"
 },
 {
  "id": "d9aa77a03ff98cae29701eddb414d3_7",
  "x": [
   "We use the res8 and res8-narrow architectures from Tang and Lin<cite> [3]</cite> as a starting point, which represent prior state of the art in residual CNNs [13] for KWS."
  ],
  "y": "similarities uses"
 },
 {
  "id": "d9d5fce2b33c15bf073a5840930be1_1",
  "x": [
   "For example, we don't replace entity names (like genes) with shorter alternatives as is done with the noun phrases in the present version and with the gene names in our earlier version <cite>11</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "d9d5fce2b33c15bf073a5840930be1_2",
  "x": [
   "We also compare the present version of BioSimplify with the older version <cite>11</cite> which is limited in its functionality because it only implements the rules described by Siddharthan 4 ."
  ],
  "y": "uses"
 },
 {
  "id": "d9d5fce2b33c15bf073a5840930be1_3",
  "x": [
   "We also compare the present version of BioSimplify with the older version <cite>11</cite> which is limited in its functionality because it only implements the rules described by Siddharthan 4 ."
  ],
  "y": "differences"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_0",
  "x": [
   "Recent papers <cite>[3]</cite> , [4] in neural machine translation have proposed the strict use of attention mechanisms in networks such as the Transformer over previous approaches such as recurrent neural networks (RNNs) [5] and convolutional neural networks (CNNs) [6] ."
  ],
  "y": "background"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_1",
  "x": [
   "Google's Vaswani et al. <cite>[3]</cite> proposed the reduction in the sequential steps seen in CNNs and RNNs."
  ],
  "y": "background"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_2",
  "x": [
   "The Transformer architectures proposed by Vaswani et al. <cite>[3]</cite> , seen in Figure 1 , inspires this paper's work."
  ],
  "y": "similarities"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_3",
  "x": [
   "The attention mechanism used by Vaswani et al. <cite>[3]</cite> can be thought of as a function that maps a query and set of keyvalue pairs to an output."
  ],
  "y": "background"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_4",
  "x": [
   "A motivation for creating the Transformer model was the sluggish training and generation times of other common sequence-to-sequence models such as RNNs and CNNs <cite>[3]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_5",
  "x": [
   "All proposed architectures including the base Transformer model <cite>[3]</cite> are trained over the International Workshop on Spoken Language Translation (IWSLT) 2016 corpus and tested similarly over the IWSLT 2014 test corpus [15] ."
  ],
  "y": "background"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_6",
  "x": [
   "On the much larger WMT English-German test set, all our models achieve better results then Vaswani et al. <cite>[3]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "db42e01dbc86b77335a0e488ff85e2_7",
  "x": [
   "Our approach also takes considerably less time than the large Transformer model with a stack of eight encoder attention heads, although it is a little slower than the smaller Transformer model reported by Vaswani et al. <cite>[3]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_0",
  "x": [
   "The PeerRead dataset<cite> (Kang et al., 2018)</cite> is an excellent resource towards research and study on this very impactful and crucial problem."
  ],
  "y": "background"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_1",
  "x": [
   "We carry our current investigations on a portion of the recently released PeerRead dataset<cite> (Kang et al., 2018)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_2",
  "x": [
   "Our approach achieves significant performance improvement over the two tasks defined in<cite> Kang et al. (2018)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_3",
  "x": [
   "For more details on the dataset creation and the task, we request the readers to refer to<cite> Kang et al. (2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_4",
  "x": [
   "One motivation of our work stems from the finding that aspect scores for certain factors like Impact, Originality, Soundness/Correctness which are seemingly central to the merit of the paper, often have very low correlation with the final recommendation made by the reviewers as is made evident in<cite> Kang et al. (2018)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_5",
  "x": [
   "We employ a Multi-Layer Perceptron (MLP Predict) to take the joint paper+review representations x pr as input to get the final<cite> (Kang et al., 2018)</cite> , RMSE\u2192Root Mean Squared Error."
  ],
  "y": "uses"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_6",
  "x": [
   "CNN variant as in<cite> (Kang et al., 2018</cite> ) is used as the comparing system."
  ],
  "y": "uses"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_7",
  "x": [
   "To compare with<cite> Kang et al. (2018)</cite> , we keep the experimental setup (train vs test ratio) identical and re-implement their codes to generate the comparing figures."
  ],
  "y": "uses"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_8",
  "x": [
   "However,<cite> Kang et al. (2018)</cite> performed Task 2 on ICLR 2017 dataset with handcrafted features, and Task 1 in a deep learning setting."
  ],
  "y": "differences extends"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_9",
  "x": [
   "We train the model with SGD optimizer, set momentum as 0.9<cite> (Kang et al., 2018</cite> ) is feature-based and considers only paper, and not the reviews."
  ],
  "y": "uses"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_10",
  "x": [
   "With only using review+sentiment information, we are still able to outperform<cite> Kang et al. (2018)</cite> by a margin of 11% in terms of RMSE."
  ],
  "y": "differences"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_11",
  "x": [
   "For Task 2, we observe that the handcrafted feature-based system by<cite> Kang et al. (2018)</cite> performs inferior compared to the baselines."
  ],
  "y": "differences"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_12",
  "x": [
   "The reason is that the work reported in<cite> Kang et al. (2018)</cite> relies on elementary handcrafted features extracted only from the paper; does not consider the review features whereas we include the review features along with the sentiment information in our deep neural architecture."
  ],
  "y": "differences"
 },
 {
  "id": "dbb0178b572c2a451853737910ac86_13",
  "x": [
   "However, we also find that our approach with only Review+Sentiment performs inferior to the Paper+Review method in<cite> Kang et al. (2018)</cite> for ACL 2017."
  ],
  "y": "differences"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_0",
  "x": [
   "As a result, neural network models that use dense vectors have been shown to have inferior performance against traditional systems that use manually crafted features, unless the dense vectors are combined with the hand-crafted surface features <cite>(Ji and Eisenstein, 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_1",
  "x": [
   "However, these solutions still suffer from the data sparsity problem and almost always require extensive feature selection to work well (Park and Cardie, 2012; Lin et al., 2009;<cite> Ji and Eisenstein, 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_2",
  "x": [
   "This model is similar to the recursive neural networks proposed by<cite> Ji and Eisenstein (2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_4",
  "x": [
   "Previous work in this task has been done over three schemes of evaluation: top-level 4-way classification (Pitler et al., 2009 ), second-level 11-way classification (Lin et al., 2009;<cite> Ji and Eisenstein, 2015)</cite> , and modified second-level classification introduced in the CoNLL 2015 Shared Task ."
  ],
  "y": "background"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_5",
  "x": [
   "The data split and the label set are exactly the same as previous works that use this label set (Lin et al., 2009;<cite> Ji and Eisenstein, 2015)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_6",
  "x": [
   "We use the Berkeley parser to parse all of the data (Petrov et al., 2006 too little data, 50-dimensional WSJ-trained word vectors have previously been shown to be the most effective in this task <cite>(Ji and Eisenstein, 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_7",
  "x": [
   "It outperforms the recursive neural network with bilinear output layer introduced by<cite> Ji and Eisenstein (2015)</cite> (p < 0.05; bootstrap test) and performs comparably with the surface feature baseline (Lin et al., 2009) , which uses various lexical and syntactic features and extensive feature selection."
  ],
  "y": "differences"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_9",
  "x": [
   "Another point of contrast between our work and<cite> Ji and Eisenstein's (2015)</cite> is the modeling choice for inter-argument interaction."
  ],
  "y": "differences"
 },
 {
  "id": "dbe1f1bdf7d94824f6f7cd176a4f6d_10",
  "x": [
   "The recursive model by<cite> Ji and Eisenstein (2015)</cite> is limited to 50 units due to the bilinear layer."
  ],
  "y": "differences"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_0",
  "x": [
   "AI has moved on from naming the entities in the image (Mei et al. 2008; Wang et al. 2009) , to describing the image with a natural sentence (Vinyals et al. 2015; Xu et al. 2015; Karpathy and Li 2015) and then to answering specific questions about the image with the advent of visual question answering (VQA) task <cite>(Antol et al. 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_1",
  "x": [
   "A number of datasets on visual question answering have been introduced in recent years (Malinowski and Fritz 2014; Ren, Kiros, and Zemel 2015) , among which <cite>(Antol et al. 2015)</cite> in particular has gained the most attention and helped popularize the task."
  ],
  "y": "background"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_2",
  "x": [
   "A number of datasets on visual question answering have been introduced in recent years (Malinowski and Fritz 2014; Ren, Kiros, and Zemel 2015) , among which <cite>(Antol et al. 2015)</cite> in particular has gained the most attention and helped popularize the task."
  ],
  "y": "motivation background"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_3",
  "x": [
   "Our FSVQA dataset, derived from <cite>(Antol et al. 2015)</cite> , minimizes such limitation by converting the answers to full-sentences, thus widely expanding the set of answers."
  ],
  "y": "extends"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_4",
  "x": [
   "We circumvent this financial cost by converting the answers in the original VQA dataset <cite>(Antol et al. 2015)</cite> to full-sentence answers by applying a number of linguistic rules using natural language processing techniques."
  ],
  "y": "extends"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_5",
  "x": [
   "Following <cite>(Antol et al. 2015)</cite> , we examined the effect of Conversely, we also examined an approach where only image features are concerned."
  ],
  "y": "uses"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_6",
  "x": [
   "This tendency is consistent with the results reported in <cite>(Antol et al. 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "dcfd8cb0179ab156a6ffcab3358a45_7",
  "x": [
   "It must nevertheless be reminded that the best performances in both <cite>(Antol et al. 2015)</cite> and our experiment were achieved with the presence of both visual and textual clues."
  ],
  "y": "similarities"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_0",
  "x": [
   "In this paper we leverage the Machine Translation of Noisy Text (MTNT) dataset<cite> (Michel and Neubig, 2018)</cite> to enhance the robustness of MT systems by emulating naturally occurring noise in otherwise clean data."
  ],
  "y": "similarities uses"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_1",
  "x": [
   "This is particularly pronounced in systems trained on clean, formalized parallel data such as Europarl (Koehn, 2005) , are tasked with translation of unedited, human generated text such as is common in domains such as social media, where accurate translation is becoming of widespread relevance<cite> (Michel and Neubig, 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_2",
  "x": [
   "In this work we present two primary methods of synthesizing natural noise in accordance with the types of noise identified in prior work (Eisenstein, 2013;<cite> Michel and Neubig, 2018)</cite> as naturally occurring in internet and social media based text."
  ],
  "y": "background"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_3",
  "x": [
   "We present a series of experiments based on the Machine Translation of Noisy Text (MTNT) data set <cite>(Michel and Neubig, 2018</cite> ) through which we demonstrate improved resilience of a vanilla MT system by adaptation using artificially noised data."
  ],
  "y": "uses"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_4",
  "x": [
   "Human generated text on the internet and social media are a particularly rich source of natural noise (Eisenstein, 2013; Baldwin et al., 2015) which causes pronounced problems for MT<cite> (Michel and Neubig, 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_5",
  "x": [
   "For expediency and convenience of experimentation we have chosen to deploy a smaller, faster variant of the model used in<cite> Michel and Neubig (2018)</cite> , which allows us to provide comparative results across a variety of settings."
  ],
  "y": "differences extends"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_6",
  "x": [
   "Other model parameters reflect the implementation outlined in<cite> Michel and Neubig (2018)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "dd603c79f87e98d23f6f8e13028ae9_7",
  "x": [
   "For this method, we inject artificial noise in the clean data according to the distribution of types of noise in MTNT specified in<cite> Michel and Neubig (2018)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_0",
  "x": [
   "Qualia Structures have been originally introduced by <cite>(Pustejovsky, 1991)</cite> and are used for a variety of purposes in Natural Language processing such as the analysis of compounds (Johnston and Busa, 1996) , co-composition and coercion <cite>(Pustejovsky, 1991)</cite> as well as for bridging reference resolution (Bos et al., 1995) ."
  ],
  "y": "background"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_1",
  "x": [
   "According to Aristotle, there are four basic factors or causes by which the nature of an object can be described (cf. (Kronlid, 2003) ): the material cause, i.e. the material an object is made of the agentive cause, i.e. the source of movement, creation or change the formal cause, i.e. its form or type the final cause, i.e. its purpose, intention or aim In his Generative Lexicon (GL) framework <cite>(Pustejovsky, 1991)</cite> reused Aristotle's basic factors for the description of the meaning of lexical elements."
  ],
  "y": "background"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_2",
  "x": [
   "Agentive: describing factors involved in the bringing about of an object, i.e. its creator or the causal chain leading to its creation Formal: describing that properties which distinguish an object in a larger domain, i.e. orientation, magnitude, shape and dimensionality Telic: describing the purpose or function of an object Most of the qualia structures used in <cite>(Pustejovsky, 1991)</cite> however seem to have a more restricted interpretation."
  ],
  "y": "background"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_3",
  "x": [
   "In general it is important to mention that by this approach we are not able to detect and separate multiple meanings of words, i.e. to handle polysemy, which is appropriately accounted for in the framework of the Generative Lexicon <cite>(Pustejovsky, 1991)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_4",
  "x": [
   "Busa, 1996) or <cite>(Pustejovsky, 1991)</cite> , as well as computer, an abstract noun, i.e. conversation, as well as two very specific multi-term words, i.e. natural language processing and data mining."
  ],
  "y": "background"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_5",
  "x": [
   "For book, the first four candidates of the Formal role, i.e. product, item, publication and document are very appropriate, but alluding to the physical object meaning of book as opposed to the meaning in the sense of information container (compare <cite>(Pustejovsky, 1991)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_6",
  "x": [
   "As candidates for the Agentive role we have make, write and create which are appropriate, write being the ideal filler of the Agentive role according to <cite>(Pustejovsky, 1991)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_7",
  "x": [
   "It seems that give is emphasizing the role of a book as a gift, read is referring to the most obvious purpose of a book as specified in the ideal qualia structures of <cite>(Pustejovsky, 1991)</cite> as well as (Johnston and Busa, 1996) and purchase denotes the more general purpose of a book, i.e. to be bought."
  ],
  "y": "motivation"
 },
 {
  "id": "dd875dd5c0f2558bb173f31bbdea00_8",
  "x": [
   "Considering the results for the Formal role, the elements drink (1st), alcohol (2nd) and beverage (4th) are much more specific than liquid as given in <cite>(Pustejovsky, 1991)</cite> , while thing at the 3rd position is certainly too general."
  ],
  "y": "motivation"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_0",
  "x": [
   "However, it still lags behind other statistical methods on very lowresource language pairs<cite> (Zoph et al., 2016</cite>; Koehn and Knowles, 2017) ."
  ],
  "y": "motivation"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_1",
  "x": [
   "We show that, at least in the case of three Turkic languages (Turkish, Uzbek, and Uyghur), the original method of <cite>Zoph et al. (2016)</cite> does not always work, but it is still possible to use the parent model to considerably improve the child model."
  ],
  "y": "uses motivation"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_2",
  "x": [
   "For example, <cite>Zoph et al. (2016)</cite> train a parent model on a (possibly unrelated) high-resource language pair, then use this model to initialize a child model which is further trained on a low-resource language pair."
  ],
  "y": "background"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_3",
  "x": [
   "We follow the transfer learning approach proposed by <cite>Zoph et al. (2016)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_4",
  "x": [
   "The basic idea of our method is to extend the transfer method of <cite>Zoph et al. (2016)</cite> to share the parent and child's source vocabularies, so that when source word embeddings are transferred, a word that appears in both vocabularies keeps its embedding."
  ],
  "y": "uses extends"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_5",
  "x": [
   "We also compared against a word-based baseline (without transfer) and two word-based systems using transfer without vocabulary-sharing, corresponding with the method of <cite>Zoph et al. (2016)</cite> ( \u00a72.2): one where the target word embeddings are fine-tuned, and one where they are frozen."
  ],
  "y": "uses"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_6",
  "x": [
   "In this paper, we have shown that the transfer learning method of <cite>Zoph et al. (2016)</cite> , while appealing, might not always work in a low-resource context."
  ],
  "y": "uses"
 },
 {
  "id": "e2705ae777acffc894f7aa18d42771_7",
  "x": [
   "In this paper, we have shown that the transfer learning method of <cite>Zoph et al. (2016)</cite> , while appealing, might not always work in a low-resource context."
  ],
  "y": "extends"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_0",
  "x": [
   "Their output exhibits a disproportionate replication of common n-grams and full captions seen in the training set [9, 11,<cite> 26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_1",
  "x": [
   "The subjectivity in what defines a good caption, has made it difficult to identify a single metric for the overall quality of Image Captioning models [5,<cite> 26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_2",
  "x": [
   "All these approaches unfortunately have a strong focus on replicating common n-grams from the ground-truth captions [5] and do not take into account the richness and diversity of human expression [9,<cite> 26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_3",
  "x": [
   "More recently, this concept has been employed as the focus for training and evaluation<cite> [26,</cite> 29] , and it has been proposed that improving caption diversity leads to more human-like captions <cite>[26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_4",
  "x": [
   "\u2500 novelty -percentage of generated captions where exact duplicates are not found in the training set [11,<cite> 26,</cite> 29 ] \u2500 diversity -percentage of distinct captions (where duplicates count as a single distinct caption) out of the total number of generated captions [11] \u2500 vocabulary size -number of unique words used in generated captions <cite>[26]</cite>"
  ],
  "y": "uses"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_5",
  "x": [
   "We take a slightly different approach from both the joint training in [22] and recent applications of GAN training in Image Captioning [9,<cite> 26]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_7",
  "x": [
   "The vocabulary size also increases but is lower than in <cite>[26]</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_8",
  "x": [
   "Note that [12, 29] use different data splits, while our models and <cite>[26]</cite> use the Karpathy 5k splits [17] ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "e3b9c00d792bcddb6eea449179e61e_10",
  "x": [
   "Another example of GAN training is <cite>[26]</cite> where the Discriminator classifies whether a multi-sample set of captions are human-written or generated."
  ],
  "y": "differences"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_0",
  "x": [
   "To help agencies monitor gang activity on social media, our past work investigated how features from Twitter profiles, including profile text, profile images, tweet text, emjoi use, and their links to YouTube, may be used to reliably find gang member profiles <cite>[BWDS16]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_1",
  "x": [
   "To help agencies monitor gang activity on social media, our past work investigated how features from Twitter profiles, including profile text, profile images, tweet text, emjoi use, and their links to YouTube, may be used to reliably find gang member profiles <cite>[BWDS16]</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_2",
  "x": [
   "In our previous work <cite>[BWDS16]</cite> , we curated what may be the largest set of gang member profiles to study how gang member Twitter profiles can be automatically identified based on the content they share online."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_3",
  "x": [
   "In our previous work <cite>[BWDS16]</cite> , we curated what may be the largest set of gang member profiles to study how gang member Twitter profiles can be automatically identified based on the content they share online."
  ],
  "y": "extends"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_4",
  "x": [
   "Gang member tweets and profile descriptions tend to have few textual indicators that demonstrate their gang affiliations or their tweets/profile text may carry acronyms which can only be deciphered by others involved in gang culture <cite>[BWDS16]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_5",
  "x": [
   "An in-depth explanation of these feature selection can be found in <cite>[BWDS16]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_6",
  "x": [
   "In our previous work, we observed that gang members use curse words nearly five times more than the average curse words use on Twitter <cite>[BWDS16]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_7",
  "x": [
   "Further, we found that 76.58% of the shared links are related to hip-hop music, gangster rap, and the culture that surrounds this music genre <cite>[BWDS16]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_8",
  "x": [
   "We consider a dataset of curated gang and non-gang members' Twitter profiles collected from our previous work <cite>[BWDS16]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_9",
  "x": [
   "Specific details about our data curation procedure are discussed in <cite>[BWDS16]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3c735811b2ea08d92659272ddcbdd_10",
  "x": [
   "We compare our results with the two best performing systems reported in <cite>[BWDS16]</cite> which are the two state-of-theart models for identifying gang members in Twitter."
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_0",
  "x": [
   "More recently, a number of novel insertionbased architectures have been developed for sequence generation (Gu et al., 2019;<cite> Stern et al., 2019</cite>; Welleck et al., 2019) ."
  ],
  "y": "background"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_1",
  "x": [
   "These frameworks license a diverse set of generation orders, including uniform (Welleck et al., 2019) , random (Gu et al., 2019) , or balanced binary trees <cite>(Stern et al., 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_2",
  "x": [
   "More recently, a number of novel insertionbased architectures have been developed for sequence generation (Gu et al., 2019;<cite> Stern et al., 2019</cite>; Welleck et al., 2019) .",
   "These frameworks license a diverse set of generation orders, including uniform (Welleck et al., 2019) , random (Gu et al., 2019) , or balanced binary trees <cite>(Stern et al., 2019)</cite> .",
   "Some of them also match the quality of state-of-the-art left-to-right models <cite>(Stern et al., 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_3",
  "x": [
   "Some of them also match the quality of state-of-the-art left-to-right models <cite>(Stern et al., 2019)</cite> ."
  ],
  "y": "background similarities"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_4",
  "x": [
   "We use one such insertion-based model, the Insertion Transformer <cite>(Stern et al., 2019)</cite> , for our empirical study."
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_5",
  "x": [
   "We note that<cite> Stern et al. (2019)</cite> also experimented with a number of other architectural variants, but we use the baseline version of the model described above in our experiments for simplicity."
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_6",
  "x": [
   "Having defined the target distribution, we take the slot loss L for insertions within a particular slot to be the KL-divergence between the oracle distribution q oracle and the model distribution p. Substituting L in for the slot loss within the training framework of<cite> Stern et al. (2019)</cite> then gives the full sequence generation loss, which we can use to train an Insertion Transformer under any oracle policy rather than just the specific one they propose."
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_7",
  "x": [
   "We follow<cite> Stern et al. (2019)</cite> and use a uniform roll-in policy when sampling partial outputs at training time in which we first select a subset size uniformly at random, then select a random subset of the output of that size."
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_8",
  "x": [
   "We perform a sweep over temperatures \u03c4 \u2208 {0.5, 1, 2} and EOS penalties \u2208 {0, 0.5, 1, 1.5, . . . , 8} <cite>(Stern et al., 2019)</cite>"
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_9",
  "x": [
   "The uniform loss proposed by<cite> Stern et al. (2019)</cite> serves as a strong baseline for both language pairs, coming within 0.6 points of the original Transformer for En-De at 26.72 BLEU, and attaining a respectable score of 33.1 BLEU on En-Zh."
  ],
  "y": "uses"
 },
 {
  "id": "e3dd013c944cf8dcb6ff90124a0e01_10",
  "x": [
   "On the other hand, we note that while the soft left-to-right and right-to-left losses perform substantially better than the hard loss employed in the original work by<cite> Stern et al. (2019)</cite> , performance does suffer when using parallel decoding for those models, which is generally untrue of the other orderings."
  ],
  "y": "differences"
 },
 {
  "id": "e59bd02bb560d80ce08dfcd6b35317_0",
  "x": [
   "We then test the robustness of a popular topic modelling algorithm, Latent Dirichlet Allocation (LDA) using a topic stability measure introduced by <cite>Greene et al. (2014)</cite> over a variety of corpora."
  ],
  "y": "uses"
 },
 {
  "id": "e59bd02bb560d80ce08dfcd6b35317_1",
  "x": [
   "For the evaluation of topic models, we follow the approach by <cite>Greene et al. (2014)</cite> for measuring topic model agreement ."
  ],
  "y": "uses"
 },
 {
  "id": "e59bd02bb560d80ce08dfcd6b35317_2",
  "x": [
   "In this paper, we explore two datasets bbc and wikilow<cite> (Greene et al., 2014)</cite> with different document size and corpus size."
  ],
  "y": "uses"
 },
 {
  "id": "e59bd02bb560d80ce08dfcd6b35317_3",
  "x": [
   "This complements previous work by <cite>Greene et al. (2014)</cite> who investigated how topic stability is influenced by number of topics over noisefree corpora."
  ],
  "y": "similarities"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_0",
  "x": [
   "Twitter conversations<cite> (Danescu-Niculescu-Mizil, Gamon, and Dumais 2011</cite>; Purohit et al. 2013 ) and popular memes (Myers and Leskovec 2012;<cite> Coscia 2013)</cite> prove this similarity in social media."
  ],
  "y": "background"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_1",
  "x": [
   "To measure commonsense for a particular situation is hard, however, adaptations can be easily captured in Twitter conversations<cite> (Danescu-NiculescuMizil, Gamon, and Dumais 2011</cite>; Purohit et al. 2013) , in memes (Myers and Leskovec 2012;<cite> Coscia 2013)</cite> , and faceto-face discussions<cite> (Danescu-Niculescu-Mizil et al. 2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_2",
  "x": [
   "To measure commonsense for a particular situation is hard, however, adaptations can be easily captured in Twitter conversations<cite> (Danescu-NiculescuMizil, Gamon, and Dumais 2011</cite>; Purohit et al. 2013) , in memes (Myers and Leskovec 2012;<cite> Coscia 2013)</cite> , and faceto-face discussions<cite> (Danescu-Niculescu-Mizil et al. 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_3",
  "x": [
   "To this end, we evaluate the open access data of the United States Supreme Court (Hawes, Lin, and Resnik 2009; Hawes 2009; <cite>Danescu-Niculescu-Mizil et al. 2012</cite> ), prepare conversation groups with different adaptation levels, implement a suitable algorithm to extract linguistic relations in these group conversations, and finally provide a comparison between the groups and the discovered linguistic relations."
  ],
  "y": "uses"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_4",
  "x": [
   "Both the original data and the most updated version used here are publicly available<cite> (Danescu-NiculescuMizil et al. 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_5",
  "x": [
   "The linguistic coordination is systematically quantified by<cite> (Danescu-Niculescu-Mizil et al. 2012</cite> ) and the arguments follow the principles of exchange theory examining behavior dynamics in low and high power groups (Willer 1999; Thye, Willer, and Markovsky 2006) : Lawyers tend to cooperate more to Justices than conversely and demonstrate strong linguistic coordination in their speech."
  ],
  "y": "background"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_6",
  "x": [
   "The linguistic coordination is systematically quantified by<cite> (Danescu-Niculescu-Mizil et al. 2012</cite> ) and the arguments follow the principles of exchange theory examining behavior dynamics in low and high power groups (Willer 1999; Thye, Willer, and Markovsky 2006) : Lawyers tend to cooperate more to Justices than conversely and demonstrate strong linguistic coordination in their speech."
  ],
  "y": "uses"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_7",
  "x": [
   "Referring exchange theory (Willer 1999; Thye, Willer, and Markovsky 2006) and the measured coordination<cite> (Danescu-Niculescu-Mizil et al. 2012)</cite> , one can order the relative power of each Justice and lawyer pair"
  ],
  "y": "uses"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_8",
  "x": [
   "We further add another dimension in the relative power: Winners and Losers, haven't been investigated in the previous study<cite> (Danescu-Niculescu-Mizil et al. 2012)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "e5bff4a27468139762496abdff3436_9",
  "x": [
   "Unlike the previous study<cite> (Danescu-Niculescu-Mizil et al. 2012)</cite> , entirely tracking back and forth utterances and proving the adaptation, e.g., linguistic coordination, by identifying the frequency of selected keywords, we directly utilize their overall conclusion and claim that linguistic relations already preserve the adaptation and any other complex collective linguistic process induced by both cooperation and competition in different power groups."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_0",
  "x": [
   "The proposed system outperforms the baseline keyword spotting model in [<cite>1</cite>] due to increased optimizability."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_1",
  "x": [
   "Recently introduced end-to-end trainable DNN approaches [<cite>1,</cite> 13] further improved accuracy and lowered resource requirements using highly optimizable system design."
  ],
  "y": "background"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_2",
  "x": [
   "In general, training of such DNN based systems required framelevel labels generated by LVCSR systems [14, <cite>1</cite>] ."
  ],
  "y": "background"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_3",
  "x": [
   "In [<cite>1</cite>] , the top level loss is derived by integrating frame-level losses, which are computed using frame-level labels from LVCSR."
  ],
  "y": "background"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_4",
  "x": [
   "The proposed model uses the same encoder/decoder structure as [<cite>1</cite>] ( Fig.1 ), but it differs in that encoder and decoder models are trained simultaneously using smoothed max pooling loss."
  ],
  "y": "differences similarities uses"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_5",
  "x": [
   "The proposed model uses the same encoder/decoder structure as [<cite>1</cite>] ( Fig.1 ), but it differs in that encoder and decoder models are trained simultaneously using smoothed max pooling loss.",
   "In [<cite>1</cite>] , both encoder and decoder models are trained with cross entropy (CE) loss using frame level labels."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_6",
  "x": [
   "The proposed smoothed max pooling loss doesnt strictly depend on phoneme-level alignment, allowing better optimization than the <cite>baseline</cite>."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_7",
  "x": [
   "Both the <cite>baseline</cite> and the proposed model have an encoder which takes spectral domain feature Xt as input and generate (K+1) outputs Y E corresponding to phoneme-like sound units (Fig.1 )."
  ],
  "y": "similarities"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_8",
  "x": [
   "In [<cite>1</cite>] , the encoder model is trained first, and then the decoder model is trained while encoder model weights are frozen."
  ],
  "y": "background"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_9",
  "x": [
   "In [<cite>1</cite>] , the encoder model is trained to predict phonemelevel labels provided from LVCSR."
  ],
  "y": "background"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_10",
  "x": [
   "In [<cite>1</cite>] , target label sequence consists of intervals of repeated labels which we call runs."
  ],
  "y": "background"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_11",
  "x": [
   "We compare the model trained with the new smoothed max pooling loss on encoder/decoder architecture with the baseline in [<cite>1</cite>] ."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_12",
  "x": [
   "Both the <cite>baseline</cite> and the proposed model have the same architecture."
  ],
  "y": "similarities"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_13",
  "x": [
   "We used the same frontend feature extract as the baseline [<cite>1</cite>] in our experiments."
  ],
  "y": "similarities uses"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_15",
  "x": [
   "We selected E2E 318K architecture in [<cite>1</cite>] as the baseline and use the same structure for testing all other models."
  ],
  "y": "similarities uses"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_17",
  "x": [
   "We call the <cite>baseline model</cite> as Baseline CE CE where encoder and decoder submodels are trained with CE loss."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_18",
  "x": [
   "Max3 CE SMP used <cite>baseline</cite> CE loss for encoder."
  ],
  "y": "uses"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_19",
  "x": [
   "Data augmentation similar to [<cite>1</cite>] has been used for better robustness."
  ],
  "y": "similarities"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_21",
  "x": [
   "Max3 CE MP model also performs better than the <cite>baseline</cite> but not as good as Max4."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_22",
  "x": [
   "Other variations Max2 (has only decoder loss) and Max1 (has CTC encoder loss) performed worse than <cite>baseline.</cite>"
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_23",
  "x": [
   "Especially the proposed Max4 model reduces FR rate to nearly half of the <cite>baseline</cite> in clean accented and noisy inside-vehicle conditions, where it's more difficult to obtain training data with accurate alignments."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_24",
  "x": [
   "Experiments show that the proposed approach outperforms the <cite>baseline model</cite> with CE loss by relative 22%-54% across a variety of conditions."
  ],
  "y": "differences"
 },
 {
  "id": "e6fe4c6c32294072dbc1ee5bb0a606_25",
  "x": [
   "Further, we show that applying smoothing before max pooling is highly important for achieving accuracy better than the <cite>baseline</cite>."
  ],
  "y": "differences"
 },
 {
  "id": "e75e14ff2812f34ff456eb472a36d2_0",
  "x": [
   "In the third part, a series of deep models including deep unfolding (Chien and Lee, 2018) , Bayesian RNN (Gal and Ghahramani, 2016; Chien and Ku, 2016) , sequence-to-sequence learning (Graves et al., 2006; Gehring et al., 2017) , CNN (<cite>Kalchbrenner et al., 2014</cite>; Xingjian et al., 2015; , GAN (Tsai and Chien, 2017) and VAE are introduced."
  ],
  "y": "background"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_0",
  "x": [
   "These types of vector representations are particularly desirable for the way in which they better model the grounding of perceptual or semantic concepts in human vocabulary<cite> (Lazaridou et al., 2015</cite>; Glenberg & Robertson, 2000; )."
  ],
  "y": "background"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_1",
  "x": [
   "As such, there has been development towards so-called multimodal distributional semantic models (Silberer & Lapata, 2014; <cite>Lazaridou et al., 2015</cite>; Kiros et al., 2014; Frome et al., 2013; Bruni et al., 2014) , which leverage textual co-occurance and visual features to form multimodal representations of words or concepts."
  ],
  "y": "background"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_2",
  "x": [
   "The work introduced in<cite> Lazaridou et al. (2015)</cite> sought to address many of the drawbacks of these models."
  ],
  "y": "background"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_3",
  "x": [
   "In this work, we introduce a further refinement on the multimodal skip-gram architecture, building upon the approaches of Mikolov et al. (2013a; b) , , and<cite> Lazaridou et al. (2015)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_4",
  "x": [
   "As explained in<cite> Lazaridou et al. (2015)</cite> , the majority of this literature focuses on constructing textual and visual representations independently and then combining them under some metrics."
  ],
  "y": "background"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_5",
  "x": [
   "The multimodal skip-gram architecture proposed by<cite> Lazaridou et al. (2015)</cite> takes a more fine-grained approach by incorporating word-level visual context and concurrently training words to predict other text words in the window as well as their visual representation."
  ],
  "y": "background"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_6",
  "x": [
   "To construct the vectors for the visual representations, we follow a similar experimental set-up as that used by<cite> Lazaridou et al. (2015)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_7",
  "x": [
   "Using the results published by<cite> Lazaridou et al. (2015)</cite> and a target word embedding of 300, we compare our results to their MMSKIP-GRAM-A and MMSKIP-GRAM-B, which maximize the similarity of the textual and visual representations Table 1 : Spearman correlation between the generated multimodal similarities and the benchmark human judgments."
  ],
  "y": "uses"
 },
 {
  "id": "e7b1c00e747f5bfbb96499d7223496_8",
  "x": [
   "In the cases of capturing general relatedness and pure visual similarity, the multimodal model of<cite> Lazaridou et al. (2015)</cite> performs better."
  ],
  "y": "differences"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_0",
  "x": [
   "Compared with previous recursive neural networks (<cite>Socher et al., 2013</cite>; 2012) , S-LSTM has the potentials of avoiding gradient vanishing and hence may model long-distance interaction over trees."
  ],
  "y": "differences motivation"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_1",
  "x": [
   "S-LSTM can be considered as bringing the merits of a recursive neural network and a recurrent neural network togetherStanford Sentiment Tree Bank (<cite>Socher et al., 2013</cite>) to determine the sentiment for different granularities of phrases in a tree.",
   "<cite>The dataset</cite> has favorable properties: in addition to being a benchmark for much previous work, <cite>it</cite> provides with human annotations at all nodes of the trees, enabling us to comprehensively explore the properties of S-LSTM."
  ],
  "y": "motivation"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_2",
  "x": [
   "In recent years, recursive neural networks (RvNN) have been introduced and demonstrated to achieve state-of-the-art performances on different problems such as semantic analysis in natural language processing and image segmentation (<cite>Socher et al., 2013</cite>; 2011) .",
   "<cite>These networks</cite> are defined over recursive tree structures-a tree node is a vector computed from its children."
  ],
  "y": "background"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_3",
  "x": [
   "We compare our model with the RvNN models presented in (<cite>Socher et al., 2013</cite>) , as we directly replaced the tensor-enhanced composition layer at each tree node with a S-LSTM memory block."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_4",
  "x": [
   "We compare our model with the RvNN models presented in (<cite>Socher et al., 2013</cite>) , as we directly replaced the tensor-enhanced composition layer at each tree node with a S-LSTM memory block."
  ],
  "y": "differences"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_5",
  "x": [
   "In this paper, we assume there are two children at each nodes, same as in (<cite>Socher et al., 2013</cite>) and therefore we use <cite>their data</cite> in our experiments."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_6",
  "x": [
   "Backpropagation over structures During training, the gradient of the objective function with respect to each parameter can be calculated efficiently via backpropagation over structures (Goller & Kchler, 1996; <cite>Socher et al., 2013</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_7",
  "x": [
   "The major difference from that of (<cite>Socher et al., 2013</cite> ) is we use LSTM-like backpropagation, where unlike a regular LSTM, pass of error needs to discriminate between the left and right children, or in a topology with more than two children, needs to discriminate between children."
  ],
  "y": "differences"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_8",
  "x": [
   "Following (<cite>Socher et al., 2013</cite>) , the overall objective function we used to learn S-LSTM in this paper is simply minimizing the overall cross-entropy errors and a sum of that at all nodes."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_9",
  "x": [
   "We specifically attempt to determine the sentiment of different granularities of phrases in a tree, within the Stanford Sentiment Tree Bank benchmark data (<cite>Socher et al., 2013</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_10",
  "x": [
   "In this paper, we put the proposed LSTM memory blocks at tree nodes-we replaced the tensorenhanced composition layer at each tree node presented in (<cite>Socher et al., 2013</cite> ) with a S-LSTM memory block."
  ],
  "y": "extends"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_11",
  "x": [
   "We used the <cite>same dataset</cite>, the Stanford Sentiment Tree Bank, to evaluate the performances of the models.",
   "In addition to being a benchmark for much previous work, <cite>the data</cite> provide with human annotations at all nodes of the trees, facilitating a more comprehensive exploration of the properties of S-LSTM."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_12",
  "x": [
   "The Stanford Sentiment Tree Bank (<cite>Socher et al., 2013</cite>) contains about 11,800 sentences from the movie reviews that were originally discussed in (Pang & Lee, 2005) ."
  ],
  "y": "background"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_13",
  "x": [
   "We use the same split of the training and test data as in (<cite>Socher et al., 2013</cite>) to predict the sentiment categories of the roots (sentences) and all phrases (including sentences)."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_14",
  "x": [
   "Following (<cite>Socher et al., 2013</cite>) , we also use the classification accuracy to measure the performances."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_15",
  "x": [
   "As mentioned before, we follow (<cite>Socher et al., 2013</cite>) to minimize the cross-entropy error for all nodes or for roots only, depending on specific experiment settings."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_16",
  "x": [
   "We tuned our model against the development data set as split in (<cite>Socher et al., 2013</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_17",
  "x": [
   "In the default setting, we conducted experiments as in (<cite>Socher et al., 2013</cite>) ."
  ],
  "y": "uses"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_20",
  "x": [
   "RNTN is different from <cite>RvNN</cite> in that when merging two nodes to obtain the hidden vector of their parent, tensor is used to obtain the second-degree polynomial interactions."
  ],
  "y": "differences"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_21",
  "x": [
   "Table 1 showed that S-LSTM achieved the best predictive performance, when compared to all the models reported in (<cite>Socher et al., 2013</cite>) ."
  ],
  "y": "differences"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_23",
  "x": [
   "Detailed annotations in the <cite>tree bank</cite> enable much interesting work to be possible, e.g., the study of the effect of negation in changing sentiment (Zhu et al., 2014) ."
  ],
  "y": "future_work"
 },
 {
  "id": "e8c60c9fc3a2d74df632f3b423adae_24",
  "x": [
   "Since for these models, phrase-level training signals are not available-the nodes here do not correspond to that in the <cite>original Standford Sentiment Tree Bank</cite>, but the roots and leafs annotations are still the same, so we run two versions of our experiments: one uses only training signals from roots and the other includes also leaf annotations."
  ],
  "y": "differences similarities"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_0",
  "x": [
   "<cite>Krishna et al. (2016)</cite> is currently the state of the art in Sanskrit word segmentation."
  ],
  "y": "background"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_1",
  "x": [
   "Though <cite>Krishna et al. (2016)</cite> has designed their system with this requirement in mind and outlined the possible extension of <cite>their</cite> system for the purpose, <cite>the system</cite> currently only predicts the final word-form."
  ],
  "y": "motivation"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_2",
  "x": [
   "It needs to be noted that the average length of a string in the Digital Corpus of Sanskrit is 6.7 (<cite>Krishna et al., 2016</cite>) ."
  ],
  "y": "background"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_3",
  "x": [
   "Such tools are put to use by some of the existing systems (<cite>Krishna et al., 2016</cite>; Mittal, 2010 ) to obtain additional morphological or syntactic information about the sentences.",
   "This limits the scalability of <cite>those systems</cite>, as they cannot handle out of vocabulary words.",
   "Scalability of <cite>such systems</cite> is further restricted as the sentences often need to undergo linguistically involved preprocessing steps that lead to human in the loop processing.",
   "The systems by <cite>Krishna et al. (2016)</cite> and Krishna et al. (2017) assume that the parser by Goyal et al. (2012) , identifies all the possible candidate chunks."
  ],
  "y": "motivation"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_4",
  "x": [
   "Such tools are put to use by some of the existing systems (<cite>Krishna et al., 2016</cite>; Mittal, 2010 ) to obtain additional morphological or syntactic information about the sentences."
  ],
  "y": "background"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_5",
  "x": [
   "Such tools are put to use by some of the existing systems (<cite>Krishna et al., 2016</cite>; Mittal, 2010 ) to obtain additional morphological or syntactic information about the sentences.",
   "This limits the scalability of <cite>those systems</cite>, as they cannot handle out of vocabulary words.",
   "Scalability of <cite>such systems</cite> is further restricted as the sentences often need to undergo linguistically involved preprocessing steps that lead to human in the loop processing.",
   "The systems by <cite>Krishna et al. (2016)</cite> and Krishna et al. (2017) assume that the parser by Goyal et al. (2012) , identifies all the possible candidate chunks."
  ],
  "y": "background"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_6",
  "x": [
   "Such tools are put to use by some of the existing systems (<cite>Krishna et al., 2016</cite>; Mittal, 2010 ) to obtain additional morphological or syntactic information about the sentences.",
   "This limits the scalability of <cite>those systems</cite>, as they cannot handle out of vocabulary words.",
   "Scalability of <cite>such systems</cite> is further restricted as the sentences often need to undergo linguistically involved preprocessing steps that lead to human in the loop processing."
  ],
  "y": "motivation"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_7",
  "x": [
   "Such tools are put to use by some of the existing systems (<cite>Krishna et al., 2016</cite>; Mittal, 2010 ) to obtain additional morphological or syntactic information about the sentences.",
   "This limits the scalability of <cite>those systems</cite>, as they cannot handle out of vocabulary words.",
   "Scalability of <cite>such systems</cite> is further restricted as the sentences often need to undergo linguistically involved preprocessing steps that lead to human in the loop processing."
  ],
  "y": "motivation"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_8",
  "x": [
   "The systems by <cite>Krishna et al. (2016)</cite> and Krishna et al. (2017) assume that the parser by Goyal et al. (2012) , identifies all the possible candidate chunks."
  ],
  "y": "background"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_9",
  "x": [
   "Those systems such as <cite>Krishna et al. (2016)</cite> can be used to identify the morphological tags of the system as <cite>they</cite> currently store the morphological information of predicted candidates, but do not use them for evaluation as of now."
  ],
  "y": "motivation background"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_10",
  "x": [
   "Those systems such as <cite>Krishna et al. (2016)</cite> can be used to identify the morphological tags of the system as <cite>they</cite> currently store the morphological information of predicted candidates, but do not use them for evaluation as of now."
  ],
  "y": "motivation"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_11",
  "x": [
   "Those systems such as <cite>Krishna et al. (2016)</cite> can be used to identify the morphological tags of the system as <cite>they</cite> currently store the morphological information of predicted candidates, but do not use them for evaluation as of now."
  ],
  "y": "differences"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_12",
  "x": [
   "Our model with attention outperforms the current state of the art (<cite>Krishna et al., 2016</cite>) ."
  ],
  "y": "differences"
 },
 {
  "id": "e9e733d38affa8a39a633ffb4d9d71_13",
  "x": [
   "Our experiments in line with the measures reported in <cite>Krishna et al. (2016)</cite> show that our system performs robustly across strings of varying word size."
  ],
  "y": "uses"
 },
 {
  "id": "eb591565efc03df1706710218a8f19_0",
  "x": [
   "Learning knowledge from analyzing large-scaled unlabeled data is compulsory and proved useful in the previous works [4, <cite>5,</cite> 6] ."
  ],
  "y": "background"
 },
 {
  "id": "eb591565efc03df1706710218a8f19_1",
  "x": [
   "knowledge from analyzing large-scaled unlabeled data is compulsory and proved useful in the previous works [4, <cite>5,</cite> 6] ."
  ],
  "y": "background"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_0",
  "x": [
   "In particular, we use methods proposed by Marie and Fujita (2018) ,<cite> Artetxe et al. (2018b)</cite> , and Lample et al. (2018) ."
  ],
  "y": "uses"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_1",
  "x": [
   "This code is derived from<cite> Artetxe et al. (2018b)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_2",
  "x": [
   "As in<cite> Artetxe et al. (2018b)</cite> , the term was set to 0.001."
  ],
  "y": "similarities uses"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_3",
  "x": [
   "The SMT system trained on synthetic data eliminates the noisy phrase pairs using 2 As in<cite> Artetxe et al. (2018b)</cite> , \u03c4 is estimated by maximizing the phrase translation probability between an embedding and the nearest embedding on the opposite side."
  ],
  "y": "similarities uses"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_4",
  "x": [
   "In fact, Lample et al. (2018) ,<cite> Artetxe et al. (2018b)</cite> and Marie and Fujita (2018) use the News Crawl of source and target language as training data."
  ],
  "y": "background"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_5",
  "x": [
   "The implementation proposed by<cite> Artetxe et al. (2018b)</cite> 7 was modified to conduct the experiments."
  ],
  "y": "extends"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_6",
  "x": [
   "Unsupervised Machine Translation Studies on unsupervised methods have been conducted for both NMT (Lample et al., 2018; Marie and Fujita, 2018) and SMT <cite>(Artetxe et al., 2018b</cite> Table 4 : Error types for which our best system corrected errors well or mostly did not correct on the dev data."
  ],
  "y": "background"
 },
 {
  "id": "ebb79e6e223d4747987aa4abfd1a58_7",
  "x": [
   "this study, we apply the USMT method of<cite> Artetxe et al. (2018b)</cite> and Marie and Fujita (2018) to GEC."
  ],
  "y": "uses"
 },
 {
  "id": "ec0ae4e56c069e3efb4a2dc12199cd_0",
  "x": [
   "AL has been successfully applied to speed up the annotation process for many NLP tasks without sacrificing annotation quality (Engelson and Dagan, 1996; Ngai and Yarowsky, 2000; Hwa, 2001; <cite>Tomanek et al., 2007a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ec0ae4e56c069e3efb4a2dc12199cd_1",
  "x": [
   "In <cite>Tomanek et al. (2007a)</cite> we introduced the selection agreement (SA) curve -the average agreement amongst the selected examples plotted over time."
  ],
  "y": "background"
 },
 {
  "id": "ec0ae4e56c069e3efb4a2dc12199cd_2",
  "x": [
   "We employed the committee-based AL approach described in <cite>Tomanek et al. (2007a)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ec0ae4e56c069e3efb4a2dc12199cd_3",
  "x": [
   "This effect is truly beneficial, especially for real-world annotation projects, due to much lower training times and, by this, shorter annotator idle times <cite>(Tomanek et al., 2007a)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ee66681690f2c92fe705a09bf7015d_0",
  "x": [
   "Our results demonstrate a significant improvement in accuracy of 7.2% over a statistical machine translation (SMT) system (Zens et al., 2005) and of 2.2% over a perceptron-based edit model <cite>(Freitag and Khadivi, 2007)</cite> ."
  ],
  "y": "differences background"
 },
 {
  "id": "ee66681690f2c92fe705a09bf7015d_1",
  "x": [
   "Given a source sequence f computing the best scoring target sequence e = arg max e \u2032 s(e \u2032 , f ) among all possible sequences E * requires a beam search procedure <cite>(Freitag and Khadivi, 2007)</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "ee66681690f2c92fe705a09bf7015d_2",
  "x": [
   ". In this paper, we employ the same features as those used by<cite> Freitag and Khadivi (2007)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ee66681690f2c92fe705a09bf7015d_3",
  "x": [
   "We use the same training/development/testing (8084/1000/1000) set as the one used in a previous benchmark study <cite>(Freitag and Khadivi, 2007)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ee66681690f2c92fe705a09bf7015d_4",
  "x": [
   "We compare our model against a state-of-the-art statistical machine translation (SMT) system (Zens et al., 2005) and an averaged perceptron edit model (PTEM) with identical features <cite>(Freitag and Khadivi, 2007)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_0",
  "x": [
   "By contrast, most of the prior work depend on parallel data in the form of a small bitext (Genzel, 2005) , a gold seed lexicon <cite>(Mikolov et al., 2013b)</cite> , or document-aligned comparable corpora (Vuli\u0107 and Moens, 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_1",
  "x": [
   "We then use this noisy seed lexicon to train context vectors via neural network <cite>(Mikolov et al., 2013b)</cite> , inducing a cross-lingual transformation that approximates semantic similarity."
  ],
  "y": "background"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_2",
  "x": [
   "The results demonstrate a substantial error reduction with respect to a word-vector-based method of<cite> Mikolov et al. (2013b)</cite> , when using the same word vectors on six source-target pairs."
  ],
  "y": "similarities uses"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_3",
  "x": [
   "We adapt the approach of<cite> Mikolov et al. (2013b)</cite> for learning a linear transformation between the source and target vector spaces to enable it to function given only a small, noisy seed."
  ],
  "y": "similarities uses"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_4",
  "x": [
   "While<cite> Mikolov et al. (2013b)</cite> derive the translation matrix using five thousand translation pairs obtained via Google Translate,"
  ],
  "y": "differences"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_5",
  "x": [
   "Unlike<cite> Mikolov et al. (2013b)</cite> , our algorithm iteratively expands the lexicon, which gradually increases the accuracy of the translation matrices."
  ],
  "y": "differences"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_6",
  "x": [
   "In this section we compare our method to two prior methods, our reimplementation of the supervised word-vector-based method of<cite> Mikolov et al. (2013b)</cite> (using the same vectors as our method), and the reported results of an EM-based method of Haghighi et al. (2008) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_7",
  "x": [
   "We evaluate the induced lexicon after 40 iterations of bidirectional bootstrapping by comparing it to the lexicon after the first iteration in a single direction, which is equivalent to the method of<cite> Mikolov et al. (2013b)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "ee8163c5a76ed9f929a960b3086356_8",
  "x": [
   "The results in Table 2 show that the method of<cite> Mikolov et al. (2013b)</cite> (MIK13-Auto) , represented by the first translation matrix derived on our automatically extracted the seed lexicon, performs well below the edit distance baseline."
  ],
  "y": "similarities uses"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_0",
  "x": [
   "Using the sense-tagged corpus of 192,800 word occurrences reported in<cite> (Ng and Lee, 1996)</cite> , I examine the effect of the number of training examples on the accuracy of an exemplar-based classifier versus the base-line, most-frequent-sense classitier."
  ],
  "y": "uses"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_1",
  "x": [
   "In Section 3, I examine the size of the training corpus on the accuracy of WSD, using a corpus of 192,800 occurrences of 191 words hand tagged with WORDNET senses<cite> (Ng and Lee, 1996)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_2",
  "x": [
   "When the task is to resolve word senses to the fine-grain distinction of WORD-NET senses, the accuracy figures achieved are generally not very high (Miller et al., 1994; <cite>Ng and Lee, 1996)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_3",
  "x": [
   "When the task is to resolve word senses to the fine-grain distinction of WORD-NET senses, the accuracy figures achieved are generally not very high (Miller et al., 1994; <cite>Ng and Lee, 1996)</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_4",
  "x": [
   "This is in contrast to disambiguating word senses to the refined senses of WoRDNET, where for instance, the average number of senses per noun is 7.8 and the average number of senses per verb is 12.0 for the set of 191 most ambiguous words investigated in<cite> (Ng and Lee, 1996)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_5",
  "x": [
   "This is in contrast to disambiguating word senses to the refined senses of WoRDNET, where for instance, the average number of senses per noun is 7.8 and the average number of senses per verb is 12.0 for the set of 191 most ambiguous words investigated in<cite> (Ng and Lee, 1996)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_6",
  "x": [
   "To overcome this data sparseness problem of WSD, I initiated a mini-project in sense tagging and collected a corpus in which 192,800 occurrences of 191 words have been manually tagged with senses of WORDNET<cite> (Ng and Lee, 1996)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_7",
  "x": [
   "To investigate the effect of the number of training examples on WSD accuracy, I ran the exemplarbased WSD algorithm L~.XAS on varying number of training examples to obtain learning curves for the 191 words (details of LEXAS are described in<cite> (Ng and Lee, 1996)</cite> )."
  ],
  "y": "uses"
 },
 {
  "id": "eeada4aedbb43b575365a15d75f2ac_8",
  "x": [
   "The performance figures of LEXAS in Table 1 are higher than those reported in<cite> (Ng and Lee, 1996)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_0",
  "x": [
   "Predicting mental health from smartphone and social media data on a longitudinal basis has recently attracted great interest, with very promising results being reported across many studies [3, 9, 13,<cite> 26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_1",
  "x": [
   "The widespread use of smart-phones and social media offers new ways of assessing mental well-being, and recent research [1, 2, 3, 5, 9, 10, 13, 14, 22, 23,<cite> 26]</cite> has started exploring the effectiveness of these modalities for automatically assessing"
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_2",
  "x": [
   "In order to overcome these issues, previous work [2, 5, 9, 10, 22,<cite> 26]</cite> has combined the instances {X uj i , y uj i } from different individuals u j and performed evaluation using randomised cross validation (MIXED)."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_3",
  "x": [
   "Research in assessing mental health on a longitudinal basis aims to make use of relevant features extracted from various modalities, in order to train models for automatically predicting a user's mental state (target), either in a classification or a regression manner [1, 2, 3, 9, 10, 13,<cite> 26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_4",
  "x": [
   "Most approaches have used the \"MIXED\" approach to evaluate models [1, 2, 5, 9, 10, 22,<cite> 26]</cite> , which, as we will show, is vulnerable to bias, due to the danger of recognising the user in the test set and thus simply inferring her average mood score."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_5",
  "x": [
   "P3 Predicting users instead of mood scores: Most approaches merge all the instances from different subjects, in an attempt to build user-agnostic models in a randomised cross-validation framework [2, 9, 10,<cite> 26]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_6",
  "x": [
   "In order to examine this effect in both a regression and a classification setting, we have followed the experimental framework by Tsakalidis et al. <cite>[26]</cite> and Jaques et al. [9] ."
  ],
  "y": "uses"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_7",
  "x": [
   "Tsakalidis et al. <cite>[26]</cite> monitored the behaviour of 19 individuals over four months."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_8",
  "x": [
   "Since different users exhibit different mood scores on average <cite>[26]</cite> , by selecting instances from the top and bottom scores, one might end up separating users and convert the mood prediction task into a user identification one."
  ],
  "y": "background"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_10",
  "x": [
   "We employed the dataset obtained by Tsakalidis et al. <cite>[26]</cite> , a pioneering dataset which contains a mix of longitudinal textual and mobile phone usage data for 30 subjects."
  ],
  "y": "uses"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_11",
  "x": [
   "In Experiment 1 we follow the setup in <cite>[26]</cite> : we perform 5-fold CV (MIXED) using SVM (SVR RBF ) and evaluate performance based on R 2 and RM SE."
  ],
  "y": "uses"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_13",
  "x": [
   "Experiment 1: Table 7 shows the results based on the evaluation setup of Tsakalidis et al. <cite>[26]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_14",
  "x": [
   "In the MIXED cases, the pattern is consistent with <cite>[26]</cite> , indicating that normalising the features on a per-user basis yields better results, when dealing with sparse textual features (positive, negative, wellbeing targets)."
  ],
  "y": "similarities"
 },
 {
  "id": "ef6f1050651a4c3ac9a53438ac1f87_15",
  "x": [
   "P3: Results following the evaluation setup in <cite>[26]</cite> (MIXED), along with the results obtained in the LOIOCV and LOUOCV settings with (+) and without (-) per-user input normalisation."
  ],
  "y": "uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_0",
  "x": [
   "We explore blindfold (question-only) baselines for <cite>Embodied Question Answering</cite>.",
   "The <cite>EmbodiedQA</cite> task requires an agent to answer a question by intelligently navigating in a simulated environment, gathering necessary visual information only through first-person vision before finally answering."
  ],
  "y": "motivation background"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_1",
  "x": [
   "To foster and measure progress in such virtual environments, new tasks have been introduced, one of them being <cite>Embodied Question Answering</cite> (<cite>EmbodiedQA</cite>) <cite>[5]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_2",
  "x": [
   "The <cite>EmbodiedQA</cite> task requires an agent to intelligently navigate in a simulated household environment [25] and answer questions through egocentric vision."
  ],
  "y": "background"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_3",
  "x": [
   "Subsequent to the introduction of the task, several methods have been introduced to solve the <cite>EmbodiedQA</cite> task <cite>[5</cite>, 6] , using some combination of reinforcement learning, behavior cloning and hierarchical control."
  ],
  "y": "background"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_4",
  "x": [
   "Subsequent to the introduction of the task, several methods have been introduced to solve the <cite>EmbodiedQA</cite> task <cite>[5</cite>, 6] , using some combination of reinforcement learning, behavior cloning and hierarchical control."
  ],
  "y": "motivation"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_5",
  "x": [
   "To our surprise, blindfold baselines achieve state-of-the-art performance on the <cite>EmbodiedQA</cite> task, except in the case when the agent is spawned extremely close to the object."
  ],
  "y": "uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_6",
  "x": [],
  "y": "uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_8",
  "x": [
   "<cite>EmbodiedQA</cite> Methods: Das et al. <cite>[5]</cite> introduced the <cite>PACMAN-RL+Q</cite> model which is bootstrapped with expert shortest-path demonstrations and later fine-tuned with REINFORCE [24] ."
  ],
  "y": "background"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_9",
  "x": [
   "To get rid of peaky answers, an entropy pruning method was applied by <cite>[5]</cite> where questions with normalized entropy below 0.5 were excluded.",
   "We also train the <cite>[5]</cite> text embedding model (an LSTM) with the optimization settings described in <cite>[5]</cite> for 200 epochs."
  ],
  "y": "differences"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_10",
  "x": [
   "We also train the <cite>[5]</cite> text embedding model (an LSTM) with the optimization settings described in <cite>[5]</cite> for 200 epochs."
  ],
  "y": "similarities"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_11",
  "x": [
   "The Nearest Neighbour method also does pretty well, and only falls behind to <cite>PACMAN</cite> (BC+REINFORCE) and NMC(BC+A3C) in the T 10 case."
  ],
  "y": "differences"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_12",
  "x": [
   "For completeness, we also include a question only baseline derived directly from the <cite>EmbodiedQA</cite> codebase, which uses only the Question LSTM in the <cite>PACMAN</cite> model, termed as <cite>PACMAN</cite> Q-only (LSTM)."
  ],
  "y": "uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_13",
  "x": [
   "As noted earlier, this means that models don't need to generalize across unseen combinations of rooms/objects/colors to perform well on this task (b) Despite entropy-pruning, there is a noticeable bias in the answer distribution of EQAv1 questions (see [<cite>5</cite>, Appendix A])."
  ],
  "y": "similarities"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_14",
  "x": [
   "Viewing these results holistically, we conclude that current methods for the <cite>EmbodiedQA</cite> task are not effective at using context from the environment, and in fact this negatively hampers them."
  ],
  "y": "motivation uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_16",
  "x": [
   "As noted in <cite>[5]</cite> , we re-iterate that these oracles are far from perfect, as they may not contain the best vantage or context to answer the question."
  ],
  "y": "similarities"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_17",
  "x": [
   "T 20 T 50 T any Navigation + VQA <cite>PACMAN</cite> (BC) <cite>[5]</cite> 48 BOW-CNN VQA-Only 56.5 Table 1 : We compare to the published results from [6] for agent spawned at various steps away from the target: 10, 30, 50, and anywhere in the environment."
  ],
  "y": "differences uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_18",
  "x": [
   "(*) indicates our reproduction of the model described in <cite>[5]</cite> Error Analysis: To better understand the shortcomings and limitations, we perform an error analysis of the one of the runs of the BoW model on different question types: Here, the color category Preposition Location Color 9.09 51.72 53.31 Table 2 : Accuracy of the BoW model on different question types subsumes color and color_room both."
  ],
  "y": "uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_19",
  "x": [
   "We show that simple question only baselines largely outperform or closely compete with existing methods on the <cite>EmbodiedQA</cite> task."
  ],
  "y": "uses"
 },
 {
  "id": "f1e5584a2139160943d9f0338e6ce0_20",
  "x": [
   "Besides providing a benchmark score for future researchers working on this task, our results suggest considerations for future dataset and task construction in <cite>EQA</cite> and related tasks."
  ],
  "y": "future_work"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_0",
  "x": [
   "We report experimental results for two answer selection datasets: (1) InsuranceQA<cite> (Feng et al., 2015)</cite> 1 , a recently released large-scale non-factoid QA dataset from the insurance domain."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_1",
  "x": [
   "The approaches for non-factoid question answering generally pursue the solution on the following directions: Firstly, the question and answer representations are learned and matched by certain similarity metrics<cite> (Feng et al., 2015</cite>; Yu et al., 2014; dos Santos et al., 2015) ."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_2",
  "x": [
   "There are two major differences between our approaches and the work in<cite> (Feng et al., 2015)</cite> : (1) The architectures developed in<cite> (Feng et al., 2015)</cite> are only based on CNN, whereas our models are based on bidirectional LSTMs, which are more capable of exploiting long-range sequential context information.",
   "(2)<cite> Feng et al. (2015)</cite> tackle the question and answer independently, while the proposed structures develop an efficient attentive models to generate answer embeddings according to the question."
  ],
  "y": "differences"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_3",
  "x": [
   "Following the same ranking loss in<cite> (Feng et al., 2015</cite>; Weston et al., 2014; Hu et al., 2014) , we define the training objective as a hinge loss."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_4",
  "x": [
   "As discussed in<cite> (Feng et al., 2015)</cite> , this is reasonable, because for a shared layer network, the corresponding elements in question and answer vectors represent the same biLSTM outputs."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_5",
  "x": [
   "The structure of CNN in this work is similar to the one in<cite> (Feng et al., 2015)</cite> , as shown in Figure 2 ."
  ],
  "y": "similarities"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_6",
  "x": [
   "Having described a number of models in the previous section, we evaluate the proposed approaches on the insurance domain dataset, InsuranceQA, provided by<cite> Feng et al. (2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_7",
  "x": [
   "One can see the details of InsuranceQA data in<cite> (Feng et al., 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_8",
  "x": [
   "Architecture-II in<cite> (Feng et al., 2015)</cite> : Instead of using LSTM, a CNN model is employed to learn a distributed vector representation of a given question and its answer candidates, and the answers are scored by cosine similarity with the question."
  ],
  "y": "background"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_9",
  "x": [
   "This is the model which achieved the best performance in<cite> (Feng et al., 2015)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_10",
  "x": [
   "Row F shared a highly analogous CNN structure with Architecture II in<cite> (Feng et al., 2015)</cite> , except that the later used a shallow hidden layer to transform the word embeddings into the input of CNN structure, while Row F take the output of biLSTM as CNN input."
  ],
  "y": "differences similarities"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_11",
  "x": [
   "Compared to Architecture II in<cite> (Feng et al., 2015)</cite> , which involved a large number of CNN filters, (H) model also has fewer parameters."
  ],
  "y": "differences"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_12",
  "x": [
   "We implemented the Architecture II in<cite> (Feng et al., 2015)</cite> from scratch."
  ],
  "y": "uses"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_13",
  "x": [
   "Wang & Nyberg (2015) and<cite> Feng et al. (2015)</cite> are the best baselines on MAP and MRR respectively."
  ],
  "y": "background"
 },
 {
  "id": "f24dde456e02fdb8e65799685275d2_14",
  "x": [
   "Model (D), which combines the ideas of Model (B) and (C), achieves the performance, competitive to the best baselines on MAP, and 2\u223c4% improvement on MRR compared to (Wang & Nyberg, 2015) and<cite> (Feng et al., 2015)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_0",
  "x": [
   "In this paper, we train a readability classification model using a corpus compiled from textbooks and features inherited from our previous works Islam et al. (2012; and features from<cite> Sinha et al. (2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_1",
  "x": [
   "We have inherited features from Islam et al. (2012; and<cite> Sinha et al. (2012)</cite> , these features achieve reasonable classification accuracy."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_2",
  "x": [
   "Recently,<cite> Sinha et al. (2012)</cite> proposed few computational models that are similar to the traditional English readability formulas."
  ],
  "y": "background"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_3",
  "x": [
   "Recently,<cite> Sinha et al. (2012)</cite> proposed few computational models that are similar to the traditional English readability formulas."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_4",
  "x": [
   "Table 3 : Performance of Bangla readability models proposed by<cite> Sinha et al. (Sinha et al., 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_5",
  "x": [
   "In order to find the best performing training model, we use 20 features from Islam et al. (2012; and<cite> Sinha et al. (2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_6",
  "x": [
   "The traditional readability formulas that were proposed for English texts do not work for Bangla texts (Islam et al., 2012; Islam et al., 2014;<cite> Sinha et al., 2012)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_7",
  "x": [
   "At first we build a classifier using two readability models from <cite>Sinha et al(2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_8",
  "x": [
   "The classification F-Score rises to 87.87 when we combine features from Islam et al. (2014) and<cite> Sinha et al. (Sinha et al., 2012)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f29baa099b13f38badeb4cbd8789f6_9",
  "x": [
   "This study also validate that features in our previous study Islam et al. (2014) and features proposed by<cite> Sinha et al. (Sinha et al., 2012)</cite> are useful for Bangla text readability analysis."
  ],
  "y": "similarities"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_0",
  "x": [
   "This paper reports the performances of shallow word-level convolutional neural networks (CNN), our earlier work (2015) [3,<cite> 4]</cite> , on the eight datasets with relatively large training data that were used for testing the very deep characterlevel CNN in Conneau et al. (2016) [1]."
  ],
  "y": "background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_1",
  "x": [
   "Recently, several variations of convolutional neural networks (CNNs) [7] have been shown to achieve high accuracy on text categorization (see e.g., [3, <cite>4,</cite> 9, 1] and references therein) in comparison with a number of methods including linear methods, which had long been the state of the art."
  ],
  "y": "background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_2",
  "x": [
   "\u2022 Our earlier work (2015) [3,<cite> 4]</cite> : shallow word-level CNNs (taking sequences of words as input), which we abbreviate as word-CNN."
  ],
  "y": "motivation background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_3",
  "x": [
   "In [3,<cite> 4]</cite> the shallow word-CNN was shown to perform well, using training sets (most intensively, 25K documents) that are mostly smaller than those used in [1] ."
  ],
  "y": "background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_4",
  "x": [
   "While these results imply that the shallow word-CNN is likely to outperform the deep char-CNN when trained with relatively small training sets such as those used in [3,<cite> 4]</cite> , the shallow word-CNN is untested on the training sets as large as those used in [1] ."
  ],
  "y": "background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_5",
  "x": [
   "Hence, the purpose of this report is to fill the gap by testing the shallow word-CNNs as in [3,<cite> 4]</cite> on the datasets used in [1] , for direct comparison with the results of very deep char-CNNs reported in [1] ."
  ],
  "y": "motivation"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_6",
  "x": [
   "Limitation of work In this work, our new experiments are limited to the shallow word-CNN as in [3,<cite> 4]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_7",
  "x": [
   "We start with briefly reviewing the very deep word-CNN of [1] and the shallow word-CNN of [3,<cite> 4]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_8",
  "x": [
   "**SHALLOW WORD-LEVEL CNNS AS IN [3,<cite> 4]</cite>**",
   "Two types of word-CNN were proposed in [3,<cite> 4]</cite> , which are illustrated in Figure 1 ."
  ],
  "y": "background"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_9",
  "x": [
   "See also the supplementary material of<cite> [4]</cite> for the representation power analysis."
  ],
  "y": "uses"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_10",
  "x": [
   "In<cite> [4]</cite> , tv-embedding training was done using unlabeled data as an additional resource; therefore, the proposed models were semi-supervised models."
  ],
  "y": "differences"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_11",
  "x": [
   "Tv-embedding training was done as in<cite> [4]</cite> ; weighted square loss was minimized without regularization while the target regions (adjacent regions) were represented by bow vectors, and the data weights were set so that the negative sampling effect was achieved."
  ],
  "y": "uses"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_12",
  "x": [
   "We observe that, as in our previous work<cite> [4]</cite> , additional input produced by tv-embeddings led to substantial improvements."
  ],
  "y": "similarities"
 },
 {
  "id": "f2b9a5633600cdf787111841bf9ce6_13",
  "x": [
   "\u2022 The shallow word-CNNs as in [3,<cite> 4]</cite> generally achieved better error rates than those of the very deep char-CNNs reported in [1] ."
  ],
  "y": "similarities"
 },
 {
  "id": "f2dfc35b67e47c12cba3cd0ec743a5_0",
  "x": [
   "Although such networks have proved useful in some semantical-dependent tasks (see e.g. a topological approach to word sense disambiguation in [<cite>17</cite>] ), I believe that the creation of novel semantic-based measurements would improve the state of the art."
  ],
  "y": "background"
 },
 {
  "id": "f2dfc35b67e47c12cba3cd0ec743a5_1",
  "x": [
   "Although such networks have proved useful in some semantical-dependent tasks (see e.g. a topological approach to word sense disambiguation in [<cite>17</cite>] ), I believe that the creation of novel semantic-based measurements would improve the state of the art."
  ],
  "y": "background"
 },
 {
  "id": "f326a3e2a5e349ce84b0a759f8e0b2_0",
  "x": [
   "This approach is well suited for non-interactive, static contexts, but recently, there has been increased interest in generation for situated dialog<cite> (Stoia, 2007</cite>; ."
  ],
  "y": "background"
 },
 {
  "id": "f326a3e2a5e349ce84b0a759f8e0b2_1",
  "x": [
   "<cite>Stoia (2007)</cite> studies instruction giving in a virtual environment and finds that references to target objects are often not made when they first become visible."
  ],
  "y": "background"
 },
 {
  "id": "f326a3e2a5e349ce84b0a759f8e0b2_2",
  "x": [
   "<cite>Stoia (2007)</cite> observed that IGs use move instructions to focus the IF's attention on a particular area."
  ],
  "y": "background"
 },
 {
  "id": "f326a3e2a5e349ce84b0a759f8e0b2_3",
  "x": [
   "<cite>Stoia (2007)</cite> observed that IGs use move instructions to focus the IF's attention on a particular area."
  ],
  "y": "similarities"
 },
 {
  "id": "f326a3e2a5e349ce84b0a759f8e0b2_4",
  "x": [
   "<cite>Stoia (2007)</cite> as well as have addressed this question, but their approaches only make a choice between generating an instruction to move or a uniquely identifying referring expression."
  ],
  "y": "differences"
 },
 {
  "id": "f326a3e2a5e349ce84b0a759f8e0b2_5",
  "x": [
   "We are planning on building on the work by <cite>Stoia (2007)</cite> on using machine learning techniques to develop a model that takes into account various contextual factors and on the work by Thompson (2009) on generating references in installments."
  ],
  "y": "future_work"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_0",
  "x": [
   "With many recent results [9, 10, 11, 12, <cite>13]</cite> approaching the stateof-the-art, end-to-end deep learning has definitely been a very important direction for speech recognition."
  ],
  "y": "background"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_1",
  "x": [
   "One approach is to utilize unpaired text data to produce a separately trained language model (LM) to rescore the output of the end-to-end approach [18,<cite> 13,</cite> 19, 20] , but at the price of extra computation during testing."
  ],
  "y": "background"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_2",
  "x": [
   "But other network architectures such as RNN-LM<cite> [13]</cite> can also be used here."
  ],
  "y": "background"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_3",
  "x": [
   "Any network architecture for end-toend speech recognition can be used here, while Fig. 3 gives the one used in this work, following the previous work<cite> [13]</cite> of integrating attentioned Seq2seq with CTC."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_4",
  "x": [
   "During testing,\u1ef9 andy are integrated into a single output sequence just as done in the previous work<cite> [13]</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_5",
  "x": [
   "We followed the previous work<cite> [13,</cite> 21] to use 80-dimensional log Mel-filter bank and 3-dimensional pitch features as the acoustic features."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_6",
  "x": [
   "For the ASR model, the encoder included a 6layer VGG extractor with downsampling used in the previous work<cite> [13]</cite> and a 5-layer BLSTM with 320 units per direction."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_7",
  "x": [
   "Speech recognition performance. \"+LM\" refers to shallow fusion decoding jointly with RNN-LM<cite> [13]</cite> , \"+AT\" refers to the adversarial training proposed here, \"+Both\" indicates training with AT and joint decoding with RNN-LM, and BT is the prior work of back-translation [21] ."
  ],
  "y": "background"
 },
 {
  "id": "f32bbd580d93f77ef764c5341b93db_8",
  "x": [
   "The results are listed in Table 1 , where \"Baseline\" refers to the plain end-toend speech recognition framework as described in Sec. 2.3, \"+LM\" refers to the shallow fusion decoding with a separately trained RNN language model (RNN-LM)<cite> [13,</cite> 20] and \"+AT\" refers to the adversarial training proposed here."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_0",
  "x": [
   "This field is referred to as \"data-to-text\" [8] and has its place in several application domains (such as journalism [22] or medical diagnosis [25] ) or wide-audience applications (such as financial [26] and weather reports [30] , or sport broadcasting [4, <cite>39]</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_1",
  "x": [
   "Recent datato-text models [18, 28, 29, <cite>39]</cite> mostly rely on an encoder-decoder architecture [2] in which the data-structure is first encoded sequentially into a fixed-size vectorial representation by an encoder."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_2",
  "x": [
   "Our contribution focuses on the encoding of the data-structure, thus the decoder is chosen to be a classical module as used in [28, <cite>39]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_3",
  "x": [
   "We report experiments on the RotoWire benchmark<cite> [39]</cite> which contains around 5K statistical tables of NBA basketball games paired with humanwritten descriptions."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_4",
  "x": [
   "This task stems from the neural machine translation (NMT) domain, and early work [1, 15, <cite>39]</cite> represent the data records as a single sequence of facts to be entirely translated into natural language."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_5",
  "x": [
   "Wiseman et al.<cite> [39]</cite> show the limits of traditional NMT systems on larger structured-data, where NMT systems fail to accurately extract salient elements."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_6",
  "x": [
   "First, instead of flatly concatenating elements from the data-structure and encoding them as a sequence [18, 28, <cite>39]</cite> , we constrain the encoding to the underlying structure of the input data, so that the delimitation between entities remains clear throughout the process."
  ],
  "y": "differences"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_7",
  "x": [
   "This equation is intractable in practice, we approximate a solution using beam search, as in [18, 17, 28, 29, <cite>39]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_8",
  "x": [
   "Because our contribution focuses on the encoding process, we chose the decoding module used in [28, <cite>39]</cite> : a two-layers LSTM network with a copy mechanism."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_9",
  "x": [
   "As outlined in Section 2, most previous work [16, 28, 29,<cite> 39,</cite> 40 ] make use of flat encoders that do not exploit the data structure."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_10",
  "x": [
   "In the low-level encoder, the traditional embedding layer is replaced by a record embedding layer as in [18, 28, <cite>39]</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_11",
  "x": [
   "As in previous work [18, 28, <cite>39]</cite> , each record embedding r i,j is computed by a linear projection on the concatenation [k i,j ; v i,j ] followed by a non linearity:"
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_12",
  "x": [
   "To evaluate the effectiveness of our model, and demonstrate its flexibility at handling heavy data-structure made of several types of entities, we used the Ro-toWire dataset<cite> [39]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_13",
  "x": [
   "The second category designed by<cite> [39]</cite> is more qualitative."
  ],
  "y": "background uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_14",
  "x": [
   "To do so, we follow the protocol presented in<cite> [39]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_15",
  "x": [
   "\u2022 Wiseman<cite> [39]</cite> is a standard encoder-decoder system with copy mechanism."
  ],
  "y": "background"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_16",
  "x": [
   "\u2022 Wiseman<cite> [39]</cite> is a standard encoder-decoder system with copy mechanism."
  ],
  "y": "background uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_17",
  "x": [
   "The decoder is the one used in [28, 29, <cite>39]</cite> with the same hyper-parameters."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_18",
  "x": [
   "To fit with the small number of record keys in our dataset<cite> (39)</cite> , their embedding size is fixed to 20."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_19",
  "x": [
   "Results are compared to baselines [28, 29, <cite>39]</cite> and variants of our models."
  ],
  "y": "uses"
 },
 {
  "id": "f34768f61dd3d95648ad9a70e83d2c_20",
  "x": [
   "Please note that, as in previous work [16, 28, 29, <cite>39]</cite> , generated texts still contain a number of incorrect facts, as well hallucinations (in blue): sentences that have no basis in the input data (e.g. \"[...] he's now averaging 22 points [...].\")."
  ],
  "y": "background"
 },
 {
  "id": "f36b605a9088532e5f430c86ffb363_0",
  "x": [
   "Vector space models, representing word meanings as points in high-dimensional space, have been used in a variety of semantic relatedness tasks (Sahlgren, 2006; <cite>Pad\u00f3 and Lapata, 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f36b605a9088532e5f430c86ffb363_1",
  "x": [
   "Vector space models, representing word meanings as points in high-dimensional space, have been used in a variety of semantic relatedness tasks (Sahlgren, 2006; <cite>Pad\u00f3 and Lapata, 2007)</cite> ."
  ],
  "y": "uses background"
 },
 {
  "id": "f36b605a9088532e5f430c86ffb363_2",
  "x": [
   "2 Following<cite> Pad\u00f3 and Lapata (2007)</cite> , we only consider co-occurrences where two target words are connected by certain dependency paths, namely: the top 30 most frequent preposition-mediated noun-to-noun paths (soldier+with+gun), the top 50 transitive-verbmediated noun-to-noun paths (soldier+use+gun), the top 30 direct or preposition-mediated verbnoun paths (kill+obj+victim, kill+in+school), and the modifying and predicative adjective-to-noun paths."
  ],
  "y": "uses"
 },
 {
  "id": "f36b605a9088532e5f430c86ffb363_3",
  "x": [
   "Following previous simulations of this data-set<cite> (Pad\u00f3 and Lapata, 2007)</cite> , we measure the similarity of each related target-prime pair, and we compare it to the average similarity of the target to all the other primes instantiating the same relation, treating the latter quantity as our surrogate of an unrelated target-prime pair."
  ],
  "y": "uses"
 },
 {
  "id": "f3b1a39203ebf0725d8dd2b8f8c7a9_0",
  "x": [
   "However, the output generated can be repetitive and generic leading to monotonous or uninteresting responses (e.g \"I don't know\") regardless of the input <cite>[2]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f3b1a39203ebf0725d8dd2b8f8c7a9_1",
  "x": [
   "Previous work on handling the shortcomings of MLE include length-normalizing sentence probability [6] , future cost estimation [7] , diversity-boosting objective function [8,<cite> 2]</cite> or penalizing repeating tokens [9] ."
  ],
  "y": "background"
 },
 {
  "id": "f3b1a39203ebf0725d8dd2b8f8c7a9_2",
  "x": [
   "Li et al. <cite>[2]</cite> use a discriminator for a diversity promoting objective."
  ],
  "y": "background"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_0",
  "x": [
   "In recent works, short phrases [11, 4] , images<cite> [3]</cite> or summaries [19] have been used as alternatives."
  ],
  "y": "background"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_1",
  "x": [
   "The task of labeling topics consists of two main components: (1) a candidate generation component where candidate labels are obtained for a given topic (usually using information retrieval techniques and knowledge bases [11, <cite>3]</cite> ), and (2) a ranking (or label selection) component that scores the candidates according to their relevance to the topic."
  ],
  "y": "background"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_2",
  "x": [
   "The method presented by<cite> [3]</cite> generates a graph where the candidate images are its nodes."
  ],
  "y": "background"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_3",
  "x": [
   "That is the output of the publicly available 16-layer VGG-net [1<cite>3]</cite> trained over the ImageNet dataset [9] ."
  ],
  "y": "uses"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_4",
  "x": [
   "We evaluate our model on the publicly available data set provided by<cite> [3]</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_5",
  "x": [
   "The 20 candidate image labels per topic are collected by<cite> [3]</cite> using an information retrieval engine (Google)."
  ],
  "y": "uses"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_6",
  "x": [
   "Our evaluation follows prior work [11, <cite>3]</cite> using two metrics."
  ],
  "y": "uses"
 },
 {
  "id": "f3c2c538019b1d9daa8e6c932d9826_7",
  "x": [
   "We compare our approach to the state-of-the-art method that uses Personalized PageRank<cite> [3]</cite> to re-rank image candidates (Local PPR) and an adapted version that computes the PageRank scores of all the available images in the test set (Global PPR)."
  ],
  "y": "uses"
 },
 {
  "id": "f3e9e5d7fb4001e3d29a171b5eb4a4_1",
  "x": [
   "Similarly to<cite> Liang et al. (2016)</cite> , we employ a sequence-to-sequence model to learn query expressions and their compositions."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f3e9e5d7fb4001e3d29a171b5eb4a4_2",
  "x": [
   "Although query induction can save a considerable amount of supervision effort <cite>(Liang et al., 2016</cite>; Zhong et al., 2017) , a pseudo-gold program is not guaranteed to be correct when the same answer can be found with more than one query (e.g., as the capital is often the largest city of a country, predicates might be confused)."
  ],
  "y": "background"
 },
 {
  "id": "f3e9e5d7fb4001e3d29a171b5eb4a4_3",
  "x": [
   "A curriculum learning (Bengio et al., 2009 ) paradigm can learn graph pattern and SPARQL operator composition, in a similar fashion of<cite> Liang et al. (2016)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_0",
  "x": [
   "Most of the presented works study the interrelationship between words in a text snip- pet (Hill et al., 2016; Kiros et al., 2015; <cite>Le and Mikolov, 2014)</cite> in an unsupervised fashion."
  ],
  "y": "background"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_1",
  "x": [
   "This makes our work distinguished from to the work of<cite> (Le and Mikolov, 2014</cite>; Hill et al., 2016; Kiros et al., 2015) where they study the interrelationship of words in the text snippet."
  ],
  "y": "differences"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_2",
  "x": [
   "We show a toy example to highlight the differences between DoCoV vector, the Mean vector and paragraph vector<cite> (Le and Mikolov, 2014)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_3",
  "x": [
   "(1) Some neural-based paragraph representations such as paragraph vectors<cite> (Le and Mikolov, 2014)</cite> , FastSent (Hill et al., 2016) use a shared space between the words and paragraphs."
  ],
  "y": "background"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_4",
  "x": [
   "Figure 1 illustrates that point, we do not see a clear interpretation of why the paragraph vectors<cite> (Le and Mikolov, 2014)</cite> are positioned in the space as in figure 1 ."
  ],
  "y": "similarities"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_5",
  "x": [
   "This is an advantage compared to existing methods for generating paragraph vectors, such as<cite> (Le and Mikolov, 2014</cite>; Hill et al., 2016) ."
  ],
  "y": "differences"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_6",
  "x": [
   "Some efforts aimed at finding a global representation of a text snippet using a paragraph-level representation such as paragraph vectors<cite> (Le and Mikolov, 2014)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_7",
  "x": [
   "The competing methods are the paragraph vectors<cite> (Le and Mikolov, 2014)</cite> , skip-thought vectors (Kiros et al., 2015) , Fastsent (Hill et al., 2016) , Sequential (Denoising) Autoencoders (SDAE) (Hill et al., 2016) ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_8",
  "x": [
   "For other models like paragraph vectors<cite> (Le and Mikolov, 2014)</cite> and Fastsent vectors (Hill et al., 2016) , they require a gradient descent inference step to compute the paragraph/sentence vectors."
  ],
  "y": "background"
 },
 {
  "id": "f587fc2bbbf3c1327b03d556e4bc05_9",
  "x": [
   "We further observe that DoCoV is consistently better than the paragraph vectors<cite> (Le and Mikolov, 2014)</cite> , Fastsent and SDAE (Hill et al., 2016) ."
  ],
  "y": "differences"
 },
 {
  "id": "f5ad574acf9ea27c0be3129238fd92_0",
  "x": [
   "Recent work has shown that state-of-the-art neural models of language and translation can be successfully trained on multiple languages simultaneously without changing the model architecture (\u00d6stling and Tiedemann, 2017; <cite>Johnson et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f5ad574acf9ea27c0be3129238fd92_1",
  "x": [
   "The recent advances in neural networks have opened the way to the design of architecturally simple multilingual models for various NLP tasks, such as language modeling or next word prediction (Tsvetkov et al., 2016; \u00d6stling and Tiedemann, 2017; Malaviya et al., 2017; Tiedemann, 2018) , translation (Dong et al., 2015; Zoph et al., 2016; Firat et al., 2016; <cite>Johnson et al., 2017)</cite> , morphological reinflection (Kann et al., 2017) and more (Bjerva, 2017) ."
  ],
  "y": "background"
 },
 {
  "id": "f5ad574acf9ea27c0be3129238fd92_2",
  "x": [
   "We consider the scenario where L1 is overresourced compared to L2 and train our bilingual models by joint training on a mixed L1/L2 corpus so that supervision is provided simultaneously in the two languages (\u00d6stling and Tiedemann, 2017; <cite>Johnson et al., 2017)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f5bf9a833c3d46b00d70498e4f1c1b_1",
  "x": [
   "Applications of lp and mad are varied, including video recommendation [1] and sentiment analysis over Twitter<cite> [5]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_0",
  "x": [
   "In this work, we propose a semisupervised extension to a well-known supervised domain adaptation approach (EA) <cite>(Daum\u00e9 III, 2007)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_1",
  "x": [
   "A domain adaptation approach for sequential labeling tasks in NLP was proposed in <cite>(Daum\u00e9 III, 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_2",
  "x": [
   "However, the proposed techniques extend to non-linear hypotheses, as mentioned in <cite>(Daum\u00e9 III, 2007)</cite> ."
  ],
  "y": "differences extends"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_3",
  "x": [
   "In this section, we give a brief overview of EASYADAPT proposed in <cite>(Daum\u00e9 III, 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_4",
  "x": [
   "As mentioned earlier, this work considers linear hypotheses only and the the proposed techniques can be extended <cite>(Daum\u00e9 III, 2007)</cite> to non-linear hypotheses."
  ],
  "y": "differences extends"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_5",
  "x": [
   "A good intuitive insight into why this simple algorithm works so well in practice and outperforms most state-of-the-art algorithms is given in <cite>(Daum\u00e9 III, 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_6",
  "x": [
   "A kernelized version of the algorithm has also been presented in <cite>(Daum\u00e9 III, 2007)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_7",
  "x": [
   "We follow the same experimental setup used in <cite>(Daum\u00e9 III, 2007)</cite> and perform two sequence labelling tasks (a) named-entity-recognition (NER), and (b) part-of-speech-tagging (POS )on the following datasets:"
  ],
  "y": "similarities uses"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_8",
  "x": [
   "We also note that EA performs poorly for some cases, as was shown <cite>(Daum\u00e9 III, 2007)</cite> earlier."
  ],
  "y": "similarities"
 },
 {
  "id": "f5d1c0d3ac45ea4949f7d01d1704f6_9",
  "x": [
   "Feature sharing algorithms are effective for domain adaptation because they are simple, easy to implement as a preprocessing step and outperform many existing state-of-the-art techniques (shown previously for domain adaptation <cite>(Daum\u00e9 III, 2007)</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_0",
  "x": [
   "<cite>Xing et al. (2015)</cite> incorporate length normalization in the training of word embeddings and try to maximize the cosine similarity instead, introducing an orthogonality constraint to preserve the length normalization after the projection."
  ],
  "y": "background"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_1",
  "x": [
   "We start with a basic optimization objective (Mikolov et al., 2013b) and introduce several meaningful and intuitive constraints that are equivalent or closely related to previously proposed methods (Faruqui and Dyer, 2014; <cite>Xing et al., 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_2",
  "x": [
   "This last optimization objective coincides with <cite>Xing et al. (2015)</cite> , but <cite>their work</cite> was motivated by an hypothetical inconsistency in Mikolov et al. (2013b) , where the optimization objective to learn word embeddings uses dot product, the objective to learn mappings uses Euclidean distance and the similarity computations use cosine.",
   "However, the fact is that, as long as W is orthogonal, optimizing the squared Euclidean distance of length-normalized embeddings is equivalent to optimizing the cosine, and therefore, the mapping objective proposed by <cite>Xing et al. (2015)</cite> is equivalent to that used by Mikolov et al. (2013b) with orthogonality constraint and unit vectors.",
   "In fact, our experiments show that orthogonality is more relevant than length normalization, in contrast to <cite>Xing et al. (2015)</cite> , <cite>who introduce</cite> orthogonality only to ensure that unit length is preserved after mapping."
  ],
  "y": "differences"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_3",
  "x": [
   "The code for Mikolov et al. (2013b) and <cite>Xing et al. (2015)</cite> is not publicly available, so we implemented and tested them as part of the proposed framework, which only differs from the original systems in the optimization method (exact solution instead of gradient descent) and the length normalization approach in the case of <cite>Xing et al. (2015)</cite> (postprocessing instead of constrained training)."
  ],
  "y": "uses"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_4",
  "x": [
   "As discussed before, (Mikolov et al., 2013b) and <cite>(Xing et al., 2015)</cite> were implemented as part of our framework, so they correspond to our uncostrained mapping with no preprocessing and orthogonal mapping with length normalization, respectively."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_5",
  "x": [
   "As it can be seen, the method by <cite>Xing et al. (2015)</cite> performs better than that of Mikolov et al. (2013b) in the translation induction task, which is in line with what <cite>they report</cite> in their paper.",
   "Moreover, thanks to the orthogonality constraint <cite>their monolingual performance</cite> in the word analogy task does not degrade, whereas the accuracy of Mikolov et al. (2013b) drops by 2.86% in absolute terms with respect to the original embeddings."
  ],
  "y": "background"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_6",
  "x": [
   "Since Faruqui and Dyer (2014) Mikolov et al. (2013b) 34.93% 73. 80% <cite>Xing et al. (2015)</cite> 36.87% 76.66% Faruqui and Dyer (2014) CCA to perform dimensionality reduction, we tested several values for it and report the best (180 dimensions).",
   "This beats the method by <cite>Xing et al. (2015)</cite> in the bilingual task, although it comes at the price of a considerable degradation in monolingual quality."
  ],
  "y": "differences"
 },
 {
  "id": "f6694f359ae948b6e4563b927a672c_7",
  "x": [
   "Our experiments show the effectiveness of the proposed model and give strong empirical evidence in favor of our reinterpretation of <cite>Xing et al. (2015)</cite> and Faruqui and Dyer (2014) ."
  ],
  "y": "differences extends"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_0",
  "x": [
   "<cite>(Herbelot and Vecchi, 2015)</cite> explored word embeddings and their utility for modeling language semantics."
  ],
  "y": "background"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_1",
  "x": [
   "<cite>(Herbelot and Vecchi, 2015)</cite> investigated a method to map word embeddings to formal semantics, which is the center of interest of this paper."
  ],
  "y": "background uses"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_2",
  "x": [
   "In this section, we summarize the task presented in <cite>(Herbelot and Vecchi, 2015)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_3",
  "x": [
   "The goal of <cite>(Herbelot and Vecchi, 2015)</cite> is to analyze whether there exists a transformation from the word embedding of a concept to its model-theoretic vector, the gold standard being the human annotations."
  ],
  "y": "background"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_4",
  "x": [
   "The transformation used in <cite>(Herbelot and Vecchi, 2015)</cite> is based on Partial Least Squares Regression (PLSR)."
  ],
  "y": "background"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_5",
  "x": [
   "<cite>(Herbelot and Vecchi, 2015)</cite> 's system."
  ],
  "y": "uses"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_6",
  "x": [
   "We compare <cite>(Herbelot and Vecchi, 2015)</cite> 's model (<cite>PLSR + word2vec</cite>) against three baselines: random vectors, mode, and nearest neighbor."
  ],
  "y": "uses"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_7",
  "x": [
   "\u2022 Random vectors: <cite>(Herbelot and Vecchi, 2015)</cite> used pre-trained word embeddings as input to the PLSR, we instead simply use random vectors of same dimension (300, continuous uniform distribution between 0 and 1)."
  ],
  "y": "differences"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_8",
  "x": [
   "<cite>(Herbelot and Vecchi, 2015)</cite> ) in the last row."
  ],
  "y": "uses"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_9",
  "x": [
   "We could reproduce the results for the QMR dataset using PLSR and word2vec embeddings (0.346 in <cite>(Herbelot and Vecchi, 2015)</cite> vs. 0.332 in our experiments, but we could not ex-3 https://github.com/Franck-Dernoncourt/ model-theoretic actly reproduce the results for the AD dataset (0.634 in <cite>(Herbelot and Vecchi, 2015)</cite> vs. 0.572 in our experiments): this discrepancy most likely results from the choice of the training set."
  ],
  "y": "uses"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_10",
  "x": [
   "For each run, a train/test split was randomly chosen (60 training samples for AD, 400 for QMR, in order to have the same number of training samples as in <cite>(Herbelot and Vecchi, 2015)</cite> 's Table 2 )."
  ],
  "y": "similarities"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_11",
  "x": [
   "Our experiments' results are averaged over 1000 runs, and for each run the training/test split is randomly chosen, the only constraint being having the same number of training samples as in <cite>(Herbelot and Vecchi, 2015)</cite> ."
  ],
  "y": "similarities"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_12",
  "x": [
   "Furthermore, the mode baseline yields results that are good on the AD dataset (0.554, vs. 0.634 in <cite>(Herbelot and Vecchi, 2015)</cite> vs. 0.572 in our PLSR + word2vec implementation), and significantly better than all other models on the QMR dataset (0.522, vs. 0.346 in <cite>(Herbelot and Vecchi, 2015)</cite> , i.e. +51% improvement)."
  ],
  "y": "differences"
 },
 {
  "id": "f7e80cf0a6724675cab2825cbf7e10_13",
  "x": [
   "The mode baseline significantly outperforms <cite>(Herbelot and Vecchi, 2015)</cite> 's model on the QMR dataset, and yields competitive results on the AD dataset."
  ],
  "y": "differences"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_0",
  "x": [
   "A number of techniques have been investigated, including cosine similarity of feature vectors (Attali and Burstein, 2006) , often combined with dimensionality reduction techniques such as Latent Semantic Analysis (LSA) (Landauer et al., 2003) , and generative machine learning models (Rudner and Liang, 2002) as well as discriminative ones <cite>(Yannakoudakis et al., 2011)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_2",
  "x": [
   "Specifically, we describe a number of different experiments improving on the AA system presented in<cite> Yannakoudakis et al. (2011)</cite> ; AA is treated as a rank preference supervised learning problem and ranking Support Vector Machines (SVMs) (Joachims, 2002) are used to explicitly model the grade relationships between scripts."
  ],
  "y": "extends"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_4",
  "x": [
   "We use the First Certificate in English (FCE) ESOL examination scripts 2 (upper-intermediate level assessment) described in detail in<cite> Yannakoudakis et al. (2011)</cite> , extracted from the Cambridge Learner Corpus 3 (CLC)."
  ],
  "y": "uses"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_5",
  "x": [
   "Moreover, we identify the best model on year 2000 and we also test it on 97 texts from the examination year 2001, previously used in<cite> Yannakoudakis et al. (2011)</cite> to report the best published results."
  ],
  "y": "uses"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_7",
  "x": [
   "As in<cite> Yannakoudakis et al. (2011)</cite> , we analyze all texts using the RASP toolkit (Briscoe et al., 2006) 4 ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_8",
  "x": [
   "The AA system described in<cite> Yannakoudakis et al. (2011)</cite> exploited features based on POS tag sequences, but did not consider the distribution of POS types across grades."
  ],
  "y": "background"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_9",
  "x": [
   "Among the features used in<cite> Yannakoudakis et al. (2011)</cite> , none explicitly captures coherence and none models intersentential relationships."
  ],
  "y": "differences"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_10",
  "x": [
   "In particular, we use the system described in<cite> Yannakoudakis et al. (2011)</cite> as our baseline AA system."
  ],
  "y": "uses"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_11",
  "x": [
   "In the following experiments, we evaluate the best model identified on year 2000 on a set of 97 texts from the exam year 2001, previously used in<cite> Yannakoudakis et al. (2011)</cite> to report results of the final best system."
  ],
  "y": "uses"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_12",
  "x": [
   "Finally, we explore the utility of our best model for assessing the publically available 'outlier' texts used in<cite> Yannakoudakis et al. (2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_14",
  "x": [
   "A significant improvement over the AA system presented in<cite> Yannakoudakis et al. (2011)</cite> and the best published result on the FCE dataset was obtained by augmenting the system with an ISA-based local coherence feature."
  ],
  "y": "differences"
 },
 {
  "id": "f8c992a887a7b7af8b3aa45f72dca7_15",
  "x": [
   "Finally, we explore the utility of our best model for assessing the incoherent 'outlier' texts used in<cite> Yannakoudakis et al. (2011)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_0",
  "x": [
   "Unsupervised machine translation has become an emerging research interest in recent years (Artetxe et al., 2017; Artetxe et al., 2018b; Marie and Fujita, 2018; Ren et al., 2019;<cite> Lample and Conneau, 2019)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_1",
  "x": [
   "Previous approaches benefit mostly from crosslingual n-gram embeddings, but recent work proves that cross-lingual language model pretraining could be a more effective way to build initial unsupervised machine translation models <cite>(Lample and Conneau, 2019)</cite> ."
  ],
  "y": "motivation background"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_2",
  "x": [
   "Based on BERT,<cite> Lample and Conneau (2019)</cite> propose a cross-lingual version called XLM and reach the state-of-the-art performance on some crosslingual NLP tasks including cross-lingual classification , machine translation, and unsupervised cross-lingual word embedding."
  ],
  "y": "background"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_3",
  "x": [
   "Following Devlin et al. (2018) ;<cite> Lample and Conneau (2019)</cite> , in our CMLM objective, we randomly sample 15% of the BPE ngrams from the text streams, and replace them by [MASK] tokens 70% of the time."
  ],
  "y": "differences extends"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_4",
  "x": [
   "It seems that pre-training decoders has a smaller effect on the final performance than pre-training encoders <cite>(Lample and Conneau, 2019)</cite> , one reason for which could be that the encoder-to-decoder attention is not pre-trained."
  ],
  "y": "differences"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_5",
  "x": [
   "Our CMLM is optimized based on the pre-trained models released by<cite> Lample and Conneau (2019)</cite> 1 , which are trained with Wikipedia dumps."
  ],
  "y": "similarities uses"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_6",
  "x": [
   "The improvement made by<cite> Lample and Conneau (2019)</cite> compared with the first five baselines shows that cross-lingual pre-training can be necessary for unsupervised MT."
  ],
  "y": "future_work"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_7",
  "x": [
   "As a result, we can further improve the translation performance significantly, compared with<cite> Lample and Conneau (2019)</cite> (with the significance level of p<0.01)."
  ],
  "y": "future_work"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_8",
  "x": [
   "We compare the context-unaware method (i.e., directly calculating the similarity scores between unsupervised cross-lingual embeddings (Artetxe et al., 2018a ) of source and target words), XLM <cite>(Lample and Conneau, 2019)</cite> and our proposed CMLM pre-training method in the Table 3 ."
  ],
  "y": "similarities"
 },
 {
  "id": "fa5413db2c8e0a32bc3805d25cd0e7_10",
  "x": [
   "More recently,<cite> Lample and Conneau (2019)</cite> reach new state-of-the-art performance on unsupervised en-fr and en-de translation tasks."
  ],
  "y": "background"
 },
 {
  "id": "fa641aca676761c79c0469c195f336_0",
  "x": [
   "They observed that English readability formulas did not work well on Bengali texts <cite>[11]</cite> , [21] ."
  ],
  "y": "background"
 },
 {
  "id": "fa641aca676761c79c0469c195f336_1",
  "x": [
   "We found only three lines of work that specifically looked into Bengali readability [6] , <cite>[11]</cite> , [21] ."
  ],
  "y": "background"
 },
 {
  "id": "fa641aca676761c79c0469c195f336_2",
  "x": [
   "Around the same time, Islam et al. independently reached the same conclusion <cite>[11]</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "fa641aca676761c79c0469c195f336_3",
  "x": [
   "We found only three lines of work that specifically looked into Bengali readability [6] , <cite>[11]</cite> , [21] .",
   "Around the same time, Islam et al. independently reached the same conclusion <cite>[11]</cite> ."
  ],
  "y": "motivation"
 },
 {
  "id": "fa641aca676761c79c0469c195f336_4",
  "x": [
   "We only have 30 annotated passages at our disposal, whereas Islam et al. <cite>[11]</cite> had around 300. But Islam et al.'s dataset is not annotated in as fine-grained a fashion as ours."
  ],
  "y": "differences"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_0",
  "x": [
   "Waseem and Hovy (2016) only consider \"hate speech\" without regard to any potential overlap with bullying or otherwise offensive language, while <cite>Davidson et al. (2017)</cite> distinguish hate speech from generally offensive language."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_1",
  "x": [
   "The lack of consensus has resulted in contradictory annotation guidelines -some messages considered as hate speech by Waseem and Hovy (2016) are only considered derogatory and offensive by Nobata et al. (2016) and <cite>Davidson et al. (2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_2",
  "x": [
   "Much of the work on abusive language subtasks can be synthesized in a two-fold typology that conExplicit Implicit Directed \"Go kill yourself\", \"You're a sad little f*ck\" (Van Hee et al., 2015a) , \"@User shut yo beaner ass up sp*c and hop your f*ggot ass back across the border little n*gga\"<cite> (Davidson et al., 2017)</cite> , \"Youre one of the ugliest b*tches Ive ever fucking seen\" (Kontostathis et al., 2013) ."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_3",
  "x": [
   "Previous work has identified instances of hate speech that are both directed and generalized (Burnap and Williams, 2015; Waseem and Hovy, 2016;<cite> Davidson et al., 2017)</cite> , although Nobata et al. (2016) come closest to making a distinction between directed and generalized hate."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_4",
  "x": [
   "Previous research has indicated a great deal of variation within such language (Warner and Hirschberg, 2012;<cite> Davidson et al., 2017)</cite> , with abusive terms being used in a colloquial manner or by people who are victims of abuse."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_5",
  "x": [
   "Furthermore, while some argue that detailed guidelines can help annotators to make more subtle distinctions<cite> (Davidson et al., 2017)</cite> , others find that they do not improve the reliability of non-expert classifications (Ross et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_6",
  "x": [
   "<cite>Davidson et al. (2017)</cite> , for instance, show that annotators tend to code racism as hate speech at a higher rate than sexism."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_7",
  "x": [
   "A number of studies on hate speech use part-of-speech sequences to model the expression of hatred (Warner and Hirschberg, 2012; Gitari et al., 2015;<cite> Davidson et al., 2017)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "faeac0a0e3c0cad79d39dea04ec59a_8",
  "x": [
   "Hence, dictionary-based approaches may be well suited to identify this type of abuse (Warner and Hirschberg, 2012; Nobata et al., 2016) , although the presence of particular words should not be the only criteria, even terms that denote abuse may be used in a variety of different ways (Kwok and Wang, 2013;<cite> Davidson et al., 2017)</cite> ."
  ],
  "y": "future_work"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_0",
  "x": [
   "Recent work by <cite>(Jiang et al., 2018</cite>; Mayfield et al., 2012) adopt deep learning approaches to compute message pair similarity, using a combination of message content and simple contextual features (e.g., authorship and timestamps)."
  ],
  "y": "background"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_1",
  "x": [
   "The contribution of this work is two-fold: 1) We propose context-aware deep learning models for thread detection and it advances the state-ofthe-art; 2) Based on the dataset in<cite> (Jiang et al., 2018)</cite> , we develop and release a more realistic multi-party multi-thread conversation dataset for future research."
  ],
  "y": "uses"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_2",
  "x": [
   "These two features are also used in<cite> (Jiang et al., 2018)</cite> , and another baseline model GTM uses only these features (Elsner and Charniak, 2008) ."
  ],
  "y": "similarities"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_3",
  "x": [
   "Training Procedure: Following<cite> (Jiang et al., 2018)</cite> , apart from a new thread, we consider the candidate threads (Active Threads) in Eq. 1 only from those appearing in one hour time-frame before m i ."
  ],
  "y": "differences extends"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_4",
  "x": [
   "We strictly follow<cite> (Jiang et al., 2018)</cite> to construct our data."
  ],
  "y": "similarities uses"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_5",
  "x": [
   "Reddit Dataset Improvement: We use the same pre-processing method in<cite> (Jiang et al., 2018)</cite> : we discard the messages which have less than 10 words or more than 100 words."
  ],
  "y": "similarities uses"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_6",
  "x": [
   "Baseline: (1) CISIR-SHCNN<cite> (Jiang et al., 2018)</cite> : A recently proposed model based on CNN and ranking message pairs."
  ],
  "y": "background"
 },
 {
  "id": "fb1061d28dbf80858c1a630621a975_7",
  "x": [
   "833 .431 .433 Evaluation Metrics: Normalized mutual information (NMI), Adjusted rand index (ARI) and F1 score, following<cite> (Jiang et al., 2018)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "fc58a9813b80afc9811b8ee27679b7_0",
  "x": [
   "Current approaches for learning such patterns include bootstrapping techniques<cite> (Huang and Riloff, 2012a</cite>; Yangarber et al., 2000) , weakly supervised learning algorithms (Huang and Riloff, 2011; Sudo et al., 2003; Surdeanu et al., 2006) , fully supervised learning approaches (Chieu et al., 2003; Freitag, 1998; Bunescu and Mooney, 2004; Patwardhan and Riloff, 2009 ) and other variations."
  ],
  "y": "background"
 },
 {
  "id": "fc58a9813b80afc9811b8ee27679b7_1",
  "x": [
   "An important step forwards is TIER light<cite> (Huang and Riloff, 2012a</cite> ) that targeted the minimization of human supervision with a bootstrapping technique for event roles detection."
  ],
  "y": "background"
 },
 {
  "id": "fc58a9813b80afc9811b8ee27679b7_2",
  "x": [
   "We then propose to rely only on these word representations to detect the event roles whereas, in most works (Riloff, 1996; Patwardhan and Riloff, 2007;<cite> Huang and Riloff, 2012a</cite>; Huang and Riloff, 2012b) , the role fillers are represented by a set of different features (raw words, their parts-ofspeech, syntactic or semantic roles in the sentence)."
  ],
  "y": "differences"
 },
 {
  "id": "fc58a9813b80afc9811b8ee27679b7_3",
  "x": [
   "Following previous works (Huang and Riloff, 2011;<cite> Huang and Riloff, 2012a)</cite> , we only consider the \"String Slots\" in this work (other slots need different treatments) and we group certain slots to finally consider the five slot types PerpInd (individual perpetrator), PerpOrg (organizational perpetrator), Target (physical target), Victim (human target name or description) and Weapon (instrument id or type)."
  ],
  "y": "similarities uses"
 },
 {
  "id": "fc58a9813b80afc9811b8ee27679b7_4",
  "x": [
   "Figure 1: F1-score results for event role labeling on MUC-4 data, for different size of training data, of \"String Slots\" on the TST3+TST4 with different parameters, compared to the learning curve of TIER<cite> (Huang and Riloff, 2012a)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "fd50c8cf386e3ce8c8dd8dc46c467f_0",
  "x": [
   "Later,<cite> Yang et al. (2015)</cite> formulated a classifier to distinguish between humorous and non-humorous instances, and also created computational models to discover the latent semantic structure behind humor from four perspectives: incongruity, ambiguity, interpersonal effect and phonetic style."
  ],
  "y": "background"
 },
 {
  "id": "fd50c8cf386e3ce8c8dd8dc46c467f_2",
  "x": [
   "One is Pun of the Day <cite>(Yang et al., 2015)</cite> , and the other is 16000 One-Liners (Mihalcea and Strapparava, 2005) ."
  ],
  "y": "uses"
 },
 {
  "id": "fd50c8cf386e3ce8c8dd8dc46c467f_3",
  "x": [
   "The datasets we use to construct humor recognition experiments includes four parts: Pun of the Day <cite>(Yang et al., 2015)</cite> , 16000 OneLiners (Mihalcea and Strapparava, 2005) , Short Jokes dataset and PTT jokes."
  ],
  "y": "uses"
 },
 {
  "id": "fd50c8cf386e3ce8c8dd8dc46c467f_4",
  "x": [
   "We set the baseline on the previous works of<cite> Yang et al. (2015)</cite> by Random Forest with Word2Vec + Human Centric Feature (Word2Vec + HCF) and Chen and Lee (2017) by Convolutional Neural Networks."
  ],
  "y": "uses"
 },
 {
  "id": "fd7bae08fd3e69744a3980daa1a649_0",
  "x": [
   "Extending the word2vec framework <cite>(Mikolov et al., 2013b)</cite> , paragraph vectors are typically presented as neural language models, and compute a single vector representation for each paragraph."
  ],
  "y": "motivation background"
 },
 {
  "id": "fd7bae08fd3e69744a3980daa1a649_1",
  "x": [
   "Barkan (2017) pointed out that the skip-gram model with negative sampling, also known as word2vec <cite>(Mikolov et al., 2013b)</cite> , admits a Bayesian interpretation."
  ],
  "y": "background"
 },
 {
  "id": "fd7bae08fd3e69744a3980daa1a649_2",
  "x": [
   "The Bayesian skip-gram model (Barkan, 2017 ) is a probabilistic interpretation of word2vec <cite>(Mikolov et al., 2013b)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "fd7bae08fd3e69744a3980daa1a649_3",
  "x": [
   "When training the model, we resort to the heuristics proposed in <cite>(Mikolov et al., 2013b)</cite> to create artificial evidence for the negative examples (see Section 3.2 below)."
  ],
  "y": "uses"
 },
 {
  "id": "fd7bae08fd3e69744a3980daa1a649_4",
  "x": [
   "Following<cite> Mikolov et al. (2013b)</cite> , we construct artificial evidence X \u2212 n for negative pairs by sampling from the noise distribution"
  ],
  "y": "uses"
 },
 {
  "id": "fd7bae08fd3e69744a3980daa1a649_5",
  "x": [],
  "y": "background"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_0",
  "x": [
   "To this end, various sense-specific word embeddings have been proposed to account for the contextual subtlety of language (Reisinger and Mooney, 2010b,a;<cite> Huang et al., 2012</cite>; Neelakantan et al., 2015; Tian et al., 2014; Li and Jurafsky, 2015; Arora et al., 2016) ."
  ],
  "y": "background"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_1",
  "x": [
   "(Reisinger and Mooney, 2010b;<cite> Huang et al., 2012</cite>; Neelakantan et al., 2015) uses neural networks to learn cluster embeddings in order to matcha polysemous word with its correct sense embeddings."
  ],
  "y": "background"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_2",
  "x": [
   "We evaluate our approach on various tasks that require contextual understanding of words, combining existing and new test datasets and evaluation metrics: word-sense induction ( (Koeling et al., 2005; Bartunov et al., 2015) ), contextual word similarity<cite> ((Huang et al., 2012</cite> ) and a new test set), and relevance detection ( (Arora et al., 2016) and a new test set)."
  ],
  "y": "uses"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_3",
  "x": [
   "This idea of local similarity has been widely used to obtain context sense representation<cite> Huang et al., 2012</cite>; Le and Mikolov, 2014; Neelakantan et al., 2015) ."
  ],
  "y": "background"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_5",
  "x": [
   "However, for embeddings from<cite> (Huang et al., 2012)</cite> and (Neelakantan et al., 2015) , which all have norm \u2248 1, the choice of \u03b1 makes little difference."
  ],
  "y": "differences"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_7",
  "x": [
   "Since the code in<cite> (Huang et al., 2012)</cite> allows choosing various distance functions, we pick all and report the best scores."
  ],
  "y": "motivation"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_8",
  "x": [
   "Overall Performance Table 5 shows that our method consistently outperforms<cite> (Huang et al., 2012</cite>; Neelakantan et al., 2015) ."
  ],
  "y": "differences"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_9",
  "x": [
   "In<cite> (Huang et al., 2012</cite>; Neelakantan et al., 2015; , the relevance metric can be seen as the distance (cosine or Euclidean) between the query word and the context cluster center."
  ],
  "y": "background"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_12",
  "x": [
   "Following<cite> (Huang et al., 2012)</cite> , we sort all the n = 2003 test pairs based on predicted similarity score and compare such ranking against the ground-truth ranking indicated by the average human evaluation score."
  ],
  "y": "uses"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_13",
  "x": [
   "We note that in<cite> (Huang et al., 2012</cite> ) the similarity between two word-context pairs is the measured using avgSimC, a weighted average of cosine similarities between all possible representation vectors of w 1 and w 2 ."
  ],
  "y": "differences"
 },
 {
  "id": "fde7f77d4685e1c9ce32a82aed4683_15",
  "x": [
   "One thing to note is that the SCWS Spearman scores of the<cite> (Huang et al., 2012)</cite> listed here are much smaller than that first reported."
  ],
  "y": "differences"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_0",
  "x": [
   "More recently, automatic induction of script knowledge from text have started to attract attention: these methods exploit either natural texts (Chambers & Jurafsky, 2008; 2009) or crowdsourced data<cite> (Regneri et al., 2010)</cite> , and, consequently, do not require expensive expert annotation."
  ],
  "y": "background"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_1",
  "x": [
   "Given a text corpus, they extract structured representations (i.e. graphs), for example chains (Chambers & Jurafsky, 2008) or more gen- eral directed acyclic graphs<cite> (Regneri et al., 2010)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_2",
  "x": [
   "Similarly, an approach which treats the whole predicate-argument structure as an atomic unit<cite> (Regneri et al., 2010)</cite> will probably fail as well, as such a sparse model is unlikely to be effectively learnable even from large amounts of data."
  ],
  "y": "background"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_3",
  "x": [
   "The approach is evaluated on crowdsourced dataset of <cite>Regneri et al. (2010)</cite> and we demonstrate that using our model results in the 13.5% absolute improvement in F 1 on event ordering with respect to their graph induction method (84% vs. 71%)."
  ],
  "y": "uses"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_4",
  "x": [
   "We evaluate our approach on crowdsourced data collected for script induction by <cite>Regneri et al. (2010)</cite> , though, in principle, the method is applicable in arguably more general setting of Chambers & Jurafsky (2008) ."
  ],
  "y": "uses"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_5",
  "x": [
   "<cite>Regneri et al. (2010)</cite> collected short textual descriptions (called event sequence descriptions, ESDs) of various types of human activities (e.g., going to a restaurant, ironing clothes) using crowdsourcing (Amazon Mechanical Turk), this dataset was also complemented by descriptions provided in the OMICS corpus (Gupta & Kochenderfer, 2004) ."
  ],
  "y": "background"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_6",
  "x": [
   "Unlike our work, <cite>Regneri et al. (2010)</cite> relies on WordNet to provide extra signal when using the Multiple Sequence Alignment (MSA) algorithm."
  ],
  "y": "differences"
 },
 {
  "id": "fe0f9312caccf41def06e4311d15fb_7",
  "x": [
   "The methods are evaluated on human annotated scenariospecific tests: the goal is to classify event pairs as appearing in a given stereotypical order or not<cite> (Regneri et al., 2010</cite> )."
  ],
  "y": "background"
 },
 {
  "id": "fe2f22d3d25358b23d0b75a6edee57_0",
  "x": [
   "<cite>Zhou et al. (2017)</cite> utilized the answer-position, and linguistic features such as named entity recognition (NER) and parts of speech (POS) information to further improve the QG performance as the model is aware that for which answer a question need to be generated."
  ],
  "y": "background"
 },
 {
  "id": "fe2f22d3d25358b23d0b75a6edee57_2",
  "x": [
   "In previous works<cite> (Zhou et al., 2017</cite>; Harrison and Walker, 2018) , named entity type features have been used."
  ],
  "y": "motivation"
 },
 {
  "id": "fe2f22d3d25358b23d0b75a6edee57_3",
  "x": [
   "We used the same split as<cite> (Zhou et al., 2017)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "fe30705e03f0475f9ab9d044a3c9ca_0",
  "x": [
   "This makes standard similarity calculations as proposed in (Lin, 1998;<cite> Curran, 2002</cite>; Lund and Burgess, 1996; Weeds et al., 2004) computationally infeasible."
  ],
  "y": "background"
 },
 {
  "id": "fe30705e03f0475f9ab9d044a3c9ca_1",
  "x": [
   "As an example the dependency relation (nsub;gave 2 ;I 1 ) could be transferred to <gave 2 ,(nsub;@;I 1 )> and <I 1 ,(nsub;gave 2 ;@)>. This representation scheme is more generic then the schemes introduced in (Lin, 1998;<cite> Curran, 2002)</cite> , as it allows to characterise pairs by several holes, which could be used to learn analogies, cf."
  ],
  "y": "differences"
 },
 {
  "id": "fe30705e03f0475f9ab9d044a3c9ca_2",
  "x": [
   "In contrast to the best measures proposed by Lin (1998;<cite> Curran (2002</cite>; Pantel et al. (2009; Goyal et al. (2010) we do not calculate any information measure using frequencies of features and terms (we use significance ranking instead), as shown in Table 1 ."
  ],
  "y": "differences"
 },
 {
  "id": "fe30705e03f0475f9ab9d044a3c9ca_4",
  "x": [
   "We create a gold standard, by extracting reasonable entries of these 2000 nouns using Roget's 1911 thesaurus, Moby Thesaurus, Merriam Webster's Thesaurus, the Big Huge Thesaurus and the OpenOffice Thesaurus and employ the inverse ranking measure<cite> (Curran, 2002)</cite> to evaluate the DTs."
  ],
  "y": "uses"
 },
 {
  "id": "fe30705e03f0475f9ab9d044a3c9ca_5",
  "x": [
   "We could not confirm that his measure outperforms Lin's measure as stated in<cite> (Curran, 2002)</cite> 1 ."
  ],
  "y": "differences"
 },
 {
  "id": "fe30705e03f0475f9ab9d044a3c9ca_6",
  "x": [
   "2 Building a gold standard thesaurus following<cite> Curran (2002)</cite> needs access to all the used thesauri."
  ],
  "y": "background"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_0",
  "x": [
   "We evaluated the proposed features with a Support Vector Machines (SVM) classifier using a corpus of 1600 reviews of hotels (<cite>Ott et al., 2011</cite>; Ott et al., 2013) ."
  ],
  "y": "uses"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_1",
  "x": [
   "In order to evaluate our proposal, we have performed some experimental study on the first publicly available opinion spam dataset gathered and presented in (<cite>Ott et al., 2011</cite>; Ott et al., 2013) ."
  ],
  "y": "uses"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_2",
  "x": [
   "The Opinion Spam corpus presented in (<cite>Ott et al., 2011</cite>; Ott et al., 2013 ) is composed of 1600 positive and negative opinions for hotels with the corresponding gold-standard."
  ],
  "y": "background"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_3",
  "x": [
   "From the 800 positive reviews (<cite>Ott et al., 2011</cite>) , the 400 truthful where mined from TripAdvisor 5-star reviews about the 20 most popular hotels in Chicago area."
  ],
  "y": "background"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_4",
  "x": [
   "In (<cite>Ott et al., 2011</cite> ) <cite>the authors</cite> used the 80 dimensions of LIWC2007, unigrams and bigrams as set of features with a SVM classifier."
  ],
  "y": "background"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_5",
  "x": [
   "In Table 4 we can observe the indirect comparison of our results with those of (Banerjee and Chua, 2014) and (Ren et al., 2014) obtained with a 10 fold cross validation experiment, and then, with a 5 fold cross validation in order to make a fair comparison with the results of (<cite>Ott et al., 2011</cite>) and (Feng and Hirst, 2013) ."
  ],
  "y": "uses"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_6",
  "x": [
   "Note that the results are expressed in terms of the accuracy as those were published by <cite>the authors</cite>; the results correspond only to positive reviews of the Opinion Spam corpus because the authors experimented in that corpus alone."
  ],
  "y": "uses"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_7",
  "x": [
   "Regarding the experiments with the 5 fold cross-validation, we obtained similar results to those of (<cite>Ott et al., 2011</cite>) and slightly lower than the ones of (Feng and Hirst, 2013) ."
  ],
  "y": "similarities"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_8",
  "x": [
   "5 fold cross-validation (<cite>Ott et al., 2011</cite>) 89.8% (Feng and Hirst, 2013) 91.3% Our approach 89.8% Table 4 : Indirect comparison of the performance."
  ],
  "y": "similarities"
 },
 {
  "id": "fe539365c7bb4555280fd1a5478aba_9",
  "x": [
   "For the experimental study we have used the positive and negative polarities reviews corresponding to the corpora proposed by (<cite>Ott et al., 2011</cite>; Ott et al., 2013) with 800 reviews each one (400 true and 400 false opinions)."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_0",
  "x": [
   "Cumulatively up to 20% error reduction is achieved relative to the standard <cite>Boulis and Ostendorf (2005)</cite> algorithm for classifying individual conversations on Switchboard, and accuracy for gender detection on the Switchboard corpus (aggregate) and Gulf Arabic corpus exceeds 95%."
  ],
  "y": "differences"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_1",
  "x": [
   "While small-scale sociolinguistic studies on monologues have shed some light on important features, we focus on modeling attributes from spoken conversations, building upon the work of <cite>Boulis and Ostendorf (2005)</cite> and show how gender and other attributes can be accurately predicted based on the following original contributions:"
  ],
  "y": "extends"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_2",
  "x": [
   "Sociolinguistic features: The paper explores a rich set of lexical and non-lexical features motivated by the sociolinguistic literature for gender classification, and show how they can effectively augment the standard ngrambased model of <cite>Boulis and Ostendorf (2005)</cite> ."
  ],
  "y": "extends"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_3",
  "x": [
   "Application to new attributes: We show how the lexical model of <cite>Boulis and Ostendorf (2005)</cite> can be extended to Age and Native vs. Non-native prediction, with further improvements gained from our partner-sensitive models and novel sociolinguistic features."
  ],
  "y": "extends"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_4",
  "x": [
   "While prosodic features have been shown to be useful in gender/age classification (e.g. Shafran et al., 2003) , their work makes use of speech transcripts along the lines of <cite>Boulis and Ostendorf (2005)</cite> in order to build a general model that can be applied to electronic conversations as well.",
   "While <cite>Boulis and Ostendorf (2005)</cite> observe that the gender of the partner can have a substantial effect on <cite>their</cite> classifier accuracy, given that same-gender conversations are easier to classify than mixed-gender classifications, <cite>they</cite> don't utilize this observation in <cite>their</cite> work."
  ],
  "y": "background"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_5",
  "x": [
   "<cite>Boulis and Ostendorf (2005)</cite> have also constrained themselves to lexical n-gram features, while we show improvements via the incorporation of non-lexical features such as the percentage domination of the conversation, degree of passive usage, usage of subordinate clauses, speaker rate, usage profiles for filler words (e.g. \"umm\"), mean-utterance length, and other such properties."
  ],
  "y": "background"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_6",
  "x": [
   "While prosodic features have been shown to be useful in gender/age classification (e.g. Shafran et al., 2003) , their work makes use of speech transcripts along the lines of <cite>Boulis and Ostendorf (2005)</cite> in order to build a general model that can be applied to electronic conversations as well.",
   "While <cite>Boulis and Ostendorf (2005)</cite> observe that the gender of the partner can have a substantial effect on <cite>their</cite> classifier accuracy, given that same-gender conversations are easier to classify than mixed-gender classifications, <cite>they</cite> don't utilize this observation in <cite>their</cite> work.",
   "<cite>Boulis and Ostendorf (2005)</cite> have also constrained themselves to lexical n-gram features, while we show improvements via the incorporation of non-lexical features such as the percentage domination of the conversation, degree of passive usage, usage of subordinate clauses, speaker rate, usage profiles for filler words (e.g. \"umm\"), mean-utterance length, and other such properties."
  ],
  "y": "motivation"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_7",
  "x": [
   "Consistent with <cite>Boulis and Ostendorf (2005)</cite> , we utilized the Fisher telephone conversation corpus (Cieri et al., 2004) and we also evaluated performance on the standard Switchboard conversational corpus (Godfrey et al., 1992) , both collected and annotated by the Linguistic Data Consortium."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_8",
  "x": [
   "The primary task we employed was identical to <cite>Boulis and Ostendorf (2005)</cite> , namely the classification of gender, etc."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_9",
  "x": [
   "We followed the preprocessing steps and experimental setup of <cite>Boulis and Ostendorf (2005)</cite> as closely as possible given the details presented in <cite>their</cite> paper, although some details such as the exact training/test partition were not currently obtainable from either the paper or personal communication."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_11",
  "x": [
   "As our reference algorithm, we used the current state-of-the-art system developed by <cite>Boulis and Ostendorf (2005)</cite> using unigram and bigram features in a SVM framework.",
   "We reimplemented <cite>this</cite> model as our reference for gender classification, further details of which are given below:"
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_12",
  "x": [
   "Also, only the ngrams with frequency greater than 5 were retained in the feature set following <cite>Boulis and Ostendorf (2005)</cite> ."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_13",
  "x": [
   "For compatibility with <cite>Boulis and Ostendorf (2005)</cite> , no special pre- processing for names is performed, and they are treated as just any other unigrams or bigrams 1 ."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_14",
  "x": [
   "The \"<cite>Boulis and Ostendorf</cite>, 05\" rows in Table 3 show the performance of this reimplemented algorithm on both the Fisher (90.84%) and Switchboard (90.22%) corpora, under the identical training and test conditions used elsewhere in our paper for direct comparison with subsequent results 2 ."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_15",
  "x": [
   "Thus, on top of the standard <cite>Boulis and Ostendorf (2005)</cite> model, we also investigated the following features motivated by the sociolinguistic literature on gender differences in discourse (Macaulay, 2005) :"
  ],
  "y": "extends"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_16",
  "x": [
   "As noted before, the standard reference algorithm is <cite>Boulis and Ostendorf (2005)</cite> , and all cited relative error reductions are based on this established standard, as implemented in this paper."
  ],
  "y": "uses"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_17",
  "x": [
   "The additional table rows are described in Sections 4-6, and cumulatively yield substantial improvements over the <cite>Boulis and Ostendorf (2005)</cite> with the work reported by <cite>Boulis and Ostendorf (2005)</cite> ), all of the above models can be easily extended to per-speaker evaluation by pooling in the predictions from multiple conversations of the same speaker."
  ],
  "y": "differences"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_21",
  "x": [
   "To give maximal consistency/benefit to the <cite>Boulis and Ostendorf (2005)</cite> n-gram-based model, we did not filter the self-reporting n-grams such as \"im forty\" and \"im thirty\", putting our sociolinguisticliterature-based and discourse-style-based features at a relative disadvantage."
  ],
  "y": "differences"
 },
 {
  "id": "ff7bafb8f21118ca3c908603ef32d0_22",
  "x": [
   "Cumulatively up to 20% error reduction is achieved relative to the standard <cite>Boulis and Ostendorf (2005)</cite> algorithm for classifying individual conversations on Switchboard, and accuracy for gender detection on the Switchboard corpus (aggregate) and Gulf Arabic exceeds 95%."
  ],
  "y": "differences"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_1",
  "x": [
   "We show that in the original supervised setting a distributional model, namely a novel application of BERT (Devlin et al., 2019) , significantly outperforms the best existing method which has access to manually labeled physical features<cite> (Wang et al., 2018)</cite> ."
  ],
  "y": "differences"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_2",
  "x": [
   "We create a training set by parsing and extracting attested s-v-o triples from English Wikipedia, and we provide a baseline for training on this dataset and evaluating on <cite>Wang et al. (2018)</cite> 's physical plausibility task."
  ],
  "y": "uses"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_3",
  "x": [
   "arXiv:1911.05689v1 [cs.CL] 13 Nov 2019 <cite>Wang et al. (2018)</cite> present the semantic plausibility dataset that we use for evaluation in this work, and they show that distributional methods fail on this dataset."
  ],
  "y": "uses background"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_4",
  "x": [
   "Current approaches to selectional preference are distributional (Erk et al., 2010; Van de Cruys, 2014) and have shown limited performance in capturing semantic plausibility<cite> (Wang et al., 2018)</cite> ."
  ],
  "y": "background"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_5",
  "x": [
   "We use <cite>Wang et al. (2018)</cite> 's physical plausibility dataset for evaluation."
  ],
  "y": "uses"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_6",
  "x": [
   "We follow the same evaluation procedure as previous work and perform cross validation on the 3,062 labeled triples<cite> (Wang et al., 2018)</cite> ."
  ],
  "y": "similarities uses"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_7",
  "x": [
   "For evaluation, we split <cite>Wang et al. (2018)</cite>'s 3,062 triples into equal sized validation and test sets."
  ],
  "y": "extends"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_8",
  "x": [
   "We reproduce the results of <cite>Wang et al. (2018)</cite> using GloVe embeddings and the same hyperparameter settings."
  ],
  "y": "similarities"
 },
 {
  "id": "ffd65a1a02c852a2670b471fb4b110_9",
  "x": [
   "For the supervised setting, we follow the same evaluation procedure as <cite>Wang et al. (2018)</cite> : we perform 10-fold cross validation on the dataset of 3,062 s-v-o triples, and report the mean accuracy of running this procedure 20 times all with the same model initialization (Table 3) ."
  ],
  "y": "similarities uses"
 }
]